{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests improvements but doesn't explicitly state what needs to be done. It implies the dataset might be noisy and contains misinformation/outofcontext images, but lacks specific instructions on how to address this. Therefore, it is not fully actionable as it does not provide concrete steps for the authors to take.", "grounding_specificity_rationale": "The review point mentions 'the dataset,' 'pristine set of tweets,' 'misinformation,' and 'outofcontext images,' which are somewhat general descriptions of potential issues. While it identifies areas of concern, it doesn't pinpoint a specific section, table, figure, or unique element within the paper or dataset that needs addressing. Therefore, it is not fully grounded specific.", "verifiability_rationale": "The review point makes a claim about the potential noise and inaccuracies in the dataset but does not provide any evidence or references to support this claim. It states a hypothesis rather than a verifiable statement. Therefore, it is 1 as it lacks supporting evidence or justification.", "helpfulness_rationale": "The review point raises a valid concern about the potential noise and inaccuracies in the artificially created dataset. It points out potential issues that could affect the quality and reliability of the data. While it doesn't provide solutions, it identifies a problem that the authors should be aware of. Therefore, it is 3 in highlighting potential problems with the dataset."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states the absence of theoretical analysis and convergence properties. While it suggests adding a section, the specifics of *where* and *how* to do this are not detailed. The action (identifying the missing theory) is clear, but the implementation details are vague.", "grounding_specificity_rationale": "The review point mentions the lack of 'theory' and 'convergence properties' in the paper. However, it does not specify which particular section, table, figure, or unique element of the paper is lacking this. The 'what' is clear, but the 'where' is not.", "verifiability_rationale": "The review point claims that the paper 'does not dig into the theory' and 'does not show the convergence properties'. This is a claim that needs to be supported. However, the review point does not provide any justification or references to back up this assertion. The claim is stated without any logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper: the absence of a theoretical analysis section and discussion of convergence properties. This is a relevant point that could guide the authors to improve their work. However, the suggestion to 'add a section' is quite general and lacks specific details on what should be included in this section or how the analysis should be conducted. The helpfulness is limited because the suggestion is broad and lacks concrete guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer is asking a question about the selection process, not providing an explicit action or suggestion for improvement. The question is about the 'why' and 'what if' of the selection, not what to do to fix something.", "grounding_specificity_rationale": "The reviewer is asking a question about the selection process and its potential impact, not specifically about a part of the paper or providing examples related to a specific section. The question is about the 'how' and 'what if' of the evaluation, not a specific 'what needs to be done' in a particular section.", "verifiability_rationale": "The reviewer is asking a question, not making a claim that requires verification. The question is about the methodology of the selection process, not a statement that needs supporting evidence.", "helpfulness_rationale": "The reviewer is asking a question about the evaluation process and its potential impact, not providing specific feedback or suggestions for improvement in the paper itself. The question is about the 'why' and 'what if' of the evaluation, not actionable steps to fix the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a missing explanation for the average duration reported in Table 1. While they don't explicitly state the purpose, they imply it's likely related to model performance. This suggests the original text lacked a clear *inference* about the table's purpose.", "grounding_specificity_rationale": "The reviewer asks a question directly referencing Table 1, indicating they are interested in information within that specific section. However, they do not explicitly identify the section or table they are referring to. They also do not provide examples of where the duration is reported in the table.", "verifiability_rationale": "The reviewer makes a claim that the paper lacks supporting explanation for the average duration in Table 1. However, they do not provide any external references or logical reasoning to back up this claim.", "helpfulness_rationale": "The reviewer's question directly points to a lack of clarity and a need for improvement in the paper. While they don't provide a specific solution, they highlight a actionable area for the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their intention to clarify Table 4 and asks a specific question about the 'splits' used. This is an explicit action, as the reviewer is directly stating what they want to know. The action is also concrete, as the reviewer clearly identifies the 'splits' as the missing information.", "grounding_specificity_rationale": "The reviewer's comment directly refers to 'Table 4' and the 'ATIS numbers' within it. This provides a clear grounding of the comment to a specific part of the paper. The reviewer also explicitly mentions 'splits', which is a specific detail within Table 4.", "verifiability_rationale": "The reviewer's comment is a question about the methodology used to obtain the ATIS numbers. While the comment itself doesn't contain a claim that requires verification, the request for clarification implies a lack of current understanding or information within the paper. Without knowing the splits, the reviewer's point about Table 4 is not 5. The information needed to verify the claim is missing from the paper.", "helpfulness_rationale": "The reviewer's comment is directly addressing a potential weakness in the paper \u2013 the lack of clarity regarding the experimental setup for Table 4. By asking about the 'splits', they are requesting information that would significantly improve their understanding and potentially the reproducibility of their work. While the comment itself doesn't provide new information, it is a valuable piece of feedback that points to a missing element that would be helpful for the authors. The reviewer is essentially asking for a clarification that is likely to be beneficial for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem (inconsistent spacing) but does not provide a concrete action or suggestion on how to address it. The reviewer points out the issue but doesn't tell the authors what to do about it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 2 and Table 3', which are specific parts of the paper. The comment clearly identifies the issue within these referenced sections.", "verifiability_rationale": "The reviewer points out a potential issue (inconsistent spacing) which can be considered a deduction or inference. However, there is no external reference or justification provided within the review point itself to support this observation as a problem.", "helpfulness_rationale": "The review point identifies a formatting issue, which is a valid concern. However, it is a minor, nonsubstantive critique and does not offer significant guidance or solutions. It is helpful in that it highlights a detail, but it lacks the depth and actionable suggestions that would be more beneficial."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem ('confusing') and provides a clear action ('more separate paragraphs'). The suggestion is concrete and directly addresses the identified issue. The reviewer knows what they want to achieve (clarify the section) and how to do it (reorganize the content).", "grounding_specificity_rationale": "The reviewer refers to 'Section 3.2' and mentions 'lexical features' and 'sentencelevel features', which grounds the reference to specific parts of the paper. While the suggestion is somewhat general within that section, it points to a specific area of potential confusion (the organization of the section). The reviewer is confident about the section and features mentioned, but less specific about the *exact* nature of the confusion.", "verifiability_rationale": "The review point is a suggestion for improvement rather than a claim requiring verification. There is no logical reasoning, common knowledge, or external references being made to support the suggestion. It's a direct recommendation, not a statement that needs to be proven.", "helpfulness_rationale": "The reviewer directly addresses a potential hindrance for authors (potential confusion) and provides a clear and actionable suggestion (reorganize the section). This is a valuable piece of feedback that directly helps authors understand and implement the changes. The reviewer anticipates the need for authors to clarify the section and offers a concrete solution."}
{"actionability_label": "1", "grounding_specificity_label": "3. 2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point does not explicitly state what the reviewer suggests the authors should do. The reviewer expresses their opinion about the space allocation but does not provide concrete actions or modifications. The reviewer states 'I find that dedicating a whole section of the paper plus experimental results is a lot of space.' This is a statement of opinion, not a suggestion for a specific action.", "grounding_specificity_rationale": "The reviewer refers to 'a whole section of the paper' and 'experimental results' generally. While they identify a category of information, they do not pinpoint a specific part of the paper, such as a table, figure, or unique element. The reference is vague and lacks precision.", "verifiability_rationale": "The review point does not contain a claim that can be verified. It is a statement of opinion about the space allocation. There is no logical reasoning, common knowledge, or external references provided to support this opinion. The reviewer states 'I find that dedicating a whole section of the paper plus experimental results is a lot of space.' This is a subjective statement without any backing.", "helpfulness_rationale": "The review point is not particularly helpful to the authors. It is a critique of the space allocation but does not provide specific suggestions or actionable feedback on how to improve their paper based on this observation. The reviewer states 'I find that dedicating a whole section of the paper plus experimental results is a lot of space.' This is a negative comment without any concrete advice or a clear benefit to the authors."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "Partially Verifiable", "helpfulness_label": "Partially Helpful", "actionability_rationale": "The first part of the review point, 'The abstract is written well and invokes intriguing early', is a positive statement and does not provide an actionable suggestion. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', suggests a direction for improvement and provides a specific example. Therefore, this part is actionable.", "grounding_specificity_rationale": "The first part of the review point, 'The abstract is written well and invokes intriguing early', does not specify which aspect of the abstract is particularly strong or where improvements could be made. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', explicitly mentions the inconsistency and provides a concrete example. Therefore, this part is 5.", "verifiability_rationale": "The first part of the review point, 'The abstract is written well and invokes intriguing early', is a statement of opinion and does not contain a claim that requires verification. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', makes a claim ('could potentially be made even better if...') and provides a specific example ('an example of the inconsistency, such as models get ranked differently') to illustrate the point. Therefore, this part is 5.", "helpfulness_rationale": "The first part of the review point, 'The abstract is written well and invokes intriguing early', is a positive statement and does not offer actionable feedback, so it is not helpful. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', suggests a direction for improvement and provides a concrete example. This directly addresses a potential weakness and offers a way to improve the abstract. Therefore, this part is 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for a discussion on the convergence of the joint learning process and its connection to obtaining stable points in probabilistic metric space. This directly implies an action: to explain how this convergence is achieved and how it leads to stable points. The reviewer clearly identifies the missing element and specifies what needs to be explained, making it concrete. Therefore, the reviewer provides a clear and actionable suggestion for the authors.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the convergence of the proposed joint learning process' and 'stable points in probabilistic metric space' as the specific parts of the paper being addressed. This is a clear and precise identification of the relevant section and concepts. The reviewer also specifies the issue: 'how the stable points in probabilistic metric space are obtained'. This further clarifies the exact area of concern. Therefore, the reviewer's comment is 5.", "verifiability_rationale": "The reviewer's comment is not a claim that needs verification, but rather a suggestion for improvement. However, the reasoning behind this suggestion is clear: the lack of this discussion could make it difficult to reproduce the results. This implicit reasoning provides a basis for verification, even though no explicit claim is made. The reviewer is pointing out a missing element that would be helpful for understanding. The need for clarity on convergence and stable points is a logical and commonsense argument. The reviewer implicitly suggests that the authors should provide this information, which could be supported by referencing papers on probabilistic metric spaces and RNN convergence. Therefore, the reviewer's comment is verifiable through the need for clarity and the logical reasoning behind it.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for the authors: to include a discussion on the convergence of the joint learning process and the obtaining of stable points in probabilistic metric space. This directly addresses a potential weakness for the authors (lack of clarity on this aspect) and provides a concrete improvement. The reviewer's comment is directly helpful for the authors' understanding and the reproducibility of their results. While it's not a claim being verified, the suggestion is a valuable contribution to the paper. The reviewer's comment is a helpful suggestion that is directly relevant to the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "Part 1 of the review point implicitly suggests discussing the results for task 1 and mentioning model (B). While it doesn't explicitly state 'do this,' the phrasing implies an action. Part 2 explicitly states 'discuss the results for the task of inferring knowledge on objects' and 'include results for model (B)', which are clear actions. However, the implicit nature of Part 1 makes the overall actionability borderline.", "grounding_specificity_rationale": "Part 1 of the review point refers to '681 as mentioned above', which is vague and doesn't clearly identify a specific part of the paper. Part 2, while general, doesn't pinpoint a specific section or aspect being criticized. Therefore, the grounding specificity is weak.", "verifiability_rationale": "The review point doesn't make a claim that needs verification. It's more of a suggestion and a request for more information. There's no assertion of correctness or lack thereof, so verifiability is not applicable.", "helpfulness_rationale": "The review point provides suggestions for improvement ('discuss the results for the task of inferring knowledge on objects' and 'include results for model (B)') and asks a question ('why don't you mention objects here?'). While the grounding specificity is weak, the intent to provide helpful feedback is present, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the description in line 212 is potentially incorrect and suggests clarifying the description. This indicates a clear action the authors should take.", "grounding_specificity_rationale": "The reviewer directly references 'line 212' and 'Figure 2', providing a precise location in the paper and context for the issue. This indicates strong grounding. They also specify the potential problem with the GRU output being a single vector instead of a set of vectors, adding to the specificity.", "verifiability_rationale": "The reviewer makes a claim about the correctness of the sentence in line 212 and provides their understanding of bidirectional encoders as supporting evidence. While they don't provide explicit references or logical reasoning within this specific review point, their understanding is a form of implicit verification, suggesting the issue is likely valid based on their expertise.", "helpfulness_rationale": "The reviewer identifies a specific area of potential confusion for the authors (the GRU output) and suggests a concrete action (clarifying the description). This directly benefits the authors and guides their next steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a preference for 'additional baselines' but does not provide specific guidance on how to implement or apply this suggestion. While it points towards a potential improvement, it lacks concrete action items.", "grounding_specificity_rationale": "The comment refers to 'this work' without explicitly naming a specific section, table, or figure. While it grounds the discussion in the reviewer's own research area, it doesn't pinpoint the exact aspect of their work that would benefit from additional baselines.", "verifiability_rationale": "The comment contains a claim ('would be nice to see some additional baselines') and provides a justification ('fairly straightforward extension of existing retrofitting work'). While the justification is somewhat subjective, it offers a basis for consideration.", "helpfulness_rationale": "The comment clearly identifies a potential area for improvement ('additional baselines') and suggests a specific type ('character embeddings'). While the suggestion itself might not be fully detailed, it provides a clear direction for the authors to explore and potentially enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the issue with the yaxis label of figure 5 and suggests a concrete change by using 'Exact Match ratio' directly. This is an explicit and concrete action that the authors can readily implement.", "grounding_specificity_rationale": "The comment explicitly mentions 'figure 5' and clearly identifies the issue with the yaxis label, making it fully grounded. It also specifies the desired change, making it specific.", "verifiability_rationale": "The comment suggests a change to the yaxis label of figure 5, implying that the current label ('Exact Match ratio') might be confusing or ambiguous. While it doesn't provide external references, the suggestion itself acts as a form of implicit verification that the current label is a potential point of confusion, and the suggested change is a clear and direct way to address it.", "helpfulness_rationale": "The comment directly points out a potential source of confusion for the authors regarding the yaxis label of figure 5 and offers a clear and actionable solution. This is likely to be helpful for the authors in improving their understanding and presentation of the figure."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a relevant concern (societal biases) and suggests a general approach (reasoning chains). However, the lack of specific implementation details makes it only 3.", "grounding_specificity_rationale": "The reviewer mentions 'societal biases' and 'knowledge bases' in a general way. They don't pinpoint a specific part of their work or the knowledge base that is being affected.", "verifiability_rationale": "The reviewer states a concern about societal biases in knowledge bases but doesn't provide any evidence or justification for this concern within the review point itself. The suggestion to use reasoning chains is a proposed solution, not a claim needing verification.", "helpfulness_rationale": "The reviewer raises a relevant concern about societal biases and suggests a general approach (reasoning chains). However, they don't provide specific steps or tools the authors should use, making it 3 but not fully so."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'improve the attention mechanism'. It also suggests a direction for this action: 'change the attention mechanism'. This is an explicit action with concrete steps, making it actionable.", "grounding_specificity_rationale": "The reviewer mentions 'seq2seq MTL' and 'attention mechanism' generally. While they indicate the area of the paper being discussed, they do not specify a particular section, table, figure, or unique element within the paper. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a critique of the process of showing attention's value rather than a critique of a specific aspect of a paper. Therefore, it contains 'X'.", "helpfulness_rationale": "The review point highlights a valid limitation in the current approach of demonstrating attention's value in seq2seq MTL. By pointing out this difficulty, it provides valuable feedback to authors, encouraging them to consider alternative approaches or more rigorous evaluation methods. While it doesn't directly solve the problem, it identifies a relevant issue that can help improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment implicitly suggests adding strong baselines to Table 3 for MCNC but doesn't explicitly state the steps or methods to achieve this. The reviewer wants to see these comparisons, indicating an actionable need, but the action itself is not clearly defined.", "grounding_specificity_rationale": "The comment explicitly mentions 'Table 3' and 'MCNC', indicating a clear identification of the specific part of the paper being addressed. It also specifies the need for 'strong baselines', detailing what is missing in the referenced part.", "verifiability_rationale": "The comment contains a claim (i.e., a statement of opinion) that 'MCNC should have many strong baselines that are not compared here' and requires justification ('can you justify the reason?'). This claim is supported by the reviewer's observation of the missing baselines and their request for explanation, making it verifiable.", "helpfulness_rationale": "The comment directly points out a weakness in the paper (the lack of strong baselines for MCNC) and suggests a concrete improvement (adding these baselines). This constructive feedback is intended to help the authors improve their draft, making the review 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the dependency of the paper on supplementary material through references like 'Sup. Fig. 6' and mentions 'model comparison' and 'span vs. sentence investigation' which are likely findings in the supplementary material. While the reviewer identifies a potential issue (the paper not being truly independent), they do not explicitly state what action the authors should take. The reviewer implies a problem but doesn't provide a clear, actionable step.", "grounding_specificity_rationale": "The reviewer specifically mentions 'Sup. Fig. 6' and refers to 'model comparison' and 'span vs. sentence investigation'. This indicates that the reviewer has identified specific parts of the supplementary material that are relevant to the criticism. The use of 'esp. S3.1 reference to Sup. Fig. 6' suggests a strong connection between the main text and the supplementary material. The reviewer is not just saying 'there's a reference to supplementary material', but rather pinpointing specific instances.", "verifiability_rationale": "The reviewer makes a judgment about the paper's independence based on the references to supplementary material. This constitutes a claim. However, the reviewer does not provide any specific evidence or reasoning to support this claim within the review point itself. The reasoning is that if the main text refers to supplementary material, the main text should be independent. The claim is based on the *implied* dependency rather than direct evidence.", "helpfulness_rationale": "The reviewer highlights a potential issue with the paper's referencing, specifically the reliance on supplementary material. This is a clear statement of a problem that the authors might encounter. However, the reviewer does not suggest a specific action or improvement that the authors should take based on this criticism. The criticism points out a potential hurdle for the authors, but it doesn't provide a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests providing more information about the annotation process, which is a concrete action. However, the specifics of what information is needed (e.g., specific traits of experts, differences from nonexpert annotation) are not explicitly stated, making it somewhat vague on the action side. The reviewer implies that this additional information would be beneficial, indicating an action that needs to be taken.", "grounding_specificity_rationale": "The reviewer mentions 'experts' in the context of annotation, which provides some grounding. However, the reviewer does not specify which experts, the unique aspects of the paper they are annotating, or the specific linguistic challenges involved. The mention of 'experts' is a general statement without precise identification, indicating weak grounding. The reviewer also asks about the 'traits of the experts,' which is a vague request without specifying the context or the nature of the annotation.", "verifiability_rationale": "The reviewer asks for a 'justification' of why annotation must be carried out by experts. This constitutes a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The justification is missing, making it 1.", "helpfulness_rationale": "The reviewer suggests several directions for improvement in the annotation process, such as describing the traits of experts and justifying expert annotation. These are relevant suggestions that could directly help the authors. However, the suggestions are presented as questions or requests rather than concrete, actionable improvements. The potential for helpfulness is present, but it needs to be realized through more specific recommendations."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point suggests improvements but does not specify how to achieve them. It lacks concrete actions or directions for the author.", "grounding_specificity_rationale": "The review point does not refer to any specific part of the paper or draft. It is a general suggestion without pinpointing the relevant section or element.", "verifiability_rationale": "The review point is a suggestion, not a claim that requires verification. It does not make any assertions that need to be supported by evidence.", "helpfulness_rationale": "The review point is a suggestion for improvement, but it lacks specific details and direction for the author. It is more of a request for information than a critique or actionable suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that 'A number of claims from this paper would benefit from more indepth analysis.' This is an explicit action, as it tells the authors what needs improvement. However, the comment is vague on how to achieve this. The authors are left to figure out what 'more indepth analysis' entails, whether it involves looking at evidence, checking citations, or comparing with other work. The action is not concrete enough to guide the authors directly on the next steps.", "grounding_specificity_rationale": "The comment states 'A number of claims from this paper would benefit from more indepth analysis.' While it identifies that the claims need more analysis, it does not specify *which* claims are being referred to. The comment does not mention any specific section, table, figure, or unique element of the paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The comment does not make a claim in the sense of stating something is wrong or requiring justification. It is a suggestion for improvement: 'A number of claims from this paper would benefit from more indepth analysis.' There is no assertion that something is incorrect, needs evidence, or requires a specific reference. Therefore, there is X to be verified.", "helpfulness_rationale": "The comment suggests that the paper's claims could benefit from more indepth analysis. This is a helpful suggestion as it points towards a concrete next step for the authors. It encourages them to think critically about the claims and potentially strengthen their arguments by exploring more evidence or comparing with other work. While it doesn't provide specific *how* to do the analysis, it guides the authors towards a valuable area of improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper 'does not really study these hypotheses' and suggests 'I would have also liked the paper to go deeper into the respective topics, at least to some extent.' This is a clear and direct criticism of the paper's content and the lack of action taken on the introduced hypotheses. The reviewer identifies the missing action (studying the hypotheses) and provides a suggestion for improvement (going deeper).", "grounding_specificity_rationale": "The reviewer explicitly mentions the hypotheses in lines 078086, indicating a clear grounding of the comment in the specific part of the paper being discussed. However, the reviewer does not specify *what* aspect of the hypotheses is lacking study. They only state that the hypotheses are not studied and suggest going deeper. This lack of specificity makes the grounding somewhat underspecific.", "verifiability_rationale": "The reviewer makes a clear claim: 'the paper actually does not really study these hypotheses (nor are they even mentioned/discussed again).' This claim is directly verifiable by examining the paper's content. The reviewer points to the absence of any discussion or analysis of the hypotheses, which can be confirmed by reviewing the relevant sections. The claim is based on a direct observation of the paper's content.", "helpfulness_rationale": "The reviewer clearly identifies a deficiency in the paper (the lack of study of the hypotheses) and offers a constructive suggestion for improvement ('I would have also liked the paper to go deeper...'). The comment is direct, points to a concrete issue, and offers a clear direction for the authors to take. The reviewer's statement about the hypotheses not being studied is actionable and verifiable."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states their lack of understanding regarding the use of the Challenge Set (CS). While they implicitly state they want clarification, the action of identifying a lack of clarity could be considered somewhat vague in terms of how to apply this understanding. The reviewer doesn't specify *how* the CS is used, making the action somewhat general.", "grounding_specificity_rationale": "The reviewer explicitly asks 'What is not clear also to me is how is used the Challenge Set.' This directly identifies the CS as the object of their inquiry, indicating strong grounding. However, the reviewer does not specify *how* the CS is used, leaving the specificity level underdetermined.", "verifiability_rationale": "The reviewer states 'I understood correctly, the CS is created by the linguistic experts and it's used for evaluation purposes.' This is a claim that needs to be verified. The reviewer does not provide any external references or logical reasoning to support this claim within the review point itself. The justification for this statement is missing.", "helpfulness_rationale": "The reviewer's primary concern is the lack of clarity regarding the use of the Challenge Set. This lack of clarity directly impacts the helpfulness of the review point for the authors. The authors would benefit from a clear explanation of the CS's role."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides an implicit suggestion by pointing out the issues with constituent parse and the term 'knowledge'. While they don't explicitly state 'I suggest using a sequence of words', the context implies it. The lack of a concrete action makes it less actionable than a comment that directly states 'Use a sequence of words for substructure'.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the paper claims the model generalizes to different knowledge', which directly points to a specific area in the paper. While they don't provide a literal section number, the phrasing strongly implies a section discussing the model's generalization capabilities. The reviewer then provides specific examples ('constituent parse' and 'sequence of words'), adding to the specificity of the grounding.", "verifiability_rationale": "The reviewer makes a claim: 'I think the substructure has to be represented as a sequence of words...'. They also provide a justification: 'it doesn't seem straightforward for me to use constituent parse as knowledge here'. The 'hesitation to call it \"knowledge\"' suggests a lack of clarity in the paper's terminology, which could be seen as a need for more evidence or a clearer explanation of why 'knowledge' might be misleading. The reasoning is present, but the level of detail could be higher.", "helpfulness_rationale": "The reviewer clearly identifies a potential issue with the representation of substructure and the terminology used ('knowledge'). They offer a concrete alternative ('sequence of words') and question the appropriateness of the term. This provides the authors with a direction for improvement and highlights a potential area for clarification. The suggestions are specific enough to be actionable."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'The relatively poor performance on nouns makes me uneasy' and then mentions 'PPDBClus' as a dataset where the gap is higher than most clustering approaches. This indicates a clear action the authors should take to investigate the cause of this performance discrepancy on nouns. The reviewer also implies that the claim about generalizability to all parts of speech is contradicted by the observed nonuniform performance, which is a specific action the authors should consider.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'nouns' as the part of speech with poor performance and also specifically mentions 'PPDBClus' as the dataset where the higher oracle GAP for clustering approaches is observed. This strong mention of specific parts of speech and the dataset clearly grounds the comment in the paper's content. The reviewer then states 'This also directly contradicts the claim that the clustering approach is generalizable to all parts of speech (124126), since the performance clearly isn't uniform.' This shows a clear identification of the specific issue and the contradiction with a claim made in the paper.", "verifiability_rationale": "The reviewer states 'the fact that the oracle GAP for PPDBClus is higher than most clustering approaches is disconcerting.' This is a claim that requires verification. While the reviewer points out a factual observation, they do not provide specific examples or references to external works to support their claim that this performance gap is disconcerting or that it contradicts the generalizability claim. The reasoning is stated as 'This also directly contradicts the claim that the clustering approach is generalizable to all parts of speech (124126), since the performance clearly isn't uniform.' While this provides some context, it lacks detailed justification or evidence to fully verify the claim.", "helpfulness_rationale": "The reviewer's comment directly points to a specific performance issue (poor performance on nouns) and highlights a potential contradiction in the paper's claims about the generalizability of the clustering approach. This is a focused and actionable feedback for the authors. The reviewer's statement 'I would like to understand the gap better' indicates a clear desire for the authors to investigate and improve their model. The comment is specific and directly related to the model's performance on a particular dataset and part of speech."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states they 'don't get the insights why the new model is better than MH' and asks for 'examples of spurious structures'. This indicates that the explanation in section 5.2 was not explicit enough to guide the reviewer in understanding the model's superiority. While the reviewer identifies a need for improvement, the specific action of 'providing examples' is not detailed enough to be fully actionable. The reviewer understands the *what* (need for examples) but not the *how* (specific examples and their relevance).", "grounding_specificity_rationale": "The reviewer mentions 'section 5.2' and 'examples of spurious structures'. While they identify a specific section, they don't pinpoint the exact part of the section or the precise nature of the 'spurious structures' they are looking for. The grounding is present (they mention a section), but it's not fully precise. The request for 'examples' is specific, but the *type* of examples is not defined.", "verifiability_rationale": "The reviewer states a clear opinion: 'I don't get the insights why the new model is better than MH'. This is a claim that needs to be supported. The reviewer then suggests 'examples of spurious structures' as a way to verify this claim. However, the paper does not currently provide these examples, and the request itself is a statement that needs to be addressed. The reviewer identifies a gap in the paper's explanation, but the suggestion for examples is a way to address it, not a 5 claim on its own.", "helpfulness_rationale": "The reviewer's review points to a genuine area of confusion regarding the model's superiority. They explicitly state they 'don't get the insights' and offer a suggestion for improvement by asking for 'examples of spurious structures'. While this suggestion is relevant and could be helpful, it is vague and lacks specific details. The reviewer acknowledges the need for clarification but doesn't provide a concrete, actionable step beyond the general suggestion of examples. Therefore, the review is helpful in identifying a problem but not in offering a direct solution."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit instructions on how to create the baseline PCFG and how to compare its perplexity to the original PCFG. The steps are clear and directly lead to implementation. The reviewer explicitly states the size of the state space and the parameterization of the matrices, making the action clear and actionable. The purpose of comparing perplexity is also stated, indicating a clear intention for the comparison.", "grounding_specificity_rationale": "The reviewer's suggestion is general and doesn't explicitly link the proposed baseline to a specific part of an existing PCFG. While it proposes a *type* of baseline, it doesn't specify *where* within an existing PCFG this baseline should be applied or why this comparison is important for a particular component. The reviewer mentions 'a PCFG' generally, without specifying a particular section, table, figure, or unique aspect of the existing PCFG.", "verifiability_rationale": "The reviewer makes a claim that this baseline provides a meaningful comparison point by suggesting comparing perplexity. The reviewer provides a method for verifying this claim by describing how to create the baseline and how to compare perplexity. The claim is supported by the proposed method, although the reviewer doesn't delve into the theoretical justification for why this comparison is valid or provide specific references for the use of perplexity in this context. The logical reasoning is present in suggesting a comparison metric, and the common knowledge aspect is in proposing a concrete method.", "helpfulness_rationale": "The review point is 5 as it directly addresses a potential issue with existing PCFGs (noncomparable parsing F1 scores) by proposing a valid alternative comparison metric (perplexity). The instructions are clear and specific, guiding the reader on how to implement the suggested baseline and perform the comparison. The reviewer's suggestion is actionable and provides a concrete way to evaluate PCFGs even when parsing F1 is not directly comparable. The impact on improving the evaluation process for PCFGs is clear."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action (providing information) and is concrete in specifying the information needed (maximum number of tasks, any annotator). The request is clear and directly leads to a specific piece of information.", "grounding_specificity_rationale": "The comment explicitly mentions 'maximum number of tasks done by any annotator' which is a specific piece of information. However, it does not specify which part of the paper this information relates to, leaving the authors to infer the relevance. The grounding is explicit but the connection to a specific section or table is missing.", "verifiability_rationale": "The comment does not contain a claim in the sense of an opinion or assertion. It is a suggestion to provide information. However, if we interpret 'verifiability' as the potential for this suggestion to be actionable and verifiable by providing the requested statistic, then it is 3 as the information could be obtained and potentially used to assess the annotation load or quality of the data. The ' claim' definition focuses on opinions or suggestions, which this point lacks.", "helpfulness_rationale": "The comment is a direct suggestion to provide a specific piece of information (maximum number of tasks done by any annotator). This information could be useful for the authors to understand the scale of the annotation effort and potentially identify any inconsistencies or biases in the annotation process. It is a practical and actionable suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "5 and Specific", "helpfulness_label": "3", "actionability_rationale": "The review point does not contain explicit or implicit actions for the authors to take. While it suggests including a hard prompt baseline, it doesn't specify how this should be done or what the expected outcome should be. The action is implied but not clearly stated.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or methodology that would benefit from the hard prompt baseline. It is a general suggestion for improving the presentation of results. Therefore, the grounding is weak as it cannot precisely identify the referenced part.", "verifiability_rationale": "The suggestion to include a hard prompt baseline is highly verifiable. The reviewer is proposing a specific implementation detail and asking for its impact on performance. This is a clear and logical claim that can be supported by experimental evidence or existing literature on hard prompting.", "helpfulness_rationale": "The suggestion to include a hard prompt baseline in Table 1 to see the increase in performance is potentially helpful. It provides context for the performance gains observed with the proposed methods and could be valuable for readers unfamiliar with hard prompting. However, it is a relatively minor suggestion and might not significantly alter the core message of the paper. Therefore, it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a 'lack of numerical results' but does not specify what these results should be, how they should be presented, or what impact they would have on the authors' work. The action is stated, but the details are missing, making it less actionable.", "grounding_specificity_rationale": "The comment mentions 'popular algorithms' and 'existing DP algorithms,' which provides some grounding by referencing a general category of algorithms. However, it does not specify which algorithms are being referred to or how they relate to the specific work being reviewed. The grounding is present but not very specific.", "verifiability_rationale": "The comment states a 'lack of numerical results' without providing any justification or reasoning. There is no logical connection drawn to explain why this is a problem or how it affects the understanding or application of the work. The claim is made without sufficient support.", "helpfulness_rationale": "The comment expresses a desire for 'numerical results' and a comparison with 'existing DP algorithms.' This directly addresses a potential need for the authors to understand the practical implications of their work. However, the request is vague and lacks specific details, making it 3 but not entirely helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'It would be good to show some empirical evidence...'. This is a direct and clear request for improvement. While it doesn't specify *how* to show the evidence, it clearly identifies the missing element (empirical evidence) and suggests a direction (for the third contribution). Therefore, it is considered explicit and points towards a concrete action, albeit one that requires further specification.", "grounding_specificity_rationale": "The comment refers to 'the third contribution of the paper' and 'the Column Subset Selection problem'. This demonstrates an attempt to identify the specific part of the paper being addressed. While it doesn't provide a literal section number, it clearly points to a specific aspect of the contribution. Therefore, it can be considered grounded. The specificity is also high as it clearly identifies the problem being addressed.", "verifiability_rationale": "The comment does not contain a claim in the sense of a critique or a statement that needs to be proven. It is a suggestion for improvement, not a statement that something is wrong or needs verification. Therefore, it does not have supporting evidence and is classified as having X (X).", "helpfulness_rationale": "The comment directly points out a missing element (empirical evidence) for a key contribution (the third contribution) and suggests a specific improvement (including evidence for the Column Subset Selection problem). This is a clear and actionable criticism that directly addresses a potential weakness. While it doesn't demand a specific type of evidence, it's a very specific suggestion for improvement. Therefore, it is considered helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment implies an action by suggesting a potential limitation of the robust training scheme. While it doesn't explicitly state what needs to be done, it encourages the authors to consider the scaling issue. The reviewer is prompting the authors to reflect on the practical applicability of their method.", "grounding_specificity_rationale": "The comment explicitly mentions 'practical datasets' and 'highdimensional domains' as areas where the robust training scheme might face challenges. These are specific parts of the paper, and the comment clearly identifies the issue related to these specific areas.", "verifiability_rationale": "The comment contains a claim that the applicability of the robust training scheme 'seems unlikely' to scale to practical datasets, particularly in highdimensional domains. While the reviewer expresses an opinion, there is no explicit justification or supporting evidence provided for this claim. The reasoning is based on common knowledge and assumptions about scaling issues.", "helpfulness_rationale": "The review point is 3 as it identifies a potential practical limitation of the proposed method. It encourages the authors to consider the realworld applicability of their robust training scheme and raises a valid concern about its scalability to highdimensional datasets. While it doesn't provide a definitive solution, it prompts the authors to think critically about the limitations of their approach."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need to distinguish between hard prompt work updates the frozen model and ones that don't, which is a clear and direct action to take. The suggestion to cite specific papers (Schick and Sch\u00fctez, etc) further clarifies the action needed.", "grounding_specificity_rationale": "The reviewer accurately identifies the specific areas of confusion: \"hard prompt work updates the frozen model\" and \"the frozen model.\" This demonstrates strong grounding as the reviewer can precisely pinpoint the section or concept being referred to. The suggestion to cite specific papers adds a layer of specificity by providing concrete examples.", "verifiability_rationale": "The reviewer makes a clear claim that the paper needs to clarify the distinction between hard prompt updates and updates to the frozen model. This claim is directly supported by suggesting specific citations (Schick and Sch\u00fctez, etc), providing a clear path for verification and supporting the claim.", "helpfulness_rationale": "The reviewer provides a concrete suggestion to improve clarity by citing relevant papers. This directly addresses a potential point of confusion for the authors and provides a clear direction for them to seek additional information. The suggestion is actionable and directly related to the identified issue."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the desire to conduct an ablation study on the VisDial dataset and specifically requests the performance of ATT(+H) without attention retrieval. This is a clear and direct action the authors should take. The request is also quite concrete, specifying the dataset and the exact component to ablate. The reviewer is asking for a specific experiment to be performed.", "grounding_specificity_rationale": "The reviewer does not explicitly name a specific section, table, or figure in the paper. However, the context implies the request is related to the 'visual reference resolution model works' and the 'performance of ATT(+H)'. While not a literal mention, the reviewer clearly implies the area of interest. The request is also very specific, asking for the performance of ATT(+H) without attention retrieval, and on the VisDial dataset.", "verifiability_rationale": "The reviewer states a desire to conduct an ablation study and asks for the performance of ATT(+H) without attention retrieval. This constitutes a claim that the authors would benefit from this analysis. However, the request itself is not verifiable in the sense of providing evidence for a flaw or error. The reviewer is suggesting an experiment, not stating a verifiable fact or issue.", "helpfulness_rationale": "The reviewer's request for an ablation study on the VisDial dataset, specifically evaluating the performance of ATT(+H) without attention retrieval, is a relevant and valuable suggestion for the authors. It directly addresses a potential area for further investigation and could provide insights into the contribution of the attention retrieval mechanism. The request is specific and directly related to the model being discussed."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking specific questions about the behavior of WPA under different input conditions and comparing its performance to Gaussian noise. These are explicit actions the authors should take to understand WPA's functionality. The reviewer is also implicitly suggesting that the authors should investigate *why* WPA performs differently with these inputs, which is a concrete action to improve their understanding.", "grounding_specificity_rationale": "The reviewer explicitly asks about the *specific input* (`np.ones`) and the *specific type of input* ('white paper') in relation to WPA's functionality. This directly addresses the grounding of the discussion within the WPA framework. The comparison to Gaussian noise further specifies the *what* is being compared. The reviewer is also asking about the *mechanism* of WPA, which is a clear specification of the area of interest.", "verifiability_rationale": "The reviewer is questioning the *justification* for WPA's performance differences with `np.ones` input and Gaussian noise. While they are asking about specific inputs, they are not providing explicit references or logical reasoning to *explain* why WPA behaves differently with these inputs. The reviewer is implicitly asking for *verification* of the observed performance differences, making this aspect 1.", "helpfulness_rationale": "The reviewer feels the paper focuses on demonstrating WPA's effectiveness but does not provide sufficient insight into *how* WPA works. They are asking for a deeper understanding of the underlying mechanisms, which is crucial for future research directions. The paper does not explicitly address this 'how' aspect, making the review point less helpful in terms of deepening understanding."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential similarity to a related work, implying that the authors should clarify this relationship. While the reviewer suggests a specific action (asking for clarification), the initial phrasing is somewhat vague, making it less concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions a 'Generating Adversarial Disturbances for Controller Verification' paper, which provides strong grounding. However, the reviewer does not specify which part of the method is similar to this related work, making the grounding less specific.", "verifiability_rationale": "The reviewer is not making a claim about the correctness or superiority of the method. They are pointing out a potential similarity to a related work. Therefore, there is X to verify.", "helpfulness_rationale": "The reviewer is asking a question and pointing out a potential area for improvement (similarity to related work). While this is a valid point, it does not directly instruct the authors on what to do or provide specific details on how to improve their method. Therefore, it is not 5 in terms of providing actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises two points: the fairness of comparing against other methods and the potential of the proposed technique to promote existing class incremental semantic segmentation methods. While these are valid concerns, they don't provide explicit, actionable suggestions for improvement. The reviewer asks questions rather than proposing concrete changes or clarifications. Therefore, while the points are relevant, they lack the explicit action or suggestion required for high actionability.", "grounding_specificity_rationale": "The reviewer's points are general and lack specific references to particular sections, tables, figures, or unique elements of the paper. They pose questions about comparisons and potential applications without pinpointing where in the paper these issues might arise. Therefore, the grounding is weak as the authors cannot confidently identify the specific part of the paper or method being discussed.", "verifiability_rationale": "The reviewer does not make any explicit claims that require verification. They are posing questions and suggesting future research directions rather than stating something that needs to be supported by evidence. Therefore, there are no claims to evaluate for verifiability, and the score defaults to 'X' for X.", "helpfulness_rationale": "The reviewer raises valid points about the limitations and potential of the proposed method. By highlighting these aspects, the reviewer provides context and potential areas for improvement for the authors. While the reviewer doesn't offer concrete solutions, they draw attention to important considerations. This can be helpful for the authors to think critically about their work and future research directions. Therefore, the review is 3 in identifying potential issues and areas for consideration."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out the lack of information regarding the setting of parameters and their sensitivity, which is an implicit action rather than an explicit one.", "grounding_specificity_rationale": "The reviewer refers to general knowledge about experimental parameters and the importance of discussing their impact, but the paper itself doesn't explicitly identify these parameters as crucial for its specific setup.", "verifiability_rationale": "The reviewer makes a claim about what the experimental section *should* contain, which is generally verifiable in the broader research community. However, *within the specific paper*, this information is missing, making the implication of the missing information 1.", "helpfulness_rationale": "The reviewer provides valuable information to the authors regarding important experimental parameters and their sensitivity, which directly addresses a potential weakness in the authors' understanding and strengthens the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential weakness in the methodology (reinforcement learning for a static VQA task). While they don't explicitly state an action to take, they imply a concern about the data efficiency and training difficulty, which are actions that need to be addressed.", "grounding_specificity_rationale": "The reviewer's comment is general and does not specify any particular section, table, figure, or unique aspect of the paper. They are making a broad statement about the suitability of reinforcement learning for this type of task.", "verifiability_rationale": "The reviewer makes a claim about a potential weakness in the approach. While it's a subjective belief, it also points to a potential area for further investigation or justification in the paper.", "helpfulness_rationale": "The reviewer raises a valid concern about the methodology. This could be helpful for the authors to consider alternative approaches or to strengthen their justification for using reinforcement learning. However, the comment lacks specific, actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the similarity of the proposed method to existing attentional modules and ResNeSt, but does not explicitly state what specific action the authors should take to address this. While the reviewer identifies a potential weakness, they do not provide concrete steps on how to improve the method based on this observation. The suggestion to investigate connections to ResNeSt is a direction, but not a specific action to be implemented.", "grounding_specificity_rationale": "The reviewer mentions 'attentional modules' generally, which is a broad category. However, they also specifically name 'ResNeSt', indicating some level of grounding. The reviewer explains *what* is similar (attentional modules and ResNeSt structure) but does not detail *how* this similarity impacts the proposed method or what specific aspects need to be addressed. The specificity is moderate as the reviewer identifies a potential area for improvement but lacks detailed explanation of the connection or impact.", "verifiability_rationale": "The reviewer makes claims about the similarity of the proposed method to existing attentional modules and ResNeSt, and the absence of discussion about ResNeSt. However, the paper does not provide any evidence to support these claims. The reviewer does not offer specific examples from the paper to back up their assertion of similarity or the omission of ResNeSt discussion. Therefore, the claims are not verifiable based on the provided information.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the novelty of the proposed method and suggests investigating connections to ResNeSt. This provides a constructive suggestion for improvement. While the reviewer does not offer specific details on how to implement this suggestion, it offers a clear direction for the authors to explore. Therefore, the feedback is 3 as it points towards a specific area for further investigation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "Not Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing comparison with testtime adaptation (TTA) methods and clearly identifies the core issue: how to prove that adjusting input data is superior to updating model parameters. The suggestion to include experimental results directly addresses the need for action.", "grounding_specificity_rationale": "The reviewer mentions 'testtime adaptation (TTA) methods' and specifies the goal of these methods (adapting to outofdistribution data with noisy input). However, the reviewer does not specify *how* to prove the superiority of data processing over model parameter adjustment. The suggestion is present, but the method of verification lacks detail.", "verifiability_rationale": "The reviewer makes a claim about the differences between TTA methods and the paper's approach and asks how to prove data processing is superior to model parameter adjustment. This is a valid claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion is posed as a question without any justification.", "helpfulness_rationale": "The reviewer's point is 5. They identify a relevant gap in the paper's analysis by pointing out the lack of comparison with TTA methods. The suggestion to include experimental results is a concrete and valuable contribution that would significantly improve the paper. The reviewer's question directly addresses a practical concern about how to validate the proposed approach."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the incorrect expression for J(\u03b8) and provides the correct one, making the action clear and direct.", "grounding_specificity_rationale": "The reviewer refers to 'the first expression for J(\u03b8)' in the paper, which can be considered grounded as it points to a specific location. However, they do not specify *which* expression within that section is incorrect, making the grounding somewhat ambiguous.", "verifiability_rationale": "The reviewer states a claim ('the first expression for J(\u03b8) is incorrect') and immediately provides the correct expression (Q(s<sup>t</sup><sub>0</sub>, \u03c0<sub>\u03b8</sub>(s<sup>t</sup><sub>0</sub>))) as evidence, making the claim verifiable.", "helpfulness_rationale": "The reviewer directly points out an error in the paper and provides the correct formula, which is immediately actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The suggestions are generally helpful in pointing out areas for improvement, but they lack specific, actionable steps. For example, the reviewer suggests 'expensive approaches' but doesn't specify which parts of the paper need to be made more costeffective. Similarly, the suggestion to 'estimates' is vague. While the reviewer identifies issues, the lack of concrete actions makes the actionable label borderline.", "grounding_specificity_rationale": "The reviewer mentions areas for improvement like 'expensive approaches' and 'estimates', which could be interpreted as implicitly referring to specific sections. However, they do not explicitly identify a specific part of the paper (e.g., a section, table, or figure) being addressed. The reviewer also mentions specific papers in the references, but these are not directly linked to the current document's content. Therefore, the grounding is weak. The specificity is also low as the reviewer doesn't detail what needs to be addressed in these areas.", "verifiability_rationale": "The reviewer makes several claims about the references. They state that 'various words in many of the references need capitalization,' 'bayesian' in many papers, 'Advances in neural information processing systems' in several papers,' and provides specific publication details for Dusenberry et al. (2020), Osawa et al. (2019), and Swiatkowski et al. (2020). These claims are supported by logical reasoning and common knowledge about academic writing conventions, as well as the provided publication details. Therefore, the verifiability is high.", "helpfulness_rationale": "The review point provides suggestions on improving referencing accuracy and points out areas for more costeffective approaches. These suggestions are generally helpful as they directly address potential issues in the paper. However, the suggestions are somewhat general and lack specific, actionable steps. For instance, while the reviewer suggests making the referencing more precise, they don't provide concrete examples of where this is lacking. Similarly, the suggestion to make approaches costeffective is broad. While the feedback is valuable, the lack of specific actions makes the helpfulness label somewhat subjective and borderline."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states what information is missing ('I didn't find all parameter values') and asks for details about specific aspects ('What are the model parameters for task 1? What lambda was chosen for the Boltzmann policy'). This indicates an explicit action the authors should take: go back and find the missing information. The request for details further makes the action concrete. While the request is somewhat direct, it is a clear call for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'model parameters' which are specific parts of the paper. However, they do not explicitly state which section, table, or figure contains this information. They imply that the information is missing. Therefore, the grounding is weakly confident. The reviewer does ask for 'how were the parameters chosen?' which adds a degree of specificity to the request, even though the initial grounding is weak.", "verifiability_rationale": "The reviewer poses a question about the methodology used for parameter selection ('How were the parameters chosen?'). This is a claim that needs to be verified. The reviewer implicitly suggests that the current method might not be standard or welljustified. The claim can be verified by checking the paper for explicit statements about the parameter selection process. If the paper lacks this detail or relies on common knowledge (e.g., 'maximum likelihood estimates'), it would be partially verifiable. If the paper provides specific references, it would be 5.", "helpfulness_rationale": "The reviewer directly asks for information that is likely missing from the paper. This is a clear and actionable request that would help the authors improve their draft. The request for the 'process of choosing' parameters is also helpful, as it encourages the authors to be more transparent and justifiable in their methodology. While the request is somewhat direct, it is a valuable piece of feedback for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue with the performance claim and suggests a comparison with detection methods. This indicates an explicit action: investigating the source of the results and exploring alternative evaluation strategies. While the reviewer doesn't specify *how* to conduct the comparison, the action of comparing is clearly stated.", "grounding_specificity_rationale": "The reviewer makes a general claim about the source of the performance and suggests a comparison with detection methods. They do not explicitly identify which step or method is being referred to as the source of the high performance or why deep learning methods are being compared. The grounding is at a high level, lacking specific references to sections, tables, or figures.", "verifiability_rationale": "The reviewer states a claim that the performance 'majorly come from the first step' and that 'conduces comparisons experiments with existing detection methods'. However, the reviewer does not provide any evidence, reasoning, or references to support these claims. The statements are presented as possibilities or suggestions without justification.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the source of the performance claims and suggests a comparison with detection methods. However, the suggestion is quite general and lacks specific details on how to conduct the comparison or what specific aspects of the 'first step' should be investigated. The helpfulness is limited as the reviewer does not provide concrete, actionable steps for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the impact of adding CBN to layer 2 and asks for an explanation of why this might be happening. It provides a clear action: to investigate the performance difference. The request for explanation makes the action more concrete. Therefore, it is 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 2' and 'layers 3 and 4' in their comment, directly identifying the specific part of the paper being addressed. They also compare the performance of GuessWhat?! in this context to a different setup. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim about the performance deterioration and asks for an explanation. While they don't provide specific examples or citations within the review point itself, the request for an explanation implies a need for justification, which is a key aspect of verifiability. The claim is stated, but further evidence or references would strengthen it.", "helpfulness_rationale": "The review points out a performance issue and asks for an explanation. This directly addresses a potential weakness in the authors' draft. The request for an explanation is a valuable piece of feedback that encourages the authors to investigate and potentially improve their model. While it doesn't suggest a specific improvement, it identifies a problem and encourages further analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the 'lack of comparison with a highly relevant method'. This is an implicit action, as the authors are identifying a missing element rather than directly instructing them on what to do. However, the action is concrete, as they clearly identify the missing comparison. Therefore, it is 2.", "grounding_specificity_rationale": "The review point mentions a specific method (1) and its components ('intertask ensemble' and 'intratask ensemble'). This demonstrates strong grounding as the authors are referring to a specific part of the paper. However, the review point does not specify *how* this comparison should be done, making it somewhat specific in terms of what is being pointed out, but less specific in terms of the action required.", "verifiability_rationale": "The review point makes a clear claim: 'Yet, the authors didn\u2019t include the method comparison or performance comparison.' This claim is verifiable through direct observation of the paper's content. There is no need for external references or logical reasoning to confirm this statement. Therefore, the claim is 5.", "helpfulness_rationale": "The review point clearly identifies a significant omission (lack of comparison with a relevant method) and suggests a concrete next step (include the comparison). This directly benefits the authors by highlighting a crucial area for improvement. Therefore, the review point is 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a limitation of the proposed method ( inability to handle headpose beyond facial expression) and asks a question about why this is the case, referencing a previous work. While it points out a weakness, it doesn't provide explicit instructions or concrete steps on how to address this limitation. The question itself is a form of implicit actionability, but lacks the clarity and specificity of a direct instruction.", "grounding_specificity_rationale": "The review point refers to \"headpose parameters\" and \"NeRF\" generally and mentions a \"previous work\" by Gafni et al. It does not explicitly refer to a specific section, table, or unique aspect of the paper being addressed. The reference to the previous work is by name, not by a specific section or table within the hypothetical paper.", "verifiability_rationale": "The review point makes a claim: \"While this paper defers this problem to a future work, a previous work (e.g., Gafni et al. ICCV 2021) is already able to control both facial expression and headpose. Why is it not possible to condition the headpose parameters in the NeRF beyond the facial expression similar to Gafni et al. ICCV 2021?\" The reviewer provides a statement about a related work and asks a question to justify their claim. The justification is based on the existence of a related work and the absence of a similar capability in the proposed method. While it's not a direct explanation, it provides a basis for understanding the difference.", "helpfulness_rationale": "The review point identifies a specific limitation of the proposed method ( inability to handle headpose beyond facial expression) and asks a question about why this is the case, referencing a previous work. While it doesn't directly tell the authors how to fix this, it points out a concrete weakness and a potential direction for improvement. It provides a context for the authors to consider and potentially investigate further."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue (similarity to backdoor triggers) and suggests a possible cause (artificial patterns). While they don't explicitly state *how* the authors should address this, they identify a type of problem that needs to be considered. This provides some level of actionable information.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Section 3.1 and 3.2' and describes the nature of the spurious features as 'artificial patterns' and 'random noise patterns'. This clearly grounds the comment to a specific part of the paper and specifies the type of issue.", "verifiability_rationale": "The reviewer makes a claim: 'It is wellknown that a few training examples with such triggers (rare spurious examples in this paper) would have a large impact on the trained model.' They provide examples of similar triggers used in prior work (Chen et al., 2017; Gu et al., 2019). This provides some justification for their claim, making it 3.", "helpfulness_rationale": "The reviewer identifies a potential issue (similarity to backdoor triggers) and suggests a possible cause (artificial patterns). This could be helpful for the authors to understand potential vulnerabilities in their model and how to improve its robustness. While it doesn't provide a direct solution, it points to a relevant area of investigation."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that the \"optimization algorithm is directly from some previous works.\" This is a clear and direct statement of an action the authors should take (review the related work). While the reviewer doesn't specify *which* previous works, the action itself is stated.", "grounding_specificity_rationale": "The reviewer mentions \"optimization algorithm\" but doesn't pinpoint a specific section, table, figure, or unique aspect of the paper where this algorithm is discussed or implemented. They are making a general statement about the algorithm's origin. While they imply it's related to the 'structural optimization\" component, this connection isn't explicitly stated.", "verifiability_rationale": "The reviewer makes a claim: \"the optimization algorithm is directly from some previous works, that is a little bit confusing and reduces the contribution.\" However, within the *review point itself*, there is no evidence or justification provided to support this claim. The reviewer is stating their observation but not providing any logical reasoning, common knowledge, or external references to back it up.", "helpfulness_rationale": "The reviewer's statement is a critique of the optimization algorithm's novelty and contribution. While they identify a potential issue (\"it seems the optimization algorithm is directly from some previous works\"), they don't provide specific suggestions for improvement or alternative approaches. The helpfulness is limited to pointing out a potential problem."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out that the pipeline style method does not perform better on XVNLI and MaRVL. While this identifies a problem, it doesn't explicitly state what needs to be changed or how the method should be improved. The reviewer mentions 'two models' but doesn't specify which part of the pipeline or model needs adjustment. Therefore, while the reviewer highlights an issue, the lack of concrete action makes it only 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions the datasets XVNLI and MaRVL where the pipeline style method performs poorly. This clearly indicates that the reviewer has identified the specific part of the paper (the evaluation on these datasets) where the issue lies. The mention of 'two models' also points to a specific component within the pipeline. Therefore, the reviewer has successfully grounded the comment in the specific section and area of concern.", "verifiability_rationale": "The reviewer states that the pipeline style method 'does not give better average results for both XVNLI and MaRVL'. This is a claim that needs to be supported. While the reviewer mentions the datasets, the extent to which the baseline models are the standard for comparison isn't explicitly stated with citations. The reviewer implies that the performance difference is significant enough to warrant attention, but the lack of explicit references makes it 3.", "helpfulness_rationale": "The reviewer identifies a performance issue with a specific method on certain datasets. This is a clear observation that could be helpful for authors trying to understand the limitations of pipeline approaches. However, the reviewer does not provide any specific suggestions or actions for the authors to take based on this observation. The feedback is diagnostic but lacks prescriptive guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the methodology used to reproduce political bias but does not explicitly state any actions or suggestions for improvement. It focuses on the inadequacy of the 'coarse' methodology without providing concrete steps the authors should take to address this issue. Therefore, the review point lacks explicit and actionable feedback.", "grounding_specificity_rationale": "The review point mentions 'left political bias' as a problem but does not specify which part of the paper this bias is located in or how the 'coarse' methodology specifically affects it. The mention is general and lacks precise grounding within the paper's structure or content. Therefore, the grounding of the issue is weak.", "verifiability_rationale": "The review point makes a claim about the inadequacy of the 'coarse' methodology but does not provide any evidence, examples, or logical reasoning to support this claim. It states a problem without justifying it. Therefore, the claim is not wellverified.", "helpfulness_rationale": "The review point is a critique of the methodology used in the paper but does not offer any constructive suggestions or actionable steps for the authors to improve their work. It is a negative statement without any positive contributions. Therefore, the review point is not helpful in guiding authors towards improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a discrepancy ('The authors mainly seem to focus on SSC...') and suggests a comparison ('...do not contrast their method with several other subsequent methods...'). While it doesn't provide explicit instructions on *how* to perform the comparison, the action is clear. The reviewer is pointing out a potential gap in the authors' discussion.", "grounding_specificity_rationale": "The comment explicitly mentions specific methods (thresholded subspace clustering (TSC), greedy subspace clustering by Park, etc.) and even provides examples. This clearly identifies the parts of the paper being addressed, making it fully grounded.", "verifiability_rationale": "The comment makes a claim ('The authors mainly seem to focus on SSC...') and provides supporting information ('...do not contrast their method with several other subsequent methods...') to back up this claim. The reasoning is clear and points to specific methods and their characteristics (computational efficiency, similar guarantees). This makes the claim 5.", "helpfulness_rationale": "The comment identifies a potential area for improvement in the authors' discussion ('...do not contrast their method with several other subsequent methods...') and suggests a direction for this improvement ('...contrast their method with several other subsequent methods...'). While it doesn't provide specific instructions on *how* to perform the comparison, it clearly points out a missing element and suggests a concrete action. This makes it 3 as it guides the authors towards a more comprehensive discussion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the issue: 'the categories are specified for each pixel' and suggests a correction: 'remove the statement about semantic segmentation being a lowlevel cue from the paper'. This is a clear, actionable suggestion that directly addresses a specific aspect of the paper. The action is to remove a statement, and the method is to identify the incorrect categorization. The reviewer provides a clear target for the authors to act upon.", "grounding_specificity_rationale": "The review point explicitly mentions 'semantic segmentation' and 'lowlevel cues' as the specific aspect of the paper being addressed. This is a literal mention of sections, tables, figures, or unique elements. The reviewer also clearly identifies the issue as an incorrect categorization. The grounding is strong because the reviewer directly refers to the relevant part of the paper and explains why it's incorrectly categorized.", "verifiability_rationale": "The review point contains a claim: 'semantic segmentation is not lowlevel since the categories are specified for each pixel'. The reviewer provides a justification for this claim by stating the nature of the categorization. While it could be strengthened by citing specific literature, the claim is verifiable based on the information provided in the review point. The reviewer provides a logical reasoning and a specific observation (categories per pixel) to support their claim.", "helpfulness_rationale": "The review point directly identifies a specific inconsistency in the paper's categorization of semantic segmentation. It tells the authors what to look for and what might be wrong. The suggestion to remove a statement is clear and actionable. This provides the authors with a concrete direction for improving their draft, making the review point 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the 'experiments section' as the main weakness. They then provide specific details, such as 'only considers CIFAR10 dataset' and 'does not consider many other datasets from Federated learning benchmarks (e.g., LEAF)'. The reviewer also names specific relevant works like 'FedProx' and 'FedMAX'. This indicates a clear and actionable identification of the problem and potential solutions.", "grounding_specificity_rationale": "The reviewer mentions the 'experiments section' and then specifically identifies the issue as being related to the 'CIFAR10 dataset' and the lack of consideration for 'many other datasets from Federated learning benchmarks (e.g., LEAF)'. They also point to 'relevant works like (FedProx ...)' and list specific 'datasets and model types'. This demonstrates a strong grounding by identifying the specific area and the specific missing components within that area.", "verifiability_rationale": "The reviewer makes a claim that the 'experiments section is the main weakness of this paper'. They then provide specific suggestions for improvement, such as 'The authors should see relevant works like (FedProx ...)' and list specific 'datasets and papers' (LEAF, FedProx, FedMAX). This provides clear reasoning and references to support the claim, making it 5.", "helpfulness_rationale": "The reviewer clearly identifies the weakness in the 'experiments section' and provides specific, actionable suggestions for improvement by mentioning 'many other datasets from Federated learning benchmarks (e.g., LEAF)' and recommending 'relevant works like (FedProx ...)' and listing specific 'datasets and papers' (LEAF, FedProx, FedMAX). This directly addresses the actionable feedback provided in the previous steps and offers concrete next steps for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the paper claims GCL introduces degree bias but does not explain *how* this occurs. While the paper proves that GCL conforms to a clearer community structure via intracommunity concentration and intercommunity scatter, it does not explicitly detail the mechanism by which this leads to degree bias. The reviewer's point is that the *how* is missing, making it difficult for the authors to understand and potentially replicate this effect.", "grounding_specificity_rationale": "The reviewer asks about the specific mechanism (GCL) and its specific effect (degree bias). The paper mentions GCL and degree bias as concepts, and the reviewer is asking for a more precise connection between them. While the paper claims GCL leads to degree bias, it does not explicitly and clearly identify the specific part of the paper or the unique element being addressed in relation to this bias. The reviewer is asking for a more precise pinpointing of the issue.", "verifiability_rationale": "The reviewer points out that while the paper proves that GCL leads to intracommunity concentration and intercommunity scatter, the *relationship* of these properties to degree bias is not intuitive enough. The reviewer is asking for a clearer explanation of *why* these properties lead to degree bias. The paper states the *what* (GCL leads to these properties), but the *why* (the intuitive link to degree bias) is not wellsupported or explained. The reviewer is asking for a more detailed and intuitive explanation of the connection.", "helpfulness_rationale": "The reviewer's request for clarification on how to get a small degree of bias from a clear community structure is a valid point that could improve the paper. It directly addresses a potential area of confusion for readers trying to understand the implications of the proposed method. While the information might be present in the paper, the reviewer is asking for a more explicit and intuitive explanation of this connection, which would be helpful for readers and authors trying to apply the method."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a discrepancy in the paper's description of how clean exemplar manifolds are constructed, specifically for nonstochastic networks like ResNet50 and ATResNet50. They are asking how the denominator in Figure 2c is computed for these networks, implying a missing detail in the paper's explanation of how 'clean' manifolds are generated. The reviewer is asking for a specific action: clarification on a methodological detail that affects the interpretation of the results.", "grounding_specificity_rationale": "The reviewer refers to 'exemplar manifolds,' 'adversarial perturbations,' and 'stochasticity of the network,' which are all specific technical terms within the paper. They also explicitly ask about the construction of 'clean exemplar manifolds' for 'ResNet50 & ATResNet50 networks.' This demonstrates a clear understanding of the relevant sections and a specific focus on the methodology used to generate these manifolds. The reviewer is identifying a specific area within the paper they are trying to understand.", "verifiability_rationale": "The reviewer is not making a claim that needs verification. They are asking a question about how a specific aspect of the methodology is implemented. While the answer to this question should be verifiable from the paper if the information is present, the reviewer's point itself does not involve making a declarative statement that requires logical reasoning, common knowledge, or external references to support.", "helpfulness_rationale": "The reviewer's question directly addresses a potential source of confusion for the authors regarding the construction of clean exemplar manifolds. Understanding how these manifolds are generated is crucial for interpreting the results in Figure 2c and for replicating the experiments. This is a valuable piece of information for the authors, making the reviewer's point 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a potential limitation of the shape model invariance study and asks a question about testing image results. While it points out a concern, the explicit action of providing quantitative results on testing images is not taken. The action is implied but not directly stated.", "grounding_specificity_rationale": "The comment explicitly mentions 'testing images' and asks about 'quantitative results' related to them. It directly refers to a specific part of the evaluation process, indicating full grounding.", "verifiability_rationale": "The review point is a question, not a declarative statement containing a claim. Therefore, it does not fit into the verifiability categories. It is not verifiable because there is no assertion being made.", "helpfulness_rationale": "The comment raises a valid concern about the limitations of using training image transformations for proving shape model invariance. By asking about testing image results, it encourages the authors to consider a more comprehensive evaluation strategy. This contributes to improving the robustness of their study."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly names a specific paper ('Ghoshdastidar and Dukkipati') and suggests a concrete action: 'discuss and compare against this specific paper'. This directly points the authors to a relevant piece of prior work and provides a clear next step for them to take. The action is not just implied but stated clearly.", "grounding_specificity_rationale": "The review point explicitly names the paper ('Ghoshdastidar and Dukkipati') and the year ('AAAI 2015'). This is a literal mention, indicating precise grounding. Furthermore, the suggestion to 'discuss and compare against this specific paper' directly addresses a specific aspect of the suggested related work, making it highly specific.", "verifiability_rationale": "The review point suggests a missing element in the authors' work: the lack of discussion and comparison with a specific related paper. While it doesn't provide evidence *within the review point itself* to *prove* the authors' work is lacking, it points to a potential gap in the literature review. The suggestion is based on the relevance of the suggested paper to the topic of tensors and hypergraphs, which are mentioned as being important in the context of the authors' work. The evidence is indirect but relevant.", "helpfulness_rationale": "The review point is 5 as it directly suggests a specific paper and a clear action to take ('discuss and compare'). This provides the authors with a concrete next step and helps them improve their literature review. The suggestion is specific, actionable, and directly relevant to the topic of tensors and hypergraphs, which are implied to be important in the context of the authors' work."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point presents questions and concerns rather than explicit actions. While the questions implicitly suggest investigating scalability and the Sinkhorn algorithm's output, they lack concrete steps on how to address these issues. The statement about computational cost is a general observation, not a specific action to be taken. The questions about scalability and Sinkhorn are implied actions but not explicitly stated or detailed.", "grounding_specificity_rationale": "The review point directly addresses the authors' concerns about the practical implementation of the Sinkhorn algorithm and its scalability on different hardware. It pinpoints specific areas within the method that require clarification or further investigation. The questions about scalability and the Sinkhorn output are explicitly directed at the authors' work, making the grounding specific. The statement about computational cost is a general observation.", "verifiability_rationale": "The review point raises questions about the authors' implementation of the Sinkhorn algorithm and the scalability of the method. The computational cost statement is generally verifiable as a common knowledge point in the field. However, the questions about scalability and the Sinkhorn output are less verifiable as they depend on the authors' specific implementation details and experimental setup. There is no explicit claim or suggestion being made, just questions.", "helpfulness_rationale": "The review point raises valid concerns about the practical implementation and scalability of the Sinkhorn algorithm. However, it primarily consists of questions and suggestions for investigation rather than direct, actionable feedback on how to improve the authors' draft. While the questions point to potential areas for improvement, they do not explicitly tell the authors what to do or how to address the identified issues."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that the paper was 'extremely hard to follow' and 'read it multiple times' before understanding. While this indicates a problem, the reviewer does not explicitly state what needs to be improved or how the authors should proceed. The comment lacks specific actionable steps or suggestions for improvement.", "grounding_specificity_rationale": "The reviewer mentions the paper being 'hard to follow' and reading it 'multiple times' but does not specify which part of the paper or section is causing the difficulty. They do not mention any specific sections, tables, figures, or unique elements of the paper as being problematic. The grounding of the comment is weak because the authors cannot pinpoint the exact issue.", "verifiability_rationale": "The reviewer claims the paper is 'extremely hard to follow' and that they had to read it 'multiple times' to understand. This is a claim that needs to be supported. However, the reviewer does not provide any evidence or justification for this statement. There are no logical reasoning, common knowledge, or external references provided to support the claim that the paper is hard to follow. The verifiability of the claim is low because there is no supporting evidence.", "helpfulness_rationale": "The reviewer states that the paper was 'extremely hard to follow' and that they read it 'multiple times' before understanding. While this highlights a significant issue, the reviewer does not offer any concrete suggestions or directions for improvement. The comment is more of a diagnosis of the problem than a critique that actively helps the authors move forward. The helpfulness of the comment is low because it lacks actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of the method to ViT and image data, which is a direct and clear statement of an action the authors should take (apply the method to other areas). This is an explicit action pointing out a deficiency.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'ViT' and 'image data' as the scope of the method, allowing the authors to identify the specific part of their work that might be affected. This strong identification makes it grounded. The reviewer also points out that the parameters are only good for this specific area, which is a specific detail.", "verifiability_rationale": "The reviewer makes a claim about the method's limitations to ViT and image data. This claim is verifiable based on the information provided in the paper (if available) regarding the focus on stateoftheart performance and the use of ViT. While the reviewer provides a reason for this limitation, the claim itself is verifiable.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the method's applicability, which is a valuable piece of feedback for the authors. By highlighting this limitation, the reviewer is pointing out a potential area where the method might not be effective, guiding the authors to consider alternative approaches or to adapt the method for their specific needs. This directly helps them improve their draft by informing them about the scope of the method's applicability."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review points out a problem (nonstandard benchmarks breaking TTA methods) but doesn't specify how the authors should address it. It's a description of an issue rather than a direct instruction on how to fix it.", "grounding_specificity_rationale": "The review mentions 'nonstandard benchmarks' and 'popular TTA methods' but doesn't specify which ones or how they are nonstandard. It's vague about the nature of the distribution shift.", "verifiability_rationale": "The review makes a claim ('This is an interesting observation...') and suggests an experiment ('If the authors can evaluate TTA on more conditions...'). This provides a direction for verification, though it's not a fully justified claim on its own.", "helpfulness_rationale": "The review identifies a potential limitation of using nonstandard benchmarks and suggests exploring WILDS. While relevant, it doesn't directly instruct the authors on how to fix the problem or what changes to make to their current draft."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that the paper does not clearly explain how the results are useful to machine learning algorithms or how they can analyze the algorithms. While the reviewer identifies a problem, they do not explicitly state what action the authors should take to address this issue. The reviewer points to a lack of clarity, but the specific steps or actions the authors should take are not detailed.", "grounding_specificity_rationale": "The reviewer mentions 'tensor networks' and 'machine learning algorithms' in a general context. They do not specify a particular section, table, figure, or unique aspect of the paper where this lack of clarity is present. The reviewer's comment is broad and does not pinpoint the exact location of the issue.", "verifiability_rationale": "The reviewer makes a claim that 'How these results are useful to machine learning algorithms or analyze the algorithm is not clear.' This is a statement of a problem. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The reasoning is based solely on the lack of clarity, which is 1.", "helpfulness_rationale": "The reviewer states that the significance of the paper is poor and that the results are not useful to machine learning algorithms. This is a direct and critical assessment of the paper's value. The reviewer does not offer any suggestions or improvements based on this feedback, making it not helpful for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer expresses a lack of confidence in the experimental results and criticizes the absence of experiments related to the specific POMDP examples they provided (surveillance in museums with thresholded rewards and privacy preserving data collection). They state, 'I am quite not convinced by the experimental results of this paper. The paper sets to solve POMDP problem with nonconvex value function. To motivate the case for their solution the examples of POMDP problem with nonconvex value functions used are: (a) surveillance in museums with thresholded rewards; (b) privacy preserving data collection. So then the first question is when the case we are trying to solve are above two, why is there not a single experiment on such a setting, not even a simulated one? This basically makes the experiments section not quite useful.' This directly indicates a lack of actionable information regarding the experimental setup or results that would allow the authors to address these specific scenarios. The reviewer doesn't provide any suggestions on how the experiments should be conducted or what modifications are needed. The criticism is about the *lack* of action, not the *action* itself if it existed.", "grounding_specificity_rationale": "The reviewer explicitly mentions two specific POMDP examples (surveillance in museums with thresholded rewards and privacy preserving data collection) as motivation for their solution. This demonstrates an attempt to ground the criticism in concrete scenarios. However, the *actionability* of these examples in the *experiments* section is the core issue. The reviewer doesn't explain *how* these examples should be used in the experiments or *why* the existing experiments don't address them. The criticism is about the *motivation* and the *lack of evidence* related to these specific examples, not about the *grounding* itself. The reviewer provides the *what* (specific POMDP examples) but not the *how* (how these examples should be tested or simulated in the experiments).", "verifiability_rationale": "The reviewer's criticism centers on the *lack of experimental evidence* related to the specific POMDP examples they propose. They are not questioning the *validity* of the problem statement or the *theoretical* aspects of solving POMDPs with nonconvex value functions. The reviewer states, 'I am quite not convinced by the experimental results of this paper' and then criticizes the *absence* of experiments related to the provided examples. The core of the criticism is the *lack of evidence* to support the claims made based on these specific problem settings. There are no references to external works or logical reasoning provided to *verify* the experimental setup or the conclusions drawn from it in the context of these specific examples.", "helpfulness_rationale": "The criticism is primarily about the *lack of experimental evidence* related to the specific POMDP examples. The reviewer doesn't offer any *new insights*, *suggestions*, or *directions* for the authors to improve their experimental setup or their understanding of these specific problem settings. The criticism itself is not actionable and doesn't provide the authors with a clear path forward. The reviewer is expressing a lack of confidence, not providing a solution. The lack of *actionable information* makes the review less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a *type* of analysis (epochwise) and *specific investigations* (batch size, sampling, deterministic/stochastic comparison). However, it does not explicitly state what specific part of the author's work needs improvement or how the suggested analysis should be implemented. The reviewer implies the benefits of this analysis but doesn't provide concrete steps for the author to take.", "grounding_specificity_rationale": "The review point suggests a *general area* of improvement (epochwise analysis) and *potential benefits* of exploring that area. However, it does not explicitly identify a specific section, table, figure, or unique element of the paper that the analysis should focus on. The target part of the paper is unclear, making the grounding weak.", "verifiability_rationale": "The review point clearly states a *position* or *suggestion*: \"I think epochwise analysis...could help provide insights...\" This is a claim. The reviewer provides *reasons* for why epochwise analysis might be helpful, listing specific examples like investigating batch size, sampling, and comparing deterministic/stochastic methods. These are logical arguments and suggestions.", "helpfulness_rationale": "The review point suggests a *general area* of improvement and *potential benefits* of exploring that area. While the suggestion is relevant to understanding optimization algorithms, it doesn't offer specific, actionable steps for the author. The feedback is more about a potential direction for future work rather than direct guidance on improving the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out the 'incremental contribution' and suggests the work is 'essentially a combination of GraphRAG and GraphCare 1'. While the reviewer doesn't explicitly state the action, the suggestion to 'include specific baselines' implies the action of adding these baselines. The reviewer also suggests the paper 'should have been introduced' essential RAG algorithms, indicating an action to improve the introduction.", "grounding_specificity_rationale": "The reviewer doesn't explicitly point to a *specific* section, table, or figure in the paper. While they suggest including 'essential RAG algorithms' like 'MedRetriever 2' and 'KGRAG 3', this is a suggestion for improvement rather than a direct identification of a flaw within the current draft. The reviewer's comment is more about the *type* of work being done rather than a specific missing element of the current submission.", "verifiability_rationale": "The reviewer makes claims about the 'contribution' being 'incremental' and suggests the work is 'essentially a combination of GraphRAG and GraphCare 1'. They also point out the 'lack of cited key baselines' and specifically name 'MedRetriever 2' and 'KGRAG 3' as examples of missing RAG algorithms. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims within this review point itself. The evidence for these claims would need to be found in the paper's content.", "helpfulness_rationale": "The reviewer identifies the 'contribution' as 'incremental' and suggests the work is 'essentially a combination of GraphRAG and GraphCare 1'. They also point out the 'lack of cited key baselines' and specifically name 'MedRetriever 2' and 'KGRAG 3' as examples of missing RAG algorithms. While the initial assessment of 'incremental' is somewhat vague, the reviewer provides specific suggestions for improvement, such as including the mentioned baselines. This indicates a clear direction for the authors to take, even if the initial assessment of the contribution's level is less concrete."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states what action the authors should take: 'It is important to understand whether the performance improvement stems solely from the network design to exploit spatial redundancies, or whether the redudancies stem from the nature of ImageNet, ie., large fraction of images can be done with Glance and hence any algorithm with lower resolution will have an unfair advantage. Note, algorithms skipping layers or channels do not enjoy this luxury.' The reviewer directly instructs the authors to create a graph. This is a clear and explicit action. While the reviewer doesn't explicitly state the *how* of creating the graph, the request is specific enough that the authors can infer the necessary steps. For example, they would likely infer that they need to collect data on T, number of images, and Expectation(T) over the ImageNet test set and then plot it.", "grounding_specificity_rationale": "The reviewer explicitly states what part of the paper they are addressing by mentioning 'T vs number of images' and 'Expectation(T) over the imagenet test set'. This directly points to specific elements within the paper. The reviewer names the variables and the dataset being used. This is a clear and precise identification of the relevant part of the paper. The reviewer is not making an inference about which part to address but is directly naming the specific aspect they want the authors to investigate.", "verifiability_rationale": "The review point presents a request for a specific type of analysis and the creation of a graph. While there isn't a direct claim being made in the sense of a statement of fact or opinion, the reviewer is suggesting a methodological approach to understanding a potential issue. The request implies that the authors should perform this analysis to address the question of whether performance gains are due to network design or dataset properties. While the request itself doesn't contain a claim, the underlying motivation (understanding performance improvements) can be considered a form of implicit judgment about the paper's strengths. The reviewer is suggesting a way to investigate a potential limitation or area for improvement.", "helpfulness_rationale": "The review point is highly specific about the type of graph to create and the data source. The reviewer explicitly states the variables to be plotted (T, number of images, Expectation(T) over ImageNet) and the purpose of the graph (to understand the source of performance improvement). This specific request is likely to be very helpful for the authors in disentangling the factors contributing to their results. The reviewer is not making a claim about the paper itself but is providing a concrete suggestion for analysis that directly addresses a potential question the authors might have. The request is actionable and directly relevant to the stated goal of understanding performance improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a suggestion to make the mathematical formulation correct, which is an explicit action. However, the reviewer also adds a constraint ('unless that makes a bunch of other equations messy'), which requires the authors to infer the best approach. This makes the action somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'equations' and 'figure' as the areas needing improvement, providing a clear reference point. This indicates full grounding as the authors can easily identify the specific section being addressed.", "verifiability_rationale": "The reviewer points out a potential issue ('this needs to be changed to be mathematically correct') and asks a question ('why is it L_l instead of just L?'). While the reviewer's suggestion isn't a claim requiring external verification, the question about notation implies a lack of clarity, which could be supported by external references. However, the reviewer doesn't explicitly claim anything that requires justification, making it borderline.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as making the mathematical formulation correct and clarifying the notation. They also ask a question directly related to their work. These suggestions are actionable and directly address potential weaknesses. The reviewer's statement about the preference for avoiding messy equations further demonstrates a clear intent to improve the authors' work. The question itself is a valuable piece of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'For sequential ensembling, it is important to study the effect of noise accumulation in the context of homomorphic encryption.' This directly identifies a specific problem and the reason for its importance. The reviewer also mentions 'This limitations prevents the use of even single deep neural networks on homomorphically encrypted data.' This further clarifies the consequence of the identified problem, making the action clear and direct. The reviewer is prompting the authors to investigate a specific issue related to their method.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'sequential ensembling' and 'homomorphic encryption' as the context of the limitation. This precise identification of the relevant parts of the paper demonstrates strong grounding specificity. The reviewer also explains 'noise accumulation' as the specific issue, further clarifying the problem within the context of homomorphic encryption.", "verifiability_rationale": "The reviewer presents a claim about the importance of studying noise accumulation in sequential ensembling within homomorphic encryption. The reviewer then provides a logical deduction by stating 'This limitations prevents the use of even single deep neural networks on homomorphically encrypted data.' While the reviewer doesn't provide direct evidence from the paper, the statement is a logical consequence of the known challenges of homomorphic encryption, making it verifiable through reasoning and common knowledge in the field. The reviewer is pointing out a practical limitation that researchers would likely want to address.", "helpfulness_rationale": "The reviewer's point directly addresses a practical limitation of sequential ensembling in the context of homomorphic encryption. By highlighting the issue of noise accumulation and its impact on the usability of the method, the reviewer provides a clear and actionable suggestion for improvement. The reviewer is prompting the authors to investigate a specific problem that directly relates to the effectiveness of their proposed approach. This is a valuable piece of feedback that directly helps the authors refine their method or explore alternative approaches."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states an action: 'it should be used standard regularization trick.' However, it does not provide concrete details on how to implement this action, such as which specific regularization method (e.g., L1, L2, Elastic Net) should be used or how it should be applied. Therefore, while the action is explicit, the lack of concrete details makes it somewhat implicit in terms of implementation.", "grounding_specificity_rationale": "The review point mentions 'stronglyconvex concave case.' This provides some grounding as it refers to a specific technical aspect of the problem. However, it does not explicitly identify the specific section, table, figure, or unique element within the paper where this case is discussed. Furthermore, it does not specify what needs to be addressed in this case. Therefore, the grounding is weak, and the specificity is low.", "verifiability_rationale": "The review point contains a claim: 'it should be used standard regularization trick.' This is a directive that suggests a change. However, the review point does not provide any logical reasoning, common knowledge, or external references to support why this specific regularization trick should be used in the 'stronglyconvex concave case.' The justification is missing, making it only partially verifiable.", "helpfulness_rationale": "The review point suggests using a 'standard regularization trick' for comparison in a 'stronglyconvex concave case.' While it doesn't specify the exact trick, it provides a direction for the authors to look for relevant comparisons. This gives the authors a starting point for their investigation and guides them towards a common practice in the field. However, the lack of specificity makes it less helpful than a more detailed suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action they want to take: 'It would be good to include in the left graph in fig 3 the learning curve for a model without any mean teacher or pi regularization'. This clearly identifies the action as adding a specific element to a graph. The reviewer also specifies the missing element as 'a model without any mean teacher or pi regularization', making the action concrete.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific part of the paper being addressed: 'the learning curve for a model without any mean teacher or pi regularization'. This directly points to a specific element in the graph. The reviewer also clearly specifies what needs to be included in this part: 'the learning curve for a model without any mean teacher or pi regularization'. This clearly defines the missing information.", "verifiability_rationale": "The reviewer makes a claim: 'It would be good to include in the left graph in fig 3 the learning curve for a model without any mean teacher or pi regularization'. This claim is verifiable by examining the graph and comparing the performance of the model with and without the regularization techniques. The reviewer provides a clear logical reasoning to support their suggestion.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for the authors to improve their understanding of the impact of mean teacher and pi regularization. The suggestion is directly relevant to the authors' work and provides a concrete action for them to take. The reviewer also implies a comparison, which is a valuable piece of information for the authors."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Fully Grounded", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states \"It would be valuable to discuss it and present your solutions in this paper.\" While this indicates a need for discussion, it doesn't explicitly state what needs to be done or how to approach it. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer directly addresses the handling of different types of inputs (biomedical signals or speech) in the paper, making it fully grounded.", "verifiability_rationale": "The reviewer presents a suggestion for discussion and solutions, which can be considered a claim. However, the claim lacks specific evidence or references to support it.", "helpfulness_rationale": "The reviewer points out a valid area for improvement (handling different input types) and suggests discussing solutions. This provides a helpful direction for the authors, but the lack of specific details makes it 3 rather than 5."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a limitation of the method: 'which might cause the poor generalization to questions that are not 'Whtypes'/transformable.' This is an explicit action that the authors should be aware of. The reviewer also suggests improvement: 'The authors should be aware of this limitation and consider alternative approaches for handling nonWhtype questions.' This implies a concrete action to be taken. Therefore, the review point is 5.", "grounding_specificity_rationale": "The reviewer's comment is not about a specific part of the paper. They are discussing the limitations of a method in general. The comment does not identify a specific section, table, or figure where the issue lies. The comment also does not specify what needs to be addressed in this method. Therefore, the comment is 1.", "verifiability_rationale": "The reviewer states a potential issue: 'the method might cause the poor generalization to questions that are not 'Whtypes'/transformable.' This constitutes a claim. The reviewer does not provide any evidence or logical reasoning to support this claim. The statement is presented as a concern, not a fact. Therefore, the claim is 1.", "helpfulness_rationale": "The reviewer clearly identifies a potential problem with the method. They state: 'the method might cause the poor generalization to questions that are not 'Whtypes'/transformable.' This is a helpful comment as it points out a potential weakness. While it doesn't offer a direct solution, it highlights an area for improvement. The reviewer's suggestion to 'consider alternative approaches for handling nonWhtype questions' indicates a constructive next step. Therefore, the review point is 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point states: \"The rockpaperscissors example is clearly inspired by an example that appeared in many previous work.\" This is a statement of fact, not a suggestion for improvement. There's no instruction on how to acknowledge the inspiration or address the lack of originality.", "grounding_specificity_rationale": "The review point mentions \"the rockpaperscissors example\" generally. It doesn't specify *which* rockpaperscissors example in the paper, nor does it explain *why* this particular example is problematic or how it was used.", "verifiability_rationale": "The review point makes a claim: \"The rockpaperscissors example is clearly inspired by an example that appeared in many previous work.\" However, it doesn't provide any evidence or justification for this claim. It's an assertion without supporting references or logical reasoning.", "helpfulness_rationale": "The review point identifies a potential issue (lack of originality) but doesn't offer any concrete steps to address it. It's a critique without offering constructive suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review states that the 'innovations of network architecture design and constraint embedding are rather limited' and that 'the performance is limited by the performance of the oracle expert.' While this points to a potential issue, it doesn't explicitly state what needs to be changed or how to implement the suggested improvements. The reviewer identifies a problem but doesn't provide concrete steps for the authors to take. Therefore, while it points to a weakness, it lacks explicit and actionable suggestions.", "grounding_specificity_rationale": "The review mentions 'innovations of network architecture design' and 'constraint embedding' but does not specify which particular part of the architecture or embedding process is limited. It implies a general limitation but fails to pinpoint the exact element. Therefore, while it identifies a potential area of concern, it does not clearly link it to a specific part of the paper or method.", "verifiability_rationale": "The review states that 'the innovations of network architecture design and constraint embedding are rather limited' and that 'the performance is limited by the performance of the oracle expert.' These statements are presented as observations or conclusions without providing specific evidence or references to support them. The claims are made without sufficient justification or evidence within the review itself. Therefore, the claims are not wellsupported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review identifies a potential limitation in the paper's core contributions (innovations) and links it to a specific factor (oracle expert performance). While this is valuable information for the authors to understand the scope of their contribution, it does not offer concrete solutions or specific directions for improvement. It primarily critiques the work rather than providing actionable feedback. Therefore, while the feedback is relevant, it lacks specific guidance on how to address the identified limitations."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the flaw in the original paper's evaluation (only pretraining on synthetic data) and proposes a concrete solution (pretraining on synthetic, finetuning on realworld with different losses). This clearly identifies an action the authors should take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'synthetic data' and proposes a specific evaluation setup ('pretrained on synthetic, finetuned on realworld with different losses'). This clearly identifies the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer makes a clear claim about the flaw in the original evaluation and provides a specific alternative evaluation setup as evidence. This claim is directly supported by the proposed method.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the original paper's evaluation methodology and provides a concrete alternative evaluation strategy. This directly addresses a potential issue and offers a clear path for improvement, making it 5 to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies two issues. The first, regarding the range in Figure 4, is somewhat vague. While it implies that sparsification doesn't significantly alter the range, it doesn't explicitly state what action the authors should take to verify this or how to adjust sparsification if they believe it should. The second point, about Lemma 2, is more explicit in calling for action, but it lacks a clear methodology or example of how to ensure the conditions are met.", "grounding_specificity_rationale": "The comment explicitly mentions 'sparsification' in the context of Figure 4, making it somewhat grounded in that it refers to a specific technique. However, it doesn't specify which part of Figure 4 is being referred to (e.g., the range of a specific variable). For Lemma 2, it directly refers to 'Lemma 2' and its 'approximately identical mean' assumption, making it fully grounded in this specific context.", "verifiability_rationale": "The comment raises concerns about the implications of the observed range in Figure 4 and the assumptions in Lemma 2. However, it doesn't provide any specific evidence, references, or logical reasoning to support these concerns. The reviewer is asking questions that require further investigation and justification, but the current point doesn't offer any answers or guidance on how to address these issues.", "helpfulness_rationale": "The comment raises valid concerns about the relationship between sparsification, the range in Figure 4, and the assumptions in Lemma 2. However, it doesn't provide any concrete suggestions or guidance on how to address these concerns. The reviewer is essentially highlighting gaps in the discussion and potential areas for further investigation, but they are not offering actionable steps for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question and suggesting a formatting change, but they are not explicitly stating what action the authors should take based on this. The suggestion is about how the update should be presented, not what needs to be changed in the paper itself. Therefore, while the reviewer is pointing out a potential improvement, they are not directly instructing the authors on what to do.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'an update' and 'bolded sections in page 6'. This clearly identifies the specific part of the paper and the issue being addressed. The comment is grounded because it directly refers to a specific element of the paper.", "verifiability_rationale": "The reviewer is not making a claim or suggesting a change that requires verification. They are asking a question and making a suggestion about the presentation of information. There is no assertion of correctness or a need for justification. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The reviewer raises a valid point about the scope of updates and suggests a concrete improvement (breaking up bold text). This indicates that the reviewer has understood a potential limitation and is proposing a solution. While it's not a direct action, it's a constructive suggestion that could be helpful for the authors. Therefore, it has some level of helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests an action (adding a citation) and provides a hint about the how (using an example). While it doesn't immediately tell them where to add it, the phrasing strongly implies it relates to the current discussion, which likely surrounds the topic on differential privacy.", "grounding_specificity_rationale": "The review refers to a general concept ('differential privacy') and suggests a general action ('add a citation') without pointing to a specific part of the paper. The reference to '2' is a general placeholder for a citation, not a specific reference within the paper.", "verifiability_rationale": "The review point states a suggestion, not a declarative claim. It doesn't make a judgment about the current state of the paper or propose a new idea. It's a helpful suggestion, but not a declarative statement that requires verification.", "helpfulness_rationale": "The suggestion is directly relevant to improving the paper's clarity, credibility, and adherence to best practices. It's a practical and helpful piece of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly points out two distinct issues: the strength of the 'additional assumptions' and the sign error in the inequality. Both of these are clearly identifiable and actionable. The reviewer names the specific section (3.2) where the assumptions are likely discussed, making it easy for the authors to locate and address them. Similarly, the reviewer points out the potential sign error in the inequality and provides a specific reference point (line 310) to verify this claim. The reviewer also suggests concrete actions: 'If the test set distribution assumption is indeed significant, the authors should consider its implications more thoroughly,' and 'Doublecheck the inequality on line 227 to ensure the sign is correct.' These actions are direct and specific, making the review point actionable.", "grounding_specificity_rationale": "The reviewer mentions 'this methodology requires significant additional assumptions' in the context of Section 3.2. While they mention the section, they don't explicitly pinpoint the exact line or paragraph within Section 3.2 that contains the specific assumptions being criticized. However, they do provide a specific example within that section: 'the test set be drawn from the same distribution as the query set.' This demonstrates a degree of specificity within the mentioned section. The reviewer also identifies the specific inequality on line 227 for the sign error, further enhancing the grounding. The claim is grounded in the section and contains a specific example, making it partially grounded. The specific example allows for verification, making it also specific.", "verifiability_rationale": "The reviewer presents two distinct claims: the strength of the 'additional assumptions' and the sign error in the inequality. Both are clearly stated. For the assumptions, the reviewer provides a specific example ('the test set be drawn from the same distribution as the query set'), which allows for verification. For the inequality, the reviewer provides a specific reference point (the inequality on line 227), making it easily verifiable. While the assessment of 'significant' assumptions is subjective, the specific assumption identified is verifiable. The inequality sign error is definitively verifiable.", "helpfulness_rationale": "The reviewer's point about the sign error in the inequality is 5 as it directly identifies a factual flaw that needs correction. However, the criticism of the 'significant additional assumptions' being made in the methodology section is less helpful. If the assumption about the test set distribution is indeed a common and natural assumption in the context of the paper, then criticizing its 'significance' might not provide actionable guidance for the authors on how to improve their draft. It might be more helpful to suggest alternative approaches or acknowledge that this is a standard assumption."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for comparison with other methods and a discussion on dimensionality reduction techniques. While the action is clear (comparing and discussing), the specifics are missing, making it somewhat vague on how to act. The reviewer identifies the *what* (comparison and discussion) but doesn't pinpoint the *how*.", "grounding_specificity_rationale": "The reviewer's comments are about the *process* of using Shapely value explanations and dimensionality reduction, not about specific sections, tables, figures, or unique elements of the paper. They are also not providing *specific* examples of why these methods are better or the advantages/disadvantages of different dimensionality reduction techniques. The reviewer is discussing the *methodology* and *discussion* aspects of the paper, rather than focusing on a particular part.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are suggesting improvements and pointing out potential weaknesses in the paper's argument. The reviewer is offering *suggestions* rather than stating something that needs to be proven or justified.", "helpfulness_rationale": "The reviewer's comments directly address potential areas for improvement in the paper and suggest concrete actions (include experimental comparison, include discussion on dimensionality reduction). While the suggestions are not fully detailed, they are directly related to improving the paper and offer actionable feedback to the authors. The reviewer is highlighting potential weaknesses and providing suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point describes the authors' actions (conducting experiments) but does not suggest specific actions or improvements they should take based on those actions. It's a report, not a prescription.", "grounding_specificity_rationale": "The review point is a general statement about the authors' experiments and findings, without specifying any particular section, table, figure, or unique aspect of the paper being discussed.", "verifiability_rationale": "The review point is a factual statement about the authors' work and does not contain a claim that requires verification.", "helpfulness_rationale": "The review point summarizes the authors' experiments and findings but does not offer any constructive feedback or suggestions on how the authors can improve their draft based on this information."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that Appendix A.2 does not illustrate the state space representation clearly. The action is to improve the clarity of the illustration. The comment is also concrete, specifying 'state space representation'.", "grounding_specificity_rationale": "The comment explicitly mentions 'Appendix A.2' and 'state space representation', allowing the authors to precisely identify the section and the specific concept being criticized. The specificity is in pointing out the lack of clarity in the illustration.", "verifiability_rationale": "The comment contains a claim that 'Appendix A.2 does not illustrate the state space representation of the environment clearly.' However, within this review point itself, there is no evidence or reasoning provided to support this claim. The reviewer is stating a potential issue, but not providing evidence or suggesting how to verify it.", "helpfulness_rationale": "The comment points out a potential area for improvement in the appendix by highlighting the lack of clarity in the state space representation illustration. While it doesn't provide specific suggestions for improvement, it serves as a headsup for the authors to reexamine Appendix A.2. The impact is that the authors might need to spend more time understanding or improving the illustration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the approach is only applicable to small or mediumscale problems. This directly identifies a limitation of the method. The reviewer also mentions 'truly large problems will overwhelm current LPsolvers,' which provides a clear consequence of the limitation. This makes the actionability explicit and somewhat concrete as it points to a specific type of problem and the nature of the overload on LPsolvers.", "grounding_specificity_rationale": "The reviewer mentions 'current LPsolvers' as a limitation. However, they do not specify which part of the paper or which element of the approach this limitation directly pertains to. They are referring to the general behavior of LPsolvers with large problems. Therefore, the grounding is weak as the authors cannot confidently determine the exact area being addressed. While the subject 'LPsolvers' is specific, the object 'a limitation' is not tied to a specific section or element of the paper.", "verifiability_rationale": "The reviewer makes a claim that the approach is limited to small or mediumscale problems and that large problems overwhelm current LPsolvers. This is a declarative statement of a limitation. While the reviewer mentions 'LPsolvers,' they do not provide specific examples or references to support this claim. However, the general concept of LPsolver limitations with scale is a generally verifiable fact in the field of optimization. The claim is 3 as it relates to a known technology, but it lacks specific evidence or references.", "helpfulness_rationale": "The reviewer points out a significant limitation of the authors' approach \u2013 its restricted applicability to small or mediumscale problems. This is a valuable piece of feedback as it highlights a potential constraint the authors might face when trying to apply their work to larger, more complex scenarios. While the reviewer does not offer a solution, identifying this limitation is helpful for guiding future work or suggesting alternative approaches for larger problems."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a lack of clarity but does not specify what action the authors should take to address this lack of clarity. It identifies a problem but doesn't provide a concrete solution or direction.", "grounding_specificity_rationale": "The review refers to 'characteristic function regularization' generally and does not specify which part of the authors' paper this pertains to. It also does not explain why this is a problem or how it relates to the authors' work.", "verifiability_rationale": "The review states that the 'overall motivation of using characteristic function regularization is not clear' which is an opinion or judgment about the authors' work. There is X being made that requires verification or justification.", "helpfulness_rationale": "The review identifies a valid weakness in the authors' draft \u2013 the lack of clarity in the motivation for using characteristic function regularization. This is a helpful point as it highlights a potential area for improvement, even though it doesn't provide specific solutions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states that the paper combines existing techniques. It also concretely names these techniques (Lykouris et al., 2018; Zhou et al., 2021; contextual linear bandits) and their application. However, it doesn't directly tell the authors what to do with this information. It highlights a potential lack of surprise and suggests the contribution might be incremental, which is more of a critique than a direct action.", "grounding_specificity_rationale": "The comment mentions specific papers and the general area of 'combining existing techniques.' While it names specific works, it doesn't pinpoint a specific section, table, figure, or unique aspect of the *review paper* being addressed. The grounding is more about the *content* of other papers rather than a direct reference to a specific part of the review itself.", "verifiability_rationale": "The comment contains a claim: 'The fact that these results can be combined together is not surprising.' This claim is not 5 within the review point itself. It relies on the reader's understanding of what constitutes 'surprising' or 'incremental' rather than providing explicit logical reasoning, common knowledge, or external references within the review point.", "helpfulness_rationale": "The comment raises a valid point about the potential incremental nature of the contribution. However, it doesn't provide specific, actionable feedback on how the authors should improve their draft based on this observation. It's more of a critique of the novelty rather than a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the aggregation operation after 'Integration' needs further clarification. This indicates an implicit action is being suggested: the authors should clarify this operation. However, the reviewer does not specify *how* this operation works or what data it processes, making the action implicit rather than concrete.", "grounding_specificity_rationale": "The reviewer refers to the 'Integration' step within the 'Multiscale modeling' section. However, they do not explicitly identify the specific subsection, table, figure, or unique element within this section that is causing the need for clarification. The reference is general, making the grounding somewhat weak. The reviewer then specifies the need for clarification on the 'aggregation operation' *after* integration, which is a specific part of the process. Therefore, while the overall reference to 'Integration' is weakly grounded, the specific action (clarifying the aggregation operation) is specific.", "verifiability_rationale": "The reviewer states that the aggregation operation after 'Integration' needs further clarification. This constitutes a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. They simply state that clarification is needed without explaining *why* it is unclear or providing *where* to find the information. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer explicitly states that the aggregation operation after 'Integration' needs further clarification. This directly points to a weakness in the paper that needs addressing. While the reviewer requests more information, they do not provide any specific details about what is missing or how to find the information. The request is clear about the area needing improvement, making it 3 in identifying a problem, but less helpful in providing specific guidance on how to fix it."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states they want clarification on 'what does 100 steps here mean?'. This indicates an action (seeking clarification) but the definition of '100 steps' is not provided, making it vague. Therefore, while an action is identified, it's not explicitly defined, making it 3.", "grounding_specificity_rationale": "The reviewer refers to 'Search models comparison 5.1'. This provides some grounding as the section or table number is mentioned. However, the reviewer doesn't specify *which* part of section 5.1 they are referring to, making the grounding only weakly specific. The specificity is also limited because the reviewer is asking about the *meaning* of '100 steps' within that section, not a specific issue within that section.", "verifiability_rationale": "The reviewer is asking a question ('what does 100 steps here mean?') without providing any context or justification for why they believe there's ambiguity. Therefore, while they are pointing out a potential issue, the verifiability of their claim is not explicitly supported by evidence within the review point itself. It's a request for clarification, implying a belief in ambiguity, but the justification for that belief isn't present.", "helpfulness_rationale": "The reviewer's primary goal is to clarify something for the authors. This is a valuable piece of feedback as it helps the authors understand the method better. However, the helpfulness is limited to enabling the authors to investigate further, rather than directly guiding them on how to improve their work. It's a request for clarification, not a direct solution or a pinpointing of a specific weakness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the improvement is 'small' and suggests concrete actions like repeating experiments and conducting statistical analysis. This indicates an awareness of the need for further investigation and improvement. However, the reviewer does not specify the exact nature of the 'small' improvement or the precise steps involved in the suggested actions, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'previous methods,' 'Table 1 and Fig.5,' and 'statistical significance' as areas needing improvement. While they don't pinpoint the exact section or element within these figures/tables, their mention strongly suggests a specific area of concern. This can be considered weak grounding as the authors can infer the issue. However, the reviewer doesn't specify what is missing or how the results should be reported, making the specificity somewhat limited.", "verifiability_rationale": "The reviewer claims the results are 'not reported' and the improvement is 'hard to know.' This is a clear claim that requires justification. The reviewer suggests repeating experiments and conducting statistical analysis as a way to address this lack of verifiability, indicating a belief in the validity of their claim. While the claim is stated, the supporting evidence is not provided at this point, making the verifiability somewhat limited.", "helpfulness_rationale": "The reviewer provides a clear and actionable critique, highlighting the limited improvement and the lack of statistical significance. They suggest concrete steps, such as repeating experiments and conducting statistical analysis, which could be directly helpful for the authors in addressing these issues. The reviewer's suggestions are specific and point towards concrete improvements, making the feedback 5 and potentially impactful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'The method is evaluated only on the tasks from Meta World...' which is an explicit action identifying a limitation. The reviewer also suggests 'I strongly recommend running experiments on a different benchmark such as Atari...', which is a concrete action based on the identified limitation. The action is clearly identified and the reviewer proposes a solution.", "grounding_specificity_rationale": "The reviewer mentions 'Meta World, a robotic manipulation domain' which grounds the comment to a specific area. However, the reviewer does not specify *which* tasks within Meta World are used for evaluation, making the grounding not fully specific. The comment clearly identifies a limitation related to the chosen domain, which can be considered specific feedback about the method's limitations. The grounding is present, but the specificity of the *exact* tasks is lacking.", "verifiability_rationale": "The reviewer makes claims such as 'It is difficult to judge whether the results will generalize to other domains' and 'I strongly recommend running experiments on a different benchmark such as Atari...'. These are claims that require justification. However, the reviewer does not provide any specific evidence or references to support these claims or the recommendation. The reasoning is present, but the supporting evidence is missing.", "helpfulness_rationale": "The reviewer points out a limitation in the evaluation of the method (lack of generalization due to Meta World focus) and suggests a concrete improvement (ATARI experiments). While the reviewer's suggestion is valuable, the *current* review point itself does not directly improve the method. It identifies a weakness in the evaluation and proposes a solution, but it doesn't offer a new insight or clarification about the method itself. The feedback is focused on the evaluation scope rather than a direct improvement of the method's mechanism."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a weakness ('a bit of analysis on what the model does is missing') and provides a clear action ('check the feedback/suggestions'). The action is direct and tells the authors exactly where to look for the analysis. The suggestion is concrete, pointing them to a specific resource (feedback/suggestions).", "grounding_specificity_rationale": "The review point refers to 'what the model does' and 'feedback/suggestions' as the location for the missing analysis. While it points to a general area of the feedback, it doesn't specify a particular section, table, figure, or unique element of the paper. The reviewer is making a general comment about the model's behavior rather than referencing a specific part of the paper.", "verifiability_rationale": "The review point makes a claim ('a bit of analysis on what the model does is missing') but does not provide any justification or evidence for this claim. It simply states the problem without explaining why it's a problem or how it should be addressed.", "helpfulness_rationale": "The review point identifies a potential improvement ('a bit of analysis on what the model does is missing') and suggests a location for this improvement ('check the feedback/suggestions'). However, it lacks any explanation of why this analysis is important or how it would benefit the authors. The suggestion is present, but the reasoning is missing, making it incomplete."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that the 'approach section' is missing. This is an explicit indication of a structural issue within the paper. While the reviewer doesn't provide concrete instructions on *what* to do with this missing section, the absence itself is a clear actionable piece of feedback. The reviewer implicitly suggests that the approach should be in a standard location within a paper, which provides a further level of actionable guidance.", "grounding_specificity_rationale": "The reviewer points to the 'approach section' as the missing element. While they don't explicitly name the section by number or title, the implication is clear. The reviewer knows *where* the information should be, even if they have to consult the supplementary material to find the details. This constitutes 'full grounding' as the authors can infer the location of the relevant information. However, the reviewer doesn't specify *what* is missing within that section, making it 'underspecific'.", "verifiability_rationale": "The reviewer's comment does not contain a claim or suggestion. They are stating a fact about the missing 'approach section'. Therefore, there is no verifiable information in this review point.", "helpfulness_rationale": "The reviewer points out that the approach section is missing and that the supplementary material should be used instead. This is a valid observation about the paper's structure. However, it doesn't directly guide the authors on how to improve their *own* draft. The reviewer is highlighting a problem with the paper's organization rather than providing a solution within the main document. Therefore, it is not 5 for improving the author's specific work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the weakness in the introduction and provides a clear suggestion for improvement. The weakness is the statement's vagueness regarding the biological plausibility of backpropagation, and the suggestion is to make it stronger.", "grounding_specificity_rationale": "The reviewer identifies the specific part of the paper (introduction) where the statement is made and provides a clear explanation of why that statement is weak. They point to the general consensus within the field about the biological implausibility of backpropagation, making their grounding specific.", "verifiability_rationale": "The reviewer identifies a claim in the introduction regarding the statement's weakness and provides a clear justification for this claim by referencing the general consensus on the biological implausibility of backpropagation. This justification serves as supporting evidence.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement directly related to a specific claim in the introduction. They identify a weakness and offer a concrete way to address it, making the review 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states a fact about the modulator being 'heuristically designed' and a potential issue with 'scalability and hyperparameter tuning.' It doesn't explicitly tell the author what to do or how to improve it. The reviewer implies a problem but lacks concrete action items. The statement about the modulator being 'heuristically designed' is explicit, but the concern about scalability and hyperparameter tuning is also explicit, though it requires the author to infer the nature of the heuristic. The reviewer points out a problem but doesn't provide concrete steps for the author to take. They mention the 'potential' need for hyperparameter tuning but don't specify which parameters or how to tune them.", "grounding_specificity_rationale": "The review mentions 'modulator' and 'hyperparameter tuning,' which are technical terms. However, it doesn't explicitly refer to a specific section, table, figure, or unique element of the paper where these things are discussed. The reviewer uses technical terms but doesn't clearly identify the specific part of the paper being addressed. The issue is presented generally without pinpointing the exact location or problem. The reviewer mentions 'modulator' and 'hyperparameter tuning' but doesn't specify which section or table discusses the modulator or which hyperparameters are involved. The issue is presented generally without pinpointing the exact location or problem.", "verifiability_rationale": "The review makes claims about the modulator being 'heuristically designed' and the need for 'tedious hyperparameter tuning' without providing any evidence, logical reasoning, or references to support these statements. The review contains a claim that the modulator is 'heuristically designed' and that there is a 'potential' scalability issue requiring 'tedious hyperparameter tuning.' It doesn't provide any evidence or justification for these claims. The review states a claim that the modulator is 'heuristically designed' and that there is a 'potential' scalability issue requiring 'tedious hyperparameter tuning.' It doesn't provide any evidence or justification for these claims.", "helpfulness_rationale": "The review points out a potential issue with the modulator's design and scalability. However, it doesn't offer any specific advice or guidance on how to address this. The reviewer states a fact about the modulator being 'heuristically designed' and a potential issue with 'scalability and hyperparameter tuning.' It doesn't provide any suggestions or guidance on how to improve the modulator or address the scalability concerns. The review highlights a potential problem but doesn't offer any helpful or actionable feedback. The review points out a potential issue with the modulator's design and scalability but doesn't offer any specific advice or guidance on how to address these issues. It presents a critique without a clear path forward."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point implies a potential issue with directly using f_R/f_P, but it doesn't explicitly state or detail the action of using less informed versions or the implications for data requirements. Therefore, it's 2.", "grounding_specificity_rationale": "The review refers to 'f_R and f_P' generally and discusses their 'structure' and the 'requirement of impractical amount of data' without pinpointing a specific part of the paper or a unique aspect. Therefore, it's 1.", "verifiability_rationale": "The review point doesn't make a claim or assertion; it describes the potential limitations of f_R/f_P. Therefore, it has no verifiability.", "helpfulness_rationale": "The review point discusses a potential practical limitation of f_R/f_P without offering concrete advice or identifying a specific weakness in the authors' draft. Therefore, it's 2."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer raises a question about the implications of overparameterization and memorization for generalization, which, while not directly instructing an action, points towards a potential area for improvement in the paper. The reviewer is implicitly suggesting that the paper should consider the connection to generalization bounds, which could be a concrete action for the authors to take. However, the reviewer does not explicitly state what action the authors should take, making it less than fully actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'generalization bounds' and the 'implications for generalization,' which clearly grounds the comment in a specific part of the paper and identifies a specific issue. They are also pointing to the acknowledged weakness regarding robust memorization and generalization, further emphasizing the grounding in a specific area of the paper.", "verifiability_rationale": "The reviewer makes a claim about a potential gap in the paper's argument regarding the connection between overparameterization, memorization, and generalization, specifically mentioning generalization bounds. This claim is somewhat supported by the acknowledgement of the paper's conclusion, suggesting the reviewer believes the paper should address this. However, the paper could potentially elaborate further on this point, making the claim less 5.", "helpfulness_rationale": "The reviewer raises a significant point that directly challenges the paper's conclusions and implications. By questioning the connection between memorization and generalization in overparameterized networks, they are highlighting a potential weakness and suggesting a valuable area for discussion and improvement. While the paper might have implicitly addressed this, the reviewer's point is a constructive criticism that could lead to significant enhancements."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states \"it does not thoroughly explore the implications of their proposed method for other NLP tasks\" and \"this somewhat limits the generalizability of the results.\" While it points to a problem, it doesn't tell the authors *how* to address it. It's a statement of a limitation, not a directive for improvement.", "grounding_specificity_rationale": "The comment refers to \"their proposed method\" and \"other NLP tasks\" generally, without pinpointing a specific section, table, figure, or unique aspect of the method being affected. It's a broad statement about the method's potential.", "verifiability_rationale": "The comment makes a claim \"this somewhat limits the generalizability of the results\" about the implications of the method for other NLP tasks but does not provide any specific examples, references, or logical reasoning to support this claim.", "helpfulness_rationale": "The comment identifies a potential limitation regarding the generalizability of the method but does not offer any concrete steps or suggestions on how to investigate this further or how to adapt the method for other NLP tasks. It's a statement of a problem without offering a solution."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "6: X", "helpfulness_label": "4", "actionability_rationale": "The review point states a lack of clarity, which is a question, not a suggestion for action. Actionability requires explicit and concrete instructions on how to improve the draft.", "grounding_specificity_rationale": "The review point refers to 'the proposed sample selection mechanism' and 'label distribution' without specifying which section or table of the paper these concepts relate to. This makes the reviewer's claim about the mechanism and concept unclear and 1 in a specific part of the paper.", "verifiability_rationale": "The review point is a question, not a claim. Verifiability requires a claim to be supported by evidence (logical reasoning, common knowledge, or external references).", "helpfulness_rationale": "The review point points out a lack of clarity regarding a specific mechanism. While this could be helpful for the authors if they are struggling with this aspect, the review point itself does not directly suggest how to improve the mechanism or the label distribution. It identifies a potential issue but lacks specific details on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The comment explicitly states 'two relatively old and small models are evaluated.' This is an explicit action, as it directly points out what was done. However, it doesn't provide concrete guidance on how this limited scope affects the analysis or recommendations. The action is identified, but the implications are not elaborated upon.", "grounding_specificity_rationale": "The comment identifies a specific aspect of the evaluation \u2013 the models used. It specifies that they are 'relatively old and small.' While it doesn't name the specific models, it clearly pinpoints the area of the evaluation being discussed. Therefore, it can be considered 'Weakly Grounded' as the authors can infer the models are likely referring to a specific category of models. The specificity of 'relatively old and small' is also clear.", "verifiability_rationale": "The comment makes a statement about the 'limited scope' of the evaluation, specifically mentioning 'two relatively old and small models.' This can be considered a claim. However, the comment doesn't provide any evidence or reasoning to support this statement. It simply states the observation without backing it up with logical arguments or references. Therefore, it lacks sufficient verifiability.", "helpfulness_rationale": "The comment points out a limitation in the evaluation \u2013 the use of 'two relatively old and small models.' While this is a valid observation, it doesn't directly help the authors improve their draft. The review doesn't suggest any concrete steps or considerations the authors should take to address this limitation. It identifies a problem but doesn't offer actionable solutions for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the connection between Knowledge Distillation (KD) and Label Smoothing (LS) and provides specific conditions (uniformly distributed teacher network and temperature set at 1) under which they can be viewed as equivalent. While the reviewer doesn't delve into the mathematical implications of these conditions, the connection and the conditions are clearly stated, making it an explicit and somewhat concrete point.", "grounding_specificity_rationale": "The reviewer mentions specific techniques (KD and LS) and provides conditions that could be relevant to understanding their relationship. However, the reviewer does not explicitly state which part of the paper or draft they are referring to, nor does they clearly specify what issue they are addressing within those techniques. The connection is implied but not explicitly grounded in a specific section or table, and the specificity of the claim within that context is not detailed.", "verifiability_rationale": "The reviewer presents a claim about the relationship between KD and LS under specific conditions. However, the reasoning behind this claim is not fully elaborated or supported by references. The conditions are stated, but the logical connection and the basis for why these conditions make them equivalent are not clearly explained or justified.", "helpfulness_rationale": "The reviewer attempts to provide a conceptual link between KD and LS, which could be helpful for some readers. However, the review does not offer specific, actionable feedback or suggestions on how to improve the draft based on this observation. The feedback is more of a conceptual point than a direct improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential improvement to the paper by suggesting the inclusion of more recent dynamicpruning methods and results on larger datasets. While it doesn't explicitly state how to implement these changes, it implies a direction for improvement. The reviewer suggests using 'more recent works' and 'results on large scale datasets including ImageNet' to 'further verify the effectiveness of the proposed method'. This indicates a desire for more robust and uptodate evaluation. However, the review lacks specific instructions on which methods to include or how to conduct the experiments on larger datasets, making the action somewhat implicit and lacking concrete details.", "grounding_specificity_rationale": "The review point explicitly mentions 'dynamicpruning methods' and 'ImageNet' as areas for improvement. It also states the need to 'further verify the effectiveness of the proposed method'. This indicates a clear focus on specific aspects of the paper and the desired outcome. The reviewer doesn't just mention 'dynamicpruning methods' but specifically suggests 'more recent works', and mentions 'large scale datasets including ImageNet' as a specific example. The goal of 'further verifying the effectiveness' is also a specific direction. Therefore, the review point is grounded in specific parts of the paper and provides clear information about the intended changes.", "verifiability_rationale": "The review point contains a claim that 'No.3. 2021. Competing dynamicpruning methods are kind of outofdate. More recent works should be included. Only results on small scale datasets are provided. Results on large scale datasets including ImageNet should be included to further verify the effectiveness of the proposed method.' This is a statement of opinion and a suggestion for improvement. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion is based on the observation that 'only results on small scale datasets are provided' and proposes 'results on large scale datasets including ImageNet'. While the implication is that larger datasets are more relevant, there is no explicit justification provided for why the current methods are outofdate or why ImageNet is the ideal choice. Therefore, the claim is present but lacks sufficient verifiable support.", "helpfulness_rationale": "The review point identifies a potential improvement to the paper by suggesting the inclusion of more recent dynamicpruning methods and results on larger datasets. The reviewer explicitly states the need for 'more recent works' and 'results on large scale datasets including ImageNet' to 'further verify the effectiveness of the proposed method'. This points to a desire for more robust and uptodate evaluation. While the review doesn't provide specific instructions on which methods to include or how to conduct the experiments, it clearly identifies a direction for improvement and a specific goal. The reviewer's suggestion is relevant to the field and addresses a potential limitation in the current evaluation. Therefore, the review point offers a clear and constructive suggestion for improvement, making it helpful to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that 'performance degrades when using the additional information about missing/wrong/redundant data'. This is a direct statement of an action (identifying a problem) and the expected outcome of a modification (adding information). The request to 'throw light on why' further implies a desire to understand the mechanism behind this action. The reviewer is directly addressing a specific aspect of the FBN results. The request is clear and actionable for the authors.", "grounding_specificity_rationale": "The reviewer refers to 'FBN results (table 5)' which is a specific part of the paper. This clearly identifies the area being discussed. The reviewer is also asking about the impact of 'additional information about missing/wrong/redundant data', which is a specific type of information. The combination of referring to a specific table and a specific type of information demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer makes a claim that 'performance degrades when using the additional information about missing/wrong/redundant data'. This is a claim that needs to be supported by evidence or reasoning. However, the reviewer does not provide any justification or explanation for *why* this degradation occurs within the review point itself. The request is a question that needs to be answered, implying a lack of current understanding or sufficient evidence.", "helpfulness_rationale": "The reviewer directly asks a question seeking clarification on a specific observation related to the FBN results. This is a clear and actionable request for the authors. The reviewer is pointing to a specific area of the results (table 5) and highlighting a potential issue (performance degradation with additional information). This is a very helpful request as it directly addresses a point of confusion or concern for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer criticizes the *purpose* of using randomly sampled CIFAR images as backgrounds, stating that this choice is not wellmotivated. While the reviewer identifies a potential issue with the experimental setup, they do not explicitly state what the authors should do to address this. The criticism focuses on the *why* of the choice rather than providing a clear action for the authors to take.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify a specific part of the paper where the use of randomly sampled CIFAR images as backgrounds is being questioned. The criticism is general and applies to the entire experimental setup. Therefore, the reviewer's comment is 1 in a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer's statement, 'Why is this particular dimension of difficulty interesting?' is a question that expresses a lack of understanding or motivation for the chosen experimental setup. It is not a claim that can be verified through logical reasoning, common knowledge, or external references. The reviewer is expressing a critique of the design goal, not a claim requiring justification.", "helpfulness_rationale": "The reviewer's comment is a critique of the experimental setup used in a paper sample, not a direct suggestion for improvement within the authors' specific draft. It raises questions about the motivation behind the chosen difficulty, which could lead to a discussion about experimental design but does not directly help the authors improve their own work. The comment is about the *design* of another example, not a specific weakness in the authors' draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'minimizing the averaged loss across the noise injected models does not ensure the flatness of the minima.' This is a clear and direct criticism of the paper's claim. Furthermore, the reviewer provides a concrete suggestion: 'To claim that the minima found by minimizing the loss in Eq (3), the analysis on the losses of the noiseinjected models after training is required.' This indicates a clear next step for the authors to take. The reviewer's point is directly actionable and provides a specific direction for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the noiseinjected models' and refers to the loss function in Eq (3). This clearly identifies the specific part of the paper being addressed. The comment is not ambiguous and directly points to this specific aspect. Therefore, the grounding is fully explicit. The reviewer also specifies what needs to be done: 'the analysis on the losses of the noiseinjected models after training is required.' This makes the action fully specific.", "verifiability_rationale": "The reviewer makes a clear claim: 'minimizing the averaged loss across the noise injected models does not ensure the flatness of the minima.' This is a statement that can be verified. While the reviewer doesn't provide a specific example or reference in the review point itself, the *claim* itself is a statement that can be supported or refuted with evidence. The reviewer also provides a *reason* for their claim: 'The reviewer argues that minimizing the average loss might not guarantee flatness in the context of noiseinjected models.' This logical reasoning makes the claim 3.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper's claim about flat minima. They directly point out that minimizing the averaged loss might not ensure flatness. This is a valuable insight for the authors. The reviewer also provides a concrete suggestion for improvement: 'To claim that the minima found by minimizing the loss in Eq (3), the analysis on the losses of the noiseinjected models after training is required.' This specific suggestion is actionable and directly addresses the identified weakness. The reviewer's comment is directly relevant and provides a clear path for the authors to improve their work. Therefore, it is 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem ('text inside the figure and the labels are too small') and provides a clear action to address it ('should be roughly the same size as the manuscript text'). This is an explicit and concrete action that authors can directly implement.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific parts of the paper being addressed ('text inside the figure and the labels'). This is a clear and precise identification, making it fully grounded. The reviewer also specifies what is wrong ('too small') and what the desired outcome is ('roughly the same size as the manuscript text'). This is fully specific.", "verifiability_rationale": "The review point makes a statement about the size of the text, which can be considered a claim. While the reviewer doesn't explicitly provide reasoning or references within the review point itself to verify this claim, the suggestion to 'zoom' implies a practical verification process. The claim is clear and directly related to a visual element of the paper. Therefore, it is 3 as it points to a clear issue that can be checked.", "helpfulness_rationale": "The review point is 5, directly pointing out a clear issue ('text inside the figure and the labels are too small') and providing a concrete suggestion ('should be roughly the same size as the manuscript text'). This directly helps the authors improve their draft by making it more readable. The suggestion is clear and easy to implement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a problem ('The motivation is not clear at all') but does not specify *how* the motivation needs to be improved or which specific aspect of the motivation is unclear. The action is implicit, requiring the authors to interpret the statement and infer the need for clearer motivation.", "grounding_specificity_rationale": "The comment explicitly mentions the 'introduction' as the area needing improvement, providing some grounding. However, it does not specify *which part* of the introduction is unclear or *what specific issues* exist within that section. The grounding is partial, leaving the authors to determine the exact area of concern.", "verifiability_rationale": "The review point does not contain a claim in the sense of a statement that requires justification or evidence. It is a statement of observation ('The motivation is not clear at all'). Therefore, it does not have verifiability in the context of supporting a claim.", "helpfulness_rationale": "The comment identifies a significant weakness ('The motivation is not clear at all') and suggests improvement ('The introduction should be carefully revised'). While it doesn't specify *how* to improve the motivation, it clearly points to a crucial area for revision, making it a helpful starting point for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly states 'alignment of relabeled reward data with human annotator judgments' which is an actionable step the authors should take. However, it does not specify how to achieve this alignment or what specific actions need to be taken. Therefore, while it points to an area for improvement, it lacks the concrete details necessary for immediate action.", "grounding_specificity_rationale": "The comment explicitly mentions 'relabelled reward data' and 'human annotator judgments,' indicating a strong grounding as the authors can identify the specific parts being discussed. However, it doesn't specify which aspects of the alignment need to be validated, making it somewhat general about the specifics of the validation process. Therefore, while the section is identified, the details are not.", "verifiability_rationale": "The comment itself does not contain a claim that requires verification. It's a statement of a problem ('insufficiently validated'). While the reviewer implies a need for validation, they don't provide any evidence or reasoning to support this claim. Therefore, it doesn't meet the criteria for verifiability.", "helpfulness_rationale": "The review points out a valid issue (lack of validation for data alignment) but does not provide any suggestions or guidance on how to address it. It identifies a problem but doesn't offer a solution, making it unhelpful for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests replacing natural language descriptions with notation and adding breakout diagrams showing attention mechanisms. These are clear, actionable steps that authors can directly implement to improve their understanding and presentation of the model. The reviewer directly states actions or suggestions that are direct or apparent.", "grounding_specificity_rationale": "The reviewer mentions 'section 4' and 'attention mechanisms' in the model description, indicating a degree of grounding. However, the suggestion to 'improve the presentation in section 4' is quite general. While the reviewer identifies a specific part of the model, the exact nature of the improvement within that section is not clearly defined. The authors would need to infer what specific aspects of the presentation require improvement.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement rather than a statement of a claim that can be verified. The reviewer does not make any claims about what is currently lacking or incorrect in the model or its presentation. The suggestion is about what should be done, not what is being done.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by pointing out a potential area for clarification and offering concrete solutions. The suggestion is about improving the presentation of section 4 by using notation and diagrams, which directly helps the authors understand the model better. The reviewer's suggestion is actionable and directly addresses a potential weakness in the presentation."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a potential limitation in the method's generalizability but does not explicitly state what action the author should take or how to address it. It raises a concern about the need for individual training, but lacks specific guidance on how to mitigate this issue.", "grounding_specificity_rationale": "The reviewer mentions 'limited number of molecules' and 'indistribution testing,' which are specific aspects of the paper. They identify the area of concern, but the inference that 'the value of this method would be limited if it needs to train for each molecule individually' is not explicitly stated, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer states a concern about the method's value if individual training is required, but this claim is not supported by any evidence or reasoning. There is no logical argument, common knowledge, or external references provided to back up this assertion.", "helpfulness_rationale": "The review point raises a concern about the method's value in a specific scenario (individual training) but fails to provide any justification or suggestions for improvement. It presents a potential limitation without offering any actionable feedback or evidence to support its claims."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies an issue (complication) with symbols, which can be considered an explicit action or an implicit action that needs to be inferred. However, it lacks specific details on *what* aspects of the symbols are complicated and doesn't propose concrete actions to address this issue. It points to a problem but doesn't offer a clear path to solution.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper or symbols being addressed. It makes a general statement about the 'symbols' without specifying which ones or what aspect of them is complicated. Therefore, it lacks grounding as it doesn't pinpoint the relevant section or element. It also lacks specificity as it doesn't detail the nature of the complication.", "verifiability_rationale": "The review point itself is not a claim that requires verification. It's a statement of observation about the complexity of symbols. While it could be followed up with a request for clarification or examples (which would be verifiable), the point itself doesn't contain a claim that needs supporting evidence.", "helpfulness_rationale": "The comment points out a potential issue (complicated symbols) that could hinder understanding and efficiency. However, it doesn't offer specific, actionable suggestions or guidance on how to improve the clarity of the symbols. It identifies a problem but doesn't provide constructive solutions, making it 3 but not highly so."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states, 'I don't understand the red line: Where does the test data come from? Do you have a ground truth?' This indicates a desire for clarification, which can be considered an actionable step. However, the explanation provided in the review point is vague and does not detail how to interpret the red line or what specific data is being referenced. Therefore, while the action of asking for clarification is present, the lack of concrete information makes it only partially actionable.", "grounding_specificity_rationale": "The reviewer directly asks specific questions about the red line: 'Where does the test data come from?' and 'Do you have a ground truth?'. These questions explicitly identify the specific part of the paper (the red line in Figure 3) and the information needed (source of test data and presence of ground truth). This demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer makes a claim by stating, 'I don't understand the red line...'. This claim is not supported by any evidence or reasoning within the review point. The reviewer is essentially asking a question that requires further explanation or justification, but the current review point does not provide any. Therefore, the claim is not verifiable based on the information provided in this review point.", "helpfulness_rationale": "The review point asks a question but does not provide any explanation or information to address the reviewer's confusion about the red line in Figure 3. The reviewer explicitly states they don't understand, and the review point does not offer any clarification. Therefore, the review point is not currently helpful in improving the draft."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests the action of 'adding periodicity to the spectral kernel'. This is a clear and direct action that the authors can readily implement. The suggestion directly addresses a potential limitation of the comparison model and proposes a concrete modification.", "grounding_specificity_rationale": "The review point explicitly states that the comparison model 'cannot capture periodic relationships' and that 'in all of the experiments except Experiment 1b the relationships that people were learning involved periodicity'. This clearly identifies the specific part of the model being addressed and the specific property of the relationships being learned. The suggestion to 'add periodicity to the spectral kernel' further pinpoints the exact area of modification. The reviewer also poses a question about whether this addition would allow the model to capture all results at a similar level to the explicitly compositional model, which directly relates to a specific aspect of the model and its performance.", "verifiability_rationale": "The review point makes the claim that 'Would adding periodicity to the spectral kernel be enough to allow it to capture all of these results at a similar level to the explicitly compositional model?'. This claim is verifiable through a suggested experiment. The reasoning is logical: if the comparison model struggles with periodicity and the experiments involved periodicity, adding periodicity to the spectral kernel should, in theory, improve its performance and allow it to match the compositional model's level. The suggestion to 'test this' provides a clear path for verification.", "helpfulness_rationale": "The review point directly addresses a potential weakness of the comparison model (its inability to handle periodicity in the context of the experiments) and offers a concrete suggestion for improvement (adding periodicity to the spectral kernel). The reviewer also poses a question that directly probes the effectiveness of this suggestion. This makes the review point 5 as it identifies a clear area for improvement and provides a direction for further investigation. The suggestion is actionable and directly relevant to the identified problem."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2: 3", "helpfulness_label": "3", "actionability_rationale": "The comment states that the paper is 'not very wellwritten' and 'possibly hurriedly written'. This is a general statement about the writing quality and does not specify what needs to be improved or how to address the issue. The action is implicit, requiring the authors to infer the need for revision and potentially seek clarification on what constitutes a 'badly written' paper. There is no explicit instruction on what specific aspects of the writing need improvement or what actions should be taken to make it better.", "grounding_specificity_rationale": "The comment does not specify which part of the paper is problematic. It refers to the paper as a whole and attributes the issue to 'possibly hurriedly written'. The authors cannot confidently determine if the problem lies in the introduction, methodology, results, or discussion. The grounding is weak because the authors are left to make an educated guess about the affected section or element.", "verifiability_rationale": "The comment contains a claim that the paper is 'not very wellwritten' and 'possibly hurriedly written'. However, this claim is not supported by any specific examples, citations, or logical reasoning. The verifiability is low because the authors are left to interpret the meaning of 'not very wellwritten' and 'hurriedly written' without any concrete evidence to back up the assertion. There is no clear justification for why the writing is poor or why it was written hurriedly.", "helpfulness_rationale": "The comment identifies a problem with the paper's writing quality but does not provide any specific suggestions or actionable steps for improvement. The authors are left to figure out what aspects of the writing are poor and how they should be revised. While the comment highlights a valid concern, it lacks the guidance needed to make concrete changes. The feedback is present but lacks direction and practical advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'could be more detailed.' This is an implicit suggestion, indicating an action the authors should take (add more detail). However, the suggestion itself is vague, lacking specific guidance on what kind of detail to add. Therefore, while the intent is actionable, the lack of concrete details makes it 3.", "grounding_specificity_rationale": "The comment refers to 'orthogonality in Part 2.' This is a specific section of the paper, indicating that the authors can reasonably identify the referenced part. However, the comment does not specify *what* is missing or unclear about the introduction of orthogonality. The grounding is present, but the specificity is lacking.", "verifiability_rationale": "The review point itself does not contain a claim or opinion. It is a suggestion for improvement. Therefore, it does not meet the criteria for verifiability, which requires a claim to be supported by evidence.", "helpfulness_rationale": "The review point clearly identifies a potential area for improvement (more detail on orthogonality). This directly benefits the authors and provides a direction for their revision. While the suggestion is general, it is still a relevant and actionable piece of feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the paper's contribution as the removal of double descent under specific conditions *in relation* to prior work. This is an explicit action. The reviewer also specifies *how* the paper's contribution is novel (removing double descent under anisotropy) and *what prior work* it builds upon (theoretical results on samplewise multiple descent). This provides a clear direction for the authors to improve their framing.", "grounding_specificity_rationale": "The reviewer connects the paper's findings to existing theoretical work. While they don't explicitly point to a specific section, table, or unique aspect of the paper, the general area of 'samplewise multiple descent' and 'double descent' is implied. This suggests a weak grounding as the authors can't confidently determine which part the comment addresses. However, the reviewer clearly specifies what needs to be addressed in this part (removing double descent under anisotropy), making the specificity high.", "verifiability_rationale": "The reviewer states a claim: 'the main contribution of the paper appears to be the result that optimal regularization can remove double descent even in certain anisotropic settings.' This is a claim that needs to be verified. The reviewer suggests the authors 'do a better job of highlighting the novelty of their result in relation to prior results.' This is a suggestion for improvement, not a direct verification of the claim itself. The reviewer acknowledges their lack of familiarity with the techniques, suggesting they might not be able to verify the claims themselves. Therefore, the claim is only 3.", "helpfulness_rationale": "The reviewer provides a clear statement of the paper's contribution in relation to prior work and suggests a way to improve the paper's framing. This is a valuable piece of feedback for the authors. However, the feedback is somewhat general and doesn't delve into the specifics of the prior work or the anisotropic settings. While the authors can understand the point and implement the suggested framing change, the feedback could be more specific to be fully impactful."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states that the two methods are independent. While this is a true statement, it does not provide any actionable advice or suggestions on how to connect or relate the two methods. The authors are not guided on how to modify their understanding or the methods themselves based on this review point.", "grounding_specificity_rationale": "The review point explicitly names 'contrastive training objective' and 'contrastive search' as the two methods being discussed. It also mentions 'intuition' and 'algorithm' as aspects of these methods. This provides a clear and specific reference point for the reviewer's comment.", "verifiability_rationale": "The review point makes a claim about the relationship between the two methods ('little inner connection on both the intuition and the algorithm'). This claim can be verified by examining the original paper and assessing whether such a connection is indeed absent or explicitly discussed as a limitation. While the *statement* is verifiable, the *truth* of the statement requires further investigation.", "helpfulness_rationale": "The review point identifies a potential area for further exploration or discussion within the paper. It points out a gap in the authors' understanding or the paper's analysis regarding the relationship between the two methods. While it doesn't directly provide a solution, it highlights a weakness in the presentation or analysis that could be addressed to improve the paper."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the existence of DAS earthquake detectors and the lack of comparison, which is a direct and actionable point for the authors to address. The suggestion to clarify the foundation model claim and demonstrate future applications are also concrete actions the authors can take.", "grounding_specificity_rationale": "The reviewer names specific existing models (PhaseNetDAS) and suggests *where* the comparison should be made (in the context of DAS). They also suggest clarifying the foundation model claim and demonstrating a future application, which directly points to specific aspects of the paper. This indicates good grounding specificity.", "verifiability_rationale": "The reviewer provides *reasons* for why the existing models are relevant and what the paper should demonstrate to justify their contribution. The suggestions are logical and point to specific areas of the paper.", "helpfulness_rationale": "The reviewer clearly identifies a gap in the paper. They specify *what* is unclear (lack of comparison) and *where* it needs to be addressed (in the context of DAS). The suggestions are concrete and actionable. The reviewer also provides a clear justification for why these suggestions are important."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question about the limitations of the triplet approach, indicating an action being taken to understand this limitation. The question prompts the authors to consider the scope and applicability of their method, suggesting a direct attempt to improve their approach by addressing the identified issue.", "grounding_specificity_rationale": "The reviewer asks a question about the limitations of the triplet approach without explicitly pointing to a specific section, table, figure, or unique aspect of the paper where this limitation is most evident. While the context implies they are referring to the method described in the paper, the question itself lacks the precision required for strong grounding.", "verifiability_rationale": "The reviewer states that the restriction to triplets is 'quite limiting' without providing any specific evidence or reasoning to support this claim. They are posing a question for the authors to consider, but not making a verifiable statement about the limitations of the approach based on logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer's question is about a potential limitation of the triplet approach. While it prompts the authors to consider the scope and applicability of their method, it doesn't directly suggest a specific action the authors should take *now* to address the identified limitation. It's a question for clarification, not a direct suggestion for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests adding AccNet as part of a larger predictor and mentions 'similar operators'. This provides a clear action for the authors to take, namely exploring this potential extension. The suggestion is directly linked to the concept of semantic segmentation, further clarifying the intended context.", "grounding_specificity_rationale": "The review point uses specific terms like 'AccNet', 'larger predictor', 'semantic segmentation', and 'similar operators'. These terms directly refer to specific aspects of the paper and the suggested improvement, indicating strong grounding. The reviewer is pointing to a concrete area for potential improvement.", "verifiability_rationale": "The review point suggests a potential extension to the work by proposing to learn AccNet within a larger predictor framework for semantic segmentation. While it doesn't provide a definitive 'yes' or 'no', it offers a concrete direction for future research and experimentation. The suggestion implies a potential improvement that could be verified through further analysis and implementation.", "helpfulness_rationale": "The review point encourages the authors to consider adding AccNet as part of a larger predictor for semantic segmentation. This is a valuable suggestion that could guide future research and potentially lead to improvements in the model. While it doesn't directly address a specific problem, it offers a concrete direction for exploration and experimentation, which can be helpful for the authors in expanding their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The statement explicitly identifies a limitation of the metric's testing and suggests a concrete improvement: 'should be tested on more datasets'. This is an explicit action that is also concrete, as it clearly states the desired improvement.", "grounding_specificity_rationale": "The reviewer mentions 'a single dataset' but doesn't specify which dataset. While the type of limitation (lack of generalization) is clear, the specific dataset is not identified, making the grounding weak. The comment focuses on the *metric's testing* rather than a specific part of the paper.", "verifiability_rationale": "The statement 'The new proposed metric is only tested on a single dataset' is a claim that can be verified by examining the testing procedures of the metric. While no specific examples or external references are provided within this review point, the statement itself is verifiable based on the reviewer's knowledge or by checking the metric's documentation. The reasoning is logical, and the claim refers to a verifiable fact.", "helpfulness_rationale": "The comment identifies a limitation of the metric's testing but doesn't offer concrete suggestions for improvement or explain why testing on more datasets is beneficial. It's a valid criticism but lacks actionable feedback for the metric's developers. The helpfulness is limited as it doesn't directly address the metric's weaknesses or provide clear guidance on how to improve it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the action: 'spelling out the setting' in the first three paragraphs of section 2. This is a clear and direct action that the authors can readily understand and attempt to implement.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific part of the paper being addressed: 'the first three paragraphs of section 2'. This is strong grounding as the authors can directly locate this section. Furthermore, the reviewer clearly states what needs to be spelled out: 'the setting', which is specific and actionable.", "verifiability_rationale": "The reviewer's comment contains a claim ('the setting needs to be spelled out more clearly') but does not provide sufficient evidence or justification for this claim. There is no logical reasoning, common knowledge, or external references provided to support the need for spelling out the setting. The reviewer is pointing out a potential issue without explaining *why* it is an issue or how it should be addressed.", "helpfulness_rationale": "The reviewer identifies a specific area where the authors are likely to struggle (clarity of the setting). While the *what* ( spelling out the setting in the specified section) is clear and actionable, the *how* of spelling out the setting is not specified. This makes the comment helpful in identifying a problem but less helpful in providing a concrete solution."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitations of the chosen baselines (R3D and C3D) and raises specific questions about the proposed method's applicability to more modern 3D CNNs (X3D, SlowFast). They also ask for a comparison of the proposed method's advantages over these newer approaches. These are clear actions that the authors can take to address the identified issues.", "grounding_specificity_rationale": "The reviewer mentions specific alternative 3D CNNs (X3D, SlowFast) when questioning the choice of R3D and C3D. This demonstrates a degree of grounding as they are not just stating a general concern but referring to specific models. However, the reviewer does not explicitly explain *why* R3D and C3D are problematic in the context of their specific task or *why* X3D and SlowFast are particularly relevant. The grounding is present but could be more detailed.", "verifiability_rationale": "The reviewer does not explicitly state a claim that requires verification. They are posing questions and making a statement about the experiments not being 'convincing.' While there's an implication of a need for better evidence, there isn't a direct assertion of a claim that needs to be supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer's point is helpful because it directly addresses a potential weakness in the experimental setup (the choice of older baselines) and prompts a discussion about the method's applicability to more modern architectures. The questions are relevant and could guide the authors in improving their evaluation or justifying their choice of baselines. While not a direct solution, it encourages a more thorough analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point contains an explicit statement about the performance difference between high and low bitrates. However, it lacks concrete suggestions for improvement. The reviewer points out a weakness without providing specific actions or modifications the authors should implement. While it identifies a problem, it doesn't offer concrete steps to address it. The lack of specific actionable items makes it less actionable than it could be.", "grounding_specificity_rationale": "The reviewer makes general observations about the performance of the proposed method at different bitrate ranges. While they mention 'high bitrate' and 'low bitrate,' they do not specify the exact sections, tables, figures, or unique aspects of the paper they are referring to. This lack of precise referencing makes the grounding weak.", "verifiability_rationale": "The reviewer makes observations about the performance of the method. These are statements of judgment or opinion, not claims that require evidence or verification. The lack of a claim means there is no verifiability in the traditional sense of supporting a statement with logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point identifies a weakness in the proposed method, which is generally helpful for authors as it highlights an area for improvement. However, the weakness is presented as a general observation without specific suggestions or context from related work. This makes it 3 but could be significantly improved by providing more concrete feedback or references."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review suggests a distinction between two concepts. While this points to a potential area for improvement in the authors' understanding, it doesn't explicitly state what needs to be done. The reviewer recommends distinguishing, but doesn't provide the steps or actions the authors should take to achieve this distinction. Therefore, it's not fully actionable.", "grounding_specificity_rationale": "The review mentions 'allornothing or cutoff phenomenon' and 'usual statistical bounds'. However, it does not explicitly identify which part of the paper this refers to. The reviewer is making a general suggestion about concepts without specifying the location or nature of the issue in the authors' work. The grounding is implied but not explicit.", "verifiability_rationale": "The review contains a claim: 'I would recommend the authors to distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with.' This claim is about suggesting a distinction between two concepts. However, the review does not provide any logical reasoning, common knowledge, or external references to support this claim. It simply recommends the action without justifying why it's important or how it should be done. Therefore, it is not verifiable.", "helpfulness_rationale": "The review offers a suggestion for improvement by recommending the authors distinguish between 'allornothing or cutoff phenomenon' and 'usual statistical bounds'. This is a specific type of suggestion aimed at clarifying a potential point of confusion or improving the authors' understanding of statistical concepts. While it doesn't provide a concrete solution, it points to a specific area for improvement in the authors' work. Therefore, it is 3 as it targets a specific aspect of the paper."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of the theoretical results to Gaussian features and noise and suggests a comparison to existing rates. This is a clear and direct action with concrete details.", "grounding_specificity_rationale": "The reviewer directly mentions \"features and noise are Gaussian,\" which is a specific and unambiguous reference to a part of the paper. They also explain the implications of this limitation and suggest a concrete next step.", "verifiability_rationale": "The reviewer makes a claim about the theoretical results and provides a clear justification by stating the specific limitation (Gaussian assumption) and suggesting a concrete next step (comparing utility rates). This justification is logical and provides a clear path for verification.", "helpfulness_rationale": "The reviewer provides a clear and actionable comment that identifies a specific limitation in the theoretical analysis and offers a concrete suggestion for improvement. This is 5 for the authors as it directly addresses a potential weakness and guides them towards further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly suggests a comparison with the original approach, which can be interpreted as an action to take. While it doesn't specify *how* to perform the comparison, it implies a concrete next step.", "grounding_specificity_rationale": "The comment explicitly mentions 'the original approach from Schiratti et al. (2015)' and 'even if only on the simulated data'. This clearly identifies the specific aspect of the original paper being addressed and the method of comparison, indicating strong grounding. The use of 'even if only on the simulated data' also implies a clear understanding of the relevant part.", "verifiability_rationale": "The comment suggests a comparison, which implies a claim that such a comparison would be useful. The 'even if only on the simulated data' part provides a justification for the suggestion, making the claim verifiable by demonstrating the potential benefits of the comparison.", "helpfulness_rationale": "The comment directly suggests a specific and actionable improvement: comparing the proposed extension with the original approach. This provides a clear direction for the authors to follow and understand the potential benefits of such a comparison."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of the baselines and provides concrete suggestions for improvement by adding specific baselines 1, 2, 3. This indicates a clear and actionable step for the authors to take.", "grounding_specificity_rationale": "The reviewer mentions the 'experimental section' and the idea of adding baselines, but doesn't specify the exact subsection or the nature of the existing baselines beyond 'two baselines.' However, the suggestion to add specific baselines 1, 2, 3 enhances the specificity of the feedback.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the experimental section and provides a suggestion to improve it by adding specific baselines 1, 2, 3. While the suggestion lacks specific references, it is a clear recommendation for improvement, making the claim 3.", "helpfulness_rationale": "The review directly addresses a potential weakness in the experimental section and offers a clear, actionable suggestion to improve it. This directly benefits the authors by guiding them on how to strengthen their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a desire for 'average results on the test set with clearly defined error bars.' This is a clear and actionable suggestion for improvement, directly addressing a potential weakness in the authors' methodology and results presentation. The reviewer provides a specific goal and a concrete step to achieve it, making it 5.", "grounding_specificity_rationale": "The reviewer mentions 'Tables 1 and 2' without specifying which table contains which data, making it somewhat unclear which part of the paper is being addressed. While the reviewer later suggests using the 'test set,' this is a general recommendation rather than a specific point within the paper that needs clarification. The initial critique about the 'dev set' for hyperparameter tuning and model selection lacks specific grounding in the paper's structure or content. The suggestion to use the 'test set' is a clear point of improvement, but it doesn't pinpoint a specific unclear part of the current paper.", "verifiability_rationale": "The reviewer makes a clear claim: 'If I understand correctly, In Tables 1 and 2, the authors report the best results on the **dev set** with the hyperparameter search and model selection on **dev set**, which is not enough to be convincing.' This claim is verifiable based on standard practices in machine learning research, where the test set should be used for final evaluation to avoid overfitting. The reviewer provides logical reasoning to support their claim, making it 5.", "helpfulness_rationale": "The reviewer's comment is a direct and actionable suggestion for the authors to improve their experimental evaluation. By recommending the use of the 'test set' and providing 'average results' with 'error bars,' the reviewer offers a concrete and beneficial improvement. This suggestion directly addresses a potential weakness in the authors' methodology and results presentation, making it 5 for the authors to enhance their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out missing information regarding the number of topics, the method of obtaining topicword parameters, and the size of the dataset. While the paper mentions the concept of topic modeling and the existence of 'topicword parameters', it does not explicitly state the number of topics used or how these parameters were derived. The paper mentions training on a dataset of 10,000 news articles, but lacks specifics on train/test split and vocabulary size, which are crucial for reproducibility and understanding the experimental setup. The reviewer's implicit request for this information can be considered an actionable suggestion, but the paper doesn't explicitly address it in a detailed manner.", "grounding_specificity_rationale": "The reviewer's request for specific details about the number of topics, the method of obtaining topicword parameters, and the size of the dataset (including train/test split and vocabulary size) can be considered as the authors identifying a specific part of the paper (the experimental setup) that needs clarification. However, the paper does not explicitly state the number of topics used or how the topicword parameters were obtained. While the paper mentions the dataset size in a general sense ('a dataset of 10,000 news articles'), it lacks the specific details requested by the reviewer. Therefore, the grounding is weak as the authors cannot confidently pinpoint the exact area needing clarification without further information from the paper.", "verifiability_rationale": "The reviewer states that the paper lacks information on how many topics were used, how topicword parameters were obtained for the AG news dataset, and the size of the dataset. The paper mentions 'topicword parameters' but does not provide any details on their derivation or the specific dataset being referred to as 'AG news'. The paper states 'The model was trained on a dataset of 10,000 news articles', which provides some information about the dataset size, but lacks specifics on train/test split and vocabulary size. The reviewer's claim that the paper does not contain a claim is incorrect as the reviewer is pointing out a missing claim (the lack of information). However, the lack of verifiable information makes the claim 1.", "helpfulness_rationale": "The reviewer's request for specific details about the number of topics, the method of obtaining topicword parameters, and the size of the dataset is directly addressing a gap in the paper's description. While the paper mentions the concept of topic modeling and the existence of 'topicword parameters', it does not provide the specific information requested by the reviewer. This lack of detail makes the information less helpful for the authors trying to understand and potentially reproduce the experiments. The reviewer's suggestion is a clear and actionable improvement to the paper's clarity and completeness."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests downplaying the distraction caused by the zeroshot version and connection to density estimation. While this is a suggestion, it lacks specific details on how the authors should change their presentation. The action is implied but not explicitly stated with concrete steps. Therefore, it is not fully actionable, but it is also not 1 as the authors can infer the need to adjust their focus.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify a specific part of the paper as being distractingly related to zeroshot learning or density estimation. The comment is a general statement about the presentation. Therefore, the grounding is weak as the authors cannot pinpoint the exact area needing adjustment.", "verifiability_rationale": "The reviewer's comment is a suggestion or opinion about the paper's presentation, not a claim that requires verification or justification. Therefore, it does not fall under the verifiability framework, which focuses on statements that need to be supported.", "helpfulness_rationale": "The reviewer offers a suggestion to improve the clarity of the paper by downplaying certain aspects. This is a helpful suggestion as it could guide the authors to focus their efforts on the core contribution. However, the suggestion is vague and lacks specific guidance on how to implement it, limiting its potential impact. Therefore, it is 3 but not very specific."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that 'details around the filtering process used to create the Arabic climate change QA dataset are lacking.' This indicates an awareness of a missing element. However, it doesn't specify *what* is lacking within the filtering process, nor does it provide a clear action on how to implement this actionable feedback. Therefore, while the reviewer identifies a gap, the action to be taken is not fully explicit or concrete.", "grounding_specificity_rationale": "The review point explicitly mentions 'filtering process' and 'Arabic climate change QA dataset.' This provides a clear reference point within the paper. While it doesn't specify a particular section or table, it clearly identifies the area of the paper where the issue lies. The reviewer also specifies that the lack of detail is regarding the 'filtering process' and that this information is needed to assess the 'dataset quality,' adding further specificity to the grounding.", "verifiability_rationale": "The review point implies a need for more information, suggesting a 'claim' that more details are required. The reviewer explains *why* more information is needed: 'Details around the filtering process used to create the Arabic climate change QA dataset are lacking' and 'more information on the translation and filtering methodology is needed to assess the dataset quality.' This provides some justification for the claim, making it 3.", "helpfulness_rationale": "The review point clearly identifies a gap in the information provided about the dataset. By stating that 'details around the filtering process used to create the Arabic climate change QA dataset are lacking' and 'more information on the translation and filtering methodology is needed to assess the dataset quality,' the reviewer directly points to a specific area where the authors need to improve. This makes the feedback reasonably specific and actionable, although it doesn't provide the exact steps to be taken."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the lack of 'attacks with different strength' and the lack of exploration of 'how different thresholds influence detection performance'. These are clear, actionable points that the authors can directly address by adding specific types of attacks and conducting experiments with varying thresholds. The reviewer provides the exact actions the authors should take, making this point 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'experiment results' and 'different thresholds' as the areas where improvements are needed. This strong grounding allows the authors to precisely identify the section and the specific issue. The reviewer also specifies the *type* of attacks ('different strength') and the *parameter* being analyzed ('different thresholds'), making this point highly specific.", "verifiability_rationale": "The reviewer makes claims about the lack of 'attacks with different strength' and the lack of 'analysis of different thresholds'. While the reviewer doesn't provide specific examples or external references to support these claims, the *lack of these elements* is a verifiable observation. The reviewer is pointing out a gap in the analysis, which can be considered a form of verifiable information, even without explicit evidence. The reviewer's statement itself is a claim that needs to be addressed.", "helpfulness_rationale": "The reviewer provides specific and actionable feedback, clearly pointing out the missing elements in the experiment results and suggesting concrete improvements. The reviewer explicitly states what is lacking and what should be added, making this feedback highly constructive and directly helpful for the authors to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the action: 'training a discriminator on generations from the learned model' to 'confirm if it is the case' (reducing exposure bias). This is a direct and clear action. While the reviewer also mentions 'in a way similar to Figure 1' and the difference from Figure 4, these are clarifying details rather than implicit actions. The core action is stated.", "grounding_specificity_rationale": "The reviewer explicitly identifies the 'generations from the learned model' as the specific part of the model being evaluated for the claim of 'reducing exposure bias'. This is a strong form of grounding as the specific part is clearly identified. The reviewer also specifies the purpose of the evaluation ('to confirm if it is the case') and the method ('training a discriminator similar to Figure 1'), which adds to the specificity.", "verifiability_rationale": "The reviewer makes a claim: 'training a discriminator on generations from the learned model is needed to confirm if it is the case, in a way similar to Figure 1'. The reviewer also provides a justification: 'Note that it is different from Figure 4, since during training the discriminator is coadapting with the generator, and it might get stuck at a local optimum'. While this justification provides context and highlights a potential issue, it does not directly verify the claim's verifiability. The claim is presented as a suggestion for evaluation, and the justification discusses a potential limitation of the method rather than providing concrete evidence for its verifiability.", "helpfulness_rationale": "The reviewer provides a clear suggestion for the authors to take: 'For evaluation, since the claim of this paper is to reduce exposure bias, training a discriminator on generations from the learned model is needed to confirm if it is the case, in a way similar to Figure 1'. This suggestion directly addresses the paper's claim and provides a concrete direction for the authors to follow. While the justification for this suggestion has limitations (as discussed in verifiability), the suggestion itself is actionable and directly relevant to the paper's goal."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the impact of specific experimental choices. It doesn't explicitly state what needs to be done. Therefore, it's likely 1. It poses a question, but doesn't guide the authors on what to do next.", "grounding_specificity_rationale": "The review point refers to 'performance difference' related to 'image sizes' and 'different variations of ResNets.' While it doesn't explicitly name a section, it clearly points to a comparison within the experimental setup or results sections. The authors can infer that the relevant part is likely the 'Experiments' or 'Results' section where these variations are described and their impact is evaluated. They would need to search to find the specific details. Therefore, it's weakly grounded as the authors can infer the area, but not pinpoint the exact subsection or figure.", "verifiability_rationale": "The review point itself isn't a declarative statement with a verb like 'explain' or 'demonstrate.' It's a question. Therefore, there's no explicit claim being made. It's a question, not a statement requiring verification.", "helpfulness_rationale": "The review point asks a relevant question about the experimental setup. Understanding the impact of these choices is crucial for reproducibility and interpreting the results. While it doesn't directly instruct the authors on what to do, answering it would provide valuable context and help the authors understand the experimental basis of the reported performance. Therefore, it's 3 as it raises a relevant point that encourages the authors to think about the implications of their experimental choices."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states the algorithm should be presented and described in detail, but does not specify how this should be done. The action is implied but not explicitly stated, making it only partially actionable.", "grounding_specificity_rationale": "The reviewer refers to the algorithm in general without specifying a particular section, table, or unique aspect. There is no literal mention of a specific part of the paper, and the reference is vague.", "verifiability_rationale": "The review point is a suggestion or recommendation and does not contain a claim that requires verification. There are no statements of fact, opinions, or judgments being made.", "helpfulness_rationale": "The review point encourages the author to provide more detail about the algorithm, which is generally helpful for understanding and replicating the method. While not a specific request, it points towards a beneficial improvement."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a concrete action: 'runtime comparison at test time'. This directly tells the authors what improvement they should consider implementing. The action is not just a suggestion but a specific request for experimentation.", "grounding_specificity_rationale": "The review point refers to 'the paper mentions the possibility to use Chebyshev polynomials'. While not a direct section number, this implies the authors can identify the relevant part of their paper where this potential speedup is discussed. The suggestion is also specific to a 'runtime comparison at test time', clearly defining the area for improvement.", "verifiability_rationale": "The review point, while not a direct criticism, implies a value judgment that a runtime comparison would be beneficial for the paper. This is a generally accepted goal in scientific computing, suggesting the suggestion is grounded in established practices. While not explicitly supported by external references, the implication is clear and logical.", "helpfulness_rationale": "The review point is 5 as it directly suggests a concrete, actionable improvement: a runtime comparison at test time. This provides a clear direction for the authors to validate or enhance their proposed method. It moves beyond criticism to offer a specific experiment or analysis to consider."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a problem ('prompts are not wellorganized') but doesn't explicitly state how to fix it. While the general issue is mentioned, the specific action needed is left implicit.", "grounding_specificity_rationale": "The reviewer mentions 'Table 6, 7' by name, which indicates some level of grounding. However, they do not specify the exact issue within these tables, making the grounding not fully specific.", "verifiability_rationale": "The reviewer makes a claim about the prompts being 'not wellorganized' and suggests they are 'squeezed together'. However, they do not provide specific examples or references to support these claims, making the verifiability low.", "helpfulness_rationale": "The reviewer identifies a valid concern about the organization of prompts and suggests a formatting issue. However, they do not provide specific details about which tables are disorganized or how the sentences are squeezed, making it difficult for the author to act upon the feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that the figures are 'not clear' and provides a specific example of confusion with the relation of subfigures in Figure 2. This indicates an explicit action that needs to be addressed. While the reviewer doesn't provide specific actions on how to make the figures clear, the explicit identification of the problem makes it actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'figure 2' and points out specific issues within that figure, such as the confusion between subfigures and the missing labels 'CMAF, L_BT, VoLTA'. This strong mention of a specific part of the paper and the detailed description of the issues demonstrates high grounding specificity. The reviewer not only identifies the area being criticized but also clearly specifies what is wrong within that area.", "verifiability_rationale": "The reviewer states that the 'figures are not clear' and points to the confusion between subfigures in Figure 2 and the missing labels. While the reviewer identifies a problem, they do not provide any logical reasoning, external references, or examples to support their claim. The comment is primarily a statement of a problem without any justification or guidance on how to address it. The reviewer identifies the *what* (figures are unclear) but lacks the *why* or *how* to make it clear.", "helpfulness_rationale": "The reviewer states that the figures are 'not clear' and provides a specific example of confusion in Figure 2. While the reviewer identifies a weakness, they do not offer any suggestions for improvement or further clarification. The comment is essentially a diagnosis without a remedy. The reviewer points out the *what* but doesn't provide any actionable steps for the authors to take."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the effect of a specific action (L_pixel) on the method's performance. This is an explicit request for the consequences of an action. While the request is for a general understanding of *why* the method works, it is still a direct inquiry about the impact of a specific action. Therefore, it can be considered explicit in identifying the area of concern and the action being questioned. However, it lacks concrete details on how this action contributes to the observed effects, making it somewhat vague in its specifics.", "grounding_specificity_rationale": "The reviewer explicitly names the 'L_pixel' component, indicating a strong grounding in identifying the specific part of the paper being discussed. However, the reviewer does not specify *what* makes this component work or why it is effective. The request is about the *component* itself, not a specific detail within it. Therefore, it can be considered '3' as the part is identified, but the specifics of its function are not detailed.", "verifiability_rationale": "The reviewer states a claim that the method works (based on observed effects) but does not provide any evidence or reasoning to support this claim. They ask 'why does the method work?' regarding the L_pixel component, but do not explain the underlying mechanisms or provide references. Therefore, the claim is 1 as it lacks supporting evidence or justification.", "helpfulness_rationale": "The reviewer's request for an explanation of why the method works, particularly concerning the L_pixel component, is directly helpful for the authors. It targets a specific area of concern and seeks to understand the underlying reasons for observed effects. While it doesn't provide a direct solution, it is a valuable piece of feedback that can guide further analysis and potentially lead to improvements. Therefore, it is '3' as it provides a direction for further investigation but lacks immediate actionable steps."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their concern about the sufficiency of the training data and provides a reason (44k dialogues vs. trillions of tokens and the need to cover personality/topic combinations). This is an explicit statement of a problem. The reviewer clearly states *what* is insufficient (training data size, diversity of user traits and personalities, topics) and *why* (it's insufficient compared to LLM training data scale). This is concrete.", "grounding_specificity_rationale": "The reviewer *mentions* training data size and the specific numbers (44k dialogues, trillions of tokens). While they don't explicitly name a *section* or *table*, the context strongly implies they are referring to the training data used for the model. This is weak grounding. The reviewer explains *why* they think they might be insufficient, linking it to the need to capture a wide range of user traits, personalities, and topics. This is relatively specific, but it's still a general area rather than a specific section/table/cell.", "verifiability_rationale": "The reviewer makes a clear statement: \"I'm unsure if 44k dialogues is sufficient...\" This is a claim that something is unclear or potentially insufficient. The reviewer *states their uncertainty* but doesn't provide concrete evidence or justification for this concern. They don't cite any specific data or studies to support their claim about the insufficiency of 44k dialogues. They also don't explain *how* this lack of data might affect the model's performance.", "helpfulness_rationale": "The reviewer's point is relevant to the authors. They are highlighting a potential limitation of the training data that could impact the model's ability to generalize across different user types and topics. This is a constructive feedback point. While the reviewer doesn't pinpoint a *specific* section of the paper, they are pointing to a general issue related to the training data. The advice they offer (considering a larger and more diverse dataset) is actionable."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The binary classification label, while indicating whether an answer is correct or not, does not provide any guidance on *how* the answer is incorrect. This means the reviewer cannot identify specific areas for improvement, such as correcting a flawed technique or addressing a conceptual misunderstanding. Without actionable feedback, the review point is not particularly helpful in guiding the author towards a better solution. The lack of explicit or implicit actionability limits the ability of the reviewer to provide targeted suggestions.", "grounding_specificity_rationale": "The comment is 1 at all. It does not identify a specific aspect of the paper being addressed. The comment is highly unspecific.", "verifiability_rationale": "The claim that the binary classification is a 'justifiable baseline metric' is not 5. While the metric provides a clear judgment (correct/incorrect), the lack of justification for its use and the difficulty in explaining *why* certain answers are considered incorrect (especially regarding finegrained errors) weakens the verifiability. The claim lacks sufficient supporting evidence or justification.", "helpfulness_rationale": "The review point is 1. The comment identifies a weakness in the evaluation metric (binary classification) but fails to provide any actionable feedback or justification for why this weakness is significant. The comment is vague and does not offer any insights into how the metric could be improved or what specific issues it might be overlooking. Without a clear connection to the authors' work, the review point is not particularly useful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment 'The writing should be improved. Some points in the paper is unclear to me.' does not specify which parts of the paper need improvement or what specific changes are required. It is a general statement about the need for writing improvement and mentions that some points are unclear, but it does not identify which points or suggest concrete actions to take. Therefore, it is 1 as it does not tell the author what to do and how to do it.", "grounding_specificity_rationale": "The comment 'The writing should be improved. Some points in the paper is unclear to me.' does not identify a specific part of the paper or a specific element within the paper that is unclear. It refers to 'some points' generally without pinpointing their location or nature. Therefore, it is 1 as it does not identify the specific part of the paper being addressed.", "verifiability_rationale": "The comment 'The writing should be improved. Some points in the paper is unclear to me.' does not contain a claim that can be verified. It is a statement of need and observation, not a claim that requires justification or evidence. Therefore, it has X and is marked as 'X'.", "helpfulness_rationale": "The comment 'The writing should be improved. Some points in the paper is unclear to me.' is not helpful because it is vague and lacks specific guidance. It tells the author that improvement is needed and that some points are unclear, but it does not specify *which* points or *how* to improve the writing. This general feedback is not actionable and does not empower the author to make specific changes. Therefore, it is 1."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The suggestion to 'use other metrics' is an explicit instruction, indicating an action the authors should take. However, it lacks specific details on which metrics to use or how to implement them, making it vague.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. It is a general suggestion about evaluation metrics, making the grounding weak. Furthermore, it does not specify *which* other metrics to use, keeping the specificity low.", "verifiability_rationale": "The review point is a suggestion, not a claim or assertion. It does not make any logical reasoning, references, or external evidence to support its suggestion.", "helpfulness_rationale": "The suggestion to use other metrics for evaluating results is a helpful suggestion that could guide the authors in potentially improving their evaluation process. While it doesn't provide a specific metric, it points towards a relevant area for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests 'there has been a large amount of work on LLM evaluation' and recommends comparing 'SynTextBench metric' to 'other metrics proposed in the literature'. While the reviewer identifies a relevant area of research and suggests a comparison, the specific aspects of LLM evaluation and the conditions for comparison are not explicitly stated. The action of suggesting a comparison is implicit, making it somewhat indirect.", "grounding_specificity_rationale": "The reviewer mentions 'LLM evaluation' and points to a specific paper 2. This indicates a level of grounding as the reviewer refers to a specific work. However, the reviewer does not explicitly state which section, table, or figure of the paper they are referring to, nor does they specify which aspect of LLM evaluation they are focusing on. Therefore, while the topic is grounded, the specific element being addressed is not clearly identified.", "verifiability_rationale": "The reviewer states that 'there has been a large amount of work on LLM evaluation' and 'it would still be good to see how SynTextBench metric compares to the other metrics proposed in the literature'. This constitutes a claim that requires verification. The reviewer mentions a specific paper 2 and a comparison with MMLU and Big Bench, which provides some justification. However, the conditions under which SynTextBench is better are not explicitly defined or justified.", "helpfulness_rationale": "The reviewer points out the 'large amount of work on LLM evaluation' and suggests comparing 'SynTextBench metric' to 'other metrics proposed in the literature'. This highlights a relevant area for discussion and provides a suggestion for improvement. However, the lack of specificity regarding the comparison limits its helpfulness for the authors. Without knowing which aspects of LLM evaluation or which specific metrics are being compared, the reviewer's point is somewhat vague and lacks concrete guidance."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "X (X)", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a potential issue ('poor writing and annotations') but does not explicitly state what needs to be done to address it. It implies the writing and annotations are unclear, but lacks a direct action for the author.", "grounding_specificity_rationale": "The comment refers to the paper generally ('paper') and mentions issues with writing and annotations, but does not specify which section, table, figure, or unique element is affected. The reviewer implies the writing and annotations are unclear, but does not provide specific examples or locations.", "verifiability_rationale": "The comment is a statement of observation ('Poor writing and annotations are a little hard to follow') rather than a claim that requires verification. It does not present a suggestion or recommendation, nor does it make a judgment that needs to be supported by evidence.", "helpfulness_rationale": "The comment identifies a potential problem (poor writing/annotations) but does not offer a solution or specific steps to address it. It is a diagnosis without a cure, lacking actionable guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point is implicitly actionable. While it points out issues, it doesn't explicitly state the exact steps the authors should take to address the identified problems. The reviewer suggests the authors doublecheck their evaluation process and investigate the discrepancy in F1 scores. This implies the authors need to take some action to improve their work, but the specific action is not laid out in the review itself.", "grounding_specificity_rationale": "The reviewer provides strong grounding by specifying the table (Table 2) and the evaluation setting ('Twitter2017 $\rightarrow$ Twitter2015'). They also mention specific metrics ('8 out of 14 evaluation metrics achieve SOTA performances') and the discrepancy in F1 scores ('why the proposed method achieves best overall F1, while not achieves best F1 in all single types?'). This demonstrates a clear understanding of the specific part of the paper being discussed.", "verifiability_rationale": "The reviewer makes a claim about the results presented in Table 2, stating that only 8 out of 14 evaluation metrics achieve SOTA performances. However, the review point itself does not provide any evidence or reasoning to support this claim. The reviewer is stating an observation based on their understanding of the results, but the verifiability relies on external information (the content of Table 2). Therefore, while the claim is stated, the evidence for it is not contained within this review point alone.", "helpfulness_rationale": "The review point is 5. It directly points out a factual deficiency in the authors' reported results (only 8/14 SOTA, discrepancy in F1). It provides specific information about the table, evaluation setting, and metrics involved. This allows the authors to immediately identify an area needing investigation and take concrete steps to improve their methodology or experimental setup. The questions posed by the reviewer also encourage the authors to think critically about their evaluation process."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the weakness: 'The paper doesn't thoroughly explore the upper limits of FedDES's scalability'. It also mentions specific aspects that are lacking, such as 'memory requirements' and 'computational complexity'. This indicates a direct identification of the issue, making it explicit. The comment also provides concrete examples of what is missing, making it concrete.", "grounding_specificity_rationale": "The comment explicitly mentions 'scalability bounds', 'memory requirements', and 'computational complexity'. It identifies these as specific aspects of the paper that lack discussion. The authors can easily identify the specific part of the paper being addressed, and the issue within that part is clearly specified.", "verifiability_rationale": "The comment identifies a weakness ('limited discussion') but does not provide any justification or reasoning for why this is a problem or how it should be addressed. It does not mention external references or logical reasoning to support the claim. The statement requires justification to be accepted or understood.", "helpfulness_rationale": "The comment points out a specific area for improvement ('limited discussion of scalability bounds') but does not provide any concrete suggestions or actions for the authors to take. While it identifies a potential weakness, it doesn't directly guide the authors on how to address it. It is more of a pointer to a problem than a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a potential ambiguity in the description of the Unsupervised Online Adaptation setting. While the reviewer's interpretation of 'unsupervised' might be based on the presence of labels, the core argument is that the description could be clearer about whether the 'supervision' comes from labels or some other form of guidance. The reviewer's suggestion to clarify this is a constructive action, even if the criticism itself isn't entirely clear. The reviewer identifies a potential point of confusion for the authors.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper it is addressing. The reviewer is criticizing the *description* of the setting rather than pointing to a specific section, table, or figure within the paper. Therefore, the grounding specificity is low as the authors cannot pinpoint the exact area being discussed.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a critique of the *setting* of the adaptation process. Therefore, according to the provided definitions, this review point does not fall under the category of containing a claim that needs to be supported by evidence. The score 'X' indicates that the comment contains only factual, descriptive statements without claims, opinions, or suggestions.", "helpfulness_rationale": "The review point raises a valid concern about the clarity of the Unsupervised Online Adaptation setting. While this concern could be helpful for the authors to understand the requirements of their adaptation process better, it does not directly provide specific, actionable feedback on how to improve their draft. It's a question about clarification rather than a direct suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests 'involving some other baselines' which is an explicit action. However, it lacks specific details on *how* to involve these baselines or *what specific baselines* should be included. The action is stated, but the implementation details are missing, making it somewhat vague.", "grounding_specificity_rationale": "The review point is a general suggestion about improving the performance of SGMs by involving more baselines. It does not explicitly identify a specific part of the paper (e.g., a section, table, or figure) that needs improvement. The suggestion is broad and doesn't target a particular element of the work.", "verifiability_rationale": "The review point makes a claim that 'It is better for authors to display the performance of accelerating SGMs by involving some other baselines'. This claim is somewhat supported by the provided references, which suggest specific ways to improve SGM performance by optimizing discretization schedules or modifying formulations. However, the *reason* for the superiority of this approach is not explicitly detailed beyond the references. The claim is supported by some evidence, but the logical reasoning could be stronger.", "helpfulness_rationale": "The review point suggests 'involving some baselines' as a way to improve SGM performance. While the suggestion is relevant and addresses a potential limitation (limited baselines), it lacks specific details on *which baselines* to include or *how* to implement the suggested optimizations. The suggestion is general and lacks concrete steps, making it less helpful in directly guiding the author's work. The reviewer provides a list of relevant papers, but doesn't explain how these papers directly address the performance issue in the context of the specific SGM being evaluated."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks 'how to explain that the data distribution illustrated in Figure 1 is inseparable from the network model?'. This is an explicit request for an explanation. However, the action is somewhat vague as it doesn't directly tell the authors what to do with this information. They need to infer how to use this explanation for their own work.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 1' and asks about the 'data distribution' within that figure. This clearly identifies the specific part of the paper being addressed, making the grounding fully grounded. The question is also specific about the relationship between the data distribution and the network model's nonlinearity in the context of a nonseparable case.", "verifiability_rationale": "The reviewer is not making a claim or assertion. They are asking a question seeking an explanation. Therefore, there is X to verify.", "helpfulness_rationale": "The reviewer is asking for an explanation of a relationship between the data distribution, the model, and the nonseparable case. While this information could be valuable for the authors to understand the limitations of their experiment, it doesn't directly provide them with a concrete action to improve their draft. The request is for clarification, not a direct actionable improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what should be changed or improved in the presentation of the results. It criticizes the 'convoluted way' and the 'disregard' of safety violations, but does not identify a specific action or detail how the presentation should be altered.", "grounding_specificity_rationale": "The reviewer states that the results disregard the safety violations of the agent in the first 1000 episodes. This can be considered **2: 3**, as the reviewer accurately identifies the specific aspect (safety violations in the first 1000 episodes) but does not explicitly state why the results disregard this aspect or how it should be addressed.", "verifiability_rationale": "The reviewer criticizes the presentation of the results but does not provide any evidence or justification for why the presentation is unclear or convoluted. The statement 'The reason for presenting the results in this way is unclear' directly supports this assessment.", "helpfulness_rationale": "The review point identifies a weakness in the presentation of the results (convoluted way, disregard of safety violations) but does not offer any actionable suggestions or clarify the motivation behind the current presentation. The reviewer's statement that the reason for the presentation is unclear further diminishes the helpfulness of the comment."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for a definition of a specific term (\tau_i^l) within the paper. This is a direct and explicit request for action, as the authors need to understand this term to grasp the timewarp function.", "grounding_specificity_rationale": "The reviewer explicitly asks for the definition of a specific term (\tau_i^l) within the paper. This indicates that the authors can identify the specific part of the paper where the definition is needed, thus demonstrating strong grounding specificity.", "verifiability_rationale": "The reviewer is not making a claim or assertion. They are simply stating a request for information. While the reviewer implicitly expects the information to be useful for understanding the timewarp function, the request itself does not contain a claim that can be verified.", "helpfulness_rationale": "The reviewer's request is clear, direct, and directly addresses a likely point of confusion for the authors regarding the timewarp function. Providing this definition is likely to be beneficial for the authors' understanding and potentially improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the issue with the standard sigmoid and its relevance to URNNs, making it actionable. It points out that the maximum slope is a crucial difference and suggests the standard sigmoid might not be optimal. However, it doesn't provide concrete steps on how to implement this change or how the maximum slope affects the URNN's behavior.", "grounding_specificity_rationale": "The comment explicitly mentions 'standard sigmoid,' 'URNN,' and 'maximum slope,' directly referencing specific parts of the paper. It also refers to 'Theorem 4.1' and its relevance to RNNs and URNNs, indicating strong grounding specificity.", "verifiability_rationale": "The comment identifies a specific technical detail (maximum slope of the sigmoid) and connects it to a relevant concept in RNNs (URNNs and Theorem 4.1). It provides a potential explanation based on the convergence behavior of RNNs, which is verifiable. The claim is supported by logical reasoning and common knowledge within the field.", "helpfulness_rationale": "The review point is 5. It identifies a specific technical detail (maximum slope of the sigmoid) that is relevant to understanding and potentially improving URNNs. It suggests that the standard sigmoid might not be optimal due to this maximum slope, which is a valuable insight. The suggestion to elaborate on Theorem 4.1 with an intuitive explanation is also a helpful contribution, making complex concepts more accessible to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a weakness ('The efficiency of such pairwise matching is very low') but does not specify how to improve it or what aspects of the matching process are inefficient. It suggests making it 'difficult to be used in practical application systems,' which is a general statement rather than a concrete action.", "grounding_specificity_rationale": "The comment refers to 'pairwise matching' generally and does not specify which particular pairwise matching algorithm or system is being criticized. It lacks a precise identification of the part of the paper being addressed.", "verifiability_rationale": "The comment contains a claim ('The efficiency of such pairwise matching is very low') but does not provide any evidence, reasoning, or references to support this statement. It lacks logical justification or external references to back up the claim.", "helpfulness_rationale": "The comment identifies a clear weakness ('The efficiency of such pairwise matching is very low') and suggests a direction for improvement ('making it difficult to be used in practical application systems'). This indicates that the comment has the potential to be helpful, as it points towards actionable steps, although it lacks specific details on how to achieve this."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment suggests an improvement ('edits the main paper space more wisely') but does not explicitly state what needs to be done. While the suggestion is present, the lack of specific steps makes it difficult to act directly on. The reviewer implies a concrete action but doesn't provide the details.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1' as the part being addressed, indicating a clear identification of the specific element in the paper. The reviewer uses a specific term ('Figure 1') to refer to a particular element.", "verifiability_rationale": "The comment contains a claim (' allocation of Figure 1 is too naive') which is a judgment or opinion about the figure's allocation. However, the suggestion ('edits the main paper space more wisely') lacks specific evidence or references to support it. The criticism is subjective and lacks concrete backing.", "helpfulness_rationale": "The review points out a specific issue (' allocation of Figure 1') and suggests an improvement ('edits the main paper space more wisely'). While the direction for improvement is clear, the lack of specific details on how to achieve this makes the feedback somewhat vague and less directly actionable for the authors. The criticism is specific to a particular element, but the improvement suggestion is general."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the action of rewriting the first sentence of the abstract. However, it lacks specificity regarding the content of the sentence or the desired outcome of the rewrite.", "grounding_specificity_rationale": "The comment explicitly mentions 'the first sentence of the abstract,' which is a specific and identifiable part of the paper. However, it does not specify what is wrong with that sentence.", "verifiability_rationale": "The comment does not contain a claim. It is a directive, not a statement requiring verification.", "helpfulness_rationale": "The comment identifies a weakness (the first sentence of the abstract needs improvement) and provides a direction for improvement (rewrite it). While it lacks specifics, it does tell the author what to do."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a discrepancy between the current practice of using a single heldout test set and the standard practice in Gaussian Process (GP) literature, which involves using multiple train/test splits or folds. This directly identifies a potential issue and suggests a solution, making it actionable.", "grounding_specificity_rationale": "The reviewer's comment is 1 in a specific part of the paper, table, figure, or unique aspect. They are making a general statement about the experimental reporting practice across the entire work, rather than pinpointing a specific section or element within a method or result.", "verifiability_rationale": "The reviewer's claim that 'Standard practice in most papers on GPs involves using a number of train/test splits or folds which give a more accurate illustration of the method\u00e2\u0080\u0099s performance' is verifiable. This claim is supported by the general understanding and common practice within the field of Gaussian Processes, referencing the benefits of multiple splits for robust evaluation.", "helpfulness_rationale": "The reviewer's point, while not directly addressing a specific weakness in the authors' draft, offers a constructive suggestion to improve the experimental methodology by adopting a more standard practice in the field. This suggests a potential improvement and encourages the authors to consider a more rigorous evaluation approach, making it 3 in guiding the authors towards better experimental design."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points out a potential inefficiency in the method but doesn't directly suggest *how* to make it simpler or identify a specific principle. It's a general observation about the method's complexity.", "grounding_specificity_rationale": "The comment refers to the 'method' in general, not a specific section, table, figure, or unique aspect of the paper. The reviewer is making a general comment about the overall method, not a specific issue within a defined part of the paper.", "verifiability_rationale": "The review points out a potential inefficiency and a suspicion about a simpler principle, which can be considered a claim. However, the reviewer doesn't provide any evidence or reasoning to support their suspicion. They express a belief but don't show why it's likely true or offer any data.", "helpfulness_rationale": "The review offers a relevant observation about the method's complexity, which could indirectly guide authors to look for simpler methods or underlying principles. However, it doesn't *directly* tell them *how* to do that. The suggestion is more of a prompt for further investigation rather than a direct, actionable improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states 'Adding a method on the top of other methods to improve transferability'. This indicates an explicit action. However, the reviewer does not specify how this method should be added or what method should be used, making it less concrete. Therefore, while an explicit action is taken, the lack of detail makes it 3 but not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions 'adding a method' but does not specify which method or where it should be added. They imply it's 'on the top of other methods,' suggesting it's related to the existing methods described in the paper. This lack of specificity means the reviewer cannot confidently identify the referenced part of the paper, making the grounding weak. Furthermore, the reviewer does not detail what the method would be or how it would improve transferability, making the specificity very low. Therefore, the grounding is weak and the specificity is underspecific.", "verifiability_rationale": "The reviewer states 'Adding a method on the top of other methods to improve transferability is good but cannot be considered a significant contribution.' This statement is a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a judgment without any backing. Therefore, the claim is 1.", "helpfulness_rationale": "The reviewer's comment is about the *value* of a potential method addition, not about providing specific, actionable feedback on how to improve the draft. They are stating that this addition is not a significant contribution. While they identify a potential area for improvement, their assessment of its significance is not helpful for the authors in terms of guiding their work. Therefore, the review point is not helpful in terms of providing actionable feedback to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly identifies a gap in the paper by pointing out the lack of clarity regarding the challenges of applying Adam under (L0, L1)smoothness. They state, 'It is not clear what are the challenges when the authors analyze Adam under the (L0,L1)smoothness condition.' This indicates a direct action the authors should take \u2013 to explain the challenges and differences from standard analysis, especially in relation to Zhang et al.'s work. The reviewer is not inferring this need, but rather pointing it out as a missing element.", "grounding_specificity_rationale": "The reviewer provides specific details about the area needing clarification: 'It is not clear what are the challenges when the authors analyze Adam under the (L0,L1)smoothness condition.' They also mention a specific paper for comparison: 'So it is better to explain the challenges, especially the difference between this one and Zhang et al.' This strong emphasis on a specific aspect and a comparison to another work demonstrates high grounding specificity. The authors can easily identify the relevant section (the analysis of Adam under (L0,L1)smoothness) and understand the specific issue (the difference from Zhang et al.).", "verifiability_rationale": "The reviewer makes a claim about the standard analysis of Adam under (L0,L1)smoothness: 'It is not clear what are the challenges when the authors analyze Adam under the (L0,L1)smoothness condition. It seems one can directly apply standard analysis on the (L0,L1)smoothness condition.' This claim is verifiable. The standard analysis might indeed be straightforward, and the reviewer is suggesting that the paper needs to explain the nuances and differences, particularly with respect to Zhang et al.'s work. The lack of explicit explanation in the original paper supports this claim.", "helpfulness_rationale": "The reviewer suggests that explaining the challenges and differences would be beneficial for the authors: 'It is better to explain the challenges, especially the difference between this one and Zhang et al.' This is a clear and helpful suggestion. By explaining the challenges, the authors can gain a deeper understanding of the (L0,L1)smoothness analysis and potentially improve their own work. The reviewer is not suggesting a new contribution, but rather pointing out a missing explanation that would be valuable for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point describes the current landscape of person reidentification methods, specifically mentioning two broad categories: those built on pedestrian detectors and endtoend methods. While it provides context, it doesn't explicitly state what the authors *should do* or *how* they should improve their draft based on this information. The reviewer highlights the twostep method and the endtoend method, which are general classifications.", "grounding_specificity_rationale": "The review point provides a general overview of person reidentification methods and their two main categories. It does not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The reviewer mentions 'twostep method' and 'endtoend method' as broad categories, not as specific references within the paper.", "verifiability_rationale": "The review point presents factual information about the current approaches in person reidentification. It states that 'most person reID methods build on the basis of pedestrian detector (twostep method)' and 'there are also endtoend method that combines detection and reID'. This is a factual statement and doesn't contain a claim that requires verification. The reviewer is simply stating what is already known about the field.", "helpfulness_rationale": "The review point provides a general overview of the field of person reidentification and highlights the two main categories of methods. This information could be helpful for an author trying to understand the current state of the field and potentially position their work within it. While it doesn't directly suggest specific improvements, it offers context that can be useful. The reviewer's statement is informative but doesn't actively guide the author towards an improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the missing citations to recent MARL work. While it doesn't directly tell the authors *how* to find these papers, it clearly identifies the *area* where these citations are needed (selfplay and populationplay with respect to exploration and coordination). This makes the action somewhat explicit and concrete.", "grounding_specificity_rationale": "The review point explicitly mentions the *area* of the paper where the missing citations are relevant (MARL work, exploration, and coordination). It also specifies the *subfields* of MARL (selfplay and populationplay). This allows the authors to confidently identify the specific part of their work that needs improvement.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It simply states a fact: the absence of specific citations. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The review point is helpful because it points the authors in the direction of relevant recent research in MARL. By highlighting the importance of selfplay and populationplay for exploration and coordination, it suggests that incorporating or referencing these areas could significantly improve their work. While it doesn't explicitly tell them *which* papers to cite, it provides a valuable context and potential solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a comparison with other selfsupervised learning (SSL) methods that are not based on contrastive learning. While this is an implicit suggestion for improvement, it doesn't explicitly state what needs to be done. The action is implied rather than directly stated.", "grounding_specificity_rationale": "The review point explicitly mentions 'other selfsupervised learning methods that are not based on contrastive learning.' This clearly identifies the specific area of comparison, allowing the authors to ground the suggestion in a specific aspect of the literature. The section, table, figure, or unique aspect being addressed is welldefined.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It's a suggestion for further research or experimentation. However, if the authors were to act on this suggestion, they would need to verify the existence and effectiveness of other SSL methods. The potential for verifiability exists if the action is taken, but the review point itself doesn't provide verifiable information.", "helpfulness_rationale": "The review point suggests comparing with other selfsupervised learning methods that are not based on contrastive learning. This is a relevant and actionable suggestion that could help the authors understand the broader context of their work and potentially identify relevant baselines for comparison. It provides a direction for further investigation and could lead to improvements in their method. While it doesn't provide a complete solution, it is a valuable piece of advice that guides the authors towards further research."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question, which can be considered an explicit request for clarification. They are directly pointing out a lack of clarity in the current explanation. While the request itself isn't very concrete, the *explanation* of the process would be more concrete. The reviewer is asking about a specific process (abstention) and its relation to a specific term (prediction probability threshold). This suggests the reviewer can identify the relevant part of the paper being addressed, making the grounding somewhat explicit. However, the reviewer is asking for a clarification of the *difference* from a 'decision threshold', which is a point of clarification and might not be immediately obvious to all readers, making it 3 rather than 5. The information needed to answer this question is present in the model's documentation or implementation, but the reviewer is asking for a clarification of the *difference*. The request is about a specific process and its relation to a specific term, indicating grounding. The request seeks clarification on a relationship, suggesting a lack of immediate understanding, hence 3. The request itself isn't very concrete, but the *explanation* of the process would be more concrete. The reviewer is asking about a specific process (abstention) and its relation to a specific term (prediction probability threshold). This suggests the reviewer can identify the relevant part of the paper being addressed, making the grounding somewhat explicit. However, the reviewer is asking for a clarification of the *difference* from a 'decision threshold', which is a point of clarification and might not be immediately obvious to all readers, making it 3 rather than 5.", "grounding_specificity_rationale": "The reviewer is asking about a specific process ('abstention process') and its relation to specific technical terms ('prediction probability thresholds'). This directly references these terms, indicating a good understanding of where to look for the information. The reviewer is asking about the *difference* between this threshold and a 'decision threshold', which is a specific question about the relationship between two related but distinct concepts. The information needed to answer this is present in the model's documentation or implementation, but the reviewer is asking for a clarification of the *difference*. Therefore, it is grounded and specific.", "verifiability_rationale": "The reviewer is making a statement about the abstention process and its relation to a 'decision threshold'. This can be considered a claim that a specific process exists and has a particular relationship to another concept. The existence of the threshold is verifiable. The relationship to a 'decision threshold' is a matter of interpretation and terminology. However, the * existence* of the threshold is clear. The *difference* from a 'decision threshold' is a point of clarification, but the * existence* is verifiable. The reviewer is making a claim about the existence and relationship of two concepts. The existence of the prediction probability threshold is verifiable. The claim about the difference from a 'decision threshold' is a point of clarification and might not be immediately obvious to all readers, making it 3 rather than 5.", "helpfulness_rationale": "The reviewer is asking a question to clarify a process. While it doesn't directly point out a weakness in the current draft, it is valuable information for the authors (or the model developers) to understand how the abstention process works. It helps them understand the model's behavior. The information is relevant to understanding the model's behavior and could be useful for the authors in interpreting model outputs. However, it's not a direct critique or suggestion for improvement of the draft itself."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests exploring 'specific combination methods' and cites examples like R1, R2, and R3. While the reviewer doesn't explicitly state 'I should implement X and Y,' the suggestion to explore these methods implies a concrete action. The reviewer also points out that 'limited exploration of combination methods' is a problem, which provides a clear direction for improvement. The suggestions are relatively specific, indicating a level of actionable insight.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'continuous learning with unlabeled data,' 'accumulates noise,' 'detrimental to representation quality,' 'limited exploration of combination methods,' 'rehearsalfree continual learning,' 'featurereplay methods,' and cites specific examples (R1, R2, R3). This demonstrates strong grounding as the relevant parts of the paper are clearly identified and the issues are wellspecified within those identified sections.", "verifiability_rationale": "The reviewer makes a claim that 'the paper contends that *We believe that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.*' The reviewer then provides reasoning and examples of potential solutions (R1, R2, R3) to support this claim. While not providing direct citations, the reviewer logically connects the identified problem to potential solutions, making the claim 3.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as 'exploring specific combination methods,' 'focusing on featurereplay methods,' and 'citing recent works like R1 in continual learning and R2 (FRoST) in CCD.' These suggestions are concrete and directly address the identified weakness. The reviewer also points out the lack of exploration of combination methods, which is a clear area for the authors to focus. The suggestions are relatively easy to understand and implement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point asks specific questions about the pretraining data and generalization without labels, which are implicit actions. However, it doesn't explicitly state the pretraining data or the method of generalization, making it somewhat vague and lacking detail on how to apply the inferred action.", "grounding_specificity_rationale": "The reviewer asks general questions about pretraining and generalization without specifying which part of the paper or method they are referring to. The questions are broad and don't identify a specific section, table, figure, or unique aspect of the paper. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer poses questions about the pretraining data and generalization without labels. These are suggestions or requests for changes, not claims that require verification. Therefore, it doesn't contain a claim that needs to be supported by evidence, making it 1.", "helpfulness_rationale": "The review point asks specific questions about the pretraining data and generalization without labels. While these questions are relevant to understanding the model's limitations and potential applicability, they are not directly addressing the authors' specific needs for improving their draft. The questions are more about inquiry than providing concrete solutions. Therefore, it is 3 in identifying potential limitations but lacks direct actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's comment does not explicitly state any action or suggestion for the authors. They are posing a question about the significance of a small difference in results, but not providing a concrete step on how to address it. The comment is primarily a query for clarification rather than a directive. Therefore, the actionability is low.", "grounding_specificity_rationale": "The reviewer is asking a question about the interpretation of results in an ablation study. They are not explicitly pointing to a specific section, table, or figure in the paper that they are referring to. While the *content* of their question is related to the ablation study in Table X, they are not naming or identifying that specific part of the paper. Therefore, the grounding specificity is weak.", "verifiability_rationale": "The reviewer is making a judgment about the significance of the results in the ablation study. They are asking whether the difference is due to noise or if the ground truth is sufficiently accurate. While they are making a claim, they are not providing any logical reasoning, common knowledge, or external references to support their assertion. The reasoning is purely based on their interpretation and lack of further information. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer is pointing out a potential area for improvement in the paper \u2013 the interpretation of results in the ablation study. They are asking for clarification on whether the small difference is meaningful. While they are not offering a solution, they are highlighting a potential weakness in the analysis and encouraging the authors to consider the significance of their findings. Therefore, the helpfulness is medium as it identifies a potential issue for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'No new evaluation metrics are proposed. Only existing evaluation metrics are proposed.' This is a clear and direct statement of what the reviewer is suggesting. The action is to not propose new metrics, and the scope is clearly defined as 'evaluation metrics'. This makes the comment 5 as the authors know exactly what needs to be addressed and what action to take.", "grounding_specificity_rationale": "The comment refers to 'evaluation metrics' in general. While it mentions 'new' and 'existing,' it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper where this concern arises. The reference is somewhat general. The comment identifies a potential issue ('need for indepth exploration') related to the application of existing metrics, but it doesn't specify *which* experimental results or *how* the exploration should be indepth. Therefore, while the general area is identified, the specific element and details are lacking, making it somewhat grounded but not fully specific.", "verifiability_rationale": "The comment contains a claim: 'No new evaluation metrics are proposed. Only existing evaluation metrics are proposed.' This is a statement of intent or a suggestion. However, the comment does not provide any justification or reasoning for why only existing metrics should be used or why new ones aren't proposed. There are no logical reasoning, common knowledge, or external references provided to support this claim. Therefore, the claim is 1 as it lacks supporting evidence or justification.", "helpfulness_rationale": "The comment raises a valid point about the limitations of relying solely on existing metrics and suggests a potential improvement by exploring new ones. However, the comment is more of a statement of a problem and a direction for improvement rather than a concrete solution. It doesn't offer specific guidance on how to conduct the 'indepth exploration' or what specific aspects of the experimental results need to be analyzed in more detail. While the point is valuable, it lacks the specific action and detail needed to be 5 for the authors. Therefore, it is 3 as it identifies a relevant area for improvement, but it lacks the depth and specificity to be fully impactful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the action of combining the two bullets and provides the location (at the end of the introduction). This makes the action very clear and direct.", "grounding_specificity_rationale": "The comment explicitly mentions the 'first two bullets about contributions (at the end of the intro)'. This provides a precise location within the paper, making the grounding very strong.", "verifiability_rationale": "The comment is a suggestion, not a claim requiring evidence. Therefore, it does not have verifiability as it doesn't make a statement that needs to be supported by reasoning, common knowledge, or external references.", "helpfulness_rationale": "The suggestion to combine the two bullets is a constructive and actionable comment that directly addresses a potential organizational issue. It is helpful for the author as it simplifies the introduction and improves readability."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a weakness ('The types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper') but does not explicitly recommend a specific action to address this weakness. While it points to an issue, the lack of a concrete step makes it less actionable than a review that suggests a particular improvement. The reviewer states the problem but doesn't provide a direct solution or guidance on how to make the information clearer.", "grounding_specificity_rationale": "The review point refers to 'the main paper' generally, without specifying a particular section, table, figure, or unique element. While the reviewer identifies a category of issues ('types of situations/social norms'), they do not pinpoint the exact part of the paper or the specific norm that is unclear. The grounding is present in identifying the paper as a whole, but it lacks the precision needed to directly identify the problematic element.", "verifiability_rationale": "The review point states a fact ('The types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper') but does not present a claim or suggestion that requires verification. It is a statement of observation rather than a proposition that needs evidence. Therefore, it does not fit the criteria for verifiability, which involves supporting a claim with logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point identifies a valid weakness in the paper ('The types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper'). This information could be helpful for the authors to understand areas where their writing or explanations could be improved. However, the point does not offer a concrete suggestion or action to address this weakness, making it less immediately helpful than a review that provides specific recommendations. It points to a problem but doesn't offer a solution."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests referring to 'more recent trends in the vision community' to improve the paper. While this points towards a direction for improvement, it doesn't explicitly state what these trends are or how to incorporate them into the current work. The action of 'refer' is present, but the specific steps or changes are not detailed.", "grounding_specificity_rationale": "The reviewer mentions 'more recent trends in the vision community' as a general concept. While this hints at a potential area for improvement, it doesn't explicitly identify a specific section, table, figure, or unique aspect of the paper that needs addressing. The grounding is implied but not clearly stated.", "verifiability_rationale": "The reviewer states the importance of demonstrating improvement over existing vision solutions. This can be considered a claim. However, the reasoning behind this importance and how to demonstrate it is not explicitly provided within the review point itself. The claim is present, but the supporting evidence is lacking.", "helpfulness_rationale": "The reviewer provides a general direction for improvement by suggesting the paper should focus on demonstrating robustness against weak boundaries in the context of the vision community. While this is a relevant suggestion for the neuroscience community as well, the reviewer doesn't provide specific actionable steps or examples on how to achieve this. The feedback is somewhat general and lacks concrete implementation details."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states \"I expect more baselines\" and \"more domains\", which are direct actions or suggestions for the authors. However, the reviewer does not specify *how* these additional baselines or domains should be chosen or what specific improvements they would bring. The criticism regarding the weighting and density functions is also implied but not explicitly stated as a direct action to be taken. Therefore, while the reviewer points towards an area for improvement, the lack of specificity in the action makes it 3 but not fully concrete.", "grounding_specificity_rationale": "The reviewer mentions \"more baselines\" and \"more domains\" but does not specify *which* baselines or *in which specific domains* they are referring to. The criticism about the weighting and density functions is also general, not pointing to a specific gap or area of weakness. The reviewer's comment is a highlevel suggestion rather than a precise identification of a missing part or a specific issue within a part. Therefore, the reviewer's comment is 1 in a specific aspect of the paper.", "verifiability_rationale": "The reviewer makes a claim: \"As I mentioned, the choices of the weighting and the way of learning density functions are not strongly motivated.\" However, the reviewer does not provide any evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up this statement. Therefore, the claim is not verifiable based on the information provided.", "helpfulness_rationale": "The reviewer's comment is clear and identifies a potential weakness in the paper (lack of strong motivation for weighting and density functions). However, the comment lacks specific details about what the reviewer expects as improvements or how the suggested baselines and domains would address these weaknesses. The lack of verifiability further reduces the helpfulness of the comment, as the authors cannot assess the validity of the criticism or the potential solutions. Therefore, the helpfulness of the comment is low."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point criticizes the significance of the results but does not provide explicit or implicit actions for the authors to take. It highlights a problem but lacks concrete steps for improvement.", "grounding_specificity_rationale": "The review point does not identify which specific part of the paper or results are affected by the lack of significance. It is a general critique without pinpointing the problematic element.", "verifiability_rationale": "The review point makes a claim about the lack of significance but does not provide any evidence or justification for this claim. It is an opinion without supporting data or reasoning.", "helpfulness_rationale": "The review point criticizes the significance of the results but does not offer specific, actionable steps or insights for the authors to improve their work. It is a general critique without concrete guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the 'limited novelty' of the paper and describes it as a 'straightforward application' of existing literature, specifically DeCorr, to a new domain. While the paper adapts DeCorr to graph collaborative filtering, the reviewer clearly identifies this as the core contribution. The modifications, such as different penalty coefficients, are presented as incremental changes rather than novel insights. The reviewer's statement is direct and identifies the lack of new concepts or findings as the key issue. The implications are that the paper doesn't offer significant advancements beyond the existing work.", "grounding_specificity_rationale": "The reviewer makes general statements about the paper's limitations, such as 'limited novelty' and 'lack of unique insights about recommender systems.' While they touch upon specific areas like 'application' and 'overcorrelation in recommender systems,' they do not pinpoint a specific section or table in the paper that they believe is problematic. The reviewer's criticism is broad and applies to the overall contribution rather than a specific aspect of the methodology or results. The lack of a clear reference to a specific part of the paper makes the grounding weak.", "verifiability_rationale": "The reviewer makes a claim about the 'limited novelty' and the 'lack of unique insights about recommender systems.' This is a clear claim that requires verification. However, the reviewer does not provide any evidence or reasoning to support their claim. They state the limitations but do not explain why these limitations exist or how DeCorr doesn't address them in the context of recommender systems. There are no external references provided to back up their assertion. The claim is presented as a statement of opinion without any supporting arguments or evidence.", "helpfulness_rationale": "The reviewer's comment is primarily a critique, identifying a perceived weakness in the paper's novelty and contribution. While they point towards an area for improvement, they do not offer concrete, actionable suggestions for the authors. The comment is more of a diagnostic statement than a constructive suggestion. The lack of specific recommendations makes it difficult to rate it as 5. The reviewer's comment is more of a negative assessment of the paper's overall impact rather than a constructive critique with actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly raises a question about the choice of ELM and the timing of gender knowledge, which can be interpreted as an implicit suggestion that the authors consider the tradeoffs between accuracy and inference time. While it doesn't directly tell the authors *how* to choose, it points to a concrete decision they need to make. However, the suggestion is somewhat vague and doesn't provide concrete steps for the authors to take in making this decision.", "grounding_specificity_rationale": "The comment explicitly mentions the tradeoffs between accuracy and inference time, and it refers to the 'pipeline setting' where gender detection is likely used. This clearly identifies the specific aspect of the ELM selection process being discussed and the context in which the potential drawback arises. The comment is wellgrounded in the practical implications of using ELMs. The specificity is high as it directly relates to the accuracy of the ELM and the timing of gender knowledge.", "verifiability_rationale": "The comment itself does not contain a claim that requires verification. It is a question and a concern. However, the *answer* to the question about the need for gender knowledge at inference time can be found in the literature on ELMs and gender detection. The comment sets the stage for verifiable information by highlighting a potential area of confusion or concern that can be addressed with further research or clarification.", "helpfulness_rationale": "The comment is 5 because it directly addresses a practical concern in choosing an ELM \u2013 the tradeoff between accuracy and the need for gender knowledge at inference time. It prompts the authors to consider the implications of using a gender detection model in their pipeline and to evaluate the potential impact on accuracy. This is a valuable piece of feedback that guides the authors towards a more informed decision."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a problem ('difficult to follow') but does not specify how the authors should improve the writing. It lacks a clear action for the authors to take. The comment is a statement of a problem, not a direct instruction on how to solve it.", "grounding_specificity_rationale": "The comment is general and does not specify which part of the paper is difficult to follow. It does not identify a specific section, table, figure, or unique aspect of the paper. The authors cannot confidently determine the referenced part.", "verifiability_rationale": "The comment states an observation ('the writing is difficult to follow') but does not make a claim that requires verification. It does not present a suggestion, judgment, or deduction that needs supporting evidence. The comment is a statement of a problem, not a claim needing justification.", "helpfulness_rationale": "The comment identifies a valid issue (difficult to follow writing) but does not provide specific, actionable advice on how to improve it. It lacks a clear path for the authors to take based on this feedback. The comment is a symptom, not a solution with concrete steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out a lack of technical substance and simply adds a new loss. While the reviewer suggests adding a new loss, they don't specify how to implement this or what the implications would be. The action is stated, but the execution details are missing.", "grounding_specificity_rationale": "The reviewer mentions '31' but doesn't provide context or explain why this specific work is relevant. The authors cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part (adding a new loss).", "verifiability_rationale": "The reviewer states 'The paper is incremental and does not have much technical substance.' This is a statement of opinion or judgment about the paper's quality. It also implies that adding a new loss is a *problem* or *improvement*, requiring justification. The claim is presented without supporting evidence or reasoning.", "helpfulness_rationale": "The review offers a suggestion (adding a new loss) but lacks the necessary details to be truly helpful. The suggestion is broad and lacks specific guidance on how to achieve it or why it's beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a potential area of difficulty (lack of intuition for the proof) and highlights a potential issue with determining f* based on P*. However, it does not explicitly state how to obtain the intuition or how to choose P* in practice. The action is implicit (identifying a problem), but the steps to resolve it are not clearly laid out.", "grounding_specificity_rationale": "The review point explicitly mentions 'intuition of the proof' and 'invertible function $f^*$' and refers to a 'fixed $P^*$'. It also asks a question directly about the practical determination of $P^*$. This clearly identifies the specific part of the paper and the issue being addressed, providing good grounding. The unique elements being addressed are the proof intuition and the function $f^*$.", "verifiability_rationale": "The review point makes a claim about the lack of intuition and the difficulty of determining $f^*$ based on $P^*$. It attempts to verify this by stating that $f^*$ depends on $P^*$. However, it doesn't provide concrete examples or external references to support the claim about the difficulty of determining $P^*$ in practice. The reasoning is present, but the depth and support could be improved.", "helpfulness_rationale": "The review point directly addresses potential areas where the original paper could be improved by providing more intuition and guidance. The questions about the intuition of the proof and the determination of $P^*$ are clear and actionable for the author. The reviewer provides specific points of confusion and suggests concrete improvements, making the feedback 5 and constructive."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point is a question about the difference between two equations and their respective terms. While the reviewer is seeking clarification, there is no explicit instruction or demand for action on the part of the authors. The authors are expected to understand the difference and potentially address it in their work. Therefore, the review point is not directly actionable in terms of guiding the authors to make a specific change to their draft.", "grounding_specificity_rationale": "The review point explicitly mentions 'Eqs. (7)' and 'Eqs. (10)', providing a clear reference point within the paper. The reviewer is also asking about the difference between the terms 'X' and 'H^(1)' within these equations, specifying the exact elements being discussed. This level of detail and specificity clearly identifies the part of the paper being addressed. Therefore, the comment is 5.", "verifiability_rationale": "The review point presents a claim about a perceived inconsistency or lack of clarity regarding the difference between two equations and their terms. The reviewer is stating that they have found this inconsistency. While the verifiability depends on the authors independently being able to confirm this difference based on the provided information, the reviewer *claims* to have found a discrepancy. This claim, if verifiable, would be a statement that requires justification or explanation. Therefore, the comment is potentially verifiable.", "helpfulness_rationale": "The review point is a question about the difference between two equations and their terms. While this question can be helpful for the authors to understand a potential inconsistency or lack of clarity, it does not directly provide a solution or suggestion for improvement. The helpfulness lies in the potential for clarification rather than direct actionable advice. Therefore, the comment is 3 as a point of clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out a problem (lack of realworld applicability) but doesn't explicitly state what action the authors should take to address it. While it implies an action by highlighting the need for empirical evidence, it doesn't provide specific steps on how to obtain or present this evidence.", "grounding_specificity_rationale": "The reviewer mentions the 'applicability of the model to realworld diffusion process' as a concern. While they identify a general area of concern, they don't specify which particular part of the paper this relates to (e.g., the model description, experimental setup, discussion section). The issue is presented as a general statement rather than a specific problem within a defined section or table.", "verifiability_rationale": "The review states that 'the main concern with the paper is the applicability of the model to realworld diffusion process' as a criticism. This is a claim about the paper's limitations. However, the review does not provide any justification or evidence to support this claim. It lacks logical reasoning, common knowledge, or external references to back up the assertion about the model's applicability.", "helpfulness_rationale": "The review identifies a relevant issue (the lack of empirical evidence for realworld applicability) but fails to offer any concrete suggestions or guidance on how the authors can address this concern. It points out a gap in the evaluation but doesn't actively help the authors improve their work by providing specific actions or evidence."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The sentence criticizes the novelty of the contribution but doesn't explicitly state what is lacking or how to improve it. It's a statement of fact, not a prescription for change.", "grounding_specificity_rationale": "The comment refers to 'the main contribution' and 'alternatives exist' but doesn't pinpoint a specific aspect of the contribution or provide a unique reference to a section, table, or figure in the paper.", "verifiability_rationale": "The comment contains a claim ('the main contribution of combining attention with other linear mechanisms is not novel') and provides a reason ('as noted in the paper, a lot of alternatives exist') to support it.", "helpfulness_rationale": "The review points out a lack of novelty but doesn't offer concrete steps for the authors to address this weakness. It's a critique of the contribution, not a direct suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the novelty of the paper appears limited and points to the ENCODE work as prior art. They also critique the decomposition as incremental. While the reviewer identifies a potential issue, they do not explicitly state how the ENCODE work directly limits the novelty or how the decomposition is specifically incremental. The action is implied but not explicitly stated and detailed.", "grounding_specificity_rationale": "The reviewer mentions the ENCODE work as a point of comparison, which can be interpreted as a form of grounding. However, they do not explicitly identify a specific section, table, figure, or unique aspect of their paper that is directly related to the ENCODE work. The grounding is implicit rather than explicit.", "verifiability_rationale": "The reviewer makes a claim that the paper's novelty is limited and critiques the decomposition as incremental. However, they do not provide any specific examples, references, or logical reasoning to support these claims. The statement is presented as an opinion without sufficient backing.", "helpfulness_rationale": "The reviewer provides a critique of the paper's novelty and the incremental nature of the decomposition. While they identify potential issues, the feedback lacks specific details, examples, or logical reasoning to support their claims. The suggestions are present but not welljustified."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'A also proposes a CLN (region proposal generation algorithm). What's about a performance comparison with this work.' This is a clear and direct request for information. The reviewer is identifying a specific aspect of paper A and asking for a comparison, which is a concrete action to be taken by the authors.", "grounding_specificity_rationale": "The review point explicitly refers to 'A' and 'CLN (region proposal generation algorithm)'. This is a very specific reference. While the abbreviation 'CLN' might not be universally known, the context strongly implies a specific algorithm from paper A. The request is also specific, asking for a 'performance comparison'.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It's a request for information. While the request itself is relevant to understanding the contribution of the proposed algorithm, the *review point itself* doesn't make a statement that needs to be supported by evidence. There's X being made that requires logical reasoning, common knowledge, or external references to be validated.", "helpfulness_rationale": "While the review point raises a valid concern about the performance of a proposed algorithm, it doesn't provide any helpful information or guidance on how to address this concern. It's a request for data or analysis, not a suggestion on how to perform the comparison or what to expect. The reviewer is pointing out a potential gap in the current work's evaluation, but they are not providing any concrete steps or insights to help the authors improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a specific issue: 'presentation is at times too equationdriven and the notation, especially in chapter 3, quite convoluted and hard to follow.' They also suggest a concrete action: 'An illustrative figure of the key concepts in section 3 would have been helpful.' This clearly indicates an explicit action that is directly related to the identified problem.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'chapter 3' when suggesting an 'illustrative figure of the key concepts in section 3 would have been helpful.' This precise identification of the section demonstrates strong grounding. The suggestion to add an 'illustrative figure' is also a specific type of improvement, indicating specificity.", "verifiability_rationale": "The reviewer states a problem ('presentation is at times too equationdriven and the notation... quite convoluted and hard to follow') and suggests a solution ('An illustrative figure... would have been helpful'). However, the reviewer does not provide any evidence or logical reasoning to support the claim that the notation is indeed convoluted or that the figure would definitively solve the problem. The suggestion is presented as a potential improvement without concrete backing.", "helpfulness_rationale": "The reviewer directly addresses a specific issue related to the presentation and offers a clear and actionable suggestion: 'An illustrative figure of the key concepts in section 3 would have been helpful.' This specific and constructive suggestion directly targets the identified problem, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly mentions 'subscripts' and suggests 'enhancement' for better readability. While the action of enhancing is clear, the reviewer does not specify *how* to enhance the subscripts. The action is implied rather than explicitly stated with concrete steps.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'figure3' and specifically mentions 'subscripts'. This indicates a clear identification of the part of the paper being addressed. The issue, 'could be enhanced for better readability and aesthetic appeal', is also clearly specified.", "verifiability_rationale": "The reviewer states a suggestion ('could be enhanced') without providing any specific examples, references, or logical reasoning to support why the subscripts need enhancement. The claim is presented as a general preference rather than a justified requirement.", "helpfulness_rationale": "The reviewer identifies a valid area for improvement (subscripts in figure3) but lacks specific details on how to achieve this. The suggestion is quite general and does not offer concrete steps or specific recommendations. Therefore, while the feedback is relevant, it lacks the actionable detail needed for significant improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that 'Technical details and formulations are limited' and further suggests that 'the main novelty reflected in the scheme or procedure'. While it identifies a problem, it doesn't provide specific steps on how to improve the technical details or formulations. The suggestion about the novelty being in the scheme/procedure is a good starting point but doesn't offer concrete actions. Therefore, it is 3 as it points to a problem and its nature, but lacks specific guidance on how to address it.", "grounding_specificity_rationale": "The comment identifies the area of 'technical details and formulations' but does not specify a particular section, table, figure, or unique element within that category. It refers to the 'scheme or procedure' as a source of novelty, implying a lack of detail in that area, but doesn't pinpoint where the missing information should be found. Therefore, it is weakly grounded as it identifies a general area of concern without specifying the exact part of the paper being addressed.", "verifiability_rationale": "The comment contains a claim that 'Technical details and formulations are limited' and infers a suggestion that 'the main novelty reflected in the scheme or procedure'. While it points to a limitation, it doesn't provide specific evidence or references to support the claim about the lack of technical details. The suggestion about the novelty being in the scheme/procedure is a good starting point but doesn't offer verifiable reasoning. Therefore, it is 3 as it makes a claim that could be supported by evidence, but lacks sufficient justification or references.", "helpfulness_rationale": "The comment identifies a potential weakness in the paper ('Technical details and formulations are limited') and suggests a direction for improvement ('improve formulations'). It provides a clear direction for the author to focus their revision efforts. While it doesn't provide specific steps on how to improve the formulations, it does highlight an area that needs attention and offers a general direction. Therefore, it is 3 as it points out a potential area for improvement and suggests a direction, even if it lacks specific details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks for a description of how the archetype positions are updated after initialization. While the initialization method (FurthestSum) is mentioned, the mechanism for subsequent updates is not described, making the action somewhat implicit.", "grounding_specificity_rationale": "The reviewer refers to Algorithm 2, the coreset C, the query Q, and the archetypes z_1 to z_k, indicating some level of grounding. However, the specific details of how these archetypes are updated are not provided, making the grounding somewhat underspecified.", "verifiability_rationale": "The reviewer makes a claim that the paper does not explain how the archetype positions are updated. While the paper presents an algorithm, the specific update mechanism is not detailed, leaving the reviewer to infer the process, which is not verifiable with explicit reasoning or external references.", "helpfulness_rationale": "The reviewer's question directly addresses a potential area of confusion or lack of detail in the algorithm description. Providing an explanation of the update mechanism would significantly improve the clarity and usefulness of the algorithm for the reader."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states what is missing in the empirical study and provides specific suggestions for improvement. This directly informs the authors about what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The review point asks specific questions about the empirical study, such as recording parameters, preprocessing steps, and the resting state condition. These questions directly ground the authors in the methodology. It also suggests including the number of regions in the parcellation, providing a concrete action to take.", "verifiability_rationale": "The reviewer provides suggestions and recommendations for the empirical study. While these are based on common practices in the field and logical reasoning, they do not require external references to be understood or accepted. Therefore, they are 3.", "helpfulness_rationale": "The review point is informative and provides concrete suggestions for improving the empirical study. While it doesn't demand a complete overhaul, it offers valuable guidance to the authors, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement 'overparameterization invariably overfits the data and results in worse performance' is explicit about the action of overparameterization leading to overfitting and worse performance. While it doesn't specify *how* this happens, it clearly identifies the consequence. Therefore, it has a moderately explicit and somewhat concrete action.", "grounding_specificity_rationale": "The statement 'overparameterization invariably overfits the data and results in worse performance' is a general principle and does not explicitly point to a specific part of the paper being discussed. It's a general statement about the potential downsides of overparameterization. Therefore, the grounding is weak.", "verifiability_rationale": "The statement 'overparameterization invariably overfits the data and results in worse performance' is a claim. However, the reviewer immediately contradicts this by stating 'overparameterization seems to be very helpful for supervised learning of deep neural networks in practice' and provides external references 1 to support this claim. The lack of sufficient evidence to support the initial statement makes it 1. The reviewer actively challenges the claim with counterevidence.", "helpfulness_rationale": "The review point initially highlights a potential issue with overparameterization (overfitting and worse performance). However, the subsequent statements provide strong counterevidence and examples of when overparameterization is beneficial. This makes the initial part of the review point 3 in pointing out a potential pitfall, but the overall point is undermined by the contradictory information provided. Therefore, the overall helpfulness is limited."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The reviewer points out specific limitations of the model and training process but does not explicitly recommend any concrete improvements or actionable steps. While the reviewer implies these issues are problematic, the lack of explicit action makes it 2. The reviewer states 'It is timeconsuming' and 'independent training' but doesn't suggest how to make it less timeconsuming or what changes to the training process would be beneficial.", "grounding_specificity_rationale": "The reviewer provides specific details about the model architecture and training process, clearly identifying the relevant parts of the paper. They also ask for comparisons, further grounding the feedback in concrete elements. The reviewer mentions 'pixel level(though sparsity by landmark)' and 'independent training on all font images and characters' and asks 'In addition, parsing model is a highorder factor graph with four types of factors. The processing efficiency of training and testing should be described and compared with existing work.' These specific details and the request for comparisons demonstrate strong grounding specificity.", "verifiability_rationale": "The reviewer states facts about the model and identifies a missing element (performance comparisons). This is verifiable. However, the lack of explanation or citations makes it 3 rather than fully. The reviewer states 'It is trained in pixel level(though sparsity by landmark) and the model is trained independently on all font images and characters. In addition, parsing model is a highorder factor graph with four types of factors.' These are verifiable statements. However, the reviewer does not explain *why* these aspects are problematic or *cite* any literature to support their claims about the impact on processing efficiency and the need for comparisons.", "helpfulness_rationale": "The reviewer explicitly states the unhelpfulness of the information due to its lack of comparison and complexity. This is clearly unhelpful. The reviewer states 'It is timeconsuming since the shape model is trained in pixel level(though sparsity by landmark) and the model is trained independently on all font images and characters. In addition, parsing model is a highorder factor graph with four types of factors. The processing efficiency of training and testing should be described and compared with existing work.' The lack of comparison and the complexity of the described model make it difficult for the authors to understand the implications and take action. The reviewer states 'I am asking for help to understand the impact of these design choices on the overall efficiency and performance of the model.' This clearly indicates a lack of helpful information."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of discussion regarding the prompt dataset creation and its source. This is an explicit action that the authors should take. Furthermore, the reviewer provides a concrete action by stating 'A discussion on the prompt dataset (for the fewshot case) creation together with its source should be discussed.' This clearly indicates what needs to be addressed.", "grounding_specificity_rationale": "The authors can accurately pinpoint the section, table, figure, or unique aspect being addressed by the review point, which is the 'Prompt Dataset' section and its source. The comment explicitly mentions 'prompt dataset creation' and 'its source', allowing the authors to directly identify the relevant part of the paper. Therefore, the grounding is fully grounded. While the reviewer doesn't specify the exact nature of the missing discussion (e.g., details about the data collection process or specific sources), the core components are clear, making the grounding strong. The specificity is somewhat lacking as the reviewer doesn't provide concrete examples of what should be discussed, but the implication is clear.", "verifiability_rationale": "The review point contains a claim: 'A discussion on the prompt dataset (for the fewshot case) creation together with its source should be discussed.' This is a clear statement that requires justification. The verifiability of this claim is somewhat lacking because while the reviewer implies the importance of this discussion for the fewshot learning setup, they don't provide specific examples or references to support the need for this particular discussion. The reasoning is present but could be strengthened with more detail or references.", "helpfulness_rationale": "The review point is 5 because it directly identifies a clear omission in the paper: the lack of a discussion on the prompt dataset creation and its source. This is a specific and actionable piece of feedback that will help the authors improve the clarity and completeness of their work. The reviewer clearly states what is missing, making it easy for the authors to address this feedback."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly suggests an action: 'an ablation on the weighting method of the crossentropy loss would be nice to see'. This action is directly tied to the proposed improvement. The suggestion is also concrete, proposing a specific type of ablation study. Therefore, the review point provides clear guidance on what the authors should do and how to implement it.", "grounding_specificity_rationale": "The reviewer mentions a specific problem related to the weighting method: 'the authors note for example that in Atlantis their method underperforms because \"the game has repetitive background sounds\". This is a scenario I'd expect the weighting might have helped remedy.' This demonstrates that the reviewer can identify a specific aspect of the weighting method that they believe needs improvement. However, the suggestion itself, 'an ablation on the weighting method', is a general idea and doesn't specifically address the 'repetitive sounds' issue. Therefore, while the reviewer can identify a specific part, the suggestion is not explicitly tied to that specific part. The grounding is implied but not fully explicit.", "verifiability_rationale": "The reviewer suggests an ablation study but does not provide any specific justification or reasoning for why this might be effective or how it would address the issue of 'repetitive background sounds'. There are no references to external works or logical reasoning provided to support the suggestion. Therefore, the claim made in the review point is not supported by any evidence or reasoning.", "helpfulness_rationale": "The reviewer suggests an ablation study on the weighting method. While this is a relevant and potentially useful suggestion, the review point lacks any specific details on how to implement this ablation or any evidence to support the effectiveness of this approach. The suggestion is general and does not provide a strong basis for the authors to improve their draft. Therefore, the review point does not offer a strong and actionable suggestion with supporting evidence."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out a critical weakness but does not explicitly state how the authors should address it. While it suggests new datasets and benchmarks, it lacks specific guidance on implementation.", "grounding_specificity_rationale": "The review mentions general areas like 'column operations' and 'TexttoSQL' without pinpointing a specific section or table. It also doesn't detail what makes the work incremental.", "verifiability_rationale": "The reviewer makes a claim about the paper's lack of novelty and provides some general reasons. However, these reasons are not specific enough to be considered verifiable claims.", "helpfulness_rationale": "The review raises a valid concern but lacks specific, actionable steps for the authors. The reasons for the lack of novelty are general and don't provide concrete directions for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a desired action: 'explain why removing some of the assumptions like bounded variance and bounded gradients is an important contribution via. solid examples.' This is a clear and actionable suggestion. The reviewer is proposing a method (using examples) to address a known issue (lacking explanation of the relaxed assumptions). This makes the comment actionable.", "grounding_specificity_rationale": "The reviewer mentions 'bounded variance' and 'bounded gradients' as specific aspects of the paper. They also suggest using 'solid examples' as a method to address the issue. This demonstrates a clear grounding of the comment in the specific parts of the paper and a concrete method to achieve the desired outcome. The reviewer is not just pointing out a general problem but a specific area and a specific way to solve it.", "verifiability_rationale": "The reviewer suggests using 'solid examples' to explain the importance of removing assumptions. However, the comment lacks specific examples or references to external work. While the *idea* is helpful, the *how* is not welldefined. The reviewer is proposing a general method but doesn't provide the necessary details to verify its effectiveness or relevance. This makes the claim somewhat underjustified.", "helpfulness_rationale": "The reviewer's point about explaining the significance of relaxed assumptions is valid and addresses a clear need in the paper. However, the lack of concrete examples or a clear methodology makes the suggestion not fully actionable. While the *direction* is helpful, the *implementation* is not wellspecified. The comment identifies a valuable area for improvement but doesn't provide a fully realized contribution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests exploring labeled consistency training and its application to graph anomaly detection. While this points towards a potential improvement, it doesn't explicitly state an action or propose a concrete change to the current method. The suggestion is openended and doesn't provide a specific direction for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'labeled data for consistency training' and 'graph anomaly detection' as potential areas for improvement. They also name two specific papers (a and b) related to graph contrastive learning. This clearly identifies the specific part of the paper and the issue being addressed, making it highly grounded. The mention of 'exact labels' further specifies the nature of the labeled data.", "verifiability_rationale": "The reviewer poses a question about the potential benefits of labeled consistency training and suggests it might provide 'effective information' for graph anomaly detection. While they imply a claim, they do not provide any evidence, reasoning, or references to support this suggestion. The statement is presented as a possibility without justification.", "helpfulness_rationale": "The reviewer's comment is more about suggesting a potential research direction (labeled consistency training for graph anomaly detection) than providing direct feedback on the current draft. They pose a question and offer a potential benefit without explaining why they think it would be beneficial or providing any references to the current work. The comment is valuable for future research but doesn't directly improve the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point states the need to 'reorganize the experimental part' and suggests focusing on 'experimental content...does not highlight the superiority of the method'. While the action 'reorganize' is explicit, the specific elements to be reorganized and the methods for reorganization are not detailed. The reviewer identifies an action but lacks the concrete steps needed for the authors to follow.", "grounding_specificity_rationale": "The review point mentions 'the experimental part' and 'experimental content...does not highlight the superiority of the method'. While the reviewer can infer that they are referring to the experimental section and the content within it, they do not explicitly name a specific table, figure, or unique aspect of the paper. The reviewer also points to a general issue (lack of highlighting superiority) rather than a specific, localized problem.", "verifiability_rationale": "The review point contains a claim that 'the experimental part needs to be reorganized' and implies that the current experimental content does not effectively highlight the superiority of the method. However, the reviewer does not provide any specific evidence or reasoning to support this claim. They are making a general observation about the experimental section without citing specific issues or providing references.", "helpfulness_rationale": "The review point identifies a general area for improvement in the experimental section ('reorganize') and suggests a direction ('focus on experimental content that highlights the superiority of the method'). However, it lacks the specific details needed for the authors to understand what needs to be changed and how to achieve the suggested focus. The feedback is general and lacks concrete suggestions, making it less helpful for specific improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem with the model's assumption about the memory span in recognition tasks and suggests an alternative. The statement 'in the most common case of recognition, old vs new judgments, new items comprise the list of all items available in memory (minus the ones seen)' is a clear identification of the issue. The suggestion 'and it's hard to see how such an exhaustive list could be effectively implemented and concrete predictions tested with simulations' is a direct action the authors could take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'old vs new judgments' and 'all items available in memory (minus the ones seen)'. These are literal mentions of specific aspects of the paper and clearly identify the issue. The comment is grounded because it directly refers to a specific part of the paper and how it relates to the model's assumptions.", "verifiability_rationale": "The reviewer makes a claim about the difficulty of implementing and testing the model with an exhaustive list. This is a verifiable statement as it points to practical challenges in cognitive modeling and memory research. While not backed by specific examples within the review point itself, the claim aligns with general knowledge in the field. The reasoning is logical \u2013 managing and testing an exhaustive list is complex.", "helpfulness_rationale": "The review point is clear and directly addresses a potential limitation of applying a specific recognition model to a common scenario. The reviewer provides a specific alternative scenario ('broader memory span') that the authors could consider. The comment is actionable and constructive, offering a potential direction for improvement rather than simply pointing out a flaw."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states two actions: 1) 'For the results of zeroshot learning on CUB dataset, i.e., Table 3 page 7, the metadata used here are \u00e2\u0080\u009cattribute\u00e2\u0080\u009d.' This is a clear instruction on what metadata to use. 2) 'This is good for fair comparison. However, from the perspective of getting better performance, better metadata embeddings options are available.' This is a suggestion for improvement. Both points are explicit and directly address specific aspects of the paper.", "grounding_specificity_rationale": "The review point explicitly mentions 'zeroshot learning on CUB dataset, i.e., Table 3 page 7' and states that the metadata used is '\u00e2\u0080\u009cattribute\u00e2\u0080\u009d'. This directly identifies the specific part of the paper and the metadata being discussed. However, the reviewer then suggests exploring 'better metadata embeddings options' based on 'Reed et al. (CVPR 2016)'. While the initial mention of 'attribute' is grounded, the suggestion to explore alternatives is more general and doesn't pinpoint a specific missing element within the 'attribute' category itself.", "verifiability_rationale": "The review point contains a claim: 'For the results of zeroshot learning on CUB dataset, i.e., Table 3 page 7, the metadata used here are \u00e2\u0080\u009cattribute\u00e2\u0080\u009d. This is good for fair comparison. However, from the perspective of getting better performance, better metadata embeddings options are available.' The claim is that 'attribute' embeddings are good for fair comparison but lack for better performance. The reviewer provides a reference to Reed et al. (CVPR 2016) to support the claim about better embeddings. However, the reasoning for why 'attribute' embeddings are less effective and how Reed et al.'s embeddings are better is not explicitly detailed.", "helpfulness_rationale": "The review point provides a critique of the 'attribute' metadata used in Table 3 and suggests exploring 'better metadata embeddings options' based on Reed et al. While the suggestion to explore better embeddings is helpful, the critique about 'attribute' being 'good for fair comparison' is less specific and doesn't offer concrete actionable feedback. The suggestion to explore Reed et al. is relevant and could be helpful for the authors."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Partially Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The questions are framed as questions seeking justification, which can be interpreted as an implicit request for action. However, the reviewer isn't *directly* telling the authors what to do. They are asking *why* something is the case. The questions are quite general. They don't point to a specific section or table. The \"why\" is vague. While the reviewer is prompting for information, they are not directly instructing how to obtain it. The questions are openended and encourage the authors to think critically and provide evidence.", "grounding_specificity_rationale": "The reviewer is asking about the *reasonableness* of a claim. This implies they might be referring to a claim made in the paper or a section they perceive to be lacking grounding. However, the *specific* claim being referred to is not explicitly stated in the review point itself. The reviewer is making a metacomment about the paper's clarity. The questions are openended and don't point to a specific part of the paper being addressed. The grounding issue is implied but not clearly identified.", "verifiability_rationale": "The questions ask for justification or clarification of the claims being made. The reviewer is asking *why* they think the training times are similar and *why* the code should be released. This involves verifying the underlying assumptions and the logic behind these suggestions. The questions are not direct claims but rather requests for supporting evidence. The reviewer is prompting for logical reasoning and common knowledge (the benefit of code release). The questions are not explicitly supported by external references in the review point itself.", "helpfulness_rationale": "The questions directly address the paper's content and encourage further action (providing justification or code). They are clear and actionable in the sense that they prompt the authors to think critically and provide evidence. The reviewer is not just pointing out a problem but also suggesting a positive step (code release). The questions are welldefined and lead to concrete suggestions. The reviewer is asking for specific information and encouraging a positive change (code release)."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points out a problem (the strong assumptions for termination states and the high cost of manual labeling) but does not explicitly state a concrete action or suggestion for improvement. While it implies that the authors should consider alternative labeling methods or data acquisition strategies, the specific steps are not detailed.", "grounding_specificity_rationale": "The review mentions 'termination states' and 'manual labeling,' which are specific aspects of the data and task. However, it does not explicitly identify a specific section, table, or unique element of the paper where this issue is occurring. The grounding is present but not fully precise.", "verifiability_rationale": "The review makes a claim about the cost of manual labeling. While this claim is generally verifiable based on common knowledge in the field, the review does not provide specific references or examples to support this claim within the context of the specific paper being reviewed. Therefore, the evidence supporting the claim is not fully robust.", "helpfulness_rationale": "The review identifies a practical issue (the high cost of manual labeling for termination states) that could motivate the authors to explore alternative labeling methods or data acquisition strategies. While it doesn't offer a specific solution, it highlights a significant bottleneck that could be valuable for the authors to address. The feedback, while not explicitly actionable, points to a relevant problem."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a potential ambiguity regarding the term 'Efficient Proxy' but does not explicitly state a solution or action to resolve it. While the reviewer points out the confusion between a specific proxy and a family of proxies, they do not offer concrete steps for the authors to take to clarify this issue. The action identified is the recognition of the ambiguity itself, which is a form of implicit action.", "grounding_specificity_rationale": "The reviewer mentions the term 'Efficient Proxy' in the review, indicating that they have identified a specific concept within the paper as potentially problematic. However, they do not explicitly point to a particular section, table, or figure where this ambiguity is most evident. The grounding is present because the term is mentioned, but it is not precisely located.", "verifiability_rationale": "The reviewer makes a claim that there is 'unclear if the authors mean a particular efficient proxy or efficient proxies in general'. The reviewer also provides a potential explanation for this ambiguity by stating that the lack of a specific 'Efficient Proxy' suggests it refers to a 'family of efficient proxies'. This constitutes a claim being made and a potential justification for it, making it 3.", "helpfulness_rationale": "The reviewer raises a valid point about the potential confusion regarding the term 'Efficient Proxy'. While they do not offer a direct solution, they encourage the authors to clarify this term, which is a helpful step in improving the draft. The reviewer's comment highlights a potential area for improvement in the authors' communication or understanding."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the methods used (Mirzasoleiman et al., 2020, Grouplearning setting, and DBSCAN) and the potential issue (redundancy of DBSCAN given the stacking). This provides clear guidance on how the authors should interpret and potentially improve their work. The reviewer identifies an implicit action: the authors should consider whether the explicit clustering is necessary given the existing 'stacking' method.", "grounding_specificity_rationale": "The reviewer explicitly names the methods used (Mirzasoleiman et al., 2020, Grouplearning setting, and DBSCAN). This allows the authors to accurately identify the specific part of the paper related to the clustering methodology. The reviewer also points out a potential issue (redundancy of DBSCAN), which is directly tied to the identified methods.", "verifiability_rationale": "The reviewer makes a claim about a potential redundancy (DBSCAN might be redundant given the stacking). While the reviewer doesn't provide external references, the claim is based on a logical understanding of how these methods might interact. If a 'stacking' method already performs grouping, the explicit use of DBSCAN might be unnecessary. The reviewer provides a logical reasoning for their claim, making it verifiable, although the degree of verifiability depends on the specifics of the 'stacking' method, which are not provided here.", "helpfulness_rationale": "The reviewer's point is clear and identifies a potential inefficiency in the proposed method. By suggesting that the explicit use of DBSCAN might be redundant, the reviewer is providing actionable feedback that could help the authors simplify their approach and potentially save computational resources. This is likely to be a helpful comment for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment 'The model seems overly simple' is a statement of opinion, not an explicit instruction on what to do. It suggests the authors might want to consider more complex models, but it doesn't pinpoint a specific aspect of the model or analysis that needs adjustment.", "grounding_specificity_rationale": "The comment 'The model seems overly simple' is a general statement about the model's overall complexity. It does not specify which part of the model, the data, the experiments, or any other element of the paper is overly simple.", "verifiability_rationale": "The comment 'The model seems overly simple' is an opinion, not a claim that can be verified with evidence or logical reasoning. It's a subjective assessment of the model's complexity.", "helpfulness_rationale": "The comment 'The model seems overly simple' points out a potential weakness and suggests considering more complex models. However, it doesn't provide specific details on what is meant by 'overly simple' or how the model should be modified. It's a general suggestion, making it 3 but not highly so."}
{"actionability_label": "High", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides two explicit suggestions: (1) to mention the negligible computational cost of CHR in the main paper and (2) to include runtime examples. These are direct actions the authors can take to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly states where the information should be added (main paper) and what information should be included (computational cost and runtime examples). This clearly identifies the specific part of the paper and the issue being addressed.", "verifiability_rationale": "The reviewer's suggestions are factual and directly address a practical aspect of the method. While they don't provide a justification for the cost being negligible, they offer concrete information that can be verified. The runtime examples are also concrete data points.", "helpfulness_rationale": "The reviewer's suggestions directly address a practical concern (computational cost) and aim to improve the paper's impact by making the method more accessible. By mentioning the cost in the main paper, the reviewer helps motivate the method. Including runtime examples provides concrete data for readers to understand the practical implications of the method. These suggestions are actionable and provide valuable information to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The reviewer states a fact ('polynomial time') and offers an opinion ('feels like...'). While the technical detail is present, the reviewer doesn't explicitly state what the authors should do next. The criticism is implied but not directly actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'Witness oracle', 'polynomial time', and 'tabular case'. This demonstrates a clear understanding of the specific parts of the paper being discussed, indicating full grounding and specificity.", "verifiability_rationale": "The reviewer states a verifiable fact ('the authors leverage the complexity...'). However, the opinion ('This feels like...') lacks sufficient justification based on the provided text. The claim is partially supported by the stated complexity but lacks further evidence.", "helpfulness_rationale": "The reviewer criticizes the approach without offering concrete suggestions or explaining why the current method is problematic. The opinion is subjective and lacks a clear connection to the identified weakness. The review does not provide actionable feedback to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the action of 'compare with existing code completion commercial applications' and suggests testing on a smaller subset of RepoEval. This action is directly tied to improving the draft by identifying relevant systems. The specifics of the comparison are not detailed, but the action itself is clear and actionable.", "grounding_specificity_rationale": "The review point mentions 'code completion commercial applications' generally. While it implies a comparison, it doesn't specify a unique section, table, figure, or element within the paper that this comparison refers to. The reviewer can infer the relevance of existing applications to the code completion task, but the exact part being addressed is not explicitly stated.", "verifiability_rationale": "The review point contains a claim that suggests a comparison but lacks specific details on how this comparison would be conducted. There is no logical reasoning, common knowledge, or external references provided to support the claim. The suggestion is vague and doesn't offer concrete steps for the authors to take.", "helpfulness_rationale": "The review point identifies a relevant gap in the paper (lack of comparison with existing systems) and suggests a relevant improvement (comparing with commercial applications). However, the suggestion is very general and lacks specific details on how the comparison would be performed. It doesn't provide concrete steps or actionable advice beyond the initial suggestion, making it only partially helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential area of ambiguity in the second paragraph of the introduction where 'modeling curves' is mentioned. While it points out the lack of clarity, it doesn't explicitly state what needs to be improved or how to proceed. The action is implied but not directly stated, making it less actionable than a more explicit suggestion.", "grounding_specificity_rationale": "The comment explicitly refers to the 'second paragraph of the introduction,' which grounds the reference to a specific part of the paper. However, it doesn't specify *what* within that paragraph is unclear or problematic. The grounding is present, but the specificity of the issue is lacking.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a suggestion for clarification rather than a statement that needs supporting evidence.", "helpfulness_rationale": "The comment identifies a potential area for improvement in the introduction by pointing out the lack of clarity in the 'modeling curves' section. While it doesn't provide a complete solution, it highlights a specific area where the authors might need more information or a clearer explanation, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states two issues: the lack of clarity regarding the shift parameter in shiftedMNIST and the suggestion to show performance on test samples from the observational distribution. While the reviewer points out the *lack* of clarity, they don't *say* what is unclear about the current explanation. They also don't provide specific *how* to improve the current setup or the experiment. This is vague. The reviewer also suggests an experiment, which is a form of action, but it's not concrete.", "grounding_specificity_rationale": "The reviewer refers to 'shiftedMNIST' and the 'shift=0' parameter. While they *mention* the topic, they don't explicitly identify the *section*, *table*, *figure*, or unique aspect of the paper where this is defined (if it is in the paper). They also don't pinpoint the exact figure or unique aspect being discussed. The reviewer also suggests showing performance on test samples from the observational distribution, which could be considered a specific aspect, but the initial part about the shift parameter lacks precise identification.", "verifiability_rationale": "The reviewer *identifies* a lack of clarity regarding the shift parameter and suggests an experiment. This can be considered a claim (albeit an implicit one) about the paper's presentation. The reviewer *suggests* showing performance on test samples from the observational distribution, which could be considered a claim requiring justification (the benefit of this experiment). However, the lack of clarity itself is the evidence, and it doesn't necessarily require external references to be verified to be a valid point. The reviewer's suggestion is a potential claim that could be argued without external verifiability within the review point itself.", "helpfulness_rationale": "The review point raises a valid concern about the lack of clarity in the experimental setup and suggests a valuable experiment. While the reviewer doesn't provide explicit, actionable steps on how to improve the current setup or the experiment, they highlight a genuine issue that could hinder the authors' understanding and ability to reproduce or build upon their work. The suggestion to show performance on the observational distribution is a concrete idea that could help clarify the impact of the domain shift. Therefore, the reviewer provides a valuable pointer that can guide the authors towards further investigation and experimentation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests 'more explanation' and 'different optimization strategies and the corresponding results'. These are clear actions that authors can take to improve their draft. The mention of 'Eq 3' further clarifies the area of improvement, making the action even more explicit. The reviewer also suggests exploring different combinations of minimizing inter and intra terms, which is a concrete action with specific implementation details. The actions are welldefined and directly address potential weaknesses in the paper.", "grounding_specificity_rationale": "The reviewer mentions 'different optimization strategies' and 'corresponding results', which points to specific areas for improvement. However, the reviewer does not explicitly identify the specific section, table, figure, or unique aspect of the paper being addressed. While the areas are relevant, the exact location within the paper is not pinpointed. The suggestion to explore different combinations of minimizing inter and intra terms in Eq 3 is specific, but the reviewer doesn't explicitly state which part of Eq 3 they are referring to (e.g., a specific equation number within the equation or a specific term within the equation).", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for improvement rather than a statement of opinion or judgment. There is no logical reasoning, common knowledge, or external references provided. The reviewer is offering constructive feedback, not making a claim that needs to be supported.", "helpfulness_rationale": "The review point provides specific suggestions for improvement, focusing on the 'expected' outcome and recommending 'more explanation' and discussing 'different optimization strategies and the corresponding results'. The suggestion to explore different combinations of minimizing inter and intra terms in Eq 3 is a concrete and actionable piece of feedback. The reviewer directly addresses potential weaknesses in the clarity of the paper and encourages exploration of a specific aspect of the method. This feedback is directly relevant to improving the paper and is likely to be helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for a definition of 'treewidth' and its importance in the proofs. This is a direct and actionable suggestion for the author.", "grounding_specificity_rationale": "The reviewer directly mentions 'treewidth' and its role in the proofs. This clearly identifies the specific part of the paper being addressed, making the grounding fully specific.", "verifiability_rationale": "The reviewer states a claim about the importance of 'treewidth' in the proofs. While they don't provide a detailed explanation or specific examples, the claim is clear and provides a basis for the author to seek clarification or a definition. The reviewer's statement is logically sound and supported by the context of the paper's proofs.", "helpfulness_rationale": "The review point directly suggests a crucial improvement for the author: including a definition of 'treewidth' as it is central to the paper's proofs. This is a clear, actionable, and directly relevant suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking *how* information redundancy is built into the algorithms. While the paper mentions a 'weight pool' and states that robustness comes from 'information redundancy implemented in our design of the weight pool,' it doesn't explicitly detail the mechanism of this redundancy. For example, is it achieved through multiple identical weights, a specific structure within the weight pool, or some other method? The paper describes the 'Fill' and 'Propagate' steps but doesn't explicitly link them to the creation of this redundancy. The reviewer is asking for a process, not just a statement of inclusion. Therefore, while the *idea* is present, the *how* is missing.", "grounding_specificity_rationale": "The reviewer's question directly refers to the 'weight pool' as the part of the algorithm where redundancy is implemented. This clearly identifies a specific part of the paper. The paper states that robustness comes from 'information redundancy implemented in our design of the weight pool,' which specifies the location of the redundancy. Therefore, the reviewer can confidently identify the relevant part of the paper. However, the *specificity* of what kind of redundancy is implemented is not detailed. The paper doesn't specify if it's multiple identical weights, a specific structure, or something else. This lack of detail makes the grounding somewhat specific but not fully specific.", "verifiability_rationale": "The reviewer is not presenting a claim or a question that requires justification. They are simply asking for an explanation of how something works. Therefore, there is X to verify, and the 'X' category (X) is appropriate.", "helpfulness_rationale": "The reviewer is asking a very specific question about the implementation details of information redundancy. While this question is valuable for understanding the design choices and potentially improving the algorithm, it is a very narrow and focused question. It may not be universally helpful to all readers who are reviewing the paper. The information gained from answering this question might be limited to a small group of people with expertise in this specific area. Therefore, the helpfulness is somewhat limited."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly asks 'How important is the added complexity?' and 'Will one IN do?'. These questions directly point to actions the authors should take, namely, investigating the impact of the multiple INs and potentially simplifying the design. While the actions are not fully specified, the reviewer clearly identifies the need for further analysis and experimentation. The questions are direct and actionable in the sense that they guide the authors towards specific investigations. However, the reviewer does not explicitly state the methods or metrics to use for this investigation, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'the dynamics predictor' as a specific part of the paper. While the general area is clear, the exact section or subsection containing the dynamics predictor is not explicitly identified. The reviewer mentions 'multiple INs at different speeds' as the specific feature being questioned. This specific feature is identifiable within the dynamics predictor section. However, the reviewer does not explicitly state which part of the paper they are referring to (e.g., a specific section number or figure caption). Therefore, while the specific feature is identified, the broader grounding of the 'dynamics predictor' itself is weak. The reviewer implies the importance of this feature but doesn't explicitly state where it is located within the paper.", "verifiability_rationale": "The reviewer states that the 'use of multiple INs at different speeds in the dynamics predictor is not ablated' and asks about its 'importance' and whether 'one IN does'. This statement can be considered a claim that the design choice is lacking empirical support. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The reviewer is making an assertion about the state of the research (lack of ablation) without providing evidence or justification within the review point itself. Therefore, the claim is not supported by verifiable information.", "helpfulness_rationale": "The review point raises a valid concern about the complexity of the model's dynamics predictor and asks for justification for its design. By prompting the authors to investigate the impact of the multiple INs and potentially simplify the design, the reviewer provides a clear direction for improvement. However, the feedback is indirect and requires the authors to conduct further analysis (ablation studies) and potentially gather more data or metrics to support their decisions. The reviewer does not provide specific suggestions or guidance on how to perform this investigation, making the feedback somewhat limited in its immediate helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the opponent maximizes classical SE and AE, not the authors' proposed multiagent payoff. While this is a clear statement of a difference, the reviewer doesn't specify *how* the SE/AE maximization relates to the authors' payoff. The action (maximizing SE/AE) is present, but the connection to the authors' objective is implicit and requires further explanation. Therefore, it's 3 in identifying a discrepancy, but lacks explicit detail on the mechanism.", "grounding_specificity_rationale": "The reviewer mentions the opponent's objective (maximizing SE and AE) but doesn't explicitly identify the specific part of the paper being addressed. They are pointing to a potential flaw in the experimental setup. However, they clearly specify what is wrong: the opponent is maximizing a different objective than the one the authors propose. This specificity is about the *objective* of the opponent, not a specific section or element of the paper. Therefore, it's not fully grounded, as the paper section isn't pinpointed, but it is specific about the issue.", "verifiability_rationale": "The reviewer makes a claim that the opponent's behavior (maximizing SE and AE) is a reason for the observed outcome (not optimizing the multiagent payoff). This claim is generally verifiable, as maximizing SE/AE is a welldefined concept. However, the *specifics* of SE and AE are not provided, making it 3 but lacking sufficient detail to fully understand the reasoning. The reviewer doesn't give examples or references to support their claim about the opponent's objective, which weakens the verifiability. Therefore, it's 3, as the general idea is supported, but lacks key elements like examples or references.", "helpfulness_rationale": "The reviewer points out a potential issue in the experimental design \u2013 that the opponent is optimizing a different objective than the one the authors propose. This raises a valid concern about the validity of comparing the authors' payoff against the opponent's results. While the reviewer doesn't directly offer a solution, they highlight a direction for the authors to consider: ensuring the opponent's objective aligns with the authors' payoff. This is a helpful point because it prompts the authors to reexamine their experimental setup and potentially adjust the opponent's objective or the evaluation metric. It doesn't provide a definitive solution, but it points to a potential area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states they are 'confused' about the statement in Theorem 5.1. While they identify a potential action (asking for clarification), the action itself is vague and lacks detail on how to apply it. The lack of a clear, explicit statement makes it difficult to pinpoint the exact action the reviewer is taking. Therefore, the action is implicit and requires the reader to infer the action, making it less actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Theorem 5.1' and 'variance regularized problem' when expressing their confusion. This demonstrates a clear identification of the specific part of the paper and the comparison they are making. The reviewer is not just stating a general observation but focusing on a specific aspect of the paper. Therefore, the grounding is explicit and points to a specific area.", "verifiability_rationale": "The reviewer states their confusion and interprets the theorem as indicating a 'disadvantage' of MMD DRO. However, they do not provide any specific evidence or reasoning to support this interpretation. They are stating an opinion based on their understanding (or lack thereof) of the theorem's implications. There is no logical reasoning, common knowledge, or external references provided to back up their claim. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer's primary statement is their confusion about the theorem and their perception of a disadvantage for MMD DRO. While they identify a potential area for improvement (asking for clarification), the review point itself does not offer concrete, actionable feedback. It's a statement of confusion rather than a constructive suggestion. The lack of a clear question or request makes this review point not particularly helpful in its current form. Therefore, the review point is not helpful in providing actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly identifies a potential issue in the experimental setup, stating that the 'mixup technique' in LUMP is also used in the proposed method's experiments on SplitCIFAR100 and SplitTinyImageNet. The reviewer then suggests conducting experiments by *excluding* the mixup technique to isolate its contribution. This is an explicit and direct action to address a potential weakness in the experimental evaluation.", "grounding_specificity_rationale": "The reviewer uses the exact same terms, 'mixup technique' and 'proposed method', to refer to the specific components being discussed. This demonstrates a clear and precise identification of the relevant parts of the paper. The suggestion to 'exclude' is also very specific, indicating a strong grounding in the details of the proposed method.", "verifiability_rationale": "The reviewer proposes a specific experimental procedure to verify the impact of the 'mixup technique'. The suggestion is to conduct experiments on the same datasets (SplitCIFAR100 and SplitTinyImageNet) *with* and *without* the mixup technique. This is a logical and verifiable claim, as the impact of the mixup technique can be directly assessed by comparing the performance of the proposed method with and without this technique. The reasoning is clear and the method is welldefined.", "helpfulness_rationale": "The reviewer's point directly addresses a potential weakness in the experimental evaluation by highlighting the lack of isolation of the 'mixup technique'. The suggestion to conduct experiments by excluding the mixup technique is a clear and actionable improvement that would significantly enhance the paper's contribution by empirically demonstrating the pure impact of the proposed method. This is a 5 suggestion for improving the clarity and completeness of the experimental evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking for clarification on a specific implementation detail of the object detection attention mechanism. While they are not explicitly stating an action they want to take, the request implies a need for more information to understand how the attention is being applied. The reviewer is asking whether the attention is performed on the image directly or on a convolutional feature map, which are distinct implementation choices. This request, while not directly instructing an action, is actionable in the sense that the authors need to understand this detail to replicate or build upon the work. The reviewer is essentially prompting for clarification on a technical aspect.", "grounding_specificity_rationale": "The reviewer is asking about the input space of the object detection attention mechanism, specifically whether it operates on the image or a convolutional feature map. They are also asking if any rescaling is involved. The reviewer is implicitly referring to a specific part of the model (the attention mechanism) and is asking for details about its input and potential transformations. While they are not explicitly naming a section or variable, the context of object detection attention strongly suggests they are referring to a specific implementation detail within that context. The request is clear about the specific components being questioned, indicating a high level of grounding specificity.", "verifiability_rationale": "The review point is a request for clarification on a potential implementation detail of object detection attention. It does not present a claim or assertion that requires verification. The reviewer is asking for information about how the attention is being performed, not making a statement that needs to be proven or justified. Therefore, it does not fit the criteria for verifiability.", "helpfulness_rationale": "The reviewer is asking for clarification on a potential implementation detail of object detection attention. While it's a request, it directly addresses a technical aspect of the model that could impact how object detection is performed. Understanding whether the attention is applied to the image or feature map, and if rescaling is involved, is crucial for the authors to understand and potentially reproduce the work. This request, while not directly instructing an action, is likely to be helpful for the authors in understanding a specific technical detail. Therefore, it is considered 5 as it directly addresses a technical implementation aspect."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer is asking a question about a specific aspect of the paper (Fourier features and NTK convergence in the highfrequency range). While this can be interpreted as an implicit action of seeking clarification, it is not a concrete action or suggestion on how to improve the draft. The reviewer is essentially prompting the authors to address a potential gap, but the action taken is vague and lacks specific steps.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Fourier features' and 'NTK convergence' in the context of the paper. They also specify the 'highfrequency range' within the NTK convergence. This demonstrates a clear identification of the specific part of the paper being addressed, making the grounding very strong. The reviewer is not just mentioning a section but rather a specific concept within a section and a specific aspect of a phenomenon.", "verifiability_rationale": "The reviewer is not making a claim or suggesting an improvement. They are expressing uncertainty and asking a question about a specific aspect of the paper. There is no logical reasoning, common knowledge, or external references provided to support a claim. The comment is essentially a question arising from a perceived gap, not a statement that needs verification.", "helpfulness_rationale": "The reviewer is asking a question about a specific aspect of the paper. While this can be seen as a request for more information, it does not directly point out a flaw, suggest an improvement, or provide actionable feedback on weaknesses. The comment is primarily a question, not a critique or a suggestion for change. It lacks the constructive elements of helpful feedback."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, not a directive, and does not explicitly state what action the authors should take. While it points to a potential issue with the RVC algorithm, it doesn't tell them how to fix it.", "grounding_specificity_rationale": "The review point explicitly mentions the 'RVC paper' and specifically refers to 'steps 1 & 2' of the algorithm and 'speed disparities observed between the RSPs and FDs'. This provides clear grounding in the specific part of the paper and the relevant issue.", "verifiability_rationale": "The review point is a question, not a declarative statement containing a claim. It does not present a deduction or require justification, making it 1 in the sense of providing evidence.", "helpfulness_rationale": "The review point is a question that encourages the authors to investigate a potential cause of their observed results. While it doesn't directly tell them how to fix the issue, it points them towards a specific algorithm and a specific area to look, making it a helpful prompt rather than a direct solution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a difference between artificial and biological networks. While it states a fact, it doesn't directly tell the authors what to do or how to improve their networks based on this observation. It raises a question.", "grounding_specificity_rationale": "The review mentions \"artificial networks trained using ASAP\" and \"biological networks.\" While it refers to categories of networks, it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. The comment is general and doesn't provide specific examples.", "verifiability_rationale": "The review states that artificial networks trained using ASAP don't *necessarily* resemble biological networks. This is a claim. However, the reviewer does not provide any specific evidence, references, or logical reasoning to support this claim within the review point itself. The justification for this statement is missing.", "helpfulness_rationale": "The review raises a valid point about the limitations of ASAP compared to backpropagation. It highlights a potential area for further investigation or discussion. While it doesn't offer a direct solution, it points out a relevant difference that could influence the authors' choice of method. However, it doesn't explicitly tell the authors what to do or how to improve their draft based on this observation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'it does not become clear how those emission distributions affect inference.' This is a direct and actionable statement identifying a gap in the paper's explanation. The reviewer also names the specific inference tasks (filtering, smoothing, marginal observation likelihood), making the target of the problem very specific.", "grounding_specificity_rationale": "The reviewer names specific inference tasks (filtering, smoothing, marginal observation likelihood) and asks how they can be computed with the proposed NPSPECHMM. This demonstrates strong grounding as the reviewer can accurately pinpoint the sections, tables, or unique aspects being addressed. The request for details on computation further enhances the specificity of the grounding.", "verifiability_rationale": "The reviewer poses a question to the authors: 'Which of the common inference tasks in a discrete HMM (filtering, smoothing, marginal observation likelihood) can be computed exactly/approximately with an NPSPECHMM?'. This constitutes a claim that requires verification. However, within the review point itself, there is no explicit justification, explanation, or references provided to support this claim. The information about the NPSPECHMM is presented in the paper, but the reviewer is asking a question that requires the authors to apply that knowledge to a specific context. Therefore, while the claim is verifiable *in principle*, the evidence for its verifiability is missing within the review point itself.", "helpfulness_rationale": "The reviewer's point is to clarify a crucial aspect of the paper (the impact of emission distributions on inference). They are directly addressing a gap in the paper's explanation. While they don't provide the answer, they *identify* where more explanation is needed. This is a 5 point as it directly targets a potential area of confusion for the authors and highlights the importance of understanding the interplay between emission distributions and inference methods."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer directly asks 'Why not compare batch and greedy in other 110 datasets?' This is a clear and explicit request for clarification on a specific aspect of the experimental setup. The reviewer is seeking to understand the reasoning behind the limited scope of the batch/greedy comparison. This directly points to an action the authors could take to improve the paper by providing more comprehensive results.", "grounding_specificity_rationale": "The reviewer explicitly mentions the datasets 7,12 and the methods 'batch and greedy'. This demonstrates a clear grounding of the review point in specific sections, tables, figures, or unique elements of the paper. The reviewer is directly referring to specific parts of the paper that are relevant to the question.", "verifiability_rationale": "The reviewer makes a claim that the paper should have compared batch and greedy in all 110 other datasets. This is a claim that is not explicitly supported by logical reasoning, common knowledge, or external references within the paper. The paper does not explicitly state that the comparison should have been across all 110 datasets, nor does it provide a clear justification for why it was limited to 10. Therefore, the verifiability of this claim is low.", "helpfulness_rationale": "The reviewer's question is about understanding the rationale behind a specific experimental choice. This is helpful for the authors to understand the design decisions. Additionally, the reviewer's request for results on the remaining 110 datasets is a direct request for more comprehensive information, which is also helpful for the authors to provide. While the question is about understanding, the request for more data makes it somewhat incomplete in terms of providing a full picture."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the perceived disconnect between the introduction's motivation for lowrank factorization and the core result's connection to polytopes. This is a clear indication of an explicit action that needs to be taken. While the reviewer doesn't provide specific details on how to implement this action, the identification of the action itself is concrete.", "grounding_specificity_rationale": "The reviewer refers to the introduction's motivation and the core result's connection to polytopes, implicitly or explicitly. While the connection might not be a literal mention of a section, the intent is clear. The reviewer also specifies the nature of the disconnect (unnecessary given the polytope result) and suggests exploring implications for lowrank factorization. This level of specificity, even without a direct section reference, falls under '5'.", "verifiability_rationale": "The reviewer makes a claim about the unnecessary motivation in the introduction and suggests exploring implications for lowrank factorization. This claim is verifiable, as it points to a specific area that could be further explored. While the reviewer doesn't provide external references or detailed explanations, the claim itself is stated, making it '4'.", "helpfulness_rationale": "The reviewer points out a potential point of confusion for the authors by highlighting the disconnect between the introduction and the main result. This directly addresses a potential need for clarification, making it helpful. While the reviewer doesn't fully develop the implications for lowrank factorization, the identification of this potential area for improvement is a valuable contribution, making it '4'."}
{"actionability_label": "None", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential ambiguity in the description of the alternating direction method used for the minmin problem. While the reviewer identifies a specific method (alternating direction method) and a problem (minmin problem), they do not explicitly state which *specific* alternating direction method is being used. This makes the action somewhat vague. The reviewer does not directly instruct the author to change anything, but rather asks for clarification on a specific implementation detail.", "grounding_specificity_rationale": "The reviewer mentions the alternating direction method in the context of solving a minmin problem. However, they do not explicitly identify the specific section, table, figure, or unique aspect of the paper where this method is applied. The reviewer's comment is general and points to a type of method rather than a specific instance within the author's work. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer poses a question about the specific alternating direction method used. This is not a claim that requires verification. A claim would be something like, 'The alternating direction method used is the standard ADMM algorithm.' The reviewer's point is a request for information, not a statement that needs to be proven or justified.", "helpfulness_rationale": "The reviewer's point raises a valid concern about the lack of specificity in the description of the alternating direction method. This could lead to confusion for the author and hinder their ability to reproduce or build upon their work. While it doesn't directly instruct the author on what to change, it identifies a potential area for clarification that could be helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point contains explicit statements about the potential issues with the algorithm, such as a 'slight performance decrease' in a specific environment and a 'concern about similar convergence to other algorithms.' However, it does not explicitly state what actions or improvements should be taken to address these issues.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'MsPacman' and refers to 'Figure 2' when discussing the performance decrease, which grounds the comment in a specific part of the paper. However, when discussing the convergence issue, the reviewer mentions 'some environment' without specifying which one or referring to a particular table or figure. The suspicion about overestimation is also not linked to a specific section.", "verifiability_rationale": "The reviewer points out observed performance and convergence issues based on experimental results in Figure 2. However, they do not provide any reasoning or justification for why these issues might be occurring. They do not cite any external references or explain the implications of these observations. The reviewer simply states the observations.", "helpfulness_rationale": "The reviewer raises concerns about the algorithm's performance and stability based on experimental observations. While the concerns are valid and point to areas for further investigation, the review point lacks specific, actionable suggestions for improvement. The reviewer does not tell the authors what to do or how to address the issues."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their observation about the performance difference between DNN+MMA and vanilla DNN when lambda is small. They also state their expectation of the trend. This is an explicit statement that guides the authors to investigate the discrepancy. While the action is not immediately obvious, the reviewer provides a clear direction for the authors to look at the figures and compare the performance trends. Therefore, it is 3.", "grounding_specificity_rationale": "The reviewer refers to 'DNN+MMA', 'vanilla DNN', and 'lambda'. While they don't explicitly state the section or figure number, the context strongly implies they are referring to the elements mentioned. This is weak grounding as the authors might need to infer the specific part of the paper being discussed. However, the specificity of the issue (performance difference based on lambda) is high.", "verifiability_rationale": "The reviewer makes a claim about the expected performance trend and then points out that the observed trend in the figures contradicts this expectation. This is a clear claim that is verifiable by examining the figures. The reasoning is straightforward: the reviewer expects improvement with increasing lambda, but the figure shows a decrease. This is highly verifiable as the discrepancy is visually apparent in the referenced figures.", "helpfulness_rationale": "The reviewer directly points out a discrepancy between their expectations and the observed results. This is a clear and actionable piece of feedback for the authors. It directly highlights a potential issue in their implementation or understanding. The reviewer's statement is a clear call for the authors to investigate the figures and understand why the performance is not behaving as expected. This is 5 as it directly addresses a potential problem."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out the absence of comparison with earlier research work from 2020. While the reviewer doesn't explicitly state the *action* of comparing, the implied action is clear. The reviewer names specific papers, making the grounding somewhat concrete, but the action itself is not explicitly stated.", "grounding_specificity_rationale": "The reviewer mentions 'earlier research work from 2020' and names a specific paper (Taghipour and Ng (2016)). This indicates a clear identification of the specific part of the paper being addressed, making the grounding somewhat strong. However, the reviewer does not specify *why* these papers are relevant or *what* is missing in the comparison, making the specificity aspect lacking.", "verifiability_rationale": "The reviewer states that the paper does not compare the results with some of the earlier research work from 2020. This constitutes a claim. However, the reviewer does not provide any justification or evidence to support this claim. The authors' explanation about the earlier systems not being stateoftheart comes later in the response, not within the review point itself.", "helpfulness_rationale": "The reviewer's comment identifies a potential improvement area for the paper \u2013 comparing it to earlier research work from 2020. While the comment itself doesn't explicitly ask for this comparison, it points to a valid and actionable suggestion for improvement. The reviewer doesn't provide any evidence or justification for this suggestion, which is why it is not considered verifiable."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point does not contain an explicit action or suggestion. It is a question about the applicability of a statistical tool. Therefore, it does not directly instruct the authors on what to do or how to improve their work.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper it is addressing. It is a general comment about the applicability of Hoeffding's inequality. Therefore, it is 1 in a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer's statement is verifiable. They are pointing out a known property of stochastic algorithms and Hoeffding's inequality. The statement is supported by logical reasoning (the conditioning in stochastic algorithms makes independent sampling less likely) and common knowledge about the application of concentration inequalities in this context. However, the reviewer is not directly pointing to a flaw *within the paper itself*, but rather suggesting a potential misunderstanding by the authors. The implication is that the authors might be applying the inequality incorrectly, but this is not explicitly stated or proven by the reviewer.", "helpfulness_rationale": "The review point raises a valid concern about the potential misapplication of Hoeffding's inequality. It could be helpful for the authors to understand the nuances of its application in stochastic settings. However, the review point itself does not directly provide concrete feedback or solutions for the authors. It's a question prompting further investigation rather than a direct instruction or clarification."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly suggests adding an optimization based metalearning approach to Table1, which is a direct instruction for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'Table1' which grounds the comment to a specific part of the paper. However, they do not specify the exact issue or how the optimization approach would be implemented, making it only partially grounded.", "verifiability_rationale": "The reviewer's comment is a suggestion ('like MAML/implicitMAML?') without providing any logical reasoning, examples, or external references to support the claim that such an addition is possible or beneficial. It lacks verifiable evidence.", "helpfulness_rationale": "The comment is a suggestion for improvement but lacks specific details on how the addition would be implemented or why it would be helpful. It is a request for judgment rather than a clear, actionable suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the potential confusion between 'causal mechanisms' and 'causality' and provides a clear definition differentiating the two. It also directly suggests the authors use the terms carefully. This is an explicit and concrete action that the authors can readily understand and implement.", "grounding_specificity_rationale": "The comment explicitly refers to 'Page 1' of the paper, allowing the authors to identify the specific section being addressed. It also clearly identifies the issue as the potential misuse of 'causal mechanisms' and 'temporal relationship'. This is 5.", "verifiability_rationale": "The comment contains a claim that authors should use the terms 'causal mechanisms' and 'causality' carefully. However, it does not provide any specific justification or examples to support this claim. The reasoning is based on general good practice in scientific writing but lacks concrete evidence or references within the comment itself. Therefore, it is not 5 as it lacks specific supporting evidence or justification within the comment itself.", "helpfulness_rationale": "The comment identifies a potential area for improvement in the authors' writing, specifically regarding the use of terminology. It suggests a concrete action: 'please use the terms carefully'. While it doesn't provide specific examples of where this confusion might arise or how to correct it, it does point towards a clear direction for improvement. Therefore, it is 3 in guiding the authors towards better practice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they 'would like to have seen a discussion of how these results related to the lower bounds on kernel learning using lowrank approximation given in \"On the Complexity of Learning with Kernels\"'. This is an explicit action, and the specifics of the paper and concept make it concrete. The reviewer is directly instructing the authors on what to include.", "grounding_specificity_rationale": "The reviewer names a specific paper ('On the Complexity of Learning with Kernels') and a specific concept within that paper ('lower bounds on kernel learning using lowrank approximation'). This provides very clear grounding. The reviewer also specifies the *nature* of the discussion they desire ('a discussion of how these results related to the lower bounds on kernel learning using lowrank approximation').", "verifiability_rationale": "The reviewer is making a claim about what the paper should include \u2013 a discussion of a specific related work. While the act of discussing is verifiable, the claim itself isn't directly supported by evidence within the review point. It's a suggestion, not a definitive statement of fact that requires verification.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for improving the paper \u2013 to include a discussion of a specific related work. This is a helpful and actionable comment that directly addresses a potential area for improvement in the related work discussion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point is a question and a request for clarification, which implies an underlying action: to seek understanding or justification regarding the unclear point. While not explicitly stating what needs to be done, the intent is clear. However, the action is somewhat vague as the reviewer doesn't explicitly state the next steps for the author. The reviewer is asking 'how well are the assumptions met?' which is a question that could be rephrased as an action, but the current form is primarily a question.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'PCA to reduce interaction count' and refers to a specific paper (1) in their review point. This demonstrates a clear grounding of the comment in the technical details of the paper and relevant external knowledge. The reviewer is directly addressing a specific aspect of the paper mentioned by the author.", "verifiability_rationale": "The reviewer is asking for justification or evidence related to the assumptions of PCA and the connection to the cited paper (1). This requires external knowledge and research. While the reviewer doesn't explicitly state a claim that needs verification, the request itself is a form of claim that needs to be supported. The verifiability is somewhat dependent on the author's familiarity with PCA assumptions and the content of paper 1.", "helpfulness_rationale": "The reviewer is directly asking for clarification on a point they found unclear ('how well are the assumptions met?'). This is a strong indicator of helpfulness as the reviewer is seeking to understand a key aspect of the method and its validity. The request for clarification is a direct attempt to improve the author's understanding of the paper. The reviewer is essentially asking for a justification or explanation of a critical assumption."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point criticizes the choice of models and suggests a specific comparison, which directly implies a change or improvement in the methodology. This makes the comment actionable as it points towards a potential adjustment in the experimental setup or analysis.", "grounding_specificity_rationale": "The review point criticizes the 'fewshot RC models considered in the paper' without specifying which models or sections they are referring to. While the general area of the paper is mentioned, the specific part being addressed is not clearly identified, making the grounding weak. It is not '1' because the models are a specific component, but it's not a precise reference to a section, table, or figure.", "verifiability_rationale": "The review point makes a claim about the models not being stateoftheart and suggests a comparison with relation extraction/generation models. This claim could potentially be verified by checking the literature or conducting experiments. While the suggestion for comparison adds a layer of complexity, the core claim about the models' status is verifiable.", "helpfulness_rationale": "The review point identifies a potential weakness in the model selection and suggests a relevant comparison. While it doesn't provide specific instructions on how to improve the models, it points towards a valuable direction for the authors to explore. This suggests a helpful suggestion for improvement, even if it's not a complete solution."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out a missing element (results) and a request for observation, but doesn't instruct the authors on what to do or how to address it. Therefore, it's not actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'sequential MCB vs a single MCT layers for the decision head,' clearly identifying a specific technical aspect of the model. It also asks about what was observed, specifying the area of interest. This is full grounding.", "verifiability_rationale": "The comment states a fact ('no results were shown') and a request for observation, but doesn't present a claim that requires verification or evidence. Therefore, it's not verifiable as a claim.", "helpfulness_rationale": "The comment highlights a missing result and prompts the authors to explore a specific comparison. This points to a potential area for further investigation and is therefore 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies areas for improvement in the paper, such as 'sensitivity to other hyperparameters' and 'language usage'. While the reviewer points out specific issues like 'we typically considers' and 'two permutation', the suggestions for improvement are somewhat general, such as 'improve language usage'. The reviewer does not explicitly state the exact action the authors should take, making it somewhat implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific instances in the paper where improvements are needed, such as 'we typically considers', 'two permutation', 'until converge', and other language usage issues. This demonstrates a clear grounding of the feedback in specific parts of the paper. The reviewer also mentions 'language usage' as an area for improvement, which is specific to a particular aspect of the paper.", "verifiability_rationale": "The reviewer provides specific examples of language usage issues and claims that these are problems in the paper. For instance, they state that 'we typically considers' should be 'we consider' and that 'two permutation' should be 'two permutations'. These claims are verifiable through common grammatical rules and knowledge of standard academic writing practices. The reviewer also states that these issues are 'minor', which provides some justification for the errors.", "helpfulness_rationale": "The reviewer provides specific examples of language errors and suggests improvements in 'language usage'. They also list 'minor comments on language usage', indicating a clear and actionable feedback. The reviewer's suggestions are directly related to the identified issues and are specific enough for the authors to understand what needs to be changed. The focus on specific grammatical errors makes the feedback 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the choice of 20 distribution sets is unclear. This is an explicit statement of a lack of clarity. However, the reviewer also asks a question about what happens if a few distribution sets are selected, implying that the current choice is not welljustified or understood. While the action of identifying a lack of clarity is explicit, the underlying action of explaining the choice and its implications is not explicitly stated, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'the choice of 20 distribution sets' which is a specific technical detail. This indicates a degree of grounding as the reviewer is pointing to a specific parameter within the context of distribution sets. However, the reviewer does not specify *why* 20 was chosen or what the implications are for the analysis. The information provided is about the *number* of sets, not the *specifics* of their choice or the impact on the results. Therefore, while the topic is grounded, the details are not.", "verifiability_rationale": "The reviewer does not make a claim or assertion in this review point. They are stating a problem (lack of clarity) and suggesting improvements (control and clarification). There is X that needs to be verified.", "helpfulness_rationale": "The reviewer provides a helpfulness score of 3 and a detailed explanation of why the point is helpful. They explicitly state that the lack of clarity regarding the choice of 20 distribution sets is a problem and suggest concrete actions to improve this. The reviewer asks 'what if you select only few number of distribution set?' which demonstrates a desire for more control and clarification. The suggestions for control and clarification are actionable and directly address the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "4: Mostly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The review point is an explicit statement of opinion, indicating a perceived limitation of the evaluative framework. However, it lacks concrete suggestions or details on how this limitation should be addressed, making it less actionable for the authors. The actions the authors *should* take are implied but not clearly defined.", "grounding_specificity_rationale": "The review point makes a general statement about the limitations of the evaluative framework without specifying which aspect (QA tasks, models, reasoning, or generation) is affected. The grounding is weak because the authors cannot confidently determine which part of the paper or method is being criticized. The specificity is also low as the nature of the limitation remains vague.", "verifiability_rationale": "The review point is a statement of opinion, not a claim requiring verification. There is no 'is this true?' or 'can you prove this' aspect in the review point.", "helpfulness_rationale": "The review point is a statement of concern about the method's limitations. It doesn't offer concrete suggestions or identify specific weaknesses that the authors should address. It's a critique rather than a helpful suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states that the perplexity experiments are carried out on obsolete language models (ngram HMM, RNN) and suggests showcasing their approach using transformerbased models. This is an explicit action. However, the reviewer does not specify how to implement this change, making the action vague.", "grounding_specificity_rationale": "The reviewer makes a general statement about the perplexity experiments being carried out on obsolete language models. They do not specify which particular aspect of the paper or experiment is being criticized. The reviewer's suggestion to use transformerbased models is a general recommendation, not a specific fix for a particular part of the paper.", "verifiability_rationale": "The reviewer states that the perplexity experiments are carried out on obsolete language models. This is a claim. However, the reviewer does not provide any evidence or references within this review point to support the claim that these models are indeed obsolete. The reviewer's suggestion to use transformerbased models is a potential solution, not a direct verification of the current models' obsolescence.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the perplexity experiments (use of obsolete models) and provides a relevant suggestion (using transformerbased models) to address this weakness. This directly helps the authors understand how to improve their perplexity experiments by aligning with current NLP trends."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that it is 'not wholly clear how it can be estimated at all'. This indicates an explicit action or suggestion that the authors should consider the difficulty of estimation. However, the reviewer does not provide a concrete method or steps to address this issue, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'mu, but as it is the proportion of missing observations.' This clearly identifies the specific parameter being discussed, indicating full grounding. However, the reviewer then states 'it is not wholly clear how it can be estimated at all', which lacks specific details on how to estimate it, making it underspecific.", "verifiability_rationale": "The reviewer makes a claim: 'as it is the proportion of missing observations  it is not wholly clear how it can be estimated at all'. This is a statement that requires verification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim, making it 1.", "helpfulness_rationale": "The reviewer points out a specific issue: the lack of clarity on how to estimate the proportion of missing observations. This directly helps the authors understand a potential limitation or area for further investigation. The comment highlights a concrete problem that needs addressing, making it 5 for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests a *conceptual* experiment involving varying the distance of initialization to the ground truth. While they imply an action (evaluating performance), the specific steps on how to implement this variation and analyze the results are not explicitly stated. The action is implied rather than directly provided.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the distance of initialization M^0 to the groundtruth M^*' and provides a range for this distance 'c' (0.01:0.01:0.1). This clearly identifies the specific aspect of the initialization matrix being addressed, making the grounding explicit. The section, table, figure, or unique aspect being addressed is also implied through the mention of M^0 and M^*.", "verifiability_rationale": "The reviewer proposes a *suggestion* for an experiment. While the *idea* of evaluating performance as a function of initialization distance is verifiable, the reviewer does not provide specific references, examples, or a clear logical reasoning to support this claim within the review point itself. The suggestion lacks concrete implementation details.", "helpfulness_rationale": "The reviewer's suggestion is about improving the evaluation methodology by considering the sensitivity to initialization. While this is a valuable direction for research and could be helpful for understanding model behavior, the review point itself does not directly address a specific weakness or problem in the original work. It proposes a potential improvement rather than a direct solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of only having bounds in expectation and suggests concrete actions like exploring highprobability bounds using ensemble methods. This demonstrates a clear understanding of the issue and provides actionable steps for improvement.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific issue: 'only bounds in expectation are provided' and suggests concrete improvements: 'Would it be possible to get highprobability bounds? For instance by using ensemble methods as performed in the experiments.' This shows a precise understanding of the problem and how to address it.", "verifiability_rationale": "The reviewer makes a clear claim: 'Only bounds in expectation are provided.' They then provide a suggestion: 'Would it be possible to get highprobability bounds? For instance by using ensemble methods as performed in the experiments.' This claim is verifiable as the authors can investigate ensemble methods and error bars to achieve highprobability bounds. The suggestion is directly related to the stated problem.", "helpfulness_rationale": "The reviewer identifies a clear weakness ('only bounds in expectation are provided') and offers concrete, actionable suggestions ('highprobability bounds', 'ensemble methods', 'robustness measures'). These suggestions directly address the identified limitation and provide a clear path for improvement, making the review point 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer expresses a general concern that the results are less impressive than expected, but they do not provide specific details about what aspects of the results are lacking or how they should be improved. They suggest evaluating the results from more aspects, such as latency, memory consumption, and network size, but these are suggestions for future evaluation, not specific actions to take on the current work. The reviewer's statement is a general assessment of the results' quality without pinpointing the specific issues.", "grounding_specificity_rationale": "The reviewer mentions 'the results seem to be less impressive' and suggests evaluating the results from more aspects like 'the actual latency on target device, the memory consumption during the inference time and the actual network size.' While they identify a potential issue (less impressive results), they don't explicitly state which part of the paper or figure these results are referring to. The suggestions are general and not tied to a specific section or table within the paper. Therefore, the grounding is weak as the reviewer cannot precisely identify the referenced part of the paper.", "verifiability_rationale": "The reviewer's comment is more of a critique and suggestion for improvement rather than a claim that requires verification. They state an opinion about the results being less impressive and suggest evaluation aspects, but they don't present a specific claim that can be logically reasoned, supported by common knowledge, or backed by external references. The comment is more about the *evaluation* of the work rather than a direct statement about the *work itself*.", "helpfulness_rationale": "The reviewer's comment is not particularly helpful in improving the draft. While they offer some suggestions, they are general and lack specific details on how the results are less impressive or what specific aspects need improvement. The suggestions are vague and do not provide concrete actionable steps for the authors to take. The comment is more about raising concerns about the evaluation process rather than providing direct feedback on the draft itself."}
{"actionability_label": "Actionable", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "Helpful", "actionability_rationale": "The reviewer explicitly states that the model does not enforce diversity and points to a specific implementation detail (how the diversity term was added). This directly indicates an actionable issue for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'the diversity term' and 'the model' generally, without pinpointing a specific section or table. This indicates weak grounding.", "verifiability_rationale": "The reviewer makes a clear claim ('the model does not enforce diversity explicitly') and provides a reason for their disappointment ('how the authors managed to get the diversity term into their model'). This makes the claim 3, as the authors can investigate how the diversity term was implemented.", "helpfulness_rationale": "The reviewer identifies a clear problem (lack of explicit diversity enforcement) and suggests a direction for improvement (investigating the implementation of the diversity term). This provides valuable guidance for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment states 'some experiments are missing' and provides examples like 'contrastive learning' and 'adversarial learning'. While it identifies a deficiency, it does not explicitly instruct the authors on what experiments to add or how to implement these additions. The suggestion is implied but not stated as an action to be taken.", "grounding_specificity_rationale": "The comment mentions 'experiments are missing' and gives examples of 'contrastive learning' and 'adversarial learning'. However, it does not specify which particular experiment is missing or where in the paper this issue is most relevant. The examples are general areas of research, not specific sections, tables, or unique aspects of the paper.", "verifiability_rationale": "The comment states 'some experiments are missing' and provides examples. This is a statement of fact, not a claim that requires verification or justification. There is no assertion that something is wrong, needs improvement, or requires evidence.", "helpfulness_rationale": "The comment identifies a valid weakness: the lack of specific experiments. However, it does not offer any suggestions or guidance on how to address this weakness. It simply points out the absence of certain types of experiments without proposing concrete improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'suggest an alternative metric' and names a specific alternative (DinoV2 Frechet Distances). This is a clear, direct action. The suggestion is quite concrete. It doesn't just say 'improve the metric,' but suggests a *specific* alternative and even mentions the metric from a cited paper (C).", "grounding_specificity_rationale": "The comment explicitly mentions which part of the paper it addresses, or it should be obvious to the authors. The comment specifies what needs to be addressed in this part, which is the use of FIDs and the suggestion to use DinoV2 Frechet Distances. The grounding is explicit and the specificity is high as it names a concrete alternative metric and even references a paper (C).", "verifiability_rationale": "The claim is that FIDs have flaws and the suggestion is to use DinoV2 Frechet Distances. The reasoning is that DinoV2 Frechet Distances are more robust and better suited for this task, as suggested by the cited paper C. The comment provides a justification for the suggestion by implying that the flaws of FIDs are significant enough to warrant a change. The evidence provided is the suggestion itself and the implication that the cited paper C supports the claim about FIDs having flaws and DinoV2 being a better alternative. The reasoning is logical and the reference to external work (even if not fully elaborated) provides some support.", "helpfulness_rationale": "The review point identifies a valid concern about the limitations of FIDs and provides a concrete suggestion for improvement by recommending DinoV2 Frechet Distances. The reviewer clearly states what is wrong with the current metric and what should be used instead. This is a direct and actionable recommendation that empowers the authors to address the identified issue. The suggestion is specific and points to a concrete alternative, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a question about the novelty of the work and asks for a comparison with a specific paper. This constitutes an explicit action to address a perceived weakness or lack of clarity. The request for a comparison of methodologies is also a concrete action aimed at providing specific feedback.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'https://aclanthology.org/2021.findingsacl.57.pdf' as a point of comparison. This grounds the discussion by referencing a specific paper. The reviewer also asks for a 'detailed comparison of approaches', which specifies the type of information desired.", "verifiability_rationale": "The reviewer asks 'Is it just applying a very similar methodology to new task?' This is a claim that requires justification. The verifiability of this claim depends on the level of detail provided in the comparison of methodologies. If the comparison is logical and references external work, it would be considered verifiable. The potential for external references makes this claim more verifiable than 1.", "helpfulness_rationale": "The reviewer's question directly addresses the core question of the paper's novelty and seeks a comparison with a relevant prior work. This is a 5 question for the authors as it helps them understand the contribution of their work in the context of existing research."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a problem: 'In the reported ablation studies in Table 2, for CUB and SOP datasets, the complete loss function performed even worse than those with some terms missing.' This is a clear indication that the reviewer has identified a specific area for improvement and is suggesting a concrete change to be made to the loss function. The reviewer is directly addressing a discrepancy they have observed.", "grounding_specificity_rationale": "The reviewer directly references 'Table 2', 'CUB dataset', and 'SOP dataset' when pointing out the issue. This is a very explicit and clear identification of the specific part of the paper where the problem lies. The reviewer is not making any assumptions or inferring the location of the issue; they are directly referencing it.", "verifiability_rationale": "The reviewer makes a clear claim: 'In the reported ablation studies in Table 2, for CUB and SOP datasets, the complete loss function performed even worse than those with some terms missing.' This is a statement of observation that can be verified by examining Table 2. While the reviewer doesn't provide the reasoning *why* this is happening, the *fact* that the complete loss function performed worse is verifiable based on the data presented in the table.", "helpfulness_rationale": "The reviewer directly points out a flaw in the reported experimental results. This is a highly valuable piece of feedback for the authors who likely conducted these experiments. By highlighting this discrepancy, the reviewer is directly informing the authors about a potential issue with their experimental setup or analysis, making the review 5 in improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the alternative (inverse triples) and the reason for considering it (CP besides CP). This is explicit. However, the reviewer does not specify how to test the alternative or why the authors didn't explore it. The action is present but lacks detail on implementation.", "grounding_specificity_rationale": "The reviewer mentions 'inverse triples' and 'CP' as the context. While 'inverse triples' is specific, 'CP' is vague. The reviewer could have been more specific about the type of CP they were referring to. The grounding is partially specific but not fully precise.", "verifiability_rationale": "The reviewer presents a suggestion ('introducing inverse triples might also be used') and states a fact ('the authors did not test such cases in their experiments'). This constitutes a claim. The reviewer implies the alternative could be beneficial but doesn't provide a specific reason *why* CP might be insufficient. The reasoning is general and lacks specific examples or references. The claim is present but lacks strong justification.", "helpfulness_rationale": "The reviewer clearly identifies a potential alternative to the authors' current approach and points out a gap in their experimentation. This directly highlights a weakness and suggests a direction for improvement. While the reviewer doesn't provide specific details on *how* to implement the alternative, they clearly articulate *why* it's a relevant consideration. The feedback is focused on a specific area for improvement and encourages further exploration. The reviewer identifies a relevant issue and suggests a potential solution, making the feedback relevant and actionable, albeit not fully detailed."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the abstract section is unclear and asks for clarification, which is a direct action. They also identify the specific terms within the unclear section ('lowrank feature subspace', 'small number of attacked samples', and 'mild assumptions'), providing concrete details on how to apply the action.", "grounding_specificity_rationale": "The reviewer identifies the specific section of the abstract that is unclear, and they even point to the specific terms within that unclear section. While they don't explicitly name a subsection, the context strongly implies it's the abstract. This is a strong form of grounding as the reviewer can accurately pinpoint the referenced part and identify the specific issues.", "verifiability_rationale": "The reviewer identifies a claim in the abstract regarding the abstract's clarity and provides a suggestion for improvement by asking for clarification or definitions of the mentioned terms. This claim is directly supported by the reasoning and suggestions provided.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the abstract and provides a specific and actionable suggestion to improve it. They ask for clarification on specific technical terms, which directly addresses a potential bottleneck for the author."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential area for improvement (complexity of Algorithm 2) but lacks specific details on how to achieve this. It doesn't explicitly state what aspects of complexity need improvement or suggest concrete modifications. Therefore, while it points towards an actionable direction, the specific steps are missing, making it less actionable than a comment that provides more detail.", "grounding_specificity_rationale": "The comment mentions 'Algorithm 2' but doesn't specify which part of the algorithm or what aspect of its complexity is being considered. This lack of specificity means the authors cannot immediately pinpoint the area of improvement, making the grounding weak. While the comment identifies a potential area, the lack of detail prevents full grounding.", "verifiability_rationale": "The review point is a statement of observation ('It seems...') and does not contain a claim that requires verification. Therefore, it doesn't fit into the categories of claim verification and is classified as 'X'.", "helpfulness_rationale": "The comment identifies a potential area for improvement (complexity of Algorithm 2) but lacks specific details on how to achieve this. While it suggests a direction for the authors to consider, it doesn't provide concrete steps or guidance on how to make the algorithm more complex. This makes it 3 in highlighting a direction but less so than a comment that offers more specific advice."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their disagreement with a claim made in the appendix (D.4) regarding the necessity of smaller architectures for language models (LMs) compared to GANs to avoid overfitting. They also ask a specific question about whether dropout is applied to the hidden states, which is a direct action the authors should take to investigate and potentially address this issue. The reviewer provides a counterexample (Zaremba et al. 2014) to support their claim, making the action quite explicit.", "grounding_specificity_rationale": "The reviewer explicitly references section D.4 of the appendix, which is a strong form of grounding. They also specify the potential reason for the discrepancy (the GAN model) and ask a very specific question about the regularization technique (dropout on hidden states). This level of detail in both identifying the issue and suggesting a direction for investigation makes the grounding very specific.", "verifiability_rationale": "The reviewer makes a claim that the baseline models are not properly regularized, which requires verification. They provide a counterexample (Zaremba et al. 2014) to support their claim. They also ask a specific question about the regularization technique (dropout on hidden states), which is a logical reasoning step to investigate their claim. While the claim itself is not fully verified within the review point, the supporting evidence and the specific question make it 3.", "helpfulness_rationale": "The reviewer's point is directly related to the appendix and challenges a potentially important finding. Their question about hidden state dropout is a clear direction for the authors to investigate and potentially improve their model. The reviewer's expertise ( mentioned in the review point) adds weight to their feedback, making the feedback potentially very helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Weakly Specific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point is somewhat vague. While it mentions 'ablations' and 'following contents', it doesn't explicitly state what actions or improvements are being suggested. The reviewer is pointing out a potential issue but doesn't provide concrete steps on how to address it. The lack of specificity makes it difficult for the author to understand the nature of the ablations and where to focus their attention. The reviewer is essentially stating a concern without providing actionable information.", "grounding_specificity_rationale": "The review point is 1. The reviewer refers to 'ablations' and 'following contents' without specifying which section or aspect of the paper is being discussed. They are making a general statement about the difficulty in locating ablations and the poor writing in the 'following contents' without pointing to a specific location. This lack of specificity makes it impossible for the author to pinpoint the issue and understand the reviewer's concern.", "verifiability_rationale": "The review point is 1. The reviewer states a concern about the difficulty in locating ablations and the poor writing in the 'following contents' without providing any evidence or justification. They are making a claim but not supporting it with logical reasoning, common knowledge, or external references. The reviewer is stating an opinion without backing it up, which doesn't provide any helpful information to the author.", "helpfulness_rationale": "The review point is 2. The reviewer identifies a potential issue but fails to provide any concrete suggestions or actions. They are pointing out a problem but don't offer any guidance on how to address it. The lack of specific information makes it difficult for the author to take any meaningful steps based on this review. The reviewer is essentially stating a concern without offering any actionable information."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'I think the authors should think through it more clearly' regarding the differential privacy application. While the action is somewhat vague, it clearly indicates a direction for improvement, making it 3. The reviewer suggests a specific area of focus (thinking more clearly), which provides a direction for the authors to follow. However, the action lacks specific details on *how* to think more clearly, making it less concrete.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or application when it states 'the differential privacy application is a bit too 'halfbaked''. The reviewer is making a general comment about the state of the application. Therefore, the grounding is weak. The authors would need to infer that the comment is about the differential privacy application, but this inference is not explicitly stated.", "verifiability_rationale": "The review point contains a claim: 'the differential privacy application is a bit too 'halfbaked'' and 'the authors should think through it more clearly'. The reviewer is making a judgment about the current state of the application and suggesting a direction for improvement. However, the claim lacks specific justification or evidence. The reviewer doesn't provide any logical reasoning, common knowledge, or external references to support this assessment of the application's 'halfbakedness'. The claim is presented as an opinion without backing.", "helpfulness_rationale": "The review point provides constructive feedback and suggests specific improvements. The reviewer identifies a potential weakness in the differential privacy application ('halfbaked') and offers a direction for improvement ('think through it more clearly'). They also acknowledge the novelty of the online algorithm and robustness and suggest moving experimental results to the main paper. These suggestions are actionable and directly address potential issues or areas for improvement. The reviewer is not just pointing out a problem but also offering a solution or a way to improve the presentation."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The statement identifies a comparison between two approaches but does not explicitly instruct the authors on how to make the multilingual chainofthought more impactful. While it points to a relevant area for discussion, it lacks concrete action.", "grounding_specificity_rationale": "The terms 'multilingual chainofthought' and 'villa chainofthought' are likely grounded as they are common terms in the field. However, the comparison itself is not explicitly linked to a specific part of the authors' work, making the grounding somewhat underspecific.", "verifiability_rationale": "The statement contains a claim ('The contribution of multilingual chainofthought is incremental') but lacks specific evidence or references within this review point to support or refute it. It relies on general assumptions or prior knowledge about the relative contributions of different approaches.", "helpfulness_rationale": "The statement raises a valid point about the relative contribution of different approaches. It highlights a potential area for further investigation or discussion. However, it does not provide specific, actionable advice on how the authors can improve their multilingual chainofthought implementation, making it less helpful in terms of direct improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action: 'You should provide the METEOR results...'. This is a direct and clear instruction for the authors. The action is also concrete as it specifies 'the METEOR results' rather than a general request.", "grounding_specificity_rationale": "The reviewer mentions 'the METEOR results' which directly points to a specific part of the paper or output. This indicates strong grounding as the reviewer is very specific about what needs to be provided. The request is clear about what information is needed.", "verifiability_rationale": "The reviewer is providing a suggestion or recommendation to the authors, not making a claim that requires verification. The statement is a direct instruction, not an assertion that needs to be proven.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion to the authors. By recommending the inclusion of METEOR results, the reviewer directly addresses a potential weakness (lack of evaluation metrics) and guides the authors on how to improve their paper. This is a very helpful piece of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem of comparing Geffects of unlearning objectives studied in isolation, which is a clear and actionable point. The reviewer also identifies the potential negative impact on the generalizability of the results, providing a concrete action for the authors to consider. The reviewer mentions 'Section 4' and the 'Geffect of each learning objective independently,' which are specific parts of the paper, making the actionable point very clear.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 4' and the 'Geffect of each unlearning objective independently and in isolation.' This precise identification of the section and the specific aspect of the paper being discussed demonstrates high grounding specificity. The reviewer also mentions 'figures and parts of the paper' where the discussion occurs, further specifying the location of the issue.", "verifiability_rationale": "The reviewer raises a concern about the comparability of Geffect values across different unlearning objectives and approaches. While this is a valid concern, the reviewer does not provide specific evidence or references to external work to support this claim within the review point. The statement is presented as a potential issue rather than a definitively supported claim.", "helpfulness_rationale": "The reviewer raises a valid point about a potential limitation of the experimental design, specifically the comparison of Geffects when unlearning objectives are studied in isolation. This is a relevant concern for the authors and highlights a potential confound in the interpretation of the results. While it doesn't directly provide a solution, it prompts the authors to consider the broader context and potential interactions between unlearning objectives."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point is a question asking for clarification rather than a directive suggestion. It does not explicitly state what the author should do or how they should apply the information. The reviewer is asking 'Have the author(s) thought about the reason why...'. This is a probing question, not a directive action.", "grounding_specificity_rationale": "The reviewer refers to 'information value is a stronger predictor' without specifying which part of the paper this relates to. They are asking 'is there any already existing linguistic theory which could explain it.' This question is general and does not identify a specific section, table, figure, or unique aspect of the paper being addressed. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point presents a claim: 'Have the author(s) thought about the reason why, information value is a stronger predictor...'. This is a statement that could be argued or proven. However, the reviewer does not provide any evidence, reasoning, or references to support why this is true. The claim is presented without sufficient justification or examples, making it 1.", "helpfulness_rationale": "The review point is a question seeking clarification about the reasoning behind a claim, not a suggestion for improvement or a request for action. While relevant to the paper's topic, it does not directly help the author improve their draft. It is more of a request for more information about the existing work rather than a constructive suggestion for change."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of discussion on future architecture design and asks a direct question about the 'biggest takeaways'. This indicates an explicit action the authors could take to improve their draft by focusing on this area.", "grounding_specificity_rationale": "The reviewer mentions 'AutoML approaches' and then narrows down the discussion to 'future architecture design'. This strong focus on a specific part of the paper demonstrates good grounding. They also ask for the 'biggest takeaways', which specifies the information needed.", "verifiability_rationale": "The reviewer states their belief that the comment is 'highly valuable' for understanding future architecture design. This is a claim that could be supported by logical reasoning or references, making it 3. However, the paper itself doesn't provide evidence to support this claim, making it 2.", "helpfulness_rationale": "The reviewer clearly states their need for information on how AutoML can inform future architecture design. This is a direct and actionable need, making the review 3. However, the review itself doesn't provide the information, limiting its full helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that T_a(t) is used in Section 3.1 but is only defined in Section 4. This constitutes an explicit action the authors should take: to check Section 3.1 and ensure they understand the usage of T_a(t) before proceeding. The reviewer also points out that the definition is missing entirely, which makes the action somewhat vague as the authors need to infer where to find the definition. However, the reviewer's intent is clear, making the action relatively concrete. The reviewer is also implying that the definition should be in Section 3.1 for clarity, which is an implicit action.", "grounding_specificity_rationale": "The reviewer explicitly states that T_a(t) is used in Section 3.1. This allows the authors to precisely identify the section where the variable is being used. Furthermore, the reviewer points out that the variable is *not* defined in Section 3.1, but rather in Section 4. This allows the authors to precisely identify the section where the definition is located. Therefore, the grounding is fully specific.", "verifiability_rationale": "The reviewer is not making a claim about the correctness of the paper's content. They are pointing out a potential issue with clarity and consistency. Therefore, the claim extraction would be 'X' (X). Since there is X being made, there is no need to verify its verifiability in the traditional sense. However, the reviewer's suggestion to define T_a(t) in Section 3.1 for clarity could be considered a form of implicit justification or reasoning, making it 2.", "helpfulness_rationale": "The reviewer points out a potential source of confusion for the authors. If the definition of T_a(t) is not in Section 3.1, where it is used, it could lead to misunderstandings or difficulties in implementing the work. While the reviewer is not directly criticizing the paper's content, they are highlighting a potential issue with the authors' own understanding or organization. Therefore, it is 3 as it points out a potential area for improvement in the authors' own work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the need for conciseness and the inclusion of empirical results, which are direct actions. However, they do not specify *how* to achieve these changes, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to the 'main part' and 'introduction part' generally. While they imply a specific area, they do not pinpoint a unique element or explicitly state the section number or heading. This indicates weak grounding. The suggestions to make the introduction more concise and include empirical results are specific in *what* to do but not *where* or *how*.", "verifiability_rationale": "The reviewer makes a judgment about the introduction being wordy and suggests adding empirical results. This constitutes a claim. However, they do not provide any logical reasoning, common knowledge, or external references to support why the introduction is wordy or why empirical results would make it concise. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the introduction (wordiness) and offers a constructive suggestion (including empirical results). This has the potential to be helpful. However, the lack of specificity about the wordiness of the introduction and the mechanism by which empirical results would improve conciseness makes the feedback less impactful and less helpful overall."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states the paper's contribution is 'an incremental advancement in efficiency over the TACTiS approach.' While this identifies a potential improvement, it doesn't explicitly state what needs to be done to achieve this. The reviewer suggests 'more substantial evidence or arguments are needed,' which implies a lack of clear action. The action is implied but not explicitly stated or detailed.", "grounding_specificity_rationale": "The review point mentions 'the paper's primary contribution' and 'TACTiS approach.' However, it does not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The grounding is implied but not precise.", "verifiability_rationale": "The review point contains the claim 'the paper's primary contribution seems to be an incremental advancement in efficiency over the TACTiS approach' and 'more substantial evidence or arguments are needed.' While the claim about the contribution is stated, the claim about the need for more evidence is not supported by any specific examples, references, or logical reasoning. The claim is made but not verified.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper's contribution and suggests the need for more evidence. However, it does not provide any specific recommendations or actionable steps for the authors to take. The feedback is identified but not followed through with concrete suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states their opinion about the paper's contributions and suggests a minor improvement. This indicates an explicit statement. However, the suggestion is broad and lacks specific details on what constitutes a \"more significant improvement.\"", "grounding_specificity_rationale": "The reviewer refers to \"different datasets\" and \"this topic\" without specifying which ones or providing context within the paper. They are making a general statement about the overall work. This indicates a lack of grounding.", "verifiability_rationale": "The reviewer makes a claim about the paper's limitations and suggests a minor improvement. They do not provide any specific examples, references, or logical reasoning to support their claim. This makes the claim 1.", "helpfulness_rationale": "The reviewer's comment is primarily opinionated and lacks concrete, actionable feedback. They identify a potential weakness but don't offer specific steps for the authors to take to address it. The feedback is general and doesn't provide much guidance. Therefore, it's not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states 'Only marginal improvements over baselines,' which is an explicit action. However, the reviewer does not specify *how* the improvements are marginal or *what* aspects of the method are improved. The action is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer states 'Only marginal improvements over baselines,' which attempts to ground the comment by referencing the comparison to baselines. However, the comment does not specify *which* method or *specific aspect* of the method shows marginal improvement. The grounding is weak because the referenced part is not precisely identified.", "verifiability_rationale": "The reviewer claims 'Only marginal improvements over baselines' and 'the error range is rather high, suggesting that the performance differences between some methods are not very significant.' This statement contains a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The verifiability verification methods are not met as there is no justification provided.", "helpfulness_rationale": "The reviewer's comment is a statement about the performance of a method compared to baselines. While it highlights a weakness ('marginal improvements'), it lacks actionable insights or specific details to help the author improve their method. The comment is vague and does not provide concrete suggestions or guidance."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states an intention ('how to make...') but doesn't provide explicit steps or criteria for achieving this. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer mentions 'more diverse' and 'representative' but doesn't specify which part of the paper or method these terms refer to. The selection of 'representative images' is also 1 in a specific section or element of the paper.", "verifiability_rationale": "The reviewer states a lack of clarity ('It is still unclear...') but doesn't provide any evidence or justification for this claim. There are no logical reasoning, common knowledge, or external references provided to support the statement.", "helpfulness_rationale": "The reviewer identifies a specific area of confusion ('how to make...') and suggests a need for more information ('how to select'). This provides a clear direction for improvement, making the comment 3. However, the lack of specific details about the desired diversity, representativeness, or selection criteria limits the potential impact."}
{"actionability_label": "4", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing elements: 'a background section to introduce the basic RL framework' and 'a brief overview of the original DPO algorithm'. These are direct and actionable suggestions for the authors.", "grounding_specificity_rationale": "The reviewer explicitly states the missing element: 'the basic RL framework'. This is a very specific part of the paper that is being addressed.", "verifiability_rationale": "The reviewer provides a clear suggestion for improvement by stating 'include a background section' and 'provide a brief overview of the original DPO algorithm'. While it doesn't provide a *justification* for why this is important, it does point to a concrete next step for the authors.", "helpfulness_rationale": "The reviewer directly points out the missing information that would be beneficial for the authors to understand the context and the modifications being proposed. The suggestions are clear and directly address the identified gaps."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out a potential limitation, which can be interpreted as an implicit suggestion for concern. While the reviewer identifies a potential issue, they do not explicitly state a concrete action or solution for the authors. The authors are not guided on how to address this potential limitation. The action is implied but not directly stated or actionable.", "grounding_specificity_rationale": "The reviewer mentions a potential limitation of the proposed method but does not specify which part of the paper or method this limitation refers to. The reference is general and does not identify a specific section, table, figure, or unique aspect. The grounding is implied but not explicitly stated.", "verifiability_rationale": "The reviewer states a potential limitation of the proposed method but does not provide any evidence, analysis, or examples to support this claim. The claim is presented as a possibility without any logical reasoning, common knowledge, or external references. The verifiability is low as there is no justification provided for the claim.", "helpfulness_rationale": "The reviewer points out a potential problem with the proposed method but does not offer any solutions or further analysis. While the reviewer highlights a concern, they do not actively help the authors improve their draft by suggesting concrete actions or providing information to address the potential limitation. The feedback is presented as a problem without offering any active improvement suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states an inconsistency in the description of the S2D structure regarding the number of parameters. They point out that if kernel height/width remain the same, increasing depth should increase the number of parameters. This is a clear and direct action the reviewer is taking, identifying a potential ambiguity in the paper's explanation. The reviewer then offers an alternative scenario (FLOPs being quadratic on activation side length) and concludes that more details are needed regarding parameters. This demonstrates a clear understanding of the potential issue and a desire to resolve it, making the action explicit.", "grounding_specificity_rationale": "The reviewer refers to 'S2D structure' and 'the number of parameters' as the specific parts of the paper being addressed. While they don't provide a specific section or table number, the concept is quite localized. The reviewer clearly identifies the issue and the specific aspect of the S2D structure that is causing confusion. The comment is explicit about the relationship between kernel dimensions and depth/parameters. The reviewer also specifies what is missing \u2013 'more details are expected' regarding parameters. This demonstrates a clear grounding of the comment in the specific aspect of the paper being discussed.", "verifiability_rationale": "The reviewer makes a claim: 'In S2D structure, it is not clear why the number of parameters does not change.' They then provide a logical reasoning: 'If the kernel height/width stay the same, then its depth will increase, resulting in more parameters.' This reasoning is sound and directly addresses the reviewer's claim. The reviewer also provides an alternative perspective: 'I agree the efficiency could be improved since the FLOP is quadratic on activation side length.' This further supports their claim and suggests a potential solution (more details on parameters). The claim is thoroughly supported by explicit reasoning and examples, making it 5.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential point of confusion for the authors regarding the S2D structure. They identify a specific inconsistency in the explanation of parameter consistency and request more details. This is a valuable piece of feedback as it highlights a potential area where the authors might be struggling to understand the method. By pointing out this ambiguity, the reviewer empowers the authors to clarify their understanding and potentially improve the efficiency of their implementation. While the reviewer doesn't propose a solution, they do identify a clear area for improvement in the paper's explanation, making the feedback helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a potential improvement to an existing method and asks a question. While it implies an action (implementing the extension), it doesn't explicitly state it, making it partially actionable.", "grounding_specificity_rationale": "The review point explicitly mentions '10' by name, providing clear grounding. It also refers to 'scoring causal predictions' and 'interventional data', which are specific technical terms within the context of machine learning or methods. Therefore, it is 5.", "verifiability_rationale": "The review point contains a claim ('The proposed method is very similar in spirit to the approach in 10...') and provides some justification ('It seems that the method in 10 can also be equipped with scoring causal predictions and the interventional data'). However, the reasoning for the 'why 10 cannot use these side information?' part is missing, making it partly verifiable.", "helpfulness_rationale": "The review point identifies a potential improvement to an existing method and asks a question. While it points out a relevant area for further exploration, it doesn't directly explain why the existing method cannot be extended or how the proposed method would be different. This makes the feedback 3 but lacking in direct guidance, leading to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies an implicit action: the need to interpret the Atari game results. However, it doesn't explicitly state how to do this or what steps should be taken. The lack of explicitness makes it 2.", "grounding_specificity_rationale": "The reviewer mentions 'a single game' and 'a single baseline' in the context of Section 7.2. While it points to a specific section, it doesn't explicitly identify the exact game or baseline. Therefore, it's not fully grounded. The lack of specificity in the game and baseline makes it weakly grounded. The specificity is also underspecified as the reviewer doesn't detail what is missing in the referenced part.", "verifiability_rationale": "The review point contains a claim: 'It is very hard to interpret this.' However, this claim is not supported by any logical reasoning, common knowledge, or external references. The statement is based on the reviewer's assessment of the situation.", "helpfulness_rationale": "The review point identifies a limitation in the experimental setup (single game, single baseline) and states that it makes the results 'very hard to interpret.' While this points to a potential issue, the reviewer does not provide specific suggestions or guidance on how to address it. The feedback is about a lack of information, which is somewhat vague."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: 'the presentation of the simulation study is not really doing a favor to the authors'. They also explicitly state the lack of explanation for GPC outperformance: 'specifically, the authors do not really comment on why the GPC (benchmark) is performing better than BPC (their method)'. Furthermore, the reviewer offers a potential explanation: 'It would be worth reiterating that this is b/c of the bandit feedback and not using information about the form of the cost function.' This provides a clear action for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the presentation of the simulation study' and specifically focuses on 'why the GPC (benchmark) is performing better than BPC (their method)'. They also state that 'the authors do not really comment on why the GPC (benchmark) is performing better than BPC (their method)'. This precise identification of the area needing improvement demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer makes a claim: 'the authors do not really comment on why the GPC (benchmark) is performing better than BPC (their method)'. This claim is verifiable by examining the paper and finding the lack of explanation. The reviewer also provides a suggestion: 'It would be worth reiterating that this is b/c of the bandit feedback and not using information about the form of the cost function.' This suggestion provides a potential justification for the observed performance difference, making the claim 3.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'It would be worth reiterating that this is b/c of the bandit feedback and not using information about the form of the cost function.' This directly addresses a potential weakness in the authors' explanation and provides a concrete direction for them to improve their understanding and potentially their method. This suggestion is directly aimed at helping the authors improve their work."}
{"actionability_label": "Medium", "grounding_specificity_label": "High", "verifiability_label": "Low", "helpfulness_label": "Medium", "actionability_rationale": "The reviewer explicitly states 'In Figure 1, the reported perplexities are over 30.' This directly points to a specific area of the paper (Figure 1) and a specific metric (perplexities) that needs attention. While the reviewer doesn't explicitly state what action needs to be taken, the identification of the issue is clear. The reviewer also mentions 'This high perplexity contradicts better BLEU scores in my experience,' which implies a potential problem that needs investigation. The reviewer identifies a discrepancy that requires further analysis.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 1' and the metric 'perplexities.' This indicates a clear identification of the specific part of the paper being addressed. The reviewer doesn't mention any ambiguity about which figure or metric is being referred to. The connection to a figure strongly suggests a specific location in the paper. The reviewer also points out a potential contradiction with BLEU scores, which further specifies the issue being addressed within the figure. The reviewer is quite specific about the location and the metric they are referring to.", "verifiability_rationale": "The reviewer states 'In Figure 1, the reported perplexities are over 30' and 'This high perplexity contradicts better BLEU scores in my experience.' These statements are claims that need to be supported. However, the reviewer does not provide any evidence or explanation within the review point itself to support these claims. The reviewer simply states the observation. There is no logical reasoning, common knowledge, or external references provided to back up the claim about the high perplexity and its contradiction with BLEU scores. Therefore, the claim is not verifiable based solely on the information provided in this review point.", "helpfulness_rationale": "The reviewer identifies a potential issue with the reported perplexity metric in Figure 1. They point out a discrepancy between the perplexity values and the BLEU scores, which are generally considered more indicative of translation quality. This discrepancy raises a valid concern about the reliability of the perplexity metric in this context. While the reviewer doesn't explicitly state what needs to be done, they have pointed out a potential problem that the authors should investigate. By highlighting this inconsistency, the reviewer provides a direction for the authors to look for potential errors or misunderstandings in the reported metrics. However, the lack of specific guidance on how to address the issue makes the review point somewhat less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the need for 'experiments on distributed deployment' and 'a larger model'. These are direct instructions on what the authors should do. While the reviewer doesn't specify *how* to do these, the actions are clear. This fits the definition of explicit actions.", "grounding_specificity_rationale": "The review point mentions 'distributed deployment' and 'a larger model' without specifying the exact sections, tables, or unique elements of the paper that require these changes. While it points to specific areas of the paper, it doesn't provide precise details. This falls under the category of 'Weak Grounding' as the authors can make an educated guess but cannot precisely identify the referenced part.", "verifiability_rationale": "The review point contains a claim: 'The evaluation needs experiments on distributed deployment and a larger model'. This is a suggestion or request for improvement. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support why these changes are necessary or beneficial. The claim is presented without sufficient justification.", "helpfulness_rationale": "The review point identifies a limitation in the evaluation process \u2013 the lack of experiments on distributed deployment and the absence of a larger model. While this points out a gap in the evaluation methodology, it doesn't directly provide actionable feedback on how to improve the work being evaluated. It suggests *what* the evaluation *should* include, rather than *how* to improve the authors' work directly. Therefore, it is not 5 in improving the authors' specific draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors need to 'elaborate on why it is important for the patterns to be rooted' and 'how they choose the roots'. This provides a clear direction for the authors to improve their draft. While the reviewer doesn't specify *what* is important or *how* to choose roots, they identify a gap in the authors' explanation, which is actionable.", "grounding_specificity_rationale": "The review point clearly identifies the concept of 'rooted patterns' and its importance in the context of GSN. It also specifies the 'GSN' method and the issue of 'lack of justification for rootedness and root selection'. This provides a precise point of reference within the authors' work, making it highly grounded. Furthermore, the point directly addresses a specific aspect of the method (root selection), making it specific.", "verifiability_rationale": "The review point is a critique of the authors' presentation and does not contain a claim that requires verification. It is a statement of observation about the lack of detail in the authors' explanation. Therefore, it does not fall under the category of verifiable claims.", "helpfulness_rationale": "The review point directly addresses a potential weakness in the authors' method description (lack of justification for rooted patterns and root selection) and offers a clear direction for improvement (elaborate or discuss alternatives). This is a valuable piece of feedback that can help the authors improve their work. The suggestion to discuss nonrooted patterns in the supplementary material further enhances the helpfulness by narrowing the scope of the critique."}
{"actionability_label": "2", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests \"It will be good to see some failure cases and related discussion\" but does not specify how to achieve this. The action is implied but not explicitly stated. The reviewer desires more content but lacks a clear direction or steps for improvement. The suggestion is vague and doesn't offer concrete guidance.", "grounding_specificity_rationale": "The review point is a general suggestion about the overall quality and discussion of the paper, without referencing a specific section, table, figure, or unique element. The grounding is weak because the reviewer is making a broad statement rather than focusing on a particular aspect. The reviewer is suggesting improvements to the paper as a whole, but doesn't pinpoint where these improvements should be made.", "verifiability_rationale": "The review point contains a claim (\"It will be good to see some failure cases and related discussion\") but does not provide any specific evidence, references, or logical reasoning to support this suggestion. The claim is presented without justification. The suggestion is presented as a desired outcome rather than a claim supported by evidence.", "helpfulness_rationale": "The review point is a suggestion for improvement, which is a positive direction. However, it lacks the specificity and actionability needed to be truly helpful. It doesn't tell the authors what to add or how to connect the discussion. While the suggestion is constructive, it doesn't provide concrete steps or specific areas for improvement, making it less impactful than a more detailed review."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a potential issue (unclear why there is a base layer GNN encoding) but doesn't specify what needs to be done regarding this issue. They are asking 'why' but don't provide a clear action for the authors to take. The action is implicit \u2013 the authors are supposed to figure out the purpose of the base layer GNN encoding. This fits the borderline because the action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed method' without specifying a particular section, table, figure, or unique aspect of the method. They are asking for clarification on the general concept rather than a specific part.", "verifiability_rationale": "The review point is a question, not a claim that needs verification. It's a request for clarification, not a statement that needs to be proven.", "helpfulness_rationale": "The reviewer identifies a potential issue (unclear purpose of the base layer GNN encoding). However, they don't offer specific suggestions or detailed explanations of why this is a problem. The feedback is present but lacks actionable steps for the authors. They are asking 'why' but not providing a solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem of the lack of discussion on computational complexity and provides concrete suggestions for improvement, such as 'stating the upper bounds of counting' and 'elaborating on empirical runtimes'. These suggestions directly address the identified issue and provide clear directions for the authors to follow. The reviewer does not leave the authors to infer what needs to be done, making the action explicit. The suggestions are also concrete, providing specific actions the authors can take.", "grounding_specificity_rationale": "The reviewer mentions 'computational complexity' and 'homomorphism counts', directly referencing the relevant concepts in the paper. They also point to a specific line (145) where the authors discuss the topic. This precise identification of the area and the specific issue demonstrates strong grounding. The reviewer not only identifies the section but also highlights a specific weakness within that section.", "verifiability_rationale": "The reviewer makes a claim that the authors 'do not adequately discuss the computational complexity of counting homomorphisms'. This is a clear statement of a deficiency. The reviewer then provides suggestions for improvement, such as 'stating the upper bounds of counting' and 'elaborating on empirical runtimes', which can be considered as evidence or reasoning supporting the claim. While the reviewer doesn't provide a citation to external work, the suggestions are logical and procedural, making the verifiability somewhat strong.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement by pointing out the lack of discussion on computational complexity and offering concrete steps the authors can take to address this. The reviewer's suggestions are directly relevant to the authors' work and are likely to be helpful in improving their draft. The reviewer's comment is not vague or general, and it directly addresses a specific issue."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a missing element (inference time study) and provides a reason (direct nature of the method) for its absence. However, they do not explicitly state how to conduct the study or what specific actions should be taken. The suggestion to compare inference speed to other methods is a good starting point but lacks concrete details.", "grounding_specificity_rationale": "The reviewer does not explicitly identify a specific part of the paper or method being addressed. They are making a general observation about the method's characteristics and suggesting a comparison to other methods without specifying which ones. The comment is vague and does not pinpoint the issue.", "verifiability_rationale": "The reviewer makes claims about the method being direct and not requiring detection or keypoint grouping, and suggests comparing inference time to other methods. While these claims can be verified (if the method is indeed direct and the other methods exist), the reviewer does not provide specific references, examples, or external work to support these claims. The suggestion to compare inference time is a good idea but lacks the necessary evidence to be 5.", "helpfulness_rationale": "The reviewer points out a valid potential improvement (studying inference time) and provides a rationale for it. They highlight the importance of this aspect for practical applications. While the suggestion is relevant and constructive, it lacks specific actionable steps or concrete examples of how the inference time study should be conducted. The comment is generally helpful but could be more detailed."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their disagreement with the paper's claim about evolutional dropout and provides a specific reason: 'can only increase the variance of some lowvariance units.' This indicates a clear and actionable point of contention. While the reviewer doesn't directly suggest a solution, the specific limitation they identify provides a clear direction for the authors to consider alternative approaches like batch normalization.", "grounding_specificity_rationale": "The reviewer's comment is 1 in a specific section, table, or figure of the paper. They are commenting on a general claim made in the paper regarding evolutional dropout. While the reviewer identifies a specific limitation ('can only increase the variance of some lowvariance units'), this limitation is presented as a general critique of the paper's claim, rather than a precise reference to a specific part of the paper. The reviewer is inferring the location of the issue rather than explicitly pointing to it.", "verifiability_rationale": "The reviewer presents a claim: 'In my opinion the claim about evolutional dropout addresses the internal covariate shift is very limited...'. This claim is supported by the reviewer's reasoning, which includes specific limitations of the paper's claim and suggests an alternative (batch normalization). The reviewer provides logical reasoning and specific examples (variance increase in lowvariance units) to support their claim.", "helpfulness_rationale": "The reviewer's comment is helpful because they identify a potential limitation in the paper's understanding of dropout and suggest a concrete alternative (batch normalization). While the comment is brief, it clearly points out a specific area for improvement and offers a direction for the authors to explore. The reviewer's specific limitation ('can only increase the variance of some lowvariance units') provides a clear starting point for the authors to investigate further."}
{"actionability_label": "2", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X (X)", "helpfulness_label": "2", "actionability_rationale": "The comment suggests adding more description, which is an implicit action. It lacks specific instructions on *how* to add this description.", "grounding_specificity_rationale": "The comment refers to the 'contribution of this paper' broadly, without specifying a section, table, figure, or unique element. It doesn't detail *what* aspect of the contribution needs more description.", "verifiability_rationale": "The comment is a suggestion, not a claim requiring justification or evidence. There's no logical reasoning, common knowledge, or external references involved.", "helpfulness_rationale": "The comment identifies a valid need for more detail but lacks specific guidance on *how* to achieve this. It's a suggestion, not a directive, making it less helpful than a comment that provides concrete steps."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides clear, explicit suggestions for improving the organization of the paper. The suggestions are concrete, detailing specific actions the authors should take, such as adding a section for attention mechanisms and referencing common techniques. These suggestions directly point to actionable steps the authors can implement to enhance their work.", "grounding_specificity_rationale": "The reviewer explicitly identifies the areas where improvements are needed, specifically mentioning the layerwise attention mechanism and common techniques like normalization. They implicitly refer to sections 2.3 and 2.4 for the attention mechanism. The suggestions are specific about what needs to be done, such as adding a section or referencing techniques. This demonstrates a clear understanding of where the authors are and what improvements are being proposed.", "verifiability_rationale": "The reviewer's suggestions are not claims that require verification. They are recommendations for improving the paper's structure and clarity. There are no logical reasoning, common knowledge, or external references provided to support these suggestions. The reviewer is not stating that something is correct or incorrect, but rather suggesting where to place information or what to reference. Therefore, there is no verifiable information being presented in this review point.", "helpfulness_rationale": "The reviewer's suggestions are relevant and address potential areas for improvement in the paper's structure and clarity. They provide concrete actions the authors should take, such as adding a section for attention mechanisms and referencing common techniques. These suggestions are directly helpful in improving the presentation and organization of the paper, making them actionable and constructive for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states a fact ('Performance differences between methods are minimal') and offers a potential explanation ('less than 1 percentage point'). While it points to a *difference*, it doesn't explicitly *recommend* an action or provide a concrete next step for the authors. It's more of an observation than a direct instruction. The statement about the percentage difference is explicit, but the advice to 'reconsider the benchmarks' is implicit and lacks concrete guidance.", "grounding_specificity_rationale": "The review point refers to 'Performance differences between methods' and 'benchmarks selected.' It doesn't explicitly identify a specific part of the paper being discussed. The reviewer is commenting on the *results* of the methods and the *choice of benchmarks*, but not on a specific element within a method or benchmark description itself.", "verifiability_rationale": "The review point makes a claim ('Performance differences between methods are minimal') and offers a potential reason ('less than 1 percentage point'). This constitutes a claim, specifically a judgment about the performance differences. The reviewer provides a *potential* explanation (random variation) and mentions the benchmarks being 'outdated and likely saturated.' These are suggestions for *why* the differences might exist, but they aren't definitive proofs or citations to external sources.", "helpfulness_rationale": "The review point points out a potential issue (minimal differences) and offers a possible explanation (random variation and saturated benchmarks). While it raises a valid concern, it doesn't offer a concrete solution or actionable advice for the authors. It's more of a diagnostic statement than a prescriptive one. The reviewer identifies a potential problem with the experimental setup or interpretation of results but doesn't offer a clear path forward for the authors. The suggestions are vague and don't provide specific guidance on how to address the issue."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "1", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer provides several explicit suggestions for improvement. They directly ask why the method works on deterministic systems, suggest evaluating on stochastic environments, and point out the missing BEAR baseline. These are clear actions the authors can take to address the concerns raised.", "grounding_specificity_rationale": "The reviewer's comments are general and do not specify a particular part of the paper they are referring to. They are broadly commenting on the method's applicability and the experimental setup. While they identify potential issues (missing baselines, lack of empirical benefit), they don't pinpoint the exact location of these problems within the paper.", "verifiability_rationale": "The reviewer makes several claims, such as questioning the method's novelty on deterministic systems and suggesting evaluating on stochastic environments. However, they do not provide any logical reasoning, common knowledge, or external references to support these claims. The claims are presented as questions and suggestions without justification.", "helpfulness_rationale": "The reviewer's comments are constructive and point towards improving the method's evaluation and understanding its limitations. They suggest evaluating on stochastic environments and addressing the missing BEAR baseline. While the suggestions are valuable, the lack of verifiability might make their impact less certain."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests a concrete action: 'cotraining and weight averaging can improve results'. This directly points to a specific technique and implies a need for explanation regarding how these methods work. The reviewer is not just asking for more details on a general area but specifically on the mechanisms behind the potential improvements. The use of 'can' suggests a possibility, but the reviewer is asking for a justification of this potential. The reviewer is also mentioning 'theocratical justification', which, while unusual, implies a specific type of reasoning that needs to be provided. This suggests a clear action the authors should take.", "grounding_specificity_rationale": "The reviewer mentions 'cotraining and weight averaging', which are specific techniques. This indicates a level of grounding as the reviewer is not just referring to a general area of the paper but specific methods. However, the reviewer does not explicitly state which section, table, or figure these techniques are related to. While the techniques are named, the exact location or context within the paper is not clearly identified. The reviewer is also mentioning 'theocratical justification', which is a general concept and does not point to a specific part of the paper. Therefore, while the techniques are named, the exact grounding within the paper is weak.", "verifiability_rationale": "The reviewer makes a claim: 'It would be better if the author could provide some theocratical justification in terms of why cotraining and weight averaging can improve results'. This is a statement of opinion and a requirement for improvement. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The term 'theocratical justification' is not a standard term in academic writing and lacks a clear definition within this context. The reviewer is simply stating a preference for a specific type of justification without providing evidence or a clear explanation of why it is necessary or beneficial. There is no external reference or logical argument presented to back up this claim.", "helpfulness_rationale": "The review point provides a suggestion for improvement: providing 'theocratical justification' for why cotraining and weight averaging can improve results. This is a specific type of feedback that encourages the authors to elaborate on the reasoning behind these methods. While the reviewer does not provide a concrete solution or evidence to support their claim, the suggestion itself is a valuable piece of feedback. It points to a potential gap in the paper's explanation and encourages the authors to provide more detailed reasoning. The reviewer is not just pointing out a weakness but suggesting a specific direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for more details about the proposed method and provides specific examples of what information is lacking: 'how the implicit distribution characterize the uncertainty of each label value and how the model mitigate the uncertainty of the label distribution.' This is a clear and direct request for information, making it 5.", "grounding_specificity_rationale": "The reviewer directly refers to a specific part of the proposed method: 'how the implicit distribution characterize the uncertainty of each label value and how the model mitigate the uncertainty of the label distribution.' This demonstrates a clear understanding of where the information is lacking and what specific details are needed, making it 5.", "verifiability_rationale": "The reviewer is suggesting improvements to the paper by requesting more details on a specific methodological aspect. While this is a valuable suggestion, it doesn't directly present a claim that requires immediate verification or support. It's more of a constructive suggestion rather than a critique containing a verifiable statement.", "helpfulness_rationale": "The reviewer's point is highly valuable as it directly addresses a potential weakness in the paper's description of the proposed method. By requesting more specific details on how uncertainty in label distribution is handled, the reviewer is providing a concrete and actionable suggestion for improving the clarity and completeness of the paper, which would be directly helpful for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a necessary condition (the Gaussian assumption of the likelihood function) that should be explicitly stated for the validity of Kalman Filtering and Smoothing and CVI. While it doesn't directly tell the author what to do, it points out a crucial missing detail that could hinder understanding and implementation. The action is implicit in pointing out the missing statement.", "grounding_specificity_rationale": "The review point explicitly refers to the likelihood function p(y | Hf_bar(tn)), which is a specific mathematical expression in the paper. This clearly identifies the part of the paper being addressed.", "verifiability_rationale": "The review point makes a claim that the Gaussian assumption for the likelihood function is a necessary condition for the applicability of Kalman Filtering and Smoothing and CVI. This claim is verifiable by understanding the requirements of these methods. The reasoning is based on the fundamental properties of Kalman filters, which rely on Gaussian noise assumptions for their optimal performance. The external reference to Kalman Filter/Smoothing and CVI is also relevant.", "helpfulness_rationale": "The review point is helpful because it highlights a potential point of confusion for the reader. While the paper might later assume a Gaussian likelihood, it's important to make this explicit earlier, especially when discussing Kalman filterbased methods. This clarification can prevent misunderstandings and ensure that the reader has a complete understanding of the assumptions underlying the methods."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point presents several suggestions for improving the paper, such as adding illustrative experiments and providing more details about the new test metric. These suggestions are clear and directly address the identified weaknesses, indicating a need for specific actions from the authors. The reviewer explicitly states what the authors should do, making it easily identifiable.", "grounding_specificity_rationale": "The review point mentions the lack of qualitative experiments and suggests providing them. While the general area of improvement is clear, the specific type of experiment, the metric, and the visualization method are not explicitly identified. The reviewer can infer the need for experiments and the concept of the new metric, but the exact implementation details are missing, making the grounding somewhat weak. The reviewer also mentions 'other metrics' for comparison, which implies a need for more specific guidance, but the exact metrics are not named, keeping the grounding underspecification.", "verifiability_rationale": "The review point states the lack of correctness testing for the proposed new test metric and comparative experiments with other metrics. While the reviewer suggests these improvements, the paper itself does not currently contain these elements. The claims about the lack of correctness testing and comparative experiments are clear and point to missing information. The reviewer does not explicitly claim that the paper contains 1 claims related to the new metric, but rather points out the lack of verification for the suggestions. The reviewer's suggestions themselves are not claims, but rather recommendations for improvement.", "helpfulness_rationale": "The review point identifies specific areas where the authors can improve their work, such as adding qualitative experiments and providing more details about the new test metric. These suggestions are clear and actionable, indicating that the reviewer has identified meaningful weaknesses and improvement areas. The reviewer's suggestions are directly linked to the identified weaknesses, making them 5. The reviewer's suggestions are not vague or general, but rather specific and concrete, making them 5. The reviewer's suggestions are directly linked to the identified weaknesses, making them 5. The reviewer's suggestions are specific and concrete, making them 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The question asks for a comparison of computational complexity, which is an explicit request for information. However, the request lacks specificity, making it difficult to know exactly what aspect of computational complexity to address and what 'other methods' are being referred to. While the intent is clear, the lack of detail hinders direct action.", "grounding_specificity_rationale": "The reviewer refers to 'other methods' without specifying which ones or pointing to a particular section of the paper. This makes it difficult to identify the specific part of the paper being addressed. The reference is broad and lacks a clear connection to a specific element within the paper's content.", "verifiability_rationale": "The review point is a question asking for information about computational complexity and a comparison with other methods. It does not contain a claim that requires verification or justification. It's a request for data or analysis.", "helpfulness_rationale": "The review point raises a valid concern about computational complexity, which is a relevant aspect for readers, especially those working with large models. However, the lack of specificity in the request makes it difficult for the authors to fully utilize this feedback. It's a relevant question but not a direct solution or suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests *specific analyses* to perform (impact of cost, reward incentives, collective return) and *specific scenarios* to explore (different alpha values, roles of winners/cooperators). However, it does not explicitly name an action to *do* next with the authors' draft. The action is implied but not stated directly.", "grounding_specificity_rationale": "The review point is general and doesn't mention a specific part of the paper. It talks about 'roles between 'winners' and 'cooperators'' and 'collective return' without linking these concepts directly to a specific section or table in the paper. The reviewer doesn't specify what aspect of the paper is being criticized or improved.", "verifiability_rationale": "The review point contains a claim: 'It seems like roles between \u201cwinners\u201d and \u201ccooperators\u201d emerge because the cost to reward the other agent becomes high for the cooperators.' This is a statement of observation based on the reviewer's understanding of the scenario. However, the reviewer does not provide any concrete evidence, references, or logical reasoning to *support* this claim. The explanation is speculative and lacks verification.", "helpfulness_rationale": "The review point suggests a *potential research direction* and raises a *specific question* about the cost of incentivization. While it offers a *general idea* for analysis, it doesn't provide concrete steps or actionable advice on *how* to conduct this analysis or what specific findings would be valuable. The suggestion is interesting and potentially valuable for researchers in the field, but it's not a direct, actionable improvement for the authors of the original paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a potential issue ('partially difficult to follow') and suggests a solution ('should be revised' and 'extend the approach description'). This is an explicit statement of a problem and a suggestion for improvement. However, the suggestion to 'extend the approach description' is vague and doesn't provide concrete steps on how the description should be revised. The lack of specific actionable steps makes the comment partially actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions '\u00a7 3' in their comment. This clearly identifies the specific part of the paper being addressed. The use of a section reference demonstrates strong grounding. While the reviewer doesn't specify *what* is wrong in section 3, they clearly indicate they are referring to a specific section. This is a clear indication of full grounding.", "verifiability_rationale": "The comment states 'The approach description (\u00a7 3) is partially difficult to follow and should be revised.' This statement makes a claim about the approach description's clarity. However, within this specific review point, there is no external reference or logical reasoning provided to support the claim that the description is 'partially difficult to follow'. The suggestion to revise it is a recommendation, but the lack of supporting evidence makes the claim 1.", "helpfulness_rationale": "The review point identifies a potential area for improvement in the approach description and suggests a concrete action (using the extra page for extension). This is a constructive comment aimed at improving the paper. The suggestion to 'extend the approach description' directly points to a specific improvement. While the initial comment about difficulty is vague, the suggestion to improve is a clear and helpful direction for the authors. The comment is likely to be beneficial for the authors in refining their approach."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out two specific areas for improvement: the lack of interpretive insights in the discussion and the absence of comparisons with other stateoftheart methods. While the reviewer clearly states these as problems, they do not provide specific, actionable steps on how to address them. For example, they don't suggest what kind of interpretive analysis would be beneficial or which specific existing methods should be compared against.", "grounding_specificity_rationale": "The reviewer refers to the 'experiments part' generally when mentioning the lack of interpretive insights and comparisons. They do not specify which section, table, figure, or unique element within the experiments section is lacking these aspects. While the content is implied to be lacking specificity, the *section* itself isn't explicitly identified.", "verifiability_rationale": "The reviewer makes claims about the experiments lacking interpretive insights and comparisons with other stateoftheart methods. However, they do not provide any logical reasoning, common knowledge, or external references to support these claims. The statements are presented as observations without justification.", "helpfulness_rationale": "The reviewer provides specific feedback about the content of the experiments section, highlighting the lack of interpretive insights and comparisons with other stateoftheart methods. This directly points to areas where the authors could improve their work by adding more analysis and context to their experiments. The feedback is directly actionable and addresses specific issues within the paper."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their desire to see 'more details' about the baselines in Figure 5, which can be interpreted as an implicit request for an action. However, the specifics of what constitutes 'more details' are not provided, making the action vague. Therefore, while the reviewer indicates a need for information, the lack of clarity in how to obtain it makes the action implicit and vague.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 5' as the target of their comment, demonstrating strong grounding. However, the specifics of what is 'hard to comprehend' in the figure and what details are needed are not specified, making the specificity of the issue vague. Therefore, the comment identifies the section but doesn't pinpoint the exact problem or solution within that section.", "verifiability_rationale": "The reviewer makes statements about the clarity of Figure 5 and the need for more details about the baselines. These statements can be considered claims that require justification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. Therefore, the claims are presented without sufficient evidence or justification.", "helpfulness_rationale": "The reviewer identifies a genuine issue (clarity of Figure 5 and lack of baseline details) and suggests a concrete improvement (providing more details). However, the comment lacks the specifics needed to be fully helpful. The reviewer *wants* to improve the paper, but the feedback is not fully realized due to the missing details. Therefore, while the feedback is relevant, the lack of specific information makes it less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the need for a 'more explicit and comparative' analysis of related work. This directly points to an action the authors should take. However, the reviewer does not specify *how* they envision this explicit and comparative analysis to be conducted, making the action only somewhat concrete.", "grounding_specificity_rationale": "The review point directly addresses the 'unclear literature review' and mentions 'utilization of GFlowNet for sequence generation'. This allows the authors to identify the specific area of the paper being discussed. The mention of GFlowNet also provides a degree of specificity. However, the reviewer does not specify *exact* sections or elements within the literature review that are unclear or *specific* issues related to GFlowNet that need clarification.", "verifiability_rationale": "The review point states 'The literature review in the paper needs improvement.' This is a claim that requires justification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no evidence provided to back up the assertion that the literature review is indeed lacking in these specific areas.", "helpfulness_rationale": "The review point offers a constructive suggestion for improvement by asking the authors to make their contributions clearer and their novelty more apparent. This is a helpful comment as it directly points towards actionable steps the authors can take to enhance their work. However, the suggestion is somewhat general and lacks specific details, making it less impactful than a more direct critique of the writing quality."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that section 3.2 can be eliminated. This indicates a clear action or suggestion. However, the reviewer does not specify *how* this elimination should be done or what specific aspect of section 3.2 is causing this suggestion. The action is present, but it is not fully concrete.", "grounding_specificity_rationale": "The reviewer refers to 'section 3.2' in their review point. This allows the authors to identify the specific section being addressed, making the grounding explicit. However, the reviewer does not specify *what* is wrong with section 3.2, making the specificity of the comment low.", "verifiability_rationale": "The reviewer states their opinion that section 3.2 can be eliminated. This constitutes a claim. However, the reviewer does not provide any justification or reasoning for this claim. There is no logical reasoning, common knowledge, or external references provided to support this suggestion.", "helpfulness_rationale": "The reviewer suggests eliminating section 3.2. While this is a concrete action in terms of identifying the section, the reviewer does not provide any *reason* for why this section should be eliminated. The suggestion is vague and lacks a clear justification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the desired improvements: 'addition of performance on word similarity and sentence translation tasks' and 'addition of morphologically rich languages like Finnish, Hebrew, etc and lowresource languages in the experiments'. These are clear and direct actions the authors should take.", "grounding_specificity_rationale": "The review point explicitly mentions 'word similarity and sentence translation tasks' and 'morphologically rich languages like Finnish, Hebrew, etc'. This clearly identifies the specific aspects of the paper being addressed. While 'etc.' is used, it strongly implies the reviewer is referring to specific languages. The actions are also quite concrete \u2013 knowing these tasks and languages means the authors can directly focus on adding them.", "verifiability_rationale": "The reviewer is suggesting improvements to the experiments. While they are not making a definitive judgment about the current experiments, they are proposing 'addition of performance on word similarity and sentence translation tasks' and 'addition of morphologically rich languages like Finnish, Hebrew, etc and lowresource languages in the experiments'. These are claims that *could* be verified by adding those experiments. The reviewer is not providing a logical reasoning or external references to *justify* these additions, but they are stating what they believe would strengthen the paper.", "helpfulness_rationale": "The review point provides very specific and actionable suggestions for improving the experiments. The suggestions directly address potential weaknesses (the lack of these standard evaluations and language coverage) and empower the authors to make informed decisions about their experimental setup. The suggestions are also concrete, meaning the authors know exactly what they should be adding."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "Both suggestions directly propose concrete actions the authors can take to improve their draft. The first suggests adding an explanation for the link between IP and the terms/equations, and the second suggests adding labels to subfigures in Figs 3 and 4. These are clear and actionable improvements.", "grounding_specificity_rationale": "The first suggestion, 'The link between IP and the terms/equations could be explained more explicitly and prominently,' does not directly identify a specific part of the paper. It refers to a conceptual link, making the grounding weak. However, the second suggestion, 'Pls include labels for subfigures in Figs 3 and 4, and not just state in the captions,' explicitly refers to 'Figs 3 and 4' and the absence of labels, making the grounding fully specific. Since the aspect asks for the overall grounding specificity, and one part is weakly grounded, the overall grounding specificity is leaning towards '2'. However, since the reviewer provides two suggestions, it's appropriate to evaluate each individually under the grounding specificity aspect. Therefore, the first suggestion is '2' and the second is '5'.", "verifiability_rationale": "Neither suggestion makes a claim that requires verification. The first suggestion is a suggestion for improvement, implying the current explanation is insufficient, and the second is a request for a specific feature. Neither requires external references or logical reasoning to be considered valid. Therefore, both suggestions are 'X'.", "helpfulness_rationale": "Both suggestions are valuable and directly address potential areas for improvement in the paper. The first suggestion helps improve the clarity of the paper, and the second suggestion improves the readability and understanding of the figures. Therefore, both suggestions are 5."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem ('The observation and conclusions are hidden in the experimental section') but does not provide explicit instructions on how to *action* on this problem. It points out where the issue lies, but doesn't tell the authors what to do about it. The suggestion to 'highlight' is implied, but not stated as a concrete action.", "grounding_specificity_rationale": "The review point explicitly mentions 'the experimental section.' This is a clear and specific reference to a part of the paper. While the reviewer can confidently identify the section being addressed, they don't specify *which* observation or conclusion within that section is hidden. The specificity is present in the *location* but not the *exact element* within that location.", "verifiability_rationale": "The review point makes a claim ('The observation and conclusions are hidden in the experimental section'). While it doesn't provide external evidence to *prove* this claim, it suggests a potential improvement area ('It would be great if the paper can highlight those observations and conclusions...'). The implication is that this hidden information could be useful, suggesting a logical connection to improvement, even without direct verification.", "helpfulness_rationale": "The review point identifies a potential improvement opportunity ('highlight observations and conclusions') and points to a specific section ('the experimental section') where this could be beneficial. It highlights a *specific area* for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'it would be better to provide some ablation experiments of these tricks' which is a direct and concrete suggestion for the authors to improve their draft. The reviewer is indicating a specific area for experimentation and how to potentially validate the model performance further.", "grounding_specificity_rationale": "The reviewer refers to 'the tricks mentioned in Section 3.4,' which grounds the comment to the specific content of the paper. However, the suggestion is general, proposing 'ablation experiments' without specifying which tricks or how to conduct them. This indicates a weak grounding as the authors need to infer the specific tricks from the paper to understand the suggestion.", "verifiability_rationale": "The review point does not contain a claim or suggestion. It is a statement of what the authors could do in the future to validate their model. Therefore, there is X to verify, and the aspect should be marked as 'X (X)'.", "helpfulness_rationale": "The review point suggests a valuable direction for the authors to take \u2013 conducting ablation studies. While it doesn't guarantee a specific outcome or identify a concrete problem, it provides a helpful suggestion for further validation. This makes it 3 as it points to a beneficial improvement area."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "None", "actionability_rationale": "The reviewer asks for a comparison, which implies an action: to investigate performance on multiclass datasets. While not explicitly stated as 'do this,' the request points to a specific action. The vagueness of 'more data' makes it less actionable than a direct suggestion.", "grounding_specificity_rationale": "The reviewer mentions 'KDE' and 'decision space' generally. They don't explicitly point to a specific section, table, or unique aspect of the paper. The request is broad and doesn't pinpoint the exact issue.", "verifiability_rationale": "The reviewer states 'Zhang et. al.44, this seems not a problem.' This is a claim that requires justification. However, the reviewer doesn't provide any evidence or reasoning to support this claim. It's a statement of observation without backing.", "helpfulness_rationale": "The reviewer's question is about clarifying a potential limitation and suggesting a comparison. While it points to an area for further investigation, it doesn't directly provide a concrete solution or actionable advice for the authors. It's helpful in identifying a potential issue but not in directly guiding the authors' work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer poses questions about the impact of the SR model's capacity on FID and the artifacts from pipelining. While these questions suggest an area for investigation, they don't explicitly state a concrete action the authors should take. The reviewer identifies potential issues, but the specific steps to address them are not detailed.", "grounding_specificity_rationale": "The reviewer refers to 'the SR model's capacity' and 'the pipelining process.' This provides some grounding by identifying the specific aspects of the work being discussed. However, the reviewer doesn't explicitly state which section, table, or unique element of the paper these relate to, making the grounding weak.", "verifiability_rationale": "The reviewer states observations about the SR model's capacity affecting FID and the presence of artifacts due to pipelining. While these observations could be considered claims, the reviewer doesn't provide explicit evidence or reasoning to support these claims within this review point. The verifiability depends on the authors' interpretation and potential followup research to confirm these observations.", "helpfulness_rationale": "The reviewer points out potential issues with the SR model's capacity and the pipelining process, which can be valuable information for the authors. By highlighting these potential limitations or areas for improvement, the reviewer provides guidance and encourages the authors to consider these aspects. While not a direct solution, it points to areas that need attention."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the issues with Appendix A and Appendix B's Proposition B.1. The reviewer clearly identifies that Appendix A is left blank and that the purpose of Proposition B.1 is unclear. The reviewer also suggests that the proof is missing, which is a direct and explicit statement of the problem. The actions to take are also clear: the authors should fill in Appendix A and provide a clear purpose and proof for Proposition B.1.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific parts of the paper that are problematic. They mention 'Appendix A' and 'Proposition B.1' directly, indicating a high level of grounding. The reviewer also explains *why* these parts are problematic, stating that Appendix A is 'left blank' and the purpose of Proposition B.1 is 'unclear'. This level of specificity shows that the reviewer has a clear understanding of the location and nature of the issues.", "verifiability_rationale": "The reviewer makes a claim that the proof is 'missing' and provides a reason for this claim by stating that it is a 'socalled \u201cproof\u201d'. While the reviewer doesn't provide a specific example of the missing proof, the phrasing strongly suggests a lack of rigor. The claim is supported by the statement that the proof is missing, making it '4' as the reasoning is present but could be more detailed.", "helpfulness_rationale": "The review point is 5 as it directly points out specific weaknesses in the paper's presentation. The reviewer clearly states that Appendix A is blank and Proposition B.1's purpose is unclear. They also suggest that the proof is missing, which is a concrete criticism. This information directly informs how the authors should improve their work, such as by filling in Appendix A, clarifying the purpose of Proposition B.1, and providing a proper proof."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point mentions the 'lack of additional necessary experiments' and suggests 'comparison experiments, ablation studies, and hyperparameter analysis'. The 'lack of' indicates an implicit action: the authors should perform these experiments. However, the specific *type* of experiments is mentioned, which makes the action somewhat concrete. The 'necessary' aspect is vague, but the reviewer *identifies* the *kind* of experiments needed. Therefore, the action is not fully explicit or concrete.", "grounding_specificity_rationale": "The review point states 'The paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis, etc.' The reviewer does not specify which section, table, figure, or unique aspect of the paper is affected by this lack. The comment is a general statement about the need for more experiments. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point contains the claim 'The paper lacks additional necessary experiments...'. This is a statement that can be verified by examining the paper's content or by suggesting improvements to the experimental design. While the reviewer does not provide specific examples or citations within this review point, the claim itself is a reasonable and potentially verifiable statement. The lack of specific details doesn't invalidate the claim itself.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper: the lack of necessary experiments. It suggests specific types of experiments that would be beneficial. This is a constructive and actionable suggestion aimed at improving the paper. The reviewer directly points out a missing element that is crucial for strengthening the paper. Therefore, the review point is 5 for guiding the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a potential area for improvement ('probably is needed') but does not explicitly state the action to be taken. While it points to a specific area ('some pretty \"old\" benchmarks'), the exact action is vague. The reviewer doesn't provide concrete steps on how to perform the analysis or identify the problematic benchmarks.", "grounding_specificity_rationale": "The review point mentions specific parts of the paper, such as 'some pretty \"old\" benchmarks\" and the \"data curation\" process, which can be considered a form of grounding. However, it does not pinpoint the exact section or element within these areas that needs improvement. The specificity is limited as it refers to a general category of benchmarks and a process rather than a precise location within the paper.", "verifiability_rationale": "The review point contains a claim ('more careful analysis probably is needed, especially for some pretty \"old\" benchmarks') that makes a judgment about the model's performance. However, it does not provide specific examples of these \"old\" benchmarks or cite any external references to support this claim. The reasoning is present but lacks concrete evidence or examples.", "helpfulness_rationale": "The review point raises a valid concern about the model's performance on certain benchmarks and suggests a more thorough analysis. However, it does not provide specific, actionable feedback on how the authors should modify their draft to address this issue. The suggestion is more of a constructive comment for future work rather than direct guidance for improving the current submission."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states the desire to add collaborative games to the experiments, which is a clear and actionable suggestion. The reviewer is proposing a specific change to the experimental setup.", "grounding_specificity_rationale": "The comment is very general and does not specify which experiments or parts of the paper it is referring to. It is a broad suggestion about the nature of the experiments, rather than pointing to a specific issue within the current draft.", "verifiability_rationale": "The review point introduces a suggestion about exploring collaborative games. While this could be interesting, the review point itself does not provide any evidence or justification for why this would be relevant or what specific outcomes to expect. It's a forwardlooking suggestion without any supporting arguments.", "helpfulness_rationale": "The review point offers a suggestion for future research (exploring collaborative games). While this could be valuable, it does not directly address specific weaknesses or flaws in the current draft. It's more of a suggestion for future work than a direct critique or solution to existing problems."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment identifies a problem (missing experimental settings) and implies a need for authors to understand these settings to interpret the figures. While it doesn't explicitly state 'Add experimental settings for Figures 19', the implication is clear. However, the action is not very concrete as the authors are left to infer the exact nature of the missing information and how to obtain it.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figures 1 to 9', indicating a clear identification of the specific parts of the paper where the experimental settings are missing. This demonstrates strong grounding as the section numbers are provided.", "verifiability_rationale": "The comment makes a factual statement: 'experimental settings for Figure 1 to Figure 9 are totally missing'. There are no claims, opinions, or suggestions being made. Therefore, it falls into the 'X' category of X.", "helpfulness_rationale": "The comment highlights a significant weakness in the paper: the absence of experimental details making the figures unconvincing. This directly impacts the authors' ability to understand and trust their results. While it doesn't suggest specific changes, it points to a crucial missing piece of information that is essential for the paper's credibility and impact. Therefore, it is 5 in identifying a critical issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises a concern about the ambiguity of how the proposed method avoids hindering the acquisition of new task knowledge. While the reviewer points out a potential issue, the review point itself does not explicitly state an action for the authors to take. The authors are left to consider the implications of the reviewer's observation and the potential role of existing parameter isolation methods in this context. The reviewer's question about clarity suggests a lack of direct guidance on how to proceed or what specific aspects to focus on regarding the interaction between pathway protection and parameter isolation.", "grounding_specificity_rationale": "The reviewer's review point discusses the general concept of parameter isolation methods and sparsity in activation channels. While the reviewer mentions 'current parameter isolation methods' and 'sparsity exhibited by activation channels,' they do not specify a particular method or a specific aspect of these concepts. The reviewer's statement is more of a general observation than a direct instruction on how to ground the discussion in specific details from the paper.", "verifiability_rationale": "The reviewer makes a claim about the ambiguity of how the proposed method avoids hindering the acquisition of new task knowledge. This claim is based on the observation that some parameter isolation methods are tailored to leverage sparsity. The reviewer's point is that the paper's rationale might be ambiguous in explaining how the proposed method avoids this. However, the verifiability of this claim depends on the context of the paper being reviewed. If the paper clearly outlines its approach and distinguishes it from methods leveraging sparsity, the claim is verifiable. If the distinction is vague, it becomes 1. Based on the information provided in the review point itself, the claim is not fully supported by explicit evidence or reasoning.", "helpfulness_rationale": "The reviewer's review point raises a question about the clarity of how the proposed method avoids hindering the acquisition of new task knowledge. While this raises a relevant concern for the authors, the review point itself does not provide a direct action or suggestion for improvement. The reviewer is prompting the authors to consider a potential issue and to clarify the method's interaction with parameter isolation. This is more of a request for clarification and a prompt for further thought rather than a direct suggestion of an actionable improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the *what* (comparisons with existing fairness algorithms) and the *why* (to enhance the paper and position the ManyFairHPO framework within the existing FairML research landscape). This indicates a clear intention to provide feedback. However, the *how* of these comparisons is not specified, making the action somewhat implicit rather than fully explicit. The reviewer suggests a concrete action (comparisons), but the details of how these comparisons should be conducted are missing, making it less concrete than a fully explicit comment.", "grounding_specificity_rationale": "The reviewer refers to 'existing fairness algorithms' generally, without specifying a particular section, table, figure, or unique element within the paper that needs to be addressed. While the reviewer implies a need for comparison, they do not provide a precise reference point within the document. The comment is vague about the specific algorithms to compare against and lacks details on the comparison methodology. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses. The specificity is also low because the reviewer does not clearly define what needs to be addressed in this general area.", "verifiability_rationale": "The reviewer makes a claim: 'Integrating benchmark comparisons against stateoftheart fairness algorithms would significantly enhance the paper.' This is a subjective statement about the potential benefits of the suggested action. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no evidence presented to justify why these comparisons are necessary or beneficial. The claim is presented as a desire rather than a wellsupported suggestion.", "helpfulness_rationale": "The reviewer's comment clearly identifies a potential weakness in the paper (lack of benchmark comparisons) and suggests a concrete improvement ('integrating benchmark comparisons against stateoftheart fairness algorithms'). This indicates a desire to enhance the paper's contribution and position within the field. However, the comment lacks specific details about *which* algorithms to compare against, *how* to perform the comparisons, and *what* the expected outcomes should be. Without these specifics, the reviewer's suggestion, while relevant, lacks the immediate practical benefit that a 5 comment would provide. It's presented as a desire rather than a clear, actionable step."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment implicitly suggests an actionable step by asking the authors to discuss the iteration cost. However, it lacks specific details on how the authors should approach this discussion, such as whether they should provide a theoretical analysis or empirical results. The lack of explicit guidance makes it somewhat vague.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper being addressed. It refers to the 'proposed method' and 'related methods' generally. Therefore, the grounding is weak as the authors cannot confidently pinpoint the exact section or aspect being discussed. The comment also does not specify what is meant by 'iteration cost' (e.g., epochs, iterations through the dataset, etc.).", "verifiability_rationale": "The comment does not contain a claim. It is a suggestion for the authors to include information about the iteration cost. While this is a request for information, it doesn't inherently require verification in the same way a criticism would. The comment itself is not a claim that needs to be supported by evidence.", "helpfulness_rationale": "The review point directly asks the authors to discuss an important aspect of their method (iteration cost) and provides a clear direction for what they should include in this discussion (comparison to related methods). This is a helpful suggestion that guides the authors towards a relevant analysis. It provides a concrete expectation for the authors' response."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a potential lack of explicitness. The authors state that the center correlation was not insightful but then use it. This implies an implicit connection. The reviewer is asking for clarification on *why* it was used despite the statement. The action is 'use the metric', but the guidance on *how* to use it effectively is missing. Therefore, it's 2 as it implies an action but lacks detailed guidance on how to apply it.", "grounding_specificity_rationale": "The reviewer is questioning the specificity of the statement 'the center correlation was not insightful for discriminating model defenses'. The authors mention the metric but do not clearly identify the specific part of the paper or the issue with it. The statement is general and lacks detail. The reviewer is asking for more clarity on *why* it's not insightful. The authors can identify the section (center correlation) but don't specify the problem. Therefore, it's weakly grounded as the authors can make an educated guess but cannot precisely identify the referenced part and specific issue.", "verifiability_rationale": "The reviewer is raising a valid point about the verifiability of the statement 'the center correlation was not insightful for discriminating model defenses'. The authors make a claim about the metric's limitations without providing explicit justification or references. The reviewer is asking for a logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a claim without sufficient backing. Therefore, it's 1 at this point as the reasoning or support is missing.", "helpfulness_rationale": "The reviewer's confusion about the authors' statement and its use in the paper suggests that the comment might not be entirely helpful. The authors are making a claim about the center correlation's lack of insightfulness, but then use it, creating ambiguity. The reviewer is asking for clarification and justification, indicating a lack of clear guidance for the authors. Therefore, the comment is 2 as it raises a valid concern but fails to provide sufficient clarification or justification to be fully actionable for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests changing the name of a phenomenon from 'distributional generalization' to 'empirical distribution matching'. This is a clear and actionable suggestion, directly addressing the name given to a specific concept. The reviewer proposes a concrete alternative name, indicating a desire for clarity and potentially a more accurate representation of the observed phenomenon.", "grounding_specificity_rationale": "The review point mentions 'a few test functions' as the basis for their critique of the name's strength. This provides some grounding by referencing a specific aspect of the empirical evaluation. However, the connection between these test functions and the broader claim about 'total variation vanishing to zero' is not explicitly stated, making the grounding somewhat weak. The reviewer also specifies the phenomenon they are concerned about ('the empirical phenomenon presented'), adding a degree of specificity to their critique.", "verifiability_rationale": "The review point makes a claim about the 'strength' of the name 'distributional generalization' in capturing the empirical phenomenon. While the reviewer offers an interpretation of the phenomenon ('the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero'), this interpretation is not directly supported by explicit examples or external references within the review point itself. The grounding provided by 'a few test functions' is not sufficient to fully verify the claim without further elaboration or evidence. The reviewer's interpretation is based on their understanding of the underlying concept.", "helpfulness_rationale": "The review point provides a suggestion (to change the name) and critiques the current name ('distributional generalization') for its perceived strength and potential misrepresentation of the empirical phenomenon. While the suggestion is clear and actionable, the lack of grounding and verifiability in the critique makes it less impactful. The reviewer is attempting to improve the clarity and accuracy of terminology, which is generally helpful for authors, but the effectiveness of this suggestion is limited by the lack of concrete evidence and examples in the critique."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states what is unclear and what is not shown. For example, they say, 'It is unclear to me what scientific insight we get from this model and formalism over the prior taskoptimized approaches' and 'this model (as formulated in Section 2.3) is not shown to be a prototype approximation to these nonlinear RNN models that exhibit emergent behavior'. These statements indicate an explicit action: to clarify the scientific insight and the model's relation to RNNs. However, the reviewer does not provide concrete steps on how to achieve this clarification. The action is stated but not elaborated upon, making it implicit rather than explicit. The reviewer also states, 'So it is not clear that your work provides any further \u201cexplanation\u201d as to how these nonlinear models attain such solutions purely through optimization on a task'. This suggests the reviewer is inferring an explanation but is not explicitly stating it.", "grounding_specificity_rationale": "The reviewer mentions 'Section 2.3' and 'nonlinear RNN models' as specific parts of the paper. This indicates a degree of grounding as the reviewer is pointing to specific sections and concepts. However, the reviewer does not explicitly state what needs to be addressed within these sections or models. The reviewer says, 'It is unclear to me what scientific insight we get from this model and formalism over the prior taskoptimized approaches' and 'this model (as formulated in Section 2.3) is not shown to be a prototype approximation to these nonlinear RNN models that exhibit emergent behavior'. While the sections are mentioned, the specific issue within them is not clearly identified. The reviewer also states, 'So it is not clear that your work provides any further \u201cexplanation\u201d as to how these nonlinear models attain such solutions purely through optimization on a task', indicating a lack of specific details about what needs to be explained within the context of RNNs and emergent behavior.", "verifiability_rationale": "The reviewer states that the scientific insight and the lack of explanation are 'not clear' and that the claim about the model not being a prototype approximation is 'not shown'. This indicates a lack of supporting evidence or justification for the claims made. The reviewer does not provide any logical reasoning, common knowledge, or external references to support their claims. For example, they say, 'It is unclear to me what scientific insight we get from this model and formalism over the prior taskoptimized approaches' and 'this model (as formulated in Section 2.3) is not shown to be a prototype approximation to these nonlinear RNN models that exhibit emergent behavior'. There is no evidence presented to support these statements. The reviewer also says, 'So it is not clear that your work provides any further \u201cexplanation\u201d as to how these nonlinear models attain such solutions purely through optimization on a task', which further highlights the lack of verifiable claims.", "helpfulness_rationale": "The review point is primarily focused on identifying a gap in the scientific insight and the model's relation to RNNs. While the reviewer points out a relevant issue, they do not provide any concrete suggestions or actionable feedback on how to address this gap. The reviewer states, 'It is unclear to me what scientific insight we get from this model and formalism over the prior taskoptimized approaches' and 'this model (as formulated in Section 2.3) is not shown to be a prototype approximation to these nonlinear RNN models that exhibit emergent behavior'. These statements highlight a lack of clarity and explanation, but they do not offer any guidance on how to improve the model or the understanding of the RNNs. The reviewer also says, 'So it is not clear that your work provides any further \u201cexplanation\u201d as to how these nonlinear models attain such solutions purely through optimization on a task', which further emphasizes the lack of actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the observation about the performance difference between ACNNv2 and ACNNv3, indicating a clear action item: 'analyze or comments on this aspect of the technique'. The suggestion to analyze the placement of adaptive convolutions is a direct action for the authors to take.", "grounding_specificity_rationale": "The reviewer mentions 'the experimental results in Table 3', which, while not explicitly stating the table number, allows for the identification of the relevant section. The suggestion to 'analyze or comments on this aspect of the technique' directly addresses the specific implementation of adaptive convolutions.", "verifiability_rationale": "The reviewer makes a claim based on the experimental results, stating that replacing normal convolutions with adaptive convolutions is not always good. They then point out the specific performance difference between ACNNv2 and ACNNv3, providing evidence to support their claim, although they do not explicitly explain *why* the placement matters.", "helpfulness_rationale": "The reviewer provides a clear observation, points to specific experimental results, and suggests a concrete next step (further analysis). This directly addresses a potential weakness and offers a direction for improvement, making the feedback valuable for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a discussion and asks questions about the potential effects of a timevarying Q and S. While this points towards a relevant area for improvement, it does not explicitly state what the author should do or how to implement it. The suggestion is more of a request for further investigation rather than a direct action item.", "grounding_specificity_rationale": "The review point refers to the 'discussion' section of the paper. While this section is identified, it is a general section and does not pinpoint a specific part of the paper being discussed. The reviewer does not explicitly state which subsection or element within the discussion is being addressed. Therefore, the grounding is weak.", "verifiability_rationale": "The review point does not contain a claim or opinion that requires verification. It is a suggestion to include a discussion and ask questions about the potential effects of a timevarying Q and S. There are no explicit statements that need to be supported by evidence or references.", "helpfulness_rationale": "The review point raises a relevant question about the motivation for timevarying parameters and suggests a discussion. While it doesn't provide a direct solution, it points towards a valuable area for improvement and encourages the author to explore the implications of their modeling choices. Therefore, it has some level of helpfulness in guiding the author towards further analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer provides a general impression of the paper's clarity and the relevance of the experiments, but does not explicitly state what needs to be improved or how the authors should go about it. While the sentiment is present, the lack of specific actions makes it difficult to classify as fully actionable. The reviewer's statement is a general feeling rather than a clear instruction on what to do next.", "grounding_specificity_rationale": "The reviewer mentions 'the presentation lacks a clear intuition' and 'experiments have little to hang on to,' which points to a lack of connection to the authors' work. However, the reviewer does not specify *which part* of the paper or *what specific element* is lacking intuition. The statements are general and do not pinpoint a concrete section or detail, making the grounding somewhat weak. While the issue is implied, the lack of specificity reduces the grounding score.", "verifiability_rationale": "The reviewer states 'Overall, the paper is not particularly easy to follow' and 'the presentation lacks a clear intuition' and 'experiments have little to hang on to.' These statements are opinions or judgments about the paper's clarity and relevance. While they contain claims, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The statements are presented as subjective impressions without any backing, making the verifiability low. The reviewer offers a general feeling rather than a verifiable point.", "helpfulness_rationale": "The reviewer's comment is a general critique of the paper's presentation and the experiments' connection to the work. They do not offer specific, actionable suggestions or identify any concrete weaknesses. The feedback is at a high level and lacks specific details about what needs to be improved. The reviewer's statement is a general sentiment rather than a constructive suggestion for improvement, making the helpfulness score low. The comment doesn't provide any concrete guidance for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point directly describes the mathematical operation in the method and proposes a modification. The reviewer clearly states the current formula and suggests adding a scaling variable. This provides a clear action for the authors to take and understand the potential impact of the change. The reviewer is not just pointing out a problem but suggesting a concrete improvement.", "grounding_specificity_rationale": "The reviewer explicitly refers to line 157 and the specific formula: 'the refined region vector is basically u_i = (1 + attention_weight) * v_i'. This provides a clear and precise reference point within the paper, demonstrating strong grounding. The reviewer is not making a general comment but focusing on a specific implementation detail.", "verifiability_rationale": "The reviewer provides a clear mathematical explanation of the current method and the proposed change. They explain that the scaling factor might be beneficial because attention weights are in 0, 1 and sums up to 1. The reviewer's suggestion of a 'scaling variable' directly addresses the limitations of the current approach by adding more control over the contribution of different regions. This is a wellsupported claim with a logical reasoning.", "helpfulness_rationale": "The review point is highly specific and directly addresses a potential limitation of a method description. The reviewer not only identifies a potential issue with the scaling factor but also suggests a concrete alternative. This is very helpful for the authors trying to understand and implement the method. The reviewer is actively contributing to improving the clarity and potential effectiveness of the method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly states 'Failures on the ALFRED benchmark often occurred due to goal misspecification'. This indicates an explicit action, which is to improve goal specification. However, the point does not specify how to achieve this improvement or what aspects of goal misspecification are most problematic. Therefore, while the action is identified, the details are lacking, making it 3 but not fully actionable.", "grounding_specificity_rationale": "The review point mentions 'goal misspecification' and 'ALFRED benchmark' but does not explicitly identify a specific part of the paper or system where this issue occurs. It describes the problem generally without pinpointing its location or the specific aspects of goal misspecification that are causing the failures. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point states a claim: 'Failures on the ALFRED benchmark often occurred due to goal misspecification.' However, it does not provide any evidence, reasoning, or references to support this claim. It identifies a problem but does not verify it. Therefore, the claim is not verifiable as there is no supporting information provided.", "helpfulness_rationale": "The review point identifies a problem ('goal misspecification') that needs to be addressed. However, it does not offer any suggestions, actions, or improvements to resolve this issue. It diagnose a problem but does not provide a prescription. Therefore, it is not helpful in guiding authors on how to improve their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer claims the improvement over IGEV is small and suggests further analysis. While the action of analyzing the multipeak distribution is implied, the reviewer doesn't explicitly state the steps or methods for this analysis. The action is vague and lacks concrete details on how to apply it. Therefore, it is 2.", "grounding_specificity_rationale": "The reviewer mentions 'IGEV' and 'SamplingGaussian' but does not explicitly identify the specific part of the paper being addressed or how these methods relate to the 'multipeak distribution problem'. The mention is general and lacks a clear connection to a specific section, table, or unique aspect of the paper. Therefore, the grounding is weak and specific.", "verifiability_rationale": "The reviewer makes claims about the 'small' improvement over IGEV and suggests that 'SamplingGaussian' might not significantly improve 'iterative optimization schemes similar to IGEV'. These are claims that need supporting evidence or justification. The reviewer does not provide any logical reasoning, common knowledge, or external references to back up these claims within the review point itself. Therefore, the verifiability is 1.", "helpfulness_rationale": "The reviewer suggests analyzing the distribution of disparities produced by IGEV and recommends exploring the potential of SamplingGaussian. While these are valid suggestions, the review point itself does not explicitly connect these suggestions to specific weaknesses in the authors' draft or explain how they will help the authors improve. The suggestions are presented as possibilities rather than concrete steps. Therefore, the helpfulness is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The criticism asks for information about the input and output domains of the functions h, g, and \u03b4. This is an implicit request for clarification. While the reviewer doesn't directly tell the author what to do, they identify a missing piece of information that is crucial for understanding the method. The action is concrete: once the domains are identified, the reviewer's point is addressed. However, the action is not explicitly stated, requiring the author to infer it.", "grounding_specificity_rationale": "The reviewer explicitly names the functions h and g and asks about their domains. This directly identifies the specific part of the paper being addressed. The grounding is literal, naming the functions. The criticism also mentions \u03b4, further emphasizing the specific focus. The reviewer clearly pinpoints the area where the lack of clarity is present.", "verifiability_rationale": "The reviewer states a fact: 'The notations h, g almost appear out of the blue. What are their input, output domains. It is the same issue with \u03b4 but it at least has some brief description.' This is a declarative statement expressing a lack of clarity. The claim is that the domains are not clearly specified. The reviewer provides logical reasoning by pointing out the missing information. The claim is supported by the absence of explicit domain information for h and g, making it 3.", "helpfulness_rationale": "The criticism directly points out a lack of clarity that could hinder understanding and potentially the implementation of the method. It provides a clear 'what' (the missing domains) and implicitly suggests 'why' it's important. The reviewer's point identifies a need for more information, which is a helpful direction for the author. However, it doesn't offer a solution, so it's not 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the results section and the performance gain. While they are asking for information, the action is implied rather than explicitly stated. The reviewer could have phrased it more directly, such as \"How does the task formulation contribute to the performance gains reported in the results?\" The lack of a specific action makes it less actionable.", "grounding_specificity_rationale": "The reviewer refers to the \"results\" section and \"performance gain\" generally. They do not explicitly point to a specific table, figure, or unique aspect within that section. While they identify a part of the paper they are concerned with, the grounding is at a higher level of abstraction.", "verifiability_rationale": "The reviewer makes a claim that the contribution of the task formulation to the performance gain is unclear. This is a verifiable statement. However, the review point itself does not provide evidence to *support* this claim. The verifiability relies on the reviewer's interpretation of the paper's lack of explicit analysis.", "helpfulness_rationale": "The reviewer's question is directly relevant to understanding the results and the contribution of different components. It highlights a potential area for improvement in the paper's analysis and presentation. While the question itself isn't a direct solution, it points to a specific weakness in the paper's reporting."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The comment explicitly states that the axes of Figure 1 are unclear. This is an explicit action that the authors should take. Furthermore, the comment is concrete as it directly points to the axes of the figure, providing a clear direction for improvement.", "grounding_specificity_rationale": "The comment explicitly refers to 'Figure 1' and asks about its axes. This directly identifies the specific part of the paper being addressed, making it fully grounded. The comment also specifies what is unclear \u2013 the axes \u2013 making it specific.", "verifiability_rationale": "The comment does not contain a claim in the sense of a definitive statement requiring justification. However, the lack of clarity about the axes can be interpreted as an implicit claim that the figure is not welllabeled. This claim is 3 as the lack of clarity itself serves as evidence, though it doesn't point to a specific error with a citation.", "helpfulness_rationale": "The comment is directly and actionable. It tells the authors to look at Figure 1 and its axes, which is a clear piece of feedback. The lack of clarity is a specific issue that the authors can address, making the feedback 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the missing element '2 Direct runtime comparisons...' and the reason for its absence 'The proposed approach is based on implicit differentiation which usually requires additional computational costs.' This clearly indicates an actionable item for the authors.", "grounding_specificity_rationale": "The review point refers to 'direct runtime comparisons' generally, without specifying a particular section, table, or figure in the paper where these comparisons should be made. It lacks the specificity needed to pinpoint the exact location of the issue.", "verifiability_rationale": "The review point contains the claim '2 Direct runtime comparisons with existing methods are missing' and provides a reason for this absence 'The proposed approach is based on implicit differentiation which usually requires additional computational costs.' While the reasoning is present, it doesn't provide a definitive justification or evidence for the claim's validity.", "helpfulness_rationale": "The review point identifies a missing experimental detail ('direct runtime comparisons') and provides a reason for its absence ('implicit differentiation and computational costs'). This information is valuable for the authors as it highlights a potential gap in the evaluation and the likely reason for it."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'I cannot see any technical contribution.' This directly points to a weakness in the proposed framework. While the reviewer doesn't specify *how* this is a technical contribution, the statement itself is a clear action the authors should take to improve their draft by addressing this perceived lack of novelty or innovation.", "grounding_specificity_rationale": "The reviewer mentions 'metalearning' and 'federated learning' as components of the framework. This grounds the comment to a specific area of the paper. However, the reviewer also states 'I cannot see any technical contribution,' which, while pointing to a weakness, doesn't specify *what* is technically lacking within those areas. The specificity of the weakness is low.", "verifiability_rationale": "The review point is a statement of opinion: 'the proposed framework is a simple combination of metalearning and federated learning. I cannot see any technical contribution.' This is a claim that lacks any supporting evidence or logical reasoning. There are no references to external works or common knowledge to back up this assertion. The claim is presented without justification.", "helpfulness_rationale": "The review point identifies a potential weakness in the framework by stating 'I cannot see any technical contribution.' While this points to an area for improvement, the reviewer does not provide any specific suggestions or guidance on how to address this weakness. The suggestion to 'improve their draft' is general and lacks specificity, making it less helpful for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer criticizes the lack of actionable advice for the authors. While they identify a problem (insufficient contribution), they don't provide specific steps or guidance on how to address it. The focus is on the *general* issue rather than offering concrete solutions. The reviewer's statement, 'However, my major concern is that the contribution is insufficient,' is a statement of opinion rather than a direct action or suggestion.", "grounding_specificity_rationale": "The reviewer's comment is about the *general* connection between multimodal complementarity and model robustness. While this is a relevant aspect of the paper, the reviewer doesn't explicitly point to a specific section, table, or figure in the paper. The focus is on the *concept* rather than a specific instance. The reviewer doesn't mention any unique elements of the paper that they believe are being addressed.", "verifiability_rationale": "The reviewer makes a claim about the intuitiveness of the conclusion, stating, 'Except for the analysis of the connection between complementary and robustness, it is expected to see more insightful findings or possible solutions.' This is a statement of opinion. While they provide a logical reasoning for why the conclusion might be intuitive ('when multimodal complementary is higher, the robustness is more delicate when one of the modalities is corrupted'), they don't provide external references or specific examples to support this claim. The reviewer presents this as a deduction or inferred observation that goes beyond merely stating facts.", "helpfulness_rationale": "The reviewer argues that the insights provided are not significant enough to be helpful for the authors. They criticize the lack of actionable advice and suggest that the conclusion is easily and intuitively obtained. The reviewer anticipates more insightful findings or solutions beyond just analyzing the connection. The reviewer's statement, 'Even though this paper could be the first work to study this connection, the conclusion could be easily and intuitively obtained,' indicates a lack of novel or impactful findings. The reviewer anticipates more insightful findings or possible solutions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the reviewer's observation about focusing on 'best' clusters and comparing representations. It also clearly indicates the reviewer's opinion that this approach is 'odd' and suggests it might be misaligned with the paper's motivation. The action is explicit (identifying the issue), and the details are concrete (mentioning 'best' clusters and 'differences in representation').", "grounding_specificity_rationale": "The comment identifies the specific elements being discussed: 'clusters' and 'representation'. While it doesn't provide a literal section reference, the context implies the reviewer is referring to a section discussing these concepts. The grounding is strong because the reviewer can confidently identify the parts of the paper being addressed, even without explicit section names. The specificity is high as the comment clearly specifies what is being compared and what is being criticized.", "verifiability_rationale": "The comment contains a claim: 'Focusing on which clusters are 'best' rather than what the differences in representation are between them, seems an odd choice'. This claim is supported by the logical reasoning that comparing differences is a more informative approach than simply ranking clusters. While the connection to the 'motivation of the paper' is implied, it provides a sufficient justification for why the reviewer finds the approach 'odd'. The evidence, though not explicitly quoted, is logical and inferable.", "helpfulness_rationale": "The comment is highly subjective but provides a clear and actionable critique of the approach. It points out a potential flaw in the methodology or the interpretation of results. This is likely to be very helpful for the authors to understand a potential issue and consider alternative perspectives or analyses. The feedback is specific about the area of concern ('clusters' and 'representation') and the suggested improvement ('comparing differences')."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out several specific issues with the paper's organization and formatting. This suggests the criticism is *explicit*.\n* \"The layout of this paper is a bit rushed.\"  This is a general statement about the overall organization.\n* \"The font size of some annotations of Figure1 and Figure 2 is relatively small.\"  This identifies a *specific* visual element and a *specific detail*.\n* \"And these two figures are not drawn explicitly enough.\"  This is a subjective assessment of the figures' quality.\n* \"Table 2 is inserted wrongly inside of a paragraph.\"  This is a *specific* factual error.\n* \"Top two lines on page 6 are in the wrong format.\"  This is a *specific* factual error.\n\nWhile the reviewer *mentions* the issues, the *action* isn't explicitly stated. The reviewer *implies* the authors should fix the rushed layout, make the figure annotations larger, improve the figure quality, correct the Table 2 placement, and fix the formatting on page 6. This implies an action, but it's not directly stated. Therefore, it's **implicit**.\n\nThe reviewer provides *some* details (font size, figures, Table 2 placement, formatting). However, they don't explicitly say *how* to fix these issues. This makes it **vague**.", "grounding_specificity_rationale": "The reviewer refers to 'some annotations\" of Figure 1 and 2, \"these two figures,\" \"Table 2,\" and \"top two lines on page 6.\" These are all specific references within the paper.\n* \"The font size of some annotations of Figure1 and Figure 2 is relatively small.\"  The reviewer accurately identifies the *specific* annotations and notes their *size*.\n* \"And these two figures are not drawn explicitly enough.\"  The reviewer identifies the *specific* figures and describes their *lack of detail*.\n* \"Table 2 is inserted wrongly inside of a paragraph.\"  The reviewer accurately identifies the *specific* table and its *incorrect placement*.\n* \"Top two lines on page 6 are in the wrong format.\"  The reviewer accurately identifies the *specific* formatting issues on a *specific* location.\n\nThe reviewer clearly identifies the *sections* where the issues occur and describes the * nature of the problems within those sections. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer states that the paper is \"not well organized\" and lists several \"explicit\" issues. These are statements of judgment and observation, which constitute a claim.\n* \"The layout of this paper is a bit rushed.\"  This is a clear observation of the paper's state.\n* \"The font size of some annotations of Figure1 and Figure 2 is relatively small.\"  This is a verifiable observation.\n* \"And these two figures are not drawn explicitly enough.\"  This is a verifiable observation about the quality of the figures.\n* \"Table 2 is inserted wrongly inside of a paragraph.\"  This is a verifiable factual error.\n* \"Top two lines on page 6 are in the wrong format.\"  This is a verifiable factual error.\n\nThe reviewer provides *specific details* about the issues they observed. While they don't offer *external references*, the issues are directly observable within the paper itself. The *verifiability* comes from the reviewer's ability to *see* these details.", "helpfulness_rationale": "The reviewer clearly identifies several concrete issues with the paper's organization and formatting. While they don't explicitly state *how* to fix them, they point to specific locations and describe the problems.\n* \"The layout of this paper is a bit rushed.\"  This points to a need for better organization.\n* \"The font size of some annotations of Figure1 and Figure 2 is relatively small.\"  This highlights a need for better figure presentation.\n* \"And these two figures are not drawn explicitly enough.\"  This suggests the need for more detailed figures.\n* \"Table 2 is inserted wrongly inside of a paragraph.\"  This indicates a need for correct formatting and placement.\n* \"Top two lines on page 6 are in the wrong format.\"  This highlights a need for correct formatting.\n\nThe feedback is relevant and points to actionable improvements, even if the authors need to infer the exact fixes. The reviewer's observations are directly related to the paper's content and presentation, making it 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states what needs to be clarified and provides concrete suggestions for improvement. For example, they say \"The authors need to clarify...\" and \"The authors should explain...\". This indicates a high level of actionability as the authors can directly identify modifications they should apply to their draft.", "grounding_specificity_rationale": "The reviewer points to specific technical terms and concepts within the paper, such as \"dual subdivision,\" \"projection \u03c0,\" and \"decision boundaries.\" They also specify what is unclear, stating \"The authors need to explain *how* the dual subdivision and projection \u03c0 work\" and \"The authors need to explain *how* the decision boundaries of neural networks are defined.\" This indicates high grounding specificity as the authors can accurately pinpoint the sections, tables, figures, or unique aspects being addressed.", "verifiability_rationale": "The reviewer doesn't just state that something is unclear. They provide specific examples of *what* is unclear and *how* it needs to be clarified. For instance, they say \"The authors need to explain *how* the dual subdivision and projection \u03c0 work\" and \"The authors need to explain *how* the decision boundaries of neural networks are defined.\" This makes the claim verifiable as the reasoning, common knowledge, or external references (if any were implied, though none are explicitly mentioned here) are readily available to support the feedback.", "helpfulness_rationale": "The reviewer provides concrete suggestions for improvement. They don't just say \"the paper needs improvement,\" but gives specific directions like \"clarify the definition of 'upper faces'\" and \"provide a clear definition of 'p'\". This makes the review 5 as it empowers the authors to significantly improve their draft by taking concrete actions."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their opinion ('I am not convinced') and identifies a specific area ('images and their augmentations') and a potential alternative ('they can be interchangeable'). This provides a clear direction for potential improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'images and their augmentations,' indicating a clear identification of the specific part of the paper being addressed. They also specify what might be wrong ('they can be interchangeable'), detailing the issue.", "verifiability_rationale": "The reviewer presents an opinion ('I am not convinced') and a counterargument ('they can be interchangeable'). However, they do not provide any specific evidence, reasoning, or references to support their claim that treating images and augmentations separately is unnecessary or problematic. The justification is missing.", "helpfulness_rationale": "The reviewer raises a relevant point about the treatment of images and augmentations, offering an alternative perspective. While the feedback is pertinent to the methodology, it does not offer concrete evidence or a definitive solution to the authors' approach. The feedback is focused on questioning a potential decision rather than providing a clear improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that 'some of the pieces are simply using existing methods' and 'the presentation of these methods are also vague (can only be understood after checking the original paper)'. While the reviewer identifies a potential action (improving the presentation), the specifics of how to do this are not detailed in the review itself. The reviewer knows *what* is missing (vagueness) but doesn't provide a concrete *how*. This makes the action implicit and vague.", "grounding_specificity_rationale": "The reviewer mentions 'equation (12)' and refers to the 'original paper'. However, they do not explicitly identify a specific part of the paper (e.g., a section, table, or figure) within the review itself. The reference to the 'original paper' is external and not a direct reference to a specific element within the submitted paper. Therefore, the grounding is weak. The comment also does not specify *what* is wrong with equation (12) within the review, making it not specific.", "verifiability_rationale": "The reviewer states 'Some of the pieces are simply using existing methods' and 'the presentation of these methods are also vague (can only be understood after checking the original paper)'. The latter part of the statement, 'can only be understood after checking the original paper', provides a basis for verification. While the reviewer doesn't cite specific external references, the statement itself acts as a form of implicit verification, indicating a lack of clarity within the submitted paper. Therefore, the claim is 3.", "helpfulness_rationale": "The reviewer points out that 'some of the pieces are simply using existing methods' and 'the presentation of these methods are also vague (can only be understood after checking the original paper)'. This clearly identifies a weakness in the draft. While the reviewer doesn't offer a specific solution, they do highlight an area for improvement, making the review 3 in guiding the authors to address these issues. The reviewer's statement itself serves as a pointer to a problem."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a problem (jumbledness) but does not specify how to address it or provide concrete actions. It lacks explicitness and concreteness.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper (e.g., a section, table, or figure) that is jumbled. It is 1 at all.", "verifiability_rationale": "The review point is an opinion ('I found...') and does not present a claim that requires verification or justification.", "helpfulness_rationale": "The review point is a general comment about the writing/presentation and does not offer specific, actionable feedback or identify a concrete problem that the author can address. It is vague and lacks direction."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a question about the importance of a specific method (annealing scheme) in a particular section of the paper. While the question is relevant to the method, it doesn't explicitly state what action the authors should take or how to implement it. The reviewer is exploring the implications of the method rather than directly instructing on its use.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the last paragraph in Section 4' and discusses the 'annealing scheme' within that section. This provides clear grounding of the specific part of the paper being addressed. The language is also specific to the method and its potential impact.", "verifiability_rationale": "The reviewer is posing a question about the potential drawbacks of the annealing scheme. They are not making a claim that can be verified through logical reasoning, common knowledge, or external references within the review point itself. The review point is a question, not a statement that can be supported or refuted.", "helpfulness_rationale": "The reviewer is asking a question and offering a potential explanation for why the annealing scheme might be crucial. This points to a potential area of concern for the authors. While it doesn't directly tell the authors how to fix the issue, it highlights a potential problem and encourages further investigation, which can be helpful in understanding the paper's limitations."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential issue (computational complexity and power demand) and asks for a comparison and clarification. While they don't explicitly state an action, the act of asking 'I wonder what is the total computational complexity compared to other methods' and 'If I imagine the Woodbury flow working on a mobile device, the number of operations could cause a significant power demand' implies a desire to understand these aspects. The reviewer doesn't state how to apply this information, but they identify a gap in the current understanding. The reviewer doesn't state an action or how to apply it.", "grounding_specificity_rationale": "The reviewer refers to 'computational complexity' and 'power demand' generally, without specifying which part of their paper or method these relate to. They don't point to a specific section, table, figure, or unique element. The comment is about the method in general, not a specific aspect of it. The reviewer doesn't identify a specific section or element of their paper that is affected by this concern.", "verifiability_rationale": "The reviewer doesn't provide any concrete information or references to support their claims about computational complexity or power demand. They pose a question and a hypothetical scenario, but without any evidence or data to back it up, the claims remain 1.", "helpfulness_rationale": "The reviewer raises a valid concern about the potential computational cost and power demand of the proposed method on mobile devices. This is a relevant and practical consideration for many applications. However, the review point lacks specific details and concrete suggestions. The reviewer doesn't provide a comparison to other methods, quantify the complexity, or offer any concrete advice on how to mitigate the power demand. While the concern is valid, the lack of specific information and solutions makes the review point 3 but not 5. The reviewer doesn't explicitly state a solution or how to apply the information."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly identifies a factual error in the authors' description of the IOI circuit and provides a clear alternative interpretation based on a specific section of a cited paper. The suggestion to use 'active' instead of 'primarily attend to' is concrete and directly actionable for the authors. The reviewer's comment is very clear and directly points out what needs to be changed in the authors' description.", "grounding_specificity_rationale": "The reviewer explicitly names the 'base IOI circuit', the 'Induction, Duplicate Token, and Previous Token heads', and refers to 'Section 3 of Wang et al., 2023'. This provides a very precise and accurate grounding of the comment, ensuring the authors can easily identify the specific part of the paper being discussed.", "verifiability_rationale": "The reviewer makes a claim that the authors' statement about the IOI circuit is incorrect and provides a reference to support this claim. The reasoning is clear and directly links the authors' statement to the cited work, making the claim highly verifiable.", "helpfulness_rationale": "The reviewer's comment is very helpful as it directly points out a factual error in the authors' description and provides a clear alternative interpretation. This allows the authors to correct their understanding and potentially improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a lack of significant difference in performance, which is an actionable observation. However, the comment also suggests a lack of justification for Algorithm 1, which is also actionable. The lack of specificity in the observation makes it less actionable overall.", "grounding_specificity_rationale": "The comment mentions 'Fig.5' and 'StableDiffusion' when discussing the performance difference, indicating some grounding. However, it doesn't specify which part of Fig.5 or which StableDiffusion implementation is being referred to, making the grounding somewhat weak. The comment also refers to 'Algorithm 1' when discussing the lack of justification, but it doesn't specify which algorithm is being referred to, making the grounding weak for that aspect as well.", "verifiability_rationale": "The comment states a lack of mathematical or theoretical justification for Algorithm 1. This is a claim that could be verified by examining the paper for such justifications. However, the comment doesn't provide any specific examples or references to support this claim, making it 1.", "helpfulness_rationale": "The comment points out a lack of significant difference in performance between the proposed method and random selection. While this is a valid observation, it doesn't provide specific guidance on how to improve the proposed method or what aspects might be contributing to the lack of difference. The comment also mentions a lack of justification for Algorithm 1, which is helpful in identifying a potential area for improvement. However, the lack of specific details makes it somewhat lacking in helpfulness overall."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests a change to the notation of triples, which is a direct and actionable suggestion. The authors can directly identify the location (line 122) and the desired change to the tuplelike structure.", "grounding_specificity_rationale": "The review point mentions 'triples denoted as $(e_1, r, e_2)$' and suggests showing its 'tuplelike structure'. While the *concept* of triples is mentioned, the specific triple on line 122 is not explicitly identified. The grounding is weak because the authors have to infer the specific location and the structure they are referring to.", "verifiability_rationale": "The review point suggests showing the 'tuplelike structure' of triples without providing any justification or reasoning for why this change would be beneficial or referencing any external sources. The claim is made without sufficient support.", "helpfulness_rationale": "The review point suggests improving the 'clarity' of the triples. While this is a generally helpful suggestion, it lacks specificity and does not provide any concrete reasons or evidence for why the triples are unclear or how the suggested change will improve clarity. The feedback is broad and lacks actionable details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the scalability issue of optimal quantization and its impact on the paper's goal of fast convergence in VI. It clearly identifies the problem (cost, dependence on clustering, bottleneck) and links it to the specific area the paper aims to address (big data/big model setting). The reviewer provides a direct action, suggesting that the authors should consider clustering as a solution to mitigate the scalability issue. The criticism is concrete in identifying the problem and its potential consequences.", "grounding_specificity_rationale": "The review point explicitly refers to the 'abstract' and the 'introduction' of the paper, as well as the 'quantization method' and its 'cost' and 'dependence on clustering'. While it doesn't pinpoint a specific section, table, or figure, the references are clear and relate to unique elements of the paper. The reviewer implies that the quantization method is a bottleneck for the paper's goal, which is a specific issue within the paper.", "verifiability_rationale": "The review point makes a claim about the scalability of optimal quantization and its impact on the paper's motivation. However, it does not provide any evidence, justification, or references to support this claim. The reviewer states a statement of opinion without backing it up with logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point identifies a potential weakness in the quantization method (optimal quantization's scalability) and its consequence for the paper's goal (fast convergence in VI). This points to a specific area where the authors could improve their work. While the review doesn't offer a direct solution, it highlights a concrete problem that needs addressing. The reviewer's comment is clear and directly relates to the paper's stated objectives, making it 3 in guiding potential improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the need to 'compare its effectiveness against existing methods, such as contrastive decoding' and mentions 'notational issues'. While the reviewer identifies a gap in the evaluation, the action of identifying this gap is clear and explicit. However, the reviewer does not specify *how* this comparison should be done, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'existing methods, such as contrastive decoding 34' and 'notational issues'. While the topics are specific, the reviewer does not explicitly identify the section, table, or figure where these issues are discussed within the paper. The reviewer also doesn't pinpoint the exact nature of the 'notational issues'. Therefore, while the *topics* are specific, the *location* and the *nature* of the issues are not precisely identified, making the grounding somewhat weak. However, the reviewer does identify the *areas* where these issues should be addressed, making it somewhat specific.", "verifiability_rationale": "The reviewer states that the paper 'should compare its effectiveness against existing methods, such as contrastive decoding'. This constitutes a claim requiring justification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no evidence of how this comparison would be done, why it is necessary, or what metrics would be used. Therefore, the claim is not supported by any evidence, making it 1.", "helpfulness_rationale": "The reviewer raises a valid concern about the lack of comparison to contrastive decoding methods, which is a relevant aspect of the methodology. However, the reviewer's point is vague. They do not specify *which* contrastive decoding methods should be compared against, nor do they provide any suggestions for how this comparison should be conducted. The reviewer also mentions 'notational issues' without specifying what these issues are. While the concern is relevant, the lack of specificity and detail makes the reviewer's point unhelpful for the authors as it doesn't provide concrete guidance or directions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the algorithm's dependence on the entire training dataset and asks a direct question about how it should operate without it. This indicates an explicit action and a clear direction for improvement, making it actionable. However, the reviewer doesn't explicitly state how the algorithm should operate without the full dataset, making it somewhat implicit.", "grounding_specificity_rationale": "The reviewer mentions 'the training dataset' and 'full perceptible' in a general sense, which can be interpreted as weak grounding. However, the reviewer directly asks a question about 'how the algorithm should operate effectively when the training dataset is not fully perceptible,' which strongly grounds the comment to the specific scenario. The request for a deeper technical contribution also implicitly grounds the comment to the paper's content.", "verifiability_rationale": "The reviewer points out a limitation of the algorithm (its dependence on the full dataset) and asks a question about its operation without it. This can be interpreted as a claim that needs further justification or exploration. While the reviewer doesn't provide specific examples or references, the question itself serves as a form of justification. The reviewer also mentions the lack of time complexity analysis and efficiency discussion, which are claims about missing information.", "helpfulness_rationale": "The reviewer's comments are valid and point to areas where the paper could be improved. The concern about the algorithm's operation without the full dataset is a constructive suggestion for discussion. The expectation for a deeper technical contribution encourages the authors to elaborate on their algorithm. While the reviewer doesn't offer concrete solutions, these points are valuable and actionable for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a limitation of representing all kernels with neural networks, providing a concrete example (RBF kernels and infinitedimensional RKHSs). This is an explicit action that is also concrete as the reviewer clearly explains the technical reason why this is a limitation.", "grounding_specificity_rationale": "The reviewer explicitly mentions the issue with RBF kernels (infinitedimensional RKHSs) and clearly explains what is wrong with the claim that all kernels can be described by neural networks. The grounding is explicit as the reviewer names a specific type of kernel and the nature of the problem is clear.", "verifiability_rationale": "The reviewer provides a clear explanation of why the claim is not true, based on the concept of RKHS dimensionality. This explanation is logical and verifiable as it relies on established mathematical principles.", "helpfulness_rationale": "The reviewer provides a concrete example of a limitation and suggests a specific improvement (clarifying the limitations of neural networks in representing kernels). This is a 5 and helpful comment for the authors as it directly addresses a potential misunderstanding and provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a direct and explicit question about the handling of longer sequences during inference with linear attention. The question clearly states the concern about the benefits of linear attention in this specific scenario.", "grounding_specificity_rationale": "The reviewer's question is highly specific, directly addressing the interaction between linear attention, autoregressive decoding, and inference with longer sequences. They are asking about the mechanism and potential benefits in this specific context.", "verifiability_rationale": "The question is 3 as it points to a potential area of investigation regarding the benefits of linear attention with longer sequences. However, without further details or context, a definitive verification is not possible. The question itself suggests a need for further analysis.", "helpfulness_rationale": "The reviewer's question is relevant to understanding the practical implications of using linear attention, particularly in scenarios with longer sequences during inference. It addresses a potential concern for practitioners implementing such models."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question ('Is it possible...') and suggests an action ('explore other measures'). This indicates an attempt to be actionable. However, the suggestion to 'explore other measures' is vague and doesn't specify what those measures might be, making the action somewhat general.", "grounding_specificity_rationale": "The reviewer mentions 'GPI with noise added' and 'Fig. 4', which grounds the comment to a specific aspect of the paper and a specific experimental setup. However, the reviewer does not explicitly state what is wrong with GPI in the context of Fig. 4 or specify what alternative measures could be used. The specificity of the critique and suggestions is limited.", "verifiability_rationale": "The reviewer suggests exploring 'alternative measures' and discusses the suitability of GPI for 'pattern separation tasks'. While the reviewer provides a *hypothesis* (noise might affect fitting) and suggests *exploring alternatives*, they do not provide explicit references or detailed reasoning to support these claims. The suggestions are presented as suggestions for improvement rather than verifiable statements based on evidence.", "helpfulness_rationale": "The reviewer provides a clear question and suggests concrete actions ('explore other measures', 'discuss alternative tasks'). They also offer a discussion point on the suitability of GPI for pattern separation tasks. These suggestions directly address potential weaknesses and provide directions for improvement, making the review helpful in guiding the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests 'reproduce their results using the same setting' as a concrete action to take. This is a clear and actionable suggestion that directly addresses the identified difference in experimental setup. The reviewer explicitly states the desired outcome, making it 5.", "grounding_specificity_rationale": "The reviewer explicitly identifies the 'AdamW with cosine lr for training' as the specific aspect being compared and highlights the 'Adam with fixed lr' as the other aspect. The reviewer clearly pinpoints the specific experimental settings used for each method. This demonstrates strong grounding as the specific parts of the paper (optimizers and learning rate) are accurately identified.", "verifiability_rationale": "The reviewer claims that directly comparing methods with different optimizers and learning rates is unfair. While the reviewer doesn't provide direct evidence *within this review point* that the paper explicitly states this difference and that it *definitely* makes the comparison unfair, the *implication* is that the authors made this comparison. The reviewer's reasoning is that different optimizers can have different convergence properties, which could affect the comparison. This claim, while not definitively proven within this review point's text, is a plausible and verifiable argument based on general knowledge of optimization algorithms. The reviewer provides a logical reasoning for why the comparison might be unfair.", "helpfulness_rationale": "The reviewer's suggestion to 'reproduce their results using the same setting' is a highly specific and actionable suggestion aimed directly at improving the authors' work. The reviewer clearly identifies the desired outcome and provides a concrete step to achieve it. This is a 5 comment for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point is a question about the design of a feedback network, not a direct critique of the feedback content itself. While the reviewer understands the question, the point doesn't explicitly state how the feedback network should use the information about the incorrect phrase, corrected phrase, and the type of mistake. The action is implied but not clearly stated. The reviewer is asking *what* to do with this information, not *how* to improve the feedback itself.", "grounding_specificity_rationale": "The reviewer explicitly asks about the impact of different types of information (incorrect phrase/corrected phrase, type of mistake) within the feedback network. They are pointing to specific aspects of the network's design and how it uses the feedback. This provides clear grounding as the reviewer is identifying specific elements being discussed.", "verifiability_rationale": "The reviewer is posing a question about the effectiveness of the feedback network. This is a claim that could be supported by evidence or analysis. While the point itself doesn't provide evidence, the question itself is a verifiable claim about the network's performance. The reasoning is that the reviewer is making an assertion about the network's behavior, which can be verified.", "helpfulness_rationale": "The reviewer is questioning whether the information about the incorrect phrase, corrected phrase, and the type of mistake is helpful for the feedback network. This is a valid concern and contributes to the helpfulness score. The reviewer is asking whether this type of feedback is beneficial for authors. While the point doesn't directly provide a solution, it's a question about the value of the feedback, making it 3. The reasoning is that the reviewer is asking a question about the utility of the feedback, which is a valid point of critique."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that standard deviations are not shown in Table 1. While it doesn't specify *how* they should be presented, the action is clear: check Table 1 for standard deviations. However, the lack of detail on the implications or required changes makes it somewhat vague on how to apply it.", "grounding_specificity_rationale": "The comment explicitly refers to 'Table 1' as the part of the paper being addressed. The reviewer then lists specific elements within that table that are missing. This demonstrates strong grounding as the section is clearly identified, and the issue within that section is also specified.", "verifiability_rationale": "The comment states a fact: 'Table 1 does not show standard deviations.' There is X being made or supported by evidence. It's a statement of observation, not a recommendation or assertion of something.", "helpfulness_rationale": "The comment identifies a weakness in the paper (lack of standard deviations) but does not provide any suggestions or explanations for how this omission affects the work. It simply states the problem without offering concrete steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the paper is a bit hard to follow and that several sections required more than one reading pass. While this suggests an issue with clarity and potentially actionable steps for improvement, the reviewer does not explicitly state what needs to be done. The suggestions for improvement (improving the structure, focusing on the IEM in Fig 3, and improving the visualization of Figs 7 and 8) are vague and lack specific details. Without concrete actions or clear steps, the review is somewhat implicit in its suggestions.", "grounding_specificity_rationale": "The reviewer mentions 'several sections' and suggests improvements to 'structure,' 'IEM in Fig 3,' and 'visualization of Figs 7 and 8.' While the *topics* of these suggestions are clear, the *exact location* within the paper is not precisely specified. For example, 'structure' is a broad term, 'IEM in Fig 3' is somewhat specific but doesn't pinpoint the exact element within the figure, and 'visualization of Figs 7 and 8' is very broad. This lack of precise grounding makes the review somewhat weakly grounded.", "verifiability_rationale": "The reviewer states that the paper is a bit hard to follow and suggests improvements to the structure, visualization of Figs 7 and 8, and focusing on the IEM in Fig 3. These statements are presented as suggestions or recommendations, not as claims that require verification. There is no explicit claim made in this review. The suggestions are vague and lack specific details or evidence to support their effectiveness.", "helpfulness_rationale": "The reviewer's comments are vague and lack specific details. While they identify areas for improvement (clarity, structure, visualization), they do not provide concrete, actionable steps or evidence to support their claims. The suggestions are broad and do not offer specific guidance on *how* to improve the structure, visualize the IEM, or enhance the visualization of Figs 7 and 8. The lack of specificity makes it difficult for the authors to take meaningful action based on this review."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desired information: 'I'd like to know the final used learning rates for the deep models (particularly CIFAR10 and CIFAR100)'. This is a direct and clear action. The reviewer also specifies the *purpose* of this information, which is to address a potential concern about the learning rate search space. The request is concrete in that it asks for specific values for specific datasets. The reviewer does not ask for a general explanation or suggestion, but rather specific data points.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific section, table, or figure in the paper. They refer to 'the final used learning rates' generally. However, the reviewer *does* specify the *datasets* for which they want the learning rates (CIFAR10 and CIFAR100). This makes the grounding somewhat implicit but the specificity about the datasets is clear.", "verifiability_rationale": "The reviewer is not making a claim about the *effectiveness* of the learning rates or suggesting a *fix* for any issues. They are simply asking for the *values* of the final learning rates used for specific datasets. Since there is X being made, there is no verification required in the traditional sense. The reviewer is providing information that could be helpful for the authors, but it's not a claim that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer directly addresses a potential concern the authors might have regarding the experimental setup and the reliability of the results if the optimal learning rate was outside the tested interval. By providing the final learning rates used for CIFAR10 and CIFAR100, the reviewer is offering concrete information that could help the authors understand and potentially replicate the experiments. The information is directly relevant to the stated issue and is presented clearly."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point identifies a potential issue (unclear impact of mitigation strategies on performance) but does not explicitly state what action the author should take or how to address it. It raises a question rather than providing a direct instruction. Therefore, it is Partially Actionable.", "grounding_specificity_rationale": "The review point discusses mitigation strategies in general without specifying which part of the paper these strategies are applied to or what specific aspect of \"overall performance\" is being considered. It lacks specificity regarding the paper's sections, tables, figures, or unique elements. Therefore, it is 1.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It's a question about the impact of mitigation strategies on performance, not a statement that needs to be supported by evidence or reasoning. Therefore, it is X.", "helpfulness_rationale": "The review point raises a valid concern about a potential tradeoff. It highlights a potential issue that the author might need to consider when implementing mitigation strategies. While it doesn't offer solutions, it points to a relevant area for further investigation or discussion. Therefore, it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that they understand the need for crossvalidation, indicating that the action (applying crossvalidation) is clear and the subsequent action (understanding its purpose) is also clear. Therefore, the reviewer is able to identify and take the next step in applying the suggested action.", "grounding_specificity_rationale": "The reviewer explicitly states 'Although it is provided that a 6fold crossvalidation is used for every dataset' and then asks 'Therefore, it is not clear why 6fold crossvalidation is required for this problem.' This clearly identifies the specific part of the paper being addressed (the justification for using 6fold crossvalidation) and explains what is wrong or missing (the lack of clear justification). This can be achieved through a general comment implying the relevant part without explicitly naming it, making it weak grounding. However, the reviewer does identify the issue and asks a question about it, indicating they can infer the need for justification. Therefore, it is weakly grounded but specifies the issue.", "verifiability_rationale": "The reviewer states 'Therefore, it is not clear why 6fold crossvalidation is required for this problem.' This is a claim that requires justification. However, the reviewer does not provide any external references or specific examples to support this claim. The justification is based on their own experience and comparison to other papers. Therefore, the claim is present but lacks key elements like examples or references, making it 3.", "helpfulness_rationale": "The reviewer's point is relevant to the paper's methodology, as it raises a valid question about the justification for using 6fold crossvalidation. This could help the authors understand a potential limitation or improvement. However, the reviewer does not provide any concrete suggestions or solutions based on their point. Therefore, while the point is relevant, it does not directly lead to actionable improvements for the authors, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point focuses on criticizing the experimental evaluation and doesn't provide any specific actions or suggestions for the authors to take based on this criticism. The reviewer states that the results are insufficient but doesn't outline how the authors should improve their results or the evaluation methodology. Therefore, the review point lacks explicit and actionable feedback for the authors.", "grounding_specificity_rationale": "The review point mentions 'Table 2' and the 'proposed approaches' and 'baselines' generally. While it identifies a specific table, it doesn't pinpoint a specific cell, row, or column within Table 2 that needs improvement. The reviewer could be referring to any of the methods or results presented in the table. Therefore, while a section of the paper is mentioned, the specific part being addressed is not clearly identified, making it weakly grounded. However, the reviewer *does* specify the *type* of result being criticized (the performance of the proposed methods compared to baselines), which adds a degree of specificity to the *nature* of the issue. This leans towards 'specific' as the reviewer is clear about the * kind of result being problematic. The combination of mentioning a table (weak grounding) and specifying the type of result (specific issue) leads to a '3' label.", "verifiability_rationale": "The review point makes a claim that the results presented are insufficient to prove the benefits of the proposed methods. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim within the review point itself. The claim is presented as an assertion without any backing. Therefore, the claim is not verifiable based on the information provided in the review point.", "helpfulness_rationale": "The review point criticizes the experimental evaluation, specifically mentioning the limited positive results and inconsistent trends. While the reviewer identifies a problem with the evaluation, they do not offer any concrete suggestions or actions for the authors to take to address this problem. The review point focuses on the *evaluation* rather than providing actionable feedback to improve the authors' work or the evaluation methodology. Therefore, the review point is not helpful in guiding the authors towards improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential area for improvement by pointing out the presence of heuristic components. However, it does not explicitly state what actions the authors should take to address this. The reviewer raises a question about the impact of these components, indicating a need for clarification rather than a direct action.", "grounding_specificity_rationale": "The review point explicitly mentions 'NonAmbiguous Query Generation procedure relies on a sophisticated filtering template.' This clearly identifies a specific part of the paper and how the authors can locate it. The reviewer names a component of their method, fulfilling the criteria for full grounding.", "verifiability_rationale": "The review point does not make a claim that needs verification. Instead, it asks for clarification regarding the impact of heuristic components. This is a request for information rather than a statement of a problem or suggestion for action.", "helpfulness_rationale": "The review point raises a valid concern about the heuristic aspects of the framework. By asking for clarification on the impact of these components, the reviewer guides the authors towards a relevant area of improvement. While it doesn't provide a direct solution, it highlights a potential area for further work and encourages the authors to focus on understanding the behavior of these components."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a specific missing piece of information needed for the proposed method (ray marching) to function. They identify the 'knowledge of CAD model correspondences' as a requirement and question the origin of the rays. While the reviewer doesn't explicitly state what should be done, they clearly identify a gap in the proposed method. This is an implicit actionability, as the reviewer highlights a necessary component that is absent. The action is clear: the method requires this information to work, and the reviewer suggests it might be a limitation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'knowledge of CAD model correspondences' and links it to the proposed method 'ray marching'. They state that this information is needed for ray marching to function. This demonstrates a clear grounding as the reviewer accurately identifies a specific aspect of the paper (CAD model correspondences) and how it is directly addressed by the mentioned method (ray marching). The grounding is strong because the reviewer names a specific section or detail and connects it to a particular technique.", "verifiability_rationale": "The reviewer questions the claim that 'ray marching can be trained without using any camera information'. They explain that without knowing the viewpoint (which is related to camera information) and the origin of the rays, it's difficult to perform ray marching. The reviewer provides a logical reasoning for why camera information might be necessary. They argue that knowing the viewpoint is crucial for determining the direction of the rays. While the reviewer's point is plausible, it might benefit from more context or clarification about the specific ray marching technique being referred to. The claim is not entirely unsupported, but the reviewer's reasoning provides a basis for questioning it.", "helpfulness_rationale": "The reviewer offers a critique of a specific assumption in the paper regarding the necessity of camera information for ray marching. While the critique highlights a potential limitation or a point of confusion, it doesn't directly suggest a concrete improvement or solution. The reviewer's point is valuable in identifying a potential area for further investigation or clarification in the paper. However, it might be perceived as less directly helpful than a suggestion for a specific change to the method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the paper would benefit from a more detailed comparison with related work. This is an explicit action. Furthermore, the reviewer specifies the aspects of the comparison, namely 'time complexity' and 'competitiveness', making the action concrete. While the 'minor' aspect is vague, the core suggestion is clear and actionable.", "grounding_specificity_rationale": "The reviewer mentions 'related work', 'time complexity', and 'competitiveness'. While the general area of 'related work' is mentioned, the specific aspects of 'time complexity' and 'competitiveness' are clearly identified. This indicates that the reviewer can accurately pinpoint the issue within a specific area of the paper, but the initial mention of 'related work' is not a precise section reference. Therefore, the grounding is weak. The specificity is high because the reviewer clearly states the aspects that need improvement.", "verifiability_rationale": "The reviewer makes a claim that the paper 'would benefit from a more detailed comparison with related work, in particular making a detailed comparison to the time complexity and competitiveness of prior art'. This is a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no evidence of how this comparison would be made or why it would be beneficial. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer identifies a clear weakness in the paper: the lack of a detailed comparison with related work, specifically regarding time complexity and competitiveness. The reviewer also suggests a concrete improvement: adding this detailed comparison. While the suggestion is clear and actionable, the lack of justification or supporting evidence makes it difficult to assess the actual value and impact of this suggestion. Therefore, the review is 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the action \"conducing experiments\" and suggests it needs to be done on \"more datasets,\" which is a concrete direction for improvement.", "grounding_specificity_rationale": "The reviewer identifies the *type* of improvement (\"more datasets\") but doesn't pinpoint a specific section, table, or unique element within the paper.", "verifiability_rationale": "The reviewer makes claims about conducting more experiments and using the full dataset but doesn't provide explicit reasoning, examples, or references to back these suggestions up.", "helpfulness_rationale": "The reviewer provides clear suggestions for improving the experimental evaluation, which is a significant aspect of research validation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states, 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' This statement identifies an implicit action or statement that needs to be inferred. The reviewer does not explicitly state what they believe is incorrect or how the tasks should have proven the claims. While the reviewer points to a potential issue, they do not provide a clear path for the authors to address it. Therefore, this comment lacks a clear, explicit action for the authors to take.", "grounding_specificity_rationale": "The reviewer states, 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' This comment does not identify a specific part of the paper or methodology being addressed. The reviewer is commenting on the overall process and the lack of clarity in the experimental setup. Therefore, the comment is 1 in a specific section, table, or figure of the paper. The reviewer identifies a lack of clarity but does not specify where this lack of clarity exists.", "verifiability_rationale": "The reviewer states, 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' This statement can be considered a claim, as the reviewer is making a judgment about the clarity and effectiveness of the experimental setup. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a statement of opinion rather than a claim requiring verification. Therefore, the claim is not supported by any evidence.", "helpfulness_rationale": "The reviewer explicitly states, 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' They also state, 'All in all, the whole dataset transformation and the ensuing experimental setup felt very cumbersome, and not very clear.' These statements directly indicate that the reviewer did not find the feedback helpful. They express a lack of understanding and the absence of actionable suggestions. Without any clear or specific guidance, the feedback is unlikely to be helpful to the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the comparison of PL conditions, which implies an action: 'Compare the PL condition I use with the one in the cited paper.' This action is explicit, as the reviewer directly states the intention of making the comparison. The reviewer does not explicitly state how to perform this comparison, but the act of comparing is a clear action that the author can undertake.", "grounding_specificity_rationale": "The reviewer explicitly states 'How does the PL condition you use compare with the PL conditions proposed in \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u0141ojasiewicz Functions\", arXiv:1709.03014?'. The reviewer directly identifies the specific PL condition they are referring to ('the PL condition I use') and the paper to compare it with ('the PL conditions proposed in the cited paper'). This clearly grounds the comparison to specific elements of the paper.", "verifiability_rationale": "The reviewer asks a question about a comparison. There is X or suggestion of improvement being made. The purpose is to seek information, not to critique or recommend changes. Therefore, the claim is 'X' as it does not contain a claim, judgment, or suggestion.", "helpfulness_rationale": "The review point asks a question about the comparison of PL conditions. While this is relevant to the author's work, it does not directly identify a weakness or suggest a concrete improvement to the current draft. The request is more of a suggestion for further research or context rather than a direct critique of the author's work. Therefore, it is not 5 in improving the draft itself."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises two questions, both of which can be considered implicit actions. The first question implicitly suggests that the authors should investigate the potential for information leakage from the ImageNet pretraining of the AutoAugment policy. The second question implicitly suggests that the authors should consider the implications of their pretraining findings for selfsupervised learning algorithms that aim for generic representations. While the actions are not explicitly stated as 'investigate' or 'consider,' they are clear directions for the authors to take further analysis. However, the actions lack concrete details on how to perform the investigation or what specific analyses to conduct.", "grounding_specificity_rationale": "The review point does not explicitly mention any specific part of the paper (e.g., a particular section, table, or figure). It is focused on the general methodology and interpretation of results. Therefore, the grounding is weak. The authors cannot confidently identify which part of their work the reviewer is referring to.", "verifiability_rationale": "The review point raises questions about the pretraining dataset and its impact on the results. While it doesn't explicitly state a claim that requires verification, the implicit questions about information leakage and the implications for SSL algorithms could be considered as underlying claims that need further clarification or investigation. However, the verifiability is low because the reviewer doesn't provide specific evidence or references to support their concerns. The questions are more of a call for clarification rather than a definitive statement that needs immediate proof.", "helpfulness_rationale": "The review point raises two important questions that could help the authors improve their draft. The first question prompts the authors to consider the potential impact of pretraining data on their findings, which could lead to a more nuanced interpretation of the AutoAugment results. The second question encourages the authors to reflect on the implications of their pretraining findings for selfsupervised learning algorithms. These questions are relevant and thoughtprovoking, and they encourage the authors to engage in further critical thinking about their work. While the reviewer doesn't provide a direct solution, they highlight potential areas for further investigation and discussion."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The first part of the review point explicitly states 'the paper has weak analysis on the alignment of entity representations,' which is an explicit action or suggestion. However, the second part, 'the authors could add more analysis about the multilingual alignment of entity representations and it would be better to have visualizations or case studies for different types of languages such as language family,' is an implicit suggestion. While the reviewer clearly states they want *more* analysis, the specific areas for improvement are not explicitly named. Therefore, while the first part is explicit, the second part lacks concrete details, making it vague.", "grounding_specificity_rationale": "The reviewer mentions 'entity representations' and 'alignment' in the context of 'weak analysis' and 'multilingual alignment.' This indicates a general understanding of the area being discussed. However, the reviewer does not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The mention of 'language families' is a general suggestion rather than a specific reference to a particular part of the paper. Therefore, while the topic is grounded, the specific location or detail within the paper is not clearly identified.", "verifiability_rationale": "The reviewer states 'the paper has weak analysis on the alignment of entity representations.' This is a claim that needs to be supported. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to back up this claim. While the reviewer offers suggestions for improvement, they do not explain *why* the current analysis is weak. Therefore, the claim is not verifiable based on the information provided.", "helpfulness_rationale": "The reviewer provides specific areas for improvement, such as 'multilingual alignment,' 'language families,' and the suggestion for 'visualizations or case studies.' These suggestions are actionable and directly address potential weaknesses in the paper. However, the reviewer does not provide any evidence or reasoning to support their claim that the current 'analysis of entity representations' is 'weak.' Without this justification, the suggestions are presented without a clear understanding of the specific problems they aim to solve. Therefore, while the suggestions are concrete, the lack of supporting evidence reduces their helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the presence of duplicates and missing information in the references list. It directly points out the issues without requiring the authors to infer them. The actions to take are clear: remove duplicates and include missing venue/year information.", "grounding_specificity_rationale": "The comment mentions the 'references list' but doesn't specify the exact section, table, or figure where the issues are located. While it identifies the *type* of issues (duplicates, missing venues/years), it doesn't pinpoint the *exact* problematic references. Therefore, the grounding is weak, and the specificity of the issues is also limited.", "verifiability_rationale": "The comment contains a claim stating the issues with the references list. However, it does not provide any justification or reasoning for why these issues are problematic or how they should be addressed. There are no external references or logical reasoning provided to support the claim. The comment only states the *what* without explaining the *why* or *how*.", "helpfulness_rationale": "The comment identifies concrete issues with the references section, such as duplicate entries and missing publication venues/years. This directly informs the authors about areas they need to address. While it doesn't explain *why* these are problems or *how* to fix them, it provides a clear starting point for improvement by highlighting specific actionable items."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues with the theoretical analysis in Theorem 1, specifically mentioning the unclear meaning of the error bound. They also suggest concrete actions, such as clarifying the error bound and comparing the results with other methods. This indicates a clear understanding of what needs to be addressed and how to do it.", "grounding_specificity_rationale": "The reviewer refers to 'the theoretical analysis in Theorem 1' and specifically points out the 'error bound'. They also mention the need to 'compare the theoretical results to other comparable methods'. This clearly identifies the specific part of the paper and the specific issue being addressed, making the grounding quite explicit.", "verifiability_rationale": "The reviewer makes a claim about the theoretical analysis being 'unclear' and suggests actions to 'clarify and compare' it. This claim is verifiable because the actions are concrete and welldefined. The reviewer is stating a problem and providing a path to solve it.", "helpfulness_rationale": "The reviewer provides specific feedback on a key aspect of the paper (the theoretical analysis) and suggests concrete improvements. This feedback is directly relevant to the authors and addresses a specific weakness, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the question: 'why the explicit methods perform better than implicit methods on the locomotion tasks'. This directly addresses a relationship between two methods. However, it doesn't provide a concrete action or suggestion on how to investigate or improve this. The reviewer identifies a gap in understanding but doesn't offer a specific step to address it.", "grounding_specificity_rationale": "The review point mentions 'locomotion tasks' and compares 'explicit methods' with 'implicit methods'. While it identifies the area of the paper being discussed, it doesn't pinpoint a specific section, table, or unique element within the paper. The mention of locomotion tasks is general, and the comparison is at a high level. Therefore, the grounding is weak.", "verifiability_rationale": "The review point contains a claim: 'why the explicit methods perform better than implicit methods on the locomotion tasks'. This is a declarative statement about the observed performance difference. However, the review point does not provide any logical reasoning, common knowledge, or external references to support this claim within its own text. It simply states the observation without further explanation or evidence.", "helpfulness_rationale": "The review point raises a valid concern about the performance difference between explicit and implicit methods in locomotion tasks. It points out the absence of pseudocode for the proposed method. However, it doesn't offer any concrete suggestions or actions to address this concern. It doesn't explain *why* explicit methods might be better, *how* the performance difference could be investigated, or *what* steps could be taken to improve the method. The mention of missing pseudocode is a symptom but not a direct solution or actionable insight."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out the limitations of using lowresource language pairs and the R3F method, which are explicit actions. However, the suggestion to 'use the method like R3F to maintain the generalization ability of the model' is implicit and requires the authors to infer the intended action. The vagueness of 'other methods' makes it difficult to pinpoint exactly what needs to be done.", "grounding_specificity_rationale": "The reviewer mentions 'lowresource language pairs' which is a general concept. While they imply this relates to a specific part of the model training or experimental setup, they don't explicitly identify a specific section, table, or unique aspect of the paper. The mention of '0.8 improvement' is numerical but doesn't directly pinpoint a specific figure or section in the paper that needs addressing. The grounding is weak because the reviewer doesn't provide a clear reference point.", "verifiability_rationale": "The reviewer makes a claim that 'it is insignificant in a practical sense' regarding the 0.8 improvement. This claim is supported by the reasoning that 'the improvement of 0.8 can be claimed'. The reasoning, while present, is somewhat vague and could benefit from more concrete examples or references to establish the significance. The claim is supported by a logical argument, but the argument itself is not fully robust.", "helpfulness_rationale": "The reviewer identifies a potential issue with the reported improvement and points out the lack of references to support the claim of practical insignificance. This directly addresses a gap in the information provided and suggests improvements to the method or the evaluation. The reviewer's suggestion to 'better finetuning by reducing representational collapse' is a constructive suggestion, although it is not explicitly linked to the lowresource language pairs. The missing references are a clear and actionable point for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests visualization as a way to address the identified research motivation. While it points in the right direction, it lacks specific action and implementation details. The reviewer is pointing out a desired outcome (visualization) but not detailing the process.", "grounding_specificity_rationale": "The review point refers to \"the authors\" and their \"research motivation.\" It doesn't pinpoint a specific section, table, figure, or unique aspect of the paper. The reference to \"the authors\" is general.", "verifiability_rationale": "The review point states: \"It would be better if the authors can visualize this effect.\" This is a suggestion, not a claim that something is wrong or needs addressing. There's no assertion that the current approach is lacking evidence or justification.", "helpfulness_rationale": "The review point identifies a relevant area for improvement but lacks the specific guidance needed for high helpfulness. While the suggestion is pertinent to the stated motivation, it doesn't provide concrete steps or details on how to achieve the visualization."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests specific actions for improvement, such as referencing related work and investigating the differences in figures. The suggestion to 'check that useful communication is actually happening' provides a clear direction for further analysis.", "grounding_specificity_rationale": "The review point refers to the 'result description' and 'figures,' which are specific parts of the paper. The reviewer also suggests investigating 'differences in figures' and 'check that useful communication is actually happening,' which are specific aspects of the results.", "verifiability_rationale": "The review point includes claims that are supported by citations to relevant literature, such as 1 and 2.", "helpfulness_rationale": "The review point is clear, provides specific suggestions, and offers a concrete area for investigation. The suggestions are directly related to improving the clarity and potential utility of the results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "6", "helpfulness_label": "5", "actionability_rationale": "The review point identifies the lack of knowledge about optimal textual formats for policy learning and the need for human labor in building text descriptions. While the reviewer suggests exploring different formats, the action of *exploring* is not explicitly stated. The reviewer points to a problem (lack of knowledge) and suggests a direction (exploring formats), which implies an action but doesn't define it precisely. Therefore, the action is implicit.", "grounding_specificity_rationale": "The review point explicitly mentions \"text descriptions for each task\" and \"optimal textual format is optimal for policy learning\". This clearly grounds the comment in the specific aspect of the paper being discussed. The reviewer is directly referring to the *text descriptions* and the *format* of the text.", "verifiability_rationale": "The review point states \"We do not know what textual format is optimal for policy learning.\" This is a statement of a problem or observation, not a claim that requires verification. The reviewer is expressing their current understanding and concerns about the lack of knowledge. There is no explicit claim being made and no evidence being presented.", "helpfulness_rationale": "The review point clearly identifies a problem (lack of knowledge about optimal textual formats) and suggests a solution (exploring different formats). This provides a clear direction for improvement and is a constructive suggestion. The reviewer is directly addressing a specific area where the authors might need help."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point mentions a 'performance improvement' and a specific number (0.02). While it points to a potential issue, the *action* isn't explicit. The authors are *told* there's improvement, *where* it is, and *how much* it is *if* it happens. They aren't told *what* to change or *how* to achieve that improvement. The suggestion about tables is more concrete in *presentation*, but the *action* of how to use them is vague.", "grounding_specificity_rationale": "The review explicitly mentions 'the biggest improvement in the bank dataset' and provides a specific numerical value (0.02). This clearly identifies the specific part of the paper being addressed, making the grounding fully explicit. The comment also specifies what is being measured ('performance improvement').", "verifiability_rationale": "The review states 'As shown in figure 3, the performance improvement of proposed methods seems not so significant, the biggest improvement in the bank dataset was ~0.02.' This is a statement of opinion or judgment about the results. It's a claim that the improvement isn't 'significant.' It also states a fact ('biggest improvement...0.02'). The suggestion about tables is a suggestion, not a claim requiring verification.", "helpfulness_rationale": "The review points out a potential weakness (lack of significant improvement) and suggests a way to present the data better. While the suggestion about tables is helpful for clarity, the core issue of the 'performance improvement' being unclear (the *nature* of the improvement) isn't resolved. The reviewer is pointing out a potential problem, but not providing a concrete solution or actionable steps for the authors to take to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the limitations of the experimental validation, mentioning 'only shallow networks are considered (2 or 3 layers)' and 'optimization strategy, including the grid search strategy for hyperparameters selection, is not described'. These are direct statements of what is missing, making it easy for the authors to understand the gaps in the evaluation. While the reviewer doesn't explicitly name an *action* to take, the lack of detail implies an action is needed to improve the validation.", "grounding_specificity_rationale": "The reviewer mentions 'Experimental validation are not convincing' generally, but also specifically identifies 'shallow networks (2 or 3 layers)' and 'optimization strategy, including the grid search strategy for hyperparameters selection' as the areas of concern. This provides a clearer indication of the specific issues. Furthermore, the reviewer points to a *specific* related work area (network pruning) as a minor issue, which helps the authors understand the context and potential connections.", "verifiability_rationale": "The review point contains a claim: 'Experimental validation are not convincing' and identifies specific limitations: 'only shallow networks are considered (2 or 3 layers)' and 'optimization strategy, including the grid search strategy for hyperparameters selection, is not described'. The reviewer also suggests considering 'layer redundancy (which is the opposite of diversity) has been considered in the context of network pruning'. While the claim itself isn't explicitly justified with a logical reasoning step within the review point, the suggestions for improvement offer a basis for understanding why the validation might be limited. The reviewer implies the lack of detail makes the validation less reliable.", "helpfulness_rationale": "The review point is helpful in that it identifies concrete weaknesses in the experimental validation and suggests concrete improvements. The reviewer points out the limited scope of the networks considered and the lack of detail on the optimization strategy, which are actionable points for the authors. The suggestion to consider layer redundancy in pruning, even as a minor point, offers a direction for further investigation. While the suggestions could be more detailed, they are still valuable and directly related to the identified issues."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a clear weakness: the lack of new theoretical results. This is an explicit statement of a deficiency, and the authors can directly infer the need for new theoretical contributions. The reviewer identifies the specific area of improvement (lack of new theoretical results) and even suggests a potential direction (new application of a known loss function). This provides a concrete action for the authors to take.", "grounding_specificity_rationale": "The review refers to 'this work' generally, indicating a lack of specific grounding. While the reviewer identifies the *type* of missing result (new theoretical results), they don't pinpoint a specific section, table, figure, or unique element of the paper that needs improvement. The weakness is more general \u2013 the lack of *any* new theoretical results, rather than a specific issue in a particular section.", "verifiability_rationale": "The review contains a claim: 'this work does not prove any new theoretical results.' However, it does not provide any evidence or reasoning to support this claim. There are no references to specific papers, theorems, or logical arguments. The reviewer simply states the deficiency without justifying it.", "helpfulness_rationale": "The review identifies a clear weakness: the lack of new theoretical results. However, it does not offer any suggestions for improvement or actionable steps to address this weakness. The authors would need to go back to the drawing board to figure out what to do about this lack of theoretical contribution. The review points out a problem but doesn't provide a path forward."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests possible explanations for why certain image parts might be easier or harder for humans. While this doesn't directly tell the authors *what* to do, it points towards potential areas of investigation. The action isn't inferred, making it not fully actionable.", "grounding_specificity_rationale": "The reviewer proposes a hypothesis about the characteristics of 'trivial' and 'impossible' parts but doesn't specify *which* parts or *what specific issue* within those parts. The grounding is weak as the authors can only make an educated guess about the referenced parts.", "verifiability_rationale": "The reviewer makes a claim about a potential hypothesis but doesn't provide any external references or specific examples to support it. The claim is presented as a suggestion rather than a welljustified statement.", "helpfulness_rationale": "The reviewer offers a potential explanation for a phenomenon observed in human experiments and asks a relevant question about whether the authors have evidence. This suggests they believe their hypothesis is worth investigating and could potentially lead to new insights or research directions. While it doesn't directly tell them how to improve their draft, it's a valuable contribution to the research process."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests \"improve it\" and \"give more illustrations and examples.\" While it points to an action, the specifics of *how* to improve Sec. 3.2 and *what* kind of illustrations/examples would be beneficial are not explicitly stated. The action is implied but not fully detailed.", "grounding_specificity_rationale": "The review point explicitly refers to \"Sec. 3.2\" and states a problem with it (\"It is hard to follow\"). This clearly identifies the specific section and the issue within it.", "verifiability_rationale": "The review point contains a claim: \"It is hard to follow Sec. 3.2.\" While the suggestion to \"give more illustrations and examples\" is a potential solution, the review point itself does not provide any external references, logical reasoning, or citations to support the claim that Sec. 3.2 is indeed difficult to follow. The suggestion is a recommendation, not a verifiable statement within the review point itself.", "helpfulness_rationale": "The review point identifies a clear weakness (\"It is hard to follow Sec. 3.2\") and offers a concrete and generally helpful suggestion (\"give more illustrations and examples\"). It clearly indicates what the author should do to improve the paper. While the *specificity* of the improvement is lacking, the general direction is actionable and beneficial."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of adding fullysupervised baselines and provides concrete details on where (table 1) and what kind (for small models) of baselines should be added. This makes the action clear and actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'fullysupervised baselines,' 'small models,' and 'table 1,' which are specific parts of the paper. It also clearly states the purpose of adding these baselines, which is to 'understand the gap between full supervision and SSL for these models.' This indicates that the authors can accurately pinpoint the referenced part and understand the issue.", "verifiability_rationale": "The comment contains a claim (suggestion to add baselines) and provides a clear justification for why this is useful ('will be useful in understanding the gap between full supervision and SSL for these models'). This justification is logical and specific.", "helpfulness_rationale": "The review point directly suggests a concrete and beneficial improvement to the paper by adding existing, wellestablished baselines. This is a clear and helpful suggestion for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue (scalability) related to hypervolume calculation. This is an *implicit* action, and while the reviewer identifies the problem, they don't explicitly state how to address it. Therefore, it is *3*.", "grounding_specificity_rationale": "The reviewer refers to \"LaMOO\" and \"hypervolume calculation.\" This is a specific algorithm and a specific concept. The reviewer also mentions \"many objectives.\" This is quite specific. The comment explicitly mentions which part of the paper it addresses, or it should be obvious to the authors. However, this comment does not specify what needs to be addressed in this part. Therefore, it is **4**.", "verifiability_rationale": "The reviewer claims the hypervolume calculation is timeconsuming. This claim is based on the reviewer's understanding of hypervolume calculation and its potential impact on scalability. This claim is verifiable, as it is based on a known property of hypervolume calculations. Therefore, it is **partially verifiable**.", "helpfulness_rationale": "The reviewer raises a concern about the practical applicability of the algorithm. This is a helpful comment, as it highlights a potential limitation that could affect the algorithm's usability. However, it is not a direct suggestion for improvement. Therefore, it is **3**."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer identifies limitations of evolutionary methods and suggests exploring state, reactiveness, and learning during an episode. While these are valid points, the suggestions are general and lack specific action items. For example, the reviewer could have suggested specific modifications to the evolutionary algorithm or pointed to relevant literature on stateful RL. The lack of concrete steps makes the actionable aspect borderline.", "grounding_specificity_rationale": "The reviewer refers to 'evolutionary methods,' 'state, reactiveness, and learning,' and 'convergence properties' in general terms. While they don't explicitly point to a specific section or table, they do identify areas that could be improved. However, they don't pinpoint the exact location or detail within the paper. The mention of 'brittle convergence properties' is a general observation rather than a specific, identifiable issue.", "verifiability_rationale": "The reviewer states that 'DeepRL methods are widely adopted' and suggests considering the 'landscape 10 years ago.' While this is a valid observation, the reviewer doesn't provide specific examples or references to support their claim within the review point itself. They also don't explain what they mean by 'brittle convergence properties' or how evolutionary methods might address this. The claim is stated but lacks sufficient justification or evidence within the provided text.", "helpfulness_rationale": "The reviewer provides several points for improvement, such as suggesting 'honest and direct' feedback and recommending considering the 'landscape 10 years ago.' While these are constructive suggestions, they are quite general and lack specific details or actionable steps. For example, what kind of 'honest and direct' feedback? What specific aspects of the 'landscape 10 years ago' should be considered? The feedback is broad and doesn't offer concrete guidance for the authors. The helpfulness is limited by the lack of specific action items and justifications."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for clarification on three key aspects: the synthesis of the focal stack, the forward model of defocus synthesis, and the handling of depth discontinuities at image edges. These are all implicit actions that the authors should take as part of implementing the method described in the paper. The reviewer is prompting the authors to explicitly state how they performed these steps, which would guide them in applying the method correctly.", "grounding_specificity_rationale": "The review point directly refers to specific components of the method: 'focal stack,' 'defocus map,' 'image,' 'depth discontinuities,' and 'edges.' These are concrete parts of the paper, and the reviewer is asking the authors to specify how these elements relate to the synthesis of defocused images. This demonstrates a clear grounding in the specific sections and details of the paper being discussed.", "verifiability_rationale": "The review point raises questions about the methodology and implementation details of the defocus synthesis. While it doesn't explicitly state a claim that requires verification, it points to areas where the authors likely have gaps in their understanding or implementation. The reviewer is implicitly suggesting that the authors should provide more details on the forward model and the handling of edges to make their work more reproducible and robust.", "helpfulness_rationale": "The review point directly addresses specific methodological and implementation details of the defocus synthesis. It asks for clarification on how the focal stack was synthesized, the forward model used, and how depth discontinuities at image edges were handled. These are all crucial aspects for understanding and potentially reproducing the method. The reviewer is providing concrete feedback on areas where the authors likely have gaps in their understanding or implementation."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out the use of nonnovel algorithms (MLP, Regression Tree, Random Forest) and the similarity of the sampling strategy to existing methods (epsilongreedy, BRPNAS). While the reviewer names specific algorithms and methods, the action is to identify these issues, which could be considered somewhat explicit. However, the reviewer doesn't provide concrete steps on how to improve the approach based on these observations, making it less actionable.", "grounding_specificity_rationale": "The reviewer mentions 'the specific components of the approach' which is a general statement. They then name specific algorithms (MLP, Regression Tree, Random Forest) and a sampling strategy (epsilongreedy, BRPNAS), which grounds the criticism to a specific part of the method. The reviewer also refers to 'NAS performance prediction before 2,3,7' and 'exactly the same as that in BRPNAS5' which specifies the issues in more detail. This indicates a good level of grounding.", "verifiability_rationale": "The reviewer makes clear claims about the lack of novelty, the use of existing algorithms, and the similarity of the sampling strategy. They provide specific examples (algorithms, sampling strategy, performance results) to support these claims. This provides strong evidence and makes the claim verifiable.", "helpfulness_rationale": "The reviewer criticizes the approach and its components, highlighting their limitations and similarities to existing work. While the reviewer identifies weaknesses, the tone is critical and doesn't offer direct, actionable improvements. The suggestions are more about pointing out flaws than providing concrete guidance on how to fix them."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies two areas for improvement: the lack of experiments with continuous tasks and the absence of experiments for entropy methods. It also directly asks for a comparison of empirical performance. The reviewer suggests concrete actions the authors can take to address these issues. The reviewer's request for clarification (asking 'why') indicates a desire for the authors to understand the limitations of their current work.", "grounding_specificity_rationale": "The reviewer's questions directly address specific aspects of the authors' work. They ask about experiments with continuous tasks (a specific part of the paper) and entropy methods (another specific part). They also ask for a performance comparison, which is a specific request for evaluation. The reviewer is pointing out specific areas and asking for information related to those areas, making the grounding specific.", "verifiability_rationale": "The reviewer's questions are not based on claims or suggestions. They are requests for information or clarification about the authors' work. While the reviewer's subsequent request for empirical performance comparison could be considered verifiable if the authors provide it, the initial part of the review point itself does not contain a claim that needs verification. The questions are about what the authors *should* do, not what they *say* about their work.", "helpfulness_rationale": "The review point is 5 because it directly points out missing elements in the authors' work (lack of experiments, missing method evaluation) and asks for specific types of experiments and comparisons. The reviewer is not just criticizing; they are providing concrete suggestions for improvement. The questions are clear and actionable, guiding the authors on what experiments to conduct and what comparisons to make. This makes the review point very informative and helpful for guiding the authors' next steps."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point directly asks for clarification on a specific technical detail (how the evaluation metrics were calculated) and raises a methodological point (the choice of evaluation metric). This is actionable for the authors as it addresses a specific gap in their understanding. While not explicitly stating an action, the reviewer implies a desire for more information, which the authors can then use to improve their draft.", "grounding_specificity_rationale": "The reviewer provides specific details about the metrics (precision, recall, F1score, AUC) and the context (breast density classification, breast cancer detection). This grounds the comment well, as it refers to specific aspects of the paper and the problem being addressed. The reviewer is also asking for justification for a specific choice, which further grounds the comment.", "verifiability_rationale": "The reviewer is asking for explanations of how the metrics were calculated and justification for using AUC. This requires logical reasoning and references (even if they are common practices in the field or the authors' own methodology). The reviewer is not just stating a fact but also asking for a reason behind a choice, which makes it verifiable.", "helpfulness_rationale": "The review point is highly informative and directly addresses a specific gap in the authors' understanding of their evaluation methodology. The reviewer is asking for clarification on a technical detail and suggesting an improvement in their reporting practices (using AUC). This is a valuable contribution that can significantly improve the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the limitations of the crosslayer attention modification and the limited improvement of selfcross attention. However, it does not provide concrete steps or specific details on how to improve the model based on these observations. The reviewer criticizes the choice of transformer without offering concrete alternatives or specific guidance on how to improve it.", "grounding_specificity_rationale": "The comment mentions 'Transformer has been adopted for lots of NLP and vision tasks' and 'selfcross attention brings limited improvement (<1%)'. While it points to specific components like 'crosslayer attention' and 'selfcross attention', it doesn't explicitly identify a specific section, table, or figure in the paper being addressed. The reviewer's claims are about the general performance of these attention mechanisms rather than a specific instance within the paper.", "verifiability_rationale": "The comment contains claims about the novelty of transformers and the lack of ML insight from the modification. It also states the limited improvement of selfcross attention. However, it does not provide any external references or logical reasoning to support these claims within the review itself. The reviewer presents observations based on their own understanding and the ablation study results, but lacks explicit justification for these claims.", "helpfulness_rationale": "The review point offers a specific observation about the limited improvement of selfcross attention and suggests that the main improvements might stem from using a naive transformer. While it points out a potential issue with a specific component, it doesn't offer concrete solutions or actionable steps to address this issue. The criticism of the transformer's novelty is somewhat subjective and doesn't directly guide improvements within the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the limitation of the experiments and suggests a concrete improvement by including sentence inference tasks. While it doesn't directly ask a question, the suggestion is clear and actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'the scope of the experiments' and suggests adding 'sentence inference tasks' like MNLI and RTE. It accurately identifies the area for improvement and specifies the desired change.", "verifiability_rationale": "The comment contains a claim ('the experiments are limited') and provides supporting information by stating the current tasks and suggesting additional tasks. It offers logical reasoning by implying the benefits of expanding the evaluation scope.", "helpfulness_rationale": "The review point identifies a valid limitation in the experimental scope and provides a clear and actionable suggestion to improve the evaluation. It directly addresses a potential weakness and offers a concrete next step for the authors. The suggestion is specific and relevant to the field."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the absence of the prompt, which is an actionable piece of feedback. While it doesn't specify *how* to include it, the implication is a clear action: 'include the prompt'.", "grounding_specificity_rationale": "The comment does not specify where the prompt should be included (e.g., appendix, supplement) or what format it should be in. The grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The comment does not contain a claim that needs verification. It is a statement of expectation or advice.", "helpfulness_rationale": "The comment is directly pointing out a missing resource that would be beneficial for the authors. It's a clear and actionable piece of feedback, though it doesn't guarantee the prompt will be found."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues with the convergence proof by pointing out the contradiction between the claim about Z being noni.i.d. and Assumption 4.1 stating X is i.i.d. They also suggest a specific modification in Appendix C, providing a clear path for improvement. The action is explicitly stated, and the steps to implement it are suggested.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Assumption 4.1' and 'Modification 1 in Appendix C', directly identifying the relevant section and suggesting a concrete next step. This strong grounding allows the authors to focus their investigation.", "verifiability_rationale": "The reviewer makes a claim about the 'lack of substantial novelty and rigor' in the convergence proof. This claim is supported by the logical reasoning that the i.i.d. assumption leads to a clear covariance structure and allows for straightforward modifications. The reviewer provides specific points within the paper (Assumption 4.1 and Appendix C) as evidence, making the claim verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable comment. They identify a potential weakness in the theoretical foundation and suggest a specific area for investigation (the implications of the i.i.d. assumption and the possibility of modifications). This directly benefits the authors by guiding their next steps and highlighting a specific issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the multinode seed cascades are 'artificially created by merging singlenode seed cascades'. This is a direct and clear statement of a methodological limitation that the authors can directly address by understanding the experimental setup.", "grounding_specificity_rationale": "The reviewer explicitly identifies the 'experimental setup' as the area of concern and clearly states how the multinode cascades were created. This makes the grounding explicit and the specificity high as they pinpoint the exact methodological issue.", "verifiability_rationale": "The reviewer makes a claim about the semireal nature of the experimental setup and provides a clear explanation of how this was achieved by merging singlenode cascades. This provides verifiable reasoning for the limitation.", "helpfulness_rationale": "The reviewer's comment is 5 as it directly points out a potential weakness in the experimental design and suggests a concrete improvement (mentioning the source 2). This is a valuable feedback point for the authors to consider."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point does not propose a specific action or suggest how to resolve the conflict between the two statements. It is a question, not a directive. Therefore, it is not actionable.", "grounding_specificity_rationale": "The review point explicitly mentions specific components of the paper: 'multienv model', 'performance loss', and 'knowledge sharing'. This demonstrates strong grounding specificity as the reviewer can easily identify the referenced parts and the issue. The comment specifies what needs to be addressed in this part (the apparent contradiction).", "verifiability_rationale": "The review point does not present a claim that requires verification. It is a question about the interpretation of results, not a statement that needs to be supported by evidence. Therefore, it is not primarily verifiable in the sense of needing external references or logical reasoning to be accepted.", "helpfulness_rationale": "The review point directly addresses a potential point of confusion for the author by highlighting a potential contradiction in the paper's findings regarding the multienv model. It asks a clear question to seek clarification. This directly contributes to the author's understanding and ability to improve their draft. Therefore, it is 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point criticizes the lack of explanation for the metrics used in the paper. It does not explicitly state an action or suggest an action. The reviewer is pointing out a deficiency in the presentation of information, not proposing a concrete step to improve it. Therefore, the review point does not offer actionable feedback.", "grounding_specificity_rationale": "The review point mentions 'the metrics used in the paper,' which can be interpreted as a form of grounding by identifying a specific part of the paper being addressed. However, the reviewer does not specify *what* these metrics are or *why* they are important or relevant to the author's work. The grounding is weak because it doesn't provide specific details about the referenced metrics or their implications. The reviewer is criticizing the lack of explanation rather than providing a clear grounding of a specific aspect.", "verifiability_rationale": "The review point does not make a claim or assertion about the metrics. It is a critique of the presentation of the metrics, not a statement that requires verification. Therefore, it does not fit into the verifiability categories as it is not making a claim that needs to be supported.", "helpfulness_rationale": "The review point is critical and points out a deficiency in the paper's presentation. While it doesn't offer a direct solution, it identifies a need for better explanation of the metrics. By highlighting this lack of explanation, the reviewer is indirectly suggesting that the authors should provide more context and justification for the metrics they use. This critique, while not explicitly actionable in a positive sense, does identify a meaningful weakness and suggests a direction for improvement, making it 3 in highlighting a need for change."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for a definition of 'learned MASK embedding', which is a clear and direct request for information. This makes it 5 as the authors can directly use this information to understand the SSL pretraining stage better.", "grounding_specificity_rationale": "While the reviewer doesn't explicitly name a section or table, the use of 'MASK' strongly implies a specific part of the model or training process. This provides some level of grounding, although it's not as explicit as naming a section. The request is also quite specific, asking for the definition of a particular 'embedding'.", "verifiability_rationale": "This review point does not contain a claim in the sense of criticizing or making a judgment about the paper. Instead, it requests information about a specific term used in the SSL pretraining stage. Therefore, it doesn't have verifiability in the same way as a critique that makes a claim and provides evidence.", "helpfulness_rationale": "The review point is 5 because it directly addresses a potential area of confusion for the authors regarding a specific technical detail in their method. It is clear and directly requests information that would improve their understanding of the SSL pretraining stage."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point is a statement of opinion, not a direct instruction on how to improve the authors' work. While it implies a potential area for improvement, it doesn't explicitly tell the authors what to do or how to do it. Therefore, it is not actionable in the sense of directly guiding the authors' actions.", "grounding_specificity_rationale": "The reviewer mentions 'results already presented in the literature for standard networks' as a basis for their comment. While this provides some grounding by referencing existing work, it doesn't specifically point to a particular part or section of the authors' current draft that needs improvement. The grounding is weak because the reviewer is referencing external knowledge rather than directly addressing the authors' work.", "verifiability_rationale": "The reviewer makes a claim ('the reported results seem to be partially derivative...') and provides a reasoning ('extension to hypernetworks of results already presented in the literature for standard networks...') to support it. This reasoning, while not exhaustive, provides some justification for the claim. Therefore, the claim is 3.", "helpfulness_rationale": "The reviewer points out a potential limitation or area for improvement in the authors' work by highlighting the derivative nature of the results. While it doesn't directly tell the authors how to improve, it identifies a relevant issue that could be discussed with the authors. Therefore, it is 3 in guiding their attention to a potential problem."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the 'scope of the study is underspecified' and provides a specific example of the potential relevance of CoT baselines for LLMs. This indicates a clear action the authors should take. The reviewer also suggests 'additional relevant CoT baselines for incontext learning of Large Language Models (for text003 and ChatGPT) are missing in Table 2 and 3 (See Question A)'. This is an explicit action with a clear goal.", "grounding_specificity_rationale": "The reviewer identifies a potential issue with the study's scope but doesn't explicitly point to a specific section, table, or figure within the paper as being underspecified. While they suggest CoT baselines for LLMs, they don't pinpoint where in the current draft these are missing. The reviewer implies the missing baselines relate to 'text003 and ChatGPT', which could be considered specific, but the initial statement about the scope being underspecified is more general.", "verifiability_rationale": "The reviewer states a claim: 'the scope of the study is underspecified'. They also provide a reason for this claim ('It seems that the work focuses on injecting CoT based approach to smallscale Language Models'). Furthermore, they offer a suggestion: 'If that is not the case, additional relevant CoT baselines for incontext learning of Large Language Models (for text003 and ChatGPT) are missing in Table 2 and 3 (See Question A)'. This provides a clear justification for the suggestion.", "helpfulness_rationale": "The reviewer identifies a potential issue with the study's scope and offers specific, actionable suggestions to address it. The suggestions are directly related to the identified problem and aim to improve the clarity and completeness of the study. The reviewer's feedback is not only identifying a weakness but also providing a clear path for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the problem ('Figure 3 is very hard to read anything') and suggests a concrete action ('improve it'). While it doesn't specify *how* to improve it, the action itself is clear and directly addresses the identified issue.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 3' as the part of the paper being addressed, indicating full grounding. However, the reviewer does not specify what aspects of the figure are difficult to read, making the specificity low.", "verifiability_rationale": "The review point does not make a claim in the sense of proposing a new method or theory. It's a suggestion for improvement ('improve the figure'). While it *implies* that the figure needs improvement for better understanding, it doesn't provide external evidence or logical reasoning to *prove* that the figure is detrimental. Therefore, it's not 5.", "helpfulness_rationale": "The review point identifies a clear weakness ('Figure 3 is very hard to read anything') and suggests a concrete improvement ('improve the figure'). While it doesn't provide specific *howto* instructions, it points to a significant area that will likely be helpful for the authors to understand their data better."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks 'How is this connected?' which is a direct request for an explanation of the relationship between two stated facts. This action is clear and directly addresses the link between the difficulty of symmetric decomposition and the nice landscape of the objective function. While the action itself is not deeply elaborated upon in the review point, the intent is clear.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the fact that tensor decomposition is in general harder in the symmetric than in the nonsymmetric case' and 'the recent findings about the `nice' landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors.' This clearly identifies the specific parts of the paper being addressed, demonstrating strong grounding. The reviewer is asking a question about the connection between these two specific concepts.", "verifiability_rationale": "The reviewer presents a question about the connection between two concepts. While this question can be valuable, it does not contain a claim that requires verification. Therefore, it fits the 'X' category as it doesn't assert an opinion or judgment about the connection itself, but rather asks for information about it.", "helpfulness_rationale": "The reviewer's question prompts the authors to consider the implications of the recent findings on the landscape of symmetric order4 tensor objective functions in relation to the known difficulty of symmetric decomposition. This question can be a valuable point of discussion and can potentially guide further research or analysis for the authors. While it doesn't directly provide a solution, it encourages the authors to connect their work with new findings, making it 3 in guiding their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states two actions to be taken: replacing the mathematical expression `n^2/(2*s^2)` with an arbitrary parameter `lambda` and using a specific learning rate of approximately 0.1. These are direct instructions on how to modify the paper, making the comment actionable. The reviewer clearly intends for the author to implement these changes.", "grounding_specificity_rationale": "The review point explicitly refers to 'lines 119121' for the first suggestion and 'line 164' for the second. This direct referencing clearly identifies the specific part of the paper being addressed, making the grounding fully grounded. The suggestions are also very specific, indicating a high level of specificity.", "verifiability_rationale": "The review point makes a claim that the learning rate of 0.1 is 'unlike the Adam default value, it is unclear what the justification behind this value is.' This statement provides a reason for the claim, indicating that the reviewer has observed a lack of justification for the chosen learning rate. The claim is supported by the absence of a clear rationale and the comparison to the Adam default, making it 5.", "helpfulness_rationale": "The review point is 5 as it directly identifies a lack of justification for a specific hyperparameter (learning rate) and provides a clear, actionable suggestion to use a specific value. This helps the author understand a potential issue and provides a concrete direction for improvement, encouraging them to provide more context or evidence for their choice of learning rate."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the existing work and provides a specific citation. This is a clear and actionable suggestion for the authors.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific paper and the concept related to joint error they are referring to, making the grounding very explicit. They also mention the specific concept of 'joint error' which is highly specific.", "verifiability_rationale": "The reviewer makes a claim about the existing research and provides a specific reference and explanation of the related work. This claim is wellsupported by evidence.", "helpfulness_rationale": "The reviewer provides a specific example of missing related work and asks for a direct comparison. This is a 5 suggestion as it directly addresses a potential gap in the paper's related work section and guides the authors to relevant literature."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the lack of justification for a new curriculum learning method and asks why existing methods can't be applied. This is a clear and direct action the reviewer is taking on the paper.", "grounding_specificity_rationale": "The review point directly refers to \"Section 1\" and asks a specific question about the limitations of existing methods in the context of text graphs. This clearly identifies the specific part of the paper being addressed.", "verifiability_rationale": "The review point makes a claim about the paper's content (that it doesn't discuss the justification for a new method). However, the review point itself doesn't provide any evidence or reasoning to support this claim. It's a statement about the paper's *lack* of discussion, not a statement that can be verified through logical reasoning, common knowledge, or external references within the review point itself.", "helpfulness_rationale": "The review point raises a valid concern about the paper's framing and asks a relevant question. While it doesn't directly critique the methodology, it points out a potential area for improvement in how the paper is presented. This makes it a helpful feedback point, though perhaps not directly addressing a flaw in the methodlogy itself."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment suggests using BERT/XLNet as a base encoder and comparing the efficacy of the transfer parts. This is an explicit action that provides concrete details on how to implement the suggestion. The reviewer also mentions the domainshift problem, which implies a specific area for improvement.", "grounding_specificity_rationale": "The comment explicitly mentions 'powerful pretrained language models, e.g., BERT, XLNet' and the 'domainshift problem'. This strong grounding allows the authors to understand exactly what part of the paper or concept is being addressed. The suggestion to compare the 'efficacy of the transfer parts' further specifies the improvement needed.", "verifiability_rationale": "The comment presents a claim about the effectiveness of pretrained models in overcoming domain shift. While this is a generally accepted idea in the NLP field, the review point itself does not provide specific evidence or references to support this claim. The justification is based on common knowledge rather than explicit verification within the review point.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for improving domain adaptation. By recommending the use of BERT/XLNet as a base encoder and focusing on the transfer parts, it directly addresses a common limitation of using simpler ngram features. This is a relevant and valuable piece of advice for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the issue ('It remains unclear whether the main performance gain originates from a particular module or if the improvement is merely due to having more parameters') and suggests a direct action to investigate this ('The current version of the ablation study does not provide definitive answers to these questions'). The reviewer points out a gap in the analysis and proposes a specific next step.", "grounding_specificity_rationale": "The review point refers to 'the proposed method' and 'the current version of the ablation study' without specifying *which* module or parameter. The reference is general, indicating a lack of precise identification of the problematic element.", "verifiability_rationale": "The review point contains a claim ('The current version of the ablation study does not provide definitive answers') which is supported by the preceding statement of uncertainty ('It remains unclear whether the main performance gain originates from a particular module or if the improvement is merely due to having more parameters'). The claim is directly stated and logically follows from the preceding statement.", "helpfulness_rationale": "The review point identifies a key limitation of the proposed method (unclear source of performance gain) and points to a gap in the analysis (the ablation study). It suggests a potential next step to address this gap ('further investigation into the contribution of individual modules and the impact of the increased number of parameters'). This information is valuable for the authors and directly addresses a potential concern."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states \"this requires more explanation\" and asks a direct question \"Why exactly...\". This indicates an expectation for the authors to clarify a specific point. However, the reviewer does not specify *what* is unclear or actionable for the authors. They are pointing out a lack of clarity, but not directing the authors to a specific step they should take.", "grounding_specificity_rationale": "The reviewer refers to \"the two quantities\" and \"learning settings\" generally, without specifying which part of the paper or what is being discussed. They are asking a question about the difference, but not pointing to a specific section, table, figure, or unique aspect of the paper that needs clarification.", "verifiability_rationale": "The reviewer states \"this requires more explanation\" and asks a question. This is not a claim that needs verification. There is no statement of opinion, judgment, or suggestion. The comment is about the clarity of the paper, not a critique or recommendation.", "helpfulness_rationale": "The reviewer offers a perspective on the submission's potential, stating \"I think NIPS should have room for a few 'pure theory' papers\" and 'still lean toward acceptance\". While this is relevant to the authors' goals, it is not a direct, actionable suggestion for improvement within the current draft. It's a comment on the submission's potential impact, not a specific fix or recommendation for the authors to implement."}
{"actionability_label": "3", "grounding_specificity_label": "3: Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment is a question prompting the authors to discuss a specific aspect of their model. While it encourages discussion, it doesn't explicitly state what parameters to focus on or how to approach the sensitivity analysis. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The comment refers to 'fixed tuning parameters,' which is a specific aspect of the model. The reviewer also asks for both 'strengths and weaknesses,' which further grounds the request. The authors can infer the specific part of the model being addressed and understand the nature of the analysis required.", "verifiability_rationale": "The comment presents a suggestion (the authors should discuss parameter sensitivity) without providing any evidence, reasoning, or references to support this claim. It's a statement of what the authors should do, not a claim that can be verified.", "helpfulness_rationale": "The comment encourages the authors to explore the sensitivity of their model's parameters. This provides a direction for further investigation and can lead to valuable insights for improving their model. While it doesn't provide a readymade solution, it offers a clear area for the authors to focus their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point asks a question about the framework's compatibility with different policy gradient approaches and requests experimental details. While the question is clear, it doesn't explicitly state what needs to be done or suggest an alternative. It's a request for information rather than a direct instruction or solution. Therefore, it's not fully actionable, but it's also not completely 1 as it points towards a potential area for improvement by requesting necessary information for replication or further experimentation. The vagueness lies in the fact that while the question is about the framework's compatibility, the specific action isn't defined.", "grounding_specificity_rationale": "The review point directly asks about the number of random seeds used in experiments. This is a specific detail about the implementation of the experiments. The authors can infer that the number of random seeds is relevant to the reproducibility and reliability of the results presented in the paper. Therefore, the grounding is explicit as the authors can identify the specific experimental parameter being asked about. The specificity is high as the reviewer is asking for a precise numerical value (the number of random seeds).", "verifiability_rationale": "The review point is a question seeking experimental details. It doesn't present a claim or opinion. Therefore, there is X to verify, making it 'X (X)' as per the defined scale.", "helpfulness_rationale": "The review point is a question seeking experimental details. While this information could be helpful for understanding the experiments, it doesn't directly suggest improvements or address a perceived weakness in the proposed framework. The reviewer isn't pointing out a flaw in the framework itself but rather asking for more information about its implementation. This is more of a request for clarification or additional context than a critique that directly prompts improvement. Therefore, it's 1 as it doesn't contribute to the reviewer's ability to improve the framework."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review points out a lack of explicit action. While the authors *should* evaluate on more datasets and tasks, the current evaluation *is* an action (the evaluation itself). The weakness is the *lack of explicitness* in the *desired* action. It's not *not* actionable, but it's not fully actionable in the way it *should* be.", "grounding_specificity_rationale": "The authors mention \"one dataset\" and \"one task,\" but they *don't* specify which ones. This is \"weakly grounded\" because the information is present but not precise. It's also \"underspecific\" because knowing it's \"one dataset\" and \"one task\" doesn't pinpoint the exact area of the paper being evaluated.", "verifiability_rationale": "The suggestion itself is verifiable. The reasoning is clear and logical. Evaluating on more datasets and tasks is a wellestablished practice for strengthening results and conclusions. There's no ambiguity or lack of supporting evidence.", "helpfulness_rationale": "The suggestion directly addresses a limitation of the current evaluation. It provides a clear direction for future work and is a logical next step. It's both verifiable and helpful."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "Not Verifiable", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer does not explicitly state an action the authors should take regarding the unclear definition. The comment is more about the lack of clarity itself, which could lead to ambiguity in actions. Therefore, it's 2.", "grounding_specificity_rationale": "The reviewer explicitly states 'In definition 2.1, what are the \"relevant\" auxiliary model weights?'. This clearly identifies a specific part of the paper. However, the reviewer also states 'The current definition is a bit difficult for me to interpret,' indicating that while the section is identified, the explanation within it is underspecified. Therefore, it is weakly grounded but underspecific.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are criticizing the clarity of a definition. Therefore, it is not verifiable.", "helpfulness_rationale": "The reviewer's primary concern is the lack of clarity in a definition, which directly impacts the authors' ability to understand and act upon the feedback. Without clear guidance, the feedback is not 5. Therefore, it is not 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the weakness of MIA testing and recommends a specific alternative (ULiRA). This is a clear and direct criticism of a methodological aspect.", "grounding_specificity_rationale": "The reviewer refers to 'MIA testing' and 'ULiRA', which are specific methods. They also explain *why* MIA testing is being criticized and *what* ULiRA is recommended, making the grounding clear.", "verifiability_rationale": "The reviewer makes a claim about the limitations of MIA testing and recommends ULiRA. While they don't provide specific examples or citations *within the review point itself*, they do point to a specific tool (ULiRA) which implies a level of grounding and specificity regarding the alternative. The lack of explicit justification within the point itself makes it less 5 than the other aspects.", "helpfulness_rationale": "The reviewer identifies a specific methodological issue (MIA testing limitations) and offers a concrete alternative (ULiRA). This directly addresses a potential concern for the author and provides a clear direction for improvement, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests that the considerations in the paper should also be applicable to kernel (ridge) regression. While this could be a valuable suggestion for future work, the review point itself does not explicitly state an action or modification that the authors should take based on this suggestion. The suggestion is more of a potential extension than a direct instruction. Therefore, while the reviewer's point has the potential to be actionable, the current phrasing lacks the explicitness and concreteness needed for immediate actionability.", "grounding_specificity_rationale": "The reviewer's comment, 'I am not familiar with the literature: all the considerations in this paper should also be applicable to kernel (ridge) regression, no? Maybe this could also be presented in the 'language of kernel interpolation/smoothing' as well?', does not identify a specific part of the paper being addressed. The reviewer is making a general statement about the applicability of the paper's findings to a different area (kernel regression) and suggesting a different framing. The comment is 1 within the specific content or structure of the paper.", "verifiability_rationale": "The reviewer's comment contains a claim: 'all the considerations in this paper should also be applicable to kernel (ridge) regression, no?'. However, this claim is not supported by any evidence, reasoning, or references within the review point. The reviewer is making a hypothesis about the broader applicability of the paper's findings, but they do not provide any specific examples, logical arguments, or citations to back up this claim. Therefore, the claim is not verifiable based on the information provided in the review point.", "helpfulness_rationale": "The reviewer's comment, 'I am not familiar with the literature: all the considerations in this paper should also be applicable to kernel (ridge) regression, no? Maybe this could also be presented in the 'language of kernel interpolation/smoothing' as well?', is not directly addressing specific weaknesses or suggesting concrete improvements to the authors' draft. The comment is more of a forwardlooking suggestion and a question about the paper's broader context. While it might be helpful for the authors in the long run, it does not provide immediate actionable feedback on the current draft. Therefore, the comment is not immediately helpful for improving the authors' current work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for *more* detail and *more specific* suggestions. While the comment implies an action (providing more information), the lack of clarity on *how* to do this makes it 2. The desire for more detail suggests an actionable point, but the vagueness of the request makes it not fully actionable.", "grounding_specificity_rationale": "The reviewer does not explicitly state which part of the paper they are referring to when mentioning the figures (e.g., 'what is 'sample count\" in fig. 2?'). The request for 'supplementary information\" indicates a lack of precise grounding in the paper's content. The confusion about 'sample count\" in the figures further supports the idea that the reviewer is not confidently identifying the specific area being addressed. While the reviewer might have a general idea, they cannot confidently pinpoint the referenced part, making it weakly grounded. However, the comment does specify what needs to be addressed (improving clarity and adding detail), making it somewhat specific in that regard.", "verifiability_rationale": "The reviewer criticizes the qualitative nature of the explanations and the lack of statistical rigor (error bars, pvalues). This directly impacts the verifiability of the claims. The absence of error bars and pvalues makes the statistical claims 1. Furthermore, the qualitative descriptions of the simulations make it difficult to assess the validity of the claims without further evidence or justification. The lack of logical reasoning or external references to support these claims further contributes to the unverifiability.", "helpfulness_rationale": "The reviewer's comments are constructive and point to specific areas for improvement. They clearly identify weaknesses in the paper's explanations and experimental procedures. While the suggestions for more detail and statistical rigor are valuable, the lack of clarity in the current explanations and the absence of statistical support make the feedback somewhat incomplete. The reviewer's desire for more information and better justification is a clear indication of a need for improvement, making the feedback 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests adding references. While this is a valid suggestion, it doesn't directly tell the author what to change or how to improve their current draft. It's a request for more information, not an actionable step. Therefore, it's 1.", "grounding_specificity_rationale": "The reviewer mentions 'Lines 5564' and discusses specific 'factors' affecting ChainofThought prompting. This indicates a clear identification of a specific section and elements within that section. Therefore, it's 5.", "verifiability_rationale": "The reviewer states that some claims are inspired from existing studies and suggests adding supportive references. While this is a valid point, the review itself doesn't provide specific examples or references to back up this claim. The suggestion is general and lacks concrete details. Therefore, it's 1.", "helpfulness_rationale": "The review point raises a valid concern about the need for better referencing but doesn't offer specific, actionable advice on which studies to cite or how to integrate them. It's a highlevel suggestion that requires the author to do further research on their own. Therefore, it's 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the action of showing settings to mimic prior work, making it actionable.", "grounding_specificity_rationale": "The review mentions 'various knobs of this algorithm' and specific examples like 'Dagger, searn, etc...,' indicating a general understanding rather than pinpointing a specific section or table.", "verifiability_rationale": "The review suggests an improvement ('This paper could be improved...') which can be interpreted as a claim. While the suggestion aligns with common practices, it lacks explicit references to specific issues within the paper.", "helpfulness_rationale": "The review offers a specific suggestion ('showing settings') that is directly related to the 'Impact' mentioned, making it a helpful direction for improvement, even without directly criticizing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly suggests 'more datasets,' which is a clear action. However, it doesn't explicitly state *how* these datasets would be used or what specific improvements they would bring, making it partially actionable.", "grounding_specificity_rationale": "The comment is general about 'datasets' and 'crosstask transferability' and does not refer to a specific section, table, figure, or element of the paper, indicating it is 1.", "verifiability_rationale": "The comment is a suggestion for improvement rather than a claim that needs verification. Therefore, it contains X and is marked as 'X (X).'", "helpfulness_rationale": "The comment suggests adding more datasets, particularly for crosstask transferability, which is a relevant and potentially valuable piece of feedback for improving the model's generalization capabilities. While vague, it points to a specific area for improvement and is therefore 3."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states 'It would have been nice to see some unique tasks created from this nice dataset showcasing the diversity of images/plots. e.g. some variety of interleaved imagetext tasks such as Question Answering from images could have been considered.' This statement is concrete, as the reviewer identifies specific types of tasks (unique tasks, interleaved imagetext tasks, question answering) that they believe are missing. They even provide an example, making the suggestion very clear and actionable for the authors.", "grounding_specificity_rationale": "The reviewer's comment is 1 to a specific aspect of the paper or dataset. They are suggesting new tasks in general, rather than pointing out a specific section, table, figure, or unique element that needs improvement. While the *suggestion* is specific, the *review point itself doesn't ground* the suggestion to a particular aspect of the dataset.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement, specifically recommending 'some unique tasks created from this nice dataset showcasing the diversity of images/plots.' This comment does not contain a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support this suggestion. It is simply a proposal for future work, not a critique of the current work that needs validation.", "helpfulness_rationale": "The reviewer's comment offers a suggestion for improvement by proposing 'some unique tasks created from this nice dataset showcasing the diversity of images/plots.' However, this suggestion lacks specific details and grounding within the context of the current paper or dataset. It is a general idea for future work rather than a constructive critique that provides actionable feedback on the existing work. Therefore, while the suggestion might be helpful in the long run, the review point itself is not particularly helpful for immediate improvement of the current draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the framework's limitations and relevance in specific scenarios. While it doesn't provide a direct *action* on how to modify the framework, it points out areas where the framework might struggle. For instance, it questions the framework's relevance with nonconvex losses and nonnorm type defenses, suggesting that the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints might make the algorithm irrelevant or limit its insights. While the reviewer doesn't explicitly state how to address these issues, they imply a need for further investigation or adaptation of the framework. Therefore, while not providing a concrete action, the review points towards areas where action is needed, making it 3.", "grounding_specificity_rationale": "The reviewer raises concerns about the framework's applicability in the context of nonconvex losses, nonnorm type defenses, and specific aspects of binary classification. However, the review point does not explicitly refer to any specific section, table, figure, or unique element of the paper being reviewed. The reviewer is making general statements about the framework's limitations and relevance in broader contexts. While the implications are grounded in the paper's content (nonconvex losses, nonnorm constraints are general concepts), the direct link to specific parts of the reviewed paper is missing. Therefore, the grounding is weak as the reviewer doesn't pinpoint a specific area of concern within the paper itself.", "verifiability_rationale": "The reviewer makes claims about the implications of nonconvex losses and nonnorm type defenses on the framework's relevance and potential upper bounds. These claims are generally verifiable within the optimization and machine learning communities, as nonconvexity and nonnorm constraints are known to introduce challenges in finding global optima and in deriving tight bounds. While the reviewer doesn't provide specific examples or citations within the review point itself, the claims are based on established knowledge. Therefore, the claims are 3 as they are based on general principles and accepted knowledge within the field.", "helpfulness_rationale": "The review point raises valid concerns about the limitations of the framework and suggests areas for further investigation. While it doesn't offer direct solutions, it points out potential weaknesses and gaps in the analysis. For example, it questions the framework's applicability in nonconvex settings and suggests exploring the duality gap and maximization over nonnorm constraints. It also raises questions about the design of better defenses when the true mean is known. These are all relevant and potentially helpful suggestions for the authors. The review points out areas where the framework might need refinement or where alternative approaches could be considered. Therefore, the review point is 4 as it highlights potential areas for improvement and further research."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the action of 'sparsify the trained models' and 'compare accuracy to the proposed model'. However, it lacks a specific method for sparsification, making the action somewhat vague on how to apply it.", "grounding_specificity_rationale": "The reviewer mentions 'Figure 3', 'baselines on the left hand side', and 'proposed model'. This indicates an attempt to reference specific parts of the paper. However, the exact structure of Figure 3 is unknown, making the grounding partially uncertain. The reviewer also specifies the baselines and the proposed model for comparison, adding some level of specificity to the suggestion.", "verifiability_rationale": "The review point proposes a new experiment ('what if we sparsify...') and asks a comparative question ('compare accuracy to...'). This constitutes a claim (a suggestion for improvement). However, the reviewer does not provide any justification, reasoning, or external references to support the value or relevance of this experiment to the proposed model.", "helpfulness_rationale": "The review point suggests an experiment ('sparsify the trained models' and 'compare accuracy to the proposed model'). While the suggestion is valid in terms of exploring model sparsity, the review lacks any explanation of why this experiment would be beneficial or how it relates to the proposed model's goals. The reviewer presents the suggestion without any supporting reasoning or evidence."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states 'reorganized', which is a clear and direct action. The authors know exactly what needs to be done.", "grounding_specificity_rationale": "The comment explicitly mentions 'Appendix H', which is a specific part of the paper. The authors can accurately pinpoint the section being addressed.", "verifiability_rationale": "The comment contains a claim ('reorganized') but does not provide any justification or evidence for why Appendix H is difficult to follow. There is no logical reasoning or references provided to support the claim.", "helpfulness_rationale": "The comment directly points to a specific area (Appendix H) and a desired improvement (reorganization). It tells the authors *what* needs to be done, making it 5 and directly helpful for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the paper is not written to be reproduced and provides a list of missing technical details, such as the number of units in the RNN implementation. This directly points to a lack of information that hinders the reproduction process. While the reviewer doesn't provide specific instructions on how to reproduce the paper, the identification of missing details makes the lack of information somewhat concrete. The reviewer's point is clear and directly addresses the reproducibility of the work.", "grounding_specificity_rationale": "The reviewer's comment is broadly about the paper's focus and the lack of reproducibility. While they identify the *area* of the paper that needs improvement (the methodology section, implicitly), they do not explicitly pinpoint a specific section, table, or figure. The missing details they list (RNN implementation, etc.) are general and not tied to a specific part of the paper. Therefore, while the comment identifies a relevant area, it lacks the specificity of pinpointing the exact element that is missing. The grounding is present in the general area, but the specifics are lacking.", "verifiability_rationale": "The reviewer makes a claim that the paper is not written to be reproduced, even with the provided pseudocode. This is a claim that requires verification. However, the reviewer does not provide any external references, logical reasoning, or specific examples to support this claim. They offer an intuitive understanding but lack concrete evidence to back up their assertion about the paper's reproducibility. Therefore, the claim is made without sufficient justification or evidence.", "helpfulness_rationale": "The reviewer's comment is valuable in identifying a significant issue: the lack of reproducibility of the paper. They highlight the gap between providing an intuitive understanding and enabling actual reproduction, which is a crucial aspect for scientific work. However, the reviewer does not offer any specific suggestions or guidance on how to address this issue. They point out a problem but do not provide concrete steps on how to improve the paper to make it reproducible. Therefore, while the comment is relevant, it lacks the actionable improvement suggestions that would make it 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point asks a question about the potential of the model, which is a broad inquiry rather than a direct instruction on how to improve the draft. While it hints at areas for improvement (novelty, testability), it doesn't explicitly state what the authors should do or how to achieve it.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly tied to a specific part of the paper or a unique detail. While the intention is related to the model's potential, the comment itself doesn't pinpoint a particular section, table, figure, or aspect of the paper that needs addressing.", "verifiability_rationale": "The review point raises a question about the potential of the model but does not present a claim that can be directly supported by evidence or logical reasoning within the review point itself. It's a speculative question rather than a statement that requires justification.", "helpfulness_rationale": "The review point raises a relevant question about the potential of the model, which could guide the authors to consider the novelty and testability of their work. While it doesn't provide a direct solution, it prompts a critical reflection on the model's contribution."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer's question about the problem's significance is an action the authors need to consider. While they don't explicitly recommend a specific fix, the act of questioning the validity of the problem itself is a prompt for the authors to engage with the paper's claims. The lack of a clear, direct action to take makes it less actionable than a critique that points to a specific, actionable flaw.", "grounding_specificity_rationale": "The reviewer mentions 'ODEs exhibiting inaccuracy while recomputing activations' and points to a 'previous paper.' This is somewhat vague. The reviewer doesn't pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. While they provide some context, they don't explicitly identify where the issue lies within the paper's content. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer *claims* the current paper doesn't provide a convincing analytical argument or empirical evidence about the issue. This is a claim that needs to be supported. However, the *lack* of evidence is the core of the criticism. While the reviewer doesn't provide specific examples of where the evidence is missing, their statement about the absence of evidence is a clear indication of a lack of verifiability. The claim itself is not wellsupported by any reasoning or references.", "helpfulness_rationale": "The reviewer's question and expression of doubt are prompts for the authors to engage with the paper's content and consider the potential issue with ODEbased weight evolution. However, the review doesn't directly point to a specific, actionable improvement or provide a clear solution. It's a question and a concern, which are helpful in identifying a potential problem, but not immediately helpful in resolving it. Therefore, it's borderline helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the weakness: 'Also, proving lower bounds for round complexity is the major chuck of work involved in proving results for batched ranking problems.' They then explain the reason for this weakness: 'However, this paper exploits an easy reduction from the problem of collaborative ranking, and hence, the lower bound results follow as an easy corrayory of these collaborative ranking results.' The term 'easy corrayory' (intended to mean 'easy corollary') further emphasizes the straightforward nature of the deduction. The reviewer clearly identifies a limitation and explains its origin.", "grounding_specificity_rationale": "The reviewer starts by making a general statement about the paper's contribution: 'Also, proving lower bounds for round complexity is the major chuck of work involved in proving results for batched ranking problems.' This sets the context. They then narrow down the specific issue: 'However, this paper exploits an easy reduction from the problem of collaborative ranking, and hence, the lower bound results follow as an easy corrayory of these collaborative ranking results.' While the reviewer identifies the paper being reviewed and points to a specific aspect of its contribution, the explanation of 'easy reduction' is vague. The reviewer refers to 'these collaborative ranking results,' which is ambiguous without knowing the specific results being referenced. The reviewer does not explicitly state the section or table where this reduction is described, making it difficult to pinpoint the exact location. The language 'easy corrayory' is also informal and could be more precise.", "verifiability_rationale": "The reviewer makes a claim: 'this paper exploits an easy reduction from the problem of collaborative ranking' and 'hence, the lower bound results follow as an easy corrayory of these collaborative ranking results.' These are statements of opinion and consequence. The reviewer provides a *reason* for their claim ('this paper exploits an easy reduction...') and a *consequence* ('hence, the lower bound results follow...'). However, they do not provide *external references* or *logical reasoning* to *support* the claim that the reduction is 'easy.' The reasoning is present but lacks external backing. The reviewer does not explicitly state the section or table where this reduction is described, making it difficult to verify the claim independently.", "helpfulness_rationale": "The reviewer's point is clear and identifies a significant limitation of the paper's contribution: the lack of novelty in the lower bound proofs due to the easy reduction. They pinpoint the core issue: 'proving lower bounds for round complexity is the major chuck of work involved in proving results for batched ranking problems' and explain *why* it's a problem: 'this paper exploits an easy reduction from the problem of collaborative ranking, and hence, the lower bound results follow as an easy corrayory of these collaborative ranking results.' This feedback directly addresses a key aspect of the paper's contribution. The reviewer provides a clear direction for the authors to consider alternative approaches or to focus on different aspects of the problem. The feedback is relatively easy to understand and directly addresses a concrete issue."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests that the prompting technique used in the study is 'basic' and that 'carefully curated prompts' could lead to better results. While this points to a potential area for improvement, the reviewer does not explicitly state what the current prompts are or how they should be curated. The action is implied but not clearly defined or actionable for the authors.", "grounding_specificity_rationale": "The reviewer refers to the 'prompting technique used in this study' but does not specify which study or which prompting technique is being criticized. Furthermore, the review does not identify which specific aspect of the paper (e.g., methodology, results, discussion) is affected by this lack of effectiveness in the prompting technique. The reference to the prompting technique is general and does not pinpoint a specific part of the paper being addressed.", "verifiability_rationale": "The review states that the 'prompting technique used in this study is very basic and fail to leverage the full potentials of LLMs' and that 'carefully curated prompts can gain better results'. This is a statement of a problem or limitation, not a claim that requires verification. There is no assertion that something is incorrect or needs to be supported by evidence. The statement is an opinion about the limitations of the prompting technique.", "helpfulness_rationale": "The review criticizes the 'prompting technique used in this study' as 'basic' and suggests that 'carefully curated prompts' could be better. While this points to a potential improvement, it does not directly tell the authors what is wrong with their current prompts or how to make them better. The suggestion is general and does not provide specific actionable feedback for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states 'Table 4: The performance on REC and RES are clearly behind more recent models.' This indicates an explicit action or suggestion, although the specific action is not clearly defined. The reviewer points to a specific table and metrics, suggesting an awareness of the issue.", "grounding_specificity_rationale": "The review point explicitly refers to 'Table 4' and mentions 'REC' and 'RES' metrics. It also names specific models (ref1, ref2) and their performance. This demonstrates a strong grounding as the reviewer accurately identifies the specific part of the paper and the metrics being discussed. The mention of specific models and their performance provides clear grounding.", "verifiability_rationale": "The review point contains a claim: 'The performance on REC and RES are clearly behind more recent models.' It also provides supporting evidence by stating the specific models (ref1, ref2) and their performance (83.2 RES cIoU on RefCOCO TestA, and 89.4 REC accuracy (IoU>0.5) on RefCOCOg Test). This claim is thoroughly supported by explicit, sufficient, and robust evidence.", "helpfulness_rationale": "The review point identifies a weakness ('performance is clearly behind') and provides specific examples. However, it does not offer any suggestions or actionable steps for improvement. While the reviewer points out the problem, they do not provide guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential gap in the model's development. While the issue is clear, the reviewer doesn't offer any specific steps or actions the authors should take to address it. They identify the *what* (evidence, concepts) but not the *how* or *what to do next*.", "grounding_specificity_rationale": "The reviewer refers to 'evidence' and 'concepts,' which are somewhat general. While the *general* idea of evidence and concepts is referenced, the *specific* part of the paper isn't pinpointed. It's a general observation about the model's development. The reviewer doesn't specify *which* evidence or *which* concepts are involved.", "verifiability_rationale": "The reviewer states a potential issue without providing any evidence, reasoning, or references. The statement is presented as a claim without justification.", "helpfulness_rationale": "The reviewer identifies a potential problem. While it's valuable for the authors to be aware of this gap, the review point doesn't offer concrete, actionable steps or guidance on how to address it. It's more of a diagnostic observation than a prescriptive improvement suggestion."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a potential weakness in the method (reliance on framewise SDSA similar to ConsiStory) and suggests a possible improvement (using crossattention). While the reviewer points out the *what* (the method and the potential improvement), the *how* of implementing the improvement or the specific steps to take are not fully detailed. The suggestion is present, but the action is somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'framewise SDSA,' 'ConsiStory,' 'CLIPseg,' and 'OTSU segmentation' as specific elements. This demonstrates strong grounding as the reviewer can accurately pinpoint the sections or unique aspects being discussed. The reviewer also explains *why* the method might be limited (reliance on a method similar to ConsiStory) and *what* could be different (using crossattention). This specificity is evident in the identified issues and potential solutions.", "verifiability_rationale": "The reviewer makes a claim about the similarity to ConsiStory's approach and the difference in mask source. This claim is verifiable because the elements mentioned (framewise SDSA, ConsiStory, CLIPseg, OTSU segmentation) are specific enough to potentially be found in the paper. While the reviewer doesn't provide direct evidence, the claim is *verifiable* based on the information provided.", "helpfulness_rationale": "The reviewer clearly identifies a potential weakness in the method (limited novelty due to the approach used) and provides a suggestion for improvement (using crossattention). This critique is specific and actionable. The reviewer's feedback is directly relevant to the method described and offers a concrete direction for the authors to consider. This provides valuable guidance for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a *potential* weakness and suggests a *specific* way to test it. This suggests it *could* be actionable if clarified. The weakness is vague ('the weakness that this method is addressing') and the suggestion is also broad ('It would be very interesting to compare this approach to previous ones on such a dataset!'). While the reviewer identifies a potential area for improvement, they don't explicitly state what needs to be done or how to implement the suggested experiment. The action is implied but not directly stated, making it less actionable.", "grounding_specificity_rationale": "The reviewer mentions \"images comprised of multiple objects, or cluttered scenes\" and \"fewshot classification on such a dataset!\" This provides some grounding, but it's still quite general. While the *types* of images and the *task* (fewshot classification) are mentioned, the *specific method* being compared and the *specific dataset* are missing. The reviewer doesn't tell the author *which* previous methods or datasets to use. The grounding is present but lacks specificity in identifying the exact problem and the exact experiment to conduct.", "verifiability_rationale": "The reviewer states a potential weakness ('It seems that the weakness that this method is addressing') and suggests an experiment ('It would be very interesting to compare this approach to previous ones on such a dataset!'). This constitutes a claim. However, the weakness is speculative ('It seems'), and the experiment is a suggestion, not a verifiable fact. There's no external reference or logical reasoning provided to *prove* the weakness or the value of the experiment. The claim is present but lacks sufficient evidence to support it.", "helpfulness_rationale": "The review points out a potential weakness and suggests an experiment to investigate it. While the suggestion is related to the potential weakness, it lacks specific instructions on how to address the weakness directly. The experiment itself is not a concrete improvement plan. The reviewer doesn't provide any evidence that the weakness exists or that the proposed experiment will be meaningful. The suggestion is interesting, but it doesn't offer immediate actionable guidance for the authors. The helpfulness is limited as the reviewer doesn't provide a clear path for improvement or verification."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the concern about the small backbone's vulnerability to global pooling and suggests testing on larger models. This is an explicit action/suggestion. The reviewer also points out the consistent improvement across frameworks and tasks, which implies a potential issue with the magnitude of improvement on smaller backbones. While the suggestion to test on larger models is concrete, the initial observation of 'just about 1% gain' on ResNet50 could be considered vague at first. However, the reviewer's suggestion to test on larger models provides a clear direction for action.", "grounding_specificity_rationale": "The reviewer explicitly mentions the use of global pooling as a potential cause of the observed limitations on smaller backbones. This directly links the performance to a specific aspect of the method, making the criticism grounded. The reviewer also suggests testing on specific larger backbone models (SwinB or SwinL), which further grounds the criticism to a specific part of the experimental setup. The criticism is not just about the method in general but about a specific implementation choice and its impact.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It's a question or suggestion for further investigation. Therefore, it has 'X'.", "helpfulness_rationale": "The reviewer raises a valid concern about the limited gains on smaller backbones and the potential impact of global pooling. This is a helpful suggestion for the authors to consider. While the review point itself doesn't contain a claim, it identifies a potential area for improvement and suggests a direction for future experimentation. The suggestion to test on larger models is a concrete and actionable step that the authors can take to address the identified limitation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement explicitly states that the extension from linear models to wide fullyconnected neural networks is trivial and that the work only considers easy wide fullyconnected neural networks. This directly identifies a lack of significant contribution in that area and provides clear guidance for the authors to improve their analysis of neural networks.", "grounding_specificity_rationale": "The reviewer criticizes the work's focus on wide fullyconnected neural networks and suggests it bypasses the core problem of overparametrized neural networks. While the reviewer mentions 'wide fullyconnected neural networks,' they do not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The criticism is about the *nature* of the analysis, not a specific part of the paper.", "verifiability_rationale": "The statement makes a claim about the *triviality* of the extension and the *simplicity* of the considered neural networks. This is a statement that, based on the review point alone, lacks supporting evidence or justification. While potentially verifiable by examining the actual proofs and discussions in Sections 3.2 and 3.3, the *review itself* doesn't contain this evidence.", "helpfulness_rationale": "The reviewer criticizes the work for not adequately addressing the analysis of neural networks, suggesting it's a significant limitation. They imply the work is 'bypassing the core problem.' This critique points out a specific area where the authors' work could be strengthened. While it doesn't provide a concrete, actionable fix, it identifies a meaningful weakness and offers a potential direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential confusion regarding the terms 'relatively inexpensive' and 'expensive to evaluate.' While the reviewer doesn't provide a direct instruction on how to address this, they clearly identify a point of ambiguity that needs clarification. This suggests an implicit action of clarifying the terminology used in the paper.", "grounding_specificity_rationale": "The reviewer refers to the abstract and introduction of a specific paper (Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach, Stroh et al. 2017). While they don't explicitly state which part of their own paper they are referring to, the mention of the paper itself indicates they could have grounded their comment more specifically. The confusion about 'inexpensive' and 'expensive' could apply to different aspects of the multifidelity framework or the models themselves, making the grounding less precise.", "verifiability_rationale": "The reviewer raises a point about the terminology used in the abstract and introduction, specifically 'relatively inexpensive' and 'expensive to evaluate.' This is a claim that needs justification or clarification. There is no logical reasoning, common knowledge, or external reference provided to support this point. The reviewer is pointing out a potential inconsistency or lack of clarity in the paper's description of computational costs.", "helpfulness_rationale": "The reviewer's point, while not providing a direct solution, is a constructive suggestion that could improve the clarity of the paper. By highlighting the potential confusion in the abstract and introduction regarding the cost of different approaches, the reviewer is suggesting that the authors should be more precise in their language. This is a valuable suggestion that, while not immediately actionable, has the potential to enhance the paper's readability and understanding."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point implicitly raises a potential issue regarding the use of the AH36M dataset in training. While it doesn't explicitly state that the dataset is used for training, it points to a potential source of unfair comparison with other methods. The reviewer suggests investigating whether the curated AH36M dataset is used for training and if other methods (e.g., HMR, SPIN) have access to this data during training. This implies an action, but it is not very concrete on how to proceed. The reviewer could have been more explicit about the specific steps to take, such as checking the author's code or experimental setup.", "grounding_specificity_rationale": "The review point explicitly mentions 'curated AH36M dataset', 'training', and 'fair comparison' with specific methods (HMR, SPIN). These terms are clearly defined and relevant to the context of the paper and the methods being compared. This demonstrates good grounding specificity.", "verifiability_rationale": "The review point makes a claim about the fairness of comparisons if the AH36M dataset is used for training and if other methods have access to this data. The reviewer provides a logical reasoning for this claim by suggesting that it could affect the fairness of the comparison. This claim is 3 as the reviewer provides a clear statement and a logical reasoning, but it doesn't provide specific examples or references to external works. Therefore, it is not 5.", "helpfulness_rationale": "The review point raises a valid concern about the fairness of comparisons in the experimental setup. It encourages the author to be more transparent about the use of the AH36M dataset in training and the data access of other methods. This is helpful as it highlights a potential flaw in the experimental design. However, the review point does not provide specific, actionable steps for the author to take to address this issue. It is a highlevel concern that requires further investigation from the author."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desired improvement: 'the paper compares to related work only on some not official test set or dev set' and provides a clear action: 'the paper should be compared on the official COOC leader board on the blind test set'. This action is directly derived from the reviewer's critique, making it actionable.", "grounding_specificity_rationale": "The reviewer implies that the paper is referring to their related work when suggesting the comparison. While not explicitly stated as 'related work' or 'Section X', the context of comparing to 'related work' strongly suggests this is the intended location for the comparison. The reviewer also provides specific details about the comparison location: 'official COOC leader board on the blind test set', which is quite specific.", "verifiability_rationale": "The reviewer provides a claim: 'the paper compares to related work only on some not official test set or dev set'. This claim is supported by providing a link to the COOC challenge and mentioning specific papers (5, 17) that have won the challenge on the official leaderboard. These external references and examples make the criticism verifiable.", "helpfulness_rationale": "The reviewer provides a clear and specific criticism: 'the paper compares to related work only on some not official test set or dev set'. They also offer a concrete suggestion for improvement: 'the paper should be compared on the official COOC leader board on the blind test set'. This feedback is directly actionable and addresses a specific weakness in the paper's evaluation methodology, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review points out a discrepancy in the results (MSE < MAE) and links it to the reliability of the experimental results. While it doesn't explicitly state what needs to be changed, it clearly identifies a problem with the experimental setup or implementation. The reviewer suggests that the smaller MSE compared to the MAE raises concerns about the validity of the experimental results. This indicates a potential issue that needs investigation.", "grounding_specificity_rationale": "The review explicitly mentions \"Table 1\" and refers to specific metrics within that table, namely \"MSE\" and \"MAE\". This indicates that the reviewer has identified a specific part of the paper and is referring to particular elements within it. The reviewer's statement \"the experimental results are unreliable, especially in Table 1, where the MSE is significantly smaller than the MAE\" clearly points to a specific section and a specific issue within that section.", "verifiability_rationale": "The review states a claim: \"The experimental results are unreliable, especially in Table 1, where the MSE is significantly smaller than the MAE, which raises concerns about their validity.\" This is a clear statement of a problem. While the reviewer doesn't provide external references or logical reasoning to support this claim, they do point to a specific observation in the results (MSE < MAE) within a specific table. The implication is that this discrepancy should be investigated to understand the source of the issue.", "helpfulness_rationale": "The review provides a clear indication of a problem in the experimental results, specifically pointing to the discrepancy between MSE and MAE in Table 1. This is a valuable piece of feedback for the authors as it highlights a potential issue with their experimental setup or implementation. By identifying a specific area of concern, the reviewer helps the authors focus their attention and potentially improve the reliability of their results. The reviewer's statement directly addresses a concrete observation in the data, making it a helpful point for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment identifies a problem (lack of novelty) but doesn't provide any specific actions or guidance on how to address it. It's unclear what the author should do next.", "grounding_specificity_rationale": "The comment is too general and doesn't specify which part of the paper or methodology is lacking novelty.", "verifiability_rationale": "The review point is a factual statement about the methodology, not a claim that requires verification.", "helpfulness_rationale": "The comment identifies a valid issue (lack of novelty), which is helpful in itself. However, the criticism is general and doesn't provide specific guidance on how the author can address this lack of novelty. It's not completely unhelpful, but it's not a 5 or specific critique."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'improve clarity' as a suggestion, which is a concrete action. They also point to the lack of 'nuance' at L255 as the specific issue that needs addressing. This directly identifies a problem and proposes a solution, making it 5.", "grounding_specificity_rationale": "The reviewer refers to 'the nuance of this position at L255,' which clearly identifies a specific part of the paper and the nature of the problem. They are not making a general comment but rather focusing on a specific location and its characteristics, making it 5.", "verifiability_rationale": "The reviewer makes the claim 'This is a good point to clarify,' which is a judgment. However, they do not provide any evidence or reasoning to support why the explanation at L255 is 'wrong' or how it addresses the lack of clarity. The claim is presented without sufficient justification, making it 3.", "helpfulness_rationale": "The reviewer directly points out a weakness ('what does \"wrong\" mean here?') and suggests an improvement ('improve clarity' implicitly). While they don't explicitly state 'improve clarity,' the implication is clear. This makes the comment 3 as it identifies a problem and suggests a direction for improvement, although it could be more specific."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their understanding of 'state' and asks a direct question about the meaning of 'elements' in the context of lines 186187. This is an explicit action, and the request for clarification about a specific term within a defined section makes it concrete.", "grounding_specificity_rationale": "The reviewer directly mentions 'lines 186187' and asks a specific question about 'elements'. This clearly identifies the section and the aspect of the paper being discussed, making it fully grounded. The specificity comes from the precise question about the meaning of a technical term within a defined context.", "verifiability_rationale": "The reviewer points out a lack of clarity regarding the term 'state' and requests clarification on the meaning of 'elements'. While the reviewer identifies a potential issue, they are not providing a definitive claim or assertion that something is wrong. They are suggesting a potential area for improvement in the paper's description. Therefore, it is not a claim that requires verification, but rather a suggestion for clarification. It lacks the supporting evidence or references that would make it verifiable.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by pointing out a lack of clarity in the description of 'state' and 'elements'. This is a constructive comment that guides the authors to seek clarification in a specific part of their paper. While it doesn't offer a direct solution, it points to a concrete area for improvement, making it helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a performance difference between two configurations and asks for an explanation of the mechanism behind the proposed module's stability. While it points out an issue, it doesn't explicitly state how to apply a solution beyond asking for more information. The action is implied but not directly stated as a concrete step.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Sec 5.3' and compares 'a generator equipped with a standard RGCN as discriminator' with 'the proposed module'. This clearly identifies the specific part of the paper and the elements being discussed, making it 5.", "verifiability_rationale": "The review point contains a claim: 'a generator equipped with a standard RGCN as discriminator tends to collapse after several (around 20), while the proposed module will not'. However, it doesn't provide any logical reasoning, common knowledge, or external references to support this claim. The verification methods are not applied, making it 1.", "helpfulness_rationale": "The review point raises a valid concern about a performance difference and directly asks for an explanation of the underlying mechanism. This is a specific and relevant request that could significantly improve the understanding and evaluation of the proposed method. While it's a request, it's a valuable and actionable feedback point."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment identifies a *type* of theoretical comparison (adaptive learning of GPRGNN) that is unclear but does not explicitly state what aspect of the comparison is lacking. It implies a problem but doesn't pinpoint the specific action needed to address it.", "grounding_specificity_rationale": "The comment mentions 'adaptive learning of GPRGNN,' which provides some level of grounding by naming a specific area. However, it does not specify which part of the paper or model this refers to, nor does it detail what is meant by 'unclear.' The grounding is weak because the referenced part cannot be precisely identified, and the issue is not clearly defined.", "verifiability_rationale": "The comment states that the 'theoretical comparisons to adaptive learning of GPRGNN is not clear' but does not provide any evidence or reasoning to support this claim. There is no specific claim being made that can be verified logically, commonly, or through external references. The statement is presented as an observation without further explanation.", "helpfulness_rationale": "The comment identifies a weakness in the theoretical comparison (lack of clarity) but does not offer any suggestions or guidance on how the authors should address this weakness. It points out a problem but fails to provide actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their suggestion to use a confidence score instead of yes/no responses. This is a direct and clear action pointing to a specific improvement.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific issue: the sufficiency of yes/no responses for measuring object hallucination. They then further specify the proposed solution: using a confidence score. This demonstrates strong grounding as the weakness and the proposed improvement are both explicitly mentioned.", "verifiability_rationale": "The reviewer makes a claim: 'yes responses do not necessarily indicate that the model comprehends the presence of the object in the image.' They then provide a supporting statement: 'as it may still produce incorrect objects when undertaking other tasks.' This claim is supported by logical reasoning and provides context.", "helpfulness_rationale": "The reviewer's point is clear and directly addresses a limitation of the current evaluation method. Suggesting a confidence score is a concrete and actionable improvement that could lead to a more accurate assessment of object hallucination."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing components in the ablation study, specifically mentioning 'experiments and explanation regarding the different queries used in spatiotemporal representation, i.e., spatial, temporal and summary'. The reviewer also poses a clear question: 'What if only have spatial one, or temporal and summary one?'. This indicates a direct identification of what needs to be addressed and a suggestion for further investigation. The action is explicit, and the details are provided, making it concrete.", "grounding_specificity_rationale": "The review point explicitly mentions 'experiments and explanation regarding the different queries used in spatiotemporal representation' and specifies the types of queries: 'spatial, temporal and summary'. This directly identifies the section of the paper being addressed. The reviewer also asks a specific question about the impact of different combinations of queries, further pinning down the exact area. The grounding is strong as the section is clearly identified, and the specificity is high as the exact components are mentioned.", "verifiability_rationale": "The review point makes a claim about the missing experiments and explanation in the ablation study related to spatiotemporal queries. While the reviewer doesn't provide specific examples of what is missing, the implication is that the current work lacks this level of detail. The suggestion to investigate different combinations of queries ('what if only have spatial one, or temporal and summary one?') provides a potential justification for why these experiments are important. Therefore, the claim is supported by logical reasoning and the suggested experiments, making it 3.", "helpfulness_rationale": "The review point directly identifies a gap in the experimental evaluation (missing ablation studies on different query types) and suggests a concrete way to address it by conducting these experiments. The reviewer's questions about the impact of different query combinations are specific and actionable for the authors. This feedback is directly helpful in improving the experimental design and completeness of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the action of reorganizing Sections 3 and 4. It also implies the action of moving specific parts of Section 4 to Section 3. This is an explicit action. Once the action of reorganizing is identified, the reviewer provides concrete details on *how* to reorganize: moving the first paragraph of Section 4 to the beginning of Section 3 and the remainder before Section 3. This makes the action concrete. Therefore, the actionability is high.", "grounding_specificity_rationale": "The review point directly refers to 'Sections 3 and 4', which are specific parts of the paper. It further specifies the *exact* parts to be moved: 'the first paragraph of sec 4' and 'the remainder of sec 4'. This allows the authors to precisely identify the areas being discussed. The grounding is explicit and complete. The comment also specifies what needs to be done in these parts: improve the organization. Therefore, the grounding specificity is high.", "verifiability_rationale": "The review point contains a claim: suggesting a reorganization of Sections 3 and 4 to address potential redundancy. This claim is supported by the logical reasoning that such redundancy might exist. The reviewer provides examples of what they perceive as redundant information (the first paragraph of Section 4 and the remainder of Section 4). The suggestion is based on common knowledge about improving clarity and organization. While it doesn't provide specific citations, the reasoning is generally accepted. Therefore, the verifiability is high.", "helpfulness_rationale": "The review point identifies a potential weakness (redundancy in Sections 3 and 4) and suggests a concrete solution (reorganization). This directly addresses a likely concern for the authors. While it doesn't provide specific steps on how to identify the redundancy or implement the reorganization, it points in a constructive direction. Therefore, the helpfulness is moderate."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the disconnect between the two concepts and identifies the potential cause as 'in part due to poor clarity.' This provides a clear action for the authors to take: improve the clarity of their work to bridge this gap.", "grounding_specificity_rationale": "The reviewer explicitly names the two concepts involved: 'improved variance control of prediction y^ or the smoothness of loss landscape' and 'zeroshot learning effectiveness.' This allows the authors to pinpoint the specific area of concern.", "verifiability_rationale": "The reviewer states a claim about the lack of connection and provides a potential reason (poor clarity). While not 5, the identification of the potential cause makes it 3.", "helpfulness_rationale": "The reviewer's comment is primarily critical and points out a perceived lack of connection without offering solutions or actionable steps for the authors. While it highlights a potential issue, it doesn't provide a specific path towards improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review points out a lack of discussion about the kmax problem and asks for a citation. While it implies a missing element, it doesn't explicitly state what needs to be done with that information or how to find the citation. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer is asking 'Where else was the kmax problem discussed? Please provide a citation for this.' This is a general question about the kmax problem in the literature, not about a specific part of the paper or a specific instance of the problem. The reviewer is not identifying a specific section, table, figure, or unique element of the paper being addressed.", "verifiability_rationale": "The review point is a question asking for information about the kmax problem and a citation. It does not contain a claim or assertion that requires verification. It's a request for data or context.", "helpfulness_rationale": "The review point asks for information about the kmax problem and a citation. While this information could be helpful for the authors to understand the context and potentially improve their work, the review point itself does not directly instruct the authors on what to do with this information. It's a question seeking context rather than a directive to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'there is no information on how the function...'. This implies an action the authors should have taken, namely to provide this information. While the action is not directly stated, the reviewer's point encourages the authors to include the estimation details and discuss the model's reliability. This makes the review point 3 by highlighting a missing piece of information that would be beneficial for the authors.", "grounding_specificity_rationale": "The reviewer refers to 'Equation 1,' which is a specific reference to a part of the paper. This clearly identifies the issue in a specific section. Furthermore, the reviewer explains the lack of information regarding the reliability of the model, which is a specific aspect of the function described in Equation 1. This strong reference to a specific part of the paper and a specific detail makes the review point highly grounded.", "verifiability_rationale": "The reviewer makes a clear statement: 'There is no information...'. This constitutes a claim that the information is missing. While the reviewer does not provide a justification for why this information is absent, the statement itself is verifiable by checking Equation 1. The claim is present, and the lack of information is a verifiable fact, even if the underlying reasons for the lack of information are not explored.", "helpfulness_rationale": "The reviewer's comment directly points out a significant deficiency in the information provided in the paper. By highlighting the lack of details about the function estimation and its reliability, the reviewer provides the authors with a clear direction for improvement. This actionable feedback is directly helpful for the authors to enhance their work. The reviewer's point encourages the authors to include the estimation details and discuss the model's reliability, which are concrete and actionable suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point implies an action: 'Check the number in L006 and add 'on the subword level' to make it more precise.' While not explicitly stated, the reviewer clearly suggests a change. The action is concrete: check the number and add the detail.", "grounding_specificity_rationale": "The review point explicitly mentions 'L006', indicating a clear identification of the specific part of the paper being addressed. The reviewer also suggests a specific improvement ('maybe add \"on the subword level\"'), which clearly specifies what needs to be done in relation to L006.", "verifiability_rationale": "The review point contains a claim: 'thousands' is not accurate here. This claim is verifiable by checking the number in L006 and potentially looking for context or clarification within the paper. The reviewer also suggests a potential solution ('maybe add \"on the subword level\"'), which provides a basis for further verification or investigation.", "helpfulness_rationale": "The review point is directly helpful to the authors. It identifies a potential factual error ('thousands' is not accurate) and suggests a concrete improvement ('add \"on the subword level\"'). This actionable feedback is likely to be beneficial for the authors in refining their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the missing hyperparameters (e.g., regularization) and implicitly suggests that the behavior of the latent path figures (y=0 at x=0) needs further attention. While the missing hyperparameters are a clear action, the connection to the figure behavior and the request for further analysis could be more explicit in detailing how to apply this information. The request for further analysis itself is an action, but its specificity could be improved.", "grounding_specificity_rationale": "The review point mentions 'latent path figures (eg Fig 3)' which provides some grounding by identifying a specific part of the paper. However, the reviewer does not explicitly state which section or table contains these figures. The behavior of the yvalue being 0 at x=0 is also mentioned, but without a clear reference to the specific figure or section where this behavior is observed. The request for further analysis is general and does not specify which interpolations are being referred to.", "verifiability_rationale": "The review point presents observations about the missing hyperparameters and the behavior of the latent path figures, which can be considered implicit claims. The request for further analysis implies a need for justification or clarification. The evidence provided is primarily descriptive (observation of the figure behavior and missing information). While there isn't a direct citation to external work, the implication is that this discrepancy needs explanation.", "helpfulness_rationale": "The review point identifies specific areas for improvement, such as checking for missing hyperparameters and examining the latent path figures. The request for further analysis on the interpolations is also a clear suggestion for improvement. While the connection between the observations and the request for further analysis could be more explicit, the reviewer provides clear directions on what the authors should do to address the identified issues."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The reviewer point identifies a weakness or improvement area but is vague, lacks clarity, or provides minimal guidance, making it only slightly beneficial for the authors. While the reviewer points out the issues, they don't explicitly recommend specific actions or modifications to address them.", "grounding_specificity_rationale": "The authors cannot confidently determine which part the comment addresses. Further, the comment does not specify what needs to be addressed in this part. However, the reviewer also explicitly mentions \"deeprag algorithm\" and \"discussion on the high concurrency\", which provides some level of grounding. The comment specifies what needs to be addressed in this part (the placement and explanation of key components).", "verifiability_rationale": "The comment states facts without suggesting changes. It does not provide any justification or reasoning for why the identified issues are problematic or why the content should be in the appendix. The reviewer simply states the *existence* of these issues.", "helpfulness_rationale": "The comment identifies weaknesses or areas for improvement but is incomplete or lacks depth. While the reviewer points out the *existence* of issues, they don't offer concrete solutions or recommendations for improvement. The feedback is clear about the problems but doesn't provide actionable steps for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing information and the area it should be found. The action is to look at Table 1 for the generative setting results. The details are concrete as the section and setting are clearly mentioned.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Table 1' and 'generative setting', allowing the authors to accurately pinpoint the relevant information. The specificity is high as the exact section or table is referenced.", "verifiability_rationale": "The reviewer presents a claim by stating the discrepancy between the two test settings mentioned and the results presented. This claim is wellsupported by the context of the limitations of the discriminative setting in realworld applications.", "helpfulness_rationale": "The reviewer's point is 5 as it directly points to a missing piece of information that is crucial for a comprehensive evaluation of the paper's claims. The request for the generative setting results is specific and actionable."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a general limitation (the effectiveness of the approach for other language families is unknown) but does not explicitly state what action the author should take. While it implies a need for further investigation, the specific steps or areas to focus on are not provided.", "grounding_specificity_rationale": "The review point refers to the 'proposed approach' in general, without specifying a particular section, detail, or aspect of the method. It also does not identify a specific part of the paper or data (like a table or figure) that is affected. The reviewer can infer the concern is about the approach's general effectiveness, but lacks specificity.", "verifiability_rationale": "The review point states a fact: 'the effectiveness of the proposed approach for other language families remains unknown.' However, it does not provide any justification, evidence, or references to support this claim. There is no logical reasoning, common knowledge, or external citations provided to back up the assertion that the effectiveness is unknown.", "helpfulness_rationale": "The review point identifies a limitation of the proposed approach but does not offer any suggestions or guidance on how to address it. It is a statement of a problem without providing any actionable steps or insights for improvement. The reviewer points out a missing piece of information but does not help the author find it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a weakness in the related work section but lacks specific guidance on how to address it. While it points to the issue of 'some related works are mainly named but their differences are not described enough,' it doesn't provide concrete steps on how to improve this. The reviewer knows the related work needs clarification, but doesn't offer specific actions or modifications to be made.", "grounding_specificity_rationale": "The comment identifies a general issue with the related work section, specifically that 'some related works are mainly named but their differences are not described enough.' While it points to the *area* of improvement (related work and the lack of description of differences), it doesn't specify which *exact* related works are lacking this description. Therefore, the grounding is weak, as the authors cannot confidently determine which part of the paper is being addressed. However, the comment does specify what needs to be addressed (differences in related works), making it somewhat specific.", "verifiability_rationale": "The review point makes a claim: 'Related work could be improved' and then provides a reason: 'Some related related works are mainly named but their differences are not described enough.' While the reviewer doesn't provide specific examples or references to support their claim, the statement itself is a claim that could potentially be verified by examining the cited works and assessing the level of detail in their descriptions of differences. The reviewer states a premise that *could* be supported or refuted.", "helpfulness_rationale": "The review point identifies a valid area for improvement in the paper (the clarity of the related work section) and suggests a direction for improvement (describing differences more). While it doesn't offer specific, actionable steps on how to achieve this, it points to a concrete problem and encourages a specific type of change. This makes it 3 as it guides the authors towards a specific area of revision."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The comment identifies a weakness or improvement area (the lack of explanation of PPP maps) but is vague, lacks clarity, or provides minimal guidance, making it only slightly beneficial for the authors. The reviewer states a belief about the value of PPP maps without explicitly stating what that value is or how the authors should interpret or use that information. The action is implicit  the reviewer believes the authors need to understand the value, but the guidance on *how* to understand it is missing.", "grounding_specificity_rationale": "The authors cannot confidently determine which part the comment addresses. The comment clearly specifies what needs to be addressed in this part (the lack of explanation of PPP maps). The comment states: \"While this point is surely intriguing, such an explanation or understanding is not explicitly given in the article.\" This clearly points to the lack of explanation of PPP maps as the issue.", "verifiability_rationale": "The comment contains a claim (the statement that the explanation of PPP maps is missing) without any supporting evidence or justification. The reasoning is purely based on the reviewer's observation that the paper doesn't explicitly explain PPP metrics. There are no external references or logical reasoning provided to support this claim.", "helpfulness_rationale": "The comment thoroughly identifies weaknesses and offers detailed, actionable, and constructive suggestions that empower the authors to significantly improve their draft. The reviewer points out a significant gap in the paper's explanation of PPP effects and suggests that this explanation is crucial. This highlights a potential area for improvement and provides a clear direction for the authors to focus their efforts. While it doesn't directly tell them what to change, it guides them on what aspect needs more explanation."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the authors do not compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. This directly identifies an action the authors could take (comparing with SpanBERT). However, the comment doesn't specify how this comparison would be implemented or what specific aspects of the methods would be compared, making the action somewhat vague.", "grounding_specificity_rationale": "The comment explicitly mentions 'other stateoftheart methods for spanrelated tasks, such as SpanBERT'. This clearly identifies the specific part of the paper (or the type of method) being referred to, indicating strong grounding. It also specifies what is being compared (spanrelated tasks) and provides a concrete example (SpanBERT), making it highly specific.", "verifiability_rationale": "The comment contains a claim that 'the authors do not compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT'. This claim is supported by the absence of any mention of such comparisons in the paper (or the reviewer's knowledge of it). While the implication is that this lack of comparison could impact credibility, the claim itself is verifiable based on the information available.", "helpfulness_rationale": "The comment identifies a potential weakness in the authors' work (the lack of comparison with stateoftheart methods) and suggests a specific area for improvement (comparing with SpanBERT). This provides the authors with a concrete direction for further research and evaluation, making the review point helpful in guiding their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a lack of explanation for the forwardprediction model, which is an implicit action. While the reviewer doesn't explicitly state how to improve the connection between the text, figure, and equations, the suggestion to 'improve the connection' implies an action. However, the specific action is not clearly defined in the review point itself.", "grounding_specificity_rationale": "The reviewer explicitly states that the 'details of the forwardprediction model' are not well explained and points to Figure 2(b) as the relevant part. They also suggest that the figure should be redrawn as a schematic. This clearly identifies the specific area and the nature of the issue, making it 5.", "verifiability_rationale": "The reviewer states that the 'details of the forwardprediction model' are 'not well explained' and provides evidence by stating that Figure 2(b) is not a schematic and that there is difficulty connecting the text and equations. This claim is supported by clear reasoning and examples, making it 5.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as 'redrawing the figure' and 'connecting the pieces of the text with the figure'. These are concrete and actionable suggestions that directly address the identified weakness, making the review point 5."}
{"actionability_label": "5", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that training only on rewarded actions in RBI is a limitation and suggests it's a *significant factor* that might explain FP+RBI's superiority. They also point out that this omission is a *missing part* that needs to be addressed. The reviewer further clarifies the *missing supervision* and its potential impact with an example ('No, the answer is Timothy Dalton'). This makes the action both explicit and concrete.", "grounding_specificity_rationale": "The reviewer identifies the specific aspect of the method being criticized: 'training only on rewarded actions.' While they don't pinpoint a specific section or table by name, this is a clear reference to a specific part of the method. Furthermore, they specify the *missing supervision* and its potential impact, making the point quite specific.", "verifiability_rationale": "The reviewer makes a claim: 'This could be one significant factor that makes FP + RBI better than RBI alone.' This is a statement of opinion or judgment. However, the reviewer does not provide any specific evidence or references to support this claim within the review point itself. They offer a hypothesis but don't logically reason it out or point to existing literature.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement: 'I think this could be one significant factor that makes FP + RBI better than RBI alone. If not, I think the authors should provide stronger baseline than RBI (that is supervised by such feedback).' This is a helpful suggestion. They also raise a relevant question ('Questions / Minor concerns:'). While the reviewer doesn't definitively prove their hypothesis about FP+RBI's superiority, they offer a valuable point for discussion and improvement. The helpfulness is moderate as the suggestion is actionable but lacks direct evidence."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point criticizes the weakness of baseline methods and the lack of discussion of limitations. While it identifies areas for improvement, it does not explicitly state what actions the authors should take to address these issues. The suggestions are vague and lack specific implementation details.", "grounding_specificity_rationale": "The review point refers to 'baseline methods' generally, without specifying a particular section, table, figure, or unique element of the paper. The authors cannot confidently determine which part of the paper is being addressed by this comment. The reference is broad and lacks specificity.", "verifiability_rationale": "The review point makes claims about the weakness of baseline methods and the lack of discussion of limitations. These are statements that require justification and are based on the reviewer's assessment of the field and the paper's shortcomings. While they are opinions, they are not purely subjective opinions without any basis.", "helpfulness_rationale": "The review point raises valid concerns about the baselines and the need for a more comprehensive discussion of limitations. It offers a potential direction for the conclusion by suggesting a comparison to reinforcement learning. However, it does not provide concrete steps or suggestions on how the authors should improve their baselines, discuss limitations, or connect their work to reinforcement learning. The suggestions are broad and lack specific guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the difference between expected performance under observation noise and the stochastic noisy function. It also suggests a potential action: 'typically, expected performance under observation noise is used for evaluation because the decisionmaker is interested in the true objective function and the noise is assumed to be noise (misleading, not representative). In the formulation in this paper, the decision maker does care about the noise; rather the objective function of interest is the stochastic noisy function. It would be good to make this distinction clearer upfront.' This action is quite direct and clear.", "grounding_specificity_rationale": "The review point clearly identifies the specific area of the paper being discussed: 'evaluation under observation noise' and 'the stochastic noisy function'. It explicitly mentions these two concepts and their relationship. The authors can easily identify the section or concepts being addressed. The comment also specifies what needs to be understood: 'the impact of observation noise on evaluation' and 'the stochastic nature of the function'.", "verifiability_rationale": "The review point contains a claim: 'typically, expected performance under observation noise is used for evaluation because the decisionmaker is interested in the true objective function and the noise is assumed to be noise (misleading, not representative). In the formulation in this paper, the decision maker does care about the noise; rather the objective function of interest is the stochastic noisy function.' This claim is supported by the reviewer's understanding of common evaluation practices and the specific formulation in the paper. While the reasoning is implicit, the claim itself is welldefined and supported by the concepts discussed.", "helpfulness_rationale": "The review point is 5 as it directly addresses a potential issue authors might face when evaluating their work under different noise conditions. It provides a clear distinction between two evaluation approaches and suggests a potential action: considering expected performance under observation noise. This is a relevant and actionable suggestion for improving the authors' understanding and evaluation process. The reviewer also provides a potential benefit of considering the stochastic noisy function, which encourages the authors to think about the implications of their formulation."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "1 (1 and Not Specific)", "verifiability_label": "1 (1)", "helpfulness_label": "2 (2)", "actionability_rationale": "The review point identifies a weakness in the paper (the incremental contribution of the method) but fails to provide explicit or concrete actions for the authors to take. The suggestion is vague and does not specify how the authors should improve their method or network design.", "grounding_specificity_rationale": "The review point makes a general comment about the method's novelty without specifying which part of the paper or method design it refers to. It lacks specificity about the issue.", "verifiability_rationale": "The review point makes a claim about the method's novelty being incremental but provides no evidence, justification, or references to support this claim. It's a statement of opinion without any backing.", "helpfulness_rationale": "The review point identifies a valid concern (the incremental contribution) but fails to offer any constructive feedback, evidence, or suggestions to address it. It's a negative statement without any positive value for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks direct questions about the model's behavior with less data and the phenomenon of gradients becoming zero. While the questions are explicit about the areas of concern, they lack specific guidance on how to address these issues or what concrete steps the authors should take. The reviewer is seeking information, which is a form of action, but it's not actionable in the sense that it guides the authors to a solution.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'line 159' and 'your experiments' in the review point. This demonstrates a clear attempt to ground the feedback in the paper and the authors' own work. The reference to a specific line and the reviewer's own experiments indicates a strong grounding.", "verifiability_rationale": "The review point does not contain a claim in the sense of suggesting a problem or proposing a solution. It is a question seeking information and clarification about the authors' own experiments and the paper's content. Therefore, it does not meet the criteria for verifiability, which requires a claim to be verified.", "helpfulness_rationale": "The reviewer is asking questions about their own experiments and the paper's content. While this information can be helpful for the authors, the review point itself does not actively guide or suggest improvements. It's more about seeking clarification and understanding existing work, which is valuable but not directly helpful in improving the draft at this stage."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point states: \"The problem formulation is somewhat unclear in the statement and introduction examples.\" This points out a *problem* but doesn't directly instruct the authors on *how* to fix it. It's a statement of a problem rather than a directive action.", "grounding_specificity_rationale": "The review point mentions 'statement and introduction examples\" but doesn't specify *which* example or part of the introduction. The description of the unclarity is vague and general.", "verifiability_rationale": "The review point states a fact: \"The problem formulation is somewhat unclear\". There is X, suggestion, or judgment being made that would require verification.", "helpfulness_rationale": "The review point identifies a meaningful weakness (unclear problem formulation in the introduction) but doesn't provide specific guidance on how to address it. It highlights an area for improvement but doesn't fully address the authors' needs for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests conducting experiments with specific LLM families, which is an implicit action. While the *what* is somewhat concrete, the *how* of implementing these suggestions within the current draft is not explicitly stated.", "grounding_specificity_rationale": "The reviewer refers to 'this paper' generally, which is not a specific section, table, or unique aspect. The suggestion is broad and doesn't pinpoint a specific problem or solution within the paper.", "verifiability_rationale": "The review point states 'This paper lacks experiments on different LLM families' which is a statement of observation, not a claim requiring verification. The suggestion is a proposal, not a claim.", "helpfulness_rationale": "The review point identifies a clear weakness ('lacks experiments on different LLM families') and offers a relevant suggestion ('conducing trials with models like...'). This directly addresses the identified weakness and provides a concrete direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The statement explicitly identifies a limitation of the method, stating 'This method seems to only work for generative models that can be finetuned as an in/outpainting model.' This directly points to a concrete action the author should take: check if their model fits this specific requirement. While the phrasing could be more direct, the action is present.", "grounding_specificity_rationale": "The reviewer is making a general statement about the limitations of a method, not specifically pointing to a particular section, table, or figure in the paper being reviewed. While the statement is about a specific type of model (finetunable in/outpainting models), it doesn't explicitly identify a specific part of the author's work where this limitation is relevant. Therefore, the grounding is weak.", "verifiability_rationale": "The statement is a claim about the limitations of a method. It is a judgment about what the method cannot do. While the statement itself is verifiable (a method either can or cannot be finetuned as in/outpainting), the reviewer is not providing evidence *within the context of the paper being reviewed* to support this claim. The verifiability here is about the definition of the method's applicability, not a specific detail within the author's work. Therefore, it is not 5 within the scope of the paper being reviewed.", "helpfulness_rationale": "The statement informs the author about a limitation of their method. This is valuable information for the author to understand the scope and applicability of the method. It helps them assess whether the method is suitable for their specific needs. While it doesn't directly suggest improvements, it provides crucial context."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential misunderstanding between the 'curve finding' method and FGE. While the reviewer explicitly states an action ('point out the potential misunderstanding and the alternative interpretation'), the action is vague and doesn't provide specific guidance on how the authors should address this or implement the alternative. The reviewer doesn't specify which part of the paper the confusion lies, making the grounding of this action somewhat weak.", "grounding_specificity_rationale": "The reviewer identifies a potential misunderstanding between the 'curve finding' method and FGE. However, the reviewer does not explicitly identify the specific part of the paper being addressed. The comment is general and doesn't pinpoint the section, table, figure, or unique aspect where the confusion arises. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer's comment is an interpretation and a suggestion for an alternative understanding of the 'curve finding' method in relation to FGE. There is X being made, and therefore, there is no evidence to verify or falsify. The comment is a suggestion, not a statement that requires justification or evidence.", "helpfulness_rationale": "The reviewer identifies a potential misunderstanding between the 'curve finding' method and FGE, suggesting an alternative interpretation. This is a valuable piece of information for the authors, as it highlights a potential point of confusion and offers a different perspective. However, the reviewer does not provide specific examples of where this misunderstanding might occur or how the alternative interpretation should be implemented. While the feedback points to a potential issue, it lacks concrete details and actionable steps, making it somewhat limited in its helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states 'linear scalarization + Concorde' as a missing baseline for comparison. This is a direct suggestion for the authors to include this method in their analysis. While the action is stated directly, the reviewer does not explicitly state *how* they should implement or apply this comparison, making it only implicitly actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'Competitive Baselines' and specifically names 'Concorde' as a missing comparison point. This clearly identifies the specific aspect of the paper being addressed (the comparison of different solvers). The comment also states the *purpose* of the comparison (to see if learningbased solvers are better for nonconvex Pareto fronts, compared to the traditional Concorde for singleobjective cases). This makes the grounding quite explicit.", "verifiability_rationale": "The comment contains a claim: 'linear scalarization + Concorde should be included for a better comparison.' This claim is supported by the reasoning that 'the obtained Pareto front is not highly nonconvex (as in Figure 2)' and that 'the SOTA heuristicsolver (e.g., Concorde) usually has the best performance' for single objective TSP. While the reasoning is present, it could be more robust by providing specific examples or references to support the claim about Concorde's performance in this specific context.", "helpfulness_rationale": "The comment is 5 as it directly points out a gap in the comparison of solvers and suggests a relevant baseline (Concorde). It provides a clear rationale for why Concorde is a valuable addition to the evaluation, linking it to the observed Pareto front characteristics and the general performance of Concorde in singleobjective TSP. This feedback is actionable and directly addresses a relevant aspect of the work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2: 5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point states \"It would be helpful if you provided glosses in Figure 2.\" This comment implicitly suggests the authors should add glosses to Figure 2. While the action of adding glosses is clear, the review point does not explicitly state how the authors should go about adding these glosses. For example, it doesn't specify if they should be textual descriptions, annotations, or something else. Therefore, while the action is implied, the specific implementation details are missing, making it partially actionable.", "grounding_specificity_rationale": "The review point explicitly refers to \"Figure 2\". This is a specific element of the paper. The authors can easily identify the section where the suggestion is being made. Therefore, the grounding is explicit and specific.", "verifiability_rationale": "The review point states \"It would be helpful if you provided glosses in Figure 2.\" This is a suggestion or recommendation, not a claim that something is wrong or needs improvement. There is no assertion of a deficiency or a requirement for justification. The statement is about what the authors should do, not what is currently lacking or needs to be proven.", "helpfulness_rationale": "The review point directly suggests a specific improvement: adding glosses to Figure 2. This points to a potential area for weakness (the lack of glosses) and offers a clear next step for the authors (adding them). It is a constructive suggestion that directly addresses a potential need for clarification or explanation. Therefore, it is 5 as it guides the authors towards a concrete action."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a gap in the literature ('no mention to any reference') but does not explicitly state the next steps the authors should take to address this gap (e.g., suggest a specific paper). The action is implied but not directly stated.", "grounding_specificity_rationale": "The comment mentions 'Memb' but does not explicitly state where in the paper or discussion 'Memb' is relevant. It also does not specify what is wrong with 'Memb' or provide any examples or details about its absence.", "verifiability_rationale": "The comment makes a claim ('there is no mention to any reference') based on the observation ('Memb is apparently the previous stateoftheart, but there is no mention to any reference'). While it lacks specific references, the claim itself is supported by the information provided in the review.", "helpfulness_rationale": "The review points out a valid issue (lack of references) and encourages the authors to find one. While it doesn't provide a specific solution, it guides the authors towards a necessary step in improving their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point is a question, not a direct suggestion or instruction on how to improve the draft. While it asks 'why not to consider finer grouping for quantization instead of pertensor and perchannel?', it doesn't provide a specific action or recommendation on how to address this question or what the implications might be. The reviewer is seeking clarification or justification, not actively proposing a solution.", "grounding_specificity_rationale": "The review point does not explicitly mention a specific aspect of the paper or methodology related to quantization. It is a general question about a design choice without pointing to a particular section, table, figure, or unique element. The reviewer is asking about a broader concept rather than a specific issue within the document.", "verifiability_rationale": "The review point is not a claim or assertion that requires verification. It is a question posed to the author, asking for justification or explanation regarding a design choice. Verifiability applies to statements that make assertions which need to be supported by evidence or reasoning, which is not the case here.", "helpfulness_rationale": "The review point is a question, not a critique or suggestion that directly improves the draft. While it might eventually lead to helpful information for the author, the review point itself does not provide actionable feedback or address a specific weakness in the work. It is a request for more information, not a constructive critique."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment suggests a *benefit* of exploring a different experimental setup (studying the impact of the ratio of unseen classes) but doesn't provide a concrete action for the author to take *now* to address their current work. It's a suggestion for future work, not a direct instruction for improvement.", "grounding_specificity_rationale": "The comment is general and doesn't refer to a specific part of the paper or identify a specific issue within the current work. It's a broad suggestion about an experimental parameter.", "verifiability_rationale": "The statement is a suggestion or recommendation, not a claim that needs to be verified or proven. There's no assertion of truth or falsity.", "helpfulness_rationale": "The comment doesn't identify any weaknesses in the current work or provide actionable steps to improve it. It's a suggestion for future research, which is valuable but not directly helpful for addressing the immediate needs of the author."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for a definition of 'active vertices' which is not explicitly stated in the sentence. While the context suggests it relates to the network's sparsity, the specific meaning is unclear. The reviewer implicitly knows that more information is needed to understand this term.", "grounding_specificity_rationale": "The reviewer is asking for a definition of 'active vertices' in the context of the sentence. The original text does not explicitly define this term, making the grounding weak. However, the request is specific, asking for a definition within this context, making it somewhat specific.", "verifiability_rationale": "The original text does not contain a claim. The reviewer is asking for clarification, not making a judgment. Therefore, this aspect is not directly verifiable within the provided text.", "helpfulness_rationale": "The reviewer's request for a definition of 'active vertices' is directly aimed at improving the clarity and understandability of the paper for the authors. This is a relevant and actionable piece of feedback, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out two main issues: the lack of acknowledgment of the theory's inapplicability to the used model and the underestimation of GNNs in industry. While the reviewer doesn't explicitly state what the authors should do, they clearly identify areas where the paper is lacking. This implies that the authors could take steps to address these limitations. However, the actionable steps are not explicitly stated, making it less actionable than a fully explicit comment.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the limitations' section when pointing out the lack of acknowledgment of the theory's inapplicability. They also specify the underestimation of GNNs in industry as a potential negative societal impact. This clear reference to a specific part of the paper and the issues within it demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer makes claims about the paper's limitations and the potential societal impact of GNNs. However, they do not provide any specific evidence, references, or logical reasoning to support these claims within the review point itself. The claims are presented as observations based on their reading, without further justification.", "helpfulness_rationale": "The reviewer raises two distinct and relevant points that could be valuable for the authors. The first point about the limitations highlights a crucial aspect that needs to be addressed. The second point about the societal impact of GNNs raises important considerations that could influence the paper's scope and discussion. While the actionable feedback is implicit, the grounding is explicit, and the points raised are likely to be helpful for the authors. The combination of these points makes the review 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks 'What does this mean exactly?' regarding the use of epsilongreedy exploration. This implies a lack of clarity in the original paper's description of this implementation detail. While the reviewer identifies a potential action (clarification), the specifics of how epsilongreedy is implemented in relation to the proposed strategy are not fully elaborated, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer attempts to ground the comment by mentioning Appendix D.2, indicating an effort to locate the relevant information. However, the request for clarification suggests that even with access to this section, the specific details of how epsilongreedy exploration is integrated with the proposed strategy are not clearly presented or easily understood. The specificity of the information is limited.", "verifiability_rationale": "The review states a fact ('For training we used an epsilongreedy...') and asks for clarification. While this statement could be verified by examining the implementation details, the request for clarification makes it somewhat ambiguous. The reviewer is seeking to understand the *mechanism* of integration, which goes beyond simply stating facts.", "helpfulness_rationale": "The reviewer's request for clarification on the use of epsilongreedy exploration is a valid question that could potentially help the authors understand a specific implementation detail. While the information might not be immediately clear, the request addresses a concrete area of potential confusion, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states their assessment of the method's novelty directly, which is an explicit action. However, they do not specify *how* the method is a combination of GCN and normalizing flow, nor do they provide concrete examples of where the lack of novelty is evident. The action is stated, but the details are missing.", "grounding_specificity_rationale": "The reviewer makes a general statement about the method's lack of novelty without specifying which part of the method or the paper this applies to. They do not mention any specific sections, tables, or unique aspects of their approach. The comment is broad and lacks focus on a particular component.", "verifiability_rationale": "The reviewer makes a claim that 'Technically, there is no enough new stuffs here.' This is a claim that needs verification. However, the reviewer does not provide any evidence or reasoning to support this claim. They do not cite specific papers, point to technical flaws, or explain why the combination of GCN and normalizing flow with a Gaussian mixture is not significant. The claim is stated, but there is no supporting evidence.", "helpfulness_rationale": "The reviewer's assessment is negative, stating that the method lacks 'enough new stuffs here.' This is a helpful comment as it points out a potential weakness in the work. While the comment is general, it provides a direction for the authors to investigate the novelty of their approach. The reviewer identifies a potential area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point states that 'Only projection head (CNN layers) are affected but not classification head (FCN layer)'. This explicitly states an action or observation about the model architecture. However, it does not provide concrete steps or instructions on how to modify or improve the model based on this observation. The reviewer is pointing out a difference in how the two heads are treated, but not what the implications are or how to address it.", "grounding_specificity_rationale": "The review point mentions 'projection head' and 'classification head' and even specifies they are 'CNN layers' and 'FCN layer' respectively. This indicates a level of grounding as the reviewer is identifying the *types* of layers involved. However, it does not specify *which* layers within those heads are affected. The description of the issue ('only' and 'but not') is also somewhat vague and doesn't detail the *nature* of the difference between the affected and unaffected heads.", "verifiability_rationale": "The review point makes a claim about the architecture of the model, stating that 'Only projection head (CNN layers) are affected but not classification head (FCN layer)'. This is a factual statement about the model's structure. The claim is supported by the description of the model's components (projection head, classification head, CNN layers, FCN layer).", "helpfulness_rationale": "The review point points out a potential area for further analysis or experimentation by the authors. It highlights a difference in how the two heads are treated. However, it does not provide specific guidance on what the authors should do next or why this difference is important. The reviewer is identifying a potential area for investigation, but lacks concrete suggestions for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the weakness of the analogy and points out specific flaws, making the criticism quite concrete. However, they do not directly suggest a replacement or a specific improvement, leaving the authors with a clear understanding of the problem but not a clear path forward.", "grounding_specificity_rationale": "The reviewer makes a general statement about the weakness of the analogy, lacking a precise identification of the specific part of the paper where the analogy is being made or discussed. However, they do mention specific concepts like HOI analysis and Harmonic analysis, providing some level of specificity regarding the criticism's content.", "verifiability_rationale": "The reviewer makes clear claims about the weakness of the analogy and the flaws in the connection between the decomposition/integration steps and Fourier analysis. However, they do not provide any evidence or references to support these claims, making them difficult to verify.", "helpfulness_rationale": "The reviewer identifies a valid weakness in the paper's approach by critiquing the analogy to HOI analysis and Harmonic analysis. However, they do not offer concrete suggestions for improvement or alternative approaches, leaving the authors with a diagnosis of the problem but not a prescription for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the findings might restrict meaningful implications, acting as an implicit action. They also clearly mentions 'bitparallel fixedpoint numbers,' providing strong grounding.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'bitparallel fixedpoint numbers,' providing strong grounding. They also specify the *type* of accelerator and the *numerical representation* they are concerned about, making it highly specific.", "verifiability_rationale": "The reviewer presents a claim about the limitations of the proposed methodology on certain accelerators. They provide a supporting statement about the prevalence of bitparallel fixedpoint numbers in existing ML accelerators, making it 3 as the connection between the methodology and the hardware is implied but not explicitly proven.", "helpfulness_rationale": "The reviewer's point is helpful in identifying a potential limitation of the proposed methodology in a specific hardware context. However, it lacks a direct suggestion for improvement, making it 3 as it highlights a potential issue without offering a concrete solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the issue with Figure 8: 'fig 8 shows images with different focusing distance, but it only shows 1m and 5m, which both exist in the training data.' This clearly identifies a lack of diversity in the demonstrated focusing distances. The reviewer also suggests a concrete action: 'does it generalize well? does it generalize well to focusing distances other than those appeared in training?'. This indicates a desire to see evidence of the model's ability to handle unseen focusing distances. The statement is clear and directly points to a specific area for improvement.", "grounding_specificity_rationale": "The review point mentions 'fig 8', which is a specific reference to the figure. While it doesn't explicitly state the 'focusing distance' values (1m and 5m) within the text, the context implies the reviewer has observed these specific values in the figure. The reviewer then asks a question directly related to the figure's content: 'does it generalize well? does it generalize well to focusing distances other than those appeared in training?'. This demonstrates an understanding of the figure's content and its potential limitations. The reviewer is not just stating a general concern but is specifically linking it to the observed figure.", "verifiability_rationale": "The review point makes a claim about the content of Figure 8: 'fig 8 shows images with different focusing distance, but it only shows 1m and 5m, which both exist in the training data.' This is a statement that requires verification. The reviewer also provides a method for verification by asking a question: 'does it generalize well? does it generalize well to focusing distances other than those appeared in training?'. This suggests a logical reasoning process to confirm the claim. The reviewer implies the need for external references (training data) to support their claim. The claim is wellsupported by a clear reasoning process and a specific question.", "helpfulness_rationale": "The review point is 5 because it directly identifies a specific issue with Figure 8, namely the limited range of demonstrated focusing distances. The reviewer provides a clear and actionable suggestion for improvement: 'does it generalize well? does it generalize well to focusing distances other than those appeared in training?'. This is a concrete next step for the authors to take. The reviewer is not just pointing out a problem but is also suggesting a way to address it, making the feedback valuable and directly applicable to the authors' work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the similarity of the proposed Xtransformation to STNs and the lack of comparison to them. It also mentions existing works that apply STNs in a local pixel neighborhood, further indicating an implicit action: the authors should consider discussing or comparing their method to these existing approaches. The grounding specificity is high as the comment clearly identifies the area of comparison (local STNs) and the missing element (comparison). The verifiability is high as the comment provides a clear claim and supports it by mentioning existing works. The helpfulness is high as the comment identifies a significant gap in the literature and suggests a direction for the authors to improve their work by considering existing approaches.", "grounding_specificity_rationale": "The authors can accurately pinpoint the specific area of the paper being addressed, which is the application of spatial transformations and the lack of comparison to existing STN methods, particularly those used locally. They mention 'spatial transformer networks (STN)\" and \"local pixel neighborhood,\" indicating a strong grounding. The comment also specifies what needs to be addressed in this part, which is the missing comparison to related works. The authors can also generalize the comment to point out the need for comparison without explicitly naming a specific section, which falls under 'general comments that clearly imply the relevant parts without explicitly naming them'.", "verifiability_rationale": "The comment contains a claim: \"A main weakness of this work is its technical novelty with respect to spatial transformer networks (STN) and also the missing comparison to the same.\" The claim is wellsupported by providing logical reasoning (the similarity to STNs) and common knowledge (the existence of local STN applications and their use in PointNet). The external references (mentioned in the review point) provide further support. The claim is thoroughly supported by explicit, sufficient, and robust evidence.", "helpfulness_rationale": "The comment is 5 as it clearly identifies a significant weakness in the work: the limited technical novelty and the missing comparison to existing STN methods. It provides a clear direction for the authors to improve their work by considering and comparing their approach to existing local STN methods and the use of STNs in PointNet. The reviewer's comment is specific and actionable, guiding the authors to address a crucial gap in their literature review and potentially their methodological contribution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides a clear, explicit action: correcting the figure number from 'Fig.7' to 'Fig.12'. Furthermore, the reviewer suggests a concrete, actionable improvement by linking proofs to each theorem and corollary. The reviewer explicitly states the issue and proposes a specific method to address it.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific figure, 'Fig.7', that needs correction. This demonstrates strong grounding as the authors can directly locate the problematic element. The reviewer also specifies the type of improvement, which is linking proofs to each theorem and corollary, adding further specificity to the suggestion.", "verifiability_rationale": "The reviewer makes a claim about the paper's overall quality, stating, 'The primary concerns are motivation, methodology soundness, and experiment persuasion.' While this is a subjective assessment, the reviewer provides reasoning for this belief, citing 'I believe this is a qualified paper with good novelty, clear theoretical guarantees, and convincing empirical results.' This reasoning, while not irrefutable proof, provides some justification for the claim.", "helpfulness_rationale": "The reviewer's comment is helpful because it points out a factual error ('Fig.7' vs. 'Fig.12') and suggests a practical improvement (linking proofs). Both of these actions are directly actionable for the authors. While the suggestion for linking proofs is relatively highlevel, it is still a concrete direction for improvement."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies issues with the selection and tagging of action verbs and the selection of action frames. While it points out the lack of clarity and justification in these processes, it doesn't explicitly state what the authors should do to improve their draft. The reviewer asks questions about the selection criteria but doesn't provide concrete steps or guidance on how to implement changes. Therefore, the review point is partially actionable as it points out a problem but lacks explicit instructions for resolution.", "grounding_specificity_rationale": "The review point explicitly refers to 'Section 3' and 'Section 3.306ff' within the paper, clearly identifying the specific parts being addressed. It also asks for explanations regarding the selection of action verbs and action frames. This demonstrates a clear understanding of where the issues lie and what needs to be explained. Therefore, the review point is 5.", "verifiability_rationale": "The review point makes claims about the lack of clarity and justification in the selection of action verbs and action frames. However, it does not provide any evidence, references, or logical reasoning to support these claims. The reviewer states what is missing but doesn't explain *why* it is missing or how it affects the paper. Therefore, the review point is 1 as it makes claims without providing supporting evidence or justification.", "helpfulness_rationale": "The review point identifies specific areas for improvement in the draft, namely the selection and tagging of action verbs and the selection of action frames. It asks questions to clarify these processes. While it points out weaknesses, it doesn't directly instruct the authors on how to fix them or provide guidance on the selection criteria. It is more of a diagnostic critique than a prescriptive one. Therefore, the review point is 3 as it identifies issues but lacks direct guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem ('some details are missing') but does not explicitly state how to address it ('how to design the rewards is not fully understandable'). It points to an action (improving clarity on rewards) but lacks specific guidance on the steps to take. Therefore, it is 2 as it identifies an actionable gap but lacks concrete instructions on how to implement the action.", "grounding_specificity_rationale": "The comment mentions 'how to design the rewards' generally, without specifying which part of the paper or element is causing the confusion. It does not clearly identify a specific section, table, figure, or unique aspect of the paper where the missing details are located. The grounding is weak because it refers to a process rather than a specific element.", "verifiability_rationale": "The comment states a problem ('some details are missing') but does not make a claim that requires verification. It describes a state of the paper rather than a proposition that needs to be proven or disproven. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The comment identifies a weakness in the paper ('some details are missing') but does not provide any suggestions or guidance on how to improve it. It points out a problem but does not offer a solution or direction for addressing it. Therefore, it is 2 as it highlights a problem without providing actionable improvement suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3: Partially Grounded", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a problem (generalization to different numbers of entities) but does not offer a specific action or suggestion on how to address it. The language is more about identifying an issue than proposing a solution.", "grounding_specificity_rationale": "The reviewer mentions 'Figure 3 of INs,' which provides a specific reference point, indicating they have identified a section or table. However, they do not explicitly state which specific part of Figure 3 is problematic, making it only partially grounded.", "verifiability_rationale": "The reviewer states a problem ('it's not clear how to generalize a model to different numbers of entities') without providing any evidence, justification, or references to support this claim. There is no logical reasoning or external references provided to verify the statement.", "helpfulness_rationale": "The reviewer raises a valid concern about the model's generalization capabilities. While they do not offer a solution, they do point out a limitation or area for further investigation, which provides some insight for the authors. However, the lack of a direct solution makes it less helpful than a point that offers a concrete improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the weakness: 'It's an incremental improvement to KNN based MT approach, little novelty' and suggests a consequence: 'backed by good experimental design. This weakness is a little nitpicking esp when I personally execution (replicable) beats idea (novelty)'. The phrase 'replicable beats idea' is a direct action the authors could take. While the reviewer doesn't directly state 'do X', the implications are clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'KNN based MT approach' and 'incremental improvement'. This clearly grounds the criticism to a specific part of the paper. The reviewer also mentions 'lack of code release', further grounding the criticism.", "verifiability_rationale": "The reviewer makes a claim: 'It's an incremental improvement to KNN based MT approach, little novelty' and provides a justification: 'backed by good experimental design. This weakness is a little nitpicking esp when I personally execution (replicable) beats idea (novelty)'. The reviewer also mentions 'if there's no code release is produced after the revision process, then this weakness stands'. This provides further justification and a logical reasoning for the claim.", "helpfulness_rationale": "The reviewer's review point is clearly aimed at helping the authors improve their draft. They identify a specific weakness ('incremental improvement, little novelty') and suggest a potential next step ('if there's no code release is produced after the revision process, then this weakness stands'). While the reviewer expresses a negative opinion about the novelty, they are still providing a constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the action the authors should take: 'discuss the runtime of Prithvi WxC'. It also identifies the specific aspect of the model that might be relevant: 'the large parameter count'. This makes the review point directly actionable, guiding the authors on what to improve.", "grounding_specificity_rationale": "The review point explicitly mentions 'Prithvi WxC' and discusses its 'runtime' and 'large parameter count'. The reviewer clearly identifies the specific part of the paper and the issue being addressed. This can be achieved through literal mention and identification of unique elements, indicating full grounding. The comment also specifies what needs to be addressed in this part (the runtime).", "verifiability_rationale": "The review point makes a claim: 'the runtime of Prithvi WxC should be discussed'. However, it does not provide any justification for this claim, logical reasoning, or external references to support why discussing the runtime is important or how to do it. The claim is presented without sufficient backing.", "helpfulness_rationale": "The review point identifies a relevant aspect of MLbased emulators (runtime) and suggests an improvement for the authors (discussing the runtime). While it doesn't explain *why* this is important or *how* to do it, it points the authors towards a valuable area for discussion. It highlights a potential weakness and proposes a concrete step to address it, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X (X)", "helpfulness_label": "2", "actionability_rationale": "The review point identifies the potential issue of overselling the method but does not provide specific actions or steps on how to address this. It lacks concrete details on which method is being oversold and how to correct it.", "grounding_specificity_rationale": "The comment is too general and does not specify which part of the paper is being addressed. It does not identify a specific section, table, figure, or unique aspect of the paper being criticized.", "verifiability_rationale": "The comment expresses an opinion about the framing of the paper and the overselling of a method, but it does not make a claim that can be verified through evidence or logical reasoning.", "helpfulness_rationale": "The comment raises a valid concern about the clarity of the paper's contribution, but it lacks specific details and actionable suggestions. It does not provide concrete steps on how to improve the paper, making it less helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review explicitly states what needs to be done with the model description, such as presenting the generative process in steps and creating a notation table. This directly tells the authors how to improve the draft, making it actionable.", "grounding_specificity_rationale": "The review mentions the 'model description' generally but doesn't specify a particular section, table, or unique element within it. The suggestions for improvement are also broad, not pointing to a specific part of the model description that needs attention.", "verifiability_rationale": "The review doesn't make a claim that needs verification. Instead, it states a problem (too many symbols, notation table) and suggests a solution (present in steps, create a table). This is a statement of what needs to be done, not a claim requiring justification.", "helpfulness_rationale": "The review provides clear and actionable feedback on the model description. It tells the authors what needs to be done and how to do it, making it a helpful suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment states 'The writing could be improved,' which is an explicit action. However, the reviewer does not specify *how* the writing needs improvement or *where* in the paper this is most evident. The action is stated, but the implementation details are missing, making it only implicitly actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the writing,' 'the main idea,' and 'the theoretical analysis' of the paper. This clearly identifies the specific parts of the paper being addressed, indicating full grounding. However, the comment does not specify *what* is wrong with the writing or suggest specific improvements within these areas, making the specificity underdeveloped.", "verifiability_rationale": "The comment contains a claim ('the writing could be improved') and provides a reason ('It took me quite a lot of effort to go back and forth to understand the main idea and the theoretical analysis') to support it. This reasoning is logical and provides context for the claim, making it verifiable.", "helpfulness_rationale": "The comment identifies a weakness ('the writing could be improved') but does not offer specific suggestions or guidance on how to address it. It's a general statement about the writing quality, which, while informative, lacks actionable advice for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the sentence is 'cumbersome' and 'can be made clearer,' indicating an intention to improve the writing. However, the suggestion lacks specific details on how to achieve this. The action is explicit (improving clarity), but the implementation is vague.", "grounding_specificity_rationale": "The reviewer directly refers to the 'Abstract' section and the specific sentence in lines 1217, indicating a clear identification of the relevant part of the paper. However, the comment does not specify what is unclear or needs improvement within that sentence. The grounding is explicit, but the specificity is limited.", "verifiability_rationale": "The review point does not contain a claim or suggestion. It is a statement of a desire for improvement. Therefore, it does not have verifiability in the sense of supporting a claim.", "helpfulness_rationale": "The reviewer suggests the abstract could be clearer. While this is a valid point, the suggestion is very general and lacks specific details on how to achieve this. The authors would not know exactly what changes are needed without more information. The feedback is present but lacks concrete action."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review points out a discrepancy in the experimental setup (Pix3D training and testing) and compares it to zeroshot methods. This doesn't directly tell the authors *what to do*. It highlights a potential flaw in their evaluation.", "grounding_specificity_rationale": "The reviewer mentions \"Pix3D training and testing\" and \"zeroshot singleimage 3D reconstruction models.\" While they identify the *parts* of the comparison, the *specificity* of the *issue* isn't entirely clear. Is the reviewer criticizing the *training data* or the *evaluation protocol*? The reference to \"zeroshot models\" is somewhat general.", "verifiability_rationale": "The reviewer states a fact about the training and testing on Pix3D, which is verifiable. The comparison to zeroshot models is also a verifiable statement, although the *implication* of unfairness might require further justification.", "helpfulness_rationale": "The reviewer points out a potential flaw in the experimental setup. While it's a valid point, it doesn't directly *teach* the authors how to improve their draft. It highlights a potential issue they might face."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of relying on 4 OCR QA datasets and suggests including more scenarios like the LLaVA benchmark. This directly points out a missing element in the evaluation, making it actionable. While the suggestion to include more scenarios is implicit, the identification of the specific type of dataset is concrete.", "grounding_specificity_rationale": "The reviewer mentions '4 OCR QA datasets' and 'LLaVA benchmark' as examples of scenarios that are missing. This demonstrates a clear understanding of the paper's evaluation section and identifies specific areas where improvements are needed. The mention of 'ablation studies' further specifies the nature of the suggested improvement.", "verifiability_rationale": "The reviewer makes a claim about the evaluation being 'limited' and 'relying on 4 OCR QA datasets.' They then provide a supporting statement, 'As the authors admit in Fig 4(5), this evaluation may be unreliable.' This logical connection between the claim and the supporting evidence makes the review verifiable.", "helpfulness_rationale": "The reviewer identifies a specific limitation in the evaluation methodology (reliance on OCR datasets) and provides a clear recommendation for improvement (including more diverse scenarios like LLaVA). This actionable feedback directly addresses a potential weakness and is relevant to the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer states they have 'a lot of problems' with the abstract visual reasoning tasks and asks for 'proof'. While they identify the *type* of problem, the review point doesn't explicitly tell the authors *what to do* to address these issues. The suggestion to investigate 'simpler visual reasoning tasks' is a potential improvement, but the review point itself doesn't directly instruct the authors on how to implement this or any other action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'abstract visual reasoning tasks' in the review point. This clearly identifies a specific aspect of the paper being discussed, making the grounding explicit.", "verifiability_rationale": "The reviewer makes a claim by asking for 'proof' that more simpler visual reasoning tasks wouldn\u00e2\u0080\u0099t do and this formulation in the paper is the way to go. They provide a justification for this claim by stating their 'trouble solving them' and the potential confusion with changing factors. This justification, while not citing external literature, provides a logical reasoning for their request for proof.", "helpfulness_rationale": "The reviewer points out a clear weakness in the abstract visual reasoning tasks and suggests investigating simpler tasks as a potential improvement. While the review point doesn't provide a concrete action for the authors to take *based on this comment*, it identifies a problem and offers a suggestion for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states concrete actions: \"Weak supervision could be better evaluated\" and \"The generation of authors is also not realistic\". These are direct suggestions for improvement.", "grounding_specificity_rationale": "The reviewer doesn't explicitly state which *specific* aspect of \"weak supervision\" they are referring to. They also don't pinpoint the exact 'structured elements\" or \"artificial tweets\" being problematic. The comment mentions \"realistic\" but doesn't provide specific examples of what makes something unrealistic.", "verifiability_rationale": "The reviewer doesn't explain *why* they believe weak supervision evaluation could be better or why the current author embedding generation is unrealistic. They state the *problem* but not the *evidence* for it.", "helpfulness_rationale": "The review point clearly identifies areas for improvement in the evaluation methodology and the author embedding generation process. It directly points to actionable steps the authors can take. This is very helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'include the keypoint detection results in the experiments section'. This action is clear and direct. While it doesn't specify *how* to perform this action, it clearly identifies the location where the information should be placed. Therefore, it can be considered explicit. However, the aspect of 'actionability' focuses on the *how* of the action, not just the *what* where it should be placed. The reviewer could have provided more detail on how to integrate this information effectively.", "grounding_specificity_rationale": "The review point mentions 'keypoint detection results' and 'experiments section'. While it identifies the type of information and the section where it should be placed, it doesn't specify *which* keypoint detection results or *which* experiments. The authors would need to infer the specific details from this general guidance. Therefore, it can be considered weakly grounded.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It's a directive for the authors to organize their information. While it's helpful for the authors, it doesn't involve making a statement that needs to be supported by evidence or references. Therefore, it can be considered not verifiable in the sense of providing evidence for *why* this is a good idea or *how* it will help. It's more of a recommendation.", "helpfulness_rationale": "The review point directly tells the authors what to do: include keypoint detection results in the experiments section. This is a clear and actionable suggestion. It provides a specific location for the information, which is helpful for the authors when they are analyzing their results and structuring their paper. The action is explicit and concrete, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question about whether the grid search of learning rate is done on the validation set. While the question itself doesn't directly state what needs to be changed, it points to a potential issue in the author's methodology, making it 3.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'validation set' in the context of the grid search of learning rate. This clearly identifies the specific part of the paper being referred to, making it fully grounded. The question is also very specific about the location of the grid search, making it highly specific.", "verifiability_rationale": "The phrase 'Minor problems:' at the end of the review point could be interpreted as a claim that the grid search is a minor problem. This claim is somewhat inferable, as the reviewer is asking for justification or evidence to support this assertion. Therefore, it is considered 3.", "helpfulness_rationale": "The review point raises a valid question about a crucial implementation detail (whether the grid search is on the validation set). This directly relates to the author's methodology and would likely help them ensure their process is sound. While the 'Minor problems' comment is subjective, the core question is helpful. Therefore, the review point is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their observation about the high number of discourse relations and directly asks a question about the authors' definition of 'discourse'. This clearly indicates an explicit action the reviewer is taking to understand the authors' choices. The reviewer is directly identifying a potential area of confusion or difference in interpretation.", "grounding_specificity_rationale": "The reviewer's question about the authors' definition of 'discourse' and 'dobj' relations does not explicitly identify a specific part of the paper being addressed. While the context is the authors' treebank, the focus is on a conceptual choice rather than a specific element within it. Therefore, the grounding is weak as the authors haven't directly pointed to where this definition is crucial.", "verifiability_rationale": "The reviewer's point does not contain a claim that needs verification. They are posing a question about the authors' methodology. Since there is X, there is no verifiability to assess. The authors have not provided any evidence or justification for their choice of discourse relations, making the point 1 at this stage.", "helpfulness_rationale": "The potential helpfulness of this review point is moderate. If the authors engage with the reviewer's question and provide a clear definition of 'discourse' and 'dobj' relations, the reviewer's point becomes 5 as it clarifies a crucial aspect of the authors' work. However, if the authors dismiss the point as 'colloquial' or not relevant, the point might not be helpful to them."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question about a specific aspect of the data (racial/economic diversity) and its implications for generalizability. While the action is not explicitly stated as a request to *add* something, it is an implicit action to identify a missing element and prompt consideration of its impact. The lack of a concrete action makes it 2.", "grounding_specificity_rationale": "The reviewer mentions 'racial/economic diversity' as the specific aspect of the sample being considered. This provides a clear indication of the part of the paper being addressed. While the reviewer doesn't point to a specific section or table, the term 'racial/economic diversity' is a specific descriptor of a characteristic within the sample, indicating a degree of grounding. The reviewer also asks about the generalizability of the results to 'other groups, especially marginalized groups,' which further specifies the area of concern within the sample.", "verifiability_rationale": "The reviewer poses a question about the generalizability of the results to other groups, especially marginalized groups. This constitutes a claim that the current sample might not be representative. However, the reviewer does not provide any justification or evidence to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the concern about generalizability. The claim is presented without sufficient support.", "helpfulness_rationale": "The reviewer's question directly addresses a potential weakness in the study's design \u2013 the lack of explicit consideration of racial and economic diversity in the sample \u2013 and its implications for the generalizability of the results. By asking about the generalizability to other groups, especially marginalized groups, the reviewer is prompting the authors to critically evaluate the representativeness of their sample and consider whether their findings might not apply broadly. This is a relevant and important question that encourages the authors to think about the limitations of their study and consider potential improvements. While it doesn't offer a solution, it identifies a problem and encourages reflection, making it 3."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "1 (2)", "verifiability_label": "3 (3)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point identifies a *direction* for improvement (higher output quality) but doesn't specify *how* to achieve it. The phrase \"there\u2019s still much room for improvement\" is a general statement, not a concrete action the authors should take. The suggestion is implicit. The authors are *told* there's room for improvement but not guided on *how* to get there. The level of \"room for improvement\" is vague. How much higher should the quality be? What specific techniques should be used?", "grounding_specificity_rationale": "The review point refers to \"Recent GAN works\" and \"amazing quality in synthesized results\" in a general way. It doesn't pinpoint a specific section, table, figure, or unique aspect of the paper being criticized. The reference to \"output quality\" is also broad. While the reviewer can *mention* areas related to GANs, they don't specify *which* part of the paper or unique element is affected. The criticism about output quality is general and doesn't detail *what* is specifically lacking.", "verifiability_rationale": "The review point contains a claim: \"Output quality is reasonable, but still far from realistic\" and \"Recent GAN works have shown amazing quality in synthesized results, and the bar has become much higher than a few years ago\". These are statements of opinion and comparison to external work. While the claim about GANs is somewhat supported by general knowledge of the field, the specific *bar* for output quality is subjective and lacks concrete evidence within the review point itself. The reviewer doesn't provide specific examples of where the current quality falls short in relation to GAN outputs. The reasoning is present but lacks specific examples or references to support the claim about the gap in output quality.", "helpfulness_rationale": "The review points out a valid concern about output quality and provides a reason for it (\"the limited novelty, low resolution output and still high hardware requirement\"). It offers a direction for improvement (\"higher output quality\"). The reviewer connects the problem to potential limitations of the work and suggests a relevant direction for future work. This suggests the comment is relevant and potentially helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly mentions the potential issue with 'soft labels' and suggests an alternative ('subpar hyperparameters'). This indicates an explicit action: investigating the soft labels and considering hyperparameters. The reviewer also points to the 'code for iNaturalist19' as the area needing investigation, which provides a clear next step. The reviewer's suggestion to 'reevaluate the results' further reinforces the explicit nature of the action required.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'CRM' and 'Crossentropy' as the areas needing investigation. This clearly grounds the issue in specific parts of the paper or code. However, the reviewer does not specify *how* the hyperparameters are subpar, leaving the grounding in that area somewhat vague. The reviewer's concern about the 'higher beta value' for iNaturalist19 also suggests a lack of specific grounding in that aspect.", "verifiability_rationale": "The reviewer states their concern 'based on the results presented'. This suggests a concern about the validity or interpretation of the reported results. While the reviewer doesn't provide external references or logical reasoning to verify their claim, the mention of '1' and 'incomplete' suggestions hints at a lack of sufficient evidence or justification to fully verify the issue. The reviewer's call for 'further investigation' implies a need for more information or analysis, which could be interpreted as a lack of verifiability.", "helpfulness_rationale": "The reviewer's overall tone is one of concern and a desire for clarification. They are asking for further investigation and a reevaluation of the results. While the reviewer identifies a potential issue, they don't provide a direct solution or a clear next step beyond investigating the code. The lack of immediate and clear actionable feedback suggests a lower level of helpfulness. The reviewer's statement that 'authors do not know what they should do after reading the comment' directly supports this assessment."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests adding evaluation for unseen words and mentions translations as a way to make this more accessible. While the suggestion is clear, the action of adding evaluation isn't explicitly stated. The suggestion to add translations is also implicit, as it implies the need for evaluation but doesn't directly state the action of adding it. The lack of explicitness makes it less actionable.", "grounding_specificity_rationale": "The reviewer mentions 'unseen words' and 'Figure 6' as areas for improvement. They also suggest 'translations' as a way to make the evaluation more accessible. While 'unseen words' and 'Figure 6' provide some grounding, the reviewer doesn't explicitly state which specific part of Figure 6 or the evaluation process they are referring to. The mention of 'translations' is also vague and doesn't pinpoint a specific element within the paper. The lack of precise identification weakens the grounding.", "verifiability_rationale": "The reviewer states a preference for more evaluation on unseen words and suggests translations. This constitutes a claim about how the evaluation should be conducted. The suggestion to add translations is a practical suggestion, but it doesn't provide strong justification or references to support its effectiveness. The lack of explicit reasoning or evidence makes it less verifiable.", "helpfulness_rationale": "The reviewer's point is clear and directly addresses a potential limitation of the current evaluation. Suggesting translations makes the feedback more actionable and impactful for a specific group. The suggestion directly tackles a potential bottleneck for Chinese speakers, making the feedback more accessible to a broader audience. The practical nature of the suggestion and its direct relevance to a specific need enhance its helpfulness."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the number of images in each category (20) and then states their concern based on that number. The action is the identification of the number of images, which is a direct and explicit statement. The suggestion to 'text the validity of the approach' is a direct action based on the identified number.", "grounding_specificity_rationale": "The reviewer explicitly states the number of images in each category (20 images in each of the 4 categories). This directly identifies the specific part of the paper being addressed. The reviewer also specifies the concern: 'I feel the number of images is small to text the validity of the approach.' This clearly indicates what needs to be addressed in this part.", "verifiability_rationale": "The reviewer makes a claim: 'the number of images is small'. This claim is supported by the explicit statement of the number of images (20) and the explanation of why 20 is small in this context. The reasoning is logical and the reference is direct.", "helpfulness_rationale": "The reviewer directly points out a limitation of the dataset (the small number of images) and raises a concern that is relevant to the validity of the approach. This is a clear and actionable feedback that directly addresses a parameter of the dataset."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for 'intuitive explanations' and points to the lack of explanations for figure elements. This indicates an expectation for concrete actions to be taken. However, the reviewer does not specify *how* these intuitive explanations should be implemented or the exact nature of the missing information in the figure captions. The action is implied but not explicitly stated in a detailed manner.", "grounding_specificity_rationale": "The reviewer refers to 'Figure captions' and specifically names 'Fig. 1 and 2'. This demonstrates a clear identification of the specific parts of the paper being addressed. The grounding is strong because the sections are explicitly mentioned. However, the reviewer does not specify *what* is missing in the captions (e.g., specific details about colors or legends). The specificity is present in identifying the figures, but the details of the required changes are not fully elaborated.", "verifiability_rationale": "The reviewer states a problem ('the paper is hard to follow') and suggests improvements ('more intuitive explanations' and 'figure explanations'). This constitutes a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support why the paper is hard to follow or why the suggested improvements will effectively address this issue. The claim is stated, but the verifiability is lacking.", "helpfulness_rationale": "The reviewer clearly states their desire for better clarity and provides specific examples of what they need (intuitive explanations and figure captions). This indicates a strong desire for improvement and a clear articulation of the problem. While the specific *method* of improvement isn't fully detailed, the *need* for improvement is evident and directly related to the stated issues."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the actions needed and provides specific locations for the issues. The reviewer states \"Text in table 1 is too small and hard to read\" and \"Algorithm 1: gradient symbol is missing in line 4\". These are direct and actionable suggestions. The reviewer identifies the specific section (table 1) and the specific line (line 4) where the issue occurs. This provides clear guidance on what needs to be improved.", "grounding_specificity_rationale": "The comment explicitly mentions which part of the paper it addresses, or it should be obvious to the authors. However, this comment does not specify what needs to be addressed in this part. The reviewer states \"Text in table 1 is too small and hard to read\" and \"Algorithm 1: gradient symbol is missing in line 4\". The reviewer accurately identifies the specific sections (table 1 and line 4 of Algorithm 1) as the parts being addressed. This indicates that the reviewer understands where the issues are located. However, the comment does not explain *why* these issues are important or how they affect the overall understanding of the paper.", "verifiability_rationale": "The claim is wellsupported but has minor gaps in explanation or references. The reviewer identifies weaknesses or areas for improvement but is incomplete or lacks depth. While the authors gain some insights, the feedback does not fully address their needs for improving the draft. The reviewer states \"Text in table 1 is too small and hard to read\" and \"Algorithm 1: gradient symbol is missing in line 4\". While these are valid observations, the reviewer does not provide any external references or logical reasoning to support these claims. The statements are based on the reviewer's direct experience of reading the text and observing the missing symbol. There is no further explanation of the impact of the small text on the overall understanding of the paper or the importance of the missing gradient symbol for the algorithm's correctness or performance.", "helpfulness_rationale": "The comment provides clear and actionable feedback on weaknesses and areas for improvement, though it could be expanded or refined to be fully comprehensive and impactful. The feedback is directly actionable and points to concrete improvements. While the feedback is helpful, it could be improved by providing more context or justification for the identified issues. The reviewer points out two specific issues: the readability of table 1 and the missing gradient symbol in Algorithm 1. These are actionable suggestions that authors can easily address. However, the review lacks context or justification for why these specific issues are significant enough to warrant further attention. For example, the reviewer could have explained how the small text hinders understanding of the data or how the missing gradient symbol affects the algorithm's convergence."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests a specific technical improvement related to rendering. This immediately suggests it's *potentially* actionable. However, the *how* is vague.", "grounding_specificity_rationale": "The review points to \"Wright et al., 1934; Figure 1\" as the specific part of the paper. This is an explicit reference. The comment specifies what needs to be addressed in this part by suggesting a rendering improvement. However, it doesn't explain *why* this rendering method might be better or how it relates to the content of Figure 1.", "verifiability_rationale": "The review point expresses uncertainty about the interaction with `hyperref` when using the suggested rendering method. It doesn't explicitly state a claim that needs verification. It's more of a question about a potential issue rather than a definitive statement.", "helpfulness_rationale": "The review point offers a potential improvement direction by suggesting a specific LaTeX command. It also raises a valid concern about the interaction with `hyperref`. While it doesn't provide a complete solution, it points towards a potential area for investigation and offers a specific technical suggestion, making it helpful, albeit not fully resolving the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the potential errors in the equation and the definition of B, and points to specific lines (Line 502 and the definition of B, Line 504). This indicates a clear and direct action the authors should take: reexamine the equation and definition to verify the sign errors.", "grounding_specificity_rationale": "The reviewer provides very specific references to the paper, mentioning 'Line 502' and 'the definition of B'. This indicates a high level of grounding as the authors can directly locate the relevant section. The reviewer also explicitly states the errors in the equation and definition, making the grounding very clear.", "verifiability_rationale": "The reviewer makes a clear claim about the sign errors in the equation and the definition of B. They also provide the correct formulas, which serves as direct verification. While external references are not provided, the mathematical nature of the error makes the verification relatively straightforward for the authors by performing a quick calculation or comparison.", "helpfulness_rationale": "The reviewer provides very specific feedback about potential errors in a key mathematical section. They point to specific lines and clearly state the incorrect signs. This is 5 and constructive, as the authors can directly investigate and potentially correct the error."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point implicitly asks for clarification on a specific implementation detail (parameter sharing) within a defined section (7.1) of the paper. While it doesn't explicitly state 'Do something!', it points to a potential area of confusion or lack of understanding. Therefore, it can be considered implicitly actionable. The reviewer is asking for information about a specific part of the paper and a specific detail within that part, making it concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 7.1' and asks about 'the ResNet' within that section. This clearly identifies the specific part of the paper and the specific component being discussed. The use of literal mention ('section 7.1') and a unique element ('ResNet') strongly indicates full grounding. The comment specifies what needs to be addressed within this part.", "verifiability_rationale": "The review point does not contain a claim that something is wrong or needs to be changed. Instead, it suggests a potential interesting baseline experiment and draws a connection to a related concept (ODE nets). While this might be valuable information for the authors, it doesn't present a verifiable error or flaw. Therefore, it is not 5. However, the suggestion and connection could be considered as providing some form of justification or context, making it partially verifiable.", "helpfulness_rationale": "The review point is informative and raises a valid point about a potential baseline experiment. It provides a suggestion for a future experiment and connects the work to a more abstract concept. While it doesn't directly tell the authors what to do, it offers context and potential avenues for further research. This level of detail and suggestion can be helpful for authors who are looking to expand their work or explore related areas. Therefore, it can be considered 3 as it provides valuable information and context, even if it doesn't immediately point to a concrete action for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a claim about the crossencoder's behavior ('It also \"attends to all candidates at once\" to obtain the final matching scores.') but doesn't explicitly state what action needs to be taken based on this observation. While the reviewer identifies a potential issue with the crossencoder's attention mechanism, the lack of a clear action makes it 3 but not fully actionable.", "grounding_specificity_rationale": "The reviewer makes a claim about the crossencoder's behavior ('It also \"attends to all candidates at once\" to obtain the final matching scores.') but doesn't explicitly name the crossencoder or any specific part of it. While the reviewer implies a problem with the crossencoder's architecture, they don't specify which part is being referred to. Therefore, the grounding is weak. The reviewer also specifies what the crossencoder is doing ('attends to all candidates'), which provides some level of specificity. However, the connection to the motivation is implied but not explicitly stated, making it somewhat specific.", "verifiability_rationale": "The reviewer makes a claim about the crossencoder's behavior ('It also \"attends to all candidates at once\" to obtain the final matching scores.') and its implications for the motivation. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim within the review point itself. The claim is presented as a statement of observation without justification.", "helpfulness_rationale": "The reviewer provides a critical assessment of the crossencoder's architecture and its potential impact on the motivation. While the criticism is direct and identifies a potential flaw, it lacks specific details and examples. The reviewer doesn't suggest concrete improvements or explain *why* attending to all candidates at once is problematic for the specific motivation. Therefore, while the feedback is valuable, it is somewhat general and lacks actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the use of an 'antiquated GNN model' and 'antiquated baseline algorithms/methods' as a potential issue. While this identifies a problem, the specific action to be taken is not explicitly stated. The reviewer implies a need to 'replace' or 'update' these, but doesn't specify *how* or *what* to replace them with. The action is implied but not concrete.", "grounding_specificity_rationale": "The reviewer mentions 'this work,' 'framework,' 'GNN model,' 'methods,' and 'baseline algorithms/methods.' While they *refer* to these areas, they do not pinpoint a specific section, table, figure, or unique aspect within the paper. The grounding is weak because the referenced part remains ambiguous.", "verifiability_rationale": "The reviewer makes a claim stating 'This work uses an antiquated GNN model and method, it seriously impacts the performance of this framework. The baseline algorithms/methods are also antiquated.' This is a claim that needs to be supported. However, the reviewer does not provide any specific examples, citations, or logical reasoning to *prove* that these methods are indeed significantly impacting performance or that they are definitively 'antiquated' in a measurable way. The claim lacks sufficient evidence.", "helpfulness_rationale": "The reviewer identifies a potential issue with the methodology (antiquated models/methods). However, they do not offer any specific suggestions or actions for the authors to take. The feedback is diagnostic, pointing out a problem, but lacks concrete guidance on how to address it. The authors are left without clear steps to improve their draft. The feedback is not prescriptive, making it less helpful in guiding concrete changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a lack of clarity regarding the *process* of how the proposed method generates the explanation for the NO2 group in Figure 1. They suggest that an *additional adhoc postanalysis* might be necessary, implying an implicit mechanism that isn't explicitly described. This makes the action of identifying the NO2 group somewhat implicit rather than a direct, concrete action. While the *outcome* (the NO2 group) is valuable, the reviewer highlights the lack of a clear, stepbystep explanation of how the method arrives at this conclusion. The vagueness in the description of the method's inner workings makes it difficult to directly apply the feedback.", "grounding_specificity_rationale": "The reviewer refers to Figure 1 and the NO2 group within it, indicating a specific part of the paper and a specific finding. This suggests some level of grounding. However, the reviewer doesn't explicitly state *which* part of the paper contains the explanation for the NO2 group. They are inferring it based on the figure. Therefore, while the *section* might be implicitly understood to be Figure 1, the explicit identification of the section isn't provided. The specificity lies in the *content* (NO2 group) but the grounding in terms of the *location* within the paper is somewhat implicit.", "verifiability_rationale": "The reviewer makes a claim: 'It's unclear how the proposed method produces this type of explanation (which says \"mutagens contain the NO2 group\").' This claim requires verification. The reviewer suggests that the method might involve an *additional adhoc postanalysis* to extract shared motifs. While this provides some justification, it lacks specific details about the nature of this postanalysis. The claim is not entirely unsupported, but it's not 5 due to the lack of concrete examples or references to support the claim about the postanalysis.", "helpfulness_rationale": "The reviewer provides a constructive criticism by highlighting a potential weakness in the paper's explanation regarding how the proposed method identifies the NO2 group in Figure 1. They point out the lack of clarity and suggest the need for an *additional adhoc postanalysis*. This feedback is valuable as it identifies a gap in the explanation and suggests a potential area for improvement. While it doesn't offer a complete solution, it points to a specific area where the paper could be clearer and more informative."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a deficiency (lack of comprehensive analysis) but doesn't directly instruct the authors on a specific action. Therefore, it's not actionable.", "grounding_specificity_rationale": "The review lacks specificity about which part of the paper needs improvement. Therefore, it's 1", "verifiability_rationale": "The review doesn't make a claim that needs verification. Therefore, it's not verifiable", "helpfulness_rationale": "The review provides a suggestion for improvement (more comprehensive analysis) but doesn't specify how to achieve it or where in the paper this improvement is needed. The tone is constructive but lacks concrete guidance. Therefore, it's 3"}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the connection to metalearning, identifies a gap in distinguishing approaches, and suggests concrete actions like citing and linking related work. While the initial statement about 'several approaches' in metalearning is vague, the subsequent suggestions are clear and actionable.", "grounding_specificity_rationale": "The reviewer mentions 'RL for architecture search and/or as optimizers for learning' as a specific example, which grounds the comment to a particular area of research. However, the initial statement about 'several approaches as well' in the context of metalearning is less specific, although it can be inferred that the authors are referring to different methods within that broader field. The suggestions to 'cite' and 'distinguish' are specific actions the authors should take.", "verifiability_rationale": "The reviewer states that 'RL for architecture search and/or as optimizers for learning' 'should be cited' and that the current work 'should be more heavily linked' to this area. While this is a valid suggestion, the review point itself doesn't provide any logical reasoning, common knowledge, or external references to support why these actions are necessary or beneficial. There is X that these approaches are directly related or that linking them would be advantageous without further justification.", "helpfulness_rationale": "The review point directly addresses a potential connection to metalearning and provides suggestions for improvement, such as citing and distinguishing related approaches. While it doesn't offer a specific solution, it guides the authors in organizing their related work and connecting their work to existing research, which is a valuable piece of feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what the reviewer intends to do with the feedback. While the reviewer expresses an intention to turk or generate feedback, the comment itself lacks a direct action. The reviewer's point is about the *process* of feedback rather than a specific actionable item for the paper.", "grounding_specificity_rationale": "The review point does not refer to a specific part of the paper or feedback mechanism. It is a general comment about the diversity of feedback, not addressing a particular element of the paper. The reviewer is discussing a process, not a specific weakness or feature.", "verifiability_rationale": "The review point expresses an opinion about the diversity of feedback but does not provide any specific evidence or justification for this opinion. There is X being made, let alone one that is supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point raises a valid concern about the lack of lexical and syntactic diversity in feedback. However, it does not directly suggest concrete improvements or actions the author should take to address this issue. The reviewer is suggesting a potential area for improvement in the feedback process, not a direct fix for a specific problem in the paper itself."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly suggests comparing the performance with two specific papers, which is a clear action to take. While the suggestion is general, it points towards a concrete improvement direction by highlighting the need for such comparisons.", "grounding_specificity_rationale": "The reviewer recommends comparing with two specific papers but does not explicitly identify the 'part' of the paper or methodology being addressed. The reference to 'the performance' is general, making the grounding somewhat weak. However, the suggestion to compare with specific papers implies a focus on a particular aspect (performance evaluation), making it somewhat specific.", "verifiability_rationale": "The reviewer recommends comparing with two specific papers but does not provide any justification or reasoning for why these papers are relevant or how they would help. There are no claims or verifiable information provided to support this suggestion.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: compare the performance with two specific papers. This directly addresses a common need in machine translation \u2013 evaluating performance against existing stateoftheart methods. While it doesn't provide specific implementation details, it points towards a concrete improvement direction."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing standard deviations as a problem, indicating an awareness of a potential issue with the presented results. The action of identifying the missing information is clear and direct.", "grounding_specificity_rationale": "The reviewer identifies the *absence* of standard deviations as a key point. While they don't explicitly name 'standard deviations' or point to a specific section, the implication is clear. The grounding is in the *lack* of a numerical metric, which is a form of implicit grounding. The identification of the *impact* (uncertainty about the best method) adds a layer of implicit grounding about the relevance of the missing information.", "verifiability_rationale": "The reviewer makes a claim that the lack of standard deviations makes it unclear which method is really the best. This is a logical claim. The reasoning is that standard deviations are a common way to assess the stability and reliability of results, which helps in determining the 'best' configuration. The claim is supported by the information provided.", "helpfulness_rationale": "The reviewer directly addresses a crucial aspect of evaluating experimental results \u2013 the ability to draw firm conclusions about which method performs best. This is a valuable piece of feedback for the authors who are trying to understand their model's performance and compare different configurations. The comment provides a clear direction for further analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer directly asks a question about the limitations of the approach and its potential for generalization. This is a clear and actionable question for the authors, as it prompts them to consider the assumptions of their method and explore broader applicability. The question is specific enough to guide the authors' thinking about the scope of their work.", "grounding_specificity_rationale": "The reviewer's question is general and does not explicitly point to a specific part of the paper or methodology being questioned. They are broadly asking if the approach can be extended, rather than pinpointing a particular area of concern. While the question is relevant, it lacks the specificity required to identify a precise section or concept within the paper being addressed.", "verifiability_rationale": "The reviewer proposes potential extensions to the approach but does not provide specific evidence or reasoning to support their claims about the current approach's limitations or the feasibility of these extensions within this review point. The suggestions are highlevel and lack concrete details or references.", "helpfulness_rationale": "The reviewer's question is constructive and directly addresses the need for more general applicability of the approach. It encourages the authors to consider the limitations of their current framework and explore potential avenues for broader use. This is a valuable and helpful question for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for an explanation of how the threshold p < 0.4 was chosen. This is an explicit request for clarification on how to *action* \u2013 understand the basis for this specific value. However, the review point lacks specific details on the reasoning or criteria used to select this threshold. The reviewer is asking for *how* to apply this action, but the information provided is insufficient to determine the exact method. Therefore, while the request is explicit, the lack of concrete details makes it somewhat vague in terms of actionability.", "grounding_specificity_rationale": "The reviewer is asking about the threshold p < 0.4, which could be interpreted as referring to a specific part of the paper (the pvalues or a related analysis). However, the review point does not explicitly identify this specific part of the paper. The reviewer is asking *what* is being addressed, but the point only states *how* they are asking about it. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses. The specificity is also low because the comment does not detail what is wrong or missing in this part (the pvalues).", "verifiability_rationale": "The review point does not contain a claim or suggestion. It is a question about a methodological choice. Therefore, it does not meet the criteria for verifiability, which requires a claim to be supported by evidence. The point is classified as 'X' as it contains X.", "helpfulness_rationale": "The reviewer is asking for justification for a specific methodological choice (the pvalue threshold). While this can be helpful for the authors to understand the rationale behind the choice and potentially improve their work, it is not actively improving the paper itself. The review point is a request for context and understanding rather than a direct critique or suggestion for change. Therefore, it is 3 in providing context but not directly actionable for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the actions needed: 'explain why there are negative numbers in Figure 1' and 'analyze the implications of Figure 2 and Figure 3.' These are clear and direct instructions on what the authors should do.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 1', 'Figure 2', and 'Figure 3' by name, indicating a strong grounding. They also specify what needs to be explained and analyzed, adding to the specificity.", "verifiability_rationale": "The reviewer makes a claim that the figures lack explanation and analysis. While they don't provide external references, they logically point out the absence of these elements, making the claim verifiable through logical reasoning and common knowledge about good scientific writing practices.", "helpfulness_rationale": "The review directly identifies a clear weakness (lack of explanation and analysis of figures) and provides a clear and actionable suggestion (explain the negative numbers and analyze the implications). This is immediately helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'Lack of Analysis' and 'Lack of comparison'. These are clear statements of what *should* be done, indicating a clear action the authors should take. While the reviewer doesn't specify *what* aspects are lacking, the identification of the missing analysis and comparison is a clear indication of actionable feedback.", "grounding_specificity_rationale": "The reviewer mentions 'data augmentation methods' and provides specific examples like 'EDA' and 'LLMbased paraphrasing'. This demonstrates an attempt to pinpoint specific areas of the paper that require improvement. However, the reviewer doesn't specify *what* aspects of these methods or comparisons are lacking, making it less fully grounded than it could be.", "verifiability_rationale": "The reviewer states that there is a 'lack' of analysis and comparison. This is a claim that needs verification. While the reviewer identifies the *type* of analysis and comparison missing, they do not provide specific evidence *within the review point itself* to support the claim that these analyses are indeed lacking. The claim is based on an assessment of the paper's content, not direct statements of error within it. Therefore, it is partially verifiable.", "helpfulness_rationale": "The reviewer clearly identifies specific areas where the paper falls short (lack of analysis, lack of comparison) and provides a concrete suggestion for improvement ('compare their approach to other paraphrasing methods'). This is a constructive criticism aimed at guiding the authors towards a better version of their work, making the review 5."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a potential issue with the experimental setup (lack of an ablation study for MMD) but does not explicitly state the action to be taken. While the reviewer suggests alternatives, the core action of conducting an ablation study is not directly implied or stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'learning with MMD' and then provides specific suggestions for alternative ablation targets ('typical knowledge distillation loss' and 'distilling a Hydra architecture with MMD loss'). The section being addressed is also implicitly clear (the MMD component).", "verifiability_rationale": "The reviewer provides a clear rationale for why an ablation study is useful ('to see the net effect of each component') and offers specific suggestions for alternative ablations. The reasoning is logical and the suggestions are concrete.", "helpfulness_rationale": "The review point identifies a potential weakness in the authors' understanding of their experimental setup (the lack of an ablation study for MMD) and provides specific, actionable suggestions for improvement. The reviewer clearly articulates the problem and offers concrete solutions, making this a 5 comment."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the action of assigning all negative samples to a distractor class. This action is clear and directly addresses a potential issue with the model's performance. However, it doesn't provide specific guidance on how to implement this action or what changes the authors should make to their model based on this finding. The action is explicit and concrete, but lacks the detail needed for direct improvement.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or model. It presents a general suggestion about a baseline experiment without linking it to a particular section, table, figure, or unique element of the work. Therefore, it is 1 in a specific aspect of the paper. The suggestion is vague and doesn't pinpoint where the authors should focus their analysis or improvements.", "verifiability_rationale": "The review point presents a suggestion and asks a question about the performance of a specific baseline. While it implies a claim that this baseline is worth evaluating, it doesn't provide any evidence, reasoning, or references to support this claim within the review point itself. The suggestion is a call to action without any justification or context.", "helpfulness_rationale": "The review point identifies a potential area for improvement by suggesting the evaluation of a simple baseline. It highlights a lack of analysis regarding this baseline and points to a potential weakness in the model's performance. However, it doesn't provide any specific guidance on how to implement this evaluation, what the expected outcome might be, or how this analysis should inform the authors' model. It's a call to action rather than a detailed explanation or constructive suggestion."}
{"actionability_label": "3. 3", "grounding_specificity_label": "5. 5", "verifiability_label": "4. 4", "helpfulness_label": "4. 4", "actionability_rationale": "The review point explicitly states the 'shrinking' advantage and the 'remains to be seen' about the future scalability. While it points to a trend, it doesn't directly tell the authors what specific changes to make to the models or the training process. The action is implied but not explicitly stated in terms of concrete modifications.", "grounding_specificity_rationale": "The review point explicitly mentions 'RLCD,' 'RLAIF,' '7B,' '30B,' and 'Tab. 2.' This clearly grounds the comment in specific elements of the paper, allowing the authors to identify the relevant information being discussed. The grounding is literal and points to a specific table.", "verifiability_rationale": "The review point makes a claim about the data presented in 'Tab. 2.' This claim is supported by the existing information in the table. The reasoning is logical and based on the observation of a trend. The information is verifiable through direct reference to the table.", "helpfulness_rationale": "The review point identifies a trend in the data and raises a question about the future scalability of the models. This provides context and highlights an area for further investigation for the authors. While it doesn't provide a direct solution, it offers a relevant observation that can be helpful in understanding the behavior of these models. The feedback is relevant to the research or development process."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'lacks specific measurements or comparisons' as a weakness in the claim of computational benefits. This is an explicit action the reviewer is pointing out is missing.", "grounding_specificity_rationale": "The reviewer mentions 'quantitative analysis,' 'measurements,' 'comparisons,' 'GPU hours,' 'memory usage,' and 'training time' as potential areas where the paper should have provided data. While the paper doesn't explicitly mention sections, tables, or figures containing this information, the reviewer has a general idea of what might be there, making the grounding weak. The reviewer clearly specifies the *type* of quantitative analysis being missing, indicating high specificity.", "verifiability_rationale": "The reviewer states a clear claim: 'While the paper claims computational benefits... it lacks specific measurements or comparisons.' This claim needs justification, making the verifiability high.", "helpfulness_rationale": "The review point provides a clear and actionable point for the authors. The reviewer highlights a specific area where the paper falls short and suggests a concrete way to address it (providing quantitative analysis). This is directly helpful for improving the paper's claims about computational efficiency."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the consequence of *not* considering the time for COLMAP and finetuning, which is the method becoming *less efficient* for these scenes. This directly identifies an action (considering the time) and how to implement it (by taking the time into account). Therefore, it is concrete and actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'COLMAP' and 'scenebyscene finetuning,' which are specific terms directly related to the method being discussed. This allows the reader to precisely identify the part of the paper being addressed. The comment also specifies the *impact* of not considering the time, which is a clear indication of grounding the feedback in a specific aspect of the work. The specificity is high as it clearly identifies the area and the consequence of neglecting the time factor.", "verifiability_rationale": "The review point contains a claim: 'rendering the method less efficient for these scenes.' However, it does not provide any external references, logical reasoning, or examples to support this claim. It presents the statement as an observation or suggestion for improvement, not as a definitive assertion that requires evidence. Therefore, while the claim is identified, the evidence provided is insufficient to verify it, making it 1.", "helpfulness_rationale": "The review point identifies a valid concern (the time impact on efficiency) and suggests a solution (considering the time). It points to a specific area for improvement (efficiency). While it doesn't provide a complete solution or a specific method for improving efficiency, it offers a clear direction for the authors to consider. It is not completely useless as it highlights a relevant factor, but it also doesn't completely solve the problem. Therefore, it is 3 as it guides the authors towards a relevant consideration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point directly asks a question about the model's components and their contributions, which is a clear indication of an actionable suggestion. The reviewer is asking for clarification on how different factors affect the model's performance, which the authors can directly use to understand and potentially improve their model.", "grounding_specificity_rationale": "The reviewer explicitly names the two factors being considered: 'noise' and 'exponential moving average'. This direct identification of the specific parts of the model being addressed makes the grounding very clear and specific. The authors can easily pinpoint the sections or aspects being discussed.", "verifiability_rationale": "The reviewer is asking a question that, while not immediately answerable with a single reference, points to a potential area for further investigation. The suggestion to compare the model with and without noise is a logical next step and a clear direction for experimentation. The request for clarification on the individual contributions is also verifiable through further analysis or experimentation. Therefore, it is 3 as it points to a verifiable suggestion.", "helpfulness_rationale": "The review point directly addresses a specific question about the contribution of different factors to the model's performance. This is highly relevant to the authors and directly helps them understand the impact of 'noise' and the 'exponential moving average'. The suggestion to compare the model with and without noise is a concrete and actionable step for them to take. Therefore, this review point is very helpful for the authors in understanding and potentially improving their model."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a question about the relevance of reporting results during training and a speculative concern about the planning component. While it touches on aspects of the training process, it does not provide explicit or direct instructions on how to improve the draft. The 'I wonder if' at the end makes it a question rather than a clear action.", "grounding_specificity_rationale": "The review point refers to 'results' and 'training' generally, without specifying a particular section, table, figure, or unique aspect of the paper. The 'I wonder if' component makes it a speculative statement rather than a clear statement of what is wrong or missing in a specific part.", "verifiability_rationale": "The review point does not contain a claim that can be supported by evidence. The first part is a statement of interest, and the second part is a speculative presumption. There is no logical reasoning, common knowledge, or external references provided to support any statement.", "helpfulness_rationale": "The review point raises a relevant question about reporting results during training, which could be helpful for the authors. However, the speculative nature of the second part ('I wonder if') makes it difficult to extract concrete and actionable feedback. The lack of clear suggestions or questions leaves the authors unsure of what to focus on or how to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks a question about a potential methodological consideration (whether sentences were treated as units) and identifies a gap in the manuscript (how entity disambiguation is handled). This directly points the authors to a missing detail and asks for clarification, making it 5.", "grounding_specificity_rationale": "The review point directly mentions 'DocRED' and 'entire sentence', clearly identifying the context and the specific issue. It also points to a missing element ('how this information is currently missing from the manuscript'), indicating a clear understanding of where the problem lies. This strong identification of the paper's content and the specific gap makes it 5.", "verifiability_rationale": "The review point states that 'This information is currently missing from the manuscript.' This is a claim that needs to be addressed. While the reviewer identifies the gap, they don't propose a specific solution or reference external work to verify how to handle it. The information is clearly stated as missing, making it verifiable but lacking in specific justification or references. Therefore, it's 3 as it points to a clear gap, but lacks the 'how' to address it.", "helpfulness_rationale": "The review point identifies a potential oversight in the methodology by pointing out a missing detail regarding how entity disambiguation is handled for sentences in DocRED. While it highlights a gap in the manuscript, it doesn't offer a specific suggestion or alternative approach to address this missing information. It simply asks for clarification on something that is not present. Therefore, it is 4 as it points to a potential area for improvement, but it doesn't actively guide the authors on how to fix it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the connection between the ablation study results and the PBSD contribution, indicating a clear action. Furthermore, the reviewer identifies the specific motivation for PBSD (improving the discriminative of the learned representation on tail classes) and poses a question about other motivations, making the action quite concrete.", "grounding_specificity_rationale": "The reviewer refers to 'the PBSD part' and 'the DSCL part,' which are specific components of the paper. They also refer to 'the main contribution,' which, while initially unclear, is later tied to PBSD. The reviewer also specifies the motivation for PBSD as improving the discriminative of the learned representation on tail classes, which is a specific aspect of the model's behavior.", "verifiability_rationale": "The reviewer makes a claim that the performance gain is 'mostly from PBSD' based on the ablation study. This claim is supported by the evidence presented in the ablation study. The reviewer also points out a discrepancy between the stated motivation (supervised contrastive learning) and the actual contribution (improving tail class discriminative ability), which is a clear justification for the claim.", "helpfulness_rationale": "The review point identifies a lack of clarity in the main contribution and points out a potential mismatch between the stated motivation and the actual contribution supported by the ablation study. The reviewer also poses a direct question about other motivations for PBSD, which is a concrete suggestion for improvement. The feedback is specific and directly addresses the identified issues, making it 5 for the authors to understand and improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer poses a question about a tester and then raises a concern about its applicability to specific pairs of distributions. While it points out a potential limitation, it doesn't explicitly state what action the authors should take. The question itself is the action.", "grounding_specificity_rationale": "The reviewer mentions \"tester,\" 'spread parameter,\" \"\u03f5, \u03b4 identity tester,\" \"\u03c0,\" \"\u03d5,\" and \"d_K(\u03c0_0, \u03c0).\" They are specifically referring to concepts and parameters related to identity testing in the context of distributions. The mention of KL divergence (d_K) also grounds the discussion to a specific measure of difference between distributions.", "verifiability_rationale": "The reviewer poses a question and then describes a scenario where the KL divergence is large. They are asking how the tester handles this specific case. There isn't a clear declarative statement of a claim or judgment.", "helpfulness_rationale": "The reviewer asks a question and provides a specific scenario. While it's relevant to identity testing, it's a question rather than a direct critique or suggestion for improvement. It doesn't offer a solution or further insight into the topic."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment identifies a problem ('unclear') but does not specify what is unclear or how to address it. It lacks explicitness and concreteness.", "grounding_specificity_rationale": "The comment refers to 'the detailed distribution of the proposed dataset' generally, lacking specific identification of a section, table, figure, or unique aspect. It does not clearly specify what is wrong or missing in the distribution.", "verifiability_rationale": "The comment states a problem ('unclear') but does not provide any evidence, logical reasoning, or external references to support the claim. It is presented as a statement of a potential issue without justification.", "helpfulness_rationale": "The comment identifies a potential issue ('unclear distribution') but does not provide any actionable feedback or suggestions on how to improve the dataset description. It fails to offer any value to the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for 'annotated labels' and 'supervised training' as a limitation of the proposed method. This directly points to an action the authors should take. The statement is clear and identifies a specific area for improvement.", "grounding_specificity_rationale": "The reviewer specifically mentions 'annotated labels' and 'supervised training' as a limitation. This directly identifies the specific part of the paper (or concept) being addressed, making the grounding strong. The reviewer also clearly states what is missing (annotated labels) and why it is a problem (limits application to supervised training), making the specificity high.", "verifiability_rationale": "The reviewer makes a claim about the potential of 'selfsupervised pretraining without annotations' as a more appealing alternative. This claim is verifiable because selfsupervised methods are a wellestablished area of research, and the lack of annotation is a demonstrable fact. The reviewer provides a clear statement of what could be improved.", "helpfulness_rationale": "The reviewer clearly identifies a significant limitation of the proposed method \u2013 the reliance on annotated labels and supervised training. This is a valuable piece of feedback for the authors, directly pointing to a key area for improvement. The reviewer's suggestion of a selfsupervised approach is a concrete and potentially impactful direction."}
{"actionability_label": "None", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two specific suggestions for improvement. The first suggestion, to add a citation and a more specific description of expressivity in the abstract, is a clear and actionable step. The second suggestion, to include learning curves for all experiments in the appendix, is also a clear and actionable step. Both suggestions directly address potential weaknesses in the paper and provide concrete directions for improvement. The reviewer explicitly states what changes should be made, making it easy for the authors to act upon.", "grounding_specificity_rationale": "The reviewer's first suggestion to improve the abstract by specifying how expressivity is measured is 'Partially Grounded and Specific'. While the reviewer refers to the abstract as a whole, they pinpoint a specific aspect ('expressivity') and suggest a concrete improvement ('change in linear regions in output space after citation'). The reviewer provides a clear target for improvement within the abstract. However, the second suggestion to add learning curves for all experiments is '3'. The reviewer refers to 'all experiments' generally and suggests adding 'learning curves'. While the *type* of experiment might be implied, the *specific* experiments and their *details* are not mentioned. The suggestion for the *format* (learning curves) is clear, but the *target* experiments are vague. Therefore, the grounding is present but not as precise as in the first suggestion.", "verifiability_rationale": "The reviewer makes two claims in their review point. The first claim is that the abstract should be more specific about how expressivity is measured. This claim is 'Verifiable' because the reviewer provides a clear suggestion for improvement ('change in linear regions in output space after citation') and explains why this is a good suggestion ('attain greater expressivity'). The reviewer also provides a logical reasoning for this suggestion. The second claim is that including learning curves would be beneficial for understanding experimental results. This claim is also 'Verifiable' because the reviewer provides a clear suggestion ('learning curves') and explains why this is a good suggestion ('to visualize training dynamics and convergence behavior'). The reviewer also provides a logical reasoning for this suggestion.", "helpfulness_rationale": "The reviewer's review point provides two clear and actionable suggestions for improvement. The first suggestion to be more specific about expressivity in the abstract is directly helpful to the authors as it gives them a concrete direction for revision. The second suggestion to include learning curves for all experiments is also directly helpful as it provides a clear and useful addition to the paper. The reviewer's suggestions are not just opinions but are specific, actionable, and provide clear guidance on how the authors can improve their work. The reviewer's language directly translates to concrete steps the authors can take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a claim and provides a clear action: 'MULT was proposed in 2019 and thus sort of out of fashion' and suggests an alternative: 'The paper regards MULT as the only deep learning based baseline that considers crosssensory interaction but MULT was proposed in 2019 and thus sort of out of fashion. * The paper regards MULT as the only deep learning based baseline that considers crosssensory interaction but MULT was proposed in 2019 and thus sort of out of fashion.'", "grounding_specificity_rationale": "The comment explicitly mentions three specific papers: 'MISA: ModalityInvariant and Specific Representations for Multimodal Sentiment Analysis, ACM MM 2020', 'M2FNet: Multimodal Fusion Network for Emotion Recognition in Conversation, CVPR workshop 2022', and 'MMDFN: Multimodal Dynamic Fusion Network for Emotion Recognition in Conversations, ICASSP 2022'. These are concrete examples of recent works in the field of multimodal emotion recognition.", "verifiability_rationale": "The comment makes a claim and provides supporting evidence: 'MISA: ModalityInvariant and Specific Representations for Multimodal Sentiment Analysis, ACM MM 2020', 'M2FNet: Multimodal Fusion Network for Emotion Recognition in Conversation, CVPR workshop 2022', and 'MMDFN: Multimodal Dynamic Fusion Network for Emotion Recognition in Conversations, ICASSP 2022' are all published in 2020 and 2022, which are after 2019, thus showing that there are more recent baselines that consider crosssensory interaction. The reasoning is clear and based on publication dates, which are verifiable.", "helpfulness_rationale": "The comment directly addresses a potential weakness in the related work section by pointing out that the cited baseline (MULT) is outdated and suggests more recent and relevant alternatives. The reviewer provides specific examples of recent papers that also consider crosssensory interaction, making the feedback actionable and constructive for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer clearly identifies a specific problem: the lack of clarity in the experimental comparison of different models and the omission of information about the number of model parameters. They propose a concrete solution: comparing tensor completion results for all models while ensuring they have the same number of model parameters. This directly addresses the actionable aspect by highlighting a missing detail and suggesting a clear path for improvement.", "grounding_specificity_rationale": "The reviewer explicitly states the *specific* issue: the lack of clarity in model comparison and the omission of information about model parameters. They also propose a *specific* solution: comparing models with similar parameters. This demonstrates strong grounding specificity, as the reviewer not only identifies the problem but also provides a clear direction for how to address it.", "verifiability_rationale": "The reviewer provides a clear and logical request for information. They specify *what* information is missing (number of model parameters) and *why* it's important (for a fair comparison). This makes the criticism verifiable, as the authors can easily check and provide this information. The reviewer's suggestion is based on a wellestablished principle in experimental design.", "helpfulness_rationale": "This review point is 5 because it directly addresses a significant weakness in the experimental setup: the lack of a fair comparison between models due to missing information about their complexity (number of parameters). By highlighting this issue and suggesting a concrete solution, the reviewer empowers the authors to improve the rigor and validity of their experiments. This is a valuable contribution to the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a discrepancy in the normalization module between two versions and specifically highlights a potential issue in Figure 4's 0/5.0 latency range where overlapping symbols are mentioned. This provides a clear area of concern and a specific example within that area, making the action explicit. The reviewer suggests standardizing the icons, which is a concrete action. However, the reviewer does not explicitly state how to implement this standardization, making it only 3.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Fig. 4' and discusses specific ranges of latency and MAE, which clearly identifies the specific part of the paper being addressed. However, the reviewer does not provide specific examples of what is overlapping in the symbols or why the figure is confusing in that range. The suggestion to standardize the icons is general and not tied to a specific element within Figure 4. Therefore, while the grounding is explicit, the grounding is not fully specific.", "verifiability_rationale": "The reviewer states 'Fig. 4 is a bit confusing...' which can be considered a claim. They also mention '2.5/4.0 MAE' as a potential reason for the confusion. While they offer a potential explanation, they do not provide external references or logical reasoning beyond the visual overlap of symbols (which is not explicitly shown to be overlapping in the provided text). Therefore, the claim is somewhat supported but lacks key elements like examples or references.", "helpfulness_rationale": "The reviewer identifies a specific area for improvement (standardizing icons) and points to a concrete issue in Figure 4. The suggestion to standardize icons is a helpful and actionable feedback for the authors. While the specific issue in Figure 4 is not fully addressed, the general suggestion is clear and aimed at improving the presentation of the work. The reviewer's feedback is directly related to the paper's content and aims to enhance its clarity."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer correctly identifies the intention to prune subdivision splines, which can be considered an explicit action. However, the paper does not provide concrete details on *how* this pruning is achieved. The lack of explicit steps makes it an implicit action that needs to be inferred.", "grounding_specificity_rationale": "The paper mentions 'subdivision splines' and 'pruning' in the context of the theoretical part. However, it does not explicitly state which specific part of the theoretical framework or algorithm these terms directly refer to. The reviewer's questions highlight this lack of precise grounding.", "verifiability_rationale": "The paper makes a claim about the goal of pruning being to remove subdivision splines. However, the theoretical part does not provide sufficient justification or evidence for this claim, such as logical reasoning, common knowledge, or external references. The lack of supporting details makes it 3.", "helpfulness_rationale": "The reviewer's questions directly address the paper's claims and identify a significant gap in the theoretical part. The lack of detail about the algorithm and its computational cost is a concrete piece of information the authors would likely need. Therefore, the review is 3, but it could be more specific and detailed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that 'W1 and W2 are not defined' and then points to specific equations (A4) where these undefined variables are used. While the reviewer doesn't directly *imply* a need for definition, the act of pointing out the missing definitions and their location in the equations is a clear and direct action the authors should take. The reviewer is not just stating a problem, but also indicating where the problem lies and what needs to be addressed.", "grounding_specificity_rationale": "The reviewer identifies the specific equations (A4) where the undefined variables W and V appear. They also mention 'W and 2 are not defined' and 'p.3, A4, eq.3: W and V not defined, same as above Eq.', which directly points to the specific location and the undefined elements within those equations. This demonstrates a clear identification of the specific part of the paper and the issue within it.", "verifiability_rationale": "The reviewer states that 'W1 and W2 are not defined' and provides the location of these undefined variables in equations (A4). However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support why these undefined variables are a problem. The comment identifies a flaw but doesn't explain its implications or provide any context to make it verifiable.", "helpfulness_rationale": "The reviewer's comment primarily criticizes the lack of definition of variables in the model description. While they point out a factual error, they do not offer any suggestions or insights on how the authors should define these variables. The comment is focused on identifying a problem rather than providing constructive advice on how to solve it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points to a specific aspect of the RPN (negative chips and training) but lacks detail on how this relates to the paper's improvement. While the reviewer *wants* more information, the current statement isn't *actionable* enough to directly guide improvements.", "grounding_specificity_rationale": "The reviewer mentions 'negative chips' and 'RPN training' but doesn't specify which part of the RPN or the training process they are referring to. This makes the grounding weak, as the connection to a specific part of the paper is not clear.", "verifiability_rationale": "The reviewer poses a question about the state of negative chips and the suggested training approach. While this can be seen as a claim that something is unclear, the reviewer doesn't provide any evidence or reasoning to support this claim. The suggestion itself is a potential improvement, but the current point is about identifying a lack of clarity.", "helpfulness_rationale": "The reviewer's point is more about identifying a lack of clarity regarding the RPN rather than providing a direct suggestion for improvement. Therefore, it's borderline helpful as it highlights an area that needs more explanation or clarification to be truly helpful."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need to evaluate the approach on new and old patients separately. This is a direct identification of a necessary action. The reviewer also implies the need for a different evaluation strategy for these two groups, which is an explicit action to be taken.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'new patients' and 'old patients' as distinct groups. This is a clear and direct identification of the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer states a need to evaluate the approach on new and old patients respectively. This is a claim that requires justification. The reviewer implies that this evaluation should be done separately for each group, providing some justification for the claim.", "helpfulness_rationale": "The reviewer points out a limitation in the current evaluation strategy, specifically the lack of consideration for patient visit history. This is a valuable suggestion that directly addresses a potential issue and empowers the authors to improve their evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'no indepth analysis' and asks 'why?'. This is a clear request for a specific action (providing analysis). While the request is for an analysis, it lacks specific details on what kind of analysis or how to explain the dynamics, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'the authors found inverse scaling happens over compute' as a specific observation. This clearly identifies a part of the paper and asks for an explanation of it, indicating strong grounding. The request 'but why?' further emphasizes the need for a detailed explanation of this specific finding.", "verifiability_rationale": "The reviewer presents a statement ('the authors found inverse scaling happens over compute, but why?') as a problem that needs to be addressed. This constitutes a claim that requires explanation. However, the reviewer does not provide any external references or logical reasoning to support this claim within the review itself. The request is directed at the authors to provide their analysis, not to validate an existing claim.", "helpfulness_rationale": "The reviewer's comment directly points out a potential weakness in the paper: the lack of indepth analysis for the observed inverse scaling with compute. This is a clear and actionable suggestion for improvement, directly addressing a gap in the current work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their desire for a 'formal definition' of multihead attention and clarifies their understanding of the split arrow in Figure 2 as input vectors. While the request for a formal definition is concrete, the request for clarification on the relationship between keys/values and input vectors is more implicit. The reviewer is inferring a missing detail rather than directly stating it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'multihead attention' and points to Figure 2 as the relevant part of the paper. This demonstrates a clear identification of the specific architectural detail being discussed. The request for clarification on the inputs to the attention layer (query, keys, values) and their relationship to the input vectors further specifies the issue.", "verifiability_rationale": "The reviewer does not make a claim that can be verified. Instead, they are pointing out a lack of clarity and asking for clarification on specific aspects of the architecture. The review point itself does not contain a claim that requires evidence or justification.", "helpfulness_rationale": "The reviewer's request for a 'formal definition' of multihead attention and clarification on Figure 2 is highly relevant and directly addresses a practical implementation issue. This feedback is actionable and constructive for the authors, helping them understand the architecture better."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly points out a specific assumption (each individual\u2019s data is iid drawn from the same distribution) made in the paper and argues that this assumption is unjustifiable and undermines a key part of their argument (the sqrt(m) term and Theorem 6 leading to Theorem 7). This is a clear and actionable criticism of a core assumption.", "grounding_specificity_rationale": "The reviewer explicitly names the 'IID assumption' and explains how it relates to the convergence argument and the sqrt(m) term. They also connect it to the applicability of Theorem 6 to prove Theorem 7. This is a highly specific criticism directly tied to a key element of the paper's methodology.", "verifiability_rationale": "The reviewer provides a clear explanation of how the IID assumption impacts the mathematical argument, specifically how it allows for the application of theorems and the derivation of the sqrt(m) term. They explain the connection between the assumption, Theorem 6, and how it leads to Theorem 7. This is a highly verifiable criticism as the reasoning is logical and directly tied to the mathematical framework.", "helpfulness_rationale": "The reviewer's comment directly challenges a fundamental assumption of the paper and points out a potential limitation in its methodology. This is likely to be 5 for the authors to understand the scope and limitations of their approach and to potentially address the issue of nonIID data."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "1 (1)", "verifiability_label": "4 (4)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer explicitly states that the policy is 'fixed' and then suggests exploring more complex tasks that could lead to a 'nonfixed policy'. While the reviewer doesn't provide a specific action on how to implement this, the suggestion itself is a clear direction. The reviewer also mentions comparing with a reinforcement learning algorithm baseline, which is a concrete step.", "grounding_specificity_rationale": "The reviewer discusses the concept of a 'policy' in reinforcement learning in general terms, without specifically referencing a particular section, table, or unique aspect of a hypothetical paper. The discussion is about the *general* concept of a policy, not a specific implementation detail within a paper.", "verifiability_rationale": "The reviewer makes a claim that 'tasks can get more complicated (like what explained in the last paragraph of the paper) so that the policy is not fixed.' This claim is supported by the logical connection between task complexity and the flexibility of the policy. The reviewer also suggests comparing with a reinforcement learning algorithm baseline, which provides a basis for verification.", "helpfulness_rationale": "The reviewer suggests exploring more complex tasks and comparing against a reinforcement learning algorithm baseline. These are relevant and potentially helpful suggestions for improving the draft. However, the reviewer doesn't provide specific steps on how to implement the complex tasks or how to perform the comparison."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a limitation of the paper's scope. While it identifies a problem (limited applicability) it doesn't explicitly tell the authors what to change or how to address the multitask modeling aspect. The authors still need to figure out how to make it more applicable themselves. The criticism is about the scope of the paper, not a specific, actionable item within the paper's content. The authors don't get a clear, concrete step to take. It's a highlevel criticism about the paper's focus, not a specific, actionable item within the paper's content. The authors still need to figure out how to make it more applicable themselves. The criticism is about the scope of the paper, not a specific, actionable item within the paper's content. The authors don't get a clear, concrete step to take. It's a highlevel criticism about the paper's focus, not a specific, actionable item within the paper's content.", "grounding_specificity_rationale": "The review points out a limitation of the paper's scope. It doesn't pinpoint *which* part of the paper the focus is on (the entire paper, really). It's a general statement about the paper's content. While it implies the paper as a whole, it doesn't explicitly name anything. The authors are not told to focus on a specific section, table, or figure. The criticism is about the *content* of the paper, not a specific section, table, figure, or element. The authors are not told to focus on a specific section, table, or figure. The criticism is about the *content* of the paper, not a specific section, table, figure, or element.", "verifiability_rationale": "The review states a limitation of the paper's scope. This is a statement of opinion or judgment about the paper's applicability. It's a claim. The statement is a general observation about the paper's focus. While it's a valid observation, the review doesn't provide any specific evidence or references to support this claim. It's a subjective assessment of the paper's content. The statement is a general observation about the paper's focus. While it's a valid observation, the review doesn't provide any specific evidence or references to support this claim. It's a subjective assessment of the paper's content.", "helpfulness_rationale": "The review points out a valid limitation of the paper's scope. It's relevant to the authors' work if they are focusing on multitask models. However, it doesn't provide concrete solutions or specific directions for improvement. The authors still need to figure out how to address the applicability issue themselves. The criticism is about the scope of the paper, not a specific, actionable item within the paper's content. The authors don't get a clear, concrete step to take. It's a highlevel criticism about the paper's focus, not a specific, actionable item within the paper's content. The authors are not told to focus on a specific section, table, or figure. The criticism is about the *content* of the paper, not a specific section, table, figure, or element. The authors are not told to focus on a specific section, table, or figure. The criticism is about the *content* of the paper, not a specific section, table, figure, or element. The authors are not told to focus on a specific section, table, or figure. The criticism is about the *content* of the paper, not a specific section, table, figure, or element."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly mentions the missing papers 1 and 2 and suggests including them. This constitutes an explicit action, as the authors can directly identify the missing parts and the required action is to include them. While the specific *implementation* of including these papers isn't detailed, the action itself is clear and actionable.", "grounding_specificity_rationale": "The review point explicitly mentions the specific papers 1 and 2 by their identifiers. This falls under the 'Literary mentions of sections, tables, figures, etc.' category of full grounding. Furthermore, the reviewer explains *why* these papers are relevant by stating they 'seem to be relevant' and satisfy 'Assumption 2', providing clear specificity about the issues with the missing parts.", "verifiability_rationale": "The review point contains a claim that 'Literature review ignores several papers that are seemed to be relevant 1, 2. It seems VRMARINA ... have a better rate than QSGD in the stochastic regime.' This claim is supported by the reasoning that these papers satisfy Assumption 2 and have a better rate. The logical reasoning and precise explanations provided support the claim, making it 5.", "helpfulness_rationale": "The review point identifies a clear gap in the literature review by pointing out the omission of relevant papers and suggesting their inclusion. This directly addresses a potential weakness in the authors' work. The suggestions are specific and actionable, guiding the authors on what to add to their literature review. The logical flow from identifying the gap to suggesting a concrete solution makes this review point 5."}
{"actionability_label": "N/A", "grounding_specificity_label": "N/A", "verifiability_label": "N/A", "helpfulness_label": "3", "actionability_rationale": "The review point does not contain explicit or implicit actions or suggestions on how to improve the draft. It poses questions for further discussion rather than providing concrete feedback.", "grounding_specificity_rationale": "The review point does not explicitly refer to any specific part of the paper or dataset. It poses questions generally about performance on different datasets.", "verifiability_rationale": "The review point does not contain a claim or suggestion that requires verification. It is a request for information and analysis.", "helpfulness_rationale": "The review point poses questions for further discussion and analysis rather than providing direct feedback or insights that would help improve the draft. It does not identify weaknesses or offer actionable suggestions."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests 'more experiments on different famous LLMs like LLaMA, Falcon, etc' and 'more experiments' but does not explicitly state how these experiments should be conducted or what specific aspects of the models or experiments need to be explored. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'experiments on T5, PaLM and GPT series LLMs' and 'benchmark score', indicating a clear reference to specific parts of the paper. However, the reviewer does not specify what aspects of these experiments need improvement or what specific changes should be made to the evaluation.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for more experiments rather than a critique or a request for justification of existing results.", "helpfulness_rationale": "The suggestion to conduct 'more experiments' on additional LLMs is a relevant and potentially helpful direction for the authors. However, it lacks specific details, making it less actionable and potentially less impactful."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the paper *does not describe* the hyperparameters used by each defense and *how* they are derived. This is an explicit statement of missing information. While the reviewer doesn't provide specific guidance on *what* to do, they clearly identify a gap in the paper's description. However, the reviewer doesn't specify *how* to derive the hyperparameters or what data is needed, making it only partially actionable.", "grounding_specificity_rationale": "The reviewer's statement is general and does not specify which defense the paper is referring to. They are making a broad claim about the paper's lack of information regarding hyperparameters. Therefore, the reviewer cannot identify a specific part of the paper being addressed, making it 1. The comment also does not specify what needs to be addressed in this part, so it is not specific.", "verifiability_rationale": "The reviewer makes a claim about the paper's content: 'The paper does not describe what hyperparameters are used by each defense nor how those hyperparameters are derived.' This is a statement of fact or deficiency. However, the reviewer does not provide any external references or logical reasoning within this review point to support their claim. The evidence would need to come from the authors when they investigate the paper themselves.", "helpfulness_rationale": "The reviewer's point is clear and identifies a significant omission in the paper's description of hyperparameters. They are directing the authors to a specific area where they need to improve their paper by looking for specific details about the hyperparameters and their derivation. While the reviewer doesn't provide a solution, they clearly point out a concrete area of improvement for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests exploring different pooling strategies, which implies a potential area for improvement. However, the suggestion is quite broad and lacks specific details on how to implement or evaluate these alternative pooling methods. The reviewer does not explicitly state what action the authors should take, such as trying max pooling or providing a concrete plan for experimentation. Therefore, while the suggestion points towards an action, it is not very specific or detailed, making it partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'tokens' in general, without specifying which section, table, figure, or unique aspect of the paper they are referring to. This lack of specificity makes it difficult for the authors to pinpoint the exact location of the issue being discussed. The reviewer does not provide any information that would allow the authors to identify a specific part of the paper being addressed. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer states that mean pooling is being used and suggests exploring other pooling strategies. This statement can be considered a claim that could be verified. The reviewer implies that the current approach (mean pooling) might have limitations or could be improved by exploring alternatives. While the reviewer doesn't provide specific examples or references to support this claim, the suggestion itself points towards a potential issue or area for improvement. Therefore, the claim is 3.", "helpfulness_rationale": "The reviewer suggests exploring different pooling strategies, which is a relevant and potentially helpful suggestion for the authors. Exploring alternative pooling methods could lead to improvements in their token representation or processing. However, the suggestion is quite general and lacks specific guidance on how to proceed. The reviewer doesn't provide concrete steps or datasets for the authors to experiment with. Therefore, while the suggestion is 3, it could be more impactful with more specific guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer is implicitly suggesting adding a column for GPU days to Table 3. While the action is not explicitly stated as 'add a column,' the reviewer implies a concrete action by mentioning 'real search cost' and 'GPU days'. The suggestion is clear and directly addresses the identified issue.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Table 3' and suggests using 'GPU days' as a metric. This demonstrates strong grounding as the specific part of the paper and the specific aspect being addressed are clearly identified.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. Instead, they are proposing a change in how search costs are reported. While this suggestion could be evaluated for its effectiveness, it doesn't inherently require external references or logical reasoning to be considered a valid point. However, it does suggest a concrete and potentially useful improvement, making it 3 in its potential impact.", "helpfulness_rationale": "The reviewer identifies a potential improvement to the presentation of search cost data by suggesting the inclusion of GPU days. This directly addresses a potential weakness in the current representation and offers a concrete suggestion for improvement, making it a helpful comment for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a missing element (training details) and asks a question (whether it's pretrained or trained on a specific dataset). While not explicitly stating an action, the question implies a desire for clarification on how the VQGAN was trained. This is an implicit action pointing towards seeking more information. The reviewer doesn't directly state *how* to implement the VQGAN, but they are asking for information that is crucial for understanding its training.", "grounding_specificity_rationale": "The reviewer names the VQGAN model and the 'Computer Vision Figures dataset' when asking about the training details. This provides a degree of grounding by specifying the model and the data involved in the training process. However, they don't explicitly state *where* in the paper these details should be found. The grounding is implicit through the mention of the model and dataset, but the connection to the missing training details isn't explicitly stated in the paper.", "verifiability_rationale": "The reviewer is not making a claim or assertion about the paper. They are asking a question: 'Specifically, I am wondering if the VQGAN is pretrained? Or only trained on the 88,635 images from the Computer Vision Figures dataset?' This is a request for information, not a statement that something is true or false. Therefore, it doesn't have verifiable components in the sense of supporting a claim.", "helpfulness_rationale": "The reviewer points out a missing training detail and asks a question about it. This is helpful because it highlights a potential gap in the information provided about the VQGAN. By asking whether it's pretrained or trained on a specific dataset, the reviewer is prompting the authors to consider the implications of these different training scenarios (e.g., potential biases from pretraining, the scope of the model's learning). This information, even in the form of a question, can guide the authors in their understanding and potentially lead to improvements in their work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the observation about 'minor improvements' regarding 'DualIS and DualDIS' on the 'MSVD dataset' in the context of 'crossmodel retrieval tasks'. This constitutes an explicit action, making it actionable. However, the action itself is vague as it doesn't specify *where* the minor improvements are located or *what* specifically changed.", "grounding_specificity_rationale": "The reviewer mentions 'DualIS and DualDIS' and 'MSVD dataset' as elements being addressed. This provides some grounding as the methods and dataset are named. However, the reviewer does not specify the exact section, table, or unique aspect of the paper being addressed. The mention of 'crossmodel retrieval tasks' is a general category, not a specific element. Therefore, the grounding is 2.", "verifiability_rationale": "The reviewer makes a claim about 'minor improvements' in the performance of 'DualIS and DualDIS' on the 'MSVD dataset'. This is a claim that needs to be supported. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to back up this claim. The statement is presented without any justification.", "helpfulness_rationale": "The reviewer points out a potential issue with the performance of 'DualIS and DualDIS' on the 'MSVD dataset' in the context of 'crossmodel retrieval tasks'. This observation is helpful as it highlights a limitation or area for improvement. However, the lack of specific details about *which* improvements are minor makes the feedback somewhat general and less helpful for pinpointing exact areas for change."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a limitation in the study's scope, specifically the lack of established relationships between top selected patches and the disease. While it points out a weakness, it doesn't explicitly instruct the authors on how to address this. The reviewer suggests focusing the study on these patches, which implies a specific action, but the comment itself doesn't detail the concrete steps to take. The reviewer is indicating a need for further investigation or a broader scope, rather than providing a direct, actionable solution within the current context.", "grounding_specificity_rationale": "The comment mentions 'top selected patches' as a specific area of the paper. However, it doesn't explicitly identify the section, table, figure, or unique element where these patches are discussed. The reviewer is pointing to a relevant part of the paper, but the exact location remains ambiguous. The comment is vague about the specific patches, making it not fully grounded.", "verifiability_rationale": "The comment states a fact: 'the relationship between the top selected patches and the disease is not yet established.' This is a claim that requires further investigation or evidence. However, the comment doesn't provide any logical reasoning, common knowledge, or external references to support this claim. It simply states the absence of a relationship without delving into why this might be the case or suggesting potential avenues for exploration. The claim is stated, but the supporting evidence is missing.", "helpfulness_rationale": "The comment identifies a valid limitation in the study's scope, specifically the lack of established relationships between top selected patches and the disease. This is a valuable piece of feedback for the authors as it highlights a direction for further research or a need to broaden the study's focus. The reviewer is pointing out a weakness in the current analysis, which can guide the authors in improving their draft by considering a wider range of patches. While the comment doesn't provide specific solutions, it identifies a meaningful area for improvement, making it 3."}
{"actionability_label": "Weakly Actionable", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The comment explicitly states a weakness ('the performance of FedSP is not the best'), but it doesn't provide specific guidance on *how* to address this weakness. The action is implied but not concretely stated.", "grounding_specificity_rationale": "The comment explicitly mentions 'FedSP' and 'Table 1' and 'Table 2', clearly identifying the specific part of the paper being discussed. This can be achieved through literal mentions of sections and tables.", "verifiability_rationale": "The comment contains a claim ('the performance of FedSP is not the best') but does not provide any justification or references to support this claim. It lacks logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The comment identifies a weakness in the paper ('the performance of FedSP is not the best') but does not provide any suggestions or guidance on how to improve the situation. It's a diagnosis without a prescription."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer requests a clearer definition of 'Omega' and points out the broad category of 'OMD' algorithms, indicating a lack of specificity in the current description. While the reviewer identifies a need for more information, the action to be taken (defining Omega) is clear. The vagueness lies in the lack of a direct statement and the ambiguity around 'OMD'.", "grounding_specificity_rationale": "The reviewer implicitly refers to the parameter 'Omega' and the algorithm 'OMD'. They can infer the relevance of sections discussing parameters and optimization algorithms, but the specific section or definition of 'Omega' is not explicitly mentioned. The mention of 'OMD' is a good start, but the lack of specificity regarding the link function and the reference to theorem 32 make it underspecified.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity regarding 'Omega', 'OMD', the link function, and the theoretical guarantee. This claim is somewhat supported by the reviewer's statement, but the paper could argue that the necessary information is present, just not clearly presented or linked. The lack of specific references weakens the verifiability.", "helpfulness_rationale": "The reviewer's comment directly points to a lack of clarity and specificity in the paper's description of key concepts. This is a valuable piece of feedback as it directly addresses areas where the authors might struggle to understand the paper. However, it lacks concrete suggestions for improvement, making it 3 but not fully constructive."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The statement is explicit about the current method (direct pixel learning) and suggests an alternative (Markovian state). It identifies a potential area for improvement by pointing out a limitation of the current approach. While it doesn't provide specific details on *how* to implement the change, it clearly states the desired outcome.", "grounding_specificity_rationale": "The reviewer explicitly names the type of model being criticized ('learned directly from pixels'). This is a clear and specific reference to a particular architectural choice or training paradigm. The mention of 'Markovian state' further clarifies the intended improvement or the core issue with the current method, providing a specific target for improvement.", "verifiability_rationale": "The statement is a claim about the models being 'learned directly from pixels without a Markovian state.' While it identifies a potential problem, it doesn't provide specific evidence or justification to support this claim. There's no reference to external works or logical reasoning to verify the statement. The 'how' is missing, making it difficult to assess the validity of the claim.", "helpfulness_rationale": "The review points out a potential improvement direction ('Markovian state'), which is helpful for guiding authors towards a specific area of research or a potential architectural change. However, it lacks specific details on *how* this improvement can be achieved or *why* direct pixel learning is problematic. The lack of verifiability makes it less actionable for the authors in terms of concrete steps."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their surprise and requests references, which is a clear action the authors could take to address the identified issue. The specificity of the request (nodewise vs. partwise Hamming distance) further clarifies the action.", "grounding_specificity_rationale": "The reviewer mentions 'Example 2' and the 'Hamming distance over entire parts of the sequence,' which allows them to identify the specific part of the paper being addressed. However, they do not explicitly state why they are surprised or what the implications are regarding the 'common' practice. The grounding is present, but the specificity of the issue is not fully detailed.", "verifiability_rationale": "The reviewer makes a claim by stating their surprise at the description of the Hamming distance usage as a 'common' practice. However, they do not provide any evidence or references to support this claim. The claim is stated, but it remains unverified.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors: 'point out some references.' This directly helps the authors improve their understanding and the clarity of their paper regarding CRF loss functions. The suggestion is specific and directly addresses the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer is suggesting a change in terminology ('Evaluation' to 'Metrics') and recommending the removal of specific sections. This is an actionable suggestion, as it proposes a concrete change to the paper or its presentation. The reviewer is indicating what they believe would be a more appropriate or clearer term and suggesting the sections containing these elements be removed. This is a direct action that the authors could take.", "grounding_specificity_rationale": "The reviewer is suggesting a change in terminology and the removal of sections. They are not explicitly pointing to a specific part of the paper or data element. The suggestion is about the *description* of the evaluation process and the *organization* of the paper. There is no specific section, table, or unique element being referenced in the suggestion itself.", "verifiability_rationale": "The reviewer is making a suggestion about terminology and the structure of the paper. This suggestion itself is not a claim that needs to be verified. It's a recommendation for improvement in how the work is presented. There is no explicit claim being made, nor is there any reference to external evidence to support the suggestion. It's a proposal, not a statement that requires logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer is suggesting a change in terminology and the removal of sections. While this could be helpful for improving the clarity and organization of the paper, it does not directly identify a weakness in the paper's content or offer a specific improvement to address a particular issue. The suggestion is about presentation rather than directly addressing the substance of the work. It lacks a clear connection to improving the core aspects of the research."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "2", "actionability_rationale": "The review points out a limitation or a missed opportunity. While it identifies a *problem* (inefficiency on GPU), it *doesn't* explicitly tell the authors *what* to do about it or *where* in their work this might be relevant. It's a statement of fact, not a directive.", "grounding_specificity_rationale": "The review uses the phrase \"work on pruning\" generally. It doesn't specify *which* pruning work or *which* part of the paper this is relevant to. The mention of \"GPU\" is a bit vague \u2013 is it about hardware, software, or algorithmic aspects? The review is broad.", "verifiability_rationale": "The review states a fact: \"As with most work on pruning, it is not yet possible to realize efficiency gains on GPU.\" This is a statement of observation based on the reviewer's experience or knowledge of the field. It's not making a definitive claim about the * authors' work specifically, but it's a wellsupported observation about the general field.", "helpfulness_rationale": "The review points out a limitation. While it's a valid observation about the current state of GPU pruning, it doesn't directly tell the authors *how* to improve their work. It highlights a potential bottleneck but doesn't offer specific solutions or directions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the limitations of the numerical evaluation and the comparison with 5. They use phrases like 'not fully convincing' and 'not completely fair,' indicating an awareness of the shortcomings. While they don't directly say 'I cannot apply this action,' the implication is that the identified limitations are actionable points for improvement in the evaluation process itself. The reviewer identifies a clear area for change or refinement.", "grounding_specificity_rationale": "The reviewer mentions 'numerical evaluation,' 'synthetic data,' and 'lack of knowledge of camera pose parameters.' While not a direct mention of a specific section or table, these phrases indicate a lack of precise identification of the specific aspect being criticized. The reviewer is pointing out limitations of the *evaluation setup* rather than pinpointing a specific part of the paper being evaluated. The reviewer provides some information about what is lacking, but it doesn't pinpoint a specific section, table, figure, or unique element.", "verifiability_rationale": "The reviewer makes claims about the 'numerical evaluation' and the 'comparison with 5 is not completely fair.' These are statements that require justification. The reviewer provides some justification by stating the limitations of the evaluation (synthetic data) and the nature of the comparison (5 is for a more complex problem). However, the reviewer's assessment of 'not fully convincing' and 'not completely fair' is somewhat subjective and lacks strong, explicit references to external sources or logical reasoning beyond the stated limitations. While the reasons are provided, the overall judgment is based on the perceived impact of these limitations.", "helpfulness_rationale": "The reviewer concludes that the review point is '1' because it doesn't identify meaningful weaknesses or suggest improvements. The reviewer points to the limitations of the evaluation and the unfair comparison with 5 as the reasons for this lack of helpfulness. While the reviewer identifies areas for improvement in the evaluation process, they don't offer concrete, actionable feedback on the *original paper* being evaluated. The criticism of the evaluation itself doesn't directly translate to actionable feedback for the authors of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a question and suggests an experiment. This is an explicit action. While the action itself is vague and lacks detail on how to apply it, the intent is clear.", "grounding_specificity_rationale": "The reviewer refers to \"numbers of bits in logits\" and \"PGD attack,\" which are specific concepts within the paper. While they don't explicitly name the section, table, or unique aspect, the intent is clear. The comment specifies what needs to be addressed.", "verifiability_rationale": "The reviewer does not make a claim. They are suggesting an experiment and asking a question. The language is about what *should* happen, not what *is* the case.", "helpfulness_rationale": "The reviewer is suggesting an experiment to strengthen the paper. This could be helpful for the authors in understanding the robustness of their method. It's not *required* to improve the paper, but it adds value. Therefore, it's 3 because it offers a suggestion, even if it's not a direct fix."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"The meta solvers seem to be centralized controllers\" and suggests clarification. This points to a lack of clarity in the paper's description of related concepts. The reviewer also provides a concrete example (Foester et al., 2016), which makes the suggestion actionable.", "grounding_specificity_rationale": "The reviewer doesn't explicitly name a specific section or part of the paper they are referring to. They use general terms like \"meta solvers\" and \"centralized RL.\" While they *imply* a connection to the methods or related work section, the exact location isn't pinpointed. The example they provide is also a general citation.", "verifiability_rationale": "The reviewer makes a claim: \"The meta solvers seem to be centralized controllers.\" However, they do not provide any evidence or references within the review point itself to support this claim. The verifiability depends on the reader's ability to find the relevant sections in the paper and understand the difference. The reviewer's suggestion to look at Foester et al., 2016, is an attempt to provide context but doesn't constitute a direct verification within the review point.", "helpfulness_rationale": "The reviewer's point highlights a potential lack of clarity in the paper's description of related work. If the authors indeed have a confusion about the relationship between \"meta solvers\" and \"centralized RL,\" this review point could be very helpful for them. It points to a specific area where their understanding might be lacking."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "5 (5)", "actionability_rationale": "The reviewer explicitly states their understanding of M_T and points out a potential ambiguity in its relation to probabilities of atomic events. While the reviewer doesn't provide a direct action, they clearly identify a potential area for clarification, which is a form of actionable feedback.", "grounding_specificity_rationale": "The reviewer mentions 'M_T' and 'probabilities of atomic events' but doesn't explicitly state which specific part of the paper they are referring to. While they identify a concept that might be unclear, they don't pinpoint the exact location or element causing the confusion, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer doesn't present a claim that requires verification. They are suggesting an improvement (adding an explanation and examples) rather than critiquing something as correct or incorrect. Therefore, it fits the 'X' category (X).", "helpfulness_rationale": "The reviewer directly points out a potential confusion for the authors (ambiguity in M_T's definition) and offers a constructive suggestion (adding an explanation and examples). This is a clear attempt to improve the authors' understanding and is therefore 5."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer is asking a question, which implies an implicit request for an action or clarification. However, the specifics of what needs to be detected and how they differ are not explicitly stated. The action itself (asking a question) is implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 2', which grounds the comment to a specific part of the paper. However, the explanation regarding the difference between detecting both entities and just the long one is not specific to the elements within Figure 2. The grounding is present, but the explanation lacks specificity within that context.", "verifiability_rationale": "The reviewer is asking a question, not making a claim that needs verification. Therefore, there is X to be verified.", "helpfulness_rationale": "The reviewer is asking a question, which could be helpful if the answer is clear and concise. However, the question is vague and doesn't provide immediate actionable feedback. The helpfulness is limited because the question itself isn't a direct suggestion or critique."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review points out a specific inconsistency in the paper's claim about the upper bound of Theorem 1 when considering a node with 0 neighbors. It directly asks for an explanation of this exception, providing a clear action for the authors to take.", "grounding_specificity_rationale": "The review explicitly mentions \"Theorem 1\" and the specific issue related to a \"node with 0 neighbors,\" indicating high grounding specificity.", "verifiability_rationale": "The review presents a claim (the theorem's upper bound is incorrect in this case) and attempts to verify it by pointing out a logical inconsistency. While it doesn't provide external references, it offers a clear logical argument.", "helpfulness_rationale": "The review is highly specific and directly addresses a potential flaw in the paper's logic. It guides the authors to reexamine their assumptions and potentially refine their theorem. This is very helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out a lack of *deeper analysis* and *solutions* regarding the detection of GPTgenerated rumors. While the reviewer suggests exploring *why* GPTgenerated rumors are as difficult to detect as natural rumors, the review doesn't explicitly state that the original paper lacks any actionable feedback. The reviewer's suggestion is more of a call for further investigation rather than a direct actionable item.", "grounding_specificity_rationale": "The reviewer's comment doesn't explicitly identify a *specific* section, table, or figure where the paper discusses the difficulty of detecting GPTgenerated rumors. While the reviewer mentions the difficulty of detecting both natural and artificial rumors, the lack of a clear *explanation* of *why* GPTgenerated rumors are closer to natural ones is evident. The reviewer's question about this specific aspect suggests a lack of grounding in the paper's discussion.", "verifiability_rationale": "The reviewer makes a claim: 'There is no analysis of why GPTgenerated Rumor is closer to Natural Rumor...'. This claim is not wellsupported by the provided text. The reviewer states a finding without providing evidence or reasoning. The experimental result that natural rumors are easiest to detect is presented as a given, not as a point requiring further investigation or explanation within the paper itself.", "helpfulness_rationale": "The reviewer's comment is critical and points out a lack of deeper analysis. While it identifies a problem, it doesn't offer a concrete solution or suggestion for improvement. It's more of a pointer to an area for improvement rather than a direct helpful suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment states 'The technical contribution is limited' and 'the contents of Section 4 are not about a formal and principled solution, but most about heuristics.' While it identifies the nature of the limitation, it doesn't explicitly state what needs to be changed or improved in Section 4. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The comment explicitly mentions 'Section 4' as the specific part of the paper being addressed. It also clearly identifies the issue as 'not a formal and principled solution, but most about heuristics' within that section. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification using logical reasoning, common knowledge, or external references. It is a statement of observation about the paper's content.", "helpfulness_rationale": "The comment identifies a limitation in the paper's technical contribution and specifically points to Section 4. This provides valuable feedback to the authors, guiding them to focus on a specific area and consider its rigor, even if a direct solution isn't offered."}
{"actionability_label": "4", "grounding_specificity_label": "4: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their desire to *explore other probability mass functions* in MixBoost. This is a clear and actionable suggestion. While the reviewer doesn't provide a specific alternative PMF, they do suggest considering *various* PMFs, which indicates a concrete action the authors can take. The reviewer's point is directly translated into a concrete action the authors can take.", "grounding_specificity_rationale": "The reviewer explicitly identifies a specific area within MixBoost where improvement could be made: the probability mass function (PMF). They also point out a specific parameterization used (quasiuniform). This demonstrates strong grounding. The reviewer isn't just saying 'the method is a bit limited'; they're pinpointing a specific aspect. Furthermore, the reviewer suggests *exploring other distributions*, which adds to the specificity of the feedback. The reviewer also hints at a potential refinement by suggesting considering various PMFs for different depths, which further specifies the area for improvement.", "verifiability_rationale": "The review point does not contain a claim in the sense of proposing a new method or a different approach. It's more of a suggestion for improvement. Therefore, it's difficult to assess verifiability in the traditional sense. It's more about *what* improvement could be made rather than *why* the current approach is flawed (with supporting evidence).", "helpfulness_rationale": "The review point is constructive and points towards a specific area for improvement. The reviewer suggests exploring different probability mass functions, which is a concrete experiment the authors can conduct. While the review doesn't propose a complete solution, it identifies a limitation and suggests a direction for future work. The reviewer's point is more about guiding the authors towards a specific experiment rather than providing a definitive answer. Therefore, it is helpful but not as '5' as a suggestion with a clear proposed solution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggestion. It raises a question about the fairness of comparing models based on abstention rates, but does not propose a concrete step to address this issue. The reviewer is critiquing the comparison method rather than offering a direct improvement.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or model where grounding is lacking. It is a general comment about the behavior of ChatGPT in terms of abstention rates and its impact on model comparison. There is no specific section, table, or figure mentioned, nor is there a clear indication of a missing element within a referenced part.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a question about the fairness of comparing model accuracies based on different abstention rates, not a statement that needs to be supported by evidence or references. The comment is about the methodology of the comparison, not a specific assertion about the paper.", "helpfulness_rationale": "The review point raises a valid concern about the fairness of comparing ChatGPT's accuracy to other models due to its higher abstention rate. This provides the authors with information to consider when evaluating model performance and highlights a potential limitation in directly comparing models with different behaviors. While it doesn't offer a solution, it does point out a potential flaw in the comparison methodology, making it 3 in identifying a potential issue."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "High", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states 'Missing references: the references below are relevant...' and names a specific paper. This is an explicit action identifying a deficiency. The suggestion to 'please discuss connections with a' is a concrete action outlining how the missing reference should be addressed.", "grounding_specificity_rationale": "The reviewer names a specific paper (a Samulowitz & Memisevic, 2008) and explains why it is relevant ('relevant to your topic, especially a. Please discuss connections with a, which uses supervised learning in QBF solving, where QBF generalizes SMT'). This demonstrates full grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim that the submitted work's topic is relevant to QBF solving and that the specific paper is relevant and should be discussed. The reviewer provides a justification for this claim by stating the relevance to supervised learning in QBF solving, where QBF generalizes SMT. This justification, while phrased as a request, provides a clear basis for verification.", "helpfulness_rationale": "The reviewer directly addresses a potential weakness (missing relevant references) and provides a clear direction for improvement (discuss connections with the cited paper). This is a 5 and constructive suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a problem: 'a monotonic relationship is imposed' and suggests a solution: 'the ensemble engenders a subspace that explicitly encodes tradeoffs and results in a continuous parameterization of the Pareto Front. Whether the mono tonic relationship can be replaced by other relationships?'. This clearly indicates an actionable suggestion with a concrete goal. The reviewer also provides a relevant citation, further emphasizing the actionable nature of the point.", "grounding_specificity_rationale": "The reviewer refers to 'a specific part of the paper' (the method section describing the monotonic relationship) and uses technical terms like 'degree of a singletask predictor participation' and 'weight of the corresponding task loss'. This indicates that the reviewer has identified a specific area within the paper and has used relevant terminology to describe the issue. The grounding is explicit and specific.", "verifiability_rationale": "The reviewer does not make a claim or assertion. They are suggesting an exploration or alternative to an existing method. Therefore, there is X to be verified. The statement 'Explaining this point may be better' is a suggestion for improvement, not a claim requiring justification or evidence.", "helpfulness_rationale": "The reviewer provides a clear motivation for their suggestion: 'it limits the flexibility of the ensemble'. They also provide a relevant citation, 1Navon A, Shamsian A, Fetaya E, et al. Learning the Pareto Front with HypernetworksC//International Conference on Learning Representations. 2020., which is directly related to the topic. This suggests a genuine desire to improve the understanding and application of the method, making the review helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer asks a question about the privacypreserving aspect of the approach and provides a specific example (traffic signals) to illustrate their concern. While the question is clear and the example is specific, the reviewer does not offer any concrete suggestions or guidance on how to address the privacy issue or the potential problem with the traffic signal application. The action is implied (identifying a potential weakness), but the lack of explicit guidance makes it less actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'privacypreserving aspect of the approach' and uses the 'traffic signal control' example to ground their concern. This demonstrates a clear identification of the specific part of the paper and a unique reference point, making it fully grounded.", "verifiability_rationale": "The reviewer presents a claim that the traffic signal application might be a poor example due to privacy concerns. However, they do not provide any evidence, references, or logical reasoning to support this claim. The statement is presented as a suggestion or observation without any backing.", "helpfulness_rationale": "The reviewer raises a valid concern about the applicability of federated learning to a specific traffic signal scenario. However, they do not offer any concrete suggestions, information, or analysis to address this concern. They are pointing out a potential issue without providing any actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem ('The hyperlink... do not seem to work') but does not explicitly state how the author should go about fixing it. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The comment mentions 'footnote 3 and 4,' which grounds the issue in specific parts of the paper. However, it does not specify *what* is wrong with the hyperlink within those footnotes, making it somewhat underspecific.", "verifiability_rationale": "The comment is a statement of observation ('The hyperlink... do not seem to work') rather than a claim that requires verification. It describes a problem without offering a solution or justification.", "helpfulness_rationale": "The comment points the author towards the location of the problem (the footnotes). While it doesn't provide a solution, it directs the author to the relevant section, making it 3 in identifying an issue."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"I suggest to revise a bit the discussion, especially in the modeling section...\" and then provides specific examples of what needs improvement: \"better formalization of the architecture,\" \"clarify the architecture,\" and questions about \"Label Embeddings are external parameters\" and the figure's depiction of \"Label Embeddings are the output of the encoder.\" These explicit suggestions and specific examples indicate a clear action the authors should take.", "grounding_specificity_rationale": "The reviewer clearly identifies the area of the paper needing improvement: \"modeling section...in its current form is not clear enough.\" They even provide a slightly more specific description: \"discussion, which in its current form is not clear enough.\" Furthermore, they offer specific questions and clarifications regarding the content of this section, such as \"Label Embeddings are external parameters\" and the figure's depiction of \"Label Embeddings are the output of the encoder.\" This demonstrates a high level of specificity in pinpointing the issue.", "verifiability_rationale": "The reviewer makes a claim about the state of the modeling section: \"in its current form is not clear enough.\" They then provide suggestions and questions to address this issue, such as \"better formalization of the architecture\" and clarifying the role of \"Label Embeddings.\" While the reviewer doesn't provide a definitive solution, they offer a clear direction for improvement and even points to a potential visual aid (the figure) that might be misleading. The claim is supported by the suggestions and questions, making it 3.", "helpfulness_rationale": "The reviewer directly addresses a specific area of the paper that needs improvement: the modeling section. They provide concrete suggestions for improvement, such as \"better formalization of the architecture\" and clarifying the role of \"Label Embeddings.\" They also point out a potential visual aid (the figure) that might be misleading. This targeted and constructive feedback is directly aimed at helping the authors improve their draft, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the section description is unclear and points to the final paragraph as the solution. This suggests an implicit suggestion to start the section with the clearer explanation. While not a direct instruction, the reviewer identifies the problem (unclear description) and implies the desired action (start with the clearer explanation). Therefore, it can be considered explicit. The reviewer also identifies the specific part of the section where the clarification is needed (the final paragraph), making it concrete.", "grounding_specificity_rationale": "The reviewer refers to 'the section' and 'the final paragraph'. While they can identify the section where the issue lies, they don't explicitly name the subsection or the specific topic within the section. However, they clearly identify the specific part of that section (the final paragraph) where the clarification is needed. Therefore, it can be considered partially grounded and specific.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for improvement, not a statement of fact that needs to be supported by evidence. Therefore, it falls under 'X'.", "helpfulness_rationale": "The reviewer directly points to the specific location within the section where the clarification is needed. This is a very direct and actionable suggestion. It clearly identifies a weakness and provides a clear path for improvement. Therefore, it is 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a limitation ('It seems like the model is limited to CTC loss') and suggests an alternative ('would it be possible to train them towards attention based encdec training?'). This is a direct and clear indication of a desire for improvement, making it 5. The reviewer proposes a specific direction for change, which the authors could readily consider.", "grounding_specificity_rationale": "The reviewer's comment is a general observation about the training methodology and does not explicitly identify a specific part of the paper or methodology being addressed. While the suggestion is relevant, the lack of pinpointing makes it weakly grounded. The reviewer doesn't mention any specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer presents a suggestion ('would it be possible to train them towards attention based encdec training?') but does not provide any specific evidence, examples, or references to support their claim about the CTC loss being a limitation. The question is openended and lacks justification. The reviewer is making a suggestion without providing sufficient context or reasoning.", "helpfulness_rationale": "The reviewer asks a direct question about an alternative training method, which is relevant to the training process and could guide the authors' development. The question is clear and encourages a 'yes' or 'no' answer, making it actionable. While subjective, the question is specific to a potential limitation and suggests a concrete improvement, making it potentially 5 if the authors consider it."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the attack methods are 'naive' and suggests 'random token addition' and 'universal adversarial suffix' as alternatives. While the reviewer points out a potential limitation in the chosen methods, the suggestion of 'other classical attack methods in NLP' is more of a suggestion for improvement rather than a direct instruction on what to implement. The reviewer doesn't specify which aspects of the attack methods are lacking, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer criticizes the 'paper,' 'classification tasks,' and the 'toy setting' in the context of the attack methods. However, the reviewer does not explicitly identify a specific part of the paper being addressed. The criticism is general and applies broadly to the experimental setup. While the reviewer mentions specific elements like 'classification tasks' and 'toy setting,' they don't pinpoint a specific section, table, or unique aspect of the paper. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer states that the attack methods are 'naive' and suggests 'random token addition' and 'universal adversarial suffix' as alternatives. The reviewer *does* make a claim by stating the current methods are 'naive' and implying the alternatives are better. However, the reviewer does not provide any justification or supporting evidence for why the current methods are naive or why the suggested alternatives are superior. The claim is presented without sufficient reasoning or references.", "helpfulness_rationale": "The reviewer criticizes the 'paper,' 'classification tasks,' and the 'toy setting' in the context of the attack methods. While the reviewer identifies a potential weakness in the experimental setup, they do not provide a clear next step for the authors. The reviewer suggests considering 'other classical attack methods in NLP' but does not explicitly state what the authors should do next. The criticism is about the methodology, and while it's a valid point, the lack of a concrete recommendation makes it less immediately helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that 'mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality...'. This is an explicit statement of a problem. However, the reviewer does not specify how to address this issue or what changes are needed. The action is identified, but the implementation is vague. Therefore, the action is explicit, but the subsequent steps are not clearly defined.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'image generation capabilities of diffusion models' as the area affected by the mitigation methods. This clearly identifies the specific part of the paper being addressed, indicating full grounding. However, the reviewer does not specify *what* aspects of these capabilities are affected (e.g., sharpness, detail, artifacts) or *how* the mitigation methods are expected to impact them. The issue is identified, but the specifics are underspecified.", "verifiability_rationale": "The reviewer makes a claim that 'mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality...'. This is a claim that needs to be supported. However, the reviewer does not provide any evidence, reasoning, or references to back up this statement. The claim is presented without sufficient justification.", "helpfulness_rationale": "The reviewer points out a potential negative impact of mitigation methods on image quality. While this identifies a problem, the review lacks specific suggestions or guidance on how to mitigate this issue. The reviewer states the problem but doesn't offer actionable steps or insights into potential solutions. The feedback is present but lacks concrete improvement suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point is not explicit or actionable. The reviewer states their observation ('I am a bit surprised that the function words dominate the content ones in a Japanese sentence') but does not provide a concrete action or suggestion for the authors. The reviewer's surprise indicates a lack of clarity or understanding, but it doesn't translate into a specific, actionable improvement for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'Figure 1' in their review point, indicating they are referring to a specific part of the paper. However, the explanation is vague, focusing on the general observation about function and content words without specifying the exact issue within Figure 1 or why this observation is relevant to that specific part.", "verifiability_rationale": "The reviewer makes a claim ('I am a bit surprised that the function words dominate the content ones in a Japanese sentence') but does not provide any justification or evidence for this claim. They express surprise but do not explain why they believe this is the case or offer any suggestions for the authors.", "helpfulness_rationale": "The review point is not particularly helpful. While the reviewer points out a potential issue (the dominance of function words), they do not provide any concrete advice or actionable steps for the authors. The lack of grounding specificity and the absence of justification make it difficult for the authors to understand the problem and how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their suggestion and the reason for it, making the action clear. The suggestion is also concrete, specifying the change from average to minimum kmeans objective across multiple seeds. There is no ambiguity about what action the reviewer is proposing.", "grounding_specificity_rationale": "The reviewer directly addresses the calculation of the baseline kmeans objective. They mention 'multiple seeds' and the 'minimal kmeans objective,' which are specific details. They also reference existing literature (1 Jin, Chi, et al. and 2 Fr\u00e4nti, Pasi, and Sami Sieranoja) that discusses the properties of kmeans and the impact of multiple seeds. This demonstrates a clear understanding of the relevant aspects of the calculation.", "verifiability_rationale": "The reviewer makes a claim that the current baseline is 'more reasonable' and provides a justification based on the properties of the average and minimum kmeans objectives. They also reference existing literature that supports these properties. The reasoning is logical and the claim is supported by the provided references, even though I cannot directly verify the references. The reviewer's statement is verifiable based on the understanding of kmeans clustering and its sensitivity to initialization and multiple runs.", "helpfulness_rationale": "The reviewer's suggestion is directly aimed at improving the baseline calculation. It provides a clear alternative (minimum objective) and a reason for it ('more reasonable'). This actionable feedback is directly relevant to the authors' evaluation process and would help them understand the baseline better. The suggestion is specific and addresses a potential weakness in the current approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer raises a specific point about the relationship between temperature and uncertainty calibration, which directly suggests a concrete action: clarifying the order of operations and the role of the regularization term H. This makes the suggestion actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions the regularization term H (lines 155160) and refers to specific sections (lines 133136) when discussing the motivation. This indicates a clear identification of the relevant part of the paper and the specific issue being addressed, making the grounding fully specific.", "verifiability_rationale": "The reviewer raises a concern about the regularization term H reducing confidence, which contradicts the stated motivation. While the paper mentions H as a regularization term, the reviewer's point about it making predictions more confident is a valid question that requires further justification or clarification. The connection between H and overconfidence isn't explicitly explained or justified, making the claim somewhat underspecific.", "helpfulness_rationale": "The reviewer's questions and confusion are directly aimed at improving the paper. While the suggestions are valid points for discussion, the lack of clear justification or explanation for the potential contradiction with the motivation makes the feedback less impactful. The suggestions are 3 but require further clarification to be fully beneficial."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'Important reference missing' and names the specific paper 'Lista'. This is a clear and actionable item for the authors to address. The authors can directly identify the missing part and take action to include it in their work.", "grounding_specificity_rationale": "The review point explicitly mentions the missing paper 'Lista' by name. This is a strong form of grounding as the authors can directly identify the specific section or paper being addressed. The comment also provides a clear reason for the missing reference, stating the importance of discussing the relationship and differences with 'Lista'.", "verifiability_rationale": "The review point contains a claim that a 'important reference missing' and that this reference, 'Lista', is crucial for contextualizing the work. The reviewer provides reasoning for this claim by stating the importance of discussing the similarities and differences with 'Lista' and placing the work in the appropriate context. This provides sufficient justification for the claim.", "helpfulness_rationale": "The review point is 5 as it directly identifies a crucial missing piece of information (a citation) and explains why it is important. The authors can directly address this by including the 'Lista' paper and discussing its relevance to their work. The explicit mention of the missing reference and the stated importance make this a very actionable and constructive comment."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for an intuitive explanation of the objective and constraints in the linear program (3) of Theorem 3. This is a direct and clear request for information, making the action explicit. The reviewer also states the desired outcome, which is to understand the objective and constraints concretely, making the action concrete. Therefore, the review point is 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Theorem 3' and specifically asks about the 'objective' and 'constraints' in '(3)'. This indicates a clear identification of the specific part of the paper being addressed. The reviewer can accurately pinpoint the section and the specific components they are interested in. Therefore, the grounding is fully specific. The reviewer can confidently determine which part of the paper and what needs to be addressed within that part.", "verifiability_rationale": "The reviewer's statement that 'this is a main theorem' implies they understand the theorem's importance. However, the reviewer's request itself is a claim that the paper lacks an intuitive explanation of the objective and constraints. While the reviewer's prior understanding is relevant, the request itself is a clear claim that the paper doesn't provide this information. Therefore, the verifiability is 3 as the reviewer's claim is based on their perception of the paper's lack of explanation, which is verifiable through reading the paper. The expectation is that the reviewer would be able to understand the LP *after reading the review*.", "helpfulness_rationale": "The reviewer explicitly states that the request 'would help the reader a lot'. This is a clear claim with a positive expectation of the impact of the review. The reviewer anticipates a significant improvement in their understanding of the linear program after reading the review. Therefore, the review point is 5."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out a *possibility* and asks a question about Algorithm 2. While it identifies a potential feature, it doesn't explicitly * tell the authors how to implement it or what changes to make. The criticism about 'avg' not being used and the unclear meaning of j' and i' are suggestions for improvement, not direct actionable steps for the authors.", "grounding_specificity_rationale": "The review refers to \"Algorithm 2\" generally. It doesn't specify *which* part of Algorithm 2 is problematic or what specific lines or operations are being questioned. The variables 'j'' and 'i'' are mentioned, but their connection to specific parts of the algorithm isn't made explicit.", "verifiability_rationale": "The review states a *possibility* and asks a question. It doesn't make a claim about what *should* be in Algorithm 2 or provide evidence to support this possibility. The criticism is presented as a suggestion for improvement rather than a claim requiring justification.", "helpfulness_rationale": "The review identifies a potential improvement area and asks a question about a specific algorithm. While it points towards a potential enhancement, it doesn't provide concrete steps or evidence to support why this improvement is necessary or beneficial. The lack of clarity around Algorithm 2 makes it difficult for the authors to act on this suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review points out 'missing details' in 'related work', 'experiments', and 'writing'. While the *location* of the missing information is specific, the *exact nature* of the missing details is not explicitly stated. The reviewer implies adding details, but the action is not fully concrete.", "grounding_specificity_rationale": "The review mentions 'related work', 'experiments', and 'writing' as areas needing improvement. This indicates that the reviewer can identify the specific parts of the paper being addressed, making the grounding strong. However, the specific *element* within each section that is missing details is not always clearly defined. For example, 'missing details in related work' is a general statement.", "verifiability_rationale": "The review states that the paper is 'not polished and not ready to publish, with missing details'. This is a claim. However, the reviewer does not provide any specific evidence or reasoning to support this claim. They suggest improvements but do not logically connect the criticism to the need for improvement.", "helpfulness_rationale": "The review identifies areas where the paper needs improvement, such as 'related work', 'experiments', and 'writing'. While this points to specific areas for the authors to focus, the criticism is somewhat general and lacks specific details about what is missing or why it is unpolished. The suggestions are to add missing details, which is helpful but lacks the depth of a more constructive critique."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific observation (accuracy drop) in relation to Figure 5 and asks a question prompting further analysis. This directly addresses a potential weakness in the results presented in the figure and suggests an area for improvement by investigating the cause of the drop. The action is explicit (pointing out the drop) and concrete (mentioning Figure 5).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 5' as the part of the paper being addressed. This is a literal mention, indicating full grounding. They also ask a question about the content of the figure, further specifying the area of concern.", "verifiability_rationale": "The reviewer poses a question about a potential cause (overfitting) for the observed accuracy drop. While they don't provide definitive evidence or references at this point, the question itself is a form of engagement with the material and a suggestion for further investigation, making it 3. There's no logical reasoning or external references provided at this stage.", "helpfulness_rationale": "The reviewer's comment is helpful because it points out a potential issue (accuracy drop) in the results presented in Figure 5 and encourages the authors to investigate the cause. This highlights a potential area for improvement in their analysis and helps them focus their attention on a specific aspect of their work. While it doesn't provide a solution, it identifies a weakness and a direction for further exploration."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential issue with the experimental setup (missing ablation studies) and suggests a specific experiment (scratchGAN) as a solution. While the reviewer doesn't explicitly state the *action* of conducting the scratchGAN experiment, the suggestion implies it. The weakness lies in not providing a clear rationale for *why* scratchGAN is a suitable choice or how it directly addresses the identified issue. The reviewer also doesn't specify the *details* of the scratchGAN experiment, making it somewhat vague on how to apply it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'scratchGAN' as a method and suggests it as a specific experiment to address the missing ablation studies. This clearly identifies a specific part of the paper (the ablation studies) and specifies what needs to be addressed (the performance of scratchGAN).", "verifiability_rationale": "The reviewer states that 'some natural ablation studies are missing' and suggests 'how does scratchGAN do if you *do* pretrain?' as a suggestion for an experiment. This constitutes a claim that something is missing and that a specific experiment would address it. The suggestion of scratchGAN and the idea of a pretraining baseline provide a basis for further investigation and verification, although the reviewer doesn't provide detailed reasoning or extensive references to support this claim.", "helpfulness_rationale": "The reviewer's point is clear: pointing out missing ablation studies and suggesting a specific experiment (scratchGAN) to address it. This is a valuable piece of feedback for the authors. It directly addresses a potential weakness in their experimental design and provides a concrete direction for further experimentation. The reviewer's suggestion is actionable and directly addresses a potential issue."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states the change in evaluation methodology for SI 6.5 compared to Mnih et al. 7 and clearly identifies the key difference: the removal of 'human starts'. This makes the action explicit. The authors know exactly what needs to be understood about the evaluation process.", "grounding_specificity_rationale": "The comment explicitly mentions 'SI 6.5' and 'Mnih et al. 7' and clearly states the difference in the evaluation methodology. The authors can easily identify the specific part of the paper and the comparison being made. This is fully grounded.", "verifiability_rationale": "The comment presents a factual statement about a change in the evaluation methodology. It doesn't require external references or complex reasoning to understand. The statement is clear and directly addresses the difference between the current work and the cited paper.", "helpfulness_rationale": "While the comment provides information about a change in evaluation methodology, it doesn't directly guide the authors on how to improve their draft. It informs them about a potential difference in results if they were to compare with Mnih et al. 7, but it doesn't offer actionable steps to enhance their current work. The information is factual but lacks direct practical guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point is a statement that criticizes the absence of a metric. While it identifies a deficiency, it doesn't explicitly tell the authors what to do or how to implement a solution. The action is implicit in pointing out a missing element.", "grounding_specificity_rationale": "The reviewer criticizes the absence of efficiency metrics, which relates to a specific aspect of the paper (efficiency). However, the exact metric or section where this should be reported is not explicitly named, making the grounding somewhat weak.", "verifiability_rationale": "The review point contains a claim that 'the paper does not report any metric that shows it is more efficient to train with this proposed method.' This claim is not supported by any evidence or reasoning within the paper being reviewed. The reviewer is stating a deficiency without providing justification or examples.", "helpfulness_rationale": "The review point is helpful in that it points out a specific weakness in the paper (the lack of efficiency metrics) and critiques the authors' claim about efficiency. This helps the authors identify a missing piece of information and potentially improve their method's efficiency claims. While it doesn't offer a solution, it guides the authors to relevant areas."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point states a limitation of the method (poor performance on general reasoning) compared to math reasoning. This doesn't directly tell the authors *what to do*. It's a statement of a problem, not a prescription for improvement. The authors need to know *what's wrong* but not necessarily *how to fix it* in this specific review.", "grounding_specificity_rationale": "The review point mentions \"general reasoning tasks\" and \"mathematic reasoning.\" While it *mentions* specific areas, the *comparison* between them is the key. The reviewer is pointing out a difference in performance between these two types of reasoning, but they don't explicitly identify a specific part of the paper, method, or experiment where this poor performance is most evident. It's a general statement about the method's effectiveness across different reasoning types, not a precise pinpointing of an issue within a specific section or table.", "verifiability_rationale": "The review point is a statement of a fact: \"The method does not work very effectively on general reasoning tasks compared with mathematic reasoning.\" There is X being made that requires verification. Verifiability applies when a claim is made and supported by evidence. This is a descriptive statement, not a claim that needs to be proven.", "helpfulness_rationale": "The review point identifies a limitation of the method (poor performance on general reasoning). While this information is relevant, it doesn't directly suggest improvements or actionable steps for the authors. It points out a weakness, but doesn't offer a direction for the authors to improve their method based on this feedback."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests using LiDARbased segmentation as an alternative to object detection for the downstream task. While they imply a specific action (switching the task), the exact *how* to implement this change and adapt the current model for segmentation is not explicitly stated. The suggestion is present, but the action is somewhat implicit.", "grounding_specificity_rationale": "The reviewer mentions 'LiDARbased segmentation' and 'KITTI and Waymo' by name. This demonstrates a clear identification of the specific aspect (the alternative task and the relevant benchmarks) being addressed. The mention of specific terms and benchmarks indicates strong grounding specificity.", "verifiability_rationale": "The reviewer critiques colorizationbased pretraining, stating it might not be the best choice for object detection, particularly for benchmarks using IoUbased metrics. They argue that object detection requires accurate locations and poses. While they make a claim about the potential benefits of segmentation, they do not provide specific examples or references to support these claims within the context of *their* current model and pretraining. The reasoning is present, but lacks concrete evidence to fully verify the claims.", "helpfulness_rationale": "The reviewer provides a clear critique of the chosen downstream task (object detection) and the potential limitations of colorizationbased pretraining for it, especially in the context of IoUbased metrics. They offer a specific alternative (LiDARbased segmentation) and explain *why* they believe it would be beneficial. This provides valuable feedback to the authors, suggesting a different direction for their work. While the suggestion is not fully detailed, it is a concrete direction and addresses a specific concern."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states a potential contradiction between the objective of Eq (12) and the IPO principle, which can be interpreted as an explicit action. However, it doesn't specify the exact location or nature of the contradiction within Eq (12), making the action somewhat vague. The authors are encouraged to investigate this further, but the current comment doesn't provide concrete steps.", "grounding_specificity_rationale": "The comment refers to 'Eq (12)' generally, indicating a potential area of concern. While it identifies a specific equation, it doesn't pinpoint the exact part of the equation, a specific section in the paper, or a unique element within Eq (12) that is causing the issue. Therefore, while it identifies a potential area, the grounding is somewhat weak.", "verifiability_rationale": "The comment contains a claim: 'the objective of Eq (12) seems to be in contradiction with IPO.' However, it does not provide any evidence, justification, or references to support this claim. It is presented as a statement of concern without further explanation or logical reasoning. Therefore, the claim is 1.", "helpfulness_rationale": "The comment raises a valid concern about a potential contradiction between the objective of Eq (12) and the IPO principle. However, it does not offer any specific suggestions or guidance on how to address this issue. The authors are left with a potentially important problem without any concrete steps to investigate or resolve it. Therefore, the helpfulness is minimal."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a concern about the assumption regarding DINO embeddings, which can be considered an explicit action or suggestion. However, the suggestion is more of a question prompting further investigation rather than a direct instruction on how to improve the draft. The lack of a concrete, actionable step makes it less actionable.", "grounding_specificity_rationale": "The reviewer directly mentions 'DINO representations' and distinguishes between geometrically distinctive concepts and concepts where class label correlates more with semantics. This clearly identifies the specific part of the paper being addressed and specifies the issue, making it 5.", "verifiability_rationale": "The reviewer raises a question about whether DINO capacity holds for semantic concepts but does not provide any evidence, justification, or references to support this claim. The statement is framed as a question rather than a definitive assertion, and there are no logical reasoning or external references provided to verify the claim.", "helpfulness_rationale": "The reviewer's point is relevant to the limitations of the proposed method (adaptation capacity). However, the feedback is primarily a question prompting further analysis rather than a direct critique or solution. While it highlights a potential area for improvement, it doesn't offer immediate, actionable guidance for the authors on how to address the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a potential issue: 'using $p$ to denote the phase mixing probability and the dummy variable in the inner loop in Phase 2 might be confusing.' This directly points to a lack of clarity in the notation. The reviewer proposes a concrete action: 'use different symbols for these two distinct purposes.' This action is clear and directly addresses the identified issue, making it 5.", "grounding_specificity_rationale": "The reviewer specifically points out a problem within the 'Algorithm 1' section of the paper. They identify two specific variables ('phase mixing probability' and 'dummy variable in the inner loop') within that section. This demonstrates a strong grounding as the reviewer can accurately pinpoint the relevant part of the paper and the specific elements causing the confusion. The comment specifies what needs to be addressed in this part.", "verifiability_rationale": "The reviewer makes a claim: 'using $p$ to denote the phase mixing probability and the dummy variable in the inner loop in Phase 2 might be confusing.' This claim is supported by the potential for ambiguity in using the same symbol for two different purposes. While the reviewer doesn't provide a detailed explanation of *why* this confusion might arise, the *potential* for confusion is plausible. The suggestion to use different symbols is a verifiable action that would address this potential issue. Therefore, the claim is 3 as it is supported by a plausible scenario, and the suggestion is concrete.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'use different symbols for these two distinct purposes.' This directly addresses a potential problem the authors might face when implementing Algorithm 1. The suggestion is concrete and provides a clear path for improvement. Therefore, the review point is 5 as it directly provides a solution to a potential issue."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "Not Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests a mathematical formulation *in the appendix* and *depicting the WiC task* in the *figure*. While these are suggestions for improvement, they are not explicitly stated as actions to be taken immediately. The reviewer implies directions for action rather than providing concrete steps. Therefore, the review is actionable but not fully explicit or concrete.", "grounding_specificity_rationale": "The reviewer does not explicitly identify a specific part of the paper (e.g., a section, table, figure) that they are addressing. Instead, they refer to the *highlevel description* and the *figure* in general. This indicates that the reviewer can identify the areas where improvement is needed, but cannot precisely pinpoint the exact element within the paper being discussed. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes claims about the lack of detail in the *highlevel description* and the confusion of the *figure*. However, they do not provide external references or logical reasoning to *support* these claims. The claims are presented as observations or suggestions for improvement, but without evidence. Therefore, the claims are not verifiable.", "helpfulness_rationale": "The reviewer provides clear suggestions for improvement, specifically suggesting a *mathematical formulation* in the *appendix* and *depicting the WiC task* in the *figure*. These suggestions are directly aimed at addressing the authors' needs and provide concrete directions for how to improve their work. The reviewer's comments are actionable and directly relevant to the paper's content. Therefore, the review is 5."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies the need for additional benchmarking tasks but does not specify how to implement this action. It lacks concrete steps or guidance on which tasks to include or how to integrate them.", "grounding_specificity_rationale": "The review point is very general and does not refer to a specific part of the paper. It makes a broad suggestion without pinpointing the exact area that needs improvement.", "verifiability_rationale": "The review point is a suggestion, not a declarative statement that requires verification. It does not contain a claim that needs to be supported by evidence.", "helpfulness_rationale": "The suggestion to include additional benchmarking tasks is relevant and generally beneficial for the thoroughness and validation of the work. However, the lack of specifics makes it less immediately actionable, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the discrepancy between the abstract and the text regarding the proposal distribution. It points out that the abstract implies a global upper bound while the text clarifies it's 'everywhere' an upper bound. This is an explicit action that guides the authors to reexamine the abstract.", "grounding_specificity_rationale": "The comment refers to the 'abstract' and the concept of 'upper bounding the target' in the 'text' or 'main part of the paper'. While it doesn't provide a literal section number, it clearly identifies the specific part of the paper where the issue lies. This is strong grounding as it pinpoints the area of concern. It also specifies what is wrong (proposal distribution not everywhere an upper bound).", "verifiability_rationale": "The comment contains a claim: 'In the abstract the authors require the proposal distribution to upper bound the target everywhere which is not true as the authors themselves clarify in the text.' This claim is wellsupported by the reviewer's statement that the authors clarify it's 'everywhere' an upper bound, providing a clear contrast and highlighting the potential for misunderstanding. The reasoning is direct and the reference to the authors' clarification makes the verifiability high.", "helpfulness_rationale": "The comment is 5 as it directly points out a potential source of confusion for the authors. It highlights a discrepancy between the abstract and the main text, guiding the authors to the specific location and nature of the clarification provided in the text. This helps the authors understand and correct a potential misunderstanding quickly."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer asks for clarification on the optimality of the policy gradient method in Eq. 6 and its relation to the overall objective in Eq. 5. While the reviewer doesn't explicitly state an action to be taken, the questions implicitly prompt the authors to consider the theoretical properties of the method and its convergence guarantees. The reviewer is asking a question that could lead to an actionable step if the authors find the method's optimality questionable and need to verify it or consider alternatives. Therefore, it can be considered an implicit action, but not a direct instruction.", "grounding_specificity_rationale": "The reviewer directly refers to 'Eq. 6' and 'Eq. 5', making the target of their question very specific. They also refer to 'Line 132' and 'd\u03c0(s)', further grounding the criticism. The reviewer is not just mentioning these elements but is asking a question about the relationship between the method described in Eq. 6 and the overall objective defined in Eq. 5. This demonstrates a clear understanding of the specific parts of the paper being discussed. Therefore, the grounding is both explicit and specific.", "verifiability_rationale": "The reviewer poses a question about the optimality of the policy gradient method in Eq. 6 in relation to the objective in Eq. 5. While the reviewer doesn't explicitly claim that the method is incorrect or that the objective cannot be achieved, the question itself implies a potential issue or a need for verification. The reviewer is asking a question that could be interpreted as a claim requiring justification. The verifiability depends on the authors' ability to independently verify the optimality claim through logical reasoning, common knowledge, or external references. Therefore, it is 2 as the claim is not explicitly stated but implied through the question.", "helpfulness_rationale": "The reviewer's questions directly address a potential area of concern for the authors \u2013 the optimality of the policy gradient method used in their work. The questions are clear and directly relate to the method's theoretical properties and its connection to the overall objective. By addressing these questions, the authors can gain a better understanding of the method's limitations and potentially make improvements to their approach. The suggestions are actionable in the sense that they prompt the authors to investigate or reconsider their method. Therefore, the review point is 5 in guiding the authors towards a more thorough understanding and potential improvement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "6: X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'freeze the partitioning in the first iteration.' It also identifies a potential issue: 'risky choice' and 'strong assumptions.' This makes it actionable. While it doesn't directly imply the action, it clearly states it, making it somewhat explicit. The action is specific, making it somewhat concrete. The comment provides a clear direction for the authors to consider, making it somewhat direct.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper (e.g., a line number or a section). It is a general comment about a methodological choice. Therefore, it is 1.", "verifiability_rationale": "The comment itself is not a claim that needs verification. It is a suggestion for further analysis and consideration of assumptions. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The comment provides a specific suggestion for improvement: 'at least discuss the limitations of this.' This is a clear and actionable piece of feedback that empowers the authors to consider a more robust approach. It is helpful because it guides them towards a more thorough analysis of their initial data coverage. The suggestion is specific and directly related to the identified issue."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out a lack of clarity regarding the overall approach and its benefits, but does not explicitly state a specific action or suggestion that the authors should take. They identify a problem (lack of understanding) but do not propose a solution or improvement strategy. Therefore, while the reviewer highlights a gap in the explanation, they do not provide actionable feedback.", "grounding_specificity_rationale": "The reviewer refers to 'the approach' and 'the paper' generally, without specifying a particular section, table, or unique element within the paper. This indicates a lack of precise identification of the area being addressed, which is a key component of grounding specificity. The reviewer does not mention any specific part of the paper or a unique aspect that they believe needs improvement.", "verifiability_rationale": "The reviewer states a concern about the paper's structure and clarity but does not make a specific claim that can be verified. They express a worry about the paper getting too technical too quickly without explaining the overall approach and why it's a good idea. While they identify a potential issue, they do not provide a claim that is supported by logical reasoning, common knowledge, or external references. The statement is more of a feeling or concern rather than a verifiable claim.", "helpfulness_rationale": "The reviewer identifies a significant lack of clarity in the paper and expresses a concern about the overall approach. While the feedback points to a valid issue, it does not offer any specific suggestions or improvements. The reviewer is essentially pointing out a problem without providing a constructive solution. Therefore, the feedback is not particularly helpful in guiding the authors towards improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action (using link prediction accuracy) but lacks detail on how to implement the inference (why not average?).", "grounding_specificity_rationale": "The paper explicitly mentions the section number (590) where the decision is made, and the issue is the choice of accuracy metric for early stopping. The authors can accurately pinpoint the section and the specific issue being addressed.", "verifiability_rationale": "The comment presents a claim (the authors should explain this) that could be partially verifiable if the paper *does* explain the reasoning, or 1 if it doesn't. The paper does not explicitly state why only link prediction accuracy was used for early stopping, nor does it provide examples of why a combined metric was not used.", "helpfulness_rationale": "The comment directly addresses a potential weakness in the paper's methodology by questioning the justification for using only link prediction accuracy for early stopping. While the paper might have implicitly addressed this, the reviewer's explicit question is still valuable for improving clarity and understanding."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "Medium", "helpfulness_label": "Medium", "actionability_rationale": "The review point explicitly asks for 'concrete details' on how to set up a classimbalanced task in a fewshot learning setting. This directly addresses a potential area of confusion for the author and provides a clear direction for their thought process. The request for 'concrete details' implies a desire for specific guidance, making it actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'classimbalanced task' within the context of 'fewshot learning.' This demonstrates a clear understanding of the relevant section of the paper. The request for 'concrete details' further emphasizes the need for specific guidance, indicating high grounding specificity.", "verifiability_rationale": "The reviewer is asking for a method or procedure to set up the task. While there isn't a single 'right' answer, the request implies a desire for wellreasoned and practical advice. This could be supported by examples or common strategies, making it '4'. It's not definitively '1' because the concepts of fewshot learning and class imbalance exist, and the request implies an expectation of explanation.", "helpfulness_rationale": "The review point directly addresses a potential area of confusion for the author regarding the implementation of classimbalanced tasks in a fewshot learning setting. By asking for 'concrete details,' the reviewer is prompting the author to clarify a specific aspect of their methodology. This has the potential to be very helpful as it encourages the author to elaborate on their approach and potentially identify issues or areas for improvement. While the request for 'concrete details' doesn't guarantee actionable feedback, it does create a scenario where the author could provide valuable information."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "None of the claims in the review point provide explicit and concrete actions for the authors. The reviewer states that the ChatGPT baseline is 'rudimentary' and that 'fewshot approach isn\u2019t tested,' but these are general statements about the baseline and experimental setup. The suggestion to 'include the discourse relation information in the prompts (probably in a ChainofThought style approach) might yield good results' is a recommendation for future work, not a specific action for the authors to take based on this review. The reviewer's opinion that this is 'extraneous' to the paper's line of evaluation further indicates a lack of actionable feedback.", "grounding_specificity_rationale": "The review point does not explicitly ground the comments in specific parts of the paper. The reviewer refers to the 'ChatGPT baseline,' 'fewshot approach,' and 'discourse relation information' but does not specify which section, table, figure, or unique aspect of the paper these relate to. While the concepts mentioned are specific, the lack of a clear reference point makes the comments weakly grounded.", "verifiability_rationale": "The review point contains one claim that is verifiable: 'fewshot approach isn\u2019t tested.' This can be verified by examining the experimental setup described in the paper. However, the other statements are either opinions or subjective assessments. The suggestion to 'include the discourse relation information in the prompts (probably in a ChainofThought style approach) might yield good results' is a recommendation based on common practices, but it's not a claim that can be directly verified with evidence from the paper. The statements about the ChatGPT baseline being 'rudimentary' are subjective and lack specific evidence to support or refute them.", "helpfulness_rationale": "The review point does not provide specific, actionable feedback that would help the authors improve their draft. The reviewer's comments are more about pointing out limitations of the baseline and suggesting future research directions rather than offering concrete suggestions for improvement. The statement that 'this will only add to the paper\u2019s evaluation' is an opinion, not a helpful suggestion. The lack of specific actions or concrete recommendations makes the review point not helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper 'first estimates a layer's sensitivity by pruning ...' but does not provide details on how the pruning was actually performed. This implies that the method used for pruning is not clearly defined, making the action somewhat implicit. While the action of estimating sensitivity by pruning is stated, the lack of detail on the pruning process makes it vague. The reviewer is asking 'how' the pruning was done, indicating that the method is not concretely described.", "grounding_specificity_rationale": "The reviewer mentions 'lines 238239' and refers to the method of 'pruning ...' This indicates that the reviewer can identify the specific section or part of the paper being addressed. The comment explicitly refers to a specific method used in the paper. Therefore, the grounding is fully grounded. However, the comment does not specify what needs to be addressed in this part, which is the lack of detail on the pruning method. Therefore, it is underspecific.", "verifiability_rationale": "The reviewer states 'we first estimate a layer's sensitivity by pruning ...' but does not provide any justification or evidence for this claim. There are no external references or logical reasoning provided to support the claim that pruning accurately reflects sensitivity. The comment does not specify what needs to be addressed in this part, which is the lack of detail on the pruning method. Therefore, the claim is not supported by any evidence, making it 1.", "helpfulness_rationale": "The reviewer clearly identifies a lack of detail in the paper regarding the method used to estimate sensitivity. They specifically ask 'how actual pruning was done' and 'how the ground truth of sensitivity is achieved'. This directly points out a potential weakness in the methodology and provides a concrete suggestion for improvement. The reviewer is providing actionable feedback that directly addresses a missing piece of information, making it 5 for the authors to understand and replicate the process."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem: 'The results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10), ideally with errorbars.' They also provide concrete suggestions: 'mean over many runs' and 'error bars'. This clearly indicates an explicit action that the authors can take to improve their draft.", "grounding_specificity_rationale": "The reviewer refers to a specific experiment: 'the results comparing standard vs. evolutional dropout on shallow models'. This clearly identifies a specific part of the paper. Furthermore, they explain *why* this part needs improvement: 'potentially subject to significant fluctuations'. They also specify *how* the authors should improve it: 'mean over many runs (at least 10), ideally with errorbars'. This shows a high level of specificity in identifying the issue and suggesting the solution.", "verifiability_rationale": "The reviewer makes a claim: 'The results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10), ideally with errorbars.' However, they do not provide any justification or reasoning for why this is a good suggestion. They simply state the recommended statistical practice without explaining its benefits or providing supporting evidence. This indicates a lack of verifiability as the claim is not supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer identifies a valid issue in the experimental methodology: the lack of statistical rigor in presenting the results. They suggest improvements that are relevant to the authors, such as using mean over many runs and error bars. While the reviewer doesn't explicitly explain *why* these improvements are necessary or beneficial, they do suggest concrete actions that could enhance the reliability and interpretability of the results. Therefore, the feedback is 3 as it points towards a meaningful change in the experimental procedure."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a lack of understanding of a paragraph and provides a potential alternative algorithm (Gittins). While the suggestion of considering Gittins is a potential action, the primary issue highlighted is the lack of clarity in the existing paragraph. The vagueness of the explanation regarding the dashed lines makes it difficult to act upon that specific part. Therefore, while the reviewer identifies a problem, the lack of a clear, actionable step based on the identified problem makes it not fully actionable.", "grounding_specificity_rationale": "The reviewer's comment is not fully grounded as they do not explicitly identify the specific paragraph that is unclear. They use a general term 'this paragraph'. However, they *do* identify specific elements within the paper that need clarification: 'the figure' and 'dashed lines'. These specific elements demonstrate a degree of grounding specificity.", "verifiability_rationale": "The reviewer makes claims about the paragraph being unclear and the explanation of dashed lines being vague. These claims could potentially be supported by referencing the lack of detail in the paragraph and the lack of a clear definition for 'dashed lines'. However, the reviewer does not provide specific examples or references to external sources to support these claims. Therefore, while the claims are potentially verifiable, the lack of supporting evidence makes it only partially verifiable.", "helpfulness_rationale": "The reviewer provides specific examples of areas for improvement, such as the clarity of a paragraph and the understanding of a figure. They also point out a lack of specificity in an explanation. These points directly address potential weaknesses in the paper and suggest concrete ways to improve it. While the suggestions could be more detailed, they are clear and actionable, making the review helpful in guiding the authors towards improvements."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the suggestion to 'mention the evaluation metric' and its benefit for clarity. This is a direct and explicit action. The reviewer also specifies the term 'Fmeasure scores (LF1) (including ROOT arcs)' from a cited paper, providing concrete details on which metric is being referenced. The reviewer's intention is clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly states 'For clarity, it would be better if the evaluation metric is mentioned here'. This directly identifies the specific part of the paper being addressed, which is the evaluation section. The reviewer is not inferring what needs to be clarified. The suggestion is also quite specific, mentioning 'evaluation metric' generally, but could be more specific. However, the grounding is clear.", "verifiability_rationale": "The reviewer makes a claim that 'mentioning the evaluation metric will improve clarity'. This is a statement of opinion or judgment. While the reviewer suggests the metric *could* improve clarity, they do not provide any specific evidence or references to support this claim. The claim is presented as a suggestion or expectation rather than a wellsupported statement. Therefore, it is not 5.", "helpfulness_rationale": "The reviewer provides a suggestion for improvement by recommending the inclusion of an evaluation metric and explaining its potential benefit for clarity. This is a direct and actionable suggestion. The reviewer also names a specific metric, making the suggestion concrete. While the suggestion itself might not be universally 'helpful' in all contexts (e.g., if the paper is already clear), the *review* point provides a concrete and actionable suggestion for improvement, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point is a question prompting further investigation rather than a direct instruction on how to modify the draft. It does not explicitly state what the authors should do or how to apply it.", "grounding_specificity_rationale": "The review point is a general question about the performance of DVP on video with different lengths. It does not explicitly refer to a specific part of the paper, section, table, figure, or unique element. The authors would need to infer the relevance of this question to their work.", "verifiability_rationale": "The review point is a question, not a claim that requires verification. It does not present a statement that needs to be supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point raises a relevant question about the performance of DVP on video with different lengths. While it doesn't directly provide actionable feedback on how to improve the draft, it prompts the authors to consider an aspect of their work that might require further investigation or experimentation. It encourages them to think critically about their results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the KLdivergence term is ignored in equation (3) within Section 3.3. The reviewer then suggests evaluating this approximation error by calculating the KLdivergence and checking if it approaches zero. This is an explicit action that is also concrete, as the authors know exactly how to implement it: calculate the KLdivergence and check its value.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3.3' and 'equation (3)' in their review point. This is a literal mention, indicating strong grounding. Furthermore, the reviewer specifies the *what* \u2013 the KLdivergence term \u2013 and the *how* \u2013 calculate and check if it approaches zero. This level of detail makes the grounding highly specific.", "verifiability_rationale": "The review point contains a claim: 'The proposed training objective has ignored the KLdivergence term in equation (3)'. This is a clear statement that requires justification. The reviewer then provides a method for verification: 'Can you evaluate such approximation error, ie. calculate the actual KLdivergence and check whether it indeed approaches zero? Experiments:'. This provides a logical reasoning (the KLdivergence should approach zero if ignored), common knowledge (it's a standard component in some training objectives), and external references (the suggestion to calculate it provides a concrete example). The reasoning is clear and the method is welldefined.", "helpfulness_rationale": "The review point identifies a specific potential issue (omission of the KLdivergence term) and provides a clear and actionable suggestion for investigation. The reviewer's request to 'evaluate such approximation error, ie. calculate the actual KLdivergence and check whether it indeed approaches zero? Experiments:' is a constructive and likely to be helpful suggestion for the authors. It directly addresses a potential weakness and provides a concrete direction for improvement. The reviewer is likely to gain valuable insights from this feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question and suggests a potential area of discussion. While it implies an action (further discussion), it doesn't explicitly state what needs to be done or how to approach it. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer mentions 'specular areas' without explicitly stating which part of the paper they are referring to. While the concept of specular areas is clear, the specific section or element being addressed is not precisely identified. The grounding is present in the general area but lacks specific identification of a section, table, figure, or unique aspect.", "verifiability_rationale": "The review point contains a suggestion ('Would be interesting to further discuss') and a question ('which situations...'). While it could be interpreted as a claim that further analysis of specular areas is needed, it lacks specific evidence or references to support this suggestion. The claim is present but not wellsupported.", "helpfulness_rationale": "The review point suggests further discussion of 'specular areas' as a potentially interesting direction. While this points towards a potential improvement or area for further exploration, it doesn't explicitly identify a weakness in the current draft or provide a concrete action item. The suggestion is relevant but lacks the directness and specificity of a fully helpful comment."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states that 'It is unclear what the major contributions of the paper are' and 'Analyzing previous work does not constitute as a contribution'. While the reviewer identifies a potential area for improvement (clarifying contributions), the criticism itself is not explicit about the *action* to be taken. The reviewer points out a lack of clarity, but doesn't explicitly state what the authors should do to address this. The second part of the criticism, that analyzing previous work isn't a contribution, is implied but not explicitly stated as a requirement for the authors to follow. Therefore, the criticism lacks a clear, direct instruction on how the authors should improve their draft based on this feedback.", "grounding_specificity_rationale": "The review point states 'It is unclear what the major contributions of the paper are'. This statement is general and does not specify *which* part of the paper the contributions are unclear. The reviewer does not identify a specific section, table, figure, or unique element of the paper where the lack of clarity is evident. Therefore, the reviewer cannot pinpoint the exact location of the issue, making the grounding weak. While the reviewer identifies a problem, they do not specify *what* is unclear within that area.", "verifiability_rationale": "The review point contains the claim 'Analyzing previous work does not constitute as a contribution'. This claim is presented without any supporting evidence or justification within the review point itself. The reviewer offers a general statement and a counterargument, but does not provide examples, references, or logical reasoning to back up this claim. Therefore, the claim is not wellsupported by the provided text.", "helpfulness_rationale": "The review point is a general critique about the paper's contributions and a specific criticism of analyzing previous work as a contribution. While it raises a valid concern, it does not provide specific, actionable feedback that would directly guide the authors on how to improve their draft. The reviewer's statement is a highlevel observation rather than a concrete suggestion for improvement. The lack of specific guidance makes the review less helpful in directly addressing the authors' needs."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing definition of n_t in Algorithm 2 and the unclear meaning of 'appropriate number' in line 225. This provides clear, actionable feedback for the authors to improve their draft.", "grounding_specificity_rationale": "The reviewer directly points to Algorithm 2 and line 225, indicating a precise location where information is lacking. They also specify what is missing (how to determine n_t) and why it's unclear (what 'appropriate number' means), making the grounding very specific.", "verifiability_rationale": "The reviewer does not make a claim in the review point itself. They are pointing out a deficiency in the information provided in the original text. While the reviewer's suggestion to clarify these points can be seen as a form of implicit critique, the direct feedback is about filling in missing information rather than critiquing existing content. Therefore, it's not 5 as a claim.", "helpfulness_rationale": "The reviewer provides very specific and actionable feedback by pointing out the missing definition of n_t in Algorithm 2 and the lack of clarity regarding 'appropriate number' in line 225. This directly helps the authors identify areas for improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out a *lack of support* for a claim made in the paper. It states the claim ('\"in practice the mixing time is even better\") and then criticizes the *experiments* as insufficient support. It *doesn't* directly tell the authors what to do. It highlights a problem. While the action is implicit (implying the need to improve experiments), the specific action (how to improve) is not explicitly stated. Therefore, it's 2.", "grounding_specificity_rationale": "The review refers to \"the claims that \"in practice the mixing time is even better\". This clearly points to a specific claim made in the paper. The reviewer is criticizing this specific claim. The review explicitly mentions the claim, making it clear which part of the paper is being addressed. While it doesn't pinpoint the exact location of the claim within the paper (e.g., \"in the experimental results section, paragraph 3\"), it clearly identifies the *content* of the claim. Therefore, it's 3.", "verifiability_rationale": "The review states that the *experiments* are \"insufficiently supported by the experiments\". It criticizes the lack of empirical evidence. The review contains a claim (\"the evidence provided to practitioners is very limited\") that is not supported by any specific evidence, logical reasoning, or external references within the review point itself. The support for the claim is vague and lacks detail. Therefore, it's 1.", "helpfulness_rationale": "The review criticizes the lack of support for a claim. It doesn't directly tell the authors how to improve their experiments or what evidence they should use. It highlights a potential weakness. While it points out a problem, it doesn't offer concrete solutions or actionable steps for the authors to take. Therefore, it's 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests a specific change: 'Could we extend the protected feature A to a vector form? For instance, A represents multiple attributes.' This is a direct suggestion for a concrete modification to how the feature 'A' is represented.", "grounding_specificity_rationale": "The reviewer introduces 'A' as a 'protected feature' and suggests representing it as a 'vector'. While the suggestion is specific, the reviewer does not explicitly refer to a specific section, table, figure, or unique element of the paper when introducing 'A'. The connection is implied but not explicitly stated.", "verifiability_rationale": "The review point is a question and a suggestion for change: 'Could we extend the protected feature A to a vector form? For instance, A represents multiple attributes.' It does not make a claim that requires verification or justification.", "helpfulness_rationale": "The review point directly addresses a potential improvement to the paper by suggesting a vector representation for a feature. This is a concrete and actionable suggestion that could be beneficial for the authors if they are considering how to represent their data. While it's a question, it clearly points towards a specific change."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the lack of clarity in the notation (x and t as vector representations) and asks specific questions about L2normalization and the similarity metric used (cosine or dotproduct). These are direct and actionable suggestions for the authors to improve their understanding and implementation of the method.", "grounding_specificity_rationale": "The reviewer directly references 'x and t in this equation (and following ones)' which clearly identifies the specific part of the paper being addressed. They also specify *what* is missing (vector representations) and *why* it's important for understanding the equation. This strong reference to a specific part of the paper demonstrates high grounding specificity.", "verifiability_rationale": "The reviewer makes a claim that the paper's explanation of the equation is lacking and that the authors need more information. This claim is wellsupported by logical reasoning (understanding the equation requires clarity on notation and implementation details) and by providing specific examples of what is missing (normalization, similarity metric). The reviewer also suggests concrete actions the authors can take to address these issues, making the verifiability high.", "helpfulness_rationale": "The reviewer's comment is 5 because it directly addresses specific areas where the authors are likely to be confused or stuck. They provide clear suggestions for the authors to take action, such as looking for notation clarifications, checking normalization, and experimenting with similarity metrics. The questions are not idle but are requests for information that will improve the authors' understanding of the method."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states their belief that the proposed transductive method is not very novel and connects it to selftraining methods in semisupervised learning. This is a direct and clear statement, making it actionable for the authors to investigate the relationship between the two methods.", "grounding_specificity_rationale": "The reviewer mentions 'selftraining methods in semisupervised learning' as a point of comparison. This grounds the discussion by linking the proposed method to a specific area of related work. However, they do not specify a particular aspect of their method that they believe is similar to selftraining, making it only weakly grounded in terms of specific details within that area.", "verifiability_rationale": "The reviewer states their belief about the novelty of the method without providing any supporting evidence or reasoning. They do not offer any specific examples or references to back up their claim. Therefore, the claim is not verifiable based on the provided text.", "helpfulness_rationale": "The reviewer's comment is a statement of opinion rather than a constructive suggestion. They are pointing out a potential weakness in the method but are not offering a specific direction or solution for the authors to explore. This makes the comment less helpful in terms of providing actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out a 'feature comparison with prior work' but doesn't explicitly state what needs to be compared or how. The comparison is described as 'shallow', indicating a lack of detail. While the action of comparing is implied, it's not a direct instruction, making it implicit. The vagueness of 'shallow' means the specific steps or aspects missing are not detailed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'two relevant papers' when discussing the feature comparison. This directly identifies the specific part of the paper being addressed, fulfilling the 'grounding' criteria. However, the reviewer does not specify *what* is lacking in the comparison with these papers. The comment focuses on the *existence* of the shallow comparison rather than detailing its specifics.", "verifiability_rationale": "The reviewer states that the 'feature comparison with prior work is shallow' and mentions 'two relevant papers'. This constitutes a claim about the quality of the existing comparison. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. There is no evidence presented to back up the assertion that the comparison is indeed shallow.", "helpfulness_rationale": "The reviewer identifies a weakness in the paper: the 'feature comparison with prior work' is shallow and misses two relevant papers. However, the reviewer does not offer any specific suggestions or guidance on how the authors should improve this comparison. The comment points out a problem but doesn't provide actionable advice on how to solve it."}
{"actionability_label": "4", "grounding_specificity_label": "3: 4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly points out the use of the word \"equivalent\" at specific line numbers. This directly identifies a potential issue or area for improvement in the authors' writing. The reviewer's suggestion to be more cautious implies a clear action the authors should take.", "grounding_specificity_rationale": "The review point explicitly names the lines (8, 56, 70, 93) where the word \"equivalent\" is used. This directly identifies the specific part of the paper being addressed. While it doesn't specify *why* the usage of \"equivalent\" at these lines is problematic or what needs to be verified, it clearly pinpoints the locations.", "verifiability_rationale": "The review point itself doesn't contain a claim in the sense of stating an opinion or judgment. However, it implicitly suggests a request for clarification or verification regarding the use of \"equivalent.\" The reviewer's suggestion to be cautious implies a need for further justification or verification. Without a direct claim, we look at if the point is supported by reasoning, common knowledge, or external references. In this case, the point is based on observation and the reviewer's interpretation of cautiousness, making it wellsupported.", "helpfulness_rationale": "The review point directly identifies a potential issue with the use of a specific word at specific locations in the paper. This provides clear feedback to the authors and suggests a concrete action they should take (doublechecking their use of \"equivalent\"). This feedback is directly actionable and relevant to improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer identifies a problem (lack of understanding) and points out a specific issue (the dominance of the paraphrase similarity view). While they don't explicitly state what needs to be done, they clearly express a desire for more clarity on the other views. This indicates a lack of explicit action, making it 3 but not fully explicit.", "grounding_specificity_rationale": "The reviewer mentions 'the effectiveness of the multiview clustering approach' and specifically highlights the 'paraphrase similarity view'. They also provide an 'empirical example of how the different views help in clustering paraphrases of the word 'slip''. This demonstrates a clear attempt to pinpoint the relevant part of the paper. However, the reviewer doesn't explicitly state which section or table refers to the multiview clustering approach, making it only partially grounded.", "verifiability_rationale": "The reviewer makes a claim about the dominance of one view and the lack of analysis on the usefulness of other views. They state that 'almost all across the board, the paraphrase similarity view does significantly better than other views and their combination'. This is a verifiable claim. However, the reviewer doesn't provide specific examples of how the other views are used or why they are less effective, making the verifiability somewhat lacking in detail and references.", "helpfulness_rationale": "The reviewer's primary statement is a problem: 'I don't understand effectiveness of the multiview clustering approach'. They then offer a specific example: 'Almost all across the board, the paraphrase similarity view does significantly better than other views and their combination'. While this example provides some context, the reviewer doesn't offer any actionable steps or insights on how to improve the understanding or effectiveness of the other views. The review primarily expresses a lack of information rather than providing helpful suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the architecture is not clearly explained, which implies an implicit action. While the reviewer identifies a lack of explanation, they don't specify what is unclear or how to improve the explanation. This makes the action implicit and vague.", "grounding_specificity_rationale": "The reviewer states the architecture is not clearly explained and that the paper is not selfcontained. This implies the reviewer can identify the missing information (the architecture details are missing) but cannot pinpoint the exact section or element of the paper where this information is lacking. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim that the paper is not selfcontained due to the lack of explanation of the architecture. However, the reviewer does not provide any specific examples or references to support this claim within the context of *this paper*. The reference to Jiang et al. (2019) is a general suggestion, not a specific instance of missing information within this paper. Therefore, the claim is not wellsupported.", "helpfulness_rationale": "The reviewer clearly identifies a significant issue: the lack of explanation for the architecture. This directly impacts the authors' ability to understand and potentially replicate their work. While the reviewer doesn't offer specific suggestions for improvement, the identification of this problem is valuable and directly actionable for the authors. The action to take is to seek a clearer explanation of the architecture."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly names 'BertScore' and 'BLEURT' and suggests a solution to the inconsistency by proposing standardization. This directly points to an actionable step the authors should take.", "grounding_specificity_rationale": "The comment explicitly mentions 'BertScore' and 'BLEURT', identifying the specific metrics involved. However, it does not specify the exact section, table, or figure where this inconsistency occurs, making the grounding somewhat weak. The suggestion to standardize is also somewhat specific in that it doesn't point to a particular type of standardization, but it's clear in its intent.", "verifiability_rationale": "The comment itself does not contain a claim in the sense of presenting an opinion or assertion about the paper's quality. However, the suggestion to standardize the naming is a practical and actionable suggestion that can be verified by checking the paper for instances of 'BertScore' and 'BLEURT'. The reasoning behind the suggestion (consistency is generally desirable) is logical and common sense, making it 3.", "helpfulness_rationale": "The comment identifies a specific, albeit minor, issue (inconsistent naming of metrics) and provides a clear and actionable suggestion (standardize the naming). This directly empowers the authors to improve their draft by addressing this specific inconsistency."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that 'some aspects in the presentation quality of this paper are a weakness' and then lists specific elements like 'Figs 1&2', 'tables with a \"\"', and 'Fig 3 and Table 2'. These are concrete actions the authors should take to improve their paper. The reviewer is not inferring these actions but directly pointing out areas for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific parts of the paper, such as 'Figs 1&2', 'tables with a \"\"', and 'Fig 3 and Table 2'. This strong identification of specific elements demonstrates high grounding specificity. Furthermore, the reviewer explains *why* these elements are problematic, such as the meaning of the \"*\" in Table 1, providing clear details on what needs to be addressed in these parts.", "verifiability_rationale": "The reviewer states that 'some aspects in the presentation quality of this paper are a weakness'. This is a claim that the authors can verify by examining the figures, tables, and the 'Dataset' column. While the reviewer doesn't provide specific evidence *within the review point itself*, the act of the authors identifying these issues implies a belief that they are weaknesses, which can be supported or not supported by external references or logical reasoning. Therefore, it is verifiable but lacks explicit justification within the review point.", "helpfulness_rationale": "The reviewer provides a clear and actionable comment that directly helps the authors improve their paper. They identify specific areas like 'Figs 1&2', 'tables with a \"\"', and 'Fig 3 and Table 2' and explain *why* these are weaknesses. This directly empowers the authors to make concrete changes to their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the *information axis tool* and *related experiments* as areas for further investigation, making it 5 for the authors to explore.", "grounding_specificity_rationale": "The review point mentions the *information axis tool* but doesn't explicitly identify a specific section, table, or figure in the paper where this tool is discussed, making it weakly grounded. While the reviewer is *curious* about *related experiments*, they are not directly referencing a specific part of the paper.", "verifiability_rationale": "The review point itself doesn't contain a claim that needs verification. It's a suggestion for further investigation, which isn't a claim.", "helpfulness_rationale": "The review point suggests exploring *related experiments*, which is a relevant and potentially helpful suggestion for the authors to consider, even though it's not a direct action. While it doesn't provide a specific action, it points towards a valuable area of exploration."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the writing style of the original comment, stating 'It would be difficult for readers to understand and evaluate,' but does not explicitly state the action or improvement the authors should take. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The review point explicitly refers to 'the text in line 293295' and suggests 'manually observed' the examples, demonstrating full grounding. However, it does not specify what is unclear or how the observation helps, making it underspecific.", "verifiability_rationale": "The review point contains a claim that 'It would be difficult for readers to understand and evaluate the results.' However, it does not provide any supporting evidence, reasoning, or external references to back up this claim.", "helpfulness_rationale": "The review point identifies a potential issue with the clarity of writing in a specific section. However, it lacks specific guidance on how the authors should improve their understanding of that section, making it less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out that the proofs are 'extremely not well organized' and 'many proofs do not have clean logic and are very hard to follow.' While this identifies a problem, it doesn't explicitly tell the authors *how* to improve the organization or make the logic clearer. The reviewer suggests improvements but doesn't provide specific, actionable steps. The lack of explicit instructions reduces the actionable nature of the comment.", "grounding_specificity_rationale": "The reviewer mentions 'many proofs' and then specifically focuses on 'Lemma 3'. This indicates a grounding in the paper, as the reviewer is referring to a specific section. However, the initial reference to 'many proofs' is broad, and the specific question about the polynomial function in Lemma 3, while specific, is within the context of a larger, less precisely defined issue. The grounding is present but could be more precise.", "verifiability_rationale": "The reviewer makes a claim that 'the proof is extremely not well organized' and 'many proofs do not have clean logic and are very hard to follow.' This is a claim that requires justification. The reviewer attempts to support this claim by pointing to Lemma 3 and asking a question about the generality of the polynomial function. While the supporting evidence is present, it's not a direct citation or a wellestablished principle. The claim is not definitively proven but is supported by observation and a probing question.", "helpfulness_rationale": "The reviewer's comment identifies a significant weakness in the paper (poorly organized proofs) and provides a specific example (Lemma 3) to illustrate the issue. The reviewer also asks a direct question about the generality of the polynomial function, which is a clear request for clarification. This level of specificity and directness makes the comment quite helpful for the authors to understand and address the problem."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the suggestion to use realworld datasets instead of synthetic ones, providing a clear action for the authors. It identifies the area for improvement (experimental setup) and the desired outcome (better validation of the paper's claim).", "grounding_specificity_rationale": "The comment refers to the paper's claim to aim at realistic scenarios and suggests using realworld datasets as an improvement. While it implies a connection between the paper's claim and the experimental setup, it doesn't explicitly identify a specific section, table, figure, or unique element of the paper being addressed. The comment is more about the motivation or claim of the paper rather than a direct critique of a specific part.", "verifiability_rationale": "The comment suggests using realworld datasets as an improvement over synthetic datasets. While it presents a suggestion, it doesn't provide explicit reasoning or examples to support why realworld datasets are better for validating the paper's claim. The suggestion is implied rather than a claim supported by logical reasoning, common knowledge, or external references within the review itself.", "helpfulness_rationale": "The review point identifies a valid area for improvement: the experimental setup. It suggests using realworld datasets, which is a relevant and actionable suggestion. However, it lacks specific details, such as which realworld datasets to use or how to adapt the current methodology to work with them. The suggestion is good but lacks the specificity and detailed guidance needed for the authors to fully implement it."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states 'limited novelty' and 'more or less just follows the strategies used in ELECTRA.' This indicates an attempt to point out a potential area for improvement. However, it lacks specific details on what aspects are lacking novelty or how the approach differs from ELECTRA. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The comment refers to 'the strategies used in ELECTRA,' which is a specific reference point. However, it does not identify a specific part of the paper or methodology that is lacking novelty or following ELECTRA's strategies. The grounding is present but the specificity is lacking.", "verifiability_rationale": "The comment makes a claim ('limited novelty') without providing any evidence, justification, or references to support this assertion. It is a subjective statement that lacks logical reasoning or external references.", "helpfulness_rationale": "The comment identifies a potential weakness ('limited novelty') but does not offer any specific suggestions or guidance on how to address it. It is a critique without constructive feedback."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the weakness: 'The motivation/need for the Newton algorithm in section 4 was somewhat lacking I felt.' This is an explicit statement of a perceived deficiency. They also suggest a direction for improvement by comparing it to a '1dimensional line search on a convex function' and even proposes 'Experiments along these lines would help motivate the need for the analysis/algorithm.' While the reviewer doesn't provide concrete details on *how* the Newton algorithm is lacking, they clearly identify the area of concern and offer suggestions for improvement.", "grounding_specificity_rationale": "The reviewer does not explicitly identify a specific part of the paper or algorithm. They refer to 'the Newton algorithm' generally. However, they do specify the *type* of problem they perceive: '1dimensional line search on a convex function.' This provides some level of specificity about the *nature* of the perceived weakness, even if the exact location isn't pinpointed.", "verifiability_rationale": "The reviewer makes a claim: 'The motivation/need for the Newton algorithm in section 4 was somewhat lacking I felt.' They then provide reasoning for this claim by stating, 'This is essentially just a 1dimensional line search on a convex function, so even something as basic as a bisecting line search will converge linearly.' While they don't provide external references to support this claim in this specific review point, they do offer a logical argument based on their understanding of convex optimization.", "helpfulness_rationale": "The reviewer clearly identifies a perceived weakness in the motivation for the Newton algorithm. They offer a specific *type* of explanation, comparing it to a basic line search. They also suggest a concrete *improvement* by proposing 'Experiments along these lines would help motivate the need for the analysis/algorithm.' While they don't provide quantitative evidence of the impact of the Newton algorithm in this specific review, they offer a qualitative argument for its perceived lack of significance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'hence the proposed MT modelling methods seem far from idiomspecific.' This action is relatively clear and direct, indicating a desire for the authors to reconsider their methods. While the reviewer doesn't provide a specific alternative action, the implication is a call to focus on NMT system strengths rather than the proposed methods.", "grounding_specificity_rationale": "The review point clearly identifies the issue as being related to the 'impact that the methods have on idiomatic vs random data' and specifically analyzes this across 'most language and score combinations' (referring to Figure 3). This directly points to a specific aspect of the experimental results and the behavior of the proposed methods under different conditions. The reviewer's statement about the 'similarity of impacts' is a clear identification of a specific part of the paper being discussed.", "verifiability_rationale": "The review point makes a claim: 'hence the proposed MT modelling methods seem far from idiomspecific.' This claim is supported by the observation that 'For the majority of language and score combinations...the impact that the methods have on idiomatic vs random data is similar.' While the observation is based on the data presented in Figure 3, the reviewer's interpretation and generalization to 'far from idiomspecific' is an inference based on this observation. The claim is supported by evidence within the paper, making it '3'.", "helpfulness_rationale": "The review point provides a clear critique of the proposed methods (upweighing and KNN) based on their observed behavior in Figure 3. It suggests an alternative interpretation of the results, which is a valuable piece of feedback for the authors. The reviewer's comment directly points to a weakness in the methodology and proposes a potential direction for improvement, making it 5 and helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the incorrect dimensions of the resulting volume (WxHx1) and identifies the bias as a scalar. While the reviewer infers that the authors are confused about the need for multiple biases, the action of identifying the incorrect dimensions and scalar bias is directly stated. This makes the action somewhat explicit. The reviewer also points out that the authors are confused about having C biases, which implies the action of identifying the confusion is implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 3.4' in the paper, which directly grounds the comment in a specific part of the document. They also refer to 'feed forward models' and 'biases', which are specific elements of the model described in that section. This indicates a high level of grounding as the reviewer not only points to a section but also specifies the type of model and the parameter in question.", "verifiability_rationale": "The reviewer makes a clear claim that 'we only found this hyperparameter for the feed forward models... C biases is confusing'. This claim is supported by the mention of 'section 3.4' where the information is likely to be found. The reviewer provides a specific location and a clear indication of the discrepancy, making the claim verifiable through logical reasoning and reference to the paper's content.", "helpfulness_rationale": "The reviewer points out a specific discrepancy between the expected bias dimensions and the available hyperparameter, which is a clear weakness in the model description. They highlight the confusion caused by the single bias parameter in the context of multiple kernels. This directly identifies a problem that the authors are likely facing, making the review 5 in pointing out a concrete issue that needs addressing."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action of showing the smoothed GT shapes in Figure 3 and Figure 5. This is a direct instruction for the authors.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific parts of the paper (Figure 3 and Figure 5) where the smoothed GT shapes should be shown. This is a precise identification of the relevant sections.", "verifiability_rationale": "The reviewer suggests showing the smoothed GT shapes as a way to 'improve understanding of the quality of the reconstruction'. While the motivation is implied, the action itself (showing the shapes) is a direct and logical step to assess reconstruction quality. The reviewer does not provide specific examples or references to justify this claim beyond the general statement of improving understanding.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion to improve the understanding of reconstruction quality. By explicitly stating where to show the smoothed GT shapes, the reviewer directly addresses a potential weakness in the paper and provides a concrete step for the authors to take. This directly empowers the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises a valid concern about the generalizability of the method to other domains, which is an implicit action suggesting a need for clarification. However, the reviewer does not explicitly state a concrete action or detail how this generalizability should be addressed. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer points out a specific detail in the paper: the selection of 21 event types from Freebase and their coverage in the ACE dataset. This directly identifies a specific part of the paper being addressed, making the grounding strong. The reviewer also mentions 'Section 2 line 262' and the numbers 21 and 33, which are specific references.", "verifiability_rationale": "The reviewer states a concern about the selection and coverage but doesn't provide any evidence or reasoning to support this concern. The claim is that the selection is arbitrary and the coverage is low, but there's no logical reasoning or external references provided to back this up. The claim is stated but not justified.", "helpfulness_rationale": "The reviewer's concern about generalizability is a valid point that could guide the authors in expanding their method. However, it doesn't offer a specific solution or suggestion. The concern about the event type selection and coverage, while valid, doesn't directly improve the draft itself. It points to a missing detail."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'cite and discuss'. This directly indicates an intention to improve the draft. However, the specifics of which references to cite and how to discuss them are not provided, making it only partially actionable. The action is implied but not fully explicit.", "grounding_specificity_rationale": "The reviewer refers to 'domain adaptation' in general. While the intent is clear, the specific section, table, or unique element of the paper being addressed is not explicitly mentioned. Therefore, the grounding is weak. The reviewer also makes a judgment about the paper lacking 'important references,' but does not specify what aspect of domain adaptation these references pertain to, making the specificity unclear.", "verifiability_rationale": "The review point contains a claim: 'This paper lacks some very important references for domain adaptation.' This is a statement of a deficiency. While the reviewer suggests 'cite and discuss' as a way to address this, this suggestion lacks specific examples or references within the review itself to fully verify the claim. The reasoning is present but lacks concrete evidence.", "helpfulness_rationale": "The review point provides a clear direction for improvement: identifying and citing relevant domain adaptation references. While the specific references are not named, the suggestion to 'cite and discuss' is actionable and provides a framework for the authors to follow. The reviewer's message is helpful in guiding the authors to look for relevant literature and think about the connection between their work and existing domain adaptation techniques."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the suspicion ('The SCNN getting \"lucky\" on domain pricing is suspicious') and provides a potential explanation ('Are the chosen hyperparameters ever at the end of the searched range? The distance to the next best model is suspiciously large there'). This makes the action both explicit and concrete, as the authors can directly identify the issue and the potential solution.", "grounding_specificity_rationale": "The reviewer refers to specific experimental results ('the SCNN getting \"lucky\"') and compares them to another result ('the next best model'). This explicit reference to specific parts of the paper and the comparison between them indicates full grounding. The comment also specifies what is being questioned ('the distance to the next best model is suspiciously large there'), further enhancing specificity.", "verifiability_rationale": "The reviewer makes a claim ('The SCNN getting \"lucky\" on domain pricing is suspicious') and provides potential reasons for this claim ('Are the chosen hyperparameters ever at the end of the searched range? The distance to the next best model is suspiciously large there'). While not providing direct citations to external works, the reviewer offers a hypothesis and a qualitative observation, which supports the claim to some extent.", "helpfulness_rationale": "The reviewer's comment directly points to a potential weakness in the authors' experimental setup (the suspicious results of the SCNN) and suggests a direction for improvement (investigating hyperparameter choices and the distance to the next best model). This directly helps the authors identify and address a specific issue, making the review 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The action is implicit (the reviewer wants more information). The specifics are not clear. Therefore, it's not actionable.", "grounding_specificity_rationale": "The comment is 1 (the referenced part is not precisely identified). The issue is also not specifically detailed. Therefore, it's 2.", "verifiability_rationale": "There is X being made. Therefore, it is not verifiable.", "helpfulness_rationale": "The comment identifies a valid issue but lacks immediate actionable guidance. Therefore, it is not 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action: 'How does the size of the model (in terms of depth or number of parameters) compare to competing approaches? The authors mention that the model consists of 4 hourglass modules, but do not say how big each hourglass module is.' The authors are asked to consider the missing information about the size of each module. This is a direct request for information, making it explicit. The action is also concrete as the authors are asked to consider the impact of this missing information on their model's design.", "grounding_specificity_rationale": "The comment mentions 'the size of the model' and 'the 4 hourglass modules', which are specific parts of the paper. However, it does not specify *how* big each hourglass module is. The authors are asked to consider the missing information about the size of each module, but the exact nature of the missing information is not clearly defined.", "verifiability_rationale": "The comment contains a claim: 'The authors mention that the model consists of 4 hourglass modules, but do not say how big each hourglass module is.' This is a statement of a missing detail. While it's a reasonable suggestion that the authors consider the size of each module, the review point itself doesn't provide specific justification or references to support this claim. The reasoning is based on the assumption that model size is important, but this isn't explicitly proven within the review point.", "helpfulness_rationale": "The comment directly addresses a potential weakness in the model description by highlighting the missing information about the size of the model's components. By pointing out this missing detail, the reviewer is prompting the authors to consider a design choice that could impact their work. This makes the review point 3 as it identifies a potential area for improvement in the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue with the dimensions of the projection matrices and asks for clarification. This directly addresses a specific aspect of the method described in Section 1.2. While the reviewer doesn't explicitly state how to fix it, they identify a concrete area where something might be incorrect, making the action somewhat implicit but clearly targeted. The reviewer's uncertainty ('...but maybe I am wrong...') suggests they are aware of a potential problem but are not certain, indicating the action is not yet fully resolved.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the dimensions of the projection matrices' within the context of 'Section 1.2'. This clearly identifies a specific part of the paper being addressed. The reviewer is not making a general comment but rather focusing on a precise detail. The phrase 'I think this should be' further emphasizes the specific nature of the concern.", "verifiability_rationale": "The reviewer states a claim about the dimensions of the projection matrices and asks for verification. However, the review point itself does not provide any evidence, reasoning, or external references to support this claim. The reviewer is posing a question for the authors to clarify, rather than presenting a verifiable statement. Therefore, the claim is not yet supported within this review point.", "helpfulness_rationale": "The reviewer's review point is a question about the correctness of a specific formula in Section 1.2. While this points to a potential issue, it does not directly tell the authors how to fix it. It's more of a diagnostic question. The reviewer's uncertainty ('...but maybe I am wrong...') suggests they are not providing a definitive solution. Therefore, the review point is not immediately helpful in providing actionable feedback."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential ambiguity in the description of PACE's contribution. While they don't provide a direct link or detailed explanation, they highlight a specific area where clarification is needed. This points to a potential misunderstanding or lack of clarity for the authors regarding PACE's role as a diagnostic tool. It doesn't completely invalidate the paper, but it does raise a valid point that needs addressing.", "grounding_specificity_rationale": "The reviewer states a claim about PACE being a 'diagnostictype prediction' without specifying *which* diagnostic approach they are referring to or *which* aspect of PACE is being highlighted as diagnostic. The reviewer also doesn't explicitly mention ClimateBench or ClimateSet, making it harder for the authors to pinpoint the exact overlap or difference. The reviewer's description of 'diagnostictype prediction' is vague and doesn't detail the specific diagnostic elements of PACE.", "verifiability_rationale": "The reviewer makes a claim: 'the claim that 'To address this gap, we propose PACE, which treats climate emulation as a diagnostictype prediction' is misleading without making clear that prior work (e.g. ClimateBench or ClimateSet) does exactly this.' However, the reviewer doesn't provide any evidence or reasoning to support their claim that the original statement is misleading or inaccurate. They simply state it as a possibility. The reviewer points out a potential lack of clarity and suggests specific prior work. However, they don't provide any evidence or reasoning to support their claim that the original statement is misleading or inaccurate.", "helpfulness_rationale": "The review point is 3 because it points out a potential area of confusion for the authors regarding PACE's role as a diagnostic tool. The reviewer highlights a specific area where clarification is needed. While they don't provide a direct link or detailed explanation, they encourage the authors to clarify their work in relation to existing diagnostic methods. This points to a potential misunderstanding or lack of clarity for the authors regarding PACE's role as a diagnostic tool. It doesn't completely invalidate the paper, but it does raise a valid point that needs addressing."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the desired action: 'move some visual results from supplementary to the main paper' and 'make use of that space for some visual results'. This is a clear and direct instruction for the authors. Furthermore, the suggestion to 'condense it to two and make use of that space for some visual results' provides a concrete action on how to achieve the first part, indicating a clear and actionable step.", "grounding_specificity_rationale": "The review point explicitly mentions 'crowd density estimation' as the area where visual results should be moved. This clearly identifies the specific part of the paper being addressed. The reviewer also implies that these visual results are crucial for understanding the experiment within this domain, making the grounding specific and clear.", "verifiability_rationale": "The reviewer's statement is a suggestion for improvement, not a claim requiring verification. While the *implied* benefit is that moving these figures would improve understanding, the statement itself doesn't *prove* that. Therefore, it's not strictly verifiable as a fact. It's more of a constructive suggestion.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion directly aimed at improving the paper's presentation and helping the authors. The suggestion to move visual results and condense others directly addresses a potential weakness in the current presentation. The implication is that these changes would enhance the authors' ability to understand and potentially improve their work. This makes the review point 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests a method (corpus residual value) but doesn't explicitly state what action needs to be taken or how to implement it. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The comment explicitly mentions 'the patient of Figure 8' and suggests a method ('detect with the corpus residual value') to verify it. This clearly identifies the specific part of the paper and proposes a concrete approach.", "verifiability_rationale": "The comment proposes a method ('detect with the corpus residual value') but doesn't provide any justification or evidence for why this method would be effective or how it would work. It's a suggestion without supporting reasoning or references.", "helpfulness_rationale": "The review points towards a potential method for verification but doesn't directly suggest improvements to the draft or provide evidence for the effectiveness of the proposed method. It's more of a question than a direct improvement suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a change in the dataset but does not explicitly state an action or provide details on how the new dataset would be used or if any modifications to the current approach would be needed. The suggestion is presented as a preference rather than a critique identifying a problem that needs fixing.", "grounding_specificity_rationale": "The reviewer explicitly states their suggestion to use 'the most popular WebQuestions (Berant et al., 2013) benchmark set' instead of 'WebQuestionsSP'. This clearly identifies the specific part of the paper (the dataset choice) being addressed, demonstrating strong grounding specificity.", "verifiability_rationale": "The review point is a suggestion or recommendation, not a claim that requires verification. There is no assertion of truth or falsity, and no evidence is provided to support or refute the suggestion.", "helpfulness_rationale": "The review point offers a suggestion for improvement by suggesting a different dataset. While the suggestion itself isn't deeply justified, it does point towards a potential area for enhancement. However, the lack of a clear rationale for the current dataset choice and the absence of a strong justification for the suggested change make the helpfulness somewhat limited."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a missing element: 'lacks analysis or results on other datasets (e.g., ImageNet derivatives)' and suggests 'verify the effectiveness of the framework on ImageNet1k or even ImageNet100' and 'present these results in the main paper'. While the reviewer points out a deficiency, the *how* is left open. The reviewer doesn't explicitly tell the authors *which* other datasets to analyze or *how* to analyze them. The suggestion about the main paper is also a preference, not a concrete requirement.", "grounding_specificity_rationale": "The reviewer mentions 'other datasets (e.g., ImageNet derivatives)' and 'the framework'. While they don't give a unique section number, they clearly refer to the concept of 'analysis' and 'results' related to these datasets and the framework. This provides some level of grounding by mentioning specific datasets and the purpose of the missing analysis. However, the *type* of analysis is vague. They could be referring to *any* analysis, not just quantitative results.", "verifiability_rationale": "The reviewer makes a claim: 'These results ideally can be presented in the main paper.' However, the reviewer doesn't provide *reasons* or *evidence* for *why* these results should be in the main paper. They simply state their preference. There is no logical reasoning, common knowledge, or external references provided to support this claim.", "helpfulness_rationale": "The reviewer provides feedback by pointing out a missing element (analysis on other datasets) and suggesting a location for presenting these results. However, the *how* is not fully specified. The reviewer doesn't tell the authors *which* other datasets to analyze or *how* to analyze them. The suggestion about the main paper is also a preference, not a concrete requirement. While the reviewer identifies a useful area for improvement, the feedback lacks detailed guidance and is more prescriptive than informative."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential ambiguity in the paper regarding the use of BigFive and MBTI. While the initial framing suggests they are models for extension, their later use as datasets in the experiments could be clearer. The reviewer's suggestion is not a direct instruction to the authors but rather a clarification needed. The reviewer is suggesting that the authors should either explicitly state that these are datasets or provide a reason for using them as such. This is a suggestion for improvement, not a direct action the authors need to take. The reviewer is highlighting a potential point of confusion for the authors.", "grounding_specificity_rationale": "The reviewer mentions BigFive and MBTI in the abstract and introduction. However, they do not explicitly state which specific part of the paper these datasets are used in the experiments. This makes the reviewer's point somewhat vague. The reviewer is suggesting that the authors should either point to a specific section or explain the connection between the initial framing and the experimental setup. This is a suggestion for clarification, not a direct action the authors need to take. The reviewer is highlighting a potential lack of specificity in the paper.", "verifiability_rationale": "The reviewer is making a suggestion for improvement by pointing out a potential ambiguity in the paper. They are not making a claim that requires justification or evidence. The reviewer is suggesting that the authors should either clarify the connection between the initial framing and the experimental setup or provide a reason for using these datasets as such. This is a suggestion for improvement, not a critique that requires verification. The reviewer is offering a potential point of clarification, not a verifiable claim.", "helpfulness_rationale": "The reviewer is providing a suggestion for improvement by pointing out a potential ambiguity in the paper. They are not making a claim that requires justification or evidence. The reviewer is suggesting that the authors should either clarify the connection between the initial framing and the experimental setup or provide a reason for using these datasets as such. This is a suggestion for improvement, not a critique that requires verification. The reviewer is offering a potential point of clarification, not a verifiable claim. The helpfulness lies in the potential for the authors to improve their understanding and the scope of their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the gap in generalization and provides a concrete solution (metalearning). The suggestions are directly aimed at improving the paper's content.", "grounding_specificity_rationale": "The reviewer mentions 'generalization to the specific TSP instances' and 'DIMES's own advantages'. While they touch upon specific aspects, they don't explicitly identify a unique section, table, or figure within the paper. The reviewer also mentions 'TSP100' which is a specific instance, indicating some grounding but not full grounding. The reviewer also suggests a comparison with metalearning, which is a specific suggestion, but the current paper doesn't explicitly address this, making it underspecified.", "verifiability_rationale": "The reviewer makes claims about the generalization gaps and suggests a comparison with metalearning. While the suggestion is valuable, the claim itself is verifiable. The reviewer points out a potential area for improvement and suggests a specific experiment, but doesn't provide immediate evidence or justification within the current paper.", "helpfulness_rationale": "The reviewer provides suggestions and suggestions for improvement, such as clarifying the generalization gaps and conducting a comparison with metalearning. These suggestions are directly aimed at improving the paper's content and are actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for information about the final thresholds used and the full set of hyperparameters. While the request is explicit about what information is needed, it does not specify how this information relates to the paper's content or how it can be used to improve the draft. The action is identified, but the context and implications are missing.", "grounding_specificity_rationale": "The reviewer is asking for information related to the paper's results and reproducibility. While the request is somewhat specific about the type of information (thresholds and hyperparameters), it does not explicitly point to a specific section, table, or figure of the paper. The information is implied but not directly referenced within the paper itself.", "verifiability_rationale": "The reviewer is stating that the final thresholds and hyperparameters were used. This is a claim. However, the paper itself does not contain this information, and there is no logical reasoning, common knowledge, or external references provided within the paper to support this claim. The claim is made based on the reviewer's understanding of the field or their own experience, which is not verifiable from the paper's content alone.", "helpfulness_rationale": "The information about thresholds and hyperparameters is relevant for ensuring the reproducibility of the results. This information is important for other researchers to be able to replicate the study and build upon it. While the information itself doesn't directly address potential weaknesses or improvements in the paper, it is crucial for the scientific process of validating and reproducing findings. The information is relevant to the scientific process, making it 3 in the context of research validation and building upon existing work."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper's conclusion about readability and question difficulty is too broad and depends on the features used. They also provide an example (POS/dependency parses) to illustrate this. This constitutes an explicit action to challenge the paper's claim and identify a missing detail (the importance of specific features).", "grounding_specificity_rationale": "The reviewer clearly identifies the paper's claim ('Your \"dataset analysis suggested that the readability of RC datasets does not directly affect the question difficulty\"') as the specific part being addressed. They then provide a specific feature (POS/dependency parses) as evidence for their claim. This demonstrates strong grounding as the paper and a specific aspect within the paper are identified.", "verifiability_rationale": "The reviewer identifies a claim in the paper ('your \"dataset analysis suggested that the readability of RC datasets does not directly affect the question difficulty\"') and provides a justification for this claim by stating that it depends on the method/features used. While the reviewer doesn't provide a definitive verification, they offer a logical reasoning for why the paper's statement might be nuanced. The claim is supported by a logical argument, making it 3.", "helpfulness_rationale": "The reviewer's comment is highly specific, pointing out a potential flaw in the paper's interpretation and providing a concrete example to consider. This directly addresses a specific aspect of the paper's methodology and offers actionable feedback to the authors, making it 5 in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific issue \u2013 the imbalance in space allocation between memory networks and the forward model. This suggests an *explicit* action: the authors should adjust the length of the corresponding sections. The reviewer also mentions a *lack of detail* in the related work, implying a need for *specific* information. This suggests the point is *partially actionable*.", "grounding_specificity_rationale": "The reviewer refers to \"basic memory networks\" and \"forward model\" without explicitly stating which section or table this refers to. The \"related work\" section is mentioned, but the *specific* missing pieces are not detailed. This indicates a lack of explicit grounding. However, the reviewer does specify the *topic* within related work as \"more reinforcement learning tasks,\" which provides some level of specificity. This suggests the comment is not fully grounded but has some specificity.", "verifiability_rationale": "The reviewer states a problem (\"the writing quality of the paper should be improved\") and provides an example of an issue (\"e.g., the authors spend the same space on explaining basic memory networks and then the forward model\"). This constitutes a claim. The reviewer also points to a *lack of detail* in the related work, which could be verified by checking the related work section. While the evidence is not a direct citation, it provides a basis for verification. This suggests the comment is *3*.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by stating that the authors should adjust the length of the corresponding sections for memory networks and the forward model. They also identify a specific area for further research by pointing out the *lack of detail* in the related work section. These suggestions are concrete and actionable, directly addressing specific weaknesses and proposing concrete improvements. This makes the comment *4*."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential issue in a theoretical construction involving quantum operations and states. While the reviewer doesn't provide explicit steps on how to fix it, they identify a flaw in the logic or a potential limitation of the assumptions. This suggests an implicit action, but it lacks the concrete details needed for full actionability.", "grounding_specificity_rationale": "The reviewer refers to 'Line 140' and the variables 'Qo', 'vo', and 'v'' to describe the issue. This provides a degree of grounding as the comment refers to a specific part of the paper and the elements involved in the problematic step. However, the mention of 'Ass.' is vague and doesn't pinpoint a specific element being addressed, weakening the grounding.", "verifiability_rationale": "The reviewer raises a concern about the assumptions underlying the theoretical construction. While they don't provide a definitive proof or counterexample, they offer a hypothesis about why the assumptions might be problematic. This makes the claim 3, as it's based on logical reasoning and the stated assumptions, but lacks external references or detailed explanations.", "helpfulness_rationale": "The reviewer points out a potential issue in a theoretical construction. While this raises a flag for the authors, it doesn't provide a direct, actionable solution. The helpfulness is limited because the authors need to further investigate the issue and potentially derive their own steps to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action (identifying the assumption as potentially problematic) but lacks concrete details on how to verify or address this assumption. The reviewer suggests testing the assumption but doesn't provide specifics on how this would be done or what the implications might be. The action is stated, but the method of implementation is missing.", "grounding_specificity_rationale": "The comment explicitly mentions the assumption being tested (d_e are good replacements for entity embeddings) and clearly identifies the issue (potential problems with this assumption). The grounding is explicit as the comment directly refers to the specific assumption being made within the paper. The part of the paper being addressed is accurately identified.", "verifiability_rationale": "The comment contains a claim (identifying an assumption as potentially problematic) and provides some justification by suggesting testing it. However, the justification is vague and doesn't specify what kind of testing or evidence would be needed. While a claim is made and some reasoning is provided, it lacks the depth and specificity of verifiable claims.", "helpfulness_rationale": "The comment raises a valid point about the assumptions made in the paper and suggests further investigation. It provides a clear direction for the authors to explore. The feedback is relevant and guides the authors towards a potential area of concern. The comment identifies a relevant issue and provides a clear direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that making the factors in a table does not help convey more messages than pure text. This is an implicit suggestion that the table is not effective for communicating information. While the reviewer doesn't explicitly say 'do something with the table,' the implication is that the current table is lacking. The action is implicit, requiring the authors to infer what needs improvement. The specificity of the action is also vague, as the reviewer doesn't pinpoint what aspect of the table is problematic.", "grounding_specificity_rationale": "The reviewer makes a general statement about tables not being effective for conveying messages. They do not identify a specific part of the paper (like a table number or a specific cell) that is lacking clarity. The grounding is weak because the authors cannot confidently determine which part the comment addresses. The specificity is also lacking as the reviewer doesn't specify what messages the table *should* convey or why the current version fails.", "verifiability_rationale": "The reviewer makes a declarative statement: 'making the factors in a table does not help convey more messages than pure text.' This is a claim that something *isn't* the case. The reviewer attempts to verify this claim by stating it's not true, but they do not provide any evidence or reasoning to support this assertion. The claim is presented without any logical support or references.", "helpfulness_rationale": "The reviewer's comment is a negative statement about the table's effectiveness. They criticize the table's current state without offering any suggestions or insights for improvement. The comment is a critique without constructive feedback. The authors are left with no actionable feedback on how to improve the table's communication of messages."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The question identifies a potential area of confusion regarding the term 'physical interaction' in the context of a simulation. While it doesn't explicitly state what needs to be changed, it points to a lack of clarity in the authors' description, which can be considered a form of implicit actionability. However, it doesn't provide a concrete direction for improvement, making it less actionable than a direct instruction.", "grounding_specificity_rationale": "The question explicitly refers to 'physical interaction' and 'one simulation,' using specific terms that are likely relevant to the authors' draft. This direct reference to specific parts of a potential model or experiment indicates high grounding specificity. The authors can easily identify the targeted aspect of their work.", "verifiability_rationale": "The question itself does not contain a claim that needs verification. It's a request for information about the nature of interactions in a simulation. Therefore, it doesn't fall under the 'Verifiability' aspect, which focuses on the presence and support of claims. The potential for the answer to be verifiable is there, but the question itself isn't a claim.", "helpfulness_rationale": "The question highlights a potential lack of clarity in the authors' description of their simulation and the types of interactions involved. By pointing out this potential ambiguity, it encourages the authors to define their terms more precisely and improve the clarity of their writing. While it doesn't provide a solution, it identifies a problem that needs addressing, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the limitation of pruning with large networks and distributed training regarding global top Q values and its impact on acceleration techniques like quantization and sparsification. This provides a clear, actionable point for authors to consider.", "grounding_specificity_rationale": "The reviewer mentions 'distributed settings' which grounds the comment to the context of the paper. However, the reviewer also specifies 'large networks' and 'global top Q values of the metric' and 'average of gradients', providing specific details about the network and training process. While the general context is mentioned, the specific aspects are clearly identified.", "verifiability_rationale": "The reviewer points out a potential issue with acceleration techniques. While the reviewer highlights a concern, they don't provide explicit logical reasoning, common knowledge, or external references to support this claim within the review point itself. The reviewer is pointing out a potential problem, not definitively stating it's a problem with *definitive* evidence within the review point.", "helpfulness_rationale": "The reviewer does not propose a specific action or solution for the authors. They are highlighting a potential issue and suggesting a need for more specific information. While this is valuable information, it doesn't directly tell the authors *what* to do."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states their belief about the subfigures, which can be considered an explicit action or suggestion. While the reviewer doesn't directly state what to do, they imply a need for clarification or correction regarding the identified subfigures. The specificity of the subfigures (in Figs 1 and 2) makes the potential issue concrete.", "grounding_specificity_rationale": "The reviewer refers to 'subfigures in Figs 1 and 2,' which is a specific reference to a part of the paper. While the reviewer doesn't identify a unique element, the mention of specific figures and their subfigures clearly identifies the issue. The grounding is explicit as the reviewer can identify the section, table, figure, or unique aspect being addressed.", "verifiability_rationale": "The reviewer makes a statement about the subfigures, which can be considered a claim. However, the reviewer does not provide any evidence or reasoning to support their claim about the swapped subfigures. The claim is presented without sufficient justification or references.", "helpfulness_rationale": "The reviewer has identified a potential error in the figures, which is a significant issue for the authors. Identifying a concrete potential problem is helpful for the authors as it highlights a specific area that needs attention. While the reviewer doesn't offer a solution, the identification of a clear problem is a valuable piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the findings of the dropout probe (improved sensitivity) and contrasts them with previous approaches (was missed). This provides an implicit action for the author to consider the implications of this difference. The concern about false positives is also a valid point, suggesting a potential tradeoff. While not entirely explicit about the *how*, the implications are clear. However, the reviewer also makes a statement without providing specific guidance, which is less actionable.", "grounding_specificity_rationale": "The review point discusses the findings of the dropout probe but does not explicitly identify a specific part of the paper or experiment being addressed. The concern about false positives is a general issue related to the method, not a specific problem with a particular aspect of the paper. The findings are presented as general observations rather than specific criticisms of a particular section or table.", "verifiability_rationale": "The review point contains claims about the findings of the dropout probe and the potential for increased false positives. However, the *how* of these claims is implied rather than explicitly stated or supported. For example, the concern about false positives is presented as a potential consequence without providing direct evidence or logical reasoning within the review point itself. The connection between improved sensitivity and the risk of false positives is not explicitly demonstrated.", "helpfulness_rationale": "The review point provides some information about the findings of the dropout probe and raises a concern about false positives. It highlights a potential improvement in sensitivity and a potential drawback. However, it does not offer concrete, actionable steps for the author to take based on these findings. The suggestions are more about raising awareness and considering potential tradeoffs rather than providing clear guidance on how to implement or address the issues."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of discussion and comparison of specific exploration methods (countbased, RND, ICM). This is a direct and actionable suggestion for the authors to improve their work by including and comparing these methods. The reviewer identifies an area for improvement and provides a clear direction for how to address it.", "grounding_specificity_rationale": "The reviewer explicitly names specific exploration methods (countbased, RND, ICM) as examples of 'many exploration methods in RL literature.' This allows the authors to precisely identify the area where the paper is lacking and understand the specific type of methods being referred to. The reviewer provides concrete examples, grounding the criticism in specific areas of the literature.", "verifiability_rationale": "The reviewer makes a claim about the paper being 'not sound' and 'does not discuss and compare these methods' but does not provide any evidence or references to support this claim within the review point itself. The claim is presented as an assertion without logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the paper (lack of discussion on exploration methods) and suggests a specific improvement (including and comparing these methods). While the reviewer doesn't provide evidence to support their claim about the paper's soundness, their suggestion is constructive and directly addresses a potential area for improvement. The reviewer provides a clear direction for how the authors can enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment states 'annotations in Figure 4 can be further enlarged'. This explicitly states an action that needs to be taken (enlarging the annotations). However, it does not provide concrete details on *how* to achieve this. The phrase 'further enlarged' implies a need for clarification or a specific method, making the action somewhat implicit.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 4', which is a specific part of the paper. It also clearly identifies the issue as 'annotations can be further enlarged', specifying what needs to be improved. This indicates that the authors can accurately pinpoint the referenced part and understand the specific problem.", "verifiability_rationale": "The comment does not contain a claim or suggestion about the paper itself. It is a practical suggestion for improving the presentation of Figure 4. Since there is X being made, it does not require verification. This falls under the 'X' category, indicating X.", "helpfulness_rationale": "The comment directly points to a specific area for improvement (Figure 4) and suggests a concrete action (enlarging annotations). While it doesn't provide a detailed methodology for enlarging the annotations, it clearly identifies a actionable step that authors can take to improve their draft. This makes it a helpful suggestion, even if not fully comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment directly points out a factual error in the reviewer's understanding of relation classification, making it 5. The reviewer immediately knows the issue and the correction.", "grounding_specificity_rationale": "The comment explicitly states the problem (incorrect assumption about the number of entities) and clearly identifies the area (relation classification). There's no ambiguity about which part of the paper or context is being discussed, making it fully grounded.", "verifiability_rationale": "The comment makes a claim about the nature of relation classification. While it's based on common knowledge, it lacks specific examples or external references to support the claim, making it 3.", "helpfulness_rationale": "The comment addresses a potential point of confusion for the author regarding relation classification. While it doesn't directly suggest improvements, it clarifies a fundamental concept, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer is asking questions about the model's capabilities and implementation details rather than providing explicit actions or suggestions for improvement. While the reviewer identifies a potential issue (inference speed) and asks a question about a specific term, they do not offer a concrete plan to address it. The request for the coefficient of the p(L, E | X) term is a question, not an actionable suggestion. The lack of justification for the value of this coefficient further supports the idea that the reviewer is not providing an actionable suggestion.", "grounding_specificity_rationale": "The reviewer asks a specific question about the coefficient of the p(L, E | X) term in line 307. This demonstrates a degree of grounding as the comment refers to a specific location in the code. However, the reviewer does not explain *why* they believe the coefficient should be 1 or provide any justification for this belief. The comment is vague and lacks detail on how to apply this information. The lack of a clear rationale makes it difficult to determine the relevance or importance of this specific implementation detail.", "verifiability_rationale": "The reviewer is asking a question about a specific implementation detail (the coefficient of the p(L, E | X) term) without providing any evidence, justification, or reasoning to support their belief that it should be 1. The comment is a question about the code, not a claim about the paper's content. There is no logical reasoning, common knowledge, or external references provided to support the claim (if any) that the coefficient should be 1. The comment is purely about the implementation.", "helpfulness_rationale": "The reviewer's comments are primarily critical and lack specific suggestions for improvement. They question the model's capabilities, point out missing hyperparameter details, and criticize the writing. While they identify potential issues, they do not offer concrete steps to address them. The lack of specific, actionable feedback makes it difficult for the authors to gain confidence in the work or identify areas for improvement. The writing critique is also subjective and does not provide specific suggestions for how to improve the writing."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'replace it' as an action, indicating a clear intention to modify the model mentioned in line 152. While the specific replacement is vague ('very high performing model'), the action itself is stated directly.", "grounding_specificity_rationale": "The reviewer refers to 'the model in line 152', which grounds the suggestion to a specific part of the paper. However, the suggestion itself, 'replace it with a very high performing model', is quite general and lacks specific details about what constitutes a 'very high performing model' or why this replacement is necessary.", "verifiability_rationale": "The reviewer makes a suggestion ('replace it with a very high performing model') without providing any justification or reasoning for why this change is beneficial or how it addresses any issues with the original model. There is X that is supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer provides a suggestion directly related to improving the example in line 152. While the suggestion is relevant, it lacks the necessary justification to be fully convincing. The reviewer does not explain why the Dozat and Manning model is problematic or what specific improvements a 'very high performing model' would bring. Therefore, while the suggestion is 3, it is not strongly supported or clearly beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions 'proofs and references are needed to demonstrate your statement' and 'One more daunting task of multiscale architecture design is unknown is that when to fuse the multiscale feature.' These are clear actions the authors should take. While the first part is somewhat vague about *which* statements need proofs or references, the second part is very specific about a missing detail (fusion strategy). The reviewer also states 'Besides these explicit multiscale methods, the models with skip connections 10 could also be regarded as using multiscale information in an implicit way.' This is an explicit statement connecting skip connections to multiscale information, even though the connection isn't immediately obvious. Therefore, while most actions are explicit, the level of detail varies, making it 4.", "grounding_specificity_rationale": "The review point states 'Some subjective statements are inappropriate to introduce this paper.' While this is a general statement, it doesn't specify *which* statements are subjective or why they are inappropriate. The reviewer also mentions 'Proofs and references are needed to demonstrate your statement' without specifying which statements require them. Similarly, 'One more daunting task of multiscale architecture design is unknown is that when to fuse the multiscale feature' and 'Besides these explicit multiscale methods, the models with skip connections 10 could also be regarded as using multiscale information in an implicit way' do not pinpoint the specific parts of the paper being discussed. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point states 'Proofs and references are needed to demonstrate your statement' and 'One more daunting task of multiscale architecture design is unknown is that when to fuse the multiscale feature.' These claims are supported by the reviewer explicitly stating the need for proofs/references and the missing detail about fusion. The statement 'Besides these explicit multiscale methods, the models with skip connections 10 could also be regarded as using multiscale information in an implicit way' is also verifiable as the reviewer is making a claim and providing a connection between skip connections and multiscale information. Therefore, the claims are wellsupported.", "helpfulness_rationale": "The review point highlights potential issues with the paper's presentation by stating 'Some subjective statements are inappropriate to introduce this paper.' This is a helpful point as it points out a potential area for improvement. The point also explicitly states 'Proofs and references are needed to demonstrate your statement,' which is a 5 suggestion as it directly points to concrete improvements the authors should make. Furthermore, 'One more daunting task of multiscale architecture design is unknown is that when to fuse the multiscale feature' is another 5 point as it identifies a specific missing detail. The statement 'Besides these explicit multiscale methods, the models with skip connections 10 could also be regarded as using multiscale information in an implicit way' is also helpful as it connects a related concept and provides context. While the first point about subjective statements is less specific, the other points are clear and actionable."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "X", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete change to be made. It is a question prompting a comparison, not a directive to improve the method.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper being addressed. It is a general question about the comparison between the proposed method and prior art, without specifying which aspects are being compared or what needs improvement.", "verifiability_rationale": "The review point does not contain a claim. It is a question, not a statement that something is wrong or needs improvement.", "helpfulness_rationale": "The review point is a question, not a statement of weakness or improvement. It does not provide actionable feedback on how to compare the proposed method with prior art or suggest any changes based on this comparison."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desire for 'more detailed analysis' and suggests 'comparing them' (referring to different languages/nationalities). This indicates a clear and direct action the authors should take. The action is also concrete, as the reviewer specifies the *type* of analysis they desire (detailed analysis, comparisons).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'language/nationality' and provides a list of specific examples ('Japanese, Chinese, English, Arabic, German...'). This clearly identifies the specific part of the paper being addressed, making the grounding fully explicit. Furthermore, the reviewer specifies the *purpose* of the analysis ('comparing them for interesting observations'), adding further detail to the referenced part.", "verifiability_rationale": "The reviewer makes a claim by stating 'Some analyses can be more detailed'. While this claim itself doesn't have external references, the reviewer implies that the current analysis is less detailed than it *could* be. The logical reasoning is that more granular analysis is possible, even if the specific *how* isn't elaborated. Therefore, the claim is partially verifiable.", "helpfulness_rationale": "The reviewer directly points out a limitation in the current analysis ('Some analyses can be more detailed') and provides a clear suggestion for improvement ('I was wondering whether there would be some interesting observations comparing them'). This is a specific and actionable piece of feedback that directly addresses a potential weakness in the analysis. The suggestion is clear and directly actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point directly asks a question, implying a suggestion for improvement ('besides norm'). However, it doesn't explicitly state what alternative property should be considered, making it vague in terms of providing a concrete action. It is explicit in pointing out a potential limitation but implicit in suggesting an alternative.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper it is referring to. It is a general question about 'features'. Therefore, it is 1. Additionally, it does not specify what is wrong or missing regarding these features, so it is not specific.", "verifiability_rationale": "The review point is a question, not a statement containing a claim (opinion, judgment, or suggestion). Therefore, it does not have verifiable content as defined in the guidelines.", "helpfulness_rationale": "The review point identifies a potential area for improvement ('besides norm') and asks for information about 'other properties of features'. This is a helpful prompt for the authors as it encourages them to think critically about their feature design and consider alternative approaches. It guides them to identify potential limitations in their current approach."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks about the behavior of F^\u2020 regarding conservation properties, which can be directly investigated. It also asks if it's possible to train F^\u2020 to conserve these properties, providing a clear direction for action. The request for numerical illustrations further specifies a concrete way to explore this.", "grounding_specificity_rationale": "The review point mentions 'symplectic integrators' and 'Hamiltonian systems,' which are specific technical terms. It also requests 'numerical illustrations,' making the point grounded and specific to the proposed method and a relevant application area.", "verifiability_rationale": "While the review point doesn't explicitly state a claim that needs verification, it poses a question about a potential property of F^\u2020 (conservation). This could be considered partially verifiable if the authors can find relevant literature on the conservation properties of similar learning methods or if they can logically reason about the implications of their method.", "helpfulness_rationale": "The review point identifies a potential gap in how F^\u2020 handles conservation compared to traditional numerical methods. It asks a relevant question about the behavior of F^\u2020 and suggests a concrete way to investigate this through numerical illustrations. This directly points to a potential area for improvement and provides a clear direction for the authors to explore."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a question about the necessity of using two SIRENs and suggests an alternative design. This directly points to a potential inefficiency or area for improvement, making it a clear action for the authors to consider. While the action itself isn't a concrete implementation detail, it's a direct suggestion that can be acted upon.", "grounding_specificity_rationale": "The reviewer refers to 'f' and 'd', which are likely specific components or functions within the method described in the paper. While not explicitly stating section numbers or figure references, the context strongly implies they are referring to these specific parts. This can be considered 'fully grounded' as the functions are clearly identifiable.", "verifiability_rationale": "The reviewer raises a question about the design choice of using two SIRENs without providing specific evidence or reasoning within this review point to support their claim that a simpler network could suffice. While the suggestion implies a potential benefit, there's no explicit verification or justification provided by the reviewer in this specific point.", "helpfulness_rationale": "The reviewer's question about the necessity of two SIRENs and their suggestion for a simpler network are relevant and directly address a design choice in the method. This provides the authors with a concrete point to consider and potentially improve their implementation, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that RQ1 is 'redundant' and 'adds no extra information.' While this suggests a lack of clarity in the reviewer's understanding of RQ1, it doesn't inherently make the review point actionable. Actionability requires the reviewer to explicitly state what the authors should do with the information. The reviewer's suggestion for an alternative analysis is helpful, but it's a suggestion, not a critique of the current RQ1 that would lead to actionable steps. The lack of specific evidence for the redundancy further weakens the actionable aspect.", "grounding_specificity_rationale": "The reviewer does not explicitly state where the redundancy lies within the paper. They suggest an alternative analysis, but they do not pinpoint the specific section, table, or figure in their own paper that is causing confusion. Therefore, the reviewer's comment lacks grounding specificity as they do not identify the exact location of the issue they are criticizing.", "verifiability_rationale": "The reviewer makes a claim that 'The RQ1 mentioned in the paper seems redundant' and provides a suggestion for improvement ('Another interesting point to analyse'). While the suggestion is valuable, the *statement* about redundancy is a claim that needs justification. However, the reviewer does not cite any specific evidence within their paper to support this claim of redundancy. The lack of supporting evidence makes the claim somewhat 1.", "helpfulness_rationale": "The reviewer provides a critique ('The RQ1 mentioned in the paper seems redundant') and a suggestion for improvement ('Another interesting point to analyse'). While the suggestion is helpful, the critique itself is vague and doesn't offer concrete steps for the authors to improve their RQ1. The lack of specific evidence for the redundancy makes the critique less impactful. The reviewer's comment is more of a suggestion than a detailed critique with actionable feedback."}
{"actionability_label": "2", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point asks a question ('Could you elaborate...') which suggests a desire for more information. However, it doesn't explicitly state what needs to be done or how to achieve the elaboration. It's implied, but not directly actionable. The request is broad and doesn't specify *what* needs to be elaborated. It doesn't offer a concrete next step.", "grounding_specificity_rationale": "The review point doesn't mention a specific part of the paper. It's a general question about related work. While the *category* of work ('other works focusing on semantic face editing') is specific, the *review point itself is 1* in the context of the paper being reviewed. The authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point doesn't make a claim. It's a question, not a statement of opinion or assertion. Therefore, it doesn't have verifiability.", "helpfulness_rationale": "The review point is helpful because it asks a relevant question about related work. It highlights a potential gap in the paper being reviewed by pointing to existing capabilities in other methods. This provides context and potentially guides the authors on future directions. By identifying this gap, the reviewer is providing valuable information for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states actions or suggestions that are direct or apparent. The authors can directly identify modifications they should apply to their draft. The suggestions are clear and actionable. For example, the authors are told to 'reduce footnote usage' and 'move important content to the main body'. These are concrete actions with clear implications.", "grounding_specificity_rationale": "The review point explicitly mentions 'much of the content is actually important' and 'details around parameter settings etc. can be moved into the appendix'. The authors can accurately pinpoint the sections, content, and details being addressed. The grounding is strong as the reviewer directly links specific content to the main body and appendix. The ' important' is a bit vague, but the overall intent is clear.", "verifiability_rationale": "The review point does not contain a claim or suggestion that requires verification. It is a critique and suggestion for improvement. The purpose is to point out a problem and offer a solution, not to present a claim that needs to be supported by evidence. Therefore, it is not verifiable because there is X to be evaluated.", "helpfulness_rationale": "The review point is 5. It directly addresses issues with footnote usage and suggests concrete actions to improve the paper's structure and readability. The reviewer provides clear guidance on where important content should be and what kind of details should be moved. This empowers the authors to make significant improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the impact of the GS module on the effective receptive field, rather than providing a direct action or suggestion. While the question is relevant, it doesn't tell the authors what to do or how to improve their draft.", "grounding_specificity_rationale": "The review point mentions the 'GS module' and 'effective receptive field' but does not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed.", "verifiability_rationale": "The review point is a question, not a claim that requires verification. There is no statement with an opinion, judgment, or suggestion that needs to be supported by evidence.", "helpfulness_rationale": "The review point raises a relevant question about a potential improvement (change in effective receptive field) related to the GS module. While it doesn't provide a solution, it points to a potentially valuable area for further investigation and could be helpful for authors exploring optimization strategies."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests adding an output head for value functions in the finetuning stage. This is an explicit suggestion, indicating a concrete action. However, the reviewer does not specify how this head should be implemented, what architecture it should have, or how the training process would differ from the pretraining stage. The lack of detail makes it difficult to know exactly what action needs to be taken.", "grounding_specificity_rationale": "The reviewer mentions 'standard RL practices' and 'value functions' as the basis for their suggestion. While they hint at the type of improvement, they do not explicitly point to a specific section of the paper or a unique element that requires modification. The suggestion is broadly applicable and lacks a clear connection to a particular part of the work.", "verifiability_rationale": "The reviewer proposes a simplification in the LSTM architecture for both pretraining and finetuning, suggesting that the probabilities of the actions might be the same in both stages. While this is a plausible idea, the reviewer does not provide any evidence, justification, or references to support this claim. The suggestion is based on an assumption without any logical reasoning or external references.", "helpfulness_rationale": "The reviewer suggests a simplification in the LSTM architecture by adding an output head for value functions during finetuning. This is a potentially helpful suggestion as it could simplify the finetuning process and potentially improve the model's performance. However, the lack of detail in the suggestion makes it difficult to assess the actual impact and whether the authors would be able to implement it effectively. The potential benefit is there, but the lack of clarity limits its helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking two questions: 'What is the rationale behind combining G4RL with HRAC (i.e., HRACG4RL)?' and 'Does G4RL require HRAC's regularization in the latent space?'. While the questions themselves are not explicit actions, they implicitly ask the authors to explain their design choices and the relationship between the two methods. The reviewer is prompting the authors to clarify their implementation. Therefore, the actionability is borderline as the reviewer is not directly asking for an action but rather seeking explanation and clarification.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'G4RL' and 'HRAC' in their questions. This clearly identifies the specific parts of the paper they are referring to. The questions are also specific about the relationship between these two methods. Therefore, the grounding is fully grounded and the specificity is also quite high as the questions directly address the relationship between the two named methods.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question about the relationship between two specific methods. There are no claims to support or refute. Therefore, the verifiability is 'X' as there is X to evaluate.", "helpfulness_rationale": "The reviewer is seeking clarification on key concepts (rationale and regularization relationship) related to their implementation. While they are not proposing a solution, this type of request is valuable for the authors to understand their work better and potentially improve it. Therefore, the review is 3 as it provides information that can aid in understanding and potentially improving the draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests 'it would be good to acknowledge some of the older works too.' While this implies an action (acknowledging older works), it doesn't explicitly state how to achieve this. The reviewer points towards an improvement but lacks specific guidance on the method of acknowledgment.", "grounding_specificity_rationale": "The reviewer mentions 'related works' generally, without specifying a particular section, table, figure, or unique aspect of the paper. The suggestion is broad and doesn't pinpoint the exact location or nature of the desired improvement within the related works section.", "verifiability_rationale": "The reviewer's statement 'it would be good to acknowledge some of the older works too' is a suggestion or a desire for improvement, not a claim that something is missing or incorrect. There is no assertion that the current related work section is flawed or needs justification.", "helpfulness_rationale": "The reviewer suggests 'it would be good to acknowledge some of the older works too.' This points towards a valuable improvement in the related work section, specifically suggesting a better organization or structure. Even though the suggestion is vague, it provides a direction for the author to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the results in Table 2 and asks a direct question about why uniform sampling isn't clearly outperforming, especially when topperforming architectures are close. This directly points to an actionable piece of information that needs clarification. The action is also concrete \u2013 they want to understand *why* uniform sampling isn't clearly outperforming.", "grounding_specificity_rationale": "The reviewer refers to 'Table 2' and 'good subregion' when expressing their confusion. This demonstrates that they are identifying specific parts of the paper being referenced. However, the reviewer does not explicitly state what they find problematic about the sampling methods in these specific areas. The grounding is present, but the specific issue being pointed out is not clearly defined, making it somewhat grounded but not fully grounded.", "verifiability_rationale": "The reviewer's statement about the results in Table 2 and their expected outcome is a statement of opinion or judgment about the paper's findings. It's not a claim that requires verification or support. The reviewer is expressing their interpretation of the results, not making a claim that needs to be proven.", "helpfulness_rationale": "The reviewer's confusion about the experimental results and their implications is not directly addressing a weakness or providing actionable feedback on how to improve the draft. They are seeking clarification on an existing result rather than pointing out a missing or unclear aspect. Therefore, the review point is not helpful in improving the draft itself."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states potential weaknesses of specific components of the method (itemoriented autoencoder, elementwise function, and the number of hidden units) as contributing to high time complexity. This is an explicit statement of how these components might be inefficient. However, the reviewer does not provide concrete details on *how* these components are inefficient or what specific actions the authors should take to address these issues. The suggestions are at a high level.", "grounding_specificity_rationale": "The reviewer explicitly names the 'itemoriented autoencoder', 'elementwise function', and 'number of hidden units' as potential sources of high time complexity. This demonstrates strong grounding as the reviewer can accurately pinpoint the referenced parts of the paper. However, the reviewer does not specify *what* is inefficient within these components or how they contribute to the high complexity. The specificity is limited to the components themselves, not the specific aspects within them that are problematic.", "verifiability_rationale": "The reviewer states a claim about the high time complexity. However, the reviewer does not provide any evidence or reasoning to support this claim. They suggest potential causes (too many users, elementwise cost, too many hidden units) but do not provide logical reasoning, common knowledge, or external references to back up these assertions. The claim is presented without sufficient justification.", "helpfulness_rationale": "The reviewer identifies potential areas for improvement and suggests *why* they might be inefficient (too many users, elementwise cost, too many hidden units). However, they do not *explain* *how* these inefficiencies manifest or *propose specific solutions*. The suggestions are at a high level and lack concrete details. The feedback is present but lacks the depth needed to fully empower the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'say pretrained solution encoders & solution decoders.\" This is a clear and direct instruction for the authors to modify their terminology. Once this action is identified, the authors know exactly what needs to be changed in their paper. The suggestion is not inferred but rather stated explicitly.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"pretrained solution encoders\" and 'solution decoders\". This directly identifies the specific part of the paper being addressed. The authors can easily pinpoint the section, table, or figure where these terms are used, providing clear grounding. The comment is not vague or ambiguous in its reference.", "verifiability_rationale": "The review point suggests improving the clarity of terminology. While it doesn't contain a direct claim in the sense of a statement requiring justification, it implies a suggestion that could be considered verifiable if the authors provide examples of where the ambiguity exists and how the suggested terminology resolves it. However, the primary focus of the review point is on the *what* (clarifying terminology) rather than the *why* of the clarity, which aligns more closely with the definition of grounding specificity.", "helpfulness_rationale": "The review point directly identifies a potential weakness in the paper (unclear figures) and offers a specific and actionable solution (clarify terminology). This is a clear and constructive suggestion that empowers the authors to improve their work. The reviewer is not just pointing out a problem; they are providing a concrete direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for information that, while not explicitly stated, is implied to be necessary for the implementation of the experiments. The authors are being implicitly asked to provide details on the computational resources required, which are crucial for understanding the practical aspects of the method. However, the point doesn't directly instruct the authors on *how* to improve their draft based on this information. It's asking for information that, if provided, could indirectly help them improve by making their method more reproducible and understandable.", "grounding_specificity_rationale": "The review point asks for information about the implementation of the experiments, which is directly related to the paper's methodology and results sections. The authors can reasonably infer where this information would be relevant. While it doesn't specify *which* experiments or *what* kind of hardware, the general area is clear. Therefore, the grounding is **weak**.", "verifiability_rationale": "The review point doesn't contain a claim in the sense of criticizing or recommending changes. It's a request for information that *should* be derivable from the paper or its supplementary materials. The verifiability concept doesn't directly apply here as there's no assertion being made. Therefore, it's **not applicable**.", "helpfulness_rationale": "The review point highlights a crucial area where the authors might be missing information necessary for the reproducibility and understanding of their experiments. It points to a practical gap in the paper's description. While it doesn't directly *teach* the authors how to improve their method, it identifies a potential weakness in the paper's completeness. This feedback is valuable for the authors to ensure their method is described clearly and completely. Therefore, it's **3**."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point directly addresses a specific implementation detail of the meta sampler and asks a clear question about its application. While it doesn't explicitly state an action to be taken, it points to a potential area of confusion for the authors regarding how the linear classifier is updated with fixed features. The reviewer requests clarification on 'when (which epoch) do the authors start applying the meta sampler?', which implies a specific step in their methodology that needs further explanation.", "grounding_specificity_rationale": "The review point explicitly mentions 'the meta sampler' and 'linear classifier', which are specific components of the methodology. The reviewer asks about the 'epochs' at which the meta sampler is applied, directly referencing a specific part of the paper where this process occurs. The grounding is clear as the reviewer directly refers to the components of the method being discussed.", "verifiability_rationale": "The review point is a question and a request for information, not a declarative statement containing a claim. It does not provide any evidence or reasoning to support a statement. Therefore, it does not have verifiability in the sense of supporting evidence. It's a request for clarification rather than a claim that needs verification.", "helpfulness_rationale": "This review point is 5 because it directly addresses a specific implementation detail of the meta sampler and asks a clear question about its application. By clarifying when the meta sampler is applied, the authors can better understand the decoupling process and how the linear classifier is updated. This clarification can resolve potential ambiguities in their own methodology and provide a concrete point of reference for future work or comparisons."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors used their own defined 'vanilla metric' and criticizes the lack of 'fairnessaware metrics like Equality odds (EO)'. This is a clear and actionable criticism. The reviewer suggests that the authors should have used standard fairness metrics. This provides a concrete direction for improvement.", "grounding_specificity_rationale": "The review point mentions 'related fairnessaware metrics like Equality odds (EO)' and suggests 'conducted more experiments on more datasets like COMPAS and Drug Comsumptionm'. This demonstrates some grounding as the reviewer refers to specific concepts and potentially specific datasets. However, it doesn't explicitly state which specific part of the paper the authors addressed. The reviewer implies the authors should have used these metrics and datasets, but doesn't pinpoint the exact location in their draft.", "verifiability_rationale": "The review point makes a claim about the authors' methodology: 'Authors use their own defined vanilla metric, and lack related fairnessaware metrics like Equality odds (EO)'. It also provides reasoning: 'Authors are encouraged to conduct more experiments on more datasets like COMPAS and Drug Comsumptionm, please kindly follow this AAAI paper which authors have cited: Exacerbating Algorithmic Bias through Fairness Attacks.' This reasoning is logical and supported by the cited paper, making the claim verifiable.", "helpfulness_rationale": "The review point clearly identifies a problem with the authors' methodology (using a custom metric and lacking fairness metrics) and provides a constructive suggestion for improvement (using standard fairness metrics and expanding experiments). The reviewer also recommends following a specific paper, which is a valuable resource. This constitutes helpful feedback that guides the authors towards better practices."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an improvement but doesn't specify how to implement it or verify the results. It's an observation about potential improvements rather than a direct instruction on how to improve the current work.", "grounding_specificity_rationale": "The review point doesn't explicitly mention any specific part of the paper. It's a general suggestion about exploring different positional embeddings.", "verifiability_rationale": "The review point is a suggestion, not a claim about the current paper. It proposes an alternative approach for future research without making a statement about the current work's validity or suggesting immediate improvements.", "helpfulness_rationale": "The review point offers a relevant suggestion for future work (exploring different positional embeddings) and a direction for validating performance improvements. However, it doesn't provide concrete steps for the authors to take *immediately* to improve their current draft. It's a suggestion for future research rather than immediate actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the missing element (value of neighborhood size h) and the need for analysis (influence on performance). It also points out the issue with inconsistent hyperparameter sets. However, it doesn't provide concrete actions on how to address these issues, such as suggesting a method for determining the value of h or how to use consistent sets. The comment is vague on how to implement the inferred action.", "grounding_specificity_rationale": "The comment explicitly mentions 'value of neighborhood size h' and 'influence over the model's performance', directly addressing specific parts of the paper. It also refers to 'different hyperparameter sets per dataset', which are unique elements. However, it doesn't specify *which* part of the paper contains these details or how to identify them. The grounding is present but not fully precise.", "verifiability_rationale": "The comment identifies a weakness in the paper (missing information about a key parameter and its influence). It also points out a potential issue with the methodology (inconsistent hyperparameters). However, it doesn't provide any external references or logical reasoning to support these claims. The comment is based on observation but lacks justification.", "helpfulness_rationale": "The comment identifies a clear weakness in the paper: the lack of information about the neighborhood size h and its influence, and the inconsistency of hyperparameters. It provides a suggestion for improvement: providing insights into how performance varies with a constant set of parameters. This directly addresses a practical concern for the author. The reviewer is essentially saying, 'You should explain this crucial parameter and its impact to make your method more robust and reproducible.'"}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer's point is a suggestion for analysis, not a direct instruction to modify their work. While the suggestion is clear, it doesn't explicitly state what needs to be done with the data or the SST dataset. The reviewer is proposing an investigation into the dataset's properties, but the action itself is not immediately apparent.", "grounding_specificity_rationale": "The reviewer explicitly mentions the SST dataset and the types of words (negation and intensity words) to analyze. This clearly identifies the specific part of the paper and the unique elements being addressed. The mention of 'phraselevel annotations' also helps in pinpointing the relevant data.", "verifiability_rationale": "The reviewer is suggesting a *potential* area for improvement in the authors' understanding of the SST dataset. While not a direct criticism or recommendation of a change, the suggestion itself requires the authors to perform a specific analysis (counting occurrences and their effect on polarity). This implies a verifiable claim about the dataset's characteristics.", "helpfulness_rationale": "The reviewer's point is not a direct criticism or recommendation of a change to the paper. It's a suggestion for further analysis of the dataset. While this analysis could be helpful for the authors' understanding, it doesn't directly guide them on how to improve their current draft. It points out a potential area for deeper exploration but doesn't offer immediate actionable steps."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'Authors don\u2019t verify the stability of the OGEAug on OOD benchmarks such as DrugOOD'. This clearly identifies an actionable step for the authors: to verify the stability. The suggestion to test on OOD benchmarks and specifically mention DrugOOD makes the action very clear and direct. The authors know exactly what they should do and how to apply it.", "grounding_specificity_rationale": "The review point explicitly mentions 'stability of the OGEAug' and suggests 'testing on OOD benchmarks such as DrugOOD'. The authors can easily identify the specific aspect of the model being addressed (stability of OGEAug) and the specific benchmark (DrugOOD) to test it. This indicates strong grounding. Furthermore, the suggestion to use DrugOOD provides specific guidance on how to address the identified issue.", "verifiability_rationale": "The review point implies a lack of verification regarding the stability of the OGEAug on OOD benchmarks. While it doesn't explicitly state a claim like 'Your method is wrong', it suggests a necessary step (testing on DrugOOD), which can be interpreted as a claim that the current assessment is lacking. The suggestion to use DrugOOD provides some level of support by offering a concrete example. However, the phrasing is more of a suggestion than a definitive statement requiring strong justification.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the authors: to verify the stability of the OGEAug on OOD benchmarks, specifically by testing on the DrugOOD dataset. This is a concrete and specific piece of feedback that directly addresses a potential area for improvement in the model's generalization capabilities. The suggestion to use DrugOOD provides a clear direction for the authors to take. This level of specificity and direction is 5 in guiding the authors towards improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the need to expand the related work section and compare to baselines, making it partially actionable. However, it lacks specific details on how to achieve these tasks, rendering it only 2.", "grounding_specificity_rationale": "The review point mentions the 'related work section' generally, without specifying which part or subsection. Similarly, the suggestion to 'Compare to the strong baselines that use the coordinates' is vague and lacks specific examples. This makes the grounding weak and the specificity lacking.", "verifiability_rationale": "The review point presents a suggestion (to expand related work and compare to baselines) without providing sufficient justification or evidence for why these steps are necessary or beneficial. The claim is present but lacks strong support.", "helpfulness_rationale": "The review point provides a clear direction for the authors, indicating where to look and what to compare. While it lacks specifics, it offers a valuable highlevel suggestion that can guide the authors' efforts."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem of single seed experiments and proposes a concrete solution by suggesting multiple seed experiments. The implications of this choice are also clearly articulated, making it actionable.", "grounding_specificity_rationale": "The reviewer refers to 'Single Seed Experiments' and elaborates on the consequences of this choice, making the grounding explicit and specific. The reviewer also explains *why* single seed is a problem ( difficulty assessing significance, impact of loss unclear) and *how* multiple seeds would help (robust evaluation, better understanding of convergence).", "verifiability_rationale": "The reviewer states a claim about the limitations of single seed experiments and provides logical reasoning (difficulty assessing significance, unclear impact of loss) and a proposed solution (multiple seeds) to support it. The reasoning is clear and wellarticulated.", "helpfulness_rationale": "The review point directly addresses a limitation and offers a clear, actionable solution. It is specific about the issue and provides a concrete suggestion, making it 5 and therefore very helpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that an entire multiGPU setup is required for the optimizations in the proposed method. While this identifies a problem, it does not provide any specific actions or suggestions for the authors to take to address this issue. The reviewer points out a limitation but does not offer any concrete steps or questions to help the authors improve their draft based on this observation.", "grounding_specificity_rationale": "The review point mentions 'optimizations in the proposed method' but does not specify which particular optimizations or where in the paper these optimizations are discussed. The reviewer makes a general statement about the requirement of a multiGPU setup without pinpointing the exact area or nature of the optimization. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part of the paper.", "verifiability_rationale": "The review point states a fact: 'An entire multiGPU setup is required for the optimizations in the proposed method...'. This can be considered a claim about the method's requirements. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a given fact without any justification.", "helpfulness_rationale": "The review point identifies a valid concern regarding the accessibility of the proposed method due to the requirement of a multiGPU setup. However, it fails to provide any actionable feedback or suggestions to the authors on how to address this limitation. The reviewer points out a practical issue but does not offer any constructive advice to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a preference for comparing with a system that captures semantics, which is an explicit action. However, the reviewer does not specify how the current system is currently lacking or what specific aspects need improvement. The suggestion to compare with Ref2 is a suggestion, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'semantics' and 'a system that also captures semantics' as context for the comparison. While they identify a specific area (semantics), they do not pinpoint a specific part of the current system or the baseline that needs improvement. The reviewer also suggests improvements ('even Ref2...can be a strong baseline...'), which is a general suggestion without specifying which aspects are lacking. The mention of Ref2 as a strong baseline is underspecific as it doesn't detail *how* it is a strong baseline.", "verifiability_rationale": "The reviewer states that 'As the current system captures the semantics through RNN based models.' This is a claim that the reviewer makes. However, they do not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestions to improve the system ('even Ref2...can be a strong baseline...') are helpful but do not inherently verify the initial claim about RNNs capturing semantics.", "helpfulness_rationale": "The reviewer offers concrete suggestions for improvement, such as 'even Ref2...can be a strong baseline...'. These suggestions are actionable and directly address potential weaknesses in the current system (lack of semantic understanding). The reviewer's suggestions are specific and point towards a concrete improvement (comparing with Ref2)."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The question asks 'why' the decoder at time step t uses only information till time step t. While the reviewer identifies a potential area for clarification, the action of explaining this choice is not explicitly requested or taken by the authors. The reviewer is seeking understanding, which the authors can address by providing a clear explanation of the underlying principles, such as causal language modeling or preventing future information leakage. The reviewer is not asking for a concrete action to be taken by the authors, but rather a clarification of a design choice.", "grounding_specificity_rationale": "The reviewer's question directly targets a specific design choice in the decoderdecoder model: why only use information up to the current time step. The authors can easily identify the specific part of the model and the information being used (up to time step t). This demonstrates strong grounding as the reviewer is asking about a specific, identifiable component of the model and its operation.", "verifiability_rationale": "The reviewer's question itself does not contain a claim that requires verification. It's a request for explanation of a design choice. Therefore, it is not '1'. However, the *answer* to this question could be verifiable if the authors can explain the underlying principles (e.g., causal language modeling, preventing future information leakage). Without that explanation, the question is not verifiable.", "helpfulness_rationale": "The question is very specific and directly addresses a potential technical detail that could be confusing for the authors. Authors are likely to find this helpful if they can provide a clear and concise explanation of the reasoning behind using only past information. The helpfulness depends on the authors' ability to provide a clear and useful explanation. The reviewer is not asking for a concrete action to be taken, but rather a clarification of a design choice that is likely relevant to the model's operation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a potential confounding factor (different head locations) in the ablation study and proposes a concrete solution by suggesting a controlled baseline that ablates heads at different locations within the model. The reviewer directly addresses a specific issue and offers a clear action.", "grounding_specificity_rationale": "The review point explicitly mentions 'head location' as a confounding factor and suggests 'ablated heads at different locations in the model' as a control. The grounding is explicit and directly refers to the specific part of the model being considered. The specificity is high as it names the exact type of control being proposed.", "verifiability_rationale": "The review point provides a clear and logical suggestion for a control experiment. It is based on the understanding of how induction heads and Fvalue (FV) heads function and proposes a welldefined methodology to isolate the effect of head location. The reasoning is sound and directly addresses the identified issue.", "helpfulness_rationale": "This review point is 5 for the authors who are conducting ablation studies. It directly addresses a potential flaw in their methodology (different head locations) and provides a clear and actionable suggestion for a control experiment. This helps the authors design a more robust and reliable study, increasing the validity of their conclusions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that a section is missing, which is an explicit action. However, it doesn't specify what is missing or how to implement it, making it somewhat vague.", "grounding_specificity_rationale": "The comment explicitly mentions 'a section on synonym identification is missing,' which clearly identifies the specific part of the paper being addressed. It also specifies the unique aspect being addressed (synonym identification). This is 5.", "verifiability_rationale": "The comment is a factual statement about the absence of a section, not a claim that requires verification. Therefore, it has X and is classified as 'X'.", "helpfulness_rationale": "The comment points out a specific omission that could be relevant to the reader. While it doesn't directly teach anything, it highlights a potential gap in the information provided. It's more of a reminder or information gap, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action: 'An overview of the workflow and the model, which can make it easier to get the whole picture of the work, is needed.' However, it does not specify how this overview should be structured or what specific aspects of the workflow or model need an overview. This makes the action vague and lacking detail on how to apply it.", "grounding_specificity_rationale": "The authors cannot confidently determine which part the comment addresses. The comment refers to 'workflow' and 'model' in general, without specifying a particular section, table, figure, or unique element of the paper. The comment specifies what needs to be addressed in this part (an overview), but not which part it is referring to.", "verifiability_rationale": "The comment does not contain a claim. It is a suggestion for improvement, not a critique or criticism of the paper. Therefore, it cannot be verified or unverified.", "helpfulness_rationale": "The comment identifies a weakness or improvement area (the lack of a clear overview of the workflow and model) but is vague and lacks clarity. It does not provide specific guidance on how to create this overview or what information should be included. This makes it less helpful for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a specific technical issue regarding the computation of the statistical dimension d_lambda and its implications for the debiasing sketching approach. While the reviewer doesn't explicitly state an action to be taken, the mention of 'I couldn't find this issue discussed in the paper' implies a potential action the authors could take, such as trying to approximate d_lambda or exploring alternative methods. The reviewer also suggests a potential issue with computing the surrogate sketch, further indicating a potential action. However, the lack of a clear, direct action or suggestion makes the actionability somewhat borderline.", "grounding_specificity_rationale": "The reviewer raises a concern about the practicality of computing the statistical dimension d_lambda. While the reviewer doesn't explicitly state that the paper fails to identify the specific part of the paper being addressed, the reviewer's point is about a *specific* detail (computing d_lambda) that isn't addressed in the paper. The reviewer's statement 'I couldn't find this issue discussed in the paper' implies a lack of grounding in the specific technical details. The paper should ideally discuss the feasibility of computing d_lambda and its impact on the method. The reviewer's point is about a *specific* detail that is missing, making it somewhat grounded but also somewhat ungrounded in the context of the specific technical detail.", "verifiability_rationale": "The reviewer presents a claim about a potential issue with the practicality of the method, specifically the difficulty of computing the statistical dimension d_lambda and the surrogate sketch. The reviewer *claims* that this issue is not discussed in the paper. While the reviewer doesn't provide evidence to *verify* this claim, the implication is that the paper *should* address the feasibility of these computations. The reviewer's point is about a missing discussion, which makes it 3 if the paper were to address this. The reviewer is pointing out a potential gap in the paper's discussion of the method's practicality.", "helpfulness_rationale": "The reviewer's overall assessment is that the comment is 'unhelpful'. While the reviewer raises valid technical concerns about the practicality of the method and points out a missing discussion, the lack of evidence to support the claim that the paper *doesn't* discuss these issues makes the helpfulness somewhat borderline. The reviewer's comment is valuable in identifying potential limitations and areas for improvement, but without concrete suggestions or verifications, it might not be fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The comment explicitly states 'redfine the figure' and clearly identifies the issue (scalars shown as vectors) and the desired outcome (expected quantities as scalars).", "grounding_specificity_rationale": "The comment explicitly mentions 'figure3', allowing the authors to accurately locate the relevant figure. The comment clearly identifies the issue (scalars being vectors) and suggests a specific improvement (expected quantities as scalars).", "verifiability_rationale": "While the comment points out a potential source of confusion, it doesn't provide a definitive justification for why showing scalars as vectors is inherently incorrect. The suggestion is more of a recommendation for improved clarity rather than a claim requiring verification.", "helpfulness_rationale": "The comment directly suggests a concrete improvement to the figure's presentation, which is likely to be beneficial for the authors in terms of clarity. While it doesn't guarantee the figure is correct, it provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'no empirical evidence is provided' and 'it would have been interesting for the authors to look deeper into this.' This indicates an implicit action of suggesting the authors conduct empirical testing. However, the action of 'looking deeper' is vague and doesn't specify how to implement this, making it only partially actionable. The suggestion about frequent word pairs is also vague and lacks concrete steps.", "grounding_specificity_rationale": "The comment mentions 'lowfrequency words,' 'sememes,' and 'word similarity data sets.' While it identifies the general area of concern, it doesn't pinpoint a specific section, table, or unique aspect of the paper being addressed. The grounding is weak because the authors can only infer the relevance of these terms. The specificity of the issue is also vague, as it doesn't clearly explain how these factors relate to the specific experimental setup or results.", "verifiability_rationale": "The comment contains a claim: 'a reasonable argument is made that the proposed models are particularly useful for learning representations for lowfrequency words (by mapping words to a smaller set of sememes that are shared by sets of words). Unfortunately, no empirical evidence is provided to test the hypothesis.' This claim is partially verifiable. While the reviewer suggests that frequent word pairs in datasets might explain the improvements, this is a suggestion for investigation rather than a direct verification of the initial claim. The reasoning is present but lacks detailed explanation or references.", "helpfulness_rationale": "The review points out a valid weakness: the lack of empirical support for the sememe mapping hypothesis. This is a valuable observation for the authors. However, the suggestions are very general. The reviewer suggests 'looking deeper' and mentions 'frequent word pairs.' While these are relevant points, they don't provide concrete steps or a specific methodology for the authors to follow. The helpfulness is limited because the suggestions are not detailed enough to be immediately actionable."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks about the 'resolution of the 3D voxel' and its 'importance'. They also suggest an 'experiment comparing different resolutions of voxel features'. These are concrete actions with clear directions. The reviewer identifies a potential limitation (the high computational cost of voxels) and proposes a specific method to investigate it (varying resolutions). The suggestions are directly actionable for the authors.", "grounding_specificity_rationale": "The reviewer asks about the 'resolution of the 3D voxel' and its 'importance'. While the *concept* of global features is implied, the *specific* parts of the method being questioned (voxel resolution) are clearly referenced within the method description. The reviewer doesn't explicitly point to a specific section, table, or unique aspect of the paper by name, making the grounding weaker. However, the questions are specific to this aspect of the method, making the grounding somewhat clear once the reviewer focuses on the voxel resolution.", "verifiability_rationale": "The reviewer makes a claim about the 'computational cost of voxel features' and suggests a 'study comparing different resolutions of voxel features' to investigate the importance of global features. This claim is supported by the suggestion of an experiment. However, the claim itself doesn't provide direct evidence or justification. The suggestion acts as a logical step to investigate the claim, making it 3. The reviewer doesn't provide specific references or examples to support the claim about computational cost.", "helpfulness_rationale": "The reviewer provides specific questions about the 'resolution of the 3D voxel' and its 'importance'. They also suggest a concrete experimental comparison ('different resolutions of voxel features') to study the 'importance of the global feature'. This directly addresses a potential limitation of the method and provides a clear path for further investigation. The suggestions are directly actionable and directly related to the method being discussed. The reviewer's point is very focused and directly relevant to the method's description."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a potential area for improvement (developing set trends) related to the presented results in Table 3. However, it doesn't explicitly state the steps to take or the specific analysis to perform. The suggestion is implied rather than explicitly stated as an action.", "grounding_specificity_rationale": "The comment explicitly refers to 'Table 3' and mentions 'PM+CL' and 'PM or CL alone'. This indicates a clear identification of the specific part of the paper being addressed, fulfilling both the 'Weak Grounding' and 'Full Grounding' criteria. The specific elements being compared are also mentioned, adding to the specificity.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a statement of observation ('It\u2019s hard to see trends here') and a suggestion for further analysis ('It would be interesting to see development set trends...'). There is no logical reasoning, common knowledge, or external references provided.", "helpfulness_rationale": "The comment identifies a potential area for improvement (analyzing development set trends) related to the presented results in Table 3. This suggests a constructive suggestion aimed at clarifying and strengthening the analysis of the presented work. While it doesn't provide a definitive answer, it offers a concrete direction for the authors to explore further."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out two issues: (1) difficulty understanding Figure 5 and (2) the metrics being compared to remaining weights. For (1), the reviewer explicitly states the figure is 'difficult to understand' and 'a lot of lines on top of each other'. This is an explicit action, but it's vague as the reviewer doesn't specify what needs to be done to improve the figure's clarity. For (2), the reviewer explicitly states the metrics are 'compared to remaining weights' and suggests reporting 'flops or model size'. This is also an explicit action and is concrete as it suggests specific alternative metrics. Therefore, the reviewer points out issues that are either implicitly stated (vague) or explicitly stated and concrete.", "grounding_specificity_rationale": "For Figure 5 clarity, the reviewer explicitly mentions 'Figure 5' and the issues 'difficult to understand' and 'a lot of lines on top of each other'. This indicates a strong grounding as the reviewer identifies the specific figure. However, the grounding is underspecific as the reviewer doesn't pinpoint the exact issue within the figure (e.g., specific overlapping lines). For the metrics reporting issue, the reviewer refers to 'the main metrics' and 'remaining weights' without specifying which metric or weight is causing the problem. They also suggest adding 'flops or model size' without specifying which one. This indicates weak grounding as the reviewer doesn't identify the exact metric or the exact figure/table where this information is missing. The specificity is underspecified as the reviewer doesn't detail what is missing or why it's important.", "verifiability_rationale": "For Figure 5 clarity, the reviewer states 'it is difficult to understand' and 'a lot of lines on top of each other'. This is a claim, but the reviewer does not provide any evidence or reasoning to support this claim. For the metrics reporting issue, the reviewer states 'the main metrics reported are performance compared to remaining weights' and suggests 'flops or model size'. This is also a claim, and the reviewer does not provide any evidence or reasoning to support this claim. Therefore, both issues are 1 as the reviewer doesn't provide logical reasoning, common knowledge, or external references to support their claims.", "helpfulness_rationale": "The reviewer points out two issues: (1) difficulty understanding Figure 5 and (2) the metrics being compared to remaining weights. For (1), the reviewer identifies a problem with a specific figure and suggests improvements. For (2), the reviewer identifies a gap in the reported metrics and suggests concrete alternatives. Both points are actionable and provide guidance for the authors to improve their draft, making them helpful."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The comment states, 'Some details of the proposed method are missing, as noted in the questions section below.' This is a general statement pointing to a location where information is lacking. While it identifies a problem, it doesn't explicitly state what is missing or where in the questions this information can be found. Therefore, it is not an explicit action, nor is it a direct instruction on what to do. It is more of a pointer than a direct action.", "grounding_specificity_rationale": "The comment, 'Some details of the proposed method are missing, as noted in the questions section below,' does not explicitly identify the specific part of the paper where the details are missing. While it refers to the 'questions section,' it doesn't pinpoint the exact location within that section where the anticipated questions relate to the missing details. Therefore, the grounding is weak as the specific part is not clearly identified.", "verifiability_rationale": "The review point is a factual statement: 'Some details of the proposed method are missing, as noted in the questions section below.' This statement can be verified by the existence of a 'questions section' where the reviewer anticipates questions about the missing details. While it doesn't provide specific examples, it is supported by the logical implication that a 'questions section' exists and contains questions about the method. Therefore, it is verifiable but lacks specific examples or references.", "helpfulness_rationale": "The review point points out the absence of details in the proposed method. This directly relates to the author's ability to understand and implement the proposed approach. While it doesn't explicitly state that the method is unclear or incorrect, the missing details could lead to that perception. Therefore, it is a relevant comment that could potentially help the author identify a problem with their work, making it 3, although it could be more direct."}
{"actionability_label": "3", "grounding_specificity_label": "3: Partially Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer's suggestion is presented as a desire for additional experiments and comparisons, rather than a direct criticism of what's already done. While it implies a need for more information, it doesn't explicitly state what action needs to be taken or how to achieve it. Therefore, it can be considered **Implicit**. The suggestion is also **Vague** as it doesn't specify the datasets or the methodology for comparison.", "grounding_specificity_rationale": "The reviewer refers to 'the evaluation on oversmoothing' without explicitly naming a section, table, or figure. This makes the grounding **Weakly Grounded**. However, the reviewer then specifies the comparison with 'variants focusing on dealing with oversmoothing, such as the setting used in GCNII.' This provides some level of specificity within the general area of evaluation, making it **Partially Specific**.", "verifiability_rationale": "The reviewer presents a suggestion for the authors to conduct further experiments and comparisons. This can be considered a **Claim** that the authors would benefit from these additional experiments. The verifiability of this claim is **Partially Verifiable**. While the suggestion is clear, it lacks specific justification or references within the review point itself. The reviewer's belief in the usefulness of these experiments is based on their understanding of the topic, not explicitly stated evidence within this review point.", "helpfulness_rationale": "The reviewer's intent is to provide guidance to the authors on how to improve their evaluation. This is a positive intent. However, the suggestion is **Vague** and lacks concrete details. It doesn't specify which datasets to use, how to compare the performance, or what specific improvements to expect. Therefore, while the intent is helpful, the lack of concrete details makes it **3**."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'Figure 4 is confusing' and 'it's not clear what the columns mean.' This directly points to a specific area needing improvement. The action is to clarify the columns, which is a concrete step.", "grounding_specificity_rationale": "The reviewer directly refers to 'Figure 4' and then specifically points to the 'columns' within that figure. This demonstrates a clear and precise identification of the relevant part and the specific issue. The grounding is strong because the section and the specific element are mentioned.", "verifiability_rationale": "The reviewer identifies a weakness in the paper (confusion about Figure 4) and suggests an improvement (clarify the columns). This constitutes a claim. While the reviewer doesn't provide a specific example of *how* the columns are confusing or *why* they need clarification, the *impact* on the authors is clear. The verifiability is somewhat dependent on the authors' ability to interpret the figure themselves. However, the reviewer's point about the columns being unclear is a verifiable observation about the paper's content.", "helpfulness_rationale": "The reviewer directly points out a weakness in the paper (confusion about Figure 4) and suggests a concrete improvement (clarify the columns). This is a clear and actionable feedback that directly addresses a specific issue. The reviewer's suggestion is directly aimed at improving the clarity of a specific element in the paper, making it 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem: 'the lack of ablation analysis (in the main paper) makes it very difficult to pinpoint from which component the small performance gain is coming from.' The reviewer also suggests a solution: 'it makes it easier to pinpoint the source of performance gain.' This is an explicit statement of the issue and a direct suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The reviewer mentions 'lack of ablation analysis' but does not specify which part of the paper this analysis should be performed on. They also do not identify any specific components or details of the ablation analysis. The reviewer's comment is general and lacks the specificity needed to pinpoint the exact area of concern. While the reviewer implies the importance of this analysis, they do not clearly state what is missing or what specific aspect needs clarification within the context of ablation analysis.", "verifiability_rationale": "The reviewer states a problem: 'the lack of ablation analysis (in the main paper) makes it very difficult...'. This is a claim that something is missing and will cause problems. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as an observation rather than a welljustified argument.", "helpfulness_rationale": "The reviewer points out a potential missing element (ablation analysis) and suggests its inclusion. This is a constructive suggestion aimed at improving the paper. While the suggestion might not be the most comprehensive, it is specific and actionable, directly addressing a potential weakness in the analysis. The reviewer's comment provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review explicitly states the finding of experiment 2 and its implication regarding the noise rate. However, it doesn't tell the authors what specific action they should take based on this finding. The actionable step is implied but not clearly defined.", "grounding_specificity_rationale": "The review specifies the condition of the experiment ('number of classes > 8') and the comparison being made. However, it refers to 'experiment 2' without explicitly stating the section, table, or unique aspect where this experiment is located. The grounding is weak because the authors need to infer the location.", "verifiability_rationale": "The review makes a claim about the results of experiment 2. However, it doesn't provide any reasoning or justification *within the review itself* to support this claim. The reviewer assumes the reader will have access to experiment 2 to verify the findings.", "helpfulness_rationale": "The review points out a specific experimental result that could be relevant to the authors. However, it doesn't provide any clear guidance on how the authors should use this information or what specific changes they should consider. The mention of 'Th.' is vague and lacks context."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action of comparing the model trained on the original dataset with the model trained on the mixture of the original and adversarial examples. This action is clearly defined and actionable for the authors. The language used, such as 'compare the model trained on the original dataset with that trained on the mixture', directly indicates the intended modification.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the original training set' and 'the adversarial set' in the paper. These are specific sections of the paper, and the reviewer also mentions 'augmented adversarial examples', which further specifies the aspect being addressed. The information provided is precise and directly points to the relevant parts of the paper.", "verifiability_rationale": "The reviewer makes a judgment about the importance of the experiment, stating 'It is critical to make it more convincing.' This constitutes a claim that requires some level of justification. The reviewer then suggests 'It is better to compare the model trained on the original dataset with that trained on the mixture', which provides a method for verifying the claim. While the claim itself isn't directly supported by external references in the review point, the suggestion offers a pathway to confirm the impact of the augmented adversarial examples.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion to improve the paper by conducting a specific experiment: comparing models trained on the original and mixed datasets. This directly addresses a potential weakness in the current experimental setup. The suggestion is specific and provides a concrete direction for the authors to follow, making it 5 in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states 'The CNN experiments are not fully convincing' which is a subjective opinion. While this opinion could lead to suggestions, the point itself does not explicitly state what needs to be done or how to improve the CNN experiments. It lacks a direct action or concrete steps for the authors.", "grounding_specificity_rationale": "The review point refers to 'the CNN experiments' generally. It does not specify which particular experiments are being discussed, nor does it pinpoint any specific aspect of the CNN architecture, training, or results. The reference is broad and lacks precision.", "verifiability_rationale": "The review point contains a claim ('The CNN experiments are not fully convincing') but does not provide any supporting evidence or justification for this statement. There are no logical reasoning, common knowledge, or external references provided to back up the claim. The statement is presented as an opinion without any supporting data or examples.", "helpfulness_rationale": "The review point expresses a negative opinion about the CNN experiments ('not fully convincing') without offering any specific suggestions or pointing out particular weaknesses. It is a critique rather than a constructive feedback. The reviewer does not provide any actionable steps for the authors to improve their work based on this point."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing with SoTA approaches, which is a valid piece of advice. However, it doesn't explicitly state how to go about comparing or what specific comparisons would be beneficial. It's a suggestion but lacks the concrete steps needed for action.", "grounding_specificity_rationale": "The review point is very general and doesn't mention any specific section, table, figure, or element of the paper. It's a broad statement about the need to compare with SoTA approaches, lacking any grounding of where this comparison should be made or what aspects are important.", "verifiability_rationale": "The review point is a suggestion, not a claim that needs verification. It doesn't make a judgment about the current work or propose a solution.", "helpfulness_rationale": "The review point suggests comparing with SoTA approaches, which is generally helpful for identifying weaknesses and guiding improvements. However, it's a very general suggestion and lacks specific details on how to compare, why it's important, or how it will lead to concrete improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point asks a 'why' question about the choice of freezing versus adaptive MLS. While it identifies a gap in understanding, it doesn't explicitly state what the authors *should* do. The answer would likely involve further investigation or justification of the freezing method. The question is valid but doesn't provide a specific, actionable suggestion. The authors would need to *research* or *experiment* to find the answer.", "grounding_specificity_rationale": "The review point refers to 'MLS selection' in general, without specifying which section or table within the MLS method it's referring to. The abbreviation 'MLS' could refer to different things in different contexts. The reviewer doesn't provide enough information to pinpoint the exact location within the MLS method.", "verifiability_rationale": "The review point presents a question about the rationale behind using freezing in MLS selection. This is a statement that requires explanation or justification. The reviewer is asking for *why* something is the case, implying a lack of clarity. The reviewer isn't providing evidence or references to support their point. They are asking a question that the authors should be able to answer.", "helpfulness_rationale": "The review point identifies a valid concern and asks a relevant question. While it doesn't directly tell the authors what to do, it points to a potential area for improvement in the authors' understanding or methodology. It's a constructive feedback point. The question is valid and could lead to improvements in the authors' work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a suggestion for analysis but lacks specific details on *how* to perform this analysis. While the intent is clear, the action is implicit. The reviewer suggests 'performing an analysis on the proposed knowledgeCLIP model that combines image, text and KGs' and draws a parallel to a specific existing work and analysis. However, the exact steps or methodology for this analysis are not provided.", "grounding_specificity_rationale": "The reviewer mentions 'the proposed knowledgeCLIP model' which is a specific part of the paper. They also reference a specific existing work and a type of analysis ('adding negation or changing entities in text'). This demonstrates a degree of grounding as the reviewer refers to a specific model and a particular type of analysis. However, the exact *issue* the proposed model is supposed to solve is not explicitly stated, making the grounding less precise.", "verifiability_rationale": "The reviewer's suggestion to 'perform an analysis on the proposed knowledgeCLIP model that combines image, text and KGs' and to 'see if the KGaugmented method can robustly handle them' is a suggestion for an experiment or analysis. While the reviewer draws a parallel to a related work, the claim itself is novel and based on a proposed model. There are no explicit references to external works or logical reasoning provided to support this claim. The verifiability relies on the authors' own implementation and observation, which is not readily available to the reviewer.", "helpfulness_rationale": "This review point is highly relevant and potentially valuable for the authors. It suggests a specific type of analysis (negation/entity changes) on a related model (text+KG) to test the robustness of the proposed imagetextKG model. This is a concrete suggestion and could help identify potential weaknesses or areas for improvement. The reviewer is also drawing a connection to a related existing work, which is a good practice for contextualizing the research. The suggestion is specific enough to guide potential experiments."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides specific examples of potential issues and suggests concrete improvements. For instance, they point out the inconsistency in notation in Eq. 3 and suggest adding variance in Alg. 2. These are explicit actions the authors should take, making the comment actionable.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Eq. 3' and 'Alg. 2' by name, clearly identifying the parts of the paper they are discussing. They also explain *why* the notation in Eq. 3 is confusing and *why* adding variance in Alg. 2 would be beneficial, providing clear details on the issue and the proposed solution. This strong grounding and specificity indicate a high level of grounding specificity.", "verifiability_rationale": "The reviewer makes specific claims about the issues in the paper, such as the confusion in 'Eq. 3' and the potential improvement from adding variance in 'Alg. 2'. They also claim that using \u03bc_g is consistent with 'Eq'. These are claims that can be supported by logical reasoning, common knowledge (or lack thereof in this case), or external references (if applicable, though not explicitly provided in the review point itself). The reviewer provides explanations for their claims, making the verifiability high.", "helpfulness_rationale": "The reviewer provides concrete suggestions for improvement, such as adding variance in 'Alg. 2'. They also point out a potential notational inconsistency in 'Eq. 3' and suggest using \u03bc_g for consistency. These suggestions are directly actionable and address potential weaknesses in the paper, making the review point 5."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their desire for a more comprehensive discussion on computational cost and complexity. This is a clear indication of an actionable suggestion that is directly related to the paper's content. The reviewer is proposing a specific improvement: adding a section or subsection dedicated to this topic.", "grounding_specificity_rationale": "The reviewer directly refers to 'computational cost,' 'computational complexity,' and 'scalability.' These are specific aspects of the method that the reviewer wants the paper to address. The reviewer is not just pointing out a problem but also specifying *where* the problem lies within the paper's content. This indicates strong grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the 'additional cost' leading to 'significant delays in computation.' This is a claim that needs to be supported by evidence or reasoning. However, the reviewer themselves do not provide any evidence or reasoning to support this claim within the review point itself. The reviewer is highlighting a potential gap in the paper's justification for this statement, making the claim 1 based on the provided text.", "helpfulness_rationale": "The reviewer's point directly addresses a practical concern (computational cost) that is relevant to the paper's contribution. The reviewer is suggesting a concrete improvement: adding a discussion about this aspect. While the paper doesn't currently provide this information, the reviewer's suggestion is a clear and actionable way to enhance the paper's completeness and practical relevance. The lack of verifiability in the reviewer's own claim doesn't negate the helpfulness of pointing out this gap."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the issue: 'how novel values in the test set are handled.' This clearly identifies an action the authors should take: 'explain how'. Therefore, the action is explicit. While the action itself is not very concrete (it doesn't specify *what* needs to be explained), the action is clearly defined. The reviewer is pointing out a missing piece of information, making it 3.", "grounding_specificity_rationale": "The review point refers to 'novel values' within the 'test set'. While it doesn't explicitly name a specific section or table, the concept of 'novel values' within a 'test set' is quite specific. The reviewer is pointing to a particular aspect of the data. The comment also implies that the authors should be able to identify these novel values. Therefore, the grounding is strong. The specificity is also good as it points to a specific area of the data (test set) and a specific type of value (novel).", "verifiability_rationale": "The review point itself does not contain a definitive claim or suggestion. It's a request for clarification on how 'novel values in the test set are handled'. While it implies a lack of clarity in the current description, it doesn't explicitly state that something is wrong or needs to be improved. Therefore, it doesn't have strong verifiability on its own. However, the request implies that the authors should be able to provide an explanation, which could be considered a form of implicit verification. Therefore, it's 2.", "helpfulness_rationale": "The review point directly addresses a potential ambiguity in the implementation by asking for clarification on how 'novel values in the test set are handled'. This is a specific and actionable request that would likely improve the clarity and reproducibility of the work. It points to a concrete area where the paper could be improved in terms of clarity and reproducibility. Therefore, it is 5 as it directly addresses a practical concern."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper lacks a 'lack of indepth analysis on experimental results'. This directly points to a specific area for improvement and provides a clear direction for the authors to follow. The reviewer also gives an example of the inconsistent performance gains, which further clarifies the nature of the missing analysis. The action is to conduct a more detailed analysis of the experimental results, considering why the improvements are limited on one dataset and significant on another.", "grounding_specificity_rationale": "The reviewer mentions 'experimental results' generally. While they provide an example of the *nature* of the results (limited improvements on offense detection and significant on coarse stereotype set), they do not explicitly identify the specific section, table, or figure where this analysis is lacking. The grounding is present in the *topic* of the analysis, but it is not as precise as it could be.", "verifiability_rationale": "The reviewer makes a claim that there is a 'lack of indepth analysis on experimental results'. This is a claim that needs to be supported. However, the reviewer does not provide any specific evidence *within this review point* to back up this claim. While the example of inconsistent performance gains could potentially be used as evidence elsewhere, it is not explicitly stated as evidence *here*. The reasoning is that the claim is made without sufficient support within the review itself.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper: the lack of indepth analysis of the experimental results. They also provide a specific example of this weakness, highlighting the inconsistent performance gains across different datasets. This is a valuable piece of feedback because it directly points to an area where the authors can improve their paper. The reviewer's suggestion to analyze why the improvements are limited on one dataset and significant on another is a concrete direction for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states \"Use modern backbone baselines (say, Resnet50 or DenseNet121)\". This is a clear, explicit action. It also mentions \"3 conv layers is definitely too small for anything nonsynthetic,\" which provides a concrete reason for the recommendation.", "grounding_specificity_rationale": "The review point mentions \"Resnet50\" and \"DenseNet121\" as examples of \"modern backbone baselines.\" This directly grounds the suggestion in specific model architectures. It also refers to \"3 conv layers\" as being \"too small for anything nonsynthetic,\" which grounds the criticism in a specific architectural detail.", "verifiability_rationale": "The review point makes a claim: \"I have to say that even given this version of the idea, I am skeptical this would work.\" This is a subjective statement about the likelihood of success. It then provides justification: \"lots of such robustness/domain invariance interventions have been proposed and have failed.\" This justification provides some support for the skepticism.", "helpfulness_rationale": "The reviewer offers specific suggestions for improvement (modern backbones) and critiques a specific aspect of the proposed method (\"3 conv layers\"). However, the overall tone is critical ('skeptic this would work\"), which might limit the immediate helpfulness in understanding *why* this specific version of the idea is unlikely to be effective."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment implicitly suggests a potential weakness in the experimental setup by highlighting the extensive hyperparameter search and the lack of similar tuning for the baseline. While it doesn't explicitly state an action like 'Add a new hyperparameter', the implication is that the baseline needs more thorough tuning. The action is somewhat vague as it doesn't specify *how* the baseline should be tuned differently.", "grounding_specificity_rationale": "The comment mentions 'multiple hyperparameters' and 'extensive hyperparameters search', which provides some grounding by referencing specific aspects of the paper's methodology. However, it doesn't pinpoint a specific section, table, figure, or unique element being addressed. The grounding is weak because it refers to general processes rather than a concrete part of the paper.", "verifiability_rationale": "The comment makes a judgment about the baseline potentially being undertuned, which can be considered a claim. It suggests a *recommendation* based on common practice, which can be seen as supported by logical reasoning (the potential for unfair comparison). However, it doesn't provide specific examples or external references to back up this claim about the baseline's tuning.", "helpfulness_rationale": "The review point identifies a potential weakness in the experimental setup by pointing out the lack of fair hyperparameter tuning for the baseline. It suggests a solution by recommending a more extensive search. This provides actionable feedback on how the baseline might be improved. While it doesn't specify *how* to implement this recommendation, it clearly highlights a potential area for improvement in the experimental design."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two explicit statements: \n1. \"Perplexity is the probability that the model generates the current sentence\" which is a clear and direct identification of a potential action the authors should take (correct the definition). \n2. \"This is not what perplexity is. Eq1  This does not look like perplexity either, this looks like crossentropy.\" This is an explicit statement of an action the authors should take (correct Eq1). The reviewer clearly identifies actions or suggests actions that are direct or apparent. Authors can easily identify modifications they should apply to their draft based on these statements. The actions are also concrete, as the reviewer specifies *what* is incorrect and *what* it should be replaced with (crossentropy).", "grounding_specificity_rationale": "The reviewer explicitly refers to \"L259\" and \"Eq1\", which are specific locations in the paper. This demonstrates strong grounding as the reviewer can accurately pinpoint the sections being addressed. The reviewer also provides specific examples of what they believe the content at these locations should be (the incorrect definition of perplexity and the incorrect classification of Eq1). This further enhances specificity.", "verifiability_rationale": "The reviewer presents two clear claims: \n1. \"Perplexity is the probability that the model generates the current sentence\" which can be verified by checking the definition of perplexity in the paper. \n2. \"Eq1  This does not look like perplexity either, this looks like crossentropy\" which can be verified by examining the content of Eq1 and comparing it to the standard definition of crossentropy. The claims are wellsupported by logical reasoning and external references (in this case, the paper's own content). The reviewer provides specific examples and references (the paper's content at L259 and Eq1) to support their claims.", "helpfulness_rationale": "The reviewer's point is 5 because it directly addresses potential misunderstandings or errors in the paper's description of perplexity and crossentropy. By highlighting the discrepancy, the reviewer is directly informing the authors about a potential area of confusion or incorrect information. This can help the authors clarify their understanding and ensure they are using the correct concepts. The reviewer's feedback is specific and directly addresses a potential issue that could hinder the authors' work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'the compared baseline is not sufficient' and 'such as MVGRL4, gptgnn5 are missing'. This indicates an explicit action being taken \u2013 the authors should add more baselines. The suggestions are direct and actionable, such as 'add more baselines of graph contrastive learning' and 'test them on some common datasets'.", "grounding_specificity_rationale": "The review point explicitly mentions 'graph classification task' and names specific missing baselines 'MVGRL4' and 'gptgnn5'. This clearly identifies the specific part of the paper and the specific issue being addressed. The suggestion to 'test on some common datasets' further grounds the recommendation.", "verifiability_rationale": "The review point makes a claim that 'the compared baseline is not sufficient' and provides examples of missing baselines 'MVGRL4' and 'gptgnn5'. While it doesn't provide a formal proof, it offers concrete examples that could be investigated to verify the insufficiency of the baselines.", "helpfulness_rationale": "The review point directly addresses a potential weakness in the experimental setup (insufficient baselines) and offers concrete suggestions for improvement. The language is clear and directly actionable for the authors. It provides a clear direction for the authors to potentially strengthen their work."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a potential weakness in the evaluation of defense strategies by suggesting an alternative attack scenario. While it points out a *possibility*, it doesn't explicitly state an action the authors should take or how to address this. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The review point mentions 'purify the input image' and 'edge map based defense strategies'. It refers to *types* of defenses and attacks, providing some grounding. However, it doesn't specify a *particular* purification method or a *specific* edge map defense strategy, making the grounding less precise.", "verifiability_rationale": "The review point proposes a potential attack scenario but doesn't provide any concrete evidence or reasoning to support it. It's a hypothesis about a *potential* weakness, not a verifiable claim with supporting arguments or references.", "helpfulness_rationale": "The review point identifies a potential area for improvement in the evaluation of defense strategies by suggesting an alternative attack. However, it lacks specific details about the 'purify the input image' method, the 'edge map based defense strategies', and the 'adaptive attack'. Without these specifics, the reviewer doesn't provide actionable feedback on how the authors should implement or evaluate these strategies. The weakness is identified, but the path to improvement is vague."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing information ('standard deviations') and the consequence of this missing information ('making it hard to judge the significance of the results'). This directly points to an actionable item for the authors to include in their experimental results section. The reviewer clearly identifies what is missing and what impact it has, providing a concrete action for the authors.", "grounding_specificity_rationale": "The review point refers to 'the experimental results' as the part of the paper being addressed. While the reviewer identifies a deficiency, they do not specify *which* aspect of 'the experimental results' lacks standard deviations. The reference is broad and doesn't pinpoint a specific element like a table, figure, or analysis section. Therefore, the grounding is weak as the authors cannot confidently determine where the issue lies.", "verifiability_rationale": "The review point makes a claim about the experimental results lacking standard deviations and the consequence of this lack being the difficulty in judging the significance of the results. The reviewer states this directly and implies the connection between the missing information and the difficulty in judging significance. While the implication is that the lack of standard deviations makes judging significance hard, the reviewer is stating this as a fact, not inferring it. Therefore, the claim is supported by the absence of information, making it 3.", "helpfulness_rationale": "The review point is 5 as it directly identifies a crucial missing element (standard deviations) in the experimental results section. This is a significant piece of feedback for the authors as it directly impacts their ability to interpret and validate the findings. The reviewer provides a clear and actionable suggestion for improvement, which is to include standard deviations. The feedback is specific and directly addresses a potential weakness in the authors' analysis of the experimental data."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a problem ('Quality of generated images by proposed method is limited') and suggests an improvement ('improved realism'). While the exact nature of the limitation isn't specified, the suggestion provides a direction for action. However, the lack of specific details makes the actionable aspect somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'generated images by proposed method' and 'realism of generated results,' indicating a clear identification of the area of concern. However, the description of the limitation ('limited') is general and doesn't pinpoint specific aspects of realism that are lacking.", "verifiability_rationale": "The reviewer makes a judgment about the 'quality' and 'realism' of the generated images, which is a claim. They also provide a reason ('While good continuous control is achieved, the realism of generated results showed in paper and supplemental material is limited'), which offers some justification for the claim.", "helpfulness_rationale": "The reviewer provides a critique of the generated images, which is a helpful point. However, the critique is general ('Quality of generated images by proposed method is limited') and lacks specific suggestions for improvement beyond 'improved realism'. The lack of concrete guidance makes the helpfulness somewhat limited."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a specific detail about the backpropagation process in the Cycle Consistency loss, which is a concrete action. However, the reviewer is correcting a potentially implicit understanding in the authors' description, making it somewhat implicit. Therefore, the action is 3.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Lines 559560' and refers to 'Cycle Consistency loss' and 'backpropagation process', which clearly grounds the comment to a specific part of the paper and the relevant concepts. The specificity is also high as the reviewer details the 'two separate standard backpropagation processes'.", "verifiability_rationale": "The reviewer makes a claim that the authors' statement is 'not entirely true' and provides a specific detail about the backpropagation process. This claim is verifiable if the specific detail about the backpropagation process is present in the paper. Therefore, it is 5.", "helpfulness_rationale": "The reviewer directly corrects a potential misunderstanding or error in the authors' description of the Cycle Consistency loss. This is a very helpful comment as it clarifies a specific implementation detail. It is not just a suggestion but a correction of a potentially inaccurate statement."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states \"calling 'hyperspectral' is confusing.\" This directly identifies an actionable suggestion for the authors to avoid using the term 'hyperspectral'. While the suggestion is direct, it lacks specific guidance on how to avoid the confusion, making it somewhat vague.", "grounding_specificity_rationale": "The review point explicitly mentions the term \"hyperspectral\" in the authors' text, clearly identifying the specific part being addressed. However, it does not specify what aspects of calling this term are confusing or suggest concrete improvements related to that term.", "verifiability_rationale": "The review point contains a claim: \"calling 'hyperspectral' is confusing.\" However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. It simply states the observation without justification.", "helpfulness_rationale": "The review point identifies a potential area for improvement (the clarity of the term 'hyperspectral') and suggests an action (avoiding the term). However, it does not provide any specific guidance on how to achieve this action or what changes the authors should make. The suggestion is general and lacks concrete details, making it less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The request for a breakdown of contribution is a direct and explicit action the authors can take. They can analyze the impact of each component (Linformer, BigBird, window attention) individually and in combination to understand their specific contributions to the final performance. This action is welldefined and actionable.", "grounding_specificity_rationale": "The paper mentions the components (Linformer, BigBird, window attention) and the idea of ablation studies in sections 3 and 4. However, it doesn't explicitly state which section or part of the paper these components are applied to in those sections. The request itself is specific (how each contributes), but the grounding to the specific sections is weak. The authors would need to infer where these components are discussed in sections 3 and 4 to ground the request effectively.", "verifiability_rationale": "The reviewer makes a claim: 'It would be better if how each of them contributes to the final performance improvements are given...'. This claim is not supported by any logical reasoning, common knowledge, or external references within the provided text. The paper doesn't provide evidence to verify this claim. The claim is stated but not justified.", "helpfulness_rationale": "The reviewer's suggestion to provide a breakdown of contribution is a clear and actionable request. It directly addresses the need for understanding the impact of each component on the final performance. This request is welldefined and would help the authors improve their understanding and potentially optimize their model. Therefore, it is 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the concern about the ablation study and provides specific evidence (Table 10) showing similar performance with and without the perception module. It also points out the missing implementation details of the 'w/o perception' experiment. The reviewer suggests a concrete improvement by asking for the implementation details. The reviewer also raises a valid point about the statistical significance of the results given the sample size, which is a concrete actionable item for the authors to consider.", "grounding_specificity_rationale": "The comment explicitly mentions 'ablation study', 'Table 10', 'w/o perception module', and discusses the *results* of the experiments (similar performance, questionable significance). The reviewer is pointing to specific parts of the paper and the observed data. The reviewer is also asking a specific question about the implementation details, indicating a clear understanding of where the issue lies. The focus is on specific aspects of the experimental setup and analysis.", "verifiability_rationale": "The comment contains a claim about the experimental results being questionable due to similar performance and the small sample size. The reviewer provides evidence (Table 10) to support this claim. However, the reviewer does not explicitly state the *reasons* for why the results are questionable (e.g., lack of variance, specific statistical tests). The evidence is present, but the reasoning is missing.", "helpfulness_rationale": "The reviewer provides specific information about the missing implementation details of the 'w/o perception' experiment and raises a concrete concern about the statistical significance of the results given the sample size. By highlighting these specific issues, the reviewer is providing valuable information for the authors to improve their draft. The reviewer is not just pointing out a problem but also suggesting a direction for investigation (looking for implementation details and considering statistical significance)."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: 'The notation for results is not clear.' They also implicitly suggest a solution by mentioning '3%p'. This is an explicit action as the reviewer directly identifies a problem and proposes a direction for improvement. The action is also concrete as the reviewer points to a specific percentage (3%) and suggests clarifying the 'p'.", "grounding_specificity_rationale": "The reviewer mentions 'CIFAR10' specifically, indicating they are pointing out an issue within a specific experiment or dataset. This demonstrates strong grounding. The reviewer also specifies the '3%p' issue, adding specificity to the grounding by identifying the exact location of the problem.", "verifiability_rationale": "The reviewer makes a claim that the notation for results is 'not clear'. This is a claim that requires verification. While the reviewer suggests clarifying the '3%p', they do not provide explicit evidence or references within this review point to support the claim that the notation is indeed unclear. The verifiability relies on the reviewer's observation and the logical implication that clarifying the percentage will likely improve clarity. The reasoning is somewhat implicit and could be strengthened with direct examples or citations if available in the paper.", "helpfulness_rationale": "The reviewer clearly identifies a problem ('the notation for results is not clear') and provides a direct suggestion for improvement ('3%p'). This is a helpful comment because it directly addresses a potential issue authors might face when interpreting the results. The suggestion is actionable and specific, guiding the authors to focus on clarifying the percentage. The impact on the authors is significant \u2013 they are given a concrete direction to improve their understanding of the results."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the authors' claim and then lists the specific errors in that claim. The phrase 'this statement makes multiple incorrect assertions' directly points to the inaccuracies in the authors' description of the CLT. The reviewer also specifies the limitations of the CLT (nonasymptotic regime and finite linear combination of arbitrary random variables) which provides a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer directly references 'line 238' of the paper, providing a precise location of the problematic statement. Furthermore, the reviewer not only identifies the error but also specifies *what* is wrong: 'According to the Central Limit Theorem (CLT), a normally distributed random variable can be produced through a finite linear combination of any random variables' and then elaborates on the limitations of this statement.", "verifiability_rationale": "The reviewer makes a claim that the authors' statement is incorrect. This claim is supported by logical reasoning. The reviewer explains why the authors' statement is incorrect by highlighting the limitations of the CLT (nonasymptotic regime and finite linear combination of arbitrary random variables). While the reviewer doesn't provide external references in this specific case, the logical explanation serves as sufficient justification.", "helpfulness_rationale": "The reviewer provides a clear and specific critique of the authors' statement. They identify the exact location of the problematic claim in the paper ('line 238') and explain *why* the authors' interpretation of the CLT is incorrect. This provides the authors with a concrete point of improvement by understanding the limitations of the theorem. The reviewer's explanation is not just a correction but also an educational point, potentially helping the authors understand the nuances of the CLT."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The request is explicit about the action needed ('analyze the time complexity'), but it lacks the concrete steps or criteria for how to perform this analysis. The reviewer doesn't specify which parts of the policies or algorithms need to be analyzed or what specific aspects of time complexity (e.g., worstcase, averagecase, amortized) are relevant. This makes the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'policies mentioned in Section 4' without specifying which section or providing any context about the policies themselves. This makes it impossible to determine which part of the paper the reviewer is referring to, resulting in weak grounding. The request also lacks specificity about what aspects of the policies need to be analyzed for time complexity.", "verifiability_rationale": "The reviewer makes a clear request ('analyze the time complexity'), which constitutes a claim. However, the request lacks sufficient justification or explanation of how to perform this analysis. There are no references or logical reasoning provided to support the claim. The request is presented as a directive without the necessary backing for it to be considered verifiable.", "helpfulness_rationale": "The request identifies a relevant and important aspect for authors to consider (time complexity of algorithms), making it potentially helpful. However, the request is vague and lacks specific instructions or criteria for the analysis. Without knowing what policies or algorithms are being referred to and what specific aspects of time complexity need to be analyzed, the reviewer's request is not very actionable for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their concern: \"I don\u2019t understand why in the human evaluation the authors use an automatic metric TSS rather than a human metric to evaluate the style control.\" This is a clear and direct statement of a potential improvement or clarification needed. The reviewer identifies a missing element (the justification for using TSS) and prompts the authors to consider an alternative. This fits the definition of an explicit action: identifying a weakness or suggesting an improvement.", "grounding_specificity_rationale": "The reviewer refers to a specific aspect of the human evaluation process: 'style control evaluation\" and a specific metric: \"TSS\". This demonstrates strong grounding as the reviewer can accurately pinpoint the section, table, figure, or unique aspect being addressed. The reviewer also clearly specifies what they are criticizing: \"why in the human evaluation the authors use an automatic metric TSS rather than a human metric to evaluate the style control.\" This clearly identifies the issue and the proposed alternative.", "verifiability_rationale": "The reviewer makes a claim: \"I don\u2019t understand why in the human evaluation the authors use an automatic metric TSS rather than a human metric to evaluate the style control.\" This is a subjective opinion. The reviewer does not provide any evidence or reasoning to support their claim. They are stating their perspective but not logically justifying it or providing examples. Therefore, it is not verifiable based on the provided text.", "helpfulness_rationale": "The reviewer's point is about raising a concern and prompting the authors to consider the limitations of using an automatic metric for style control evaluation in a human context. While the review prompts the authors to think critically about their evaluation process, it does not directly suggest a concrete action or improvement the authors should take. The reviewer is not providing a solution or a recommendation, but rather highlighting a potential issue. Therefore, it is not 5 in directly guiding the authors to improve their review process or the paper itself."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a valid issue (lack of diversity in experiments) but doesn't provide explicit or concrete steps on how to address it. It suggests 'including experiments across more diverse domains' but doesn't specify which domains from TDMPC 2 or how to implement this change. While it implies a need for improvement, the lack of specific actions makes it not fully actionable.", "grounding_specificity_rationale": "The review point suggests improvements to the experiments but doesn't explicitly identify the specific part of the paper being addressed. It refers to 'experiments' in general and 'more diverse domains' without specifying which section, table, or unique aspect of the paper this relates to. While it hints at a connection to TDMPC 2, it doesn't pinpoint a specific element within the paper.", "verifiability_rationale": "The review point makes a claim: 'it would strengthen the paper to include experiments across more diverse domains'. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. It simply states the suggestion without justifying why it would be beneficial or how it would be implemented.", "helpfulness_rationale": "The review point identifies a relevant area for improvement (experiment diversity) and suggests a direction (TDMPC 2 domains). However, it lacks the specific details needed to be truly helpful. Authors would understand the suggestion, but they wouldn't know how to translate it into concrete changes. The suggestion is general and lacks actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a *specific* issue: the lack of clarity in the LUQ design process. It suggests a *potential* improvement: focusing on the goal of logarithmic and unbiased quantization. While it identifies a problem (lack of clarity) and suggests a direction (focusing on the goal), it doesn't tell the author *how* to address the lack of clarity. The suggestion is more of an *idea* than a concrete action.", "grounding_specificity_rationale": "The review refers to \"the LUQ itself\" and \"quantizer is clear.\" While it mentions a specific component (LUQ), it doesn't explicitly state which section or subsection it's referring to. The clarity is about the *design process*, not necessarily a specific detail within the LUQ itself. The review points out that the *process* of designing the LUQ is straightforward *once* the goal is clear. It criticizes the lack of clarity in the *design process*. It's about the *how* of that section, not a direct criticism of a specific detail within it.", "verifiability_rationale": "The review states: \"I'd say the main contribution of this paper is showing that such a simple combination of existing techniques is sufficient to achieve (surpringly good) accuracy, rather than proposing novel techniques.\" This is a statement of opinion about the *nature* of the paper's contribution. The review point doesn't offer any evidence or references to support this interpretation within the text itself. The claim is presented as a judgment about what the paper is doing, not a claim that requires verification based on facts or external sources.", "helpfulness_rationale": "The review point identifies a potential area for improvement (focusing on the design goal) but doesn't provide concrete steps or specific suggestions. It's more of a constructive comment than a direct critique or a clear call to action. The suggestion is about a *potential* improvement, not a specific *how* to improve. While it points out a potential avenue for improvement, it lacks the specific guidance needed for a truly impactful review."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the computational cost (2x samples) and the resulting performance impact (1.5x slower). This is a clear and direct identification of an action the authors should take to improve their draft by considering the computational implications of RegMixup.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"RegMixup\" and the specific implementation detail of \"2x samples per iteration\". This is a clear and specific identification of the part of the paper being addressed, making it fully grounded. The reviewer also specifies the *what* (computational cost) and *why* (potential for unfair comparison) of the issue, making it specific.", "verifiability_rationale": "The reviewer makes a claim about the relationship between the 2x samples and the slower speed. While they don't provide external references or detailed examples within the review point itself, the connection is logically inferred and actionable for the authors. The reviewer states a clear relationship between two observed aspects.", "helpfulness_rationale": "The review point directly identifies a specific implementation detail of RegMixup that could impact performance and suggests a potential issue with fair comparison. This is a clear and actionable piece of feedback that guides the authors towards considering the computational aspects of their method and improving the fairness of their comparisons. The feedback is also constructive, prompting the authors to think critically about their experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their intention to understand how to relax the requirement of visiting all ballaction pairs. This indicates a clear action. However, the reviewer does not provide any specific methods or strategies for achieving this relaxation. The action is stated but not elaborated upon, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'ballaction pairs,' which implies they are discussing a specific technical aspect of an algorithm. While they don't explicitly name the algorithm or the context, the topic is clear enough to infer the area of discussion. However, the reviewer does not specify *which* algorithm or the precise location of the ballaction pairs within it. The grounding is implied but not fully explicit.", "verifiability_rationale": "The review point is a question asking for clarification on a previous remark. It does not contain a claim that requires verification. It is a request for information rather than a statement making a judgment.", "helpfulness_rationale": "The reviewer asks a question about a specific aspect of an algorithm, which is relevant to improving efficiency. However, the review point itself does not provide any concrete suggestions or information to help the author. It is a request for clarification rather than a proposed solution or actionable insight. Therefore, it has limited direct helpfulness in improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "Partially Grounded and Specific", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The suggestion is explicit, stating 'More datasets...'. However, it lacks detail on *which* datasets, *how many*, and *why* these additional datasets are needed. The action is present, but the specifics are missing, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'traditional multilingual tasks like XNLI, XTREME' and 'tasks with different levels of reasoning requirements,' indicating a clear identification of the specific parts of the work being addressed. However, the reviewer does not explicitly state what is *wrong* with the current datasets or tasks, nor does it provide specific examples of what needs to be improved within these areas. The grounding is present, but the specifics of the issues are missing, making it partially grounded and specific.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a suggestion for improvement rather than a critique that needs to be supported by evidence or reasoning. Therefore, it is not verifiable in the sense of providing a claim that needs justification.", "helpfulness_rationale": "The review point directly addresses a potential weakness in the work \u2013 the lack of evidence on diverse tasks and reasoning requirements. It suggests a concrete next step: gathering more data on specific tasks. This directly points towards a potential area for improvement and provides a clear direction for the authors. While it lacks specific details, it is a clear suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests replacing the current baselines with specific existing methods, RefNeRF and MipNerf. While the suggestion is explicit, the rationale for why these are better baselines is not provided. The action is to suggest using these baselines, but the implementation details are missing.", "grounding_specificity_rationale": "The reviewer explicitly names RefNeRF and MipNerf as better baselines for specific aspects of the work. This demonstrates strong grounding as the author can accurately pinpoint the section being addressed (baseline methods) and identify the issue (the need for better baselines for specific tasks).", "verifiability_rationale": "The reviewer states that the suggestion is to 'improve the choice of the baseline methods' and provides 'good baselines' as examples. This is a clear claim. However, the verifiability is limited as the reviewer does not provide any logical reasoning, common knowledge, or external references to support the claim that RefNeRF and MipNerf are indeed better baselines. The claim is made without sufficient justification.", "helpfulness_rationale": "The reviewer suggests replacing the current baselines with specific existing methods, RefNeRF and MipNerf, for specific tasks. This is an explicit suggestion and provides some actionable feedback. However, the reviewer does not explain *why* these are better baselines or what specific improvements they offer. The authors would need to figure out how to integrate these suggestions into their own work, making the feedback 3 but requiring further clarification."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The phrase 'lack of implementation details' is explicit, indicating a need for more information. However, it's vague because it doesn't specify what details are missing or how they should be implemented.", "grounding_specificity_rationale": "The reviewer mentions 'implementation details' generally and points to Section 4.1. While it hints at a location, it doesn't explicitly name a specific part of the section, table, or figure. The criticism is broad and lacks specific information.", "verifiability_rationale": "The review point states a problem ('lack of implementation details') without providing any solutions or justifications. It's a critique, not a claim that needs verification.", "helpfulness_rationale": "The review point identifies a valid weakness (lack of implementation details) and suggests an improvement (adding these details). It's a constructive criticism. However, it doesn't specify where in Section 4.1 the details should go, which could make it slightly less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a significant weakness in the paper (lack of empirical evaluation) but does not explicitly state how the authors should address this. It implicitly suggests that the absence of empirical evaluation is a problem, but it doesn't provide concrete steps for the authors to take. The comment is vague and lacks specific guidance on what kind of empirical evaluation is needed or how to demonstrate the practical value of the contribution.", "grounding_specificity_rationale": "The comment does not specify which parts of the paper are lacking empirical evaluation or which methods should be compared. It broadly states that there is no empirical evaluation whatsoever and no comparison with other methods. The comment is about the *absence* of something rather than pointing to a specific section or technique.", "verifiability_rationale": "The comment contains a claim: 'No empirical evaluation whatsoever is provided, there is no comparison (except for on an abstract level) with other methods. It is completely unclear what the practical value of the contribution even could be.' This claim is 3 because the absence of empirical evaluation and comparisons is a factual observation. However, the claim about the 'unclear practical value' is an inference based on the lack of empirical evidence and comparisons.", "helpfulness_rationale": "The review point is highly critical of the paper, highlighting the lack of empirical evaluation and practical value. While it identifies a significant issue, it does not provide specific, actionable steps for the authors to take to address these shortcomings. The criticism is about the *absence* of something and the *unclear practical value* of the contribution, rather than offering concrete suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper is limited in navigation problems and suggests combining RL and planning, which are concrete actions or suggestions. The reviewer points out a limitation and proposes a specific improvement.", "grounding_specificity_rationale": "The reviewer accurately identifies the specific area of the paper (navigation problems) where the limitation exists and mentions a related concept (PRMRL). They pinpoint the section or aspect being addressed, showing strong grounding. The reviewer specifies the type of problems and even hints at a related field, making it highly specific.", "verifiability_rationale": "The reviewer makes a claim about the paper's limitation in navigation problems and links it to the existence of PRMRL. This claim is supported by the statement about the paper's limitations and the mention of a related concept. While the exact nature of the limitation could be further clarified, the claim itself is verifiable based on the information provided.", "helpfulness_rationale": "The reviewer provides a clear and actionable feedback by pointing out a limitation in the paper's applicability to navigation problems and suggesting a relevant improvement by combining RL and planning. This feedback is specific and directly addresses a potential area for future research or application."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a potential issue ('are all feature spaces wellsuited for 1NN?') and suggests a solution ('If a feature space is not close to a spherical Gaussian, it may perform poorly. If feature dimensions are individually standardized, it would avoid this issue.'). This indicates a clear action to be taken.", "grounding_specificity_rationale": "The comment directly references a specific line in the paper ('line 213') and then elaborates on the issue ('are all feature spaces wellsuited for 1NN?') and the suggested solution ('If feature dimensions are individually standardized, it would avoid this issue.'). This shows a strong grounding in the specific location and context.", "verifiability_rationale": "The comment poses a question ('are all feature spaces wellsuited for 1NN?') which can be considered a claim. While it suggests a solution ('If feature dimensions are individually standardized, it would avoid this issue.'), this is more of a suggestion than a direct verification of the claim about all feature spaces. The verifiability relies on the reader's understanding of feature space geometry and 1NN performance.", "helpfulness_rationale": "The comment identifies a relevant limitation of using 1NN with feature spaces and provides a concrete suggestion ('If feature dimensions are individually standardized, it would avoid this issue.'). This actionable feedback is directly relevant to authors using 1NN and dealing with feature space issues."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two explicit suggestions for improvement: correcting the inaccurate statement about rewards in standard MDPs and clarifying the action space definition. These are both concrete actions the authors can take to address the identified issues.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'section 3.1, line 143' and 'line 154', demonstrating a clear understanding of the specific parts of the paper being discussed. They also point out specific inaccuracies or areas of potential confusion, further enhancing the grounding of the comment.", "verifiability_rationale": "The reviewer provides clear explanations and suggestions for both the inaccurate statement about rewards and the unclear action space definition. For the rewards statement, they explain that standard MDPs typically have rewards associated with transitions, not just state changes. For the action space, they suggest that actions are likely single features or the power set. They also provide examples (transitions and features) to support their claims, making the verifiability high for both points.", "helpfulness_rationale": "The reviewer's suggestions are directly relevant and would significantly improve the reader's understanding of MDPs, particularly the reward mechanism and the nature of actions. The correction on line 143 is a crucial point for clarity. The suggestion on line 154, while potentially minor, addresses a potential point of confusion and promotes better understanding of the action space."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out the phrase 'a response candidate can meet each utterace' as being unclear. While the reviewer identifies a potential area for improvement, the specific action to be taken is not explicitly stated. The suggestion to clarify is implicit, making it less actionable than a comment that directly suggests a replacement or a more precise phrasing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'line 280' and the phrase 'a response candidate can meet each utterace'. This precise identification demonstrates that the authors can accurately pinpoint the section and the specific issue, indicating full grounding. The comment specifies what needs to be addressed within that section, making it underspecific but grounded.", "verifiability_rationale": "This comment does not contain a claim. It is a statement identifying a problem (lack of clarity) without providing any justification or evidence. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The reviewer identifies a specific instance in the paper ('a response candidate can meet each utterace') that they find difficult to understand. This directly points to a potential area for improvement in the authors' writing. By highlighting this, the reviewer provides a concrete example for the authors to focus on. While the suggestion is general ('clarity'), it is still a helpful pointer for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, which can be interpreted as an implicit request for the authors to consider this. While not a direct instruction *how* to identify limitations, it's a prompt for reflection. However, it lacks specific instructions on *what* limitations to consider or *how* to apply an action. The action of considering limitations is implied, but the means to do so are not explicitly stated.", "grounding_specificity_rationale": "The review point is a general question about limitations and does not specify a particular part of the paper or method being discussed. It does not identify a specific section, table, figure, or unique element of the paper. The comment is vague and does not detail what needs to be addressed in this part.", "verifiability_rationale": "The review point itself does not contain a claim. It is a question, not a statement making a judgment. Therefore, it cannot be evaluated for verifiability as there is X to verify.", "helpfulness_rationale": "The review point is a question that prompts the authors to consider other limitations and specifically asks if the shallow network issue extends to the current work. While it encourages selfreflection and potentially leads to valuable insights, it does not directly provide actionable feedback on how to improve the draft. The question is openended and lacks specific guidance on what limitations to consider or how to address the shallow network issue."}
{"actionability_label": "Not Applicable", "grounding_specificity_label": "Not Applicable", "verifiability_label": "1: Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer's point is not explicitly about actionable feedback. While the suggestion to add machine translation evaluation is a potential improvement, it's presented as a critique of the current evaluation methodology rather than a direct, actionable suggestion for improving the current draft. The reviewer doesn't identify a specific, actionable step the authors should take *now* based on this comment.", "grounding_specificity_rationale": "The reviewer's point is not explicitly about grounding or specificity. The criticism focuses on the *evaluation methodology* rather than the clarity or precision of the feedback itself. The reviewer doesn't identify a specific section or aspect of the paper that needs improvement.", "verifiability_rationale": "The reviewer makes a claim about the evaluation methodology being 'close to open domain'. However, this claim is not directly supported by evidence within the paper. The reviewer doesn't provide specific metrics, analyses, or references from the paper to back up this characterization. While the suggestion to add machine translation evaluation is a potential improvement, it's not a fact about the current evaluation methodology being verifiably 'close to open domain'.", "helpfulness_rationale": "The reviewer's point, while relevant, is primarily about the *evaluation methodology* and its potential limitations. It doesn't directly provide the authors with specific, actionable feedback on how to improve their current draft. The suggestion to add machine translation evaluation is a potential *future improvement* rather than a direct, actionable improvement for the current work. Therefore, it's not 5 in the sense of providing immediate guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer has explicitly asked for two specific parameters of the dropout mechanism: the dropping rate and the number of masks. This is an explicit request for concrete information that would directly help the authors understand and potentially replicate the experimental setup. The request is clear and directly addresses the implementation details.", "grounding_specificity_rationale": "The reviewer is directly asking about parameters of a mechanism described in the paper (dropout applied to document presentation from an encoder). The paper should ideally specify these details. The request is precise and directly targets a specific aspect of the described process, making it highly grounded. The reviewer is not asking for a general description of dropout but specific implementation details.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. The reviewer is simply stating their understanding of the dropout mechanism and asking for clarification on specific parameters. There is no logical reasoning, common knowledge, or external references provided in the review point itself to verify the reviewer's understanding.", "helpfulness_rationale": "The reviewer's question directly targets crucial implementation details of the dropout mechanism. This information is likely to be highly valuable to the authors as it would help them understand and potentially replicate the experimental setup. The request is specific and directly asks for information that would directly benefit the authors."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out the need for *comparisons* with other singlestage attacks and the lack of justification for the twostage approach. While the reviewer suggests *what* should be done, the review itself doesn't explicitly * tell the authors how to address these shortcomings. It identifies *an action* (comparisons) but doesn't * specify how* to do it (e.g., with which specific singlestage attacks, what benchmarks). Therefore, while the reviewer identifies a need for action, the review itself doesn't provide the specific details for implementation, making it partially actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions the need for *further justifications* regarding the effectiveness of the twostage optimization approach. They also specify *what needs to be shown* \u2013 comparisons with other singlestage attacks and the use of proper benchmarks and SOTA comparisons. The reviewer clearly identifies the *parts* of the paper being addressed: the twostage approach, the experimental results on fusion models, and the need for specific comparisons. This demonstrates a clear understanding of where the paper falls short and what specific information is missing.", "verifiability_rationale": "The reviewer states that *only showing the performance drop on fusion models is not enough* and that *comparisons with other singlestage attacks are also needed*. These are statements of opinion about the insufficient evidence. The reviewer doesn't provide any *new* evidence or logical reasoning within the review itself to support these claims. The *review itself* doesn't offer a clear path to *verifying* these statements. The reviewer is highlighting potential weaknesses, not providing concrete evidence within the review to support their assessment.", "helpfulness_rationale": "The reviewer clearly identifies key areas for improvement in the paper, such as providing further justifications for the twostage approach, including comparisons with other singlestage attacks, and using proper benchmarks and SOTA comparisons. The reviewer also explains *why* these improvements are needed, highlighting the lack of sufficient evidence. By pointing out these specific weaknesses and suggesting concrete directions for improvement, the reviewer is providing valuable information to the authors, making it helpful."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential issue ('This sentence is confusing') but doesn't explicitly state what the author should do to address it. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'the sentence 9395', clearly identifying the specific part of the paper being discussed. They also suggest the author reread the sentence, directly addressing the issue within that specific part.", "verifiability_rationale": "The reviewer makes a claim ('This sentence is confusing') but doesn't provide any evidence, reasoning, or references to support this claim. They are stating their perception of the sentence's clarity.", "helpfulness_rationale": "The reviewer points out a potential area of confusion in the paper. While it doesn't provide a direct solution, it highlights a problem that could hinder understanding and potentially lead to errors. It encourages the author to seek clarification, which is a positive step."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the inconsistency between Fig 1 and Fig 2 and identifies the difference in the number of encoderdecoder models. This constitutes an explicit action and provides concrete details on how to implement it (i.e., the specific difference observed).", "grounding_specificity_rationale": "The comment explicitly mentions 'Fig 1' and 'Fig 2', accurately identifying the specific parts of the paper being addressed. It also clearly specifies the issue: 'a single shared encoderdecoder for multiple tasks' versus 'one encoderdecoder per auxiliary task'. This is full grounding and specific identification of the problem.", "verifiability_rationale": "The comment contains a claim ('Fig 1 is not consistent with Fig 2') and identifies the nature of the inconsistency ('a single shared encoderdecoder for multiple tasks' vs 'one encoderdecoder per auxiliary task'). However, it does not provide any logical reasoning, external references, or examples to support this claim. The reviewer is stating an observation, but doesn't explain *why* it's inconsistent or suggest *how* to resolve it. Therefore, it is not 5.", "helpfulness_rationale": "The comment is clear and identifies a potential issue in the figure description. It points out a discrepancy that could indicate a misunderstanding or error in the paper. However, it does not provide specific guidance on how to address the inconsistency or suggest any concrete improvements to the authors' work. It identifies a problem but doesn't actively help them resolve it, making it 3 but not 5."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about a specific aspect of the method (the attention mechanism) and provides a specific point of inquiry. They are asking for clarification on the scope of attention, which is a concrete action.", "grounding_specificity_rationale": "The reviewer asks a question about a specific part of the paper (related to equation 2 and the description of N_l^(s)). They are also inferring an issue based on their interpretation of equation 2, which suggests they can identify the relevant section and understand the issue being raised.", "verifiability_rationale": "The reviewer makes a claim about the attention mechanism's scope and provides evidence (equation 2 and their interpretation) to support their claim. This demonstrates an attempt to verify or refute a specific statement.", "helpfulness_rationale": "The reviewer's question directly addresses a potential misunderstanding of the method and aims to improve the authors' understanding. This is a highly constructive and specific piece of feedback that directly helps the authors improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem: 'How does the ineq. after l433 follow from Lemma 7?'. This clearly indicates an actionable issue the reviewer has encountered. They are asking for clarification on a specific step, which is a direct request for information. The reviewer also offers a hypothesis ('It seems to follow somehow from a combination of the previous inequalities'), further indicating an attempt to understand the connection. The request to 'facilitate the reading a bit' is also an actionable suggestion for the authors.", "grounding_specificity_rationale": "The reviewer refers to 'the ineq. after l433' and 'Lemma 7'. These are specific references to the text. The reviewer also mentions 'previous inequalities', further pinning down the scope. This indicates strong grounding as the reviewer is directly addressing a specific part of the paper and a specific claim (the connection between the inequality and Lemma 7). The reviewer is not making a general statement about the paper but is focusing on a specific mathematical relationship.", "verifiability_rationale": "The reviewer presents a question: 'How does the ineq. after l433 follow from Lemma 7?'. This can be interpreted as a request for justification or clarification of a step. While it doesn't explicitly state a claim that requires verification, it implies a lack of clarity regarding a specific mathematical relationship. The reviewer is asking for a logical connection between two specific elements. However, the review point itself doesn't contain a definitive claim that requires external verification or logical reasoning beyond understanding the referenced elements.", "helpfulness_rationale": "The reviewer's comment is directly addressing a potential issue the authors might be facing regarding the connection between a specific inequality and Lemma 7. By asking this question, the reviewer is providing a clear direction for the authors' investigation. The reviewer's suggestion to 'facilitate the reading a bit' is also a helpful suggestion. However, the review point itself doesn't contain a definitive claim that requires verification or a specific action to be taken. It's more of a pointer to an area that needs clarification."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer states: \"The claim of making use of \u201cannotation guideline\u201d may be an overstatement  this paper only considered label name, label description and fewshot examples, however, annotation guideline in IE domain are very complicated and was curated by linguists. E.g., For TACRED slot filling (https://tac.nist.gov/2015/KBP/ColdStart/guidelines/TAC_KBP_2015_Slot_Descriptions_V1.0.pdf), section 3.6 per:city_of_birth, they use \u201cGPEs below the city level (e.g. 5 boroughs of New York City) are not valid fillers.\u201c as an example rule to guide annotators. The prompts proposed by this paper might not fully capture the depth of true guideline understanding.\" While the reviewer identifies a potential overstatement, the specific action or suggestion to address this overstatement is not explicitly stated. The reviewer implies that the paper didn't fully utilize annotation guidelines but doesn't provide a concrete action or direction for improvement. Therefore, it is not fully actionable.", "grounding_specificity_rationale": "The reviewer states: \"this paper only considered label name, label description and fewshot examples\". This explicitly names the specific aspects of the paper being addressed, demonstrating strong grounding. The reviewer also implies that the annotation guidelines are missing, further adding to the specificity of the point.", "verifiability_rationale": "The reviewer makes a claim: \"The claim of making use of \u201cannotation guideline\u201d may be an overstatement\". This claim is supported by providing a specific example from the TACRED paper (https://tac.nist.gov/2015/KBP/ColdStart/guidelines/TAC_KBP_2015_Slot_Descriptions_V1.0.pdf), section 3.6, which illustrates the complexity of annotation guidelines. This external reference and example serve as verifiable support for the claim.", "helpfulness_rationale": "The reviewer identifies a potential overstatement regarding the use of annotation guidelines in the paper. This highlights a potential weakness in the paper's description of its methodology and its relation to existing annotation guidelines. While the reviewer does not explicitly state what the authors should do to improve, the identification of this potential overstatement and the provision of a concrete example (from the TACRED paper) make the review helpful in pointing out a specific area for improvement and encouraging the authors to consider the complexities of annotation guidelines. The suggestion to \"improve the depth of true guideline understanding\" is a constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the weakness: 'the author only compare their method to the BERTbaseline.' This is a direct and clear identification of an action the authors should take. Furthermore, the suggestion to 'compare their method to token pruning and token combination baselines' is a concrete action with specific details on how to implement it.", "grounding_specificity_rationale": "The review point does not specify *where* the weak comparison is happening. It broadly states that the comparison is only to the BERTbaseline without mentioning specific experiments, tables, figures, or unique aspects of the paper. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point makes a claim: 'the author only compare their method to the BERTbaseline' and suggests 'comparing their method to token pruning and token combination baselines'. This claim is verifiable by the authors by examining their experimental setup and comparing it to the suggested baselines. The reasoning is logical, and the suggestion provides a concrete direction for improvement.", "helpfulness_rationale": "The review point is clear about the missing baselines and suggests comparing against them. This provides a helpful direction for the authors to improve their experimental evaluation. While it identifies a weakness, it could be expanded to include more specific suggestions or reasons for the choice of baselines."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The comment identifies a potential weakness in the model but does not provide any specific actions or suggestions for improvement. It simply states the existence of a problem without offering a path forward.", "grounding_specificity_rationale": "The comment is very general and does not point to a specific part of the paper or model aspect. It broadly states that the model lacks demonstrated weaknesses without specifying where or what these weaknesses might be.", "verifiability_rationale": "The comment identifies a potential weakness in the model but does not provide any evidence, examples, or references to support this claim. It simply states the problem without any verification.", "helpfulness_rationale": "The comment highlights a valid concern about the model's demonstrated weaknesses but does not offer any specific suggestions, examples, or guidance on how to address this issue. It points out a problem but doesn't provide a solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The question is explicit about seeking information, but it lacks detail on how to act upon it. The suggestion to compare methodologies is vague.", "grounding_specificity_rationale": "The reviewer asks about 'others' and 'previous extractthengenerate methodologies' without specifying which ones or providing details. The reference to 'previous' is general.", "verifiability_rationale": "The claim is based on the absence of a related work section and the lack of comparative experiments, which can be verified. However, the claim itself is a statement of observation rather than a direct suggestion for improvement.", "helpfulness_rationale": "The review point raises a concern about the lack of related work and comparative experiments, which could be considered a weakness. However, it doesn't offer concrete suggestions or propose improvements to the methodology."}
{"actionability_label": "2", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an alternative approach to handling churn but does not explicitly state how this approach should be implemented or what actions the authors should take. While it implies a potential improvement, the specific steps or actions are not clearly defined, making it difficult to assess the direct impact on the authors' work. The reviewer suggests training 3040 models, but doesn't specify how this training should be done or what the 'burn in' process entails in the context of the authors' specific model or dataset.", "grounding_specificity_rationale": "The review point discusses the concept of 'churn' and suggests an alternative involving 'unlabeled data' and 'constraints.' However, it does not specify which part of the paper or analysis is being addressed. The terms 'churn,' 'unlabeled data,' and 'constraints' are general and do not pinpoint a specific element within a paper or experimental setup. The reviewer's suggestion is presented as a general idea rather than a specific critique of a particular aspect of the authors' work.", "verifiability_rationale": "The review point presents an alternative approach to handling churn but does not explicitly claim that the current method is flawed or that this alternative is a solution. It raises a question about the computational cost of training many models but does not provide a verifiable argument or evidence to support why this approach is better or how it would be implemented. The reviewer's point is more of a suggestion than a claim that needs verification.", "helpfulness_rationale": "The review point offers a different perspective on handling churn, highlighting the practical challenges of training and burning in a large number of models. While it prompts the reader to consider alternatives, it does not provide concrete, actionable advice or specific solutions. The reviewer's suggestion is more of a thought experiment or a point for discussion rather than a direct improvement or a clear recommendation for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the difference in dropout settings between Moon's approach (single dropout rate) and Variational dropout (inputoutput and recurrent dropout). This highlights a potential inconsistency or area for further investigation. While it doesn't directly tell the author *what* to do, it points to a specific aspect of the methodology that requires attention. The reviewer is making an observation about the implementation details.", "grounding_specificity_rationale": "The review point discusses the *type* of dropout used in different approaches. While it doesn't explicitly refer to a specific section, table, or figure in the paper, it clearly identifies the relevant concepts (dropout rate, Moon's approach, Variational dropout) and their characteristics. The grounding is in the general description of the methods being compared.", "verifiability_rationale": "The review point is an observation about the implementation details of different dropout methods. It doesn't present a claim that requires verification or justification. It's a statement of fact about how different approaches are implemented.", "helpfulness_rationale": "The review point points out a potential inconsistency or area for further exploration regarding the implementation of dropout. While it provides some information, it doesn't directly guide the author on how to improve their draft. It's more of a suggestion for further analysis or consideration of alternative implementations."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer does not explicitly state what action the authors should take to address the lack of largerscale experiments. They point out the missing element but do not demand its inclusion or specify how to fix it. The reviewer's comment is more about identifying a gap in the experimental design rather than prompting a direct action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Largerscale experiments' and provides specific examples of what these should include, such as 'gridworlds with walls' and 'nontrivial tiles'. They also suggest alternative domains like 'videogame domains'. This clearly identifies the specific part of the paper where this information should be found and what kind of content is missing. The grounding is strong because the reviewer pinpoints the exact location and nature of the deficiency.", "verifiability_rationale": "The reviewer makes a claim about the lack of justification for the absence of largerscale experiments. They suggest specific areas where the experiments should have been included, such as 'at least gridworlds with walls' and 'simulators for such experiments'. These suggestions, while not providing immediate references, indicate a logical reasoning and a clear direction for the authors to look for supporting evidence or justifications in the paper. The claim is verifiable by examining the experimental setup section of the paper.", "helpfulness_rationale": "The reviewer provides a clear criticism regarding the lack of justification for the limited scale of the experiments. They also offer concrete suggestions for improvement, such as including 'gridworlds with walls' and 'simulators for such experiments'. These suggestions are actionable and directly address the identified weakness, making the review helpful for the authors to understand potential limitations and how to enhance their work. The reviewer's comment is not just a criticism but also a constructive suggestion."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'no information from 2hop neighbors is included' and suggests 'again' (implying a previous consideration or mention of this concept). This indicates a clear action the authors should take: include this information. The action is directly identified and the consequence (including the information) is also clear.", "grounding_specificity_rationale": "The comment refers to '2hop neighbors' without explicitly linking it to a specific section, table, figure, or unique aspect of the paper. While the concept of 2hop neighbors is generally understood, the comment doesn't pinpoint the exact part of the paper where this information would be relevant. The grounding is weak because the authors can only make an educated guess about where this information might be applicable.", "verifiability_rationale": "The comment contains the claim 'this method is simple' and 'it is highly unclear why it is effective'. The claim 'this method is simple' could be considered 3 by observing the description of the method. However, the claim 'it is highly unclear why it is effective' lacks specific justification or examples. There is no external reference provided to support this claim. The verifiability is limited because the effectiveness claim is not wellsupported.", "helpfulness_rationale": "The review points out a missing component ('no information from 2hop neighbors is included') and suggests its inclusion ('again'). While this points to a potential improvement, it doesn't provide a detailed explanation of *why* 2hop neighbors are important in the context of the paper's content or *how* their inclusion would be beneficial. The suggestion is present, but it lacks depth and concrete guidance. The helpfulness is limited because the suggestion is general and lacks specific details or justification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the preference for using DICOM images over PNG images and recommends the FastMRI challenge dataset. This is a clear and direct action, providing a specific direction for the authors to improve their draft. The reviewer suggests comparing inference speeds, which is a concrete action that can be directly implemented to evaluate different methods. The explicitness and concreteness of the suggestions make this review point 5.", "grounding_specificity_rationale": "The review point explicitly mentions 'the real dicom image' and 'FastMRI challenge dataset,' which are specific and welldefined parts of the paper. The reviewer also implicitly encourages comparing inference speeds, which is a concrete action related to evaluating methods. The strong focus on specific data formats and a benchmark dataset demonstrates high grounding specificity. The authors can easily identify the referenced parts and understand the suggested improvements.", "verifiability_rationale": "The review point contains claims about the suitability of DICOM images and the usefulness of the FastMRI dataset. The recommendation to compare inference speeds provides a clear justification for these claims, linking them to a standard evaluation metric. The logical reasoning and practical suggestion of comparing inference speeds make this claim verifiable. The reviewer provides a clear rationale and a concrete action (comparing inference speeds) that can be directly implemented.", "helpfulness_rationale": "The review point is 5 as it provides clear and actionable feedback. The reviewer explicitly recommends using DICOM images and suggests using the FastMRI dataset for evaluation. The suggestion to compare inference speeds is a practical and relevant step for the authors to take when improving their draft. The directness and practicality of the feedback make this review point very valuable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The question asks 'what happens if...', which implies a desire for explanation or clarification. It doesn't directly propose a concrete action the authors should take. Therefore, it's likely not 5. While it might lead the authors to realize the issue, it doesn't explicitly tell them what to do or how to apply it. The lack of explicit action makes it less than fully actionable.", "grounding_specificity_rationale": "The reviewer is implying a potential problem with using SV BRDF maps with existing CAD models, but the specific location or type of information being requested isn't explicitly stated. It's implied (potential problems with using SV BRDF maps with existing CAD models), but the exact location or nature of the problem isn't clearly identified. The reviewer is asking about the consequences of a scenario, not directly pointing to a specific part of the paper.", "verifiability_rationale": "The review point is a question posed to the authors, not a claim that needs verification. There is no assertion of right or wrong, no suggestion of a change, no judgment about the paper. Therefore, it doesn't contain a claim that can be supported or not supported.", "helpfulness_rationale": "The question raises a valid concern about a common scenario in 3D rendering and physicallybased modeling. It points to a potential source of confusion or error for the authors. However, as established in the actionability and grounding specificity evaluations, it doesn't directly tell the authors what to do. It encourages the authors to consider a specific scenario and think about its implications, which can be helpful in identifying potential issues, but it doesn't provide a direct solution or action for them."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states \"More evaluation would have been welcome.\" This is a clear action and a concrete desire for improvement. The reviewer identifies the *what* (evaluation) but doesn't specify the *how* or the *specific aspects* of evaluation they would like to see. However, the action itself is clear and actionable. The reviewer knows what they are referring to when they say \"evaluation.\"", "grounding_specificity_rationale": "The reviewer mentions \"CIFAR10 in the full label and lower label scenarios.\" This clearly identifies the specific part of the paper or model being addressed. The reviewer can accurately pinpoint the section being discussed. However, the reviewer does not specify what is *wrong* with the evaluation in these scenarios. The comment identifies the *where* but not the *what is wrong*. The grounding is explicit, but the specificity is lacking.", "verifiability_rationale": "The reviewer states \"More evaluation would have been welcome.\" This is a claim that the evaluation is lacking. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a suggestion for improvement without any backing. The claim is present, but the verification is missing.", "helpfulness_rationale": "The reviewer states \"More evaluation would have been welcome, especially on CIFAR10 in the full label and lower label scenarios.\" This is a helpful comment as it directly points towards a specific area for improvement (evaluation on CIFAR10 with different label settings). The reviewer identifies a potential weakness (lack of evaluation in these areas) and suggests a direction for improvement. However, the comment lacks specific details on *how* the evaluation should be improved. The helpfulness is focused on a specific area, but the *how* is missing."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "Low", "grounding_specificity_label": "Low", "verifiability_label": "Low", "helpfulness_label": "Medium", "actionability_rationale": "The reviewer identifies a potential issue with the inclusion of the ResNet architecture description, suggesting it distracts from the core contribution (CBN). While the reviewer implies an actionable suggestion (removing the ResNet details), the criticism is more about the *motivation* for including the ResNet details rather than a direct call to *do* something specific with the existing description. The lack of explicit action makes it less actionable.", "grounding_specificity_rationale": "The reviewer criticizes the inclusion and focus of the ResNet architecture description. While they mention 'Section 2.1,' they don't explicitly identify a *specific* part within that section that they find unclear or problematic. They point to the *general* nature of the criticism, suggesting the description is 'independent of the choice of model.' This lack of pinpointing makes the grounding less specific.", "verifiability_rationale": "The reviewer states, 'I don't understand why Section 2.1 is included.' This is a statement of belief or a lack of clarity, not a claim that requires verification or justification. There's no assertion that something is incorrect or needs explanation. Therefore, there's no verifiable element to this comment.", "helpfulness_rationale": "The reviewer offers a suggestion for improvement: 'the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed CBN approach.' This is a constructive comment offering a potential *action* (reducing ResNet description and increasing CBN motivation). While the criticism itself is more of a critique of the *organization*, the suggestion provides a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a lack of clarity regarding the expected outcome of a matrix multiplication, which can be interpreted as an implicit call for the author to clarify the sparsity of the resulting matrix. While it doesn't explicitly state 'You need to... calculate the condition number of the projection matrix', it points to a missing piece of information that the author should be aware of. Therefore, it is not entirely 1 as it highlights a potential area of confusion that the author should address.", "grounding_specificity_rationale": "The review point refers to 'equation (1)' and 'the resulting matrix', which indicates a focus on a specific part of the paper. While it doesn't explicitly name a section or table, it clearly points to a specific mathematical element. The reviewer is asking about the properties of this specific matrix, making the grounding somewhat explicit but not fully so. Therefore, it can be considered weakly grounded as the paper element is identifiable through reference to a specific equation and the resulting matrix.", "verifiability_rationale": "The review point is a question about the clarity of a mathematical operation. It doesn't make a claim that the resulting matrix *must* be sparse or that the multiplication is inherently flawed. Instead, it raises a potential point of confusion for the author. Therefore, it doesn't contain a claim that requires verification, making it 1.", "helpfulness_rationale": "The review point points out a potential ambiguity in a key mathematical step. While it doesn't directly tell the author how to fix it, it highlights a point where clarification is needed. This could be helpful for the author to understand the intended behavior of the projection matrix. However, it doesn't offer a concrete solution, making its helpfulness limited. Therefore, it is not 5 as it doesn't provide a direct path to improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the connection between NGD and NGF through discretization and the link between solving NGF and IVPs. They also explicitly suggest that initialization plays a role *similar* to pretraining. This is an explicit statement linking two concepts and proposing a potential solution. While it doesn't provide a detailed *howto* for pretraining, it clearly identifies the area of overlap and suggests a relevant concept (pretraining) for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'initialization' and connects it to 'pretraining,' directly addressing the concept of initialization in the context of NGD/NGF. They also use more specific terms like 'discretization' and 'initial value problem.' This clearly identifies the area of interest and uses specific terminology, making it grounded. The suggestion to consider initialization similar to pretraining is also quite specific.", "verifiability_rationale": "The reviewer makes a claim about the role of initialization in NGD/NGF and its similarity to pretraining. This is a claim that requires verification. While the reviewer suggests a direction for investigation (focusing on the connection to IVPs and pretraining), they do not provide direct evidence or citations within the review point itself to support this claim. The suggestion is more of a *potential* area for further research or clarification rather than a definitively verifiable statement.", "helpfulness_rationale": "The reviewer provides a clear connection between the concepts of NGD, NGF, discretization, IVPs, and initialization, and suggests that initialization plays a role similar to pretraining. This directly addresses a potential area of confusion or a need for further explanation in the original paper. The suggestion is actionable in that it points towards a specific area of investigation or improvement, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point implicitly suggests an action related to named entity extraction by stating 'It is not clear how named entities were extracted from the datasets.' However, it does not explicitly state what needs to be done to improve this clarity. The suggestion for English proofreading is explicit, stating 'An Englishproofreading would significantly improve the readability of the paper.'", "grounding_specificity_rationale": "The review point does not explicitly identify which part of the paper or dataset the named entity extraction process refers to, making it weakly grounded. Similarly, the English proofreading suggestion does not specify which part of the paper needs improvement, also making it weakly grounded. Neither part is specific about what needs to be extracted or proofread.", "verifiability_rationale": "The review point contains claims. For named entity extraction, the claim is 'It is not clear how named entities were extracted from the datasets.' This could be considered 3 if examples of unclear extraction were provided. For English proofreading, the claim is 'An Englishproofreading would significantly improve the readability of the paper.' This could be considered 3 if evidence of poor readability was provided. However, neither claim is fully supported by explicit references or logical reasoning within the review point itself.", "helpfulness_rationale": "The review point is helpful in identifying areas for improvement. The suggestion to clarify named entity extraction is a specific action that authors can take to enhance their work. The suggestion for English proofreading is a concrete action that directly addresses readability. While more specific examples could be provided, the core ideas are clear and actionable."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The first part of the review point explicitly states the implication of 'for every arm a' being a single optimistic parameter. The second part of the review point implicitly suggests a specific initialization strategy (T_0 = m Sqrt(T)) and provides a calculation showing an improvement. Both parts are explicit and, in the case of the initialization, concrete.", "grounding_specificity_rationale": "The first part of the review point refers to 'a' without explicitly naming the section, table, figure, or unique aspect being addressed. The second part refers to 'what you give' without explicitly naming the condition or section. Therefore, the grounding is weak in both cases.", "verifiability_rationale": "The first part of the review point makes a judgment about the ambiguity of the wording 'for every arm a' implying a single parameter, which can be considered a claim. The second part makes a judgment about a potential improvement and provides a logical calculation to support it, making it 5.", "helpfulness_rationale": "The first part of the review point points out a lack of clarity in the description, which is helpful for the authors to understand the method better. The second part suggests a concrete alternative initialization and shows an improvement, which is a significant and actionable suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that 'L and E should be defined' and points to specific lines (296 and 302) where the inconsistency in formatting occurs. This indicates a clear action the authors should take, making the comment actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'lines 296 and 302' where the inconsistency in the formatting of 'L' and 'E' is observed. Furthermore, they specify that 'L, E are sometimes italicized'. This precise identification of the location and the formatting style demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer points out an inconsistency in the formatting of variables without providing any external references or logical reasoning to support why this inconsistency is a problem. Therefore, the claim is not wellverified.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential issue with the clarity and correctness of the paper by highlighting the inconsistency in the formatting of variables. This is a valuable piece of feedback that can help the authors improve their work, making the comment 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states that more experiments are needed, making it an explicit action. However, it lacks specific details on *which* experiments to add or *how* to conduct them, making it vague and therefore '3'.", "grounding_specificity_rationale": "The comment does not specify which part of the experimental section is weak or suggest improvements to a particular element. Therefore, it is 1.", "verifiability_rationale": "The comment does not contain a claim. It is a suggestion for improvement, which falls under 'X'.", "helpfulness_rationale": "The comment identifies a weakness and suggests improvement, which is helpful. However, the lack of specificity makes it less helpful than a more detailed suggestion, thus scoring it '2'."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests exploring a broader range of models and techniques beyond LoRA and SPP. While this is a valuable direction, it does not provide specific, actionable steps for the authors. The authors are not told which models or techniques to consider, how to implement the comparisons, or what specific aspects of the models to focus on. The suggestion is general and lacks concrete details.", "grounding_specificity_rationale": "The review point suggests exploring a broader range of models and techniques beyond LoRA and SPP. It does not explicitly identify a specific part of the paper or section where these comparisons should be made. The authors are left to wonder which aspects of the manuscript are relevant for these comparisons. While the suggestion is about a type of comparison, it doesn't pinpoint the location or nature of the comparison within the manuscript.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a suggestion for improvement rather than a statement that needs to be supported by evidence. There is no logical reasoning, common knowledge, or external references provided within the review point itself.", "helpfulness_rationale": "The review point suggests exploring a broader range of models and techniques beyond LoRA and SPP. This is a valuable direction for improvement as it encourages the authors to consider more advanced and potentially more effective methods for parameterefficient finetuning. While it doesn't provide specific *howto* guidance, it points towards a potentially impactful area of research and could lead to significant improvements if the authors follow up. The suggestion is clear and actionable in terms of the *what* (exploring other models) and encourages further investigation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the errors and provides clear, actionable suggestions for correction. For example, it points out the incorrect use of \"of\" vs. \"to\" and suggests using \"to\" for the preposition of a gerund. This is a direct and concrete action the authors can take.", "grounding_specificity_rationale": "The review point explicitly identifies the line number (line 265) where the error occurs. This provides a clear and specific location for the authors to focus their attention. Furthermore, the suggestion to use \"to\" is directly tied to the identified error. The reviewer is not making an inference about what's wrong, but rather pointing to a specific instance.", "verifiability_rationale": "This review point does not contain a claim that requires verification. It's a suggestion for improvement in writing style and a correction of a grammatical error. While it implies the errors exist, it doesn't present a new claim or assertion about the paper's content or methodology. The suggestions are based on standard English conventions.", "helpfulness_rationale": "The review point is highly specific, pointing out exact line numbers and providing clear, actionable suggestions. The reviewer is directly guiding the authors towards improving their writing style and correcting a grammatical error. This level of detail and specificity makes the feedback very valuable and directly actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'Mistakes in Eqs.' which clearly identifies a problem in the equations. The reviewer is asking for clarification on a specific issue (the relationship between matrix inversion and division of samples) within these equations. This is an explicit action that is also concrete as it points to a specific area of concern within the equations.", "grounding_specificity_rationale": "The reviewer refers to 'W4 \u2013 Mistakes in Eqs.' This is an explicit reference to a specific equation number. The reviewer is also asking a specific question about the relationship between two concepts within that equation. This comment accurately identifies the specific part of the paper and clearly specifies the issue being addressed.", "verifiability_rationale": "The comment does not contain a claim. It is a question posed to clarify an issue identified in the equations. Therefore, it does not have verifiable support as it is not making a judgment or assertion.", "helpfulness_rationale": "The reviewer is asking a specific question to clarify an error in their equations. While it doesn't provide a direct solution, it identifies a specific area of confusion, which can be helpful for the authors to focus their debugging efforts and understand the context of the mistake. This is a form of constructive feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment is a general assessment of the paper's novelty and doesn't specify what is wrong or how to improve it. It lacks explicitness and concreteness.", "grounding_specificity_rationale": "The comment is about the paper as a whole and doesn't identify a specific section, table, figure, or unique aspect of the paper. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The comment is an opinion about the paper's incremental nature and doesn't present a claim that requires verification or support. Therefore, it has X.", "helpfulness_rationale": "The comment is a general assessment of the paper's novelty and doesn't provide specific actionable feedback or suggestions for improvement. It is vague and lacks clarity, making it only slightly beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their desire to know the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This is a clear indication of an action the reviewer wants to take or understand. The request is direct and lacks ambiguity regarding the desired outcome.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the experiment section' and 'LDA+LSTM' in their request. This demonstrates a clear attempt to ground the request within the specific context of the paper and the proposed baseline. The request is also specific to the 'topic switch percent metric'.", "verifiability_rationale": "The reviewer is essentially asking for a claim or statement about the performance of the LDA+LSTM baseline. While not a direct claim, the request implies an expectation or question about the baseline's behavior. The potential for this information to be useful (helping the authors understand the baseline) adds a layer of implicit support for verifiability.", "helpfulness_rationale": "The reviewer's request is directly relevant to understanding the performance of the proposed baseline model. Knowing the topic switch percent would provide valuable insight into the baseline's ability to maintain topic coherence over the sequence of text. This information could help the authors diagnose potential issues or identify strengths of their baseline approach."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The reviewer states that the motivation is 'unclear to me' and that they 'do not know what they should do' after reading the comment. This indicates that the comment does not explicitly point out a problem for the authors to solve or a specific action to take. The reviewer's statement about not knowing what to do directly implies that the comment lacks actionable information for the authors.", "grounding_specificity_rationale": "The reviewer's comment focuses on the general problem of predicting the state of occluded objects and the uncertainty in annotations. While they mention 'occlusion,' 'state, including position, size and motion,' and 'annotation,' they do not explicitly identify a specific part of the paper, table, figure, or unique aspect where this problem is occurring. The reviewer's comment is more about the general challenge rather than pinpointing a specific element within the paper being addressed.", "verifiability_rationale": "The reviewer states, 'The motivation of this task is unclear to me. When an object is totally occluded, its state, including position, size and motion, is very difficult to predict. Although authors consume much time to annotate such objects, but the quality can not be guaranteed because we do not know their real states.' This statement presents a claim about the difficulty of predicting occluded object states and the uncertainty in annotations. The reviewer provides a logical reasoning for why the motivation is unclear, linking it to the inherent challenges of predicting occluded states. This reasoning provides support for the claim.", "helpfulness_rationale": "The reviewer explicitly states that the motivation is 'unclear to me' and that they 'do not know what they should do' after reading the comment. They also state that the comment 'does not provide actionable feedback' and that it 'does not offer concrete suggestions or actionable steps for the authors.' This indicates that the comment, while potentially pointing out a problem, does not offer any guidance on how the authors should address it. The lack of actionable feedback makes the comment less helpful."}
{"actionability_label": "1", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "The reviewer states the claim is 'insufficiently backedup' and that the paper 'does not even mention the TD3GA algorithm'. While the reviewer implies a missing action, they don't explicitly state what action is missing or how to implement it. The lack of explicit guidance makes it vague and implicit.", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks for an explanation of why the treesliced Wasserstein distance outperforms the original optimal transport distance. This directly implies an action: to explain the observed performance difference. Therefore, the actionability is high.", "grounding_specificity_rationale": "The reviewer specifically mentions sections 6.1 and 6.2 where the result is discussed. This indicates a clear understanding of the location of the relevant information, demonstrating strong grounding specificity. The grounding is literal: 'Sections 6.1 and 6.2'.", "verifiability_rationale": "The reviewer asks 'why occurs'. This implies a desire for a logical justification or reasoning behind the observed result. The paper should ideally provide reasons for the performance difference, making this review point verifiable. The request for an explanation is a form of verification.", "helpfulness_rationale": "The reviewer's question directly addresses a surprising result. While it doesn't propose a concrete fix, it encourages further investigation and understanding of the findings. This makes the review point helpful in clarifying the results and guiding future analysis. It's not a critique that directly improves the paper, but it's helpful in understanding the current one."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a desire for clarification regarding the word \"confident.\" While the reviewer doesn't specify *what* is confusing about \"confident,\" the intention to seek clarification is clear and actionable. The reviewer is suggesting rephrasing, which is a direct action the authors can take.", "grounding_specificity_rationale": "The reviewer refers to the word \"confident\" within the sentence \"We have found it easier to be confident about applying ceterus paribus convexity;\". While they don't explicitly state which part of the paper they are referring to, they are pointing to a specific phrase and asking for clarification on the word within that phrase. This makes the grounding somewhat specific, as it targets a particular aspect of the text.", "verifiability_rationale": "The reviewer is not making a claim about what is *wrong* with the paper or the sentence. They are asking for clarification on the meaning of the word \"confident\". Therefore, there is X being made that requires verification. The focus is on improving the clarity of communication, not on identifying a factual error.", "helpfulness_rationale": "The reviewer is explicitly asking for clarification on a specific part of the text. This is a valuable piece of feedback as it directly addresses a potential point of confusion for the authors. While it doesn't propose a solution, it is a constructive step towards improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly mentions 'improving clarity and confidence in empirical results' as a goal, which is an explicit action. However, the reviewer also provides specific suggestions like 'polishing of figures,' 'addressing specific issues such as missing axis labels, randomly masked out portions of curves, single seed experiments, core findings in section one are conducted on two small scale datasets and a single architecture type'. While the general goal is explicit, the specific actions are also clearly stated and actionable. Therefore, the action is somewhat explicit and concrete.", "grounding_specificity_rationale": "The review point explicitly refers to 'figures,' 'axis labels,' 'curves,' 'single seed experiments,' 'two smallscale datasets,' and 'single architecture type.' These are specific parts of the paper being addressed. Furthermore, the reviewer explains the issues within these parts, such as 'impedes clarity' and 'lack of confidence in empirical results.' This indicates that the reviewer not only identifies the specific part but also specifies the problems within that part. Therefore, the grounding is fully specific.", "verifiability_rationale": "The review point contains the claim 'there is a lack of polishing of figures and of empirical results which impedes clarity and well as confidence in empirical results.' This is a claim that requires verification. The reviewer provides specific examples to support this claim, such as 'missing axis labels,' 'randomly masked out portions of curves,' 'single seed experiments,' 'two small scale datasets,' and 'single architecture type.' These examples serve as evidence to verify the claim. The claim is thoroughly supported by explicit, sufficient, and robust evidence. Therefore, the claim is 5.", "helpfulness_rationale": "The review point is highly specific and directly addresses the identified weaknesses in the empirical findings. The reviewer provides concrete suggestions for improvement, such as 'improving the polish of figures,' 'addressing the issues with axis labels,' 'conducting multiple seed experiments,' 'evaluating core findings on a broader range of datasets,' and 'exploring different architectures.' These suggestions are actionable and provide clear guidance for the authors. The reviewer's message is clear, and the suggestions are directly linked to the identified problems. Therefore, the review point is 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desired information: 'It would make for a stronger case if the paper reports the numbers observed when the label noise experiment is performed on imagenet with 1000 classes as well'. This is a direct and clear request for specific data points, making it 5 for the authors.", "grounding_specificity_rationale": "While the reviewer doesn't provide a literal section number, the phrase 'the label noise experiment' strongly implies a specific part of the paper or previous work the authors are referring to. The request to include results for 'ImageNet with 1000 classes' further pinpoints the exact area of interest. This allows the authors to anticipate the requested data and understand its relevance.", "verifiability_rationale": "The reviewer makes a clear claim: 'This would further stress test the conjecture. Even if the phenomenon significantly weakens in this setting, the numbers are worth seeing.' This claim is verifiable through the suggested experiment of running the label noise experiment on ImageNet with 1000 classes. The logical reasoning is that this experiment will provide data to test the conjecture, and the suggestion to 'see the numbers' implies a desire for concrete evidence.", "helpfulness_rationale": "The reviewer's suggestion is directly relevant to the stated conjecture and provides a concrete way to test it. Even if the results are not positive, the effort to run the experiment is valuable and directly addresses the concern. The suggestion is actionable and verifiable, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's question is explicit in asking for a justification for the choice of metric. However, the request for 'additional feedback' is vague and doesn't provide a specific action or solution. The lack of a concrete suggestion makes the action somewhat implicit.", "grounding_specificity_rationale": "The reviewer connects the concept of parallel processing in the brain to the technical term 'network updates', which can be considered a form of grounding. However, they do not specify which part of the paper they are referring to or what specific issue they are trying to clarify. The grounding is present but not fully specific.", "verifiability_rationale": "The reviewer poses a question, which can be interpreted as a claim, but does not provide any evidence or reasoning to support it. The request for 'additional feedback' is vague and lacks specific examples or references. The lack of supporting evidence makes the claim 1.", "helpfulness_rationale": "The review contains a relevant question and a request for 'additional feedback', which are generally helpful. However, the lack of specificity in the request for additional feedback makes it less immediately helpful. The reviewer is pointing out a potential area for improvement, but doesn't detail how."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is not actionable. It asks a question about the objective of adversarial prediction accuracy, but it does not provide explicit or concrete instructions on how to improve the draft based on this understanding. The reviewer is asking for information about a concept, not how to apply it.", "grounding_specificity_rationale": "The review point is 1. It does not identify a specific part of the paper or the issue being addressed. It is a general question about the objective of a metric, not a specific critique of a particular section or element of the paper.", "verifiability_rationale": "The review point is not verifiable as it does not contain a claim that can be supported or refuted. It is a question about the objective of a metric, which is not a claim in itself. There is no logical reasoning, common knowledge, or external references provided within the review point itself.", "helpfulness_rationale": "The review point is not helpful. It is a question about the objective of adversarial prediction accuracy, which, while potentially informative, does not directly provide actionable feedback on how to improve the draft. The reviewer is asking for clarification on a concept, not a specific suggestion for change."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point identifies several areas where the authors' draft could be improved, but the language used to describe these areas is somewhat vague. While the reviewer points out missing information (e.g., 'lacks transparency regarding the experiment setup'), the specific actions the authors should take are not always explicitly stated. For example, the reviewer mentions 'no mention of the number of different sets of incontent examples used in the experiments,' but doesn't explicitly state that the authors need to find this information. The reviewer also states that the evaluation 'does not explore the effects of varying the number of InContext Examples,' but doesn't provide a concrete action the authors should take to address this. However, the reviewer does identify specific missing information (e.g., 'the number of different sets of incontent examples'), which suggests a degree of actionability. The reviewer also identifies specific limitations (e.g., 'rely solely on one dataset'), which are concrete actions. The reviewer's language is generally clear enough to guide the authors, but could be more explicit in some instances.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper (e.g., a section, table, figure, or unique element). The reviewer refers to the 'experiment setup' and the 'dataset used' in general terms. While the reviewer identifies limitations related to the evaluation process, they do not pinpoint the exact section or table where these issues are most relevant. The reviewer's comments are more about the overall evaluation methodology and the scope of the dataset rather than specific elements within the paper.", "verifiability_rationale": "The review point contains claims about the evaluation being 'not sufficiently comprehensive' and lacking 'transparency regarding the experiment setup.' These are claims that need to be supported. However, the reviewer does not provide specific examples or references to back up these claims. For instance, they mention the absence of information about 'the number of different sets of incontent examples' but do not provide a source or a specific example of where this information is missing. Similarly, they state that the evaluation 'does not explore the effects of varying the number of InContext Examples' without providing a concrete example of this limitation or a reference to support it. The reviewer also mentions that the evaluation 'rely solely on one dataset,' but doesn't provide a specific example of why this is a limitation or a reference to support this claim. Therefore, while the review points out issues, it does not provide sufficient evidence or reasoning to verify these claims.", "helpfulness_rationale": "The review point provides specific feedback about limitations in the evaluation process, such as the lack of transparency regarding the experiment setup and the reliance on a single dataset. While these points highlight areas for improvement, they do not offer concrete solutions or directions for the authors to take. The reviewer points out problems but doesn't actively help the authors fix them. For example, the reviewer states that the evaluation 'does not explore the effects of varying the number of InContext Examples,' but doesn't suggest an alternative approach or how the authors should address this limitation. The feedback is primarily diagnostic rather than prescriptive. Therefore, while the review points out issues, it does not actively help the authors improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review points out a potential redundancy, suggesting a possible simplification or clarification. While it doesn't *immediately* tell the author how to change their implementation, it encourages the author to consider the relationship between their framework and SimCLR, making it 3.", "grounding_specificity_rationale": "The statement that the contrastive learning framework is the same as SimCLR is generally true and broadly understood within the field. While a highly specific paper might delve into subtle differences, the reviewer's statement is not ambiguous and points to a wellknown relationship, making it fully grounded. The grounding is literal and explicit.", "verifiability_rationale": "The reviewer makes a factual claim that can be verified by someone familiar with contrastive learning. The claim is supported by common knowledge in the field and doesn't require external references, making it 5. The reasoning is logical and doesn't need external evidence to be considered valid.", "helpfulness_rationale": "The review points out a factual correction about the relationship between the contrastive learning framework and SimCLR. This is helpful for the author as it clarifies a potential point of confusion and suggests a possible simplification or clarification, making the review 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point suggests improving related work but doesn't specify *how*. It's a statement of suggestion, not a direct instruction.", "grounding_specificity_rationale": "The review point explicitly mentions 'related work (such as 1,2,3)', directly identifying the specific area of related work to be addressed.", "verifiability_rationale": "The review point makes a suggestion about improving related work, which is an opinion or judgment, not a claim that can be verified.", "helpfulness_rationale": "The review point offers a general suggestion about related work but lacks specific details or actionable steps, making it only slightly beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a *lack* of comparison against existing text GANs and suggests including them. While not explicitly stating what to do, they identify a missing element and suggest a type of comparison. The reviewer also mentions 'SeqGAN' specifically, providing a concrete example of the type of model they are referring to. This provides a clear direction for the authors to take.", "grounding_specificity_rationale": "The reviewer mentions 'existing text GANs' generally and then specifically names 'SeqGAN'. While the general category isn't a specific section, the mention of a specific model grounds the comment to a particular aspect of the paper. The reviewer also identifies the *lack of comparison* as the issue within that specific area.", "verifiability_rationale": "The reviewer makes a claim: 'There is no comparison against existing text GANs...'. They provide some supporting information by mentioning 'SeqGAN', which is a specific example. However, they do not provide a logical reasoning, external references, or concrete examples beyond 'SeqGAN' to justify why this is a significant issue or how the authors should go about making the comparison. The claim is present, but the supporting evidence is limited.", "helpfulness_rationale": "The reviewer identifies a clear gap in the evaluation: the absence of a comparison against existing text GANs. They also suggest a specific type of comparison (against existing text GANs, including pretrained models). This points directly to an actionable improvement for the authors and highlights a relevant area for evaluation. While the suggestion could be more detailed, it provides a clear direction."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential area for improvement (lack of algorithmic focus) and criticizes the novelty, but it does not provide explicit or concrete steps for the authors to take. It is a critique, not a constructive suggestion.", "grounding_specificity_rationale": "The comment criticizes the novelty of the paper and the focus on algorithmic aspects but does not explicitly point to a specific section, table, figure, or unique element of the paper being addressed. The grounding is weak because the authors cannot confidently determine which part the comment refers to. The specificity is underspecific because the comment does not detail what needs to be addressed in this part.", "verifiability_rationale": "The comment contains a claim ('the paper seems limited') but does not provide any supporting evidence or justification for this claim. There is no logical reasoning, common knowledge, or external references to back up the assertion that the paper is limited in novelty. The claim is presented without sufficient support.", "helpfulness_rationale": "The review point raises a valid concern about the paper's novelty and suggests focusing on algorithmic aspects. However, it does not offer concrete suggestions or actionable steps for the authors to take. It is a critique of the paper's current direction rather than a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment implicitly suggests an improvement by pointing out the existence of relevant methods in a different field (computer vision). While it doesn't explicitly state an action like 'Add a comparison to a CV method', the implication is clear. The action is somewhat vague as the reviewer doesn't specify *which* CV method is relevant or *how* it should be compared.", "grounding_specificity_rationale": "The comment explicitly mentions 'a method mentioned in the computer vision setting' and implicitly refers to the potential applicability of these methods to the language task. The grounding is strong because the comment directly refers to a category of methods and their potential relevance. The specificity is somewhat lacking as the reviewer doesn't identify a unique aspect or provide a concrete example of a CV method.", "verifiability_rationale": "The comment identifies a potential weakness in the paper's comparison strategy by suggesting the absence of relevant computer vision methods. It provides a justification (potential adaptability) but lacks specific examples of these methods or a detailed explanation of how they could be adapted. The claim is that the paper should consider these methods, and the reasoning is that they might be applicable. However, the evidence for this claim is somewhat lacking in terms of specific references or detailed explanations.", "helpfulness_rationale": "The comment identifies a potential gap in the paper's comparison strategy by suggesting the inclusion of relevant computer vision methods. It provides a rationale for this suggestion, arguing that these methods might be adaptable to the language task. While the suggestion itself is somewhat vague (no specific CV method mentioned), the *identification of this potential gap* is a valuable piece of feedback. It points to a potential area for improvement in the paper's analysis and framing. The reviewer is not just criticizing the choice of baselines but also suggesting a potential alternative or related area of research to consider."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests estimating the time complexity for scalability but doesn't explicitly state how this should be done or what actions need to be taken. The action is implicit.", "grounding_specificity_rationale": "The comment refers to 'the learning algorithm' generally without specifying a particular part of the paper, a method, or a unique element. The grounding is weak as the authors can only make an educated guess about which part is being addressed.", "verifiability_rationale": "The comment presents a suggestion (estimating time complexity) without providing any logical reasoning, common knowledge, or external references to support its value or necessity for scalability. It lacks a claim that is verifiable.", "helpfulness_rationale": "The comment offers a suggestion related to a crucial aspect of algorithm performance (scalability). While it points to an important consideration, it lacks specific guidance on how to implement the suggestion or why it is essential for the specific context of the paper. The helpfulness is limited as the suggestion is not wellsupported."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a connection to 'properties of universal kernels' and mentions a specific result from 'Chapter 4 of Steinwart and Christmann'. While the exact area of the original paper isn't specified, the reviewer provides a clear action: investigate the connection to universal kernels. The reviewer also specifies the *type* of property being considered (ability to shatter finite datasets). This makes the action quite explicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'properties of universal kernels' and specifically refers to 'Chapter 4 of Steinwart and Christmann'. This provides strong grounding. They are not just guessing; they are referencing a specific section of a standard text. The reviewer also specifies the *type* of property being considered (ability to shatter finite datasets). This makes the grounding very specific within the field of kernel methods.", "verifiability_rationale": "The reviewer is suggesting a *potential* connection and referencing a *specific theoretical concept*. They are not making a claim that *something is wrong* with the original paper. They are offering a suggestion or a pointer to a related area. Therefore, it doesn't fit into the 'claim extraction' category. It's more of a suggestion or a pointer to related work, not a direct claim requiring verification. This leads to 'X'.", "helpfulness_rationale": "The reviewer is offering a *potential* connection and referencing a *specific theoretical concept*. This could be helpful if the original paper was indeed using a method that doesn't inherently consider the properties of universal kernels. It could provide a valuable perspective or a potential improvement. However, without knowing the context of the original paper, it's hard to say *how* helpful it would be. It's a potentially valuable suggestion, but its impact is uncertain."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states 'The discussion around equation (10) is very terse, and not very clearly explained.' This comment identifies a problem (terse and unclear) but does not directly instruct the author on what to do or how to improve the discussion. The author would need to infer the need for more detail and clarity. Therefore, it is implicit and somewhat vague.", "grounding_specificity_rationale": "The review point mentions 'equation (10)'. This allows the reviewer to identify a specific part of the paper. However, the point does not specify *what* is wrong with the discussion around this equation. The author would need to infer the issue. Therefore, it is grounded but not specific.", "verifiability_rationale": "The review point makes a claim: 'The discussion around equation (10) is very terse, and not very clearly explained.' This is a statement of opinion about the clarity of the discussion. However, the review point does not provide any external references or logical reasoning to support this claim. It is a subjective observation without evidence. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point identifies a lack of detail and clarity in the discussion around equation (10). While it points out a problem, it does not offer any specific suggestions or guidance on how the author should improve the discussion. The reviewer is diagnostic rather than prescriptive. Therefore, it is 3 in highlighting an area for improvement but does not actively help the author implement changes."}
