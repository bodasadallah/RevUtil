{"actionability_label": "1 (1)", "grounding_specificity_label": "3 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "2 (2)", "actionability_rationale": "The review point points out a potential issue (noise in the dataset) but doesn't explicitly state what needs to be done. It's a statement of possibility, not a directive. Therefore, it's 1 as it stands. However, it *suggests* an action: 'Check the dataset for noise.' This is a potential for action, but the review itself isn't explicit or concrete.", "grounding_specificity_rationale": "The reviewer mentions 'artificially created,' 'noise,' 'misinformation,' and 'outofcontext images.' These are *specific* aspects of the dataset. The reviewer *doesn't* explicitly state *how* to identify or measure this noise. While the aspects are mentioned, the comment doesn't pinpoint a specific section, table, figure, or unique element of the paper related to this noise. Therefore, it's only **partially grounded**.", "verifiability_rationale": "The reviewer states the *possibility* of noise but doesn't provide any evidence or justification. There's no logical reasoning, common knowledge, or external references provided to support the claim that the dataset might contain noise. The comment is a statement of possibility, not a claim backed by evidence. Therefore, it's **1**.", "helpfulness_rationale": "The reviewer points out a potential problem (noise) in the dataset. While it *could* be helpful to identify this, the review itself doesn't offer a concrete solution or actionable advice. It's a *potential* source of improvement, but the review itself isn't very helpful in guiding the authors *now*."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking for a justification for a methodological choice (the aggregation method) rather than directly asking for actionable feedback on the paper or the review itself. While the reviewer's comment is clear and identifies a potential improvement (better justification), it doesn't directly instruct the authors on how to improve their draft based on this methodological choice. The focus is on *why* something was done, not *what* to do next.", "grounding_specificity_rationale": "The reviewer does not explicitly state which parts of the paper the AND/OR method refers to. They are asking *why* specific alternative aggregation methods were not used *in the context of the paper's structure*. This lack of explicit connection to specific sections or elements of the paper makes the grounding weak. The reviewer is implicitly asking about the relevance of these alternatives to the paper's content.", "verifiability_rationale": "The reviewer states their concern that the justification for not considering the AND/OR or elementwise min/max methods is unclear. However, the provided justification in the 'rationale' field *is* a clear explanation of *why* these alternatives were not considered: they are asking about the *consequences* of using these methods (e.g., how they would affect the interpretation of results) rather than providing explicit references to external literature or logical reasoning based on the nature of the data. While the reviewer's concern about verifiability is valid, the provided justification *does* attempt to explain the reasoning. Therefore, it's not entirely 1.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the justification for a methodological choice. However, the comment itself doesn't directly offer a solution or improvement to the paper based on this concern. The reviewer is asking *why* something was done, not *what* to do next. Therefore, while the comment has merit, it doesn't directly translate to helpful feedback for the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'what splits are used for obtaining the ATIS numbers?' which is a direct and explicit request for information about Table 4. The action is to identify the specific splits used, and it is concrete as the reviewer clearly identifies the table and the information they need.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Table 4' and asks a specific question about the 'splits used for obtaining the ATIS numbers'. This clearly identifies the specific part of the paper being addressed, making the grounding strong. The information about the splits is also clearly specified in the question.", "verifiability_rationale": "The reviewer's comment is a question that requires a factual answer about the experimental setup used to obtain the ATIS numbers in Table 4. If the paper explicitly states the splits used, this information is verifiable. The reviewer is not making a claim but rather asking for clarification, which can be answered with logical reasoning and references to the experimental setup described in the paper.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential area of confusion (lack of clarity on Table 4) and asks for crucial information (the splits used). This is a helpful comment as it seeks to improve the understanding and reproducibility of the results presented in Table 4. The reviewer acknowledges the authors' previous response, indicating the need for more detailed information."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer implies a desire for better wording, but the action is not explicitly stated. The phrasing 'on par or better' is vague and could be interpreted as downplaying underperformance. The reviewer suggests the wording 'mimics' another paper, but doesn't provide specific actionable steps on how to improve the wording itself.", "grounding_specificity_rationale": "The reviewer makes a general comment about the results ('the results') without specifying a particular section, table, figure, or unique aspect of the paper. The comment is 1 at all.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a statement of opinion about the phrasing used. Therefore, it falls under 'X'.", "helpfulness_rationale": "The reviewer provides a specific example of how the phrasing 'on par or better' might be interpreted negatively, highlighting a potential issue for the authors. This directly addresses a practical concern and offers a suggestion for improvement, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point primarily criticizes the lack of novelty without explicitly stating what needs to be changed or how the work can be improved. While the reviewer points out existing work on adversarial attacks, they don't provide specific actionable feedback on how the current work could be made more novel. The criticism is more of a statement of fact than a prescriptive improvement suggestion.", "grounding_specificity_rationale": "The reviewer's statement about the lack of novelty is 1 in the paper. They make a general claim about adversarial attacks being wellstudied without specifying which aspects of their work are lacking novelty or how it differs from existing approaches. The grounding is weak because the reviewer doesn't point to a specific section or element of the paper that needs improvement.", "verifiability_rationale": "The statement about the lack of novelty is verifiable as it claims a deficiency in the paper's contribution. However, the reviewer does not provide any specific examples, references, or logical reasoning to support their claim. The verifiability is low because the reviewer's assertion lacks concrete evidence or justification.", "helpfulness_rationale": "The review point is not helpful because it does not offer any actionable feedback or suggestions for improving the work. The reviewer identifies a perceived lack of novelty but fails to provide any concrete steps or insights on how the current work could be made more innovative. The statement is a critique without constructive improvement suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point does not suggest any concrete actions or improvements to the paper. It simply states an opinion about the space allocation. There is no explicit or implicit recommendation on how to adjust the space or what benefits it would provide.", "grounding_specificity_rationale": "The reviewer refers to 'a whole section of the paper' and 'experimental results' generally, without specifying which section, figure, or unique aspect of the paper is being discussed. The reference is vague and does not identify a specific part of the paper being addressed.", "verifiability_rationale": "The review point expresses an opinion about the space allocation but does not provide any evidence or justification for why it is excessive. It lacks a claim that can be verified.", "helpfulness_rationale": "The review point is not helpful because it does not offer any concrete suggestions or actionable feedback to the authors. It is a subjective statement about the paper's structure and length, without providing any evidence or justification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the paper uses integrated gradients and postprocessing steps, which are direct actions the authors should implement. The reviewer also suggests an ablation study as a needed improvement, which is a concrete action. The reviewer clearly identifies the areas where the authors need to make changes.", "grounding_specificity_rationale": "The reviewer mentions 'integrated gradients,' 'postprocessing steps,' and 'falsepositive neurons,' which are specific parts of the paper. They also explicitly state the need for an 'ablation study' to demonstrate the importance of postprocessing. This shows the reviewer can accurately pinpoint the relevant sections and the specific issue within those sections.", "verifiability_rationale": "The reviewer makes a claim about the paper's lack of demonstration of the importance of postprocessing steps. While the reviewer suggests an ablation study, they don't provide any evidence within the review point itself to support the claim that the paper is indeed lacking this. The reviewer's suggestion is a logical next step but doesn't constitute verification based on the information provided in the review point.", "helpfulness_rationale": "The reviewer's overall tone is negative, suggesting that the comment is not particularly helpful. They point out a deficiency (lack of demonstration of postprocessing importance) and suggest a solution (an ablation study), but they don't provide any evidence or reasoning within the review point to support the claim that the paper is lacking this. The reviewer's suggestion, while valid, doesn't address a perceived critical flaw in the paper's current state."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the proposed method (matching the head of noun phrases) and then immediately identifies a limitation: 'It\u2019s not clear how to handle the situation when the head word is not a pronoun.' This indicates an explicit statement of a problem. However, the reviewer does not provide a concrete solution for this issue. While the core idea of matching noun phrase heads is a potential action, the lack of a specific mechanism for handling nonpronoun cases makes the action somewhat vague and not fully actionable.", "grounding_specificity_rationale": "The reviewer proposes a method (matching the head of noun phrases) and immediately specifies how it should be applied (for pronoun predictions). This strong connection between the proposed method and its intended use clearly grounds the suggestion. The reviewer also identifies a specific type of prediction (pronoun) and a specific mechanism (noun phrase head matching), making the suggestion quite specific to the identified problem. Therefore, the comment is both grounded and specific.", "verifiability_rationale": "The reviewer makes a claim that the proposed method is 'not clear how to handle the situation when the prediction is a pronoun.' They then suggest a solution ('matching the head of noun phrases') but do not provide any evidence or justification for why the original method was unclear or why this new method is superior. The suggestion is presented as a potential fix without supporting arguments. Therefore, the claim is made without sufficient verification or justification.", "helpfulness_rationale": "The reviewer identifies a specific problem (handling nonpronoun predictions) and offers a potential solution (matching the head of noun phrases). While the solution is not detailed, it points in a direction that could be helpful for the authors. The reviewer's comment is clear and directly addresses a potential limitation in the proposed method. Therefore, the comment identifies a meaningful weakness and offers a suggestion, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "Not Verifiable", "helpfulness_label": "Helpful", "actionability_rationale": "The review point contains two parts. The first part, 'The abstract is written well and invokes intriguing early', is a positive statement and does not provide an actionable suggestion. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', explicitly states a direction for improvement and provides a specific example. Therefore, while one part is not actionable, the other is actionable. The overall actionability is 3 as it suggests a potential improvement direction with a specific example.", "grounding_specificity_rationale": "The review point contains two parts. The first part, 'The abstract is written well and invokes intriguing early', does not identify a specific part of the paper being addressed. The second part, 'could potentially be made even better if, for 'evaluating with gold answers is inconsistent with human evaluation'  an example of the inconsistency, such as models get ranked differently is also given there.', explicitly mentions the inconsistency between gold answer evaluation and human evaluation and provides a specific example of this inconsistency. Therefore, the second part is 5, making the overall grounding specificity fully grounded.", "verifiability_rationale": "The review point does not contain a claim that requires verification. The first part is a positive statement about the abstract. The second part suggests a potential improvement direction but does not provide a claim that needs to be supported by evidence. Therefore, the review point is not verifiable as it does not present a claim that needs justification or evidence. The reviewer is suggesting a potential area for further investigation or clarification, but not making a definitive claim that requires verification.", "helpfulness_rationale": "The review point offers a suggestion for improvement regarding the abstract, specifically pointing out a potential inconsistency between gold answer evaluation and human evaluation and providing an example. While it doesn't offer a solution, it provides a direction for the author to explore and potentially improve their work. Therefore, the review point is helpful as it suggests a valuable area of investigation and provides a concrete example to guide the author's thinking."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the paper claims the GRU outputs a 'single vector' while suggesting the correct interpretation is a 'set of vectors' based on Figure 2. This is an explicit statement of the paper's description. The reviewer also infers an action: the authors should clarify the output representation of their GRU. The reviewer provides a clear alternative interpretation based on the figure, making the intended meaning quite concrete.", "grounding_specificity_rationale": "The reviewer directly references 'line 212' and 'Figure 2' to pinpoint the discrepancy. They also specify the components involved ('source sentence', 'encoder', 'vector representation') showing a clear understanding of the relevant parts of the paper. The reviewer clearly identifies what is wrong ('a single vector' vs. 'a set of vectors') and where it occurs ('line 212' and 'Figure 2'). This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim: 'The sentence in line 212... is not strictly correct.' This is a clear statement of a perceived error. The reviewer also provides a potential justification for the discrepancy by referencing 'Figure 2' and suggesting an alternative interpretation ('a bidirectional encoder that encodes the source sentence into a set of vectors...'). While not a full citation, this provides a source of verification and a potential explanation, making the claim 3.", "helpfulness_rationale": "The reviewer's point is 5. They directly identify a potential error in the paper's description. They also offer a clear alternative interpretation based on a figure, guiding the authors towards a likely correct understanding. The reviewer's comment is specific, actionable, and directly addresses a potential ambiguity, making it very constructive for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the issue with the yaxis label of figure 5 and suggests a concrete change. The suggestion is to use 'Exact Match ratio' directly, which is a clear and actionable improvement for the authors to implement.", "grounding_specificity_rationale": "The comment explicitly mentions 'figure 5' and clearly identifies the issue with the yaxis label. It also specifies the desired change, which is to use 'Exact Match ratio' directly. This provides a precise and specific reference point for the authors.", "verifiability_rationale": "The comment identifies a potential issue with the clarity of the yaxis label in figure 5. While it doesn't provide external references, the suggestion itself is a form of implicit justification, guiding the authors to consider the directness of the label. The authors can directly apply this suggestion by checking the label in figure 5.", "helpfulness_rationale": "The comment is clear, specific, and directly points out a potential area of confusion for the authors. It suggests a straightforward improvement by using a more direct label. This is a constructive and actionable feedback that empowers the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a concern about societal biases in knowledge bases, which is an implicit action. However, the suggestion to 'attack implicit offensive texts with reasoning chains' is vague and lacks concrete steps on how to implement this. Therefore, while the concern is raised, the suggested action is not clearly defined or actionable.", "grounding_specificity_rationale": "The reviewer mentions 'knowledge bases' and the potential issue of 'societal biases,' which can be considered a form of grounding. However, they do not specify a particular section, table, figure, or unique aspect within the paper where this issue arises. The suggestion is also very general and does not point to a specific part of the paper.", "verifiability_rationale": "The reviewer makes a claim about the lack of discussion on societal biases in knowledge bases. However, they do not provide any evidence, reasoning, or references to support this claim within the review point itself. The suggestion to 'attack implicit offensive texts with reasoning chains' is a potential solution, not a verification of the problem.", "helpfulness_rationale": "The reviewer raises a valid concern about potential societal biases in knowledge bases, which is relevant to the authors. However, the suggested approach is very general and lacks specific actionable steps on how to check for biases or implement the reasoning chain method. The review points out a problem but doesn't offer concrete solutions for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem (difficulty in showing value) and suggests a solution (improve the attention mechanism). While it points to a weakness, the suggestion is broad and lacks specific details on how to improve the attention mechanism.", "grounding_specificity_rationale": "The review point mentions seq2seq MTL and attention but does not specify a particular part of the paper or analysis that is causing the difficulty in demonstrating value. It is a general statement about the setting.", "verifiability_rationale": "The review point is a critique of the process of showing value in seq2seq MTL and attention mechanisms, rather than presenting a claim that can be verified with evidence. It does not offer a specific claim or justification for why attention is difficult to show value.", "helpfulness_rationale": "The review point identifies a valid issue (the difficulty in demonstrating the value of attention in seq2seq MTL) and offers a relevant suggestion (improving the attention mechanism). While the suggestion is broad, it is still actionable and provides direction for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The comment implicitly suggests that the absence of strong baselines is a problem, but it doesn't explicitly state what the authors should do to address this. The action of adding baselines is not directly requested or implied.", "grounding_specificity_rationale": "The comment explicitly mentions 'Table 3, MCNC' and 'strong baselines that are not compared here', indicating a clear identification of the specific part of the paper being addressed. It also mentions 'many strong baselines', providing specific examples.", "verifiability_rationale": "The comment states that 'MCNC should have many strong baselines that are not compared here' and that 'this comment is 1 at all'. This is a claim that requires justification, but the justification is missing. The reasoning is present ('should be addressed'), but the supporting evidence or references are absent.", "helpfulness_rationale": "The comment directly points out a significant omission ('many strong baselines that are not compared here') and requests a justification ('can you justify the reason?'). This is a clear and actionable feedback that empowers the authors to improve their draft by understanding the missing comparisons."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises a question about the necessity of a separate concept map extraction task, suggesting that general summarization might suffice. While this implies a potential area for improvement, it doesn't provide a direct, actionable suggestion for the authors to improve their *concept map extraction* method itself. The reviewer is more questioning the *purpose* of the separate task rather than providing a clear path to fix it.", "grounding_specificity_rationale": "The reviewer's statement is a general observation about the challenges of distinguishing concept maps as the number of nodes increases. They do not specify which part of their own paper they are referring to or provide any specific details about the issues they are encountering with a particular concept map. The reference to 'this' is vague and doesn't pinpoint a specific section, table, figure, or unique aspect of their work.", "verifiability_rationale": "The reviewer's point about the potential redundancy of a separate concept map extraction task is presented as a hypothesis or suggestion for improvement. They offer a reason (readability) but do not provide any concrete evidence or references to support their claim. The statement is a potential observation rather than a verifiable fact about their work or a specific issue they are facing.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the potential overlap between general summarization and concept map extraction. They suggest that focusing on general summaries might be more efficient for readability. While this offers a potential alternative approach, it does not directly instruct the authors on how to improve their *concept map extraction* method. It's more of a suggestion for a broader improvement in the field rather than a specific, actionable feedback for the authors' current task."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a potential issue but lacks a clear and direct action for the authors to take. It's more of a symptom than a clear instruction on how to fix it. The criticism is implicit (implying the writing is unclear or confusing) and vague (doesn't specify *what* is misleading).", "grounding_specificity_rationale": "The reviewer mentions \"lines 102106\" which grounds the comment to a specific part of the paper. However, the criticism itself, \"is misleading,\" is a general statement about the content of those lines, not a specific issue within that section. The grounding is weak because the reviewer doesn't pinpoint the *exact* confusing element within those lines. The authors cannot confidently determine which part the comment addresses (it's about lines 102106, but not the specific issue within). However, the comment clearly specifies what needs to be addressed in this part (lines 102106 are misleading).", "verifiability_rationale": "The reviewer states a claim: \"Lines 102106 is misleading.\" This is a statement of opinion or judgment about the paper's content. The reviewer doesn't provide any evidence or justification for this claim within the review point itself. It's a statement that needs to be supported by the authors or the reviewers who assessed those lines. The comment contains a claim without any supporting evidence or justification.", "helpfulness_rationale": "The reviewer identifies a potential issue (\"lines 102106 is misleading\") but doesn't offer any specific suggestions or explanations for why the lines are misleading or how the authors should improve them. The criticism is a statement of a problem without a constructive solution. The comment identifies a weakness or improvement area but is vague, lacks clarity, or provides minimal guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The suggestion to use the 'same feature set' from Uto et al. (2020) is an explicit action. While it doesn't specify *how* to obtain those features, the reviewer clearly states the intention, making it actionable for the author.", "grounding_specificity_rationale": "The comment explicitly mentions 'Uto et al. (2020)''s system' and 'Uto et al. (2020)''s same feature set'. This indicates a strong grounding as the specific paper and feature set are named, allowing the author to directly identify the relevant information.", "verifiability_rationale": "The comment presents a suggestion ('Perhaps using Uto et al. (2020)'s same feature set could also improve the results of this work.') without providing any logical reasoning, external references, or examples to support it. It is a claim that requires further investigation and experimentation, but it is not currently verifiable.", "helpfulness_rationale": "The comment is relevant to the goal of improving performance, as it suggests a practical approach by using existing features. However, it lacks novelty and does not provide any new insights or guidance beyond replicating an existing experiment. The suggestion is clear and actionable, but it doesn't offer a significant contribution or alternative approach, making it 3 but not highly impactful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their opinion about the substructure representation and the appropriateness of the term \"knowledge.\" They also provide a specific alternative (constituent parse). This is an explicit action and concrete details on how to implement the inferred action.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'substructure\" part of the paper they are referring to. They also provide a specific suggestion for its representation (sequence of words or constituent parse) and critique the term \"knowledge.\" This indicates a clear identification of the specific part and its issues.", "verifiability_rationale": "The reviewer makes a claim about the substructure representation and the term \"knowledge\" but does not provide any evidence or reasoning to support their claim. They suggest an alternative but do not explain why it is better.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the paper's terminology and suggests an alternative representation. While the suggestion is concrete, the lack of justification or evidence to support why the current approach is problematic or why the alternative is better makes the helpfulness somewhat limited."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the steps to create a baseline PCFG with a smaller state space and directly parameterized matrices. It provides the dimensions of the matrices involved, which is a concrete detail on how to implement the proposed baseline. The purpose of comparing perplexity is also clearly stated. The reviewer is directly identifying a method and its application.", "grounding_specificity_rationale": "The review point mentions PCFGs, state size, and specific matrices (H, I, J, K, L) with defined dimensions. It refers to the rank 'r' of the original PCFG and the state size of the smaller one. While it doesn't explicitly point to a specific section or table in a paper, the concepts are clearly relevant to the context of PCFGs. The reviewer is specifying the parameters of the smaller PCFG and the quantities being compared (perplexity).", "verifiability_rationale": "The review point presents a claim: 'under this setting, parsing F1 might not be directly comparable, but perplexity can still be compared.' It provides a method for creating the baseline PCFG and explains the rationale for comparing perplexity. The dimensions of the matrices are provided, which would be sufficient for someone to attempt this comparison. The claim is supported by the described methodology and the stated reason for comparing perplexity.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the authors: to create a baseline PCFG with a smaller state space and directly parameterized matrices. The reviewer explicitly states the dimensions of the matrices and the purpose of the comparison (perplexity). This provides the authors with a starting point for their experiments and a reason to compare their model's performance. The suggestion is specific and directly related to the original PCFG's rank. However, the review point does not delve into the expected outcomes of this comparison or provide guidance on interpreting the results, making it somewhat incomplete in terms of providing full constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks the author to add information about the maximum number of tasks done by any annotator. While it implies the author should add this information, it doesn't explicitly state the action or provide guidance on how to find this information. It also doesn't specify why this is important.", "grounding_specificity_rationale": "The review point refers to 'any annotator' and 'tasks done by any annotator.' This is very general and doesn't point to a specific section, table, figure, or unique element in the paper. The 'any' makes it weakly grounded.", "verifiability_rationale": "This review point is a suggestion for improvement, not a claim that needs verification. There is X being made that requires justification.", "helpfulness_rationale": "The review point suggests an improvement, which is generally helpful. However, it's a very specific and localized suggestion. It doesn't provide a lot of actionable guidance or explain why this information is important."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a problem with understanding the paper's narrative, stating that the experiments are difficult to connect to the research question and hypothesis. While the reviewer doesn't explicitly state what needs to be changed, the act of identifying this problem implies a desire to improve the clarity and integration of the paper. This can be considered an implicit action. However, the action itself is vague, as the reviewer doesn't specify *how* the connection between the experiments and the question/hypothesis needs to be made clearer. Therefore, it's not a concrete action, making it 3.", "grounding_specificity_rationale": "The reviewer's comment is about the overall difficulty in understanding the paper's narrative and the connection between the experiments and the research question/hypothesis. They do not pinpoint a specific section, table, or figure as unclear. Instead, they express a general feeling of confusion about the 'whole picture.' The reviewer's comment is highlevel and doesn't identify a specific part of the paper that needs clarification. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer's comment is a statement of opinion and a suggestion for improvement (making the connection clearer). It does not present a claim that can be verified through logical reasoning, common knowledge, or external references. The reviewer is not pointing out a factual error or a missing citation. They are making a judgment about the clarity of the paper's presentation. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer's comment is clearly aimed at improving the paper. They identify a problem (difficulty understanding the connection between experiments and research question/hypothesis) and suggest a way to address it (improving clarity). This is a valuable piece of feedback that directly addresses a reader's experience with the paper. While the feedback is not specific about *what* needs to be changed, it clearly points towards improving the paper's narrative and connection between results and theory. Therefore, it is helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states \"I don't think the probabilistic connection is drawn very well.\" This is a statement of opinion about the quality of the connection, not a specific action the authors should take. While it implies a potential area for improvement, it doesn't directly instruct the authors on what to do. The action is implied but not explicitly stated and concrete.", "grounding_specificity_rationale": "The reviewer's comment \"I don't think the probabilistic connection is drawn very well.\" is a general critique of the approach, not a specific comment on a particular section or concept within the paper. They do not identify which part of the paper they are referring to when they talk about the \"probabilistic connection.\" Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer's statement \"I don't think the probabilistic connection is drawn very well.\" is a subjective opinion about the quality of the approach. It does not contain a claim that requires verification or support. There are no references to external works or logical reasoning provided in this statement.", "helpfulness_rationale": "The reviewer's comment is a critique of the *approach* used, specifically the probabilistic connection. While this points to a potential area for improvement in the methodology, it does not offer specific, actionable feedback on how the authors should modify their draft. The comment is more about the *motivation* or *formalization* of the connection rather than a direct suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the 'robust training scheme' and attributes its likely lack of scalability to the 'dimensionality of the data' and the 'size of V'. This indicates an explicit action or suggestion regarding the method's applicability.", "grounding_specificity_rationale": "The reviewer makes a general statement about the applicability of a method to 'practical datasets, particularly those supported on highdimensional domains' without explicitly pointing to a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer states a belief about the limitations of the robust training scheme and offers a reason for this belief, linking it to the 'dimensionality of the data' and the 'size of V'. While a reason is provided, it's not definitively verifiable from the information given in the review point.", "helpfulness_rationale": "The reviewer raises a valid concern about the practical applicability of a proposed method and offers a potential reason for its limitations. While it doesn't provide a direct solution, it highlights a relevant area for consideration for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a gap in the paper's justification for using a 4year timeframe for studying style shifts. They state, 'Without these answers, it is hard to appreciate what the model is capturing.' This points to an actionable gap: the authors need to explain the limitations of the dataset timeframe and how it affects the model's understanding of style. The reviewer is not just pointing out a problem; they are also suggesting a solution (by providing justification).", "grounding_specificity_rationale": "The reviewer's comment is a general question about the choice of datasets and the nature of style shifts over a 4year period. They do not explicitly point to a specific section, table, figure, or unique aspect of the paper. While they are asking for clarification, the reference to the dataset is broad and lacks specific grounding within the paper's content.", "verifiability_rationale": "The reviewer is posing a question about the dataset and the model's ability to capture style shifts. While they are not making a definitive claim, the question itself is a request for information that would help the authors. It doesn't present a logical reasoning, common knowledge, or external references. Therefore, it doesn't fit the criteria for verifiability. It's more of a request for clarification rather than a verifiable statement.", "helpfulness_rationale": "The reviewer's comment directly points to a weakness in the paper's justification. They are asking for clarification and examples of style shifts, which directly addresses a potential area of confusion for the authors. This question is specific and directly requests information that would be beneficial for the authors to understand and improve their model."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a distinction between 'hard prompt work updates the frozen model' and 'ones that don't' and even suggests a potential reference point. The suggestion is clear and actionable for the authors.", "grounding_specificity_rationale": "The review point refers to 'hard prompt work updates the frozen model' and 'ones that don't.' While it uses technical terms, it doesn't explicitly point to a specific section, table, or figure in the paper. The grounding is implied rather than explicitly stated.", "verifiability_rationale": "The review point presents a suggestion ('I think it would make sense to make a distinction...') and even suggests a starting point for further investigation ('Schick and Sch\u00fctez, etc.'). While the specific reference isn't fully detailed, the suggestion itself is a claim that can be verified through further research or by examining the cited work.", "helpfulness_rationale": "The review point directly addresses a potential point of confusion for the authors regarding different types of model updates. It provides a clear categorization and even a potential starting point for further investigation. This is a very helpful suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing links to specific prior work and highlights the key structural and inferential similarities. This directly points to a actionable improvement: the authors should include a discussion of these related works and explain how their approach relates to or differs from them.", "grounding_specificity_rationale": "The reviewer not only mentions the specific works but also highlights the 'similar structure of the CRF' and the 'ability to perform exact inference' as key similarities. This demonstrates strong grounding as the specific paper and the relevant feature are identified. The reviewer also implies the need to discuss the relevance of this prior work, adding to the specificity.", "verifiability_rationale": "The reviewer makes a clear claim that the paper is missing a discussion of relevant prior work. They further support this claim by stating that these prior works have a 'similar structure of the CRF' and the ability to perform 'exact inference'. This provides a logical reasoning and specific examples, making the claim verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'include a discussion of relevant prior work on Continuous Conditional Random Fields and Conditional Neural Fields that has a similar structure of the CRF and ability to perform exact inference'. This directly addresses a potential weakness and provides specific guidance on how to improve the paper. The reviewer also explains *why* this prior work is relevant, making the feedback 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks for experiments to understand WPA's behavior with different inputs, which is a direct and actionable request. They suggest testing with `np.ones` and exploring other inputs that could represent 'white papers'. This directly points to a specific area for improvement in the model's understanding. While the reviewer doesn't provide a specific solution, they are prompting the authors to conduct experiments, which is a clear direction for action.", "grounding_specificity_rationale": "The reviewer refers to 'WPA' specifically, which is good grounding. However, the concept of a 'white paper' input is not explicitly defined or grounded in the paper's context. It's more of a suggestion for an experiment rather than a clearly identified part of the work. The reviewer is prompting for an *experiment* related to understanding WPA, rather than directly pointing to a specific section or table with a clear issue.", "verifiability_rationale": "The reviewer is not making a definitive claim that requires verification. They are suggesting experiments to *explore* the behavior of WPA, rather than stating something that needs to be proven. The request is more about prompting further analysis and investigation rather than making a claim that needs supporting evidence. The reviewer is asking for *how* WPA works, not *what* it does currently.", "helpfulness_rationale": "The reviewer's point is not inherently harmful but lacks a concrete solution. While it prompts the authors to investigate and potentially discover new insights, it doesn't directly tell them how to improve their model. The request for 'insights beyond just performance' is valuable for research directions but doesn't provide a direct path to improvement. The reviewer is more of a suggestion for further exploration than a direct prescription for action."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states an action (clarify the method) but is vague on how to apply it.", "grounding_specificity_rationale": "The comment explicitly mentions which part of the paper it addresses (method) and clearly identifies the issue with that part (similarity to a specific related work).", "verifiability_rationale": "The comment asks for clarification, not a claim that needs verification.", "helpfulness_rationale": "The comment asks for clarification, which is valuable but doesn't directly improve the draft within the review itself."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer poses two questions: 'Is it fair to compared with other methods?' and 'could the proposed technique promote existing Class incremental semantic segmentation methods?'. While the questions highlight potential issues or areas for exploration, they don't provide explicit instructions on what the authors should do. The first question probes the validity of the comparison, and the second explores the potential of the technique. Neither directly instructs the authors on how to improve their draft.", "grounding_specificity_rationale": "The reviewer mentions 'a proposal generator pretrained on MSCOCO'. While they identify the *source* of the pretraining data, they don't explicitly pinpoint a *specific part* of the paper or the proposed method that is directly affected or needs clarification due to this choice. The concern is about the *source* of the data, not a specific element within the paper. The reviewer also asks a question about future possibilities, which doesn't directly ground the criticism to a specific part of the paper.", "verifiability_rationale": "The reviewer raises concerns about the fairness of the comparison and the potential for the proposed technique to enhance existing methods. However, the reviewer does not provide any evidence, arguments, or references to support these claims. The statements are presented as questions or potential issues, not as verifiable claims made by the authors. There is no logical reasoning, common knowledge, or external references provided to support these statements as claims made by the authors.", "helpfulness_rationale": "The reviewer's comment is more of a concern and a forwardlooking question rather than a direct suggestion for improvement. They are questioning the fairness of the comparison and speculating on the potential of the technique. While these points are relevant to the authors' work, they do not provide specific, actionable feedback that would directly help the authors improve their current draft. The questions are about potential issues or future directions, not concrete suggestions for improvement within the current work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the missing information: 'However, the experimental section (Sec. 3) did not mention or discuss how these parameters are set and how sensitive the performance is with respect to these parameters.' While the reviewer identifies the missing information, they don't provide specific values or ranges for the parameters. The action is implicit (identifying the missing information), but it's not explicitly stated how to set the parameters or how sensitive the performance is to them.", "grounding_specificity_rationale": "The reviewer does not point to a specific section or detail within the paper regarding the experimental setup. They are pointing to a general omission of information that *should* be present. The grounding is in the general knowledge of experimental design, not in specific details within the paper itself.", "verifiability_rationale": "The reviewer makes a claim about what the experimental section *should* contain: 'the experimental section (Sec. 3) did not mention or discuss how these parameters are set and how sensitive the performance is with respect to these parameters.' This claim is generally verifiable in the broader research community (knowledge of good experimental practices). However, the paper itself does not provide this information, making the review 1 within the paper's content.", "helpfulness_rationale": "The reviewer is informing the authors of important information they likely missed regarding the experimental setup. This is a valuable piece of feedback that could help the authors reproduce and understand the results. The reviewer is highlighting a crucial omission in the reported experimental details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points out a *problem* (tersely written section) but doesn't offer a *specific action* to fix it. It mentions 'slower development\" which is vague.", "grounding_specificity_rationale": "The comment explicitly states \"Section 4\" and then describes its characteristic (\"very tersely written\"). This directly identifies the specific part of the paper being addressed.", "verifiability_rationale": "The comment states \"Section 4 is very tersely written.\" While it expresses an opinion, it's based on a general understanding of what \"tersely\" means in this context, which can be considered a form of logical reasoning.", "helpfulness_rationale": "The comment identifies a valid issue (tersely written section) and, implicitly, suggests improvement ('slower development\"). While the *how* isn't specified, it still provides a direction for the author to improve."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer raises several questions about the implementation details of the bilinear layer and its relation to other approaches. While the paper describes the use of a bilinear layer, it doesn't explicitly state the exact type of bilinear layer used or how it differs from other common bilinear pooling methods beyond the general mention of 'bilinear layer'. The paper also lacks a clear explanation of how the bilinear layer is swapped out with Hadamard product and MCB approaches. Furthermore, the role of Equation (3) in the dimensionality reduction process is not explicitly stated in the context of the bilinear layer implementation. The reviewer's questions are about understanding the implementation details rather than a direct request for an action.", "grounding_specificity_rationale": "The reviewer's questions are directly related to the implementation of the bilinear layer and its relation to other methods. The paper should ideally specify which 'bilinear layer' is being referred to and how it differs from other common bilinear pooling methods. The paper should also clarify the exact mechanisms for replacing this layer with Hadamard product and MCB approaches. The role of Equation (3) in the dimensionality reduction process is also a specific implementation detail that should be addressed. The reviewer's questions are clearly linked to specific implementation aspects of the method.", "verifiability_rationale": "The reviewer is asking for clarification on the implementation details of the bilinear layer and its relation to other approaches. This is a request for information, not a claim that needs to be verified. The paper should ideally provide clear explanations and references to support the implementation choices. However, the reviewer's statement is not a claim that can be verified or unverified. The verifiability is low as the reviewer is not making a claim that requires evidence.", "helpfulness_rationale": "The reviewer's questions are about understanding the implementation details of the bilinear layer and its relation to other approaches. While these questions are valid and could be helpful for the authors, the paper itself does not provide the necessary information to answer them. The lack of clarity in the paper regarding these implementation details makes the reviewer's request for clarification potentially helpful for the authors. However, the paper itself is not providing the information needed to answer the reviewer's questions, so the helpfulness of the review point is limited."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the concern about the claim of stateoftheart results and the contribution of the first step, making it clear what needs to be improved. The reviewer also suggests a comparison with existing detection methods, which is a concrete action to address the identified issue.", "grounding_specificity_rationale": "The reviewer refers to 'stateoftheart results,' 'challenging scene text recognition tasks,' and 'deeplearning based approaches,' which provides some level of specificity. However, the reviewer does not explicitly name a specific section, table, or unique aspect of the paper being addressed. The reviewer also suggests a comparison with detection methods, which is somewhat specific, but the overall grounding of the initial claim is not fully precise.", "verifiability_rationale": "The reviewer makes a claim about the results being stateoftheart and outperforming deeplearning approaches. This claim is not supported by any specific evidence, references, or logical reasoning within the review point. While the reviewer suggests a comparison with detection methods, this is presented as a general suggestion without any backing within the provided text.", "helpfulness_rationale": "The reviewer provides a clear and specific criticism of the authors' claims and suggestions for improvement. They point out a lack of transparency in the results and propose a concrete alternative (comparison with detection methods). This actionable feedback is directly aimed at helping the authors improve their work."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the *lack* of comparison with a specific method. While it doesn't directly tell the authors *how* to perform the comparison, it clearly identifies the *action* of comparing with 1 and suggests a *type* of comparison (performance). This makes it 2.", "grounding_specificity_rationale": "The review point explicitly mentions '1' and its specific techniques ('intertask ensemble' and 'intratask ensemble'). It also specifies the *purpose* of the comparison as 'performance comparison'. This clearly grounds the comment to a specific part of the paper and its intended action.", "verifiability_rationale": "The review point makes a claim that 'the authors didn\u2019t include the method comparison or performance comparison.' However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. It simply states the absence of something without explaining *why* it's missing or how it would be beneficial.", "helpfulness_rationale": "While the review point identifies a valid gap in the related work and suggests a meaningful comparison, it lacks justification for why this comparison is important or how it would help the authors. The reviewer points out a missing piece but doesn't explain *why* it's crucial or how it would improve the work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states the action of including related work A and highlights its cruciality, making it clear what needs to be done.", "grounding_specificity_rationale": "The review point explicitly mentions the related work A and states its importance, allowing the authors to accurately pinpoint the section that needs attention.", "verifiability_rationale": "The review point makes a claim about the importance of modular networks for VQA and provides a justification by stating that A is crucial. This claim is logically supported and verifiable.", "helpfulness_rationale": "The review point is clear, identifies a specific area for improvement (lack of mention of modular networks), and provides a concrete suggestion (include work A). This directly helps the authors understand and potentially improve their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states they found the distinction between static and temporal features confusing because the paper doesn't clearly define 'S' and 'Xt'. While the reviewer *wants* the paper to be clearer, the comment itself doesn't explicitly state an action to be taken, nor does it directly identify a missing part to be added. It points to a lack of clarity.", "grounding_specificity_rationale": "The reviewer explicitly states: \"what is S and Xt\". This directly identifies the specific part of the paper (the definitions of 'S' and 'Xt') that is causing confusion. The comment is precise and points to a specific element within the paper.", "verifiability_rationale": "The reviewer states: \"I found the notation / the explicit split between 'static\" and temporal features into two variables confusing, at least initially. In my view this requires more information than is provided in the paper (what is S and Xt).\" This comment contains a claim (the statement about the confusion). However, the reviewer does not provide any external references or logical reasoning to support why this confusion is a problem or why more information is needed. The justification is based on the reviewer's personal experience of finding it confusing, which is an observation, not a verifiable claim.", "helpfulness_rationale": "The comment directly points out a weakness in the paper (lack of clarity regarding 'S' and 'Xt') and suggests an improvement (clarifying these variables). This is a clear identification of an area for improvement in the authors' draft. While it doesn't offer a specific solution, it highlights a specific problem."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states areas where more detail is needed, such as providing 'definitions of the resistance distance' and 'more explanations on Alg. 1 with brief sentences defining A_t, Y_t,...'. These are direct actions the authors should take to improve their draft.", "grounding_specificity_rationale": "The review point explicitly mentions 'definitions of the resistance distance' and Algorithm 1, which are specific parts of the paper. While it doesn't directly point to a section number, the mention of a specific concept and algorithm makes the grounding relatively specific once the authors locate those parts.", "verifiability_rationale": "The review point makes a judgment about the writing being 'generally good though more details could sometimes be provided'. This is a claim that could be supported by the authors' own experience or by common knowledge about technical writing. The reviewer also points out the lack of 'definitions' and 'explanations', which are verifiable issues.", "helpfulness_rationale": "The review point is 5 because it directly identifies areas where the authors can improve their work. By asking for 'definitions of the resistance distance' and 'more explanations on Alg. 1', the reviewer provides concrete and actionable feedback that the authors can readily use to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggest a change to the paper. It raises a question about the scope of the invariance study and requests additional evidence. While the reviewer's suggestion is valuable, the point itself doesn't directly prompt the author to take a specific action.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly grounded in a specific part of the paper. They are making a general comment about the limitations of the invariance study based on the type of transformations used. The comment is not pointing to a specific section, table, or figure. The grounding is weak because the reviewer is making a suggestion about a potential improvement rather than pinpointing a specific issue.", "verifiability_rationale": "The review point contains a claim: 'Are there any quantitative results on testing images?' The reviewer is questioning the verifiability of the paper's claim about shape model invariance based on training image transformations. The paper *claims* that this approach *fully proves* invariance, and the reviewer is asking for supporting evidence (quantitative results on testing images) to back this claim. The paper, in its current state, does not provide this supporting evidence.", "helpfulness_rationale": "The review point raises a valid concern about the limitations of the experimental validation. It points out that the paper might be overstating the implications of training transformations for invariance. This could be helpful for the author to consider the limitations of their approach and potentially strengthen their claims or add a note about the need for testing image transformations. However, it doesn't directly provide a solution or a clear next step for the author."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point contains an explicit action ('investigate the computational cost') but lacks specific details on how to do so. The statement is general and could be made more concrete. The reviewer also points out a specific concern about scalability on normal machines, which is a concrete action, but the current point doesn't address this concretely. The Sinkhorn connection is a question, not an explicit action.", "grounding_specificity_rationale": "The review point makes general statements about the computational cost of optimal transport without specifically referencing the authors' method or results. It doesn't pinpoint a particular section, table, or figure. The questions about scalability and the Sinkhorn connection are also general inquiries about the Sinkhorn algorithm in general, not about the authors' specific implementation or results.", "verifiability_rationale": "The statement about computational cost is generally verifiable as a known fact in the field. However, the reviewer's questions about scalability and the Sinkhorn connection are valid inquiries that could potentially be answered with evidence, making them 1 at this point. The lack of specific references or examples makes it difficult to verify the claims.", "helpfulness_rationale": "The point raises a relevant concern about the computational cost, which could be helpful for the authors. However, it lacks specific details on how to investigate this. The question about scalability is directly relevant and actionable. The question about the Sinkhorn connection is also a valid and actionable question."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a problem (nonstandard benchmarks breaking TTA methods) but does not provide explicit or implicit instructions on how to address it. The authors are left to figure out what changes are needed based on this observation alone.", "grounding_specificity_rationale": "The review point mentions 'TTA methods' and 'natural distribution shift, like WILDS 9'. While it mentions WILDS, it doesn't explicitly identify a specific part of the paper being addressed, nor does it clearly detail what is wrong or missing in that part related to TTA methods. The grounding is weak as it only mentions a general area of concern.", "verifiability_rationale": "The review point states an observation ('This is an interesting observation...') and suggests a potential solution (WILDS). However, it doesn't provide any specific evidence or reasoning to support the claim that 'nonstandard benchmarks break a lot of popular TTA methods'. The verifiability is low as there's no concrete basis for this claim within the review point itself.", "helpfulness_rationale": "The review point identifies a potential issue with the evaluation methodology (nonstandard benchmarks) and suggests WILDS as a potential improvement. However, it doesn't provide specific, actionable steps for the authors to take or concrete examples of how to implement this suggestion. The helpfulness is limited as the authors are left to interpret and act upon this suggestion without further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states: 'how these results are useful to machine learning algorithms or analyze the algorithm is not clear.' This directly points to an action the authors should take \u2013 to clarify the connection between tensor networks, PMF, and machine learning/algorithm analysis. While the reviewer doesn't provide the explicit steps, they identify the missing link. The action is stated directly, making it explicit.", "grounding_specificity_rationale": "The reviewer mentions 'tensor networks,' 'PMF of discrete variables,' 'machine learning algorithms,' and 'algorithm analysis.' While they refer to specific concepts, they do not point to a specific section, table, or figure in the paper. The grounding is implicit \u2013 the reviewer understands these terms but doesn't know where the detailed connection is explained. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim: 'how these results are useful to machine learning algorithms or analyze the algorithm is not clear.' This is a claim that needs verification. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. The verifiability is minimal, as there's no logical reasoning or external references provided to justify the statement.", "helpfulness_rationale": "The reviewer directly criticizes the lack of clarity and impact, stating 'how these results are useful to machine learning algorithms or analyze the algorithm is not clear.' This is a strong statement that directly points to a significant gap in the paper's communication. The reviewer identifies a clear weakness in the presentation of the significance of the work. While the reviewer doesn't offer a solution, they clearly identify a problem that needs addressing."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a problem: 'It's not clear how to sample from the DPP if the eigenfunctions e_n's are inaccessible (Eq (10) line 130)'. This directly identifies a lack of clarity or a point requiring further explanation. While it doesn't provide a solution, it clearly points to a specific area needing attention. Therefore, it is considered explicit in identifying a problem.", "grounding_specificity_rationale": "The comment refers to 'sampling from the DPP' and 'leverage scores', which are specific concepts. It also explicitly mentions 'Eq (10) line 130', which grounds the comment to a specific location in the paper. While it doesn't pinpoint the exact issue within the DPP or leverage score section, it clearly identifies the relevant concepts and a specific equation. This makes it '3'.", "verifiability_rationale": "The comment contains a claim: 'It's not clear how to sample from the DPP if the eigenfunctions e_n's are inaccessible (Eq (10) line 130). This seems to be the same problem with sampling from the leverage score in 3, so I'm not sure how sampling from the DPP is easier than sampling from the leverage score.' This claim is not supported by any evidence or reasoning within the review point. The reviewer states a perceived similarity and a lack of clarity without providing any justification or references. Therefore, it is '1'.", "helpfulness_rationale": "The comment identifies a potential area for improvement in the paper by highlighting the difficulty in sampling from the DPP when eigenfunctions are inaccessible and drawing a parallel to the challenges with leverage scores. However, it does not provide any concrete suggestions or guidance on how to address this issue. The reviewer states a problem but doesn't offer a solution or further explanation. Therefore, it is '2' as it points to a potential improvement area, but lacks actionable suggestions."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a limitation, which is a clear action pointing out a missing piece of information. The specificity around 'fewshot learners beyond Prototypical Networks' adds detail, making it actionable for the authors to investigate this generalizability.", "grounding_specificity_rationale": "The reviewer mentions 'Prototypical Networks' and 'fewshot learners,' which are concepts present in the paper's context. However, they don't explicitly state which section or subsection these concepts belong to, making the grounding somewhat weak. The specificity regarding the types of learners is present, but the connection to the paper's content isn't explicitly stated.", "verifiability_rationale": "The reviewer makes a claim about a limitation but provides no evidence, reasoning, or references to support it. The claim is presented as a statement of fact without any backing.", "helpfulness_rationale": "The reviewer identifies a limitation in the scope of the work. While relevant, it doesn't offer a specific suggestion for improvement or a constructive point for the authors to build upon. It's more of a negative observation about the boundaries of the research."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem with Equation 3 and proposes a concrete solution: 'Equation 3 directly removes the modal subset of all instances. How to deal with the problem mentioned above.' This indicates a clear understanding of the issue and a direct suggestion for improvement. The reviewer provides a specific method (stratified analysis and reweighting) to address the problem, making the suggestion actionable.", "grounding_specificity_rationale": "The reviewer mentions 'different modalities of different instances' and 'Equation 3,' indicating they are aware of specific components being affected. However, they do not explicitly identify a *specific* part of the paper (e.g., a table, a section, a particular calculation within Equation 3) that is causing the problem. While they mention relevant terms, they don't pinpoint a single element being problematic, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer identifies a problem with Equation 3 and proposes a solution. This constitutes a claim that requires verification. The suggestion to 'stratify the analysis and reweight the modal subsets based on their performance' is a logical and potentially verifiable approach. While it might require further justification or evidence to fully support the claim, the suggestion itself is grounded in logical reasoning and a proposed method, making it 3.", "helpfulness_rationale": "The reviewer clearly articulates the issue with Equation 3 and provides a specific suggestion for improvement. The suggestion is directly relevant to the problem and offers a concrete path for the authors to investigate and potentially address the issue. This makes the review point 5 as it directly addresses a practical concern and offers a clear next step for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the limitation of sequential ensembling in homomorphic encryption due to noise accumulation and its impact on the usability of even single deep neural networks. It identifies the problem and its consequence, making it directly actionable for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'sequential ensembling' but does not explicitly identify the specific section, table, figure, or unique aspect of the paper where this ensembling technique is discussed. While the term is general, the reviewer implies it's a problem in the context of homomorphic encryption without pinpointing the exact location within the paper.", "verifiability_rationale": "The claim that 'this limitation prevents the use of even single deep neural networks on homomorphically encrypted data' is supported by the reasoning that 'for sequential ensembling, it is important to study the effect of noise accumulation in the context of homomorphic encryption.' While the reasoning is logical and based on established knowledge in the field, it does not provide specific examples or external references within this review point itself.", "helpfulness_rationale": "The review point identifies a significant limitation of sequential ensembling in the context of homomorphic encryption, specifically the accumulation of noise and its effect on the usability of deep neural networks. This is a clear and actionable piece of information that directly impacts the authors' potential approach and understanding of the challenges involved."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the need to 'use standard regularization trick' for comparison, which is a direct action. However, it doesn't specify the *type* of standard regularization trick, making it somewhat vague in terms of concrete implementation.", "grounding_specificity_rationale": "The review point explicitly mentions 'stronglyconvex concave case', which is a specific aspect of the problem. It also suggests a 'standard regularization trick' for comparison within this specific context, indicating a clear grounding of the issue and a suggestion for action.", "verifiability_rationale": "The review point makes a claim about the appropriate method ('standard regularization trick') for comparison in a 'stronglyconvex concave case'. This claim is supported by common knowledge and standard practices in optimization, making it 5.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion ('use standard regularization trick') for comparing the proposed method with existing ones in a specific scenario ('stronglyconvex concave case'). This directly addresses a practical concern for the authors and offers a standard approach, making it 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a valid weakness in the original paper's evaluation setup (pretraining only on synthetic data) and suggests an alternative evaluation strategy (pretraining on synthetic data and finetuning on realworld data with different losses). While the reviewer doesn't explicitly state how to implement the new evaluation, they do suggest a concrete *change* to the evaluation process. The suggestion is directly related to the identified weakness and proposes a specific *action* (finetuning on realworld data with different losses). However, the reviewer doesn't provide specific steps or examples of how to *implement* this change, making the action somewhat vague. Therefore, while the reviewer identifies a meaningful issue and suggests a concrete solution, the lack of specific implementation details makes the action somewhat vague and less actionable within the review itself.", "grounding_specificity_rationale": "The reviewer explicitly states the suggestion for a different evaluation setup: 'pretraining on synthetic data but finetuning on realworld datasets with different losses'. This clearly identifies the specific part of the paper (the evaluation setup) that needs improvement. The reviewer also mentions 'pretrained on synthetic data' and 'realworld datasets' as specific elements. The reviewer does not mention external work or examples in this part of the suggestion. Therefore, the grounding is explicit regarding the type of data and the training/finetuning process, but lacks specific examples or references within the suggested change itself.", "verifiability_rationale": "The reviewer's point is not presented as a claim that *their* suggested evaluation is correct or superior. They are presenting it as a suggestion for improvement. The reviewer does not provide any logical reasoning, common knowledge, or external references to support the claim that this new evaluation setup is necessarily better. The statement is framed as a preference or a potential improvement rather than a definitive assertion. Therefore, the claim is not explicitly stated, and there is no verifiable evidence provided within the review point itself.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the original paper's evaluation (pretraining only on synthetic data) and suggests an alternative evaluation strategy (pretraining on synthetic data and finetuning on realworld data with different losses). This points to a valuable direction for improvement and highlights a potential area where the model's performance might be better demonstrated. However, the reviewer does not provide specific steps or examples of how to *implement* this change. They are presenting a suggestion for improvement rather than a direct solution. Therefore, while the review points to a meaningful issue and proposes a potentially valuable improvement, it lacks the direct guidance needed to be fully helpful in terms of implementation. The suggestion is more of a *hypothesis* for improvement rather than a concrete *solution*."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a question about the scope of the update and suggests a formatting change. While the suggestion about paragraphs is helpful, the question itself is broad and lacks a clear answer. The reviewer does not explicitly state what needs to be done or how the update should be applied, making it less actionable than a direct suggestion. The request is about asking a question rather than providing a solution.", "grounding_specificity_rationale": "The reviewer refers to 'update,' 'environments,' 'true environment,' 'page 6,' and 'bolded sections.' While they *mention* specific parts of the paper, they do not accurately identify what those sections are or what they contain. This indicates weak grounding as the authors cannot confidently determine which part the comment addresses. The request is also very general, lacking specificity about the nature of the update or the formatting change.", "verifiability_rationale": "The review point does not contain a claim or suggestion. It is a question posed to the authors. Therefore, it does not meet the criteria for verifiability, which requires a claim to be verified.", "helpfulness_rationale": "The review point offers a suggestion to break out the bolded sections into paragraphs, which is a helpful suggestion. However, the primary part of the review point is a question about the scope of the update, which is not directly answerable with the information provided. While the suggestion about paragraphs is helpful, the lack of a clear answer to the question makes the overall review point less helpful. The question is vague and does not provide immediate guidance to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing the perspective taken in the present manuscript to the contributions of prior efforts. This is an explicit action as it directly tells the authors what to do. While the specific comparison method isn't detailed, the action itself is clear and actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 6' as the area for comparison. This is a literal mention of a specific section, making the grounding full. The comment also asks to compare the 'perspective,' which is a specific request related to this section.", "verifiability_rationale": "The review point contains a claim: 'compare the perspective taken in the present manuscript to the contributions of prior efforts.' However, it does not provide any specific examples, references, or logical reasoning to support this claim within the review itself. The comparison itself is a suggestion that the authors would need to investigate further to verify.", "helpfulness_rationale": "The review point asks the authors to compare their work to prior efforts. This is a valuable piece of feedback as it directly addresses the relationship between the current work and the existing literature, which is crucial for academic integrity and understanding the novelty of the contribution. While it doesn't specify *how* to compare, it is a relevant and helpful suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the action of 'examine the performance with different numbers of scenarios.' This is an explicit action as it directly tells the authors what to do. However, it is vague because it doesn't specify how to change the numbers of scenarios. The authors are left to interpret what 'different' means in this context (e.g., incrementally, randomly, by a factor). Therefore, while the action is stated, the lack of concrete details makes it partially actionable.", "grounding_specificity_rationale": "The review point refers to 'scenarios' in general. While it mentions 'scenarios,' it doesn't pinpoint a specific section, table, figure, or unique element of the paper. The reference to 'scenarios' is broad and doesn't provide a precise location for the authors to focus their attention. Furthermore, even though it mentions 'different numbers of scenarios,' it doesn't specify which numbers or how these numbers should be varied. The grounding is weak because the authors have to infer the meaning of 'scenarios' and the nature of the variation.", "verifiability_rationale": "The review point makes a claim by suggesting an experiment: 'I would assume that the performance is closely related to the number of scenarios used for training, and therefore, it is interesting to examine the performance with different numbers of scenarios.' This is a judgment about the value of the experiment. However, the review point itself doesn't provide any justification for *why* this experiment would be insightful or *how* the results would be interpreted. The suggestion is a claim that requires further support or explanation from the authors to be considered verifiable. It lacks the logical reasoning or references needed to be 5.", "helpfulness_rationale": "The review point suggests an experiment that could be valuable for understanding the impact of the number of scenarios on performance. This is a relevant and interesting area of investigation for the authors. However, the suggestion is quite general and lacks specific details. The authors are not told what specific numbers to try, how to vary them, or what kind of analysis to perform. While the suggestion is relevant, the lack of specificity makes it less helpful than a more detailed recommendation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point discusses the potential impact of training data disturbances on the quality label but does not explicitly state an action or suggestion for the authors to take. The focus is on raising a concern rather than providing a direct solution.", "grounding_specificity_rationale": "The review point mentions 'training data disturbances' and 'quality label' but does not specify which type of disturbance or how it relates to the quality label. This lack of specificity makes the grounding weak.", "verifiability_rationale": "The review point presents a question and a hypothetical scenario about the impact of training data disturbances on the quality label. It does not make a claim that is explicitly supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point raises a valid concern about the potential impact of training data disturbances on the quality label. It prompts the authors to consider this issue, which can be helpful in identifying potential problems in their training process. While it doesn't provide a solution, it does highlight a relevant area for investigation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete change the authors should make. It critiques the level of strategic behavior demonstrated, implying a lack of full strategic analysis rather than providing a specific action to take. Therefore, it is not 5 or even explicitly actionable.", "grounding_specificity_rationale": "The review point mentions 'strategic predictions' (l28) and 'opponent doesn't behave strategically'. While it doesn't explicitly point to a specific section or table, the reference to 'strategic predictions' can be interpreted as a unique element of the paper. However, it doesn't specify *what* aspect of the opponent's behavior is nonstrategic. Therefore, it is weakly grounded but somewhat specific in identifying the issue.", "verifiability_rationale": "The review point contains a claim: 'this seems like only a very first step...' and provides a justification: 'in light of what they claim ('strategic predictions', l28), their setting is only partially strategic/game theoretic as the opponent doesn't behave strategically (i.e., take into account the other strategic player).' While it doesn't provide a direct citation, it offers a logical reasoning based on the concept of strategic predictions. Therefore, it is 3.", "helpfulness_rationale": "The review point identifies a limitation in the strategic aspect of the work ('only a very first step towards real strategic settings' and 'only partially strategic/game theoretic'). However, it does not offer specific, actionable steps for the authors to take to address this limitation or improve the strategic aspect. It is more of a critique than a constructive suggestion. Therefore, it is 2."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer requests more details about the aggregation operation after 'Integration' but does not specify the exact action or how to apply it. They state 'Please provide more details in the main paper', which is a general instruction without concrete steps.", "grounding_specificity_rationale": "The reviewer refers to 'Integration' within the 'Multiscale modeling' section but does not explicitly identify the specific part of the paper being addressed (e.g., a subsection, table, or figure). The reference is implied rather than precise.", "verifiability_rationale": "The reviewer suggests that the aggregation operation needs clarification but does not provide any external references or logical reasoning to support this claim. They are stating a need for improvement without evidence.", "helpfulness_rationale": "The reviewer's request to provide more details about a specific operation ('aggregation operation after \"Integration\"') is a clear and actionable feedback for the authors. It directly addresses a potential area for improvement in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a gap in explored techniques (actionable) and highlights a similarity to prior work (actionable). However, they do not provide specific, actionable steps for the authors to take to address this gap or build upon the similarity.", "grounding_specificity_rationale": "The reviewer mentions 'energy models' (grounded) and the goal of 'compositional generation through logical combination of concepts learned through data subsets' (vague). They also refer to a 'prior VAE paper' (implied grounding, but not specific). However, they do not explicitly identify a specific section, table, figure, or unique element of the paper.", "verifiability_rationale": "The reviewer makes a claim: 'the use of energy models for image generation is much more unexplored compared to GANs and VAEs' (claim). However, the justification 'exploring it further is great' (subjective) and the reference to a 'prior VAE paper' (potential verification, but not explicitly stated or detailed) do not provide a clear, logical, or wellsupported argument.", "helpfulness_rationale": "The reviewer provides context by highlighting a gap in research and drawing a connection to prior work. This is helpful in identifying potential areas for improvement. However, they do not offer specific, actionable steps or suggestions for the authors to implement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'The method is evaluated only on the tasks from Meta World...'. This is a clear and direct statement of a limitation. The reviewer also suggests an action, 'I strongly recommend running experiments on a different benchmark such as Atari...', which is a direct response to the identified limitation. The action is concrete, stating a specific alternative benchmark.", "grounding_specificity_rationale": "The reviewer mentions 'Meta World, a robotic manipulation domain' as the scope of evaluation. While not a specific section or table, it is a wellknown benchmark in the field, allowing for some level of grounding. The reviewer further specifies the type of benchmark with 'Atari', which is a concrete example of a different domain. The reviewer also explains the consequence of this limited evaluation ('Hence, it is difficult to judge whether the results will generalize to other domains.') and suggests a solution ('I strongly recommend running experiments on a different benchmark such as Atari...'). This demonstrates an understanding of the potential limitations of the current evaluation scope and a clear suggestion for improvement.", "verifiability_rationale": "The reviewer makes a claim: 'The method is evaluated only on the tasks from Meta World...'. This is a clear statement of a fact. The reviewer then provides a justification: 'Hence, it is difficult to judge whether the results will generalize to other domains.' This is logical reasoning. The reviewer also suggests a solution: 'I strongly recommend running experiments on a different benchmark such as Atari...'. This provides a concrete example and a clear suggestion for improvement. The reviewer also mentions the type of benchmark ('Atari'), which provides some level of external reference.", "helpfulness_rationale": "The reviewer clearly identifies a limitation in the evaluation scope ('The method is evaluated only on the tasks from Meta World...') and provides a concrete suggestion to address this limitation ('I strongly recommend running experiments on a different benchmark such as Atari...'). The reviewer also explains the consequence of the limited evaluation ('Hence, it is difficult to judge whether the results will generalize to other domains.'). This demonstrates a clear understanding of the problem and a direct and actionable recommendation. The reviewer's point is not just a critique but also a constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'check the feedback/suggestions' to find the missing analysis of what the model does. This action is concrete and directly tells the authors where to look for the improvement.", "grounding_specificity_rationale": "The review point mentions 'what the model does' as a general area for analysis but does not specify a particular section, table, figure, or unique aspect of the paper. The grounding is weak as the authors need to infer the specific part of the paper being addressed.", "verifiability_rationale": "The review point contains a claim: 'a bit of analysis on what the model does is missing'. While it doesn't provide specific examples or external references within the paper itself, it suggests a direction ('check the feedback/suggestions') which can be considered a form of implicit verification or guidance for the authors to find the information.", "helpfulness_rationale": "The review point is helpful because it identifies a specific weakness ('a bit of analysis on what the model does is missing') and provides a clear suggestion on how to address it ('check the feedback/suggestions'). This directly guides the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a problem: 'The task setup is not described clearly.' It also implies a need for clarification: 'For example, which notes in the EHR (only the current admission or all previous admissions) do you use as input and how far away are the outcomes from the last note date?'. While it doesn't provide a direct solution, it points the author to specific details that need to be clarified.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or methodology. It uses general terms like 'task setup' and asks a question without clearly identifying a section or table. Therefore, the grounding is weak.", "verifiability_rationale": "The review point does not contain a claim in the sense of stating an opinion, judgment, or suggestion. It is a question or observation about the clarity of the task setup. Therefore, it does not have verifiable content in the defined sense.", "helpfulness_rationale": "The review point is helpful in that it identifies a crucial missing element: the lack of clarity in the task setup. This directly points the author to areas that need to be defined or explained in their paper. While it doesn't offer a solution, it highlights a specific area requiring attention."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point discusses the potential data requirements of f_R/f_P, which is a valid concern. However, it does not explicitly state how to determine the amount of data needed for less informed models. While it highlights a potential limitation, it lacks a direct action for the authors to take.", "grounding_specificity_rationale": "The review point discusses the limitations of f_R/f_P in general terms, without specifying which part of the paper is affected. It does not identify a specific section, table, figure, or unique aspect of the paper as being problematic.", "verifiability_rationale": "The review point does not contain a claim. It is a statement about the potential data requirements of f_R/f_P, which is a question rather than a claim requiring verification.", "helpfulness_rationale": "The review point raises a valid concern about the practical data requirements of f_R/f_P. However, it does not offer any suggestions or actionable steps for the authors to address this limitation. It is a critique of a potential gap between theory and practice, but without a solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a potential weakness in the research (lack of experiments) but does not explicitly state what needs to be done to address this weakness. While it points out a missing element, it doesn't provide a clear, actionable step for the authors.", "grounding_specificity_rationale": "The review point mentions 'labeled data' and 'imitation learning' but does not specify which labeled data or which imitation learning method is being referred to. It lacks a precise identification of a specific part of the paper or issue.", "verifiability_rationale": "The review point contains a claim about the lack of experiments but does not provide any logical reasoning, common knowledge, or external references to support this claim. It simply states a gap in the research.", "helpfulness_rationale": "The review point points out a gap in the research (lack of experiments) but does not offer concrete solutions or guidance on how to address this gap. It highlights a potential area for future work but does not actively help the authors improve their current draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "Not Verifiable", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer points out a potential issue with overparameterization and its implications for generalization. While they raise a valid concern, the comment lacks a clear, explicit action or suggestion for the authors. The reviewer is diagnosing a potential problem rather than directly instructing the authors on what to do. The connection between overparameterization, memorization, and generalization is implied, but the specific action to address this is not stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'generalization bounds' and questions the connection between overparameterization, memorization, and generalization. They also state that they acknowledge this in the conclusion. This clearly identifies the specific area within the paper being addressed and the nature of the issue. The reviewer provides context (generalization bounds) and specifies the problem (lack of connection to memorization).", "verifiability_rationale": "The reviewer raises a question about a conceptual link: 'Since overparameterization can often lead to powerful memorization and good generalization performance, the necessary conditions may have stronger implications if they are connected to generalization bounds.' This is a question about the interpretation of existing concepts and theories. There is X being made that something is or is not verifiable. The reviewer is asking for clarification or further explanation rather than making a definitive statement that requires evidence.", "helpfulness_rationale": "The reviewer asks a question about a potential limitation or area for future work in the paper. While the question is relevant, it does not directly provide actionable feedback or insights that would empower the authors to significantly improve their draft. The comment is more of a diagnostic or evaluative point than a constructive suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out a potential ambiguity regarding the use of \"certificate\" and suggests that this ambiguity might arise from its meaning in complexity theory. This constitutes an explicit action that the authors should take to clarify the usage of \"certificate\".", "grounding_specificity_rationale": "The reviewer not only identifies the potential ambiguity but also specifies the location (line 267) where this ambiguity might occur. Furthermore, the reviewer explains what might cause the misinterpretation (the strong meaning of \"certificate\" in complexity theory), providing a clear and specific point of reference within the paper.", "verifiability_rationale": "The reviewer makes a claim that the use of \"certificate\" might be misinterpreted due to its meaning in complexity theory. This claim is supported by a logical reasoning explaining why this misinterpretation could occur. The reviewer provides a clear justification for their statement.", "helpfulness_rationale": "The reviewer's point directly addresses a potential source of confusion for the authors regarding a specific term. By highlighting the ambiguity and its potential link to complexity theory, the reviewer provides a clear and actionable suggestion for the authors to clarify their understanding of \"certificate\" at the mentioned line. This feedback is directly helpful to the authors in improving their understanding of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their belief that the proxlinear subproblem can be reformulated using the conjugate function and provides a specific suggestion. This indicates a clear action: to investigate this reformulation and its implications for Algorithm 1.", "grounding_specificity_rationale": "The reviewer directly addresses the proxlinear subproblem mentioned in Algorithm 1. They identify the specific area of concern and propose a concrete alternative method (using the conjugate function). This demonstrates a strong understanding of the relevant section and provides a specific suggestion.", "verifiability_rationale": "The reviewer makes a claim about a potential reformulation and provides a logical argument for why this reformulation might make the motivation of Algorithm 1 unclear. While they don't provide a detailed proof, the reasoning is clear and points to a potential issue with the existing algorithm's justification.", "helpfulness_rationale": "The potential for this review to be 5 depends on the validity of the reviewer's claim and the impact of the suggested reformulation. If the proxlinear subproblem *can* be reformulated using the conjugate function as suggested, and this simplifies or improves Algorithm 1, then it would be 5. However, if the reviewer's claim is incorrect or the reformulation doesn't lead to any improvement, it would be unhelpful. The lack of concrete evidence of the reformulation's validity makes it difficult to definitively assess helpfulness."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly mentions 'competing dynamicpruning methods' and suggests 'including more recent works'. This provides clear guidance on what the authors should look for and what improvements they should consider. The action is explicitly stated and concrete.", "grounding_specificity_rationale": "The review point refers to 'competing dynamicpruning methods' without explicitly naming a specific section, table, or figure. While the authors can infer the intended area, the grounding is weak. However, the review also specifies 'small scale datasets' and 'large scale datasets including ImageNet', which adds some specificity to the inferred area. The authors know what kind of datasets are missing and what should be included.", "verifiability_rationale": "The review point makes a judgment about the 'outofdate' nature of 'competing dynamicpruning methods' and suggests 'including more recent works'. This constitutes a claim. The reasoning provided is that these methods are 'outofdate', which implies a lack of current relevance. While not backed by external references in this specific point, the logical reasoning is present. The claim is somewhat justified by the implied lack of current relevance.", "helpfulness_rationale": "The review point clearly identifies a weakness in the paper ('competing dynamicpruning methods are kind of outofdate') and provides a direct suggestion for improvement ('include more recent works'). This is 5 and directly relevant to the authors' work. The reviewer is providing constructive feedback for enhancing the paper's relevance and evaluation."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the action of making the captions more descriptive, which is a clear and actionable request for the authors. Clarification questions should be treated as explicit statements if they give a direct action. Making captions more descriptive is a direct action that the authors can implement.", "grounding_specificity_rationale": "The comment does not explicitly mention a specific section or table number, making the grounding weak. However, the focus is clearly on the captions themselves, making the grounding relatively strong. The comment specifies what needs to be addressed in this part (more descriptive captions).", "verifiability_rationale": "The comment contains claims about the captions being annoying and the 'scramble network' needing a better explanation. However, the justification for these claims is general and lacks specific examples or references. The comment does not provide a logical reasoning, common knowledge, or external references to support these claims.", "helpfulness_rationale": "The comment provides clear suggestions for improvement (making captions more descriptive) and asks for clarification (better explanation of the scramble network). These are direct and actionable feedback that empowers the authors to significantly improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment explicitly asks 'Why is this particular dimension of difficulty interesting?' which directly prompts the authors to provide a justification. However, it doesn't specify *how* this choice is interesting or *what* problem it addresses. The action is to explain the motivation, but the method is vague.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper. It is a general question about the task difficulty introduced by the use of CIFAR images. While the choice of CIFAR images is specific, the reasoning behind it is not addressed, and the comment doesn't identify a particular section or table to discuss this issue.", "verifiability_rationale": "The comment is a question seeking information about the motivation behind using randomly sampled CIFAR images. It does not contain a claim or assertion that requires verification. Therefore, it falls under the category of 'X'.", "helpfulness_rationale": "The comment identifies a potential weakness in the experimental setup (task difficulty due to CIFAR images) but fails to provide any actionable feedback or suggestions to address this weakness. It simply asks 'why is this interesting' without offering any concrete improvements or justifications. Therefore, it is not particularly helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the problem: 'The motivation is not clear at all.' However, it does not specify which part of the paper the motivation refers to or what specific changes are needed. While the intent is clear, the lack of concrete action makes it only 2.", "grounding_specificity_rationale": "The comment explicitly mentions the 'introduction' as the area needing revision, providing full grounding. However, it does not specify what is unclear within the introduction or what needs to be improved. The issue is identified, but the specific problem and solution are missing.", "verifiability_rationale": "The review point does not contain a claim. It is a statement of fact: 'The motivation is not clear at all.' Therefore, it does not have verifiability as it lacks a claim to be verified.", "helpfulness_rationale": "The comment identifies a significant weakness in the paper (lack of clear motivation) and suggests a direction for improvement (carefully revise the introduction). While it doesn't provide specific edits, it points to a crucial area for revision, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'alignment of relabeled reward data with human annotator judgments' which implies an action needs to be taken. However, it does not specify what needs to be aligned or how the alignment should be validated, making it only partially actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'relabelled reward data' and 'human annotator judgments', allowing the authors to accurately identify the specific part of the paper being addressed. This demonstrates full grounding. However, the comment does not specify what needs to be aligned or how the validation should be conducted, making it underspecific.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. However, the implicit need to validate the alignment of the data with human judgments can be considered a form of 'verifiability' at a very basic level. Without a specific claim, it's difficult to fully apply the verifiability scale, but the need for validation suggests a weak level of verifiability.", "helpfulness_rationale": "The comment directly points out a problem ('alignment of relabeled reward data with human annotator judgments remains insufficiently validated'). This makes it directly helpful in identifying an issue. However, it does not offer any suggestions or actions for improvement, making it less helpful than a comment that proposes a solution or a course of action. Therefore, it is 3 as it highlights a need for attention."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies the problem (not wellwritten, hurriedly written, hard to read) and mentions areas (figures/tables) needing improvement. However, it does not explicitly state how to address these issues. The suggestions are implied but not directly provided. For example, it doesn't say 'improve the introduction' or 'revise the figure captions'. It's a general statement about the overall quality and presentation.", "grounding_specificity_rationale": "The comment is very general and does not specify which part of the paper is being addressed. It talks about the writing quality and formatting in general, without pointing to a specific section, table, or figure. The reviewer cannot confidently determine which part the comment refers to. For example, it doesn't say 'Section 3.2' or 'Figure 4'.", "verifiability_rationale": "The comment contains a claim ('The paper is not very wellwritten...') but does not provide any specific evidence or justification for this claim. It doesn't cite specific sections, examples, or external references to support the assertion. The reasoning is vague and lacks concrete examples. For example, it doesn't say 'This poor grammar in Section 2 is due to a lack of editing' or 'The figures are unprofessional because they don't have clear labels'.", "helpfulness_rationale": "The comment identifies a general area for improvement (writing quality and presentation) and points to specific areas (figures/tables) that need attention. While it doesn't offer specific, actionable steps, it encourages the author to focus on these aspects. It's better than no feedback, as it highlights what needs work. However, it lacks the specific guidance needed for immediate action. For example, it doesn't say 'Rewrite the introduction to be clearer' or 'Use a professional design tool for the figures'."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'could be more detailed,' indicating an intention for the authors to add more information. While the action is implied rather than stated directly, it is still an explicit action in the sense that the authors are expected to expand on the topic. The concreteness is somewhat lacking as the reviewer doesn't specify *what* is missing, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'Part 2' and 'orthogonality,' which clearly identifies the specific section and concept being addressed. This demonstrates strong grounding as the authors can easily locate the referenced part. However, the specificity is limited as the reviewer doesn't pinpoint the exact issue within the introduction of orthogonality, making it somewhat underspecific.", "verifiability_rationale": "The reviewer's statement is a suggestion or judgment about the quality of the introduction. While it implies a lack of detail, it doesn't provide a logical reasoning or external reference to support this claim. Therefore, it is not verifiable.", "helpfulness_rationale": "The reviewer points out a potential area for improvement by suggesting the introduction of orthogonality could be more detailed. While this is a helpful suggestion, it doesn't offer concrete steps or a solution for the authors. The feedback is more about identifying a weakness than providing actionable advice, making it 3 but not fully helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the paper's contribution as the removal of double descent under specific conditions *in relation* to prior work. This is an explicit action. The reviewer also identifies *which* prior work is relevant and *what* the paper's contribution is (removing double descent under anisotropy). This is concrete.", "grounding_specificity_rationale": "The reviewer identifies a gap in the paper's contribution by highlighting existing theoretical work and the paper's own contribution. This directly points to a specific aspect of the paper's novelty. While the reviewer doesn't explicitly name a section or theorem, they describe the *type* of setting (anisotropic) that makes the contribution novel. This is weak grounding. The reviewer specifies the *conditions* under which the contribution holds (optimal regularization, anisotropic settings). This is relatively specific, but could be more precise.", "verifiability_rationale": "The reviewer makes a claim: \"the main contribution of the paper appears to be the result that optimal regularization can remove double descent even in certain anisotropic settings.\" This is a clear statement of opinion. The reviewer *claims* they are not sure if this is the case and suggests the paper should clarify this. They also state they couldn't verify the claims themselves. This indicates a lack of strong supporting evidence within the review point itself. The reviewer is expressing uncertainty, not providing a definitive verification.", "helpfulness_rationale": "The reviewer's point is relevant to understanding the paper's contribution and its place within the existing literature. It helps the authors contextualize their work. The reviewer's point is clear and directly addresses a potential area of confusion for readers. The reviewer's suggestion to highlight the novelty of their result in relation to prior results is actionable and would improve the clarity and impact of the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states a fact: the contrastive training objective and contrastive search are independent. While this is a true statement, it does not provide any actionable advice or suggestions for the authors. The authors are not given any guidance on how to think about the relationship between these methods, how they might be connected, or what further research could be done. Therefore, the review point lacks actionable information.", "grounding_specificity_rationale": "The review point explicitly mentions 'contrastive training objective' and 'contrastive search' by name. This clearly grounds the discussion in the specific methods being discussed in the paper. The reviewer is specifically addressing these two concepts, indicating a clear understanding of the relevant parts of the paper.", "verifiability_rationale": "The review point makes a claim: 'these methods have little inner connection.' However, it does not provide any evidence, reasoning, or references to support this claim. It is presented as an assertion without any backing. Therefore, the claim is not wellsupported by the provided information.", "helpfulness_rationale": "The review point is a statement of observation: that the two methods are independent. While this is a valid point, it does not offer any constructive feedback or suggestions to the authors. It does not guide them towards further analysis, potential improvements, or alternative approaches. Therefore, the review point is not particularly helpful in improving the authors' work."}
{"actionability_label": "High", "grounding_specificity_label": "N/A", "verifiability_label": "N/A", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states: 'It would be stronger if the base DA methods were similarly evaluated with/without the architectural competitors such as AutoDial and AdaBN that are direct competitors to TN.' This is a clear and direct suggestion for an action to be taken. The reviewer identifies a specific area for improvement in the evaluation process. The suggestion is welldefined and actionable.", "grounding_specificity_rationale": "The review point itself does not contain a specific claim about a particular part of the paper. The reviewer's suggestion is about improving the *evaluation methodology* by comparing against other architectures. While the suggestion is grounded in the context of DA and architectures, the *review point itself* does not explicitly refer to a specific part of the paper or methodology with a claim. The reviewer's suggestion is about a *general* improvement in the evaluation process, not a specific critique of a particular aspect of the paper or method.", "verifiability_rationale": "The review point is a prescription for improvement, not a claim that something is verifiable. The reviewer suggests *how* the evaluation should be done, not what something is verifiable. The statement 'It would be stronger if...' does not contain a claim that can be verified. The suggestion is about the *process* of evaluation, not a statement of fact or opinion that can be supported by evidence.", "helpfulness_rationale": "The reviewer states: 'It would be stronger if the base DA methods were similarly evaluated with/without the architectural competitors such as AutoDial and AdaBN that are direct competitors to TN. It would be stronger if the base DA methods were similarly evaluated with/without the architectural competitors such as AutoDial and AdaBN that are direct competitors to TN.' This statement directly suggests a way to improve the review process for the authors. The reviewer provides a clear and actionable suggestion that is likely to be helpful for the authors. The suggestion is specific and directly addresses a potential weakness in the evaluation methodology."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point directly states a limitation of the paper's theoretical result and suggests a change (not using Gaussian assumptions). It also asks a question (how the rates achieved by their procedure to existing rates in the literature). This suggests a clear action for the authors to take. While the comparison is vague, the core action is clear.", "grounding_specificity_rationale": "The authors can infer the specific part of the paper being addressed (the main theoretical result with Gaussian assumptions) and understand what needs to be improved (not using Gaussian assumptions). However, the exact section or wording of the theorem or assumptions is not explicitly mentioned, making the grounding weak. The suggestion to compare rates is specific, but the grounding of the 'comparison' itself is weak.", "verifiability_rationale": "The review point contains a claim (the Gaussian assumption is a strong requirement and needs comparison). However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The claim is presented as a statement of opinion without evidence.", "helpfulness_rationale": "The review point identifies a specific limitation of the theoretical result and suggests a concrete improvement (not using Gaussian assumptions). It also highlights a gap in comparison to existing literature. This provides the authors with a clear direction for future work and constructive feedback, making it helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests comparing the proposed extension with the original approach of Schiratti et al. (2015). This constitutes an explicit action, as the reviewer directly states what needs to be done. However, the point lacks concrete details on *how* to perform this comparison. The reviewer does not specify which aspects of the proposed extension and the original approach should be compared, making the action implicit rather than fully explicit. The action is also vague as it doesn't provide guidance on the expected outcome or the benefits of such a comparison.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or methodology that needs comparison with Schiratti et al. (2015). The reviewer makes a general suggestion without pinpointing a particular section, table, figure, or unique aspect of the work. Therefore, the grounding is weak, as the authors cannot confidently determine where the comparison should take place. The comment is also vague in terms of what aspects of the proposed extension and the original approach should be compared.", "verifiability_rationale": "The review point does not contain a claim that can be verified. It is a suggestion or recommendation, which is an opinion or judgment, not a statement that can be supported by evidence or logical reasoning. There are no references to external works or logical arguments provided to justify the usefulness of the comparison.", "helpfulness_rationale": "The review point suggests comparing the proposed extension with the original approach of Schiratti et al. (2015). While this comparison could be a valuable suggestion for improving the authors' work, the review point lacks specific guidance on *how* to perform the comparison. It does not specify which aspects of the extensions should be compared, what the expected outcome of the comparison should be, or how this comparison would lead to improvements. Without these details, the reviewer's suggestion is not fully actionable and lacks sufficient justification."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment expresses a preference for a detailed algorithm description but does not explicitly state what is missing or needs improvement. It is a statement of benefit rather than a critique or suggestion for action. While it implies the need for more detail, it doesn't directly tell the authors what to add or how to improve their current draft.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper or method that needs improvement. It is a general statement about the value of detailed algorithm descriptions. The reviewer cannot confidently determine which aspect of the algorithm is lacking detail.", "verifiability_rationale": "The comment is a statement of opinion or judgment about the value of detailed algorithm descriptions, not a claim that needs verification. It does not contain a claim that requires supporting evidence, common knowledge, or external references.", "helpfulness_rationale": "The comment suggests providing a more detailed algorithm description, which could be helpful for understanding. However, it does not directly identify specific weaknesses in the current draft or provide actionable steps for the authors to take. It is a suggestion for improvement rather than constructive feedback on existing issues."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the issues with prompt organization and sentence spacing, making it 5. The reviewer points out 'the prompts are not wellorganized (Table 6, 7)' and 'All sentences squeeze together.' These are direct statements about specific issues, allowing the authors to directly address these points. The reviewer also states 'clean style design' which is a positive comment but does not hinder actionability as it highlights a desired state.", "grounding_specificity_rationale": "The review point explicitly mentions specific tables (Table 6, 7) when describing the issue with prompt organization. The phrase 'All sentences squeeze together' is less specific, but the grounding is present in the reference to tables. The reviewer clearly identifies the location of the problem, making the grounding explicit and strong.", "verifiability_rationale": "The review point identifies a problem with prompt organization and sentence spacing, but it lacks a deeper justification or external reference for *why* these issues are significant. While the reviewer points out 'the prompts are not wellorganized (Table 6, 7)' and 'All sentences squeeze together,' they do not provide specific reasons *why* these are problems or *how* they impact the paper. The observation about 'sentences squeezing together' is noted but not deeply analyzed or linked to a specific principle. The grounding is present, but the lack of explicit reasoning or external references makes the claim somewhat underjustified.", "helpfulness_rationale": "The review point identifies specific weaknesses in the formatting and organization of the paper, making it 5. The reviewer points out 'the prompts are not wellorganized (Table 6, 7)' and 'All sentences squeeze together.' These are concrete issues that the authors can directly address. The reviewer's statement 'clean style design' is a positive comment but does not detract from the helpfulness of pointing out the specific problems. The authors have clear areas to improve based on these specific feedback points."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue with FFNs and suggests a solution (adding a sentence about the lack of a solution). This is a direct and concrete action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'omitted FFNs' and the reason for it ('a linear decomposition cannot be obtained'). They also specify the potential solution by asking about 'existing work' and suggesting an 'approximation'. This clearly identifies the specific part of the paper and the nature of the problem, making it 5.", "verifiability_rationale": "The reviewer states a claim about the difficulty of obtaining a linear decomposition for FFNs and suggests a way to address it (adding a sentence). While the suggestion itself isn't a direct citation, the implication that the problem is open (an approximation might exist) provides some verifiable information. The reviewer is making a claim and suggesting a solution, which falls under verifiability.", "helpfulness_rationale": "The reviewer directly addresses a potential improvement to the paper's clarity and completeness by pointing out the omission of FFNs and suggesting a way to inform the reader about this. This is a constructive and actionable suggestion that directly benefits the reader."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a question about the reasoning behind the effectiveness of the L_pixel component, which can be interpreted as an implicit request for an action, namely, to provide a clearer explanation. While not explicitly stating 'improve the explanation of L_pixel', the intent leans towards this direction. However, the reviewer doesn't specify *how* to achieve this improvement, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly names the 'L_pixel' component, providing a clear and accurate identification of the specific part of the paper being addressed. This demonstrates strong grounding. However, the reviewer does not specify *what* is wrong with L_pixel or *why* it is effective, making the specificity of the grounding somewhat lacking.", "verifiability_rationale": "The reviewer makes a claim that the reasoning behind the method's effectiveness, particularly regarding the L_pixel component, is unclear. This claim is verifiable as the reviewer directly states this lack of clarity. However, the reviewer does not provide any evidence or arguments to support this claim within the review point itself, making the verifiability somewhat lacking.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper (the lack of explanation for the L_pixel component) and suggests an improvement (providing stronger arguments or intuitions). This directly addresses a need for the authors and is therefore 5. The reviewer's comment is actionable in the sense that it points to a specific area requiring improvement and suggests a concrete direction for that improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The binary classification label identifies that there is an issue with the technique, but it doesn't specify *how* or *where* in the implementation this error occurs. While the reviewer acknowledges the importance of the TAL task, the binary label itself lacks the explicit actionability needed for the author to know exactly what to change. The lack of detail makes it difficult to form concrete actions based on this feedback.", "grounding_specificity_rationale": "The binary classification label identifies that the technique is a source of error. However, it doesn't explicitly pinpoint *which* part of the generated text or the generated output this error is manifesting in. The label is somewhat specific about the *type* of error (technique) but lacks the grounding in a specific section or element of the generated output.", "verifiability_rationale": "The claim that the binary classification is a 'justifiable baseline metric' is presented as a statement of opinion. While the reviewer believes it's likely a technique error, the prompt doesn't provide enough information to definitively verify this claim. The justification for this classification might not be explicitly stated or universally agreed upon without further analysis of the generated text and the specific TAL task.", "helpfulness_rationale": "The comment identifies a problem with the generated text, specifically a 'technique error.' However, it doesn't provide specific guidance on *how* to identify and correct this error. The helpfulness is limited because the author still needs to perform additional analysis and reasoning to pinpoint the exact cause and implement a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a limitation of the method regarding the applicability to real and categorical features. While it points out a valid concern, it doesn't propose a specific action or improvement to address this limitation. The reviewer is essentially asking a question about applicability rather than suggesting a concrete change.", "grounding_specificity_rationale": "The review point mentions \"binary features,\" \"real features,\" and \"categorical features.\" While it identifies a category of features, it doesn't explicitly pinpoint a specific section, table, figure, or unique element within the paper that the method is applied to. The grounding is weak because the reviewer is referring to general feature types rather than a specific part of the work.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It's a question about the applicability of the method to different types of features. Since there's no statement that needs to be supported with evidence, it doesn't fall into any of the verifiability categories.", "helpfulness_rationale": "The review point raises a valid concern about the method's applicability to different feature types. However, it doesn't offer any suggestions, actions, or verifiable claims to address this limitation. It's a question posed without providing any constructive feedback or guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The statement is somewhat explicit as it mentions 'the proposed solution' and 'Guzman et. al.' However, it lacks specific details on how the proposed solution is an 'incremental step' and what the 'minor suggestions' entail. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The comment mentions 'the proposed solution' and 'Guzman et. al.' but does not explicitly identify a specific part of the paper or methodology being discussed. The grounding is weak because the authors cannot confidently determine which aspect of the work is being referenced.", "verifiability_rationale": "The comment does not contain a claim. It is a statement of observation ('The proposed solution is an incremental step') without any supporting evidence or justification. Therefore, it does not fit into the verifiability categories.", "helpfulness_rationale": "The comment provides context by relating the proposed solution to Guzman's work. While it sets the stage for further discussion, it does not directly guide the authors on how to improve their draft based on this observation. The helpfulness is limited as there is no explicit action or suggestion provided."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the paper 'doesn't thoroughly explore the upper limits of FedDES's scalability' and then lists 'memory requirements' and 'computational complexity' as specific aspects missing from this exploration. This directly points to an actionable suggestion: authors should investigate these specific factors to understand the scalability limits of FedDES. The action is not just implied but explicitly mentioned, and the specific aspects to look for make it concrete.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper (e.g., 'Section 3.2', 'Algorithm 1', a particular figure). While it mentions 'FedDES's scalability,' it doesn't pinpoint a unique element or section within the paper where this discussion should occur. Therefore, while the topic is relevant, the specific location within the paper is not clearly identified. The specificity is present in the *topics* being discussed (memory and computation), but not in the *location* within the paper.", "verifiability_rationale": "The review point contains a claim: 'the paper doesn't thoroughly explore the upper limits of FedDES's scalability.' It also provides evidence for this claim by listing specific aspects that are missing ('memory requirements' and 'computational complexity'). While the reasoning is implicit (the authors should analyze these aspects), the claim is stated, and the evidence (the absence of these discussions) is clear. The claim is not just a subjective opinion but a statement about the content of the paper.", "helpfulness_rationale": "The review point is 5 because it clearly identifies a gap in the paper's discussion regarding the scalability of FedDES. It guides the authors to look for information on 'memory requirements' and 'computational complexity.' This provides a concrete direction for the authors to improve their understanding of the algorithm's limitations and potential areas for optimization. The suggestion is actionable and directly addresses a potential area of weakness."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a limitation of LLMs and suggests generating instances with more constraints and variables. This is an explicit action. However, it lacks specific guidance on how to implement this action, making it somewhat vague. The reviewer is pointing out a potential issue and suggesting a direction for improvement, but the specifics of how to achieve this are not detailed.", "grounding_specificity_rationale": "The reviewer is making a general observation about the limitations of LLMs and suggesting a way to address it by generating instances with more constraints and variables. The comment does not explicitly refer to a specific part of the paper, such as a particular section, table, or figure. The suggestion is quite broad and does not specify which constraints or how to implement them, making it underspecific.", "verifiability_rationale": "The reviewer is making a statement about the limitations of LLMs and suggesting an alternative approach. This can be considered a claim or an opinion about LLM capabilities. The support for this claim is the reviewer's general understanding or experience with LLMs and their limitations. However, the review point itself does not provide specific evidence or references to back up this claim.", "helpfulness_rationale": "The comment points out a potential limitation of LLMs in handling large instance sizes and suggests generating instances with more constraints and variables. This raises a concern about the applicability of LLMs in certain scenarios. The reviewer is providing a practical concern and suggesting a potential solution, which can be helpful for the authors in understanding the limitations and exploring alternative approaches. However, the suggestion is quite general and lacks specific details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly states that the results are presented in a 'convoluted way' and that 'safety violations of the agent in the first 1000 episodes were disregarded.' While the reviewer's assessment of the presentation being 'convoluted' is subjective, the comment does identify a specific issue ('safety violations of the agent in the first 1000 episodes were disregarded') that could be actionable for the authors. However, the degree of 'convolutedness' is not explicitly defined, making it somewhat subjective.", "grounding_specificity_rationale": "The comment refers to 'the results' generally, without explicitly naming a specific section, table, or figure. While it implies a specific area of the results based on the context of safety violations, it does not provide a unique identifier or a precise location within the document. Therefore, the grounding is weak. The comment also specifies what needs to be addressed ('safety violations of the agent in the first 1000 episodes were disregarded'), making it somewhat specific in that regard.", "verifiability_rationale": "The comment contains a claim: 'the results disregard the safety violations of the agent in the first 1000 episodes.' It also states an opinion: 'The reason for presenting the results in this way is unclear.' However, the comment does not provide any evidence or justification to support the claim that 'safety violations of the agent in the first 1000 episodes were disregarded.' The statement about the unclear reason is also not verifiable based on the information provided in the review point itself.", "helpfulness_rationale": "The review point is not helpful because it does not provide any concrete information or actionable feedback to the authors. The comment criticizes the presentation of results but fails to specify *how* the results should be presented or *what* specific issues need to be addressed. The lack of clarity and specific actionable feedback makes it difficult for the authors to improve their draft based on this review point."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides an explicit action: 'Elaborate a bit more in the main text why this holds'. They also specify the *how*: 'intuitively, since the RNN unlike the URNN will converge to the nearest FP'. This provides concrete guidance on how to improve the explanation. The reviewer identifies a specific area for improvement related to the explanation of Theorem 4.1.", "grounding_specificity_rationale": "The reviewer refers to 'line 134' and 'Theorem 4.1', making the information specific to the text. They also specify the *type* of sigmoid function and the *mechanism* of RNNs/URNNs convergence, adding further specificity. The reviewer's suggestion is directly tied to a specific part of the paper.", "verifiability_rationale": "The reviewer does not make a claim. They are suggesting an improvement to the presentation of information. Therefore, the verifiability score is 'X' (X).", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'elaborate a bit more in the main text why this holds (intuitively, since the RNN unlike the URNN will converge to the nearest FP)'. This directly addresses a potential area of confusion or lack of clarity in the explanation of Theorem 4.1. The reviewer provides a reason for the suggestion (lack of intuition) and a potential explanation (convergence behavior). This is a helpful suggestion for improving the clarity and understanding of the theorem."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests an improvement ('edits the main paper space more wisely') but doesn't explicitly state the current allocation of Figure 1 or provide concrete steps on how to reallocate the space. The suggestion is general and lacks specific details on what needs to be done.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1' and directly refers to the allocation of this specific figure. The reviewer clearly identifies the part of the paper being addressed.", "verifiability_rationale": "The review point contains a claim (' allocation of Figure 1 is too naive') but lacks specific justification or examples to support this claim. The suggestion ('edits the main paper space more wisely') is vague and doesn't provide a clear path for improvement. There's no external reference provided to back up the criticism.", "helpfulness_rationale": "The review point identifies a specific issue (Figure 1 allocation) and offers a general suggestion for improvement (better space management). However, it doesn't provide concrete, actionable steps on how to achieve this improvement. The feedback is relevant but lacks the specific details needed for the author to act immediately, making it only marginally helpful."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need to 'manually design a plan' and further clarifies it needs to be 'based on the ground truth.' This is a clear, direct action that is also concrete as it specifies the basis for plan design. The reviewer identifies a specific aspect of the proposed method (plan design) and its dependence on ground truth, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer clearly identifies the issue as being related to the 'ground truth' and the 'planbased method.' They specify the problematic aspect of the proposed method as 'manually designing a plan based on the ground truth.' The reviewer also points out the implication: 'not comparable to learned plan methods' and 'may be difficult to generalize to a new dataset without the ground truth summary.' This precise identification of the problematic aspect and its consequences demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim: 'The learned plan methods are not comparable to the methods with predefined plans based on Table 2.' They provide a reason for this: 'It indicates that the proposed method may be difficult to generalize...' This claim is supported by the stated difficulty in generalization, making it 3. The reviewer infers a limitation of the proposed method based on the comparison to other methods.", "helpfulness_rationale": "The reviewer highlights a significant limitation of the proposed method: its reliance on ground truth for plan design. They point out a crucial drawback: 'the proposed method may be difficult to generalize to a new dataset without the ground truth summary.' This directly addresses a practical challenge and suggests a limitation in the method's applicability. The reviewer's comment is directly actionable for authors trying to understand the limitations of the proposed method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a limitation in the experimental methodology but does not explicitly state what action the authors should take to address this limitation. The reviewer points out the absence of multiple test splits, which is a valid concern, but does not provide concrete steps or suggestions on how to implement this change. Therefore, the actionability is limited as the authors are not directed to perform a specific action.", "grounding_specificity_rationale": "The reviewer refers to 'experiments' and 'results' generally, without specifying a particular section, table, figure, or unique aspect of the paper. While they imply it's related to the experimental setup, they do not pinpoint the exact location or nature of the issue. This makes the grounding weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point contains a claim: 'Standard practice in most papers on GPs involves using a number of train/test splits or folds'. The reviewer provides a general justification, stating 'While I imagine that the size of the datasets considered in this work entail that this can take quite a long time to complete, I highly encourage the authors to carry out this exercise'. While the reasoning is logical, it lacks specific examples or references to external works to support the claim. Therefore, the verifiability is somewhat good as the claim is wellsupported but lacks key elements like examples or references.", "helpfulness_rationale": "The review point identifies a valid concern regarding the experimental methodology and suggests a common practice. The reviewer's encouragement to 'carry out this exercise' is a helpful suggestion for improvement. However, the review itself does not offer a concrete alternative solution or specific steps the authors should take to address the identified limitation. The helpfulness is moderate as the reviewer points out a valid issue and suggests a potential improvement, but lacks a direct recommendation for action within the review itself."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the definition of uncertainty is unclear and points to 'the posterior distribution' as the current definition. While the reviewer offers a specific interpretation involving priors and posteriors, the exact *nature* of the ambiguity within the current definition isn't pinpointed. The reviewer identifies the *area* where clarification is needed, but the *specific* ambiguity remains somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the posterior distribution' as the part of the paper they are referring to when discussing uncertainty. They also further specify 'epistemic model uncertainty', which clearly identifies the section and the type of uncertainty. This strong identification of the specific part and the nature of the uncertainty demonstrates full grounding.", "verifiability_rationale": "The reviewer states that the current definition of uncertainty is unclear ('The uncertainty is defined based on the posterior distribution.') and then provides an alternative explanation involving 'epistemic model uncertainty represented in the prior distribution, and upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data.' This provides a clear reasoning and justification for why the current definition might be unclear, making the claim verifiable.", "helpfulness_rationale": "The reviewer provides a specific suggestion for improving the clarity of the definition of uncertainty. They propose explaining the role of the prior distribution in representing epistemic model uncertainty and how the posterior distribution updates these beliefs based on observed data. This concrete suggestion makes the feedback actionable and directly addresses a potential point of confusion, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the need for 'Missing some citations to set this in context of other MARL work e.g. recent papers on selfplay and populationplay with respect to exploration and coordination'. This clearly identifies an action the authors should take: 'add citations to recent papers on selfplay and populationplay with respect to exploration and coordination'. The action is also relatively concrete, as the specific areas of citation are mentioned (selfplay, populationplay, exploration, coordination).", "grounding_specificity_rationale": "The comment explicitly mentions 'recent papers on selfplay and populationplay with respect to exploration and coordination'. This directly points to specific areas within the MARL field where citations are needed. However, the comment does not explicitly state which section, table, or figure of the paper requires this context. Therefore, while the grounding is present, it is not as precise as 'Full Grounding'.", "verifiability_rationale": "The review point itself does not contain a claim in the sense of an opinion or assertion. It is a statement of a need. However, if we were to interpret the implicit need for the authors to *find* and *verify* these citations, the reasoning could be considered somewhat logical. The reviewer implies that the authors should search for and cite relevant recent work. However, the review point itself doesn't provide specific examples or references to guide the authors in their search. The verifiability is limited to the logical implication that these citations are relevant.", "helpfulness_rationale": "The comment clearly identifies a need for citations and even specifies the *type* of citations required. This directly points the authors towards relevant recent work in MARL. While the review point itself doesn't *verify* the existence or relevance of these citations, the suggestion to include them is a valuable piece of feedback that can help the authors position their work within the current state of the field. The reviewer is directly prompting the authors to improve their literature review."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer implicitly suggests adding details about PCA, but the exact action isn't fully specified. It's a pointer to a missing element.", "grounding_specificity_rationale": "The reviewer accurately identifies the *section* and *figures* where the issue lies, demonstrating strong grounding. However, they don't specify *what* is missing within those figures, making it only *underspecific*.", "verifiability_rationale": "The reviewer clearly states a problem and provides specific examples (Appendix, PCA details) to support it. While they don't explicitly *recommend* a solution, the implication is clear.", "helpfulness_rationale": "The comment identifies a clear weakness in the paper's presentation and points to a specific area needing improvement. While it doesn't explicitly *recommend* a solution, it provides a clear direction for the authors to take action."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of explicit detail regarding how the embeddings are combined and fed into the CSCM. While the paper mentions separate embedding and addition with positional encoding, it doesn't clearly state the method of combination or how this combined embedding is then used as input for the CSCM. This lack of clarity makes it difficult for the reviewer to understand the exact mechanism and potentially replicate or build upon the work. The reviewer can identify the action (identifying the combination method), but the specifics are missing, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer's comment is 1 at all. They are making a specific request about the combination of embeddings and their feeding into the CSCM, but the paper does not explicitly mention this aspect. The reviewer has to infer that the paper deals with embeddings and CSCM, and then make a specific suggestion about their combination. This lack of explicit mention makes it difficult for the authors to pinpoint the exact location and nature of the issue. The comment is not directly addressing a specific part of the paper as it is generally about the architecture.", "verifiability_rationale": "The reviewer's comment is 1. The paper describes the individual components (embedding, addition, positional encoding) but does not explicitly state how these are combined and fed into the CSCM. There is no logical reasoning, common knowledge, or external references provided to support the claim that this is the method used. The reviewer is making an assumption based on their understanding of common practices, but the paper lacks this explicit detail. The claim is made without sufficient justification or evidence.", "helpfulness_rationale": "The reviewer's point is 3. While the paper describes the individual components involved, it lacks a clear explanation of how they are integrated into the CSCM. This omission could hinder the authors' understanding and implementation of their work. The reviewer's suggestion to clarify this aspect is directly addressing a potential implementation detail and could provide valuable information for the authors. However, the lack of any information on this aspect makes it not entirely helpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action: 'it would have been better to evaluate the methods across different splits of trainvaltest'. This action is concrete, as it tells the authors exactly what needs to be done. The reviewer is suggesting a specific change in their experimental procedure.", "grounding_specificity_rationale": "The comment does not explicitly identify the specific part of the paper being addressed. While the reviewer mentions 'trainvaltest splits,' they do not explicitly state that they are aware of these specific splits within the paper's methodology. The grounding is implicit as the reviewer is implying a better way to evaluate, but not directly pointing to a specific section or table.", "verifiability_rationale": "The comment contains a claim: 'it would have been better to evaluate the methods across different splits of trainvaltest'. This claim is not directly supported by logical reasoning, common knowledge, or external references within the review point itself. The reviewer is making a recommendation based on their understanding of the benefits of different splits, but the evidence for *why* this is better is not explicitly stated in the review point.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for improving the experimental evaluation. By recommending the use of different trainvaltest splits, the reviewer is directly pointing the authors towards a potential improvement in their methodology. This provides valuable guidance and is likely to be helpful for achieving more robust results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states an action: 'can be combined together'. This instruction is both explicit and concrete. It tells the authors exactly what needs to be done and how to apply it. The authors know precisely where to make the change (the first two bullets of the introduction) and what the desired outcome is (a combined bulleted point). There is no ambiguity about how to achieve this action.", "grounding_specificity_rationale": "The reviewer explicitly identifies the location of the relevant information: 'the first two bullets about contributions (at the end of the intro)'. This is a clear and accurate grounding of the comment to a specific part of the paper. The authors can easily identify the section being addressed.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement, not a claim that requires verification. There are no statements like 'You should do X because Y' where Y needs to be proven. The comment is a direct suggestion to reorganize the introduction.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion to improve the paper's structure. It directly addresses a specific organizational aspect (the introduction's bullet points) and offers a concrete solution (combining the bullets). This is a helpful suggestion that empowers the authors to make a practical improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests referring to 'more recent trends in the vision community' to understand how the paper improves upon existing solutions. While this implies a need to compare against recent work, the specific action of 'comparing' is not explicitly stated or detailed. The reviewer also mentions validating the algorithm's ability to find closed contours and its robustness to weak boundaries, but doesn't provide concrete steps on how to do this comparison or validation. Therefore, while the reviewer points towards a relevant area, the suggested action is implicit rather than explicit and lacks specific details.", "grounding_specificity_rationale": "The reviewer mentions 'more recent trends in the vision community' as a point of comparison. This comment does not explicitly identify a specific part of the paper, method, or experiment being discussed. While the general area of 'vision community' is mentioned, there's no specific section, table, figure, or unique element of the paper that the reviewer is referring to. The comment is more about the general field rather than a specific aspect of the submitted paper.", "verifiability_rationale": "The reviewer makes a claim about the paper's contribution by stating, 'an important question is how much this paper can really improve over the existing solutions.' This is a claim that could potentially be supported by evidence. However, the reviewer then suggests 'refer to more recent trends in the vision community' without providing specific examples or references. While the suggestion points towards a way to verify the claim, the lack of concrete references makes the verification process incomplete or difficult to follow. The claim is present, but the supporting evidence is missing or vague.", "helpfulness_rationale": "The reviewer provides a clear direction for the authors to improve their draft by suggesting they refer to 'more recent trends in the vision community' and validate the algorithm's performance on 'finding closed contours' and 'robustness to weak boundaries.' This suggests a concrete next step for the authors, guiding them towards relevant literature and specific areas of evaluation. While the suggestion to 'refer' is general, it provides a clear focus for further investigation and improvement. The reviewer highlights specific areas that need attention, making the feedback actionable in terms of what to investigate."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'I expect more baselines to be compared' and 'more domains to be tested'. These are direct requests for action on specific aspects of the work. The reviewer also mentions 'the choices of the weighting and the way of learning density functions are not strongly motivated', which implies a desire for more concrete guidance on these aspects. These explicit statements indicate a high degree of actionability.", "grounding_specificity_rationale": "The reviewer refers to 'more baselines' and 'more domains' as specific areas for improvement. While they mention 'the weighting and the way of learning density functions' generally, the *specific* aspects of these are not detailed. However, the reviewer's statements clearly point to specific, identifiable parts of the work that need attention, indicating a degree of grounding. The reviewer is not just saying 'there's something wrong', but pointing to specific areas lacking.", "verifiability_rationale": "The reviewer makes claims about the current work, specifically stating 'I expect more baselines to be compared and more domains to be tested' and 'the choices of the weighting and the way of learning density functions are not strongly motivated'. However, the reviewer does not provide any specific evidence or references to support these claims. The request for 'stronger empirical results' is a call for future work, not a verifiable statement about the current work. The claims are about what *should* be done, not what is currently lacking with supporting evidence.", "helpfulness_rationale": "The reviewer's comment directly points to areas where the current work could be improved by adding more baselines and testing on more domains. They also criticize the motivation behind the current weighting and density functions. These are concrete suggestions for enhancing the work. The reviewer is not just pointing out a problem, but suggesting specific, actionable steps to make the work better. This makes the comment 5 for guiding future iterations of the work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the issue with Figure 2 ('some symbols are not explained clearly') and raises a question about the multisphere icosahedral discretization process. While the reviewer points out a lack of clarity, they don't provide a specific action or suggestion on how to improve the figure or address the potential redundancy and interference. The reviewer identifies a problem but doesn't offer a concrete solution.", "grounding_specificity_rationale": "The comment explicitly refers to 'Figure 2' and mentions 'some symbols are not explained clearly'. This clearly identifies the specific part of the paper being addressed. However, the reviewer also raises a question about a 'multisphere icosahedral discretization process' without explicitly stating which section or figure this refers to, making the grounding less precise for that aspect.", "verifiability_rationale": "The comment contains a claim ('some symbols are not explained clearly') but lacks specific evidence or references to support this claim. The reviewer states a problem but doesn't provide examples of the missing explanations or cite external sources to demonstrate the ambiguity. The claim is stated but not thoroughly verified.", "helpfulness_rationale": "The comment identifies a potential weakness in the presentation of Figure 2 ('some symbols are not explained clearly'). However, it doesn't provide specific, actionable feedback on how to improve the clarity of the figure or address the concerns about information redundancy and interference. The reviewer points out a problem but doesn't offer concrete suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a problem ('writing is difficult to follow') but does not specify an action or suggestion for improvement. It's a statement of a symptom rather than a prescription for remedy.", "grounding_specificity_rationale": "The comment is general and does not specify which part of the paper is being referred to. It lacks precision in identifying the issue.", "verifiability_rationale": "The comment states an observation ('the writing is difficult to follow') but does not make a claim that requires verification. It's a statement of a problem, not a claim that needs supporting evidence.", "helpfulness_rationale": "The comment identifies a valid issue ('writing is difficult to follow') but does not provide specific, actionable advice on how to improve it. It's a symptom, not a solution with concrete steps."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'It would also be nice to have some intuition of the proof' which is an explicit action. However, the reviewer does not provide concrete steps on how to *obtain* this intuition, making the action somewhat vague. The reviewer also points out a potential ambiguity regarding the dependence of f* on P*, which could be considered an implicit action if the reviewer expects the authors to understand this dependency. Therefore, the action is 3 but lacks concrete details.", "grounding_specificity_rationale": "The reviewer mentions 'intuition of the proof' generally. They do not explicitly identify a specific section, table, figure, or unique aspect of the paper they are referring to. While the topic is specific, the reference is vague. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer states 'It would also be nice to have some intuition of the proof' and 'Also, the invertible function f* would depend on the fixed P*'. These statements are claims that the authors should be aware of and understand. The reviewer provides some justification by explaining the potential ambiguity of f* depending on P*. However, the reviewer does not explicitly claim that something is incorrect or needs verification. The language is more about information needs. Therefore, the claim is somewhat justified but lacks strong supporting evidence.", "helpfulness_rationale": "The reviewer clearly states their desire for more information regarding the intuition of the proof and the dependence of f* on P*. This indicates a desire for improvement, making the review 3. However, the reviewer does not provide specific guidance on how to determine the appropriate P* or how to leverage this understanding in practice. The review lacks concrete solutions, making it less impactful."}
{"actionability_label": "3. 3", "grounding_specificity_label": "3. 3", "verifiability_label": "1. 1", "helpfulness_label": "4. 4", "actionability_rationale": "The review point explicitly states 'A also proposes a CLN' and asks 'What's about a performance comparison with this work?'. The action is to ask for a comparison, which is an explicit instruction. However, the reviewer does not specify how to perform this comparison or where to find the relevant information, making it vague.", "grounding_specificity_rationale": "The review point refers to 'A' proposing a 'CLN'. The reviewer cannot confidently identify which specific paper 'A' is referring to, and the term 'CLN' is not defined within the review point, making the grounding weak. The request is to compare performance, which is a general concept and lacks specific details.", "verifiability_rationale": "The review point contains a claim in the form of a question: 'What's about a performance comparison with this work?'. However, the request itself is not supported by any evidence or references within the review point. The reviewer is asking for information, but doesn't provide any justification or context for the request.", "helpfulness_rationale": "The review point identifies a potential relevant contribution 'A' and asks a pertinent question about its performance. This directly relates to the authors' work and guides them towards a specific type of analysis. While it doesn't provide a direct answer, it is a focused and relevant suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem ('presentation is at times too equationdriven and the notation, especially in chapter 3, quite convoluted and hard to follow') and also suggests a concrete action ('An illustrative figure of the key concepts in section 3 would have been helpful'). This makes the action both explicit and concrete.", "grounding_specificity_rationale": "The reviewer identifies the specific section ('chapter 3') where the issue is located and suggests an improvement ('an illustrative figure of the key concepts in section 3 would have been helpful'). This demonstrates strong grounding as the authors can easily identify the referenced part. While the suggestion is broad (an illustrative figure), it clearly points to a specific area within the paper.", "verifiability_rationale": "The reviewer makes a claim about the presentation being convoluted ('the notation, especially in chapter 3, quite convoluted and hard to follow') and suggests an improvement ('An illustrative figure of the key concepts in section 3 would have been helpful'). While the reviewer doesn't provide specific examples or references to external work to support their claim about the convolutedness, the suggestion is a logical consequence of identifying the problem. The claim is not entirely 1 as it's based on the reviewer's direct experience. The suggestion, while not a specific example, is a logical next step to improve clarity.", "helpfulness_rationale": "The reviewer provides a clear description of a weakness ('presentation is at times too equationdriven and the notation... quite convoluted and hard to follow') and offers a specific suggestion for improvement ('An illustrative figure of the key concepts in section 3 would have been helpful'). This actionable feedback empowers the authors to address the identified issue and improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a factual difference between Batch Normalization (BN) and Online Normalization (ON) regarding gradient bias. While the reviewer doesn't explicitly state an *action* to be taken based on this observation, the identification of this difference itself is an action the author needs to address. The reviewer highlights a specific technical detail that requires further explanation or clarification. Therefore, while not a direct instruction on how to fix the bias, the identification of this difference is a concrete point that the author needs to engage with, making it 3 in that sense.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Batch Normalization' and 'Online Normalization' by name. This demonstrates strong grounding as they are directly referencing specific concepts in the paper. The reviewer is also asking a question about the *mechanism* of bias, which is a specific aspect within these concepts. Therefore, the grounding is both strong and specific.", "verifiability_rationale": "The reviewer does not make a claim in the sense of proposing a new idea or opinion. They are pointing out a difference and asking a question about it. Therefore, it fits the 'X' category. There is no need to verify the veracity of a claim in this case.", "helpfulness_rationale": "The reviewer identifies a specific point of confusion related to a technical detail (the difference in gradient bias between BN and ON). While the review itself doesn't offer a solution, it highlights a specific area where the author needs more clarity. By pointing out this confusion, the reviewer provides a target for the author to focus on, making it 3 in guiding their attention and study. It doesn't provide a concrete action to take, but it identifies a problem that needs addressing."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a direct question asking for clarification on the definition of 'local interactions'. This directly points the author to a specific area needing further explanation. The action is clear: the author should look for the definition of 'local interactions' in the paper.", "grounding_specificity_rationale": "The review point asks about 'local interactions' without explicitly naming a section, table, figure, or unique aspect of the paper. While the reviewer can infer the topic, the specific part of the paper being referred to is not clearly identified. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point does not contain a claim that something is wrong or needs improvement. It is a question seeking clarification on a definition. Therefore, there is X to verify. The score should be 'X'.", "helpfulness_rationale": "The review point is a question seeking clarification on a specific concept ('local interactions'). While this points the author to an area that needs attention, it doesn't directly identify a weakness or propose an improvement. The helpfulness is somewhat limited as it's primarily a clarificatory request rather than a directive to enhance the work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states what is missing from the empirical study, which can be directly acted upon by the authors. The reviewer suggests adding details like recording parameters, preprocessing steps, the resting state condition, and the harmonization technique. These are all concrete actions the authors can take to improve their work.", "grounding_specificity_rationale": "The reviewer explicitly asks for a 'brief explanation of the harmonization technique' and 'the number of regions in the parcellation'. These are specific requests that directly identify the relevant part of the paper and the exact issue. The request for the 'restingstate condition' also implies a specific part (the experimental setup).", "verifiability_rationale": "The reviewer asks a question about the 'restingstate condition' (eyesopen or eyesclosed). This requires the authors to provide verifiable information to answer the question. Additionally, the request for a 'brief explanation of the harmonization technique' implies the authors need to provide a justification for their method, which can be supported by references or logical reasoning.", "helpfulness_rationale": "The review point provides a list of concrete suggestions for the authors, including adding specific details about the empirical study (recording parameters, preprocessing, resting state condition, harmonization, number of regions). These suggestions are actionable and would significantly improve the authors' understanding and the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "None", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states they 'would like' more description, which implies an action: 'Add more description of the Starcraft environment'. However, the action is vague as it doesn't specify where this description should go or how it should be formatted. The lack of specificity makes it less actionable than a comment that says, for example, 'Expand the description of the Starcraft environment in Section 2.3'.", "grounding_specificity_rationale": "The reviewer refers to the 'Starcraft environment' generally, which is a specific domain within the paper's context. However, they do not explicitly identify a specific section, table, figure, or unique aspect of the Starcraft environment. While the term is specific, it lacks the literal grounding of referring to a concrete element of the paper.", "verifiability_rationale": "None", "helpfulness_rationale": "The reviewer's desire for more description directly addresses a potential weakness for the authors, which is their lack of understanding or explanation of the Starcraft environment. Even though the suggestion is general, it is still a valuable piece of feedback that could lead to improvements in the paper's clarity and completeness."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'why don't you use other domain adaptation methods to further improve the performance?'. This is a clear and direct action suggesting a change to the proposed method. The suggestion is also concrete, pointing to a specific area for improvement by using 'other domain adaptation methods'.", "grounding_specificity_rationale": "The reviewer mentions 'the adversarial attack or correction method and the domain adaptation method used by the authors are proposed by prior work.' While this is a general statement, the reviewer doesn't explicitly identify *which* specific methods are being used or suggest *which* alternative methods to consider. The suggestion to use 'other domain adaptation methods' is vague in terms of specific examples or benefits.", "verifiability_rationale": "The reviewer makes claims such as 'the adversarial attack or correction method and the domain adaptation method used by the authors are proposed by prior work' and 'why don't you use other domain adaptation methods to further improve the performance?'. These claims are generally verifiable by checking the literature and the current stateoftheart in domain adaptation. However, the suggestion lacks specific details about *which* alternative methods are most suitable or *why* the current methods are suboptimal.", "helpfulness_rationale": "The reviewer identifies a lack of innovation in the combination of existing methods and suggests exploring 'other domain adaptation methods' to improve performance. This is a valid point that can lead to actionable feedback. However, the suggestion is quite general and doesn't offer specific guidance on which alternative methods to consider or how they might be implemented. The phrasing 'why don't you use' could be perceived as slightly directive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states the lack of a discussion on prompt dataset creation and its source. This is an explicit action that the authors should take. Furthermore, the action is concrete as the authors know exactly what is missing and what they should include.", "grounding_specificity_rationale": "The review point explicitly mentions 'prompt dataset creation' and 'its source'. This allows the authors to accurately pinpoint the specific aspect being addressed, resulting in full grounding. Additionally, the point clearly states that there is a lack of discussion, providing a specific detail about what is missing.", "verifiability_rationale": "The review point contains a claim that a discussion on prompt dataset creation and its source should be included. While it doesn't provide explicit verification for this claim, it sets a clear expectation that is generally understood in the research community as a necessary detail for reproducibility and understanding. Therefore, it can be considered 4 as the implication is generally accepted.", "helpfulness_rationale": "The review point directly identifies a crucial missing element \u2013 a discussion of the prompt dataset creation and its source. This is a 5 and constructive suggestion that will directly benefit the authors in improving their draft by ensuring necessary details are included for clarity and reproducibility."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests an *action*  'ablation on the weighting method of the crossentropy loss'. It further suggests a *concrete* implementation  'suggestion to ablate weighting'. There is no need for inference to understand the authors' intended modification. Therefore, the review point is 5.", "grounding_specificity_rationale": "The reviewer provides a *specific reason* for suggesting the ablation  'The authors note for example that in Atlantis their method underperforms because 'the game has repetitive background sounds''. This grounds the suggestion to a specific observation made by the authors. While the suggestion itself is general ('ablation'), it is grounded to a specific problem. Therefore, the grounding is strong, although the suggestion is not fully specific.", "verifiability_rationale": "The review point makes a *claim*  'An ablation on the weighting method of the crossentropy loss would be nice to see'. It also provides a *justification* for this claim  'The authors note for example that in Atlantis their method underperforms because 'the game has repetitive background sounds''. While the 'repetitive background sounds' is not a direct citation, it serves as a plausible explanation and a basis for the suggestion. Therefore, the claim is somewhat supported by evidence.", "helpfulness_rationale": "The review point directly and clearly suggests a specific improvement ('ablation') and provides a reason for it ('the underperformance in Atlantis due to repetitive sounds'). The suggestion is actionable and directly addresses a potential issue. The reviewer's expression of 'nice to see' indicates a positive and constructive perspective. Therefore, the review point is 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem ('experiments are only done on one game environment') and suggests a general improvement ('More experiments are necessary'). However, it does not explicitly state how the authors should go about conducting these additional experiments. The action is implied rather than explicitly stated and clearly defined.", "grounding_specificity_rationale": "The comment refers to 'the experiments' generally, without specifying which particular experiments or the exact nature of the single game environment used. There is no clear identification of a specific section, table, figure, or unique aspect of the paper being addressed.", "verifiability_rationale": "The comment identifies a limitation ('experiments are only done on one game environment') and suggests a direction for improvement ('More experiments are necessary'). This can be considered a judgment or claim about the current experimental setup. However, the suggestion itself is a general recommendation rather than a specific, verifiable statement supported by external references or logical reasoning within the paper itself.", "helpfulness_rationale": "The comment points out a valid limitation in the experimental design ('experiments are only done on one game environment'). It suggests a relevant improvement ('More experiments are necessary'). However, the suggestion lacks specific details on how the authors should expand their experiments (e.g., on which other environments, with what parameters, etc.). The feedback is present but lacks concrete guidance, making it 3 but not entirely helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need to explain the importance of the relaxed assumptions and to provide examples. This is a clear action, although the specifics of the explanation are not detailed.", "grounding_specificity_rationale": "The reviewer is implicitly referring to the paper as a whole when discussing the contribution of the relaxed assumptions. While they are asking for specific examples, they are not pinpointing a specific section or element of the paper.", "verifiability_rationale": "The reviewer makes a claim about the need for explanation and examples and suggests that providing examples will verify this claim. This is a clear and verifiable suggestion.", "helpfulness_rationale": "The reviewer directly points out a weakness in the authors' presentation (lack of explanation and examples) and suggests a concrete improvement (providing examples). This is a 5 comment for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a concern about the performance of the new classification network compared to the standard softmax network and provides specific suggestions for improvement, such as reporting classification accuracy on ImageNet data and asking for theoretical justifications. These suggestions directly address the identified issue and offer concrete steps for the authors to take.", "grounding_specificity_rationale": "The reviewer refers to 'a new classification network' and compares it to 'the standard softmax network'. They also suggest 'ImageNet data' as a place to report accuracy. While the initial phrasing could be more precise (e.g., 'the new classification network proposed in the paper'), the reviewer does identify the specific part of the paper being addressed and suggests a concrete metric for evaluation. The suggestion to report accuracy on ImageNet is a clear indication of the specific aspect being evaluated.", "verifiability_rationale": "The reviewer asks for 'classification accuracy of the proposed classifier on ImageNet data' and 'some theoretical justifications, if possible'. These are concrete requests for information and analysis. The request for accuracy provides a clear metric to verify the claim, and the request for theoretical justifications aims to provide a logical reasoning behind the performance difference, making the claim verifiable.", "helpfulness_rationale": "The reviewer's point is directly relevant to the authors' work, as they are questioning a potential tradeoff between indistribution accuracy and outofdistribution detection. The suggestions for reporting classification accuracy on ImageNet and asking for theoretical justifications make this review actionable and provide concrete steps for the authors to take to address the concern. This directly helps them improve their draft by identifying a potential issue and providing directions for investigation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states a potential issue with a specific type of recognition list (recognition lists) in a specific scenario (old vs. new judgments). They also describe *how* this might be problematic, indicating a clear action the authors could take \u2013 reconsider their list construction. This fits the definition of explicit and concrete actionability.", "grounding_specificity_rationale": "The reviewer mentions 'recognition lists' and 'old vs. new judgments', which strongly implies a concern about a specific part of the paper related to recognition methodology. While they don't explicitly point to a section or table, the context suggests they are referring to the way recognition lists are constructed and used in this specific scenario. The specificity lies in identifying the potential issue (exhaustive list) and the context (old vs. new judgments). However, the grounding is weak because the authors wouldn't immediately know *which* part of the paper this refers to without further context.", "verifiability_rationale": "The reviewer states a potential limitation of a specific recognition model in a specific scenario. This constitutes a claim that needs verification. However, the reviewer does not provide any specific examples, references, or logical reasoning to support this claim. They are simply stating a potential issue without backing it up.", "helpfulness_rationale": "The reviewer points out a potential issue with a specific method (recognition lists) in a specific context (old vs. new judgments). They do not offer any alternative solutions or suggestions. The reviewer is essentially highlighting a potential flaw in the methodology without providing any actionable improvements. The authors would need to interpret this and potentially reconsider their approach, but the review point itself doesn't directly help them implement a fix."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer's comment is explicit in pointing out the need for alternative formulations of Confidence Diversity (CD) and asking for clarification on the difference between CD and Predictive Uncertainty. The reviewer also explicitly asks why entropy is not a good measure of diversity. These are direct requests for information and actions to be taken. The reviewer clearly states the actions they want to be taken: 'It is difficult to what extra information is CD capturing on top of Predictive Uncertainty' and 'why is entropy not a good measure...'.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Confidence Diversity (CD)' in their comment. This clearly grounds the comment in a specific part of the paper. The reviewer also asks a specific question about entropy, which further grounds the comment in a specific element (the teacher's output diversity across samples). The comment identifies a specific area (CD) and a specific aspect within that area (the difference from predictive uncertainty and the suitability of entropy).", "verifiability_rationale": "The reviewer's comment is a claim that there is difficulty in understanding what extra information Confidence Diversity (CD) captures beyond Predictive Uncertainty and why entropy is not a good measure of diversity. The comment requests clarification and justification for these points. The comment does not provide any external references or logical reasoning to support this claim. The claim is based on the reviewer's own interpretation and the need for further explanation in the paper.", "helpfulness_rationale": "The reviewer's comment is highly specific and directly points to areas where the paper could be improved. They are asking for clarification on a specific concept (CD vs. Predictive Uncertainty) and a justification for a methodological choice (why entropy isn't suitable). This is a valuable feedback point as it guides the authors on what needs further explanation and justification. The reviewer is not criticizing the current state of the paper but is suggesting concrete improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a potential issue with the assumptions for termination states but doesn't explicitly state which specific termination states are problematic or provide concrete steps for the authors to address this. While it implies a weakness, the action is not clearly defined or actionable.", "grounding_specificity_rationale": "The comment mentions 'termination states' generally but doesn't pinpoint a specific section, table, figure, or unique aspect of the paper where the assumption might be strong. The grounding is weak because the authors can only make an educated guess about the referenced part.", "verifiability_rationale": "The comment contains a claim ('the assumptions for termination states are quite strong') and provides a justification ('in the general case, it is very expensive to label a large number of data manually'). This justification, while lacking specific examples or references, does provide some logical reasoning and is verifiable based on practical considerations. Therefore, it is 3.", "helpfulness_rationale": "The comment raises a valid concern about the practicality of manual labeling for complex termination conditions. It highlights a potential bottleneck in the data annotation process. While it identifies a problem, it doesn't offer specific, actionable suggestions for the authors to address this issue, making it 3 but not fully so."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out that the paper does not explicitly state how the number of bins is determined. While the reviewer infers that the contribution might be related to the binning process, this is not explicitly stated in the text. The actionability is somewhat present as the reviewer identifies a missing piece of information, but it is not explicitly stated as an action to be taken by the authors.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify a specific part of the paper being addressed regarding the contribution with respect to ECE_sweep. The reviewer is more focused on the lack of clarity about the binning process in general. While the comment implies a concern about the contribution, it does not pinpoint the exact section or table where this contribution is discussed. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer makes a claim that the contribution is 'fundamentally different' and that the paper is 'not something fundamentally different'. However, the reviewer does not provide any evidence or justification for this claim. The reasoning provided by the reviewer is not supported by the paper's content. The claim is presented without any supporting arguments or references to external sources. Therefore, the verifiability is low as the claim is not wellsupported.", "helpfulness_rationale": "The reviewer states that the comment is 'unhelpful' because it does not provide a solution to the confusion about the nature of the contribution with respect to ECE_sweep. The comment identifies a problem (lack of clarity) but does not offer any actionable steps or suggestions for the authors to improve their draft. The helpfulness is low as the comment does not provide any guidance or resolution to the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The statement is explicit about the purpose of the FGT evaluation in the ablation study. It clearly states 'only leveraged to evaluate the method performance in the ablation study' which directly identifies an action or suggestion (evaluating method performance in the ablation study).", "grounding_specificity_rationale": "The reviewer refers to the 'evaluation of FGT' and its 'use in evaluating the method performance in the ablation study'. While not a literal mention of a section or table, the context implies the reviewer is pointing to the FGT evaluation. The reviewer also specifies 'in the ablation study' which provides some specificity about the referenced part. However, the connection to the FGT evaluation itself isn't explicitly stated.", "verifiability_rationale": "The reviewer makes a claim about how the FGT evaluation is being used ('only leveraged to evaluate the method performance in the ablation study'). This claim is supported by the statement itself, which logically explains the reviewer's understanding of the FGT evaluation's role. There are no external references or logical reasoning issues.", "helpfulness_rationale": "The reviewer's point is that the evaluation of FGT is only used in the ablation study and not to evaluate the method performance in the main evaluation. While this is a valid point, the review point itself doesn't directly provide actionable feedback on how to improve the authors' draft. The authors would need to ask the authors of the comparative methods to provide their code to validate the ablation study. Therefore, the review point is not directly actionable for improving the authors' work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an implicit action: 'modelling curves' needs clarification. However, it doesn't provide specific details on how to achieve this clarification. The action is implied but not explicitly stated or concrete.", "grounding_specificity_rationale": "The comment explicitly mentions 'the second paragraph of the introduction,' which clearly identifies the specific part of the paper being addressed. However, it does not specify what is being modelled within that paragraph. The grounding is present, but the specificity of the identified issue is lacking.", "verifiability_rationale": "The comment contains a claim: 'in the introduction, the second paragraph talks about modelling curves, but it is not immediately obvious what is being modelled (presumably tumour growth).' However, it does not provide any evidence or justification to support this claim. It is presented as a statement of potential confusion without logical reasoning or references.", "helpfulness_rationale": "The comment identifies a potential area for improvement by highlighting the lack of clarity regarding what is being modelled. However, it does not provide any specific suggestions or guidance on how the author should address this issue. The feedback is present but lacks actionable steps."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests 'more explanation' and 'discussing different optimization strategies and the corresponding results'. These are clear actions that the authors should take. The reviewer also mentions 'Eq 3', which is a specific part of the paper, making the action even more concrete. The suggestion to explore different optimization strategies and their consequences is a concrete action that the authors can implement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the main contributions of this paper is the CBR' and 'Eq 3'. This clearly identifies the specific part of the paper being addressed. The reviewer also suggests 'different optimization strategies and the corresponding results', which is a specific area within the CBR. The reference to a specific equation (Eq 3) makes the grounding very strong. The suggestion to explore different strategies and their consequences is also very specific.", "verifiability_rationale": "The reviewer states 'expected' and suggests 'more explanation' and 'discussing different optimization strategies and the corresponding results'. These statements can be considered claims that the paper needs to address. However, the review point does not provide any specific evidence, references, or logical reasoning to support these claims. There is no external data or examples provided to back up the assertion that the paper lacks these explanations or discussions.", "helpfulness_rationale": "The review point provides specific suggestions for improvement, focusing on a key contribution (CBR) and a specific technical detail (Eq 3 and optimization strategies). The reviewer suggests 'more explanation' and 'discussing different optimization strategies and the corresponding results', which are actionable and directly related to the identified weaknesses. While the reviewer doesn't propose a new optimization strategy, they clearly point out the need for more discussion and exploration of existing ones. This is a valuable piece of feedback for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly suggests an action: including a definition of 'treewidth'. This is a clear and explicit instruction, making it 5 for the authors. The reviewer identifies a specific area where more information is needed and proposes a concrete solution.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'treewidth' and its role in the proofs. This provides strong grounding for the suggestion, as the reviewer clearly identifies the specific concept being addressed and its importance within the paper's context.", "verifiability_rationale": "The reviewer states that 'treewidth is central to all the proofs'. This provides a basis for verification. While it might not be a universally known fact within the specific subfield, it's a reasonable assumption for a paper making claims about the complexity of algorithms based on treewidth. The reviewer provides a claim and a reason for it.", "helpfulness_rationale": "This review point directly addresses a crucial element of the paper \u2013 the concept of 'treewidth' and its importance to the proofs. By suggesting the inclusion of a definition, the reviewer provides a clear and actionable piece of feedback that empowers the authors to improve the clarity and accessibility of their work. This is a 5 suggestion as it directly addresses a potential barrier for readers and future researchers attempting to build upon this work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X (X)", "helpfulness_label": "None", "actionability_rationale": "The reviewer implies what needs to be done to make the paper selfcontained, but doesn't explicitly state the action. The lack of a specific section or detail makes it 3 but not fully concrete.", "grounding_specificity_rationale": "The reviewer mentions 'large parts of the main paper' requiring the supplementary material, indicating a lack of precise grounding. The request for source code further supports this.", "verifiability_rationale": "The reviewer does not make a claim that needs to be verified. They are stating a problem and a request.", "helpfulness_rationale": "The reviewer clearly states a problem (lack of selfcontainment) and a request (sharing source code), which is helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: the opponent maximizes classical Solution Equilibrium (SE) and Alternating Equilibrium (AE), not the authors' proposed multiagent payoff. This is an explicit statement of an action: identifying the opponent's objective as a potential reason for outperforming the authors' payoff. While the reviewer doesn't provide a concrete action on how to address this, the identification of the issue is clear and actionable.", "grounding_specificity_rationale": "The reviewer refers to 'the opponent' and their 'experiments' in a general sense. While not a direct mention of a specific section, table, or figure, the context strongly implies a reference to the experimental setup described earlier in the paper. The reviewer is building upon the reader's understanding of the experimental design. However, the reviewer does not explicitly state which part of the paper they are referring to, making the grounding somewhat weak. The reviewer also specifies the *type* of objective the opponent has (maximizing SE/AE), which adds some specificity to the identified part, but the connection to a *specific* element within that part is missing.", "verifiability_rationale": "The reviewer makes a claim: the opponent's outperformance is due to their different objective (maximizing SE/AE instead of the authors' payoff). This claim is supported by logical reasoning: the definitions of SE and AE indicate that players aim to maximize their own best outcome given expected actions of others, which differs from the authors' payoff. The reviewer also provides common knowledge within the game theory community regarding the objectives of SE and AE. While the reviewer doesn't explicitly cite external references, the understanding of these concepts relies on established principles. The claim is wellsupported by logical reasoning and common knowledge.", "helpfulness_rationale": "The reviewer's point is valuable for the authors. It highlights a potential flaw in their experimental design and the interpretation of their results. By pointing out the discrepancy in the opponent's objective, the reviewer encourages the authors to consider alternative objectives for the opponent and potentially refine their payoff definition. While the feedback is not a direct solution, it points to a potential area for improvement and further analysis of the experimental setup. The reviewer's suggestion to consider the authors' payoff as the opponent's objective is a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a potential weakness: 'It would be good to describe why certain choices were made.' They then offer a solution: 'I presume it has to do with the attention model paper this one iterates on, but clarification would be good.' This clearly identifies an implicit action: the reviewer is suggesting a clarification regarding the algorithm choice. While the action is implied, it is directly stated and can be inferred. The reviewer also provides a concrete suggestion: 'I would like to see a more detailed explanation of why the REINFORCE algorithm was chosen over alternatives like PPO.' This suggests a concrete action: to provide a justification for the algorithm choice. Therefore, the review point is explicit about the need for clarification and provides a concrete suggestion, making it actionable.", "grounding_specificity_rationale": "The reviewer mentions 'REINFORCE algorithm' and 'PPO' as potential alternatives. This indicates a grounding as the specific algorithm is mentioned. However, the reviewer does not explicitly state which section, table, or unique aspect of the paper they are referring to regarding the algorithm choice. The grounding is weak because it relies on the general context of the paper and the suggested alternative algorithm. The comment does not specify *what* needs to be addressed in this part (the algorithm choice).", "verifiability_rationale": "The reviewer makes a claim: 'It would be good to describe why certain choices were made.' This is a claim that requires justification. The reviewer then suggests a solution: 'I presume it has to do with the attention model paper this one iterates on, but clarification would be good.' This suggests a verification method: 'I would like to see a more detailed explanation of why the REINFORCE algorithm was chosen over alternatives like PPO.' This implies a need for logical reasoning and potentially external references (the 'attention model paper'). While the reviewer doesn't explicitly provide the justification within the review point itself, they *claim* that a justification is missing and *suggest* a way to address it, indicating an attempt to verify the claim.", "helpfulness_rationale": "The reviewer identifies a potential improvement to the paper by suggesting a clarification of the algorithm choice. They propose a concrete suggestion: 'I would like to see a more detailed explanation of why the REINFORCE algorithm was chosen over alternatives like PPO.' This directly addresses a potential weakness (lack of justification) and offers a concrete way to improve the paper. The reviewer's suggestion is specific and actionable. While the reviewer doesn't provide the actual justification, the *request* for it is a valuable contribution to the paper. The reviewer's point is not vague or general; it points to a specific area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states they are confused about the theorem, indicating they can identify it but not understand its implications.", "grounding_specificity_rationale": "The reviewer mentions 'Theorem 5.1' and 'variance regularized problem,' showing they have some connection to the text, but their confusion indicates a lack of precise understanding.", "verifiability_rationale": "The reviewer's confusion about the theorem makes it 1.", "helpfulness_rationale": "The reviewer's confusion and lack of understanding of the theorem's implications make it unhelpful."}
{"actionability_label": "4", "grounding_specificity_label": "X", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a question and requests clarification on the applicability of morphologic segmentation across domains. This constitutes an explicit action, as the authors should be able to directly identify the need for clarification. The request is also concrete, pointing out a specific potential issue (domain adaptation) and asking about the generality of a technique (morphologic segmentation).", "grounding_specificity_rationale": "This review point does not explicitly refer to a specific part of the paper or identify a unique element. The reviewer is making a general point about the applicability of a technique across domains, which is a conceptual issue rather than a specific issue within a particular section, table, or figure.", "verifiability_rationale": "This review point does not contain a claim that requires verification. It is a question posed to the authors, not a statement that needs to be supported by evidence or references.", "helpfulness_rationale": "The reviewer is trying to help the authors by pointing out a potential limitation (the assumption of invariant morphologic segmentation across domains) and asking a relevant question. This is a valuable contribution to the authors' work, as it highlights an area where the authors might need to consider additional steps or adapt their approach. While it doesn't directly provide a solution, it encourages the authors to think critically about their methodology and consider the implications of domain adaptation. The helpfulness is '4' because it prompts a consideration that could lead to improvement, but it's not a direct instruction on how to improve the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missingness of a discussion about the Set Transformer and related works that use summary tokens. While it doesn't directly tell the authors what to do, it points to a clear area for improvement in the related work section. This implies an action: \"You should include a discussion about the Set Transformer and related works that use summary tokens.\" The reviewer identifies a gap and suggests an area for expansion.", "grounding_specificity_rationale": "The review point clearly identifies the specific area of the paper where a discussion is missing: the \"related work\" section. Furthermore, it pinpoints specific examples of works that should be included (Set Transformer and other works using summary tokens). This strong identification of the location and content makes it highly grounded.", "verifiability_rationale": "The review point makes a claim about the deficiency of the paper's related work section. It provides a specific link to a relevant paper (Set Transformer), which serves as direct evidence supporting the claim that this area needs discussion. The reviewer provides a concrete example to back up their statement.", "helpfulness_rationale": "The review point is 5 because it directly identifies a gap in the related work section and provides a concrete example (the Set Transformer paper) to guide the authors in expanding this section. The suggestion to \"look into the cited paper and other works\" is a clear and actionable next step for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks a question about a specific technical aspect of the paper: 'How Fourier features accelerate NTK convergence in the highfrequency range?'. This constitutes an explicit request for information. While it doesn't directly instruct the authors on what to change, it clearly identifies a point of potential weakness or area needing clarification. Therefore, it is considered explicit and points to a specific area for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'Fourier features,' 'NTK convergence,' and 'highfrequency range.' While they don't explicitly name a section or equation, these terms strongly suggest a specific part of the paper. The context implies they are referring to a particular analysis or claim related to these concepts. This can be considered weak grounding as the authors need to infer the specific section or part being addressed. However, the specificity of the terms indicates a clear area of inquiry. Therefore, it is considered somewhat specific.", "verifiability_rationale": "The review point is a question and does not contain a claim that needs verification. Therefore, it does not fit into the categories of 'X' or any verifiability score. The value is 'X'.", "helpfulness_rationale": "The reviewer is asking a specific question about a technical detail in the paper. This can be helpful for the authors if they haven't addressed this specific point or if the reviewer's uncertainty highlights a potential area for clarification. While it doesn't directly suggest an improvement, it points to a potential weakness and asks for clarification, which can be constructive. Therefore, it is considered 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'The effectiveness of lower bound double qlearning is doubtful' and points to specific experimental results in Figure 2 (MsPacman) and other environments (WizardOfWor, Zaxxon RoadRunner, BattleZone). While the reviewer identifies a potential issue, they do not specify how to address it or what changes should be made to the algorithm. The suggestions are very general. Therefore, while the reviewer points out a potential problem, they do not provide explicit or concrete steps for the authors to take. The lack of specific actions makes it less actionable.", "grounding_specificity_rationale": "The reviewer mentions specific algorithms (Clipped DDQN) and environments (MsPacman, WizardOfWor, Zaxxon RoadRunner, BattleZone) in their review point. They state 'in MsPacman of Figure2, the algorithm shows slight performance decrease of Clipped DDQN' and 'in some environment such as WizardOfWor, Zaxxon RoadRunner and BattleZone, these algorithms seems converge into same solutions'. This demonstrates that the reviewer can accurately pinpoint the specific part of the paper and the experimental setups being discussed. The use of specific names and descriptions indicates strong grounding specificity.", "verifiability_rationale": "The reviewer makes claims about the performance of the algorithm and its convergence behavior in specific environments. They state 'in MsPacman of Figure2, the algorithm shows slight performance decrease of Clipped DDQN' and 'in some environment such as WizardOfWor, Zaxxon RoadRunner and BattleZone, these algorithms seems converge into same solutions'. These are statements that require verification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The lack of justification makes it 3, as the observation itself is a claim, but the supporting evidence is missing.", "helpfulness_rationale": "The reviewer raises concerns about the effectiveness of a specific algorithm and points out potential issues in certain experimental settings. While the reviewer's point is valid and highlights potential problems, it does not directly suggest concrete improvements or point to a clear flaw that the authors can immediately fix. The suggestions are more about questioning the results rather than providing a clear path forward. Therefore, while the review is relevant, it lacks the direct guidance needed to be 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their observation about the performance difference between DNN+MMA and vanilla DNN when lambda is small. They also point to specific figures (fig.34) as evidence. This indicates a clear action the reviewer is taking based on their understanding. The reviewer is suggesting a specific improvement: investigating why the performance is worse and why it approaches the vanilla method from below.", "grounding_specificity_rationale": "The reviewer refers to 'DNN+MMA', 'vanilla DNN', and 'lambda' in their review point. While they don't explicitly name 'fig.34', the context strongly links the performance difference to the figures. The reviewer is identifying a specific area within the paper (the performance comparison) and a specific element within that area (lambda). This can be considered 'weak grounding' as the connection to the figures is inferable but not direct.", "verifiability_rationale": "The reviewer states their expectation that the performance of DNN+MMA should approach vanilla DNN from above as lambda becomes small. This is a claim that requires justification. While the reviewer's expectation is based on common understanding of regularization parameters (lambda), the review point itself doesn't provide explicit references or examples to support this claim. Therefore, it is not '5'. The claim is present, but the supporting evidence is missing within the review point.", "helpfulness_rationale": "The reviewer directly asks a question about the performance discrepancy and points to specific figures. This is a clear attempt to improve the draft by seeking clarification on a specific issue. While the reviewer doesn't explain *why* the performance is worse, they are actively trying to understand the behavior of the model. This makes the review point 3 as it identifies a concrete area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a deficiency in the paper by stating 'The paper does not compare the results with some of the earlier research work from 2020.' While this is a valid observation, the reviewer does not explicitly state how the authors should address this lack of comparison. The reviewer's subsequent justification in the author response, 'Those systems are not stateoftheart', is provided after the initial point is made. Therefore, the reviewer identifies a problem but doesn't offer a direct action for the authors to take immediately.", "grounding_specificity_rationale": "The reviewer mentions 'earlier research work from 2020' and specifically names one example, Taghipour and Ng (2016). This indicates that the reviewer has identified a specific area in the paper where a comparison is lacking. However, the reviewer does not specify *what* aspect of the results or methodology is not being compared, nor does the paper itself explicitly state what is missing. The mention of 'Taghipour and Ng (2016)' provides a degree of grounding, but the specifics of the missing comparison are not detailed.", "verifiability_rationale": "The reviewer makes a claim by stating 'The paper does not compare the results with some of the earlier research work from 2020.' This is a subjective observation. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The claim is presented without any backing. The reviewer's justification 'Those systems are not stateoftheart' is provided after the initial claim.", "helpfulness_rationale": "The reviewer's point, 'The paper does not compare the results with some of the earlier research work from 2020', is a valid observation that could be helpful for the authors to understand the context of their work. However, the reviewer does not provide any specific suggestions or evidence to support this claim. The reviewer's subsequent justification, 'Those systems are not stateoftheart', is provided after the initial point is made. Therefore, while the point identifies a potential improvement area, it lacks concrete suggestions and supporting evidence to make it truly helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors have performed significance testing and suggests that the choice of test might be incorrect. It further recommends using a paired test (Wilcoxon signedrank test) instead of an independent samples ttest because the samples are generated from the same input, implying a dependency that violates the independence assumption of the latter. The reviewer provides a clear action: 'Use the Wilcoxon signedrank test instead.' This action is very explicit and directly addresses the identified issue.", "grounding_specificity_rationale": "The review point explicitly identifies the issue as the potential incorrectness of the statistical test used for significance testing. It recommends using a paired test (Wilcoxon signedrank test) and explains why an independent samples ttest is inappropriate in this scenario due to the dependency between the samples. The reviewer provides a specific suggestion and a clear reasoning for why the current approach is flawed. The grounding is strong as it directly points to the relevant statistical methodology and provides a concrete alternative.", "verifiability_rationale": "The review point contains a claim: 'the choice of test might be incorrect.' It provides justification for this claim by stating that the comparison is between two samples generated from the same input, which violates the independence assumption of an independent samples ttest. It then offers a solution: 'Use the Wilcoxon signedrank test instead.' The claim is supported by logical reasoning and a specific statistical concept (Violation of independence assumption). The evidence provided is clear and directly addresses the identified issue.", "helpfulness_rationale": "The review point is 5 as it directly identifies a potential flaw in the authors' methodology (incorrect statistical test) and provides a clear and specific suggestion for improvement (using a paired test). It explains *why* the current approach is problematic (Violation of independence assumption) and *how* the suggested approach addresses this issue. The reviewer offers a concrete recommendation and a logical explanation, making it very actionable and beneficial for the authors."}
{"actionability_label": "5 (5)", "grounding_specificity_label": "3 (3)", "verifiability_label": "3 (4)", "helpfulness_label": "4 (4)", "actionability_rationale": "The review point explicitly states a weakness ('the paper lacks an ablation study') and directly suggests an improvement ('explaining why they chose the prompt in this specific way'). It provides a clear action for the authors: conduct an ablation study. The suggestion is concrete in terms of the *type* of study (exploring different prompting strategies).", "grounding_specificity_rationale": "The review point refers to 'the prompt in this specific way' and 'why they chose the prompt.' While it doesn't explicitly name a section or table, the authors can infer that the reviewer is referring to the section discussing the chosen prompt. However, the *reason* for choosing that specific prompt is not elaborated upon in the review point itself.", "verifiability_rationale": "The review point contains a claim: 'the paper lacks an ablation study explaining why they chose the prompt in this specific way, e.g., fewshot examples for CoT might improve performance.' This claim suggests a solution. While the suggestion to use fewshot examples for CoT is a common practice and doesn't necessarily require external references to be considered valid, the *lack* of an ablation study is a factual observation. The reasoning is based on common knowledge about prompting strategies.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper (lack of an ablation study) and provides a constructive suggestion for improvement (explaining the prompt choice). It directly addresses a potential area for enhancement. While the suggestion is quite general, it's still a valuable piece of feedback that guides the authors in a specific direction."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they would like to see a discussion of a specific paper and a specific concept within that paper. This is an explicit action, and the action is concrete as the paper and concept are clearly identified.", "grounding_specificity_rationale": "The reviewer explicitly names a specific paper and a specific concept within that paper. This allows the authors to accurately pinpoint the relevant part of the suggested work, making the grounding fully grounded. The request also specifies what needs to be understood (relevance to their work), making the specificity high.", "verifiability_rationale": "The reviewer is not making a claim that needs verification. They are suggesting a resource. Therefore, it doesn't fit into the verifiability categories. However, the suggestion itself is 5.", "helpfulness_rationale": "The reviewer clearly identifies a specific area for improvement in the related work discussion and provides a concrete suggestion (read this paper). This is a 5 comment for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that the models are 'not stateoftheart' and suggests a 'comparison' with 'relation extraction/generation models' in a 'fewshot setting'. This is an explicit statement of a weakness and a suggestion for improvement. However, the reviewer does not specify how this comparison should be done or what metrics should be used, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'fewshot RC models' and then narrows it down to 'relation extraction/generation models'. While they identify the type of models, they do not pinpoint a specific section, table, figure, or unique aspect of the paper being discussed. However, they do specify what kind of comparison they want ('comparison in a fewshot setting').", "verifiability_rationale": "The reviewer makes a claim that the models are 'not stateoftheart' and suggests a 'comparison' with 'relation extraction/generation models' in a 'fewshot setting'. This is a claim that can be supported by logical reasoning (the existence of more advanced models) and by referencing the specific comparison suggested. However, the claim lacks specific examples or references to external works to strengthen the argument.", "helpfulness_rationale": "The reviewer points out a potential weakness in the paper's evaluation methodology by suggesting a comparison with relation extraction/generation models in a fewshot setting. This is a valid point that could improve the evaluation. However, the reviewer does not provide concrete suggestions on how to perform this comparison or what specific improvements the authors should expect, making the feedback somewhat vague and less immediately actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests adding background knowledge and moving related work discussions, which are explicit actions. However, the specifics of *how* to do this are missing, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'background knowledge' and 'related literatures,' which are specific elements of the paper. However, the comment does not identify a specific section, table, figure, or unique aspect of the paper that it is addressing, making the grounding weak.", "verifiability_rationale": "The reviewer provides suggestions for improving the organization but does not support these suggestions with logical reasoning, common knowledge, or external references. The claim is that the paper needs more background and earlier related work discussion, but there's no justification for why this is necessary or beneficial.", "helpfulness_rationale": "The reviewer identifies a general organizational issue and suggests improvements in the form of adding background knowledge and moving related work discussions. While lacking specific details, this points the authors in a direction for improvement and highlights a common problem in academic writing."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing with specific models, which can be interpreted as an implicit action to expand the experimental evaluation. However, the exact nature and implementation of this action are not explicitly stated, making it somewhat vague.", "grounding_specificity_rationale": "The review point explicitly mentions 'PanopticFPN' and 'Mask2Former', which grounds the reference to specific models. It also implies the need for a more comprehensive comparison, which is a specific aspect being addressed. Therefore, it is grounded and specifies what needs to be considered.", "verifiability_rationale": "The claim is that the lack of comparison with these specific models is a relevant point. This is a logical claim based on standard practices in the field. The suggestion provides a clear direction for the author to consider and potentially implement. Therefore, the claim is verifiable.", "helpfulness_rationale": "The review point directly addresses a potential weakness in the experimental evaluation \u2013 the lack of comparison with specific stateoftheart models. By suggesting these models, the reviewer provides a concrete direction for the author to consider and potentially improve their analysis. While it doesn't dictate *how* to compare, it highlights a relevant gap. The reviewer is essentially pointing out a missing piece of the puzzle, which is helpful for the author's work."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their lack of expertise in pruning, the results being 'less impressive,' and suggests evaluating on 'latency, memory consumption, and network size.' While the intention is clear, the *specifics* of the results and the *connection* to the suggested metrics are not detailed, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer generally criticizes the results of the work, mentioning the motivation being 'good' but the results being 'less impressive.' They do not explicitly point to a specific section, table, or figure in the paper being addressed, nor do they specify *why* the results are less impressive. The grounding is implied but not precise.", "verifiability_rationale": "The reviewer makes a claim that the results are 'less impressive' and suggests evaluating on specific metrics. However, within this review point, there is no explicit justification or evidence provided to support the claim that the results are indeed less impressive. The suggestion for evaluation is a step towards verifiability, but the claim itself lacks supporting evidence within this review.", "helpfulness_rationale": "The reviewer points out a potential weakness in the paper's evaluation and suggests improvements. This is generally helpful for the authors as it highlights an area for improvement in the evaluation process. However, the criticism is not very specific, and the suggestion for evaluation, while good, is not concretely linked to a specific issue in the paper within this review point."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the existence of a gap between the lower and upper bounds and suggests a specific mathematical expression (sqrt(\u03b2) instead of \u03b2^(1/3)). This is an explicit action, as the authors can directly try to derive the bounds with the suggested change. While the *reason* for the gap isn't deeply explored, the *what* is clear.", "grounding_specificity_rationale": "The review point mentions specific concepts like 'lower bound,' 'upperbound,' 'beta,' 'graphs,' 'independence number,' 'adaptive adversary,' and 'counterfactual feedback.' While it doesn't explicitly point to a specific part of a paper or method, it names several relevant concepts. This suggests a degree of grounding, as the reviewer refers to specific mathematical concepts. However, it lacks the explicit identification of a *particular* element within a paper that is affected by this bound gap.", "verifiability_rationale": "The review point contains a claim: 'There is a gap between the lower bound and the upperbound (sqrt(\u03b2) instead of \u03b2^(1/3)).' It also provides suggestions and implications, such as 'In particular, for some graphs, the existing bound with the independence number may be better' and 'This is also true for the results on the adaptive adversary and the counterfactual feedback.' However, it does not provide sufficient evidence, logical reasoning, or external references to support these claims. The reasoning is presented as a statement of observation rather than a justified assertion.", "helpfulness_rationale": "The review point identifies a potential improvement to the bounds by suggesting sqrt(\u03b2) instead of \u03b2^(1/3). While this points to a concrete direction for improvement, it lacks the detailed explanation and justification needed to make it truly actionable. The reviewer highlights areas where the bounds might not be as tight as they could be, but they don't provide a clear path for the authors to explore this further or understand the implications of the suggested change. The suggestions are presented as possibilities rather than concrete steps."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about the novelty of the work and requests a comparison with a specific paper. This constitutes an explicit action to identify a weakness and seek clarification. The request for a comparison is also a concrete action to understand the differences in approaches.", "grounding_specificity_rationale": "The reviewer explicitly mentions a specific paper (https://aclanthology.org/2021.findingsacl.57.pdf) as a point of comparison. This grounds the comment to a specific aspect of the related work. The reviewer also asks about the differences in approaches, which is a specific question about the methodology.", "verifiability_rationale": "The reviewer poses a question that can be answered by comparing the methodologies of the submitted paper and the cited paper. This requires external references and a comparison of the approaches, which can be verified.", "helpfulness_rationale": "The reviewer's question directly addresses the core contribution of the paper (novelty) and its relationship to existing work. This provides valuable information for the authors to understand the significance and potential impact of their work. The request for a comparison is a clear request for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the observation: 'In the reported ablation studies in Table 2, for CUB and SOP datasets, the complete loss function performed even worse than those with some terms missing.' It also directly asks for an explanation: 'That does not appear to make sense. Why?' This is an explicit statement of the issue and a clear request for action (explaining why).", "grounding_specificity_rationale": "The review point explicitly mentions 'the reported ablation studies in Table 2' and specifically identifies the datasets 'CUB and SOP' where the unexpected result occurred. This demonstrates a clear grounding of the issue in specific parts of the paper.", "verifiability_rationale": "The review point makes a claim: 'In the reported ablation studies in Table 2, for CUB and SOP datasets, the complete loss function performed even worse than those with some terms missing.' However, it does not provide any evidence, reasoning, or references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the statement that the results are unexpected.", "helpfulness_rationale": "The review point identifies a discrepancy in the experimental results and asks for an explanation. While this points to a potential issue, it doesn't offer any actionable suggestions or insights beyond asking 'why.' It highlights a gap in understanding but doesn't provide concrete steps the authors can take to address the problem."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states \"Introducing inverse triples might also be used in other embedding models besides CP.\" This directly tells the authors what to consider. It also implicitly suggests that this could be a valuable alternative. The reviewer is indicating a potential area for the authors to expand their work.", "grounding_specificity_rationale": "The review point clearly mentions \"inverse triples\" and \"other embedding models.\" These are specific technical terms within the context of embedding models. The reviewer is directly referencing specific aspects of the authors' work they are commenting on.", "verifiability_rationale": "The review point contains a claim: \"the authors did not test such cases in their experiments.\" This is a statement of fact based on the reviewer's observation of the authors' experiments. The reviewer also implies that this could be beneficial (\"might also be used\"). While it doesn't provide a direct justification for *why* it's beneficial, it points to a potential area for improvement.", "helpfulness_rationale": "The review point directly points out a potential improvement the authors could make (testing inverse triples) and highlights a gap in their current experiments (not testing other embedding models). This provides a clear direction for future work and identifies a specific area for the authors to address."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The comment states that the GP method is 'straightforward and naive' and mentions the existence of 'dynamical modeling' and 'Gaussian Process Dynamical Model'. However, it does not explicitly state what is meant by 'naive' or provide concrete steps for improvement. The reviewer implies a lack of sophistication but does not specify how the current method falls short or what should be improved.", "grounding_specificity_rationale": "The reviewer mentions 'the way of using GP' generally, without specifying a particular section, table, figure, or unique aspect of the paper. They mention the 'GP community' and 'Gaussian Process Dynamical Model' but do not clearly identify which part of the paper they are referring to. The grounding is weak because the specific location or element being criticized is not explicitly identified.", "verifiability_rationale": "The comment contains a claim that the author's method is 'straightforward and naive' and that the 'GP community' has investigated 'dynamical modeling' and 'Gaussian Process Dynamical Model'. However, the reviewer does not provide specific examples or references to support the claim that the author's method is 'naive' or lacking in detail. The claim is not wellsupported by logical reasoning, common knowledge, or external references within the context of the author's specific method.", "helpfulness_rationale": "The comment criticizes the method and points to the existence of other work. However, it does not provide specific, actionable feedback on how the author should improve their method. It lacks concrete suggestions or guidance on what aspects of the method need to be changed or improved. The feedback is at a high level and does not offer specific steps for the author to take."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the action: 'You should provide the METEOR results...'. This action is clear and directly tells the authors what to do. The instruction is also concrete, as it specifies 'provide the METEOR results' without ambiguity.", "grounding_specificity_rationale": "The reviewer suggests providing METEOR results. While the *topic* of the suggestion (model evaluation) is clear, the reviewer does not explicitly point to the specific section, table, or figure where METEOR results are typically reported in recent works. The suggestion is general, implying it should be included in the evaluation section.", "verifiability_rationale": "The reviewer makes a suggestion: 'You should provide the METEOR results...'. This is presented as a directive without any logical reasoning, common knowledge, or external references to support the importance of METEOR results. There is no justification provided for why METEOR is relevant or how it should be presented.", "helpfulness_rationale": "The reviewer's suggestion to provide METEOR results is relevant to researchers working on similar tasks, as METEOR is a standard metric for evaluating models. However, the suggestion is relatively basic and lacks novelty or specific guidance on how to interpret or present the results. It serves as a recommendation rather than a detailed critique or actionable improvement."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem: 'Studying Geffect of each learning objective in isolation, raises the concern regarding the comparability of Geffect values across various unlearning objectives and approaches.' This is a clear and direct identification of a weakness in the methodology. The reviewer also implies a potential negative consequence: 'This can potentially impact the comparability of Geffect values across various unlearning objectives and approaches.' While the reviewer doesn't explicitly suggest a solution, the identification of the problem is actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 4' and the specific issue of 'comparability of Geffect values across various unlearning objectives and approaches' when referring to unlearning objectives studied in isolation. This is a precise identification of the relevant part of the paper and the specific concern. The reviewer uses the exact phrase 'in isolation' to highlight the issue.", "verifiability_rationale": "The reviewer states a concern: 'This can potentially impact the comparability of Geffect values across various unlearning objectives and approaches.' While this is a logical observation, the reviewer does not provide specific evidence or references to external work to support this claim. The reviewer does not explicitly state how this impact can be verified or measured.", "helpfulness_rationale": "The reviewer points out a potential limitation in the experimental design: 'Studying Geffect of each unlearning objective independently and in isolation to other learning objectives. Results are also shown and discussed in separate figures and parts of the paper. Studying Geffect of each learning objective in isolation, raises the concern regarding the comparability of Geffect values across various unlearning objectives and approaches.' While this highlights a valid concern, the reviewer does not offer any concrete suggestions or alternative approaches to address this limitation. The reviewer's point is more about identifying a potential flaw in the methodology rather than providing a solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitation of using only 'two typical games' and suggests testing on 'more complex problems, especially those with larger depth...'. This is an explicit action to identify a weakness. The suggestion to test on more complex problems with larger depth is concrete, indicating a clear understanding of what needs to be addressed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'ReBeL's performance' and 'more complex problem' as areas for improvement. This is a clear identification of the specific part of the paper being addressed. The reviewer also specifies the nature of the complex problems as 'bigger depth' and mentions the potential impact on 'huge inputs of the value and policy function'. This specificity helps authors understand what needs revision and why.", "verifiability_rationale": "The reviewer makes a claim about the limited scope of the experiments and its potential impact on the generalizability of the results. This is a claim that requires verification. However, the reviewer does not provide specific examples of where the current experiments are lacking, how increased depth would cause issues with value and policy functions, or cite any specific literature to support this claim. The reasoning is present at a high level, but lacks concrete evidence.", "helpfulness_rationale": "The reviewer clearly identifies a significant limitation in the experimental evaluation and provides a concrete suggestion for improvement by testing on more complex problems. This feedback is directly actionable and helps authors understand where their current evaluation is insufficient."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states the paper's contribution is 'an incremental advancement in efficiency over the TACTiS approach.' This suggests a lack of clear, direct action. While it *mentions* an improvement, it doesn't *recommend* or *explain* *how* to achieve it. The reviewer identifies the *type* of contribution but doesn't provide concrete steps or suggestions for achieving it.", "grounding_specificity_rationale": "The review point mentions 'the paper's primary contribution' and 'TACTiS approach.' It doesn't explicitly name a *specific* section, table, figure, or unique aspect of the paper being addressed. The focus is on the *general* contribution and the *comparison* to another approach. Therefore, the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point contains a claim: 'The paper's primary contribution seems to be an incremental advancement in efficiency over the TACTiS approach.' This is a statement of opinion. However, the reviewer does not provide any evidence or justification to *support* this claim. They are expressing a doubt or skepticism about the significance of the contribution, but without any logical reasoning, common knowledge, or external references to back it up.", "helpfulness_rationale": "The review point raises a concern about the significance of the paper's contribution and suggests it is an 'incremental advancement in efficiency over the TACTiS approach.' However, it does not offer any concrete suggestions or actions for the authors to take. The reviewer is questioning the contribution but does not provide a path forward or any guidance on how the authors should address this concern."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a gap in the paper's discussion but does not provide a direct action for the authors to take. It states 'lacks discussion' rather than 'please include a discussion on...'.", "grounding_specificity_rationale": "The review point uses specific terminology related to the paper's content, such as 'theoretical guarantee,' 'approximation ratio,' 'hierarchical strategy,' and 'global optimal.' This clearly indicates the specific area where the authors should look for missing information.", "verifiability_rationale": "The review point makes a claim about the paper's content, stating that 'the paper lacks discussion on the theoretical guarantee...'. This claim can be verified by examining the paper for the mentioned concepts.", "helpfulness_rationale": "The review point points out a missing piece of analysis that could be relevant for the authors to understand the limitations and potential improvements of their method. While it doesn't directly instruct what to do, it highlights a gap that could be valuable for them to address."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a problem (lack of a quantitative measure) but does not propose a specific action or solution. It focuses on the *what* (lack of measure) rather than the *how* or *why*. Therefore, while it points out an area for improvement, it doesn't actively guide the authors on what to do next. This aligns with the 'Explicit vs. Implicit' and 'Concrete vs. Vague' criteria for actionable, where the action is implied but not clearly defined.", "grounding_specificity_rationale": "The review point mentions 'quantitative measure' and 'visual inspection' without specifying *where* these should be applied or *what* aspects of the VCEs are lacking. It doesn't pinpoint a specific section, table, figure, or unique element of the paper. While it identifies a potential area for improvement, it doesn't clearly indicate the specific part of the VCEs that need evaluation. This aligns with the 'Weak Grounding' category.", "verifiability_rationale": "The review point suggests using 'visual inspection' as a way to evaluate VCEs. However, it doesn't provide a clear reasoning or justification for why visual inspection is a suitable or reliable method. There's no explanation of what constitutes good or bad VCEs based on visual inspection, nor are there any references to external standards or practices. This aligns with the 'X' category, as the review point doesn't explicitly state a claim about the VCEs or provide evidence to support it.", "helpfulness_rationale": "The review point is essentially a problem statement: 'Generally lacking a quantitative measure to evaluate the generated VCEs. Evaluation is mainly performed with visual inspection.' It doesn't offer any concrete suggestions or actions that the authors can take to address this issue. It's a critique without a proposed remedy. This aligns with the '1' category, as it doesn't provide any actionable feedback to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The statement 'The generated videos have significant artifacts' is somewhat vague as it doesn't specify the type of artifacts. While the question 'Only some of the beach videos are kind of convincing' implies an issue with the visual quality, it's not explicitly stated what's wrong. The mention of 'action recognition performance is much below the current stateoftheart' is more actionable as it points to a measurable metric, but it doesn't directly suggest a concrete improvement. The lack of explicit and concrete suggestions makes it less actionable.", "grounding_specificity_rationale": "The reviewer mentions 'generated videos,' 'action recognition performance,' and 'UCF dataset.' While they don't explicitly name a specific section or table, the context strongly implies they are referring to the results and analysis related to the action recognition task on the UCF dataset. This can be considered weakly grounded as the authors can infer the relevant part. The mention of 'deeper architectures' and 'optic flow' also hints at specific techniques, adding some specificity.", "verifiability_rationale": "The reviewer makes a claim by stating 'The generated videos have significant artifacts' and 'The action recognition performance is much below the current stateoftheart.' They also provide reasoning by suggesting 'Questions: action recognition performance is below SOTA, deeper architectures, optic flow'. While they don't provide specific examples or citations, they are referencing common knowledge in the field. This makes the claim 3 as it's based on logical reasoning and common practices.", "helpfulness_rationale": "The reviewer identifies a clear weakness in the generated videos ('significant artifacts') and suggests a direction for improvement ('action recognition performance'). The question about 'convincing' beach videos further encourages the authors to focus on visual quality. While the specific type of artifacts isn't mentioned, the reviewer provides a concrete area for the authors to focus their efforts. The suggestion to use 'deeper architectures' and 'optic flow' for improvement is also helpful. The reviewer's point is directly actionable and encourages the authors to address the visual quality."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a potential limitation of the proposed method but does not explicitly state an action or provide concrete guidance on how to address it. It's more of a headsup than a direct instruction.", "grounding_specificity_rationale": "The review point explicitly mentions 'the proposed method' and the specific issue related to 'new languages' and 'limited model capacity,' providing clear grounding.", "verifiability_rationale": "The review point presents a potential limitation without providing any evidence or justification. It's a statement of possibility rather than a claim supported by reasoning or references.", "helpfulness_rationale": "The review point raises a concern about the proposed method but does not offer any actionable feedback or solutions. It's a negative comment without a clear path forward."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation in the experimental setup (single game, single baseline) but doesn't explicitly state how the authors should address it. While the implication is that this limitation hinders interpretation, the specific steps to resolve it are not provided. Therefore, it's 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 7.2' and refers to the 'Atari game results,' clearly identifying the specific part of the paper being discussed. They also specify 'a single game' and 'a single baseline,' adding detail to the identified section. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer states that the 'Atari game result (Section 7.2) is limited to a single game and a single baseline. It is very hard to interpret this.' This statement expresses an opinion or judgment about the interpretability of the results based on the limited experimental setup. However, the reviewer does not provide any external references or logical reasoning to support this claim. Therefore, it is 1.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the experimental setup (single game, single baseline) which could hinder the interpretation of the results. While the reviewer points out a valid limitation, they do not provide specific suggestions or actions for the authors to take to address this issue. The feedback is clear about the problem but lacks actionable steps for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'In Figure 1, the reported perplexities are over 30.' This directly points to a specific metric and its value within the paper. The reviewer also asks a question ('How did you calculate perplexity?') which implies a lack of clarity or potential error in the reported value. This explicit identification of a metric and its value makes the comment actionable. The reviewer clearly indicates what needs to be investigated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 1' and the metric 'perplexities.' This clearly identifies the specific part of the paper being referred to. While the reviewer doesn't specify *which* perplexity value in Figure 1 is over 30, the focus on the metric itself indicates a clear grounding. The grounding is weak in the sense that it points to a general issue with the metric rather than a specific instance, but it is still grounded.", "verifiability_rationale": "The reviewer states 'This high perplexity contradicts better BLEU scores in my experience.' This constitutes a claim or observation about the relationship between perplexity and BLEU scores. However, the reviewer does not provide any evidence, reasoning, or external references to support this claim. The comment simply presents a contradiction without explaining why or providing context. Therefore, the claim is 1.", "helpfulness_rationale": "The reviewer's point is clear and directly identifies a potential issue with the reported perplexity metric in Figure 1. By pointing out the high value and its apparent contradiction with BLEU scores, the reviewer highlights a specific area that needs investigation for the authors. While the reviewer doesn't offer a solution, the identification of the problem is a valuable piece of feedback. The comment is direct and targets a specific metric, making it 3 in highlighting a potential flaw."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question about a specific change (larger word embedding and LSTM parameters). This constitutes an explicit action. The reviewer directly asks what happens when the model uses larger parameters, which is a clear and actionable suggestion for the authors to investigate.", "grounding_specificity_rationale": "The reviewer directly references the authors' claim about significantly fewer parameters and smaller word embedding size and LSTM size. This is a clear identification of the specific part of the paper being addressed. The reviewer then asks a specific question about the impact of *larger* parameters, indicating a clear understanding of the section and a specific issue within it.", "verifiability_rationale": "While the reviewer does not explicitly state a claim, the question directly challenges the authors' implicit assumption that their smaller parameter settings are optimal. The reviewer is asking for evidence to support or refute this assumption, which can be considered a form of implicit claim requiring justification. The question itself provides the justification by asking for results with larger parameters.", "helpfulness_rationale": "The reviewer's question directly targets a key aspect of the authors' methodology and claims, seeking clarification and evidence. The question is specific and directly relevant to the authors' work, making it a valuable piece of feedback. It encourages the authors to provide more comprehensive information and to justify their parameter choices."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point states that 'Performance differences between methods are minimal' and offers a potential explanation 'less than 1 percentage point'. While this identifies a difference, it doesn't explicitly recommend a specific action or provide concrete guidance on how to address this minimal difference. The suggestion to 'reconsider the benchmarks' is implicit rather than explicit and actionable.", "grounding_specificity_rationale": "The review point refers to 'methods' and 'benchmarks' generally, without specifying which particular method or benchmark is being discussed. The reviewer states that the benchmarks are 'outdated' and 'likely saturated', but these statements are general and do not pinpoint a specific section, table, figure, or unique aspect of the paper. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point makes a claim that 'performance differences between methods are minimal' and offers a potential explanation 'less than 1 percentage point'. This constitutes a claim. However, the reviewer does not provide specific evidence or references to support this claim. The suggestion to 'reconsider the benchmarks' is a potential justification but lacks concrete examples or external references to back it up. The verifiability is limited because the reasoning and common knowledge provided are not sufficiently robust or supported.", "helpfulness_rationale": "The review point offers a potential explanation for the minimal performance differences ('less than 1 percentage point') and suggests considering 'outdated benchmarks'. This provides some guidance for the authors. It highlights a potential issue and offers a direction for further investigation, even if it doesn't provide a definitive solution. The feedback is not entirely absent but lacks the depth of a fully comprehensive critique."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is pointing out a lack of detail in the paper regarding a specific methodological aspect. They are asking for clarification on how the paper handles uncertainty in label distribution. While the reviewer identifies a missing element (more details), they are not explicitly stating that they need to perform a specific action. The request is more about understanding the existing method better. Therefore, it is not fully actionable as it doesn't directly instruct the authors on what to do. The reviewer is implicitly suggesting that the authors should provide more information about how the implicit distribution characterizes uncertainty and how the model mitigates this uncertainty.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly pointing to a specific section, table, or figure in the paper. They are referring to a general concept ('more details about the proposed method') and asking about a specific aspect of it ('how the implicit distribution characterize the uncertainty of each label value and how the model mitigrate the uncertainty of the label distribution'). While the reviewer identifies a specific area of the method that needs clarification, they are not providing a precise reference to the relevant part of the paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer is making a request for more information rather than stating a claim that needs verification. They are asking the authors to provide details about how the implicit distribution characterizes uncertainty and how the model handles it. Since there is no existing information to verify against, the comment does not contain a claim that requires justification or evidence. Therefore, it is 1 as it is not making a statement that needs to be supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer's comment is relevant to the paper's content as it points out a lack of detail regarding a specific methodological aspect. They are asking the authors to provide more information about how the implicit distribution characterizes uncertainty and how the model mitigates this uncertainty. While the comment itself doesn't offer a direct solution, it identifies a specific area where the authors could improve their work by providing more clarity and detail. Therefore, it is 3 as it highlights a relevant gap in the current information."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the Gaussian assumption for p(y | Hf(tn)) is crucial *before* the ELBOs are assumed. They point out that while this is assumed later, it's a necessary condition for the Kalman Filter/Smoothing and CVI methods to be applicable. This is a direct and actionable suggestion for the authors.", "grounding_specificity_rationale": "The reviewer specifies that the Gaussian assumption is important *before* the ELBOs are assumed. This provides a clear and specific location where this assumption is critical, demonstrating strong grounding.", "verifiability_rationale": "The reviewer provides a clear reason for why the Gaussian assumption is important: it is a prerequisite for the Kalman Filter/Smoothing and CVI methods to function correctly. This logical reasoning makes the claim verifiable.", "helpfulness_rationale": "The reviewer highlights a fundamental requirement for the Kalman Filter/Smoothing and CVI methods to work. By pointing out that p(y | Hf(tn)) must be Gaussian *before* the ELBOs are derived, the reviewer provides essential information that is directly helpful for the authors to understand and implement the methods. This information is crucial for the validity of the approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper does not clarify the use of unsupervised random forests in the title, abstract, introduction, and discussion. They identify the specific sections where this information is missing and suggest adding a clarification. This is an explicit statement of what needs to be added, making it actionable.", "grounding_specificity_rationale": "The reviewer points to the title, abstract, introduction, and discussion as the specific sections where the use of unsupervised random forests is missing. They also explain why this information is important (correct interpretation of results) and what is missing (explanation of the method). This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim that the results are for unsupervised random forests. They provide a logical reason for this claim's importance (casual readers would remember the wrong conclusions) and suggest a solution (fix it for publication). While they do not provide external references, the reasoning is clear and the suggestion is concrete, making it 4.", "helpfulness_rationale": "The reviewer highlights a critical omission regarding the use of unsupervised random forests in the initial sections of the paper. This omission directly impacts the correct interpretation of the results. The reviewer's suggestions for improvement (adding a clarification) are actionable and directly address the identified weakness."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states what they believe should be in the paper: 'a)It is better to provide some illustrative experimental results to demonstrate that minimising HSICcondi could indeed perform better than minimising HSIC_HOOD. Possibly, one toy dataset can be used to demonstrate the separability of inlier features and outlier features. b)The authors propose a new test metric, however, lacking the correctness test and comparative experiments with other metrices. It may be better to provide some visualization results or schematic diagram, which could make readers easier to understand.' This clearly indicates the reviewer has identified specific, actionable improvements they believe are missing or could be improved upon. The reviewer is not merely pointing out a weakness but suggesting concrete ways to address it.", "grounding_specificity_rationale": "The reviewer's suggestions, while relevant, lack specific grounding. For example, they suggest 'some illustrative experimental results' but don't specify which toy dataset or how the separability should be demonstrated. Similarly, they suggest a 'new test metric' and 'visualization results or schematic diagram' without providing details. The reviewer is indicating a need for more concrete examples and explanations, but the current suggestions are general and could apply to multiple scenarios, making it difficult to pinpoint the exact area needing improvement.", "verifiability_rationale": "The reviewer's suggestions are presented as improvements or additions to the paper. They are not claiming that existing elements are 1 or incorrect. The suggestions are actionable, but the reviewer doesn't provide any evidence within the review point itself to suggest that these improvements are already present or partially implemented. Therefore, the lack of specific evidence makes it 2.", "helpfulness_rationale": "The reviewer's suggestions directly address potential weaknesses in the paper, such as the lack of qualitative experiments and the need for a clearer understanding of the proposed method. The suggestions are relevant and could significantly improve the paper's clarity and impact. However, the lack of specificity in the suggestions makes them less immediately helpful. The reviewer is pointing out concrete areas for improvement, making them 3, but the generality of the suggestions means they require further elaboration from the authors to be fully utilized."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about computational complexity and requests a comparison. This is an explicit request for information. However, the request is vague and does not specify which other methods to compare with, making it only partially actionable.", "grounding_specificity_rationale": "The review point refers to 'other methods' in the context of computational complexity. While the reviewer is implicitly referring to methods mentioned in the paper, the connection is not explicitly stated. The reviewer does not pinpoint a specific section or table where these methods are discussed. Therefore, the grounding is weak.", "verifiability_rationale": "The review point contains a claim: 'Is it true that the proposed method requires much more computation than other methods?'. The reviewer then requests a comparison of computational complexity. This request, while not a definitive statement, provides a direction for verification. The reviewer is asking for evidence to support or refute their belief. Therefore, it is 3.", "helpfulness_rationale": "The review point asks a question about computational complexity and requests a comparison. While this points to a potential inefficiency or area for improvement, it does not directly provide actionable steps or suggestions for the authors on how to address this. It is a diagnostic question rather than a prescriptive one. Therefore, it is 2 in terms of directly guiding the authors to improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a lack of clarity regarding how node importance is used in a 1shot scenario and points out a discrepancy between the paper's lack of 1shot experiments and the existence of 1shot settings in related works. While the reviewer doesn't explicitly state what should be done, they highlight a missing piece of information and a potential inconsistency. The action is implicit \u2013 the reviewer knows there should be a 1shot setting and that related works use it, but the paper doesn't explain it or address the absence of such an experiment. The level of detail is low, making it somewhat vague on how to apply the identified action.", "grounding_specificity_rationale": "The review point refers to 'node importance among nodes with same label in support set' and '1shot paper setting'. The reviewer is specifically asking about a methodological detail within a defined part of the paper. While the paper doesn't explicitly mention these terms, the concepts are related to the overall methodology. The reviewer can infer the relevance of these aspects to the paper's content.", "verifiability_rationale": "The review point makes a claim about the lack of clarity regarding node importance in 1shot and the absence of a 1shot experiment, even though related works have them. The reviewer doesn't provide specific evidence or references to support this claim within the paper. The claim is based on an observation of the paper's content and a comparison to related works. The support for this claim is the absence of the information the reviewer seeks.", "helpfulness_rationale": "The review point is valuable in identifying a potential area for improvement in the paper's presentation by highlighting the lack of clarity regarding node importance in 1shot and the inconsistency with related works. While it doesn't directly suggest a methodological change to the authors' draft, it prompts them to consider the 1shot setting and the implementation of node importance. The feedback is indirect but points to a potential issue with the paper's clarity and completeness."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the need for 'more discussions' regarding a specific issue (why LLMs struggle with finegrained hard constraints) and a solution (addressing these problems). This directly points to concrete actions the authors should take. The reviewer is not just pointing out a weakness but suggesting a specific improvement strategy. The action is explicitly stated, and the concrete nature of the suggestion (discussions on specific aspects and potential solutions) makes it actionable.", "grounding_specificity_rationale": "The review point does not explicitly name a specific section, table, or figure in the paper. It is a general suggestion for the entire paper. However, it implies a focus on the area related to LLM limitations and constraints. This can be considered weak grounding as the authors can infer the need for discussion based on the identified problem. The specificity of the suggestion (why and how to address the problem) is present, but the lack of a direct reference point makes the grounding somewhat weak.", "verifiability_rationale": "The review point does not contain a claim in the sense of stating an opinion or judgment. It is a suggestion for improvement. While it implies a potential area for improvement in the paper, there is no logical reasoning, common knowledge, or external references provided to support this suggestion. Therefore, it does not meet the criteria for verifiability. The suggestion is a potential action, but without concrete examples or justifications, it cannot be considered verifiable.", "helpfulness_rationale": "The review point directly addresses a potential area for improvement in the paper (LLM limitations with finegrained constraints) and suggests a concrete action (more discussions and addressing the problems). This is a clear and actionable feedback for the authors. The suggestion is directly related to the identified weakness and provides a direction for improvement. While it could be more specific, it is still a helpful suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests two concrete actions that the authors should take to improve their draft. The first part directly addresses the relationship between the Independent Parameter (IP) and the terms/equations, indicating a clear and actionable improvement. The second part directly suggests a labeling improvement for subfigures, which is a specific and actionable change. Both suggestions are direct and do not require the authors to infer what needs to be done.", "grounding_specificity_rationale": "For the first part of the review point, 'The link between IP and the terms/equations could be explained more explicitly and prominently,' the grounding is weak. While the reviewer implies a connection exists, they do not specify which section, table, or unique aspect of the paper this link is intended to address. The reviewer mentions 'terms/equations' generally, without pointing to a specific location. For the second part, 'Pls include labels for subfigures in Figs 3 and 4, and not just state in the captions,' the grounding is also weak. The reviewer does not explicitly state which subfigures need labeling. They simply state 'include labels for subfigures'.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is offering advice on how to improve the paper, not stating an opinion or judgment about the paper that needs to be supported by evidence.", "helpfulness_rationale": "The review point is 5 because it directly addresses potential weaknesses in the draft. The first suggestion, to explain the link between the IP and the terms/equations, is a clear indication of an area where the authors can improve their clarity and understanding. The second suggestion, to include labels for subfigures, is a specific and actionable improvement that would enhance the readability and presentation of the figures. Both suggestions are directly addressing potential issues and offer clear actions for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem (hidden observations/conclusions) but does not provide explicit or concrete actions for improvement. It points out a lack of clarity rather than offering a specific path to resolution. Therefore, it lacks explicit and actionable instructions for the authors to follow.", "grounding_specificity_rationale": "The comment explicitly mentions 'the experimental section,' which is a clear and specific reference to a part of the paper. This indicates that the authors can accurately pinpoint the section being addressed.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a statement of a potential issue rather than an assertion that needs supporting evidence. Therefore, it does not fall under the verifiability scale and is classified as 'X'.", "helpfulness_rationale": "The comment identifies a potential area for improvement (lack of clarity about experimental results) and suggests that highlighting these observations could be beneficial for understanding tradeoffs. While it doesn't provide a complete solution, it points to a specific area for the authors to focus and potentially improve. Therefore, it offers some guidance and is 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'it would be better to provide some ablation experiments of these tricks' which clearly identifies an action the authors should take. The 'these tricks' refers to the 'tricks mentioned in Section 3.4', making the action quite concrete.", "grounding_specificity_rationale": "The comment refers to 'the tricks mentioned in Section 3.4', which implies the reviewer has identified specific techniques in that section. While the exact tricks aren't named, the reference to a specific section grounds the comment. However, the suggestion to 'provide some ablation experiments' is a general direction rather than a precise specification of what needs to be done with those tricks.", "verifiability_rationale": "The comment does not contain a claim that can be verified. It is a suggestion for future experiments, not a statement of what is currently lacking or a claim that needs justification.", "helpfulness_rationale": "The comment provides a suggestion for improving the model by conducting ablation studies. This is a relevant and actionable piece of feedback that could help the authors understand the impact of the tricks mentioned in Section 3.4. While it doesn't provide a definitive solution, it points in a useful direction for further experimentation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their intention to ask a question about the performance of their approach on multiclass datasets. This constitutes an explicit action. However, the action itself is vague. The reviewer does not specify how they expect to get the comparison data or where to find it. Therefore, while the action is explicit, the lack of detail makes it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions specific terms like \"KDE,\" \"binary classifier space,\" \"decision space,\" and even provides a citation 44 to support their point about Zhang et. al.'s approach. This demonstrates strong grounding specificity. The reviewer is not just mentioning a general issue but is pinpointing the specific context and referencing a relevant piece of information.", "verifiability_rationale": "The core of the review point is a question: \"I wonder whether it is possible to show the comparison of the performance on datasets that the decision space is beyond binary?\" This is a request for information, not a claim that needs to be verified. There is no assertion of truth or falsity in the question itself. Therefore, it lacks verifiability.", "helpfulness_rationale": "The reviewer is asking a question that could potentially be helpful for the authors who are using KDE and are concerned about its performance in multiclass scenarios. The question is relevant to the aspect of the method and its applicability. However, the review point itself does not offer a solution or provide any information to answer the question. It simply poses a request for more data or clarification. Therefore, while the question is relevant, the review point as presented is not directly helpful in improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out a gap in the justification for the approximations made in the paper. While they identify the potential vulnerability in lines 107110, they don't explicitly state what the authors should do to address this. The reviewer is implicitly suggesting a need for *further analysis* of the approximations, which is a vague action. They haven't provided concrete steps or specific areas within the approximations that need improvement.", "grounding_specificity_rationale": "The reviewer identifies a lack of clear identification of the approximations as areas for improvement. They are pointing out that the paper doesn't explicitly state which approximations are problematic or *why* they are problematic. The reviewer is not providing a specific section or table number to ground their critique, and they are not detailing the specific issues with the approximations. The grounding is weak because the reviewer is not pointing to a specific part of the paper and explaining *what* is wrong with it.", "verifiability_rationale": "The reviewer expresses a concern that the reasoning behind the approximations is not sufficiently supported. They believe the justification for the assumptions in lines 107110 might be a potential vulnerability. They are questioning the *verifiability* of that specific part of the reasoning. The reviewer is not providing external references or logical reasoning to support their claim about the approximations. The claim is that the possible vulnerability exists, but the justification for this claim is lacking.", "helpfulness_rationale": "The reviewer is not directly suggesting an action or critique for the authors. They are criticizing the *reasoning* behind the approximations. They are questioning *why* these approximations were made and whether they are a real concern. The reviewer is not providing a direct suggestion or critique of the authors' work. They are criticizing the justification of the authors' choices."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly asks a question: 'How does the proposed method avoid impeding the learning of new task knowledge?' This constitutes an explicit action or suggestion, as the reviewer is directly addressing a potential issue with the proposed method. However, the action is vague, as it doesn't provide specific details on how the proposed method achieves this avoidance. The reviewer is asking a general question rather than providing a concrete action or recommendation.", "grounding_specificity_rationale": "The review point mentions 'parameter isolation methods' and 'sparsity exhibited by activation channels in deep networks' in a general context. While it identifies the broad area of concern, it doesn't pinpoint a specific section, table, figure, or unique aspect of a method within the paper. The grounding is weak because the reviewer is broadly addressing issues without clearly linking the critique to a specific element of the paper.", "verifiability_rationale": "The review point poses a question: 'How does the proposed method avoid impeding the learning of new task knowledge?' This can be interpreted as a claim that current parameter isolation methods *do* hinder the learning of new task knowledge. However, the review point does not provide any logical reasoning, common knowledge, or external references to support this claim. The reviewer is asking a question as a point of inquiry, not presenting an assertion that requires verification.", "helpfulness_rationale": "The review point is a question posed to better understand the limitations of existing methods and how the proposed method addresses them. While this is a valuable point of inquiry, it does not directly offer actionable feedback or suggestions to the authors regarding their specific method. The reviewer is asking a question, which is a form of inquiry, but it doesn't provide concrete guidance or solutions."}
{"actionability_label": "3.5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the need for comparisons with existing fairness algorithms and explains the potential benefits. However, it lacks specific details on how these comparisons should be conducted.", "grounding_specificity_rationale": "The review point refers to 'existing fairness algorithms' generally, without specifying a particular section, table, figure, or unique element in the paper. The reviewer implies the need for comparisons but doesn't point to a specific location or detail the comparison method.", "verifiability_rationale": "The review point contains a claim about the benefits of the suggested comparisons. However, it doesn't provide specific evidence or reasoning *within the review point itself* to support why these comparisons would be beneficial or how they would be implemented. The reasoning is generally accepted knowledge in the field.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper (lack of benchmark comparisons) and offers a direct and actionable suggestion to address this weakness. The reviewer clearly states the need and the proposed solution, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment implicitly suggests adding a discussion of iteration cost. While it points to a missing element, the specific action of 'discussing iteration cost' is not explicitly stated, making it somewhat vague. Therefore, the comment is 3 but lacks explicitness in the action itself.", "grounding_specificity_rationale": "The comment explicitly mentions 'the proposed method' and 'related methods including baseline methods'. This clearly identifies the specific parts of the paper being addressed, indicating full grounding. The specificity is high as the reviewer is pointing to very concrete elements of the work.", "verifiability_rationale": "The comment is a suggestion to include information about iteration cost, not a claim that requires verification. It's a recommendation rather than a statement that needs supporting evidence. Therefore, it doesn't have verifiable elements in the sense of providing evidence for a claim.", "helpfulness_rationale": "The comment identifies a valid gap in the discussion \u2013 the lack of iteration cost analysis. It suggests adding this analysis, which is a relevant and actionable suggestion. However, it doesn't provide specific guidance on *how* to analyze the iteration cost or *why* it's important. The weakness is present, and the suggestion is relevant, but it lacks specific guidance, making it 3 but not fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the limitation: 'The new proposed model can be used only with a small number of dimensions because of the curse of dimensionality imposed by the core tensor C.' This is an explicit action stating a constraint. Furthermore, the reason for this constraint, the 'curse of dimensionality imposed by the core tensor C', is also explicitly stated, making the action concrete.", "grounding_specificity_rationale": "The review point explicitly mentions 'the core tensor C' as the specific part of the model being discussed. This is a literal mention of a specific component, indicating full grounding. Additionally, the comment explains the limitation in relation to this specific component, detailing what is problematic about it.", "verifiability_rationale": "The review point contains a claim: 'The new proposed model can be used only with a small number of dimensions.' This claim is supported by the reasoning: 'because of the curse of dimensionality imposed by the core tensor C.' The curse of dimensionality is a wellknown concept in machine learning, making this claim verifiable.", "helpfulness_rationale": "The review point is helpful because it clearly identifies a limitation of the proposed model, which is a crucial piece of information for the authors. The explanation of the limitation, 'because of the curse of dimensionality imposed by the core tensor C', provides context and helps the authors understand why this limitation exists. While it doesn't suggest alternative solutions, it directly addresses a potential weakness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests a specific alternative name ('distributional convergence') for the phenomenon described, indicating a clear and actionable suggestion. While the reviewer also critiques the name itself, the suggestion to use 'distributional convergence' is a concrete action the authors could take.", "grounding_specificity_rationale": "The reviewer critiques the name 'distributional generalization' but does not specify which part of the paper or discussion this criticism refers to. There is no mention of a specific section, table, figure, or unique aspect of the paper. The reference is vague.", "verifiability_rationale": "The reviewer makes a claim that the name 'distributional generalization' is 'strong' and that the phenomenon is based on 'a few test functions on which the outputs match.' While the reviewer attempts to support their claim about the limited evidence, the evidence provided is weak and speculative. The claim is not fully justified by concrete examples or references.", "helpfulness_rationale": "The reviewer's point is generally helpful as suggesting a more accurate or less overstated name is beneficial for clarity. However, the lack of strong evidence to support their critique of the name and the general nature of their critique make the overall helpfulness somewhat limited. The suggestion is present, but the lack of strong backing reduces its overall impact."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point criticizes the 'theoretical contribution' and identifies a 'weak, unpractical bound' in the 'proof'. While it points to a general area and a general issue, it doesn't explicitly state what specific action the authors should take to improve the contribution or address the bound. The criticism is about the *outcome* rather than a direct instruction on *how* to achieve it.", "grounding_specificity_rationale": "The review mentions 'theoretical contribution' and 'proof' as the areas being criticized. While it pinpoints these areas, it doesn't specify a particular section, table, figure, or unique element within the paper that is affected. The criticism is about the general areas rather than a specific part. The issue identified is 'a weak, unpractical bound', which is a general characterization of the proof rather than a specific detail within it.", "verifiability_rationale": "The review point contains a claim: 'I still find the theoretical contribution ok but not particularly strong, given existing results. As mentioned in the review, it is a weak, unpractical bound, and the proof, in itself, does not provide particular mathematical novelty.' However, it does not provide any specific evidence, examples, or references to support this claim. The statement is presented as an observation rather than a claim that requires verification.", "helpfulness_rationale": "The review point highlights a potential weakness in the paper's contribution and raises concerns about the 'weak, unpractical bound' in the proof. This sets expectations for the authors regarding the quality of their contribution and the rigor of their methodology. While it doesn't offer concrete solutions, it points out a specific area that needs attention, making it a helpful piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer's point is not explicitly actionable. While they identify a potential issue with the placement of adaptive convolutions based on the experimental results in Table3, the original paper should have addressed this. The reviewer does not provide specific steps or modifications that the authors should implement. The suggestion is more of a comment on a missing analysis rather than a direct action item.", "grounding_specificity_rationale": "The reviewer's point is 1 in specific parts of the paper. They refer to 'adaptive convolutions' generally and do not identify a specific section, table, or unique aspect of the technique. While they later mention 'the last layer' in their analysis, the initial point is about the general placement. The specificity of the feedback is lacking, making it difficult for the authors to pinpoint the issue.", "verifiability_rationale": "The reviewer makes a claim that 'it seems that replacing normal convolutions with adaptive convolutions in not always a good' and 'the placement of adaptive convolutions is important, but there is no analysis or comments on this aspect of the technique.' This claim is verifiable because the reviewer provides the experimental result from Table3 (ACNNv3 performed worse than ACNNv2) as evidence. The reasoning is clear and directly supports their claim.", "helpfulness_rationale": "The reviewer's point is 3. They identify a potential issue with the placement of adaptive convolutions based on the experimental results. This suggests a direction for further investigation and improvement. While it doesn't directly tell the authors what to change, it provides a valuable insight that can guide the authors towards a more thorough analysis of their technique. The feedback is relevant to the observed experimental outcome."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'should be supplemented,\" indicating a direct action to provide more information. While it doesn't specify the exact nature of the supplementation, the action is clear and concrete.", "grounding_specificity_rationale": "The comment clearly refers to the \"result comparison\" of the two search methods, specifically mentioning \"model structure.\" This precise identification of the part of the paper being addressed demonstrates strong grounding specificity.", "verifiability_rationale": "The comment itself does not contain a claim that requires verification. It's a request for more information. Therefore, it doesn't fit into the categories of 'X' (X) or the verifiable categories. However, the implied need is to understand the results of the comparison to 'supplement' it, suggesting a potential lack of specific justification for needing more information.", "helpfulness_rationale": "The comment identifies a relevant aspect of the work (the comparison of search methods) and points out a potential improvement (providing more details). While it doesn't specify *what* kind of additional information is needed, it clearly indicates a gap in the current information. This suggests a helpful but not fully comprehensive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states that the axes of Figure 1 are unclear. This directly points out a specific action the authors should take: to understand or clarify the meaning of the axes.", "grounding_specificity_rationale": "The comment directly refers to 'Figure 1' and explicitly states that the axes are unclear. This clearly identifies the specific part of the paper and the issue within it.", "verifiability_rationale": "While the comment itself doesn't contain a claim in the sense of a definitive statement, it implies a need to understand the figure, which can be considered a form of guidance. The lack of clarity about the axes is a logical consequence of examining the figure.", "helpfulness_rationale": "The comment directly points out a specific area of confusion related to a figure. This is immediately actionable for the authors and directly addresses a practical issue they might be facing when trying to understand their own paper's visual elements."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that '2 Direct runtime comparisons with existing methods are missing' and suggests a reason for this absence ('The proposed approach is based on implicit differentiation which usually requires additional computational costs.'). This clearly indicates an actionable item for the authors. The authors are directly informed that they should perform these comparisons. The point is explicit and concrete, specifying the number of comparisons and the type of comparison required. The reason provided, while general, still points to a clear action for the authors to take.", "grounding_specificity_rationale": "The review point refers to 'direct runtime comparisons' and 'existing methods' without specifying which particular methods are relevant. While the reviewer mentions 'implicit differentiation' as a reason, this is a general concept and doesn't directly reference the authors' specific implementation or algorithms. The reviewer's statement is about the *type* of comparison (direct runtime) and the *general* nature of the missing comparisons. There's no specific section, table, figure, or unique element being directly referenced. The grounding is at a higher level, referring to a category of comparisons rather than a specific instance within the paper.", "verifiability_rationale": "The review point clearly states a claim: 'Direct runtime comparisons with existing methods are missing.' This is a declarative statement indicating a deficiency. The reviewer then provides a justification for this claim: 'The proposed approach is based on implicit differentiation which usually requires additional computational costs.' This justification, while likely true in general, doesn't offer specific examples of existing methods that would be suitable for comparison or cite specific literature demonstrating this computational overhead in the context of the authors' work. The explanation is somewhat general and lacks specific references or citations to directly support the claim within the authors' specific context. The reviewer is explaining *why* the comparisons are missing, not providing a direct, verifiable fact about the comparisons themselves.", "helpfulness_rationale": "The review point identifies a significant weakness: the absence of direct runtime comparisons. It is 5 because it explicitly tells the authors what to do: perform two direct runtime comparisons with existing methods. The reviewer also provides a reason for this absence, which further guides the authors in their investigation. Runtime comparisons are a crucial piece of feedback for authors as they directly impact the practical applicability and efficiency of the proposed method. This information is valuable and directly addresses a practical concern for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states, 'I cannot see any technical contribution.' This is an explicit statement about what the authors should do. However, the reviewer does not specify *how* they believe the authors can improve their draft. The suggestion to 'improve their draft' is vague and lacks concrete steps.", "grounding_specificity_rationale": "The reviewer mentions 'metalearning' and 'federated learning' when describing the framework. This grounds the comment somewhat by identifying the specific areas of machine learning involved. However, the reviewer does not specify *what* the technical contribution is within these areas. The statement 'I cannot see any technical contribution' is general and does not pinpoint a specific weakness or improvement.", "verifiability_rationale": "The reviewer makes a statement of opinion: 'I cannot see any technical contribution.' This statement does not contain a claim that requires verification or evidence. It is a judgment about the work.", "helpfulness_rationale": "The reviewer points out a perceived weakness in the framework ('the proposed framework is a simple combination of metalearning and federated learning') and suggests that the authors cannot identify any technical contribution. While the reviewer identifies a weakness and suggests an action ('improve their draft'), the weakness is general and lacks specificity. The reviewer does not provide concrete suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for clarification on two specific aspects of the paper: 'the \u201cupper faces\u201d of the convex hull' and 'decision boundaries of neural networks, specifically regarding the variable 'p''. This directly points to actionable improvements the authors should make. The reviewer is not just pointing out a problem but also suggesting a direction for improvement.", "grounding_specificity_rationale": "The review point directly refers to 'the upper faces of the convex hull' and 'decision boundaries of neural networks'. It even names a specific variable, 'p', that is causing confusion. This indicates a high level of grounding specificity as the reviewer is pinpointing exact sections and details.", "verifiability_rationale": "While the review point doesn't make an explicit claim about *what* the \"upper faces\" mean or *why* 'p' is undefined, it *identifies* a lack of clarity and a missing definition. This can be considered a claim that needs verification. The reviewer's suggestions for improvement (\"The dual subdivision and projection \u03c0 need to be explained better\" and \"It would make sense to move def.\") provide some implicit justification for the identified issues.", "helpfulness_rationale": "The review point provides very specific and actionable feedback. The reviewer isn't just pointing out a problem; they're also suggesting concrete steps the authors can take to improve their understanding and the clarity of their work. The suggestions are directly tied to the identified issues."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the disentangling is done manually and provides a concrete example of the first module (the semantic segmentation network). While the reviewer doesn't explicitly state what should be learned instead, the action of identifying the manual disentanglement is clear and actionable. The reviewer suggests an alternative approach (learning everything) but doesn't provide specific details on how to implement it, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly states that the disentangling is done manually and provides a specific example of the first module (the semantic segmentation network). This allows the reader to accurately pinpoint the section being addressed, demonstrating strong grounding. However, the reviewer does not specify *why* manual disentanglement is a problem or what specific issues exist with this approach in the context of the paper. The claim is clear about what is being addressed, but the lack of explanation about the *why* makes it less specific.", "verifiability_rationale": "The reviewer makes a claim that manual disentanglement is a 'problem' and suggests an alternative approach. This constitutes a claim that needs to be supported. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion for improvement is presented without sufficient justification or evidence.", "helpfulness_rationale": "The reviewer points out a potential improvement (learning everything) but does not provide a clear explanation of why manual disentanglement is a problem in the specific context of the paper. The suggestion is relevant, but without a justification, it feels like a suggestion without a clear rationale, making it less helpful for the authors to understand the issues and how to improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of a strong connection between the theoretical analysis and the proposed method, and also points out that the proposed method is a simple adoption of selfattention from transformers. While the reviewer identifies a weakness, the criticism is somewhat vague as it doesn't pinpoint a specific action the authors should take to improve the connection or the method's effectiveness for distant nodes. The action is implied but not clearly stated.", "grounding_specificity_rationale": "The reviewer's comment focuses on the *general* idea of applying selfattention to graphs, without specifying which part of the paper this is being applied to. The comment is not explicit about a specific section or table, and it doesn't detail what is being addressed in this part. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part of the paper.", "verifiability_rationale": "The reviewer states that the proposed method 'simply adopts the idea of the selfattention mechanism from the transformer and apply it to the graph' and 'I fail to see the strong connection between the theoretical analysis and the proposed method'. While the reviewer identifies a claim, the reasoning behind this claim is not explicitly provided. The verifiability is low because the reviewer doesn't offer any logical reasoning, common knowledge, or external references to support their assessment of the method's connection to the theory.", "helpfulness_rationale": "The reviewer's comment is a clear criticism of the proposed method's connection to the theoretical analysis and its effectiveness for distant nodes. While the reviewer identifies a weakness, the feedback is somewhat vague as it doesn't provide specific suggestions or examples of how the method could be improved. The helpfulness is limited because the reviewer doesn't offer concrete guidance or evidence to support their claim."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states a limitation ('does not seem to be scalable'), which is an explicit action (identifying a problem). However, they don't specify *how* the method isn't scalable or what changes would be needed.", "grounding_specificity_rationale": "The reviewer refers to 'the method' generally, not a specific part of the paper. They don't point to a section, table, or figure. The reviewer identifies a *general* limitation (scalability) but doesn't pinpoint where the current method falls short in terms of data handling.", "verifiability_rationale": "The reviewer makes a claim: 'It's not reasonable to expect a single instance can hold all the training data...' This is a subjective statement about the practicality of the current approach. The reviewer doesn't provide any evidence or reasoning to support their claim about scalability. They state the problem without offering solutions or references.", "helpfulness_rationale": "The reviewer points out a significant limitation of the method. While they express a desire for scalability, the *review itself* doesn't offer concrete solutions or further explanation. It's a critique of a limitation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks 'Why eta_ri term is noncentral chisquared distribution?' This directly points to a lack of explanation or reasoning in the paper regarding this specific aspect. The paper states the distribution but doesn't explain the underlying logic or derivation, making the action implicit rather than explicit. The action itself (asking 'why') is concrete, but the lack of explanation makes it 1 in terms of providing guidance to the authors.", "grounding_specificity_rationale": "The reviewer directly refers to the 'eta_ri term' in their review point. This indicates that the reviewer can confidently identify the specific part of the paper being addressed. The comment is grounded because it names a specific element. However, the comment itself doesn't specify *why* this term follows a noncentral chisquared distribution. The specificity is lacking in the explanation provided.", "verifiability_rationale": "The reviewer's question is a request for justification or explanation. It doesn't present a claim that needs verification. Therefore, it doesn't fit the 'Verifiability' criteria as it's not a claim being made and supported. However, it does highlight a lack of verifiable reasoning for a methodological choice.", "helpfulness_rationale": "The reviewer's question directly addresses a potential point of confusion or a missing justification in the paper. It asks a direct question about a specific aspect of the methodology. This type of feedback is 5 and constructive for the authors, as it seeks to clarify a specific point and potentially improve their understanding or implementation of the method."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a lack of significant difference in StableDiffusion performance between the proposed method and randomized selection. However, it also mentions the lack of discussion on this observation, which is vague and doesn't provide a clear action for the authors to take. The comment also states a lack of mathematical or theoretical justification for Algorithm 1, which is a direct action pointing to a potential improvement. The first part of the comment is 3, while the second part is 5.", "grounding_specificity_rationale": "The comment explicitly refers to 'Fig.5' when discussing the performance difference. This is a clear reference to a specific part of the paper. The comment also explicitly refers to 'Algorithm 1' when discussing the lack of justification. This is a clear reference to a specific part of the paper. Both references are literal mentions, making them fully grounded.", "verifiability_rationale": "The comment states a claim about the lack of significant difference in StableDiffusion performance and the lack of mathematical or theoretical justification for Algorithm 1. For the performance difference, the comment doesn't provide any supporting evidence or justification, making it 1 based on the review point alone. For the lack of justification of Algorithm 1, the comment explicitly states the absence of such justification without providing any examples or references, making it 1 based on the review point alone. The comment itself is a claim, but it lacks supporting evidence within the review point.", "helpfulness_rationale": "The comment points out a lack of discussion regarding the StableDiffusion performance difference, which could be helpful for the authors to understand the implications of the proposed method. However, the comment also highlights the lack of mathematical or theoretical justification for Algorithm 1, which is a clear weakness and a direct suggestion for improvement. The lack of justification is a significant point that the reviewer believes the authors should address. The lack of discussion on the performance difference is also a helpful point, although it is vague. The lack of justification for Algorithm 1 is the most helpful aspect of the review point."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the lack of speed analysis and suggests an alternative metric (FLOPs comparison). The reviewer directly points out what is missing and what they believe is a more relevant comparison. This is a clear and actionable suggestion for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'inference speed' and 'prior work' in the context of the proposed network. While they don't pinpoint a specific section, table, or figure, they clearly identify the area of the paper being discussed (performance comparison) and the type of comparison being suggested (inference speed vs. FLOPs). This indicates a degree of grounding, though not complete specificity.", "verifiability_rationale": "The review point states a preference for an alternative metric (FLOPs comparison) over the existing one (inference speed comparison) without providing any justification or evidence for why the lack of the former is a problem. The statement is purely based on opinion or judgment.", "helpfulness_rationale": "The review point identifies a valid limitation in the experimental evaluation (lack of inference speed comparison) and suggests a potentially more insightful metric (FLOPs comparison). While it points out a gap, it doesn't explain *why* this gap is significant for the specific work being reviewed or provide concrete steps on how to address it. The suggestion is good but lacks actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the need for comparison to contrastive decoding methods and highlights potential notational issues. This points to specific areas for improvement. However, the exact nature of the comparison and the specific notational issues are not detailed in this review point, making it somewhat vague in terms of actionable steps.", "grounding_specificity_rationale": "The reviewer mentions 'existing methods, such as contrastive decoding' and 'notations issues.' While they categorize the issues, they don't pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. The reference to 'notations issues' is also general and lacks specificity.", "verifiability_rationale": "The reviewer makes a claim that the paper should compare against existing methods and address notational issues. However, they do not provide any logical reasoning, common knowledge, or external references to support this claim within this specific review point. The suggestions are presented as recommendations rather than verifiable statements.", "helpfulness_rationale": "The reviewer identifies a valid concern regarding the lack of comparative evaluation and potential notational issues. This is a constructive point that could guide the authors. However, the lack of specific details or references makes it difficult for the authors to understand the exact nature of the comparison or the notational problems, thus limiting its helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation of the algorithm: 'The effectiveness and problem of the algorithm are that it requires access to the entire training dataset.' While this identifies a problem, it doesn't explicitly state how the algorithm *should* operate without the full dataset or suggest any concrete modifications to achieve this. The reviewer's suggestion, 'Have the authors considered how the algorithm should operate effectively when the training dataset is not fully perceptible?', is a question posed rather than a direct action or solution. Therefore, while the issue is actionable, the reviewer doesn't provide a clear path forward, making it 3 but lacking detail.", "grounding_specificity_rationale": "The reviewer states, 'The algorithm requires access to the entire training dataset.' This is a general statement about the algorithm's dependency. While it identifies a limitation, the reviewer doesn't specify *which* part of the algorithm is dependent on the full dataset. They don't point to a specific section, table, or figure, nor do they detail what aspect of the algorithm is affected. Therefore, the grounding is weak as the specific part being addressed is not clearly identified.", "verifiability_rationale": "The reviewer's concerns are about the *motivation* and *technical contribution* of the paper, not directly about a claim *within the review point itself*. The reviewer states, 'Overall: The trigger proposed in this paper is novel, but the related validation experiments are not comprehensive, and the time complexity of the computation and the efficiency of the algorithm are not clearly analyzed.' These are metacomments about the paper's content and the authors' work, not verifiable claims within the review point. The reviewer is expressing expectations about what should be included in the paper rather than stating something that can be proven true or false based on the review point alone.", "helpfulness_rationale": "The reviewer's overall assessment is negative, stating, 'I expect the authors to further elucidate the technical contribution rather than the form of the attack.' This indicates a desire for more specific and actionable feedback on the algorithm's technical aspects. While the reviewer identifies a limitation of the algorithm, they don't provide concrete suggestions for improvement or a detailed explanation of the algorithm's technical contributions. The reviewer's expectation for more technical elucidation suggests that the current feedback is not sufficiently helpful in addressing the algorithm's shortcomings from a technical perspective."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The question is very specific and asks for clarification on a potential issue related to the practical application of linear attention during inference. It directly prompts the authors to consider the efficiency of their model when the input sequence is longer than what was seen during training. This makes it 5 as it directly addresses a potential limitation of their approach.", "grounding_specificity_rationale": "The reviewer mentions 'linear attention' and 'autoregressive decoding' but does not explicitly state which part of the paper they are referring to. They are asking about the benefits of inference, which is a general question about the application of the method. Therefore, the grounding is weak as the authors cannot confidently determine which part of the paper or specific detail is being addressed.", "verifiability_rationale": "The reviewer is asking a question, not making a claim that needs to be verified. Therefore, it is not verifiable as it does not present a statement that requires justification or evidence.", "helpfulness_rationale": "The question is relevant to the practical application of a specific technique (linear attention) and highlights a potential drawback or area for improvement during inference. While it doesn't directly suggest a solution, it points to a limitation that users might encounter, making it 3 in identifying a potential issue."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a belief that the paper's handling of a debate is 'carelessly resolved' and then poses specific questions about alternative scenarios (distribution shift, disentangling experiments). While the reviewer doesn't directly demand action, they point to a potential gap in the paper's analysis and methodology. The reviewer identifies the *action* of resolving the debate but doesn't provide concrete steps on how to achieve this.", "grounding_specificity_rationale": "The reviewer is not explicitly stating that the paper is missing information or has unclear sections. Instead, they are questioning the paper's reasoning and methodology regarding a potential distribution shift. The reviewer is implicitly suggesting a potential flaw in the paper's approach but is not pinpointing a specific section or element that is lacking. The paper is not '1' in the sense of having an unclear section, but the reviewer's questions highlight a potential area for improvement in the paper's analysis.", "verifiability_rationale": "The reviewer directly challenges the paper's claim that the debate was 'carelessly resolved' by asking why the distribution couldn't have changed and requesting experiments to disentangle distribution shifts from the removal of information. The reviewer is questioning the *verifiability* of the paper's reasoning and methodology. The paper does not provide sufficient evidence or justification for its claim about the debate's resolution. The reviewer's questions are aimed at verifying the paper's reasoning and methodology.", "helpfulness_rationale": "The reviewer's questions and requests for clarification are directly aimed at helping the authors understand and potentially improve their draft. By asking why the distribution couldn't have changed and requesting experiments, the reviewer is trying to guide the authors towards a more thorough analysis of their data and methodology. While the reviewer doesn't explicitly recommend specific actions, their questions are highly relevant to improving the clarity and rigor of the paper. The reviewer is providing a *request for information* that is directly relevant to the authors' work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential inconsistency in the interpretation of the experimental results, specifically regarding the 'additional parameters' and the performance of the 'Unary' baseline. This is an explicit statement identifying a problem. The reviewer also poses a question about the impact of a potentially stronger baseline, which is a direct action the authors could take to investigate the issue. The request for clarification is also an explicit action to understand the results better. Therefore, the review point is actionable as it identifies a potential problem and suggests a course of action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'LinearTop,' 'NLTop,' and 'Unary,' which are specific components or models within the paper. This indicates a high level of grounding as the reviewer can identify these specific parts. However, the reviewer does not specify *what* is wrong with the 'Unary' baseline or how it performs worse than expected based on external knowledge. The specificity is limited to identifying the potential issue without explaining its cause or providing examples. Therefore, the grounding is fully grounded but not fully specific.", "verifiability_rationale": "The reviewer states a potential inconsistency in the experimental results and poses a question about the impact of a potentially stronger baseline. This constitutes a claim that there is a performance boost despite the addition of parameters. However, the reviewer does not provide any logical reasoning, examples, or references to support this claim. The statement is presented as a question for clarification rather than a verifiable observation. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer raises a relevant point about the interpretation of the experimental results and encourages the authors to doublecheck their baselines. While the point is relevant, it does not provide specific guidance on how to improve the model or address the potential issue. It is more of a question for clarification than a direct suggestion for improvement. Therefore, the review point is 3 as it highlights a potential area for further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out the need for more reading and suggests improvements. This suggests a lack of specific actionable steps. While the suggestions are stated, they are not explicit about how to achieve the improvements. For example, 'improve the structure' is a suggestion but lacks concrete steps. The reviewer doesn't specify what aspects of the structure need improvement or how to implement it.", "grounding_specificity_rationale": "The reviewer mentions 'several sections' and 'more than one reading pass,' which is vague. They specifically mention 'the IEM in Fig 3' and 'Fig 7' and 'Fig. 8' (assuming 'Fig.' is a typo and meant 'Fig.'). These are more specific references. However, the reviewer does not specify *what* is unclear about the sections or the figures. They offer general suggestions for improvement.", "verifiability_rationale": "The reviewer states a problem ('The paper is a bit hard to follow') and offers solutions ('improve the structure,' 'put more focus on the IEM in Fig 3,' 'improve the visualization of the Fig 7, and Fig. 8'). These are suggestions, not explicit claims requiring verification. The reviewer is offering recommendations rather than stating something that needs to be proven or justified.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, even if they are general. They identify areas where the paper could be clearer. While the suggestions are broad, they directly address the identified issue of difficulty in following the paper. They offer concrete directions for improvement, even if those directions are not fully detailed."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the desire for a \"more detailed discussion of related work\" and specifies the focus on \"differences to the presented work.\" This is a clear action with a defined implementation. The reviewer is not leaving ambiguity about what needs to be done.", "grounding_specificity_rationale": "The review point explicitly refers to the \"related work section\" of the paper. This is a literal mention of a specific part of the paper. The reviewer also clearly states the focus on \"differences,\" adding further specificity to the request.", "verifiability_rationale": "The review point contains a claim: \"As the available space allows it, the paper would benefit from a more detailed discussion of related work...\" This claim is supported by the implication that a more detailed related work section would \"better contextualize the presented work.\" While the reviewer doesn't provide external references or specific examples *within this review point*, the claim itself is stated and the benefit is implied.", "helpfulness_rationale": "The review point provides a clear suggestion for improvement: adding more detail to the related work section, specifically focusing on differences. This is a direct and actionable piece of feedback aimed at enhancing the paper's context and clarity. While it's a suggestion, it's quite specific and directly addresses a potential area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks for the 'final used learning rates' for the deep models, particularly for CIFAR10 and CIFAR100. This is a direct request for information that is actionable for the authors. The reviewer also mentions that the authors searched only 4 different learning rates, which raises a concern about whether the optimal learning rate for the baseline was outside the tested interval. This added detail makes the request more specific and actionable. The reviewer is essentially asking for concrete information that could potentially impact the validity of the results.", "grounding_specificity_rationale": "The reviewer explicitly states the 'final used learning rates' and the 'CIFAR10 and CIFAR100' where these rates are relevant. This provides a clear target for the information being requested, indicating that the reviewer has identified a specific part of the paper and the information needed. However, the reviewer does not explicitly state the *values* of these learning rates, nor does they provide any specific examples or details about the search process. The concern about the limited search space is implied but not explicitly stated as part of the information being sought.", "verifiability_rationale": "The reviewer is making a request for information ('I'd like to know the final used learning rates') without providing any immediate justification or claim. However, the reviewer also expresses a concern about the limited search space of 4 learning rates, suggesting that the optimal learning rate for the baseline might have been missed. This implies a potential flaw in the experimental setup that could affect the results. While the reviewer is not making a direct criticism, they are providing context and a potential issue that could be verified with the requested information. The reasoning is present in the form of the concern about the search space, but it's not a fully developed argument with clear evidence.", "helpfulness_rationale": "The reviewer's request for the 'final used learning rates' is directly relevant to understanding the experimental setup and potentially identifying a flaw in the methodology. The reviewer is providing context about the specific models and datasets (CIFAR10 and CIFAR100) where these learning rates are crucial. This information will allow the authors to assess whether the optimal learning rate for the baseline was within the explored range. The request is specific and directly addresses a potential issue with the experimental results. The reviewer is essentially providing a concrete piece of information that could significantly improve the authors' understanding and confidence in their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their disagreement with the chosen transformer model and asks a specific question about why locality bias is not a concern. This directly addresses a potential limitation of their method. The request for justification is a clear action the authors can take. The reviewer provides a specific reason (limited speed of information propagation) for their disagreement, making the action quite explicit. While not a direct instruction on how to implement a change, the request is actionable in the sense that the authors can consider the provided reasoning.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific section, table, or figure in the paper. They are commenting on the general concept of locality bias. While they mention 'transformer free of localitybias,' this is a general term and doesn't pinpoint a specific part of the paper being affected. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim about their disagreement with the chosen model. However, they do not provide any external references or logical reasoning to support their claim or explain why the chosen approach is superior. The justification is based on their understanding of the locality bias, but it lacks external validation. Therefore, the claim is not wellsupported.", "helpfulness_rationale": "The reviewer directly asks for a justification for a specific methodological choice. This is a highly relevant and actionable point for the authors. They are seeking to understand the reasoning behind a decision that impacts their work. This directly helps them evaluate and potentially adopt a different approach."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action or suggestion: 'This should be clarified.' However, it lacks specific details on *how* the output depends on the data order or what aspects of the algorithm are affected. The action is implied but not fully concrete.", "grounding_specificity_rationale": "The comment explicitly mentions 'the output from the algorithm' and 'the order in which the data are processed.' This demonstrates strong grounding as the specific part of the paper being addressed is clearly identified. However, the comment does not specify *what* aspect of the algorithm's output is being affected by the data order, nor does it detail *why* this dependency is a concern. The specificity is limited.", "verifiability_rationale": "The comment does not contain a claim in the sense of a statement requiring justification or proof. It's more of an observation or a question prompting further investigation. There is no logical reasoning, common knowledge, or external references provided to support the assertion that the output depends on the data order. Therefore, it scores as 'X'.", "helpfulness_rationale": "The comment points out a potential issue with the algorithm's output and suggests clarifying it. While it doesn't provide a complete solution, it identifies a problem area and encourages further investigation, which can be helpful for the authors trying to understand the algorithm's behavior. The helpfulness is moderate as it highlights a potential problem but doesn't offer a definitive resolution."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "Not Verifiable", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer does not explicitly state an action or suggestion based on the fact that other papers used different crossvalidation methods. They are questioning the *reason* for choosing 6fold crossvalidation, not what it entails.", "grounding_specificity_rationale": "The reviewer explicitly states the specific aspect of crossvalidation being questioned: '6fold crossvalidation is not understood' and 'why 6fold crossvalidation is required for this problem.' This clearly identifies the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer does not provide any evidence or reasoning to support their claim about why 6fold crossvalidation is required. They are stating a fact (it wasn't used in other papers) but not providing a justification for their choice.", "helpfulness_rationale": "The reviewer is not providing a clear reason or justification for their choice of 6fold crossvalidation. Without a clear rationale, the review point is not immediately helpful for the authors to understand the reasoning behind the experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential area for improvement but does not explicitly state the action the authors should take. It raises a question about the impact of heuristic components, which is a suggestion rather than a direct action.", "grounding_specificity_rationale": "The review point explicitly mentions the 'NonAmbiguous Query Generation procedure' and its reliance on a 'sophisticated filtering template,' clearly identifying a specific part of the paper.", "verifiability_rationale": "The review point suggests the authors should 'clarify the impact of these heuristic components.' This is a request for information about an existing aspect, not a claim about a flaw or missing element that requires verification.", "helpfulness_rationale": "The review point provides a clear direction for the authors to focus their analysis on the 'NonAmbiguous Query Generation procedure' and its heuristic aspects. It guides their investigation without being vague or unhelpful."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a specific missing piece of information (knowledge of CAD model correspondences) required for a certain technique (ray marching) mentioned in the paper. This implies that without this information, the proposed method might not be directly applicable or require significant modifications. While the reviewer identifies a potential limitation, the action is somewhat implicit  the reviewer is inferring that the method might not work without this information, rather than explicitly stating 'You need CAD model correspondences for ray marching.'", "grounding_specificity_rationale": "The reviewer explicitly mentions 'knowledge of CAD model correspondences' as a specific piece of information needed for the proposed method. This directly identifies a specific part of the paper (the CAD model) and highlights a specific issue related to it. The comment is quite specific about the missing element.", "verifiability_rationale": "The reviewer questions the claim in the paper regarding the possibility of training the proposed method without camera information. They argue that without knowing the viewpoint (which is related to camera information), performing ray marching (as they seem to understand it) might be impossible because the origin of the rays is unclear. The reviewer provides a logical argument based on their understanding of the technique, but they don't provide external references to support their claim about the necessity of camera information. The claim is presented without strong justification within the provided text.", "helpfulness_rationale": "The reviewer's comment is a valid critique of the paper's claim regarding the necessity of camera information. They are pointing out a potential limitation or a point of confusion for the proposed method. While they don't offer a solution, their comment is relevant to the technical details of the paper and highlights a potential area for clarification or further discussion. The feedback is constructive in identifying a potential issue."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a need for clarification regarding the lines in Figure 4. While the action of clarifying is somewhat explicit, the reviewer does not provide specific details on what needs to be clarified or how the lines should be interpreted. The lack of concrete action makes it less actionable than a point that explicitly states a change to be made.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 4' as the part of the paper that needs improvement. This clear identification of the specific figure makes the grounding fully grounded. Additionally, the reviewer points out a specific issue within the figure ('the line of No adapt or Finetune are covered by other lines'), which further enhances the specificity of the grounding.", "verifiability_rationale": "The review point contains a claim that 'in Figure 4, the line of No adapt or Finetune are covered by other lines, without additional explanation.' This claim is verifiable through observation of the figure. However, the reviewer does not provide any external references or logical reasoning to support why this lack of explanation is a significant problem. The verifiability is based on the direct observation within the paper itself, making it 3 as there is no external evidence provided.", "helpfulness_rationale": "The review point identifies a weakness in the paper (nonselfexplanatory figures) and suggests a direction for improvement (clarification). This level of identification and suggestion makes it 3. However, it lacks specific guidance on how to achieve this clarification, making it less helpful than a point that suggests a concrete change."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies the importance of the sampling method for convergence but does not explicitly instruct the authors on how to improve or change their sampling strategy. It points out a gap in the experimental evaluation of the sampling method. While the reviewer suggests comparing to uniform sampling (mentioned in supplementary material), they don't provide a concrete action for the authors to take to address this issue.", "grounding_specificity_rationale": "The review point discusses the importance of sampling and its impact on convergence but does not specify which part of the paper or experiment this refers to. It mentions 'sampling performed to obtain different initializations x_0' and 'convergence to optimum' generally, without pinpointing a specific section, table, figure, or unique aspect of the paper. The comparison to uniform sampling is in the supplementary material, not the main text.", "verifiability_rationale": "The review point makes a claim about the importance of the sampling method for convergence and points out a lack of experimental evaluation. While it suggests comparing to uniform sampling (mentioned in supplementary material), it doesn't provide specific evidence or references to support this claim within the main text. The evidence is indirect and relies on the supplementary material.", "helpfulness_rationale": "The review point raises a valid concern about the experimental setup and suggests a potential area for improvement (more experimental evaluation of the sampling method). While it doesn't provide a direct solution or specific steps for the authors to take, it highlights a potential weakness in the current work, which could be helpful for the authors to consider and potentially address in future iterations of their research. The suggestion to compare to uniform sampling, even if in the supplementary material, indicates a direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the action \"conducing experiments,\" making it somewhat explicit. However, the suggestion lacks specific details on *which* datasets or *how* the experiments should be conducted beyond \"more datasets.\"", "grounding_specificity_rationale": "The reviewer mentions \"more datasets,\" which is a specific element being referred to. However, they don't explicitly identify which part of the paper this relates to (e.g., experimental setup, results section, tables/figures).", "verifiability_rationale": "The reviewer makes claims about the need for more experiments on \"more datasets\" and \"the full dataset instead of that in the lowresource regime.\" While the *implication* is that more data would be beneficial, the *claim itself* lacks explicit justification or references.", "helpfulness_rationale": "The reviewer identifies a potential area for improvement (limited experimental validation) and suggests a concrete action (conducting more experiments). While it doesn't provide specific *how* to do this, it guides the author towards further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The reviewer states, 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' This indicates an implicit action (identifying a problem) but lacks a concrete step for the authors to take. They know *what* is unclear, but not *how* to address it. Therefore, the action is not explicitly stated or actionable.", "grounding_specificity_rationale": "The reviewer says, 'the whole dataset transformation and the ensuing experimental setup felt very cumbersome, and not very clear.' This is a general criticism of the process, not a specific reference to a part of the paper or methodology. The reviewer doesn't identify a particular section, table, figure, or unique aspect that is unclear. Therefore, the comment lacks grounding.", "verifiability_rationale": "The reviewer states, 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' This statement itself is not a claim that requires verification. It's a statement of lack of understanding. There are no opinions, judgments, or suggestions being made. Therefore, there is X to be verified.", "helpfulness_rationale": "The reviewer explicitly states, 'it was not clear how the generic argument task and the random argument task proved what the authors claimed.' This directly indicates a lack of actionable feedback for the authors. They are left without a clear path to improve their draft based on this comment. Therefore, the feedback is 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point is a question, not a directive or statement containing explicit actions. It asks about the model's ability to handle tabular data, but doesn't provide any specific actions or guidance on how to do so. Therefore, it lacks explicitness and concreteness required for actionability.", "grounding_specificity_rationale": "The review point is a general question about the model's ability to handle tabular data. It does not specify which part of the paper or data it is referring to. The grounding is weak as the authors cannot confidently determine which aspect the comment addresses. However, the comment does specify what needs to be addressed in this part, which is the model's ability to handle tabular data. Therefore, it is 3.", "verifiability_rationale": "The review point is a question, not a declarative statement containing a claim. There is no assertion, judgment, or suggestion made. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The review point raises a valid point about the model's potential handling of tabular data. It identifies a potential area of improvement or future research direction. While it doesn't provide immediate actionable advice on how to handle tabular data, it highlights a relevant aspect of multimodal learning. Therefore, it offers some value to the authors by prompting further thought and discussion, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem with the theoretical analysis (unclear meaning of the error bound) and provides concrete suggestions for improvement (clarify the error bound and compare with other methods). This indicates a clear understanding of the issue and a direct path for the authors to address it.", "grounding_specificity_rationale": "The reviewer specifically refers to 'the theoretical analysis in Theorem 1' and identifies a specific issue ('unclear analysis') within it. They also suggest concrete improvements ('clarify the error bound' and 'compare with other methods'). This demonstrates a precise identification of the relevant part of the paper and a clear articulation of the problem and solution.", "verifiability_rationale": "The reviewer makes a claim about the weakness of the theoretical analysis and provides a justification for this claim by stating the lack of meaning of the error bound and the value of comparison with other methods. While they don't provide a detailed proof, they do state a claim and offer a logical reasoning for it.", "helpfulness_rationale": "The reviewer identifies a specific area for improvement in the paper (the theoretical analysis) and provides concrete suggestions for how the authors can address this weakness. This makes the review point directly actionable and valuable for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "Not Helpful", "actionability_rationale": "Part 1 of the review point is an implicit statement, lacking a direct instruction on how to verify the claim. Part 2 is an explicit statement, but the action of how to use this information is not provided. Therefore, it is 2.", "grounding_specificity_rationale": "The reviewer makes a general claim about the performance of different method types without specifying which part of the paper or what aspect is being compared. This is 1. The second part of the review point does not specify what is missing. Therefore, it is 1.", "verifiability_rationale": "The first part of the review point makes a claim about the performance of methods but does not provide any evidence or reasoning to support it. The second part is a factual statement without a claim. Therefore, it is 1.", "helpfulness_rationale": "The first part of the review point is a general observation about a trend, which is not directly helpful for the author. The second part points out a missing element but doesn't offer a solution. Therefore, it is not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly criticizes the use of lowresource language pairs and suggests considering the R3F method. However, the suggestion lacks specific details on how to apply the R3F method or what modifications are needed. The criticism about the 0.8 improvement is implicit, as the reviewer doesn't provide concrete steps or evidence to support this claim. While the criticism is clear, the lack of concrete action makes it partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'lowresource language pairs' and 'multilingual model' but doesn't explicitly identify a specific part of the paper being addressed. The reference to the 0.8 improvement is a general statement about the magnitude of the effect, not a specific aspect of the paper. The reviewer doesn't provide a clear mapping between the criticism and a specific section, table, figure, or unique element of the paper. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim: 'In some lowresource language translations from 1.2>2.0, although the improvement of 0.8 can be claimed, it is insignificant in a practical sense.' This claim is presented without providing specific evidence or references to support the assertion that the 0.8 improvement is insignificant. While the claim is stated, the lack of supporting evidence or justification makes it 1.", "helpfulness_rationale": "The review point provides general feedback about the limitations of lowresource data and suggests considering a method. However, the suggestion to use 'the method like R3F' is vague and lacks specific details on how to apply it. The reviewer doesn't offer concrete recommendations or explain why R3F is particularly relevant in this context. The criticism about the 0.8 improvement is mentioned, but the reviewer doesn't provide a specific alternative or improvement strategy based on this observation. The overall feedback is general and lacks concrete, actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "6", "helpfulness_label": "3", "actionability_rationale": "The review point suggests visualizing the performance decline, which is an explicit action. However, it lacks concrete details on how to create the visualization, making it only 3.", "grounding_specificity_rationale": "The review point refers to the general issue of PU learning methods and performance decline with increasing dimensionality. It does not specify a particular section, table, or unique aspect of the paper, making it 1.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a suggestion for improvement.", "helpfulness_rationale": "The review point offers a relevant direction (visualization) but lacks specific details on how to implement it. This makes it 3 but not fully so."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the suggestion to move the empirical result to supplementary material. This is a direct and clear action. Once the action is identified, the authors know exactly what needs to be done: move the result to the supplementary section.", "grounding_specificity_rationale": "The reviewer refers to 'the empirical version of the objective (3)' as the part being addressed. While they don't explicitly name the specific section or table within objective (3), the reference is clear enough to imply a specific part of the paper. The reviewer is indicating they are referring to the empirical aspect of objective (3) and suggesting it be moved. This allows for full grounding as the section being referenced is implied through the context of the objective.", "verifiability_rationale": "The reviewer does not make a claim about the paper or suggest improvements based on their review. They are making a suggestion to the authors regarding where to place a specific result. Since there is X being made, there is nothing to verify.", "helpfulness_rationale": "The reviewer suggests moving an empirical result to supplementary material. While this is a valid suggestion for the authors' organization and accessibility, it does not directly address a weakness or propose an improvement to the core content of the paper. The helpfulness is moderate as it provides a practical suggestion but lacks a direct impact on the paper's content or addressing a perceived issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the definition of approximation error as the 'gap between the objective values'. This is a direct statement of what the error *is*, making it explicit. However, the reviewer does not provide concrete steps or guidance on how to calculate or implement this definition, making it vague. The lack of specific details on how to identify and measure the 'gap' leaves the reviewer (and potentially the author) unsure of the practical application.", "grounding_specificity_rationale": "The reviewer refers to 'approximation error' and 'objective values' without specifying the exact section, table, figure, or unique aspect of the paper being addressed. While they imply it's related to the draft they're reviewing, the exact location or definition isn't pinpointed. Therefore, the grounding is weak. However, the reviewer *does* specify what needs to be addressed: 'the gap between the objective values'. This adds some specificity to the problem they're highlighting.", "verifiability_rationale": "The reviewer makes a claim: 'It would be better to provide a mathematical characterization.' This is a statement of suggestion and implies a desire for a more precise definition. However, the reviewer does not provide any evidence or reasoning to support this claim. They state the problem (ambiguity in the definition) but don't explain *why* it's a significant issue or what the consequences are for the authors. Therefore, the claim is 1 based on the provided text.", "helpfulness_rationale": "The reviewer's primary goal is to improve the clarity of the definition of approximation error. While they suggest a mathematical characterization, they don't provide any specific steps or examples of how this characterization would be formulated. The suggestion is present, but it lacks concrete guidance. Therefore, it's 3 in identifying a need for clarification but lacks the actionable steps to achieve that clarification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "Highly Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a point of clarification regarding Corollary 10 and the relationship between uncertainty sampling and the minimization of the expected 01 loss and the expected convex surrogate. While the reviewer doesn't propose a specific action, they clearly identify a potential ambiguity or a point where further explanation is needed. The reviewer states, 'This does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate.' This statement itself is an explicit action suggesting a clarification is needed.", "grounding_specificity_rationale": "The reviewer's comment directly references 'Corollar 10' and discusses the concepts of 'uncertainty sampling', 'expected 01 loss', and 'expected convex surrogate'. The reviewer explicitly states, 'Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss; this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate.' This clearly identifies the specific part of the paper being addressed and explains the relationship being questioned, making it 5.", "verifiability_rationale": "The reviewer makes a claim about the relationship between uncertainty sampling and the minimization of two different loss functions. The reviewer states, 'Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss; this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate.' This claim is verifiable by understanding the definitions of expected 01 loss, expected convex surrogate, and descent directions. The reviewer provides a logical argument based on these concepts, making the claim verifiable.", "helpfulness_rationale": "The reviewer provides a specific example of a potential point of confusion in the paper regarding a technical claim. They are suggesting that the paper should clarify the relationship between uncertainty sampling and the minimization of the expected 01 loss and the expected convex surrogate. This is a valuable contribution as it directly addresses a potential ambiguity and guides the authors to improve their understanding. The reviewer's comment is actionable and constructive for the authors, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the reassignment probability is 1/n and suggests it should be higher. They also identify the simplistic evolution model as a limitation and imply a need for a more complex model. These are direct statements and clear suggestions for improvement.", "grounding_specificity_rationale": "The reviewer refers to the 'reassignment probability' and the 'evolution model' generally, without explicitly pointing to a specific section, table, or figure in the paper. While the implications are about the model's mechanics, the direct references are broad.", "verifiability_rationale": "The reviewer states facts about the current reassignment probability and the simplicity of the evolution model. They *imply* that a higher probability and a more complex model would be beneficial. However, they do not provide external references or logical reasoning *within this specific review point* to support these claims.", "helpfulness_rationale": "The reviewer clearly identifies two specific weaknesses in the proposed model: the low reassignment probability leading to slow dynamics and the simplistic evolution model. They provide direct suggestions for improvement, such as increasing the reassignment probability and considering more complex evolution models. While the immediate verifiability is low, the suggestions are concrete and actionable."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point mentions a 'performance improvement' and a specific number (0.02). It also suggests an alternative way to present the data (tables). While it points to a *potential* improvement, the *action* isn't explicit. The authors are *told* there's improvement, *where* it is, and *how much* it is *if* it happens. They aren't told what to change or how to achieve that improvement. The mention of 'performance improvement' is explicit, but the action to improve isn't. The suggestion about tables is explicit, but the action isn't.", "grounding_specificity_rationale": "The review mentions 'the biggest improvement in the bank dataset' and provides a specific number (0.02). It also refers to 'figure 3' and 'tables'. These are specific references to parts of the paper and the suggested improvement method. The authors can easily identify the specific part of the paper being addressed (the bank dataset), and the suggestion to use tables is a clear action on how to present the data.", "verifiability_rationale": "The review states 'As shown in figure 3, the performance improvement of proposed methods seems not so significant, the biggest improvement in the bank dataset was ~0.02.' This is a claim about the significance of the improvement. It also states 'Additionally, using some tables to directly show the key improvements may be more intuitive and detailed,' which is another claim. However, the review does not provide any logical reasoning, common knowledge, or external references to support these claims. It simply states them as observations.", "helpfulness_rationale": "The review offers constructive feedback by pointing out a potential lack of significant improvement and suggesting an alternative way to present the data (tables). While this is helpful in identifying an area for potential improvement and offering a suggestion, it doesn't directly instruct the authors on what specific changes to make to achieve this improvement or how to effectively use tables. The suggestions are more about presentation and analysis rather than direct actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests improvements to Sec. 3.2 by stating 'improve it' and 'give more illustrations and examples'. While it doesn't explicitly state what needs to be improved, it implies a concrete action. The suggestion to provide more illustrations and examples is a direct action that the authors can take to address the identified difficulty in following the section. However, the level of detail in the suggested action is low, making it somewhat vague.", "grounding_specificity_rationale": "The review point explicitly refers to 'Sec. 3.2' and states 'It is hard to follow Sec. 3.2'. The authors can directly identify the specific section being addressed. The comment clearly pinpoints the area of difficulty within that section. This level of specificity allows the authors to understand exactly where the issue lies.", "verifiability_rationale": "The review point contains a claim: 'It is hard to follow Sec. 3.2'. The suggestion to 'give more illustrations and examples' provides a logical reasoning to address this claim. It suggests a concrete way to improve the clarity of the section. While it doesn't cite external references, the suggestion itself serves as a form of justification and guidance for the authors.", "helpfulness_rationale": "The review point clearly identifies a problem ('It is hard to follow Sec. 3.2') and offers a constructive suggestion ('give more illustrations and examples') to improve it. The suggestion is directly related to the identified problem and provides a clear direction for the authors to take. While the suggestion is somewhat general, it is still a valuable piece of feedback that can help the authors improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the action of 'Adding fullysupervised baselines for small models in table 1'. This is a clear and direct instruction for the authors to implement. The action is not implicit and is very concrete, specifying the type of baselines, the models, and the table to which they should be added. There is no ambiguity about how to perform this action.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. While the intent is to improve the paper in general, the suggestion to 'add baselines to table 1' implies a focus on Table 1. However, the review does not specify *what* aspects of Table 1 or the baselines need improvement. It lacks a clear reference point within the paper.", "verifiability_rationale": "The review point contains a claim (the suggestion to 'add fullysupervised baselines for small models in table 1') but lacks sufficient justification or reasoning. It does not provide examples, references, or logical explanations for why this addition would be beneficial or how it should be implemented. The statement is presented as a suggestion without a clear basis.", "helpfulness_rationale": "The review point suggests a concrete action (adding baselines) which is a valuable contribution to the field. However, it lacks specific guidance on *how* to add these baselines, *why* they are needed, or what specific problems they should address. While the suggestion is actionable, the lack of detail makes it less immediately helpful to the authors. The reviewer provides a direction but not the implementation details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points out a problem (small datasets) but doesn't explicitly recommend an action or provide concrete steps for the authors to take. It suggests looking at larger datasets but doesn't specify how to do that or what to do with the results.", "grounding_specificity_rationale": "The review criticizes the datasets used in general without specifying a particular section of the paper or detailing what is wrong with them. It lacks specificity regarding the part of the paper being addressed and the nature of the issue.", "verifiability_rationale": "The review makes a claim about the datasets being small and suggests looking at larger datasets. However, it doesn't explicitly prove that small datasets are the cause of the unconvincing results or that using larger datasets will definitively solve the problem. The connection between the problem and the solution is implied but not explicitly supported by evidence within the review.", "helpfulness_rationale": "The review identifies a potential area for improvement (small datasets) and suggests exploring larger datasets. However, it doesn't provide specific, actionable steps for the authors to take or offer concrete guidance on how to implement the suggestion or what to expect. The reviewer acknowledges it as a minor issue, indicating it might not be perceived as a critical problem requiring immediate action."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the concern about the similarity to RMED and suggests a 'sufficient discussion' on this comparison. This is an explicit action and a concrete suggestion on how to implement it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'RMED' as the relevant existing algorithm and points out the similarity. This is a clear identification of the specific part of the paper being addressed. The reviewer also suggests a 'sufficient discussion' on this comparison, which is a concrete suggestion on how to apply the identified issue.", "verifiability_rationale": "The reviewer makes a claim: 'The paper needs to give a sufficient discussion on the comparison with RMED.' This claim is verifiable by examining the paper and assessing whether it contains a sufficient discussion on the comparison with RMED.", "helpfulness_rationale": "The reviewer directly addresses a potential weakness in the paper's presentation of its novelty by pointing out the similarity to an existing algorithm and suggesting a specific improvement (a sufficient discussion). This is a clear and actionable suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'It would be good if such a comparison could be included.' This directly points to a specific area for improvement in the paper and suggests a concrete action to be taken. The reviewer is indicating that the paper lacks a comparison of GCG's transferability across LLMs, which is a actionable suggestion for the authors.", "grounding_specificity_rationale": "The reviewer refers to 'GCG' and 'other LLMs' in their suggestion. While they don't explicitly state the section number or a unique aspect, the suggestion itself is quite specific: 'comparing GCG's transferability across LLMs.' This indicates a clear understanding of the concept being suggested and a specific action to be taken, even if the exact location isn't pinpointed.", "verifiability_rationale": "The reviewer states 'It would be good if such a comparison could be included.' This is a statement of what the paper should contain. The reviewer also provides a reason for this suggestion: 'GCG could craft adversarial prompts and transfer them to other LLMs.' This provides some justification for the reviewer's claim and suggests a logical connection between the existing work on GCG and the potential for transferability.", "helpfulness_rationale": "The reviewer provides a specific suggestion ('comparing GCG's transferability across LLMs') and a clear rationale for it ('GCG could craft adversarial prompts and transfer them to other LLMs'). This suggests a valuable and actionable improvement that directly addresses a potential gap in the paper. The reviewer is directly pointing out a missing element and providing a reason why its inclusion would be beneficial."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a weakness ('the number of tasks quite limited') and suggests a concrete action ('I would like to see several tasks'). This is an explicit and concrete action, making it 5.", "grounding_specificity_rationale": "The review point implies the authors are referring to the tasks used in their experiments, but it does not explicitly name a specific section, table, or unique aspect of the paper. Therefore, the grounding is weak. The comment identifies a general weakness ('limited') without specifying what is limited, making the specificity low.", "verifiability_rationale": "The review point contains a claim ('I consider the number of tasks quite limited'). The request for 'sequential results in terms of tasks learned rather than epochs' provides a standard for how results should be reported, making the claim 3. However, it lacks specific examples or external references to fully support this suggestion.", "helpfulness_rationale": "The review point directly addresses a weakness in the experiments and provides a clear, actionable suggestion ('I would like to see several tasks'). While it doesn't offer detailed analysis of the current results, it sets a specific expectation for future reporting, making it moderately helpful."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the prompt should be in the appendix or supplement. This is an explicit action. Furthermore, the reviewer suggests it might be in the supplement, providing a concrete location. While the reviewer doesn't specify *how* to implement this, the location is clear, making it somewhat concrete.", "grounding_specificity_rationale": "The reviewer refers to 'the prompt' without specifying which prompt or why it should be in the appendix or supplement. They mention it might be in the supplement, which is a weak form of grounding. However, they don't detail the specific aspect of the paper or the prompt that necessitates this placement. The specificity of the suggestion is limited.", "verifiability_rationale": "The review point does not contain a claim. It is a suggestion or request for clarification. Therefore, it does not have verifiability as it lacks a statement that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer is asking for clarification on where the prompt is. This is helpful in ensuring the authors have all the necessary information for their submission. However, it is not a direct critique or suggestion for improvement, making its helpfulness somewhat limited."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point does not explicitly state what action the authors should take. It raises a question about the rationale behind analyzing only the last convolutional layer. While the reviewer points out a potential area for improvement, they don't provide a direct instruction or suggestion for the authors to follow.", "grounding_specificity_rationale": "The review point explicitly mentions 'the last convolutional layer' as the specific part of the paper being analyzed. This clearly identifies the section the reviewer is referring to.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a question about the motivation for a specific analysis choice, not a statement of opinion or judgment that needs supporting evidence.", "helpfulness_rationale": "The review point identifies a potential area for improvement in the paper's presentation or analysis by highlighting the lack of clarity regarding the motivation for analyzing only the last convolutional layer. While it doesn't directly tell the authors what to do, it points out a gap in explanation that could be addressed by the authors themselves."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential point of confusion or a practical consideration that the original statement missed. While technically correct that the choice of constraint doesn't require tuning a *free* parameter, the act of *choosing* between convex/concave and increasing/decreasing could be seen as a decision that needs justification or further explanation. The reviewer doesn't explicitly state what action should be taken, but they highlight a potential area of ambiguity or a point that requires further clarification.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. It makes a general comment about the description of shape constraints. Therefore, the grounding is weak as the authors cannot pinpoint the exact section or table being referred to.", "verifiability_rationale": "The review point makes a claim that the choice of constraint can be seen as a hyperparameter that needs tuning. This claim is verifiable as the reviewer provides a logical reasoning: the act of choosing between different constraint types involves a decision that could be considered a parameter. However, the reviewer does not provide specific examples or references to support this claim, making the verifiability somewhat limited.", "helpfulness_rationale": "The review point is helpful because it highlights a potential point of confusion or a practical consideration that the original statement missed. By pointing out that the *choice* of constraint could be seen as a hyperparameter, the reviewer encourages the author to be more precise in their description and to consider the implications of their choice. While the review point doesn't provide a solution, it offers a valuable point of reflection and potential clarification. It avoids being overly prescriptive and instead prompts the author to think more deeply about their constraints."}
{"actionability_label": "1", "grounding_specificity_label": "4: Mostly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggestion for the authors. It raises a question about the interpretation of the results regarding the multienv model. While the reviewer implies a potential action (clarifying the contradiction), the point itself lacks a direct instruction on how to proceed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the multienv model' and points out the 'performance loss' and 'outperformance due to knowledge sharing' regarding this model. This clearly identifies the specific part of the paper being addressed, demonstrating strong grounding specificity.", "verifiability_rationale": "The reviewer points out a logical conflict: 'It is stated both that the multienv model has an inevitable performance loss and that the multienv model outperforms the singleenv model due to knowledge sharing.' This statement presents a contradiction that requires further clarification or justification. While the reviewer doesn't provide external references, the *statement itself* identifies a point that needs verification or explanation.", "helpfulness_rationale": "The review point effectively highlights a lack of clarity in the paper's explanation of the multienvironment model's performance. By pointing out the conflicting statements, the reviewer helps the authors identify a potential area of confusion or misinterpretation. This directly contributes to the authors' understanding and allows them to focus on resolving this specific issue."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that Figure 3 is 'challenging to understand' and that the 'workflow and captions are unclear, and the representation of communication modes on the left side is confusing'. While the reviewer doesn't explicitly state an action to be taken, the identification of these elements as unclear implies an action to clarify them. The lack of explicit instructions makes it 3 in the sense that the authors should be able to identify the specific parts needing improvement.", "grounding_specificity_rationale": "The reviewer explicitly names three specific elements within Figure 3: 'workflow,' 'captions,' and 'representation of communication modes.' This clearly identifies the specific part of the paper being addressed, indicating strong grounding. While the reviewer doesn't state how to improve these aspects, they clearly specify what needs to be improved.", "verifiability_rationale": "The review point states that Figure 3 is 'challenging to understand' and that the 'workflow and captions are unclear, and the representation of communication modes on the left side is confusing'. This statement expresses a judgment about the clarity of specific elements within the paper. Therefore, it contains a claim that requires some form of justification or explanation. The lack of external references or logical reasoning makes it '3' as the authors can infer the issue but might need more context to fully understand the problem.", "helpfulness_rationale": "The reviewer directly points out a specific weakness in the paper: 'Figure 3 is challenging to understand. The workflow and captions are unclear, and the representation of communication modes on the left side is confusing.' This clearly identifies a problem that the authors can directly address. While the comment doesn't suggest a specific solution, it highlights a concrete area needing improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the term 'learned MASK embedding' and asks for its meaning in the context of the SSL pretraining stage. This is a direct identification of a missing definition and a clear request for action.", "grounding_specificity_rationale": "The reviewer directly asks for the meaning of 'learned MASK embedding' in the context of the SSL pretraining stage. This directly identifies the specific part of the paper and asks for a definition, making it 5.", "verifiability_rationale": "The reviewer points out a lack of clarity regarding a specific technical term. While it doesn't present a claim needing verification, it highlights a missing piece of information that could be considered verifiable in the sense that it needs to be explained. However, the primary action is to seek clarification, making it borderline in terms of verifiability.", "helpfulness_rationale": "The reviewer's point is very specific and directly addresses a potential confusion for the authors. Requesting clarification on a specific technical term is likely to be 5 for the authors in understanding and implementing the proposed method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The statement is explicit about the *nature* of the results (derivative) and *how* they were obtained (extension of standard networks to hypernetworks). It *doesn't* explicitly state *what* needs to be done. Is the reviewer saying the results are derivative *in general*, or is it specific to a certain part of the paper? The phrasing is broad enough to be considered implicit.", "grounding_specificity_rationale": "The reviewer mentions \"results already presented in the literature for standard networks\" and \"extension to hypernetworks.\" This shows the reviewer has *some* idea of where the results are coming from and what the context is. However, they don't explicitly state *which specific result* in the paper they are referring to. It's a bit vague.", "verifiability_rationale": "The reviewer *claims* that the results are \"partially derivative.\" This is a clear statement of opinion or judgment. However, the reviewer doesn't provide *why* they think the results are derivative. They don't offer evidence or reasoning. This makes it 1.", "helpfulness_rationale": "The reviewer highlights a potential issue (lack of novelty/derivative results in this area). This suggests a desire for the authors to address this. However, the comment doesn't offer specific, actionable steps or suggestions for how the authors should improve their work based on this observation. The comment is diagnostic but not prescriptive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states a clear problem: 'the scope of the study is underspecified.' This indicates an explicit identification of a deficiency. While the reviewer doesn't explicitly state what is underspecified, they offer potential areas of underspecification (focus on small models, missing LLM baselines) as implicit suggestions for improvement. Therefore, the action is explicitly identified, though not fully detailed.", "grounding_specificity_rationale": "The reviewer mentions 'scope' and 'study,' which can be interpreted as a weak grounding, as they are general terms. However, the reviewer does not explicitly identify a specific part of the paper, table, figure, or unique aspect that is underspecified. The reviewer suggests potential areas of underspecification (smallscale models, missing LLM baselines) but doesn't pinpoint a specific element of the paper. Therefore, while a general area is mentioned, the specific element is not clearly identified.", "verifiability_rationale": "The reviewer makes a claim: 'the scope of the study is underspecified.' However, they do not provide any logical reasoning, common knowledge, or external references to support this claim. The reviewer suggests potential reasons (focus on small models, missing LLM baselines) but doesn't offer evidence or justification for why the scope is indeed underspecified. Therefore, the claim is made without sufficient support or justification.", "helpfulness_rationale": "The reviewer raises a concern about the scope and suggests missing baselines. While this points to a potential issue, the reviewer does not provide specific, actionable suggestions for the authors on how to improve their draft based on this feedback. The feedback is more about identifying a problem than offering concrete solutions. Therefore, the review lacks clear guidance on how the authors can improve their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem ('Figure 3 is very hard to read anything on the figure.') and suggests a concrete action ('improve the figure'). This fits the definition of explicit and concrete actionability.", "grounding_specificity_rationale": "The reviewer specifically mentions 'Figure 3' which indicates strong grounding. However, the reviewer does not specify *what* is wrong with the figure, making it only weakly specific.", "verifiability_rationale": "The reviewer makes a claim about Figure 3's readability ('Figure 3 is very hard to read anything on the figure.') but does not provide any justification or evidence for this claim. There is no logical reasoning, common knowledge, or external references provided to support the statement. Therefore, it is 1.", "helpfulness_rationale": "The reviewer identifies a valid issue (readability of Figure 3). However, the suggestion is very general ('improve the figure') and lacks specific details on how to improve the figure's readability. It points out the problem but doesn't provide concrete solutions, making it 3 but lacking in detail."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment implies the GAT is trained with the whole model and suggests reviewing by a native speaker and rewriting, but lacks explicitness and concreteness. Authors can deduce the issue (potential training problem) and the actions (reviewing, rewriting), but the specific action and how to apply it are not clear.", "grounding_specificity_rationale": "The comment refers to \"The GAT\" and \"the whole model\" without explicitly pointing to a specific section, table, figure, or unique element of the paper. The authors cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part (training process, review, rewriting).", "verifiability_rationale": "The review point doesn't make a declarative statement that can be judged as true or false. It's a question and a suggestion for improvement, not a claim that needs verification.", "helpfulness_rationale": "The comment suggests helpful actions but lacks specific details, making it difficult for the authors to act. While the intent is helpful, the lack of concrete guidance reduces its potential impact."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states two actions: 'Replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda`' and 'Taking SGD learning rate ~ 0.1'. These are clear and direct instructions on what the authors should do. The reviewer also explains *why* the learning rate should be changed, stating 'unlike the Adam default value, it is unclear what the justification behind this value is'. This provides a clear motivation for the suggested change. The actions are also concrete, specifying the exact replacement and the target learning rate.", "grounding_specificity_rationale": "The review point explicitly refers to 'lines 119121' and 'line 164'. This clearly identifies the specific part of the paper being addressed. Furthermore, the point not only identifies the location but also specifies the issue with the learning rate and the proposed change, making it highly specific about what needs to be addressed.", "verifiability_rationale": "The review point makes a claim: 'unlike the Adam default value, it is unclear what the justification behind this value is'. This is a statement that can be verified by examining the paper. The reviewer points out a gap in the authors' reasoning regarding the choice of the learning rate. While they don't provide the justification themselves, they clearly identify the lack of justification as a verifiable fact. The reasoning is based on the observation that the justification is missing, which can be confirmed by reading the paper.", "helpfulness_rationale": "The review point is concise and directly addresses potential issues and improvements. It suggests a concrete change to the formula and recommends an alternative for the learning rate. The reviewer's statement about the lack of justification for the learning rate is a clear indication of a potential weakness that the authors could address. The suggestions are actionable and directly improve the clarity and completeness of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests analyzing the domain gap and adding discussions about the gap between datasets. While this is a relevant concern, the suggestion lacks specific actions or concrete steps on how to analyze the gap. The reviewer does not explicitly state what needs to be done, such as comparing feature distributions or evaluating model performance on different datasets. The suggestion to add discussions is also vague and does not provide a specific direction for the discussion. Therefore, the review point is only implicitly suggesting an action, making it 2.", "grounding_specificity_rationale": "The review point discusses the domain gap and suggests adding discussions about the gap between datasets. It does not specify which part of the paper or model this refers to. The reviewer does not identify a specific section, table, figure, or unique aspect of the paper where the domain gap is being discussed. The suggestions are general and do not point to a particular area for improvement. Therefore, the review point does not identify a specific part of the paper or model, making it 1.", "verifiability_rationale": "The review point suggests analyzing the domain gap and adding discussions about the gap between datasets. While these suggestions are relevant, they lack specific evidence or references to support them. The reviewer does not provide any logical reasoning, common knowledge, or external references to justify the need for analyzing the domain gap or the value of adding discussions about it. The suggestions are general and do not offer a clear path forward. Therefore, the review point makes a claim (the suggestion itself) but does not provide sufficient justification or references to make it verifiable.", "helpfulness_rationale": "The review point raises a valid concern about the domain gap and suggests considering the similarity between datasets. This is a relevant point that could guide the authors in their transfer learning efforts. However, the suggestions are very general and lack specific, actionable recommendations. The reviewer does not provide concrete steps on how to analyze the domain gap or what specific discussions to include. The suggestions are too broad and do not offer a clear roadmap for improvement. Therefore, while the core idea is helpful, the lack of specific guidance makes the review point only marginally helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The statement 'I don't see anything NLPspecific in their approach' identifies an area for improvement but lacks specific details on what is missing. While it points to a potential issue, it doesn't explicitly state what should be NLPspecific or how to achieve that. Therefore, it is 3 but lacks concrete details.", "grounding_specificity_rationale": "The comment 'I don't see anything NLPspecific in their approach' does not explicitly identify a specific part of the paper being addressed. The reference to 'their approach' is vague and could apply to any part of the work. Therefore, the grounding is weak.", "verifiability_rationale": "The comment 'I don't see anything NLPspecific in their approach' contains a claim (the statement of opinion) but does not provide any supporting evidence or justification. There is no logical reasoning, common knowledge, or external references to back up this assertion. Therefore, it is 1.", "helpfulness_rationale": "The comment is directly critical of the authors' claim about NLPspecificity. While it identifies a potential issue, it does not offer any suggestions or guidance on how to address it. Therefore, it is not 5 as it lacks actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including a comparison with at least one NCEbased method. While this is a clear direction for improvement, it lacks specific details on which method to compare or how to perform the comparison. The suggestion is general and could be expanded with more concrete actions.", "grounding_specificity_rationale": "The review point suggests including a comparison with at least one NCEbased method. This is weakly grounded as the authors don't explicitly identify a specific NCE method or detail the nature of the comparison. However, the second part of the review, referencing paper 1, provides specific information about a potential method and its properties, making it somewhat specific.", "verifiability_rationale": "The review point presents a claim: that comparing with NCE methods is a useful suggestion, and that paper 1 demonstrates the feasibility of learning EBMs on natural images with a strong noise distribution. This claim is partially verifiable. The suggestion to compare is general. The reference to paper 1 provides a potential piece of evidence supporting the feasibility of learning EBMs with strong noise, which could indirectly inform the comparison with NCE methods, but it doesn't explicitly state how.", "helpfulness_rationale": "The review point offers a suggestion for improvement by recommending a comparison with NCE methods. It also provides a potential piece of evidence (1) that could support this suggestion. While it doesn't specify *which* NCE method or *how* to perform the comparison, it offers a clear direction for the authors to explore and potentially build upon existing work. The suggestion is relevant and provides a starting point for further investigation, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides two suggestions: adding a significance test to the human evaluation results and comparing the proposed method with recent LLMs. These suggestions are direct and specific, indicating that the reviewer has identified potential weaknesses or areas for improvement. The reviewer explicitly states what should be done, making the actions clear and actionable. The suggestions are also concrete, as they specify the type of analysis and comparison to be performed.", "grounding_specificity_rationale": "The reviewer suggests adding a significance test to the human evaluation results and comparing with recent LLMs. However, the reviewer does not specify *which* human evaluation results or *which* recent LLMs are being referred to. The mention of 'the human evaluation results' and 'some most recent LLM' lacks specificity. While the *concept* of a significance test and comparison with LLMs are relevant, the lack of identification makes it difficult for the authors to pinpoint the exact area that needs improvement. The grounding is weak because the authors cannot confidently determine which part of the paper the reviewer is addressing.", "verifiability_rationale": "The reviewer explicitly states that it is 'better to carry significance test on the human evaluation results' and that it is 'also beneficial to compare the proposed method with some most recent LLM'. These statements present claims that are generally wellsupported by common practices in research methodology and machine learning. The reviewer is not introducing novel concepts or making unsupported claims. The suggestions are based on established statistical methods and comparisons with relevant stateoftheart models. Therefore, the claims are verifiable based on common knowledge and accepted practices.", "helpfulness_rationale": "The reviewer provides two concrete suggestions: adding a significance test to the human evaluation results and comparing the proposed method with recent LLMs. These suggestions are directly related to improving the rigor of the evaluation and the relevance of the comparison. The reviewer clearly identifies potential weaknesses or areas for improvement. The suggestions are actionable and provide a clear direction for the authors to follow. While the lack of specificity in the *type* of LLM comparison might require further clarification, the core idea of comparing with recent LLMs is valuable and directly addresses potential limitations in the current evaluation or baseline comparisons. The suggestions are wellaligned with common practices and offer concrete improvements."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'this requires more explanation' and asks a direct question 'Why exactly...'. This indicates an actionable gap, as the authors should be able to understand the need for more explanation. However, the reviewer does not specify *what* is different about the two quantities, making the action only implicit.", "grounding_specificity_rationale": "The reviewer refers to 'two quantities' and 'learning settings' without specifying which part of the paper these quantities relate to. They ask 'why exactly are the two quantities different', indicating a lack of grounding in the specific section or table. Furthermore, while they ask a question, the question itself does not specify what needs to be addressed in this part, making it underspecific.", "verifiability_rationale": "The reviewer states 'this requires more explanation' and asks a question 'Why exactly...'. This can be considered a claim that requires more justification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support why the explanation is needed or why it captures the difference in learning settings. The verifiability is weak because the reasoning is missing.", "helpfulness_rationale": "The reviewer explicitly states 'this requires more explanation' and asks a question 'Why exactly...'. This is a clear and actionable feedback that empowers the authors to improve their draft by seeking clarification. While the reviewer does not specify *what* is different, the request for explanation and the question itself highlight a meaningful weakness that the authors can address. The feedback is not vague or minimal guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment asks for a discussion, which implies an action, but it doesn't explicitly state what action should be taken. The reviewer is asking the authors to analyze and discuss the sensitivity of fixed tuning parameters, but they are not providing a specific instruction on *how* to do this analysis.", "grounding_specificity_rationale": "The reviewer mentions 'fixed tuning parameters,' which provides some level of grounding by referencing a specific aspect of the model. However, they don't explicitly state which section, table, or figure these parameters are located in, making the grounding somewhat weak.", "verifiability_rationale": "The review point itself is not a claim or assertion that requires verification. It is a request for information about the sensitivity of fixed tuning parameters. Therefore, it doesn't directly contribute to verifiability in the sense of validating a claim.", "helpfulness_rationale": "The reviewer is asking a specific question about a relevant aspect of the model (fixed tuning parameters) and requests an analysis of their sensitivity (both strengths and weaknesses). This directly points the authors to a specific area for further investigation and provides a clear direction for improving their understanding of the model. While not a direct instruction on *how* to analyze sensitivity, it's a valuable piece of information for the authors to consider."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point asks a question about the framework's compatibility with different policy gradient approaches and requests experimental details. It doesn't explicitly state what needs to be done or suggest an alternative. Therefore, it's unlikely to be fully actionable. It's a request for information rather than a proposed change.", "grounding_specificity_rationale": "The reviewer clearly identifies the relevant part of the paper as the 'experiment results' section and specifically asks about the details within that section related to the algorithms mentioned. The reviewer accurately identifies the section and the information needed.", "verifiability_rationale": "The review point is a question seeking information. Questions, by their nature, require verification or justification to be considered verifiable. The request for clarification about experimental details is a logical request, implicitly seeking confirmation or clarification, which can be considered a form of justification. The reviewer is prompting the authors to provide a detail that is important for understanding the experimental process and potentially for reproducing the results.", "helpfulness_rationale": "The review point is a question seeking information. Questions can be helpful if they lead to a better understanding of the paper's details. The question directly requests information crucial for understanding the experimental setup and potentially replicating or building upon the work. This information is valuable for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies an implicit action: the authors should evaluate their work on more than one dataset and more than one task. However, the action is vague because it doesn't specify which additional datasets or tasks should be considered. The reviewer suggests expanding the evaluation, but the exact methodology for this expansion is not provided.", "grounding_specificity_rationale": "The review point does not explicitly identify the specific dataset or task on which the evaluation is performed. It only states that the evaluation is done on 'one dataset and one task'. Therefore, the grounding is weak because the authors cannot confidently determine which part the comment addresses. The comment does specify what needs to be addressed (wider evaluation), but the current grounding is about the *what*, not the *where* within the paper.", "verifiability_rationale": "The review point is a statement of opinion, not a claim that requires verification or justification. It suggests that the current evaluation is limited and that future work should involve more datasets and tasks, but it doesn't provide any specific evidence or references to support this suggestion.", "helpfulness_rationale": "The review point identifies a valid weakness in the paper: the limited scope of the evaluation to a single dataset and task. This is a concrete issue that could impact the generalizability and robustness of the conclusions. The reviewer also provides a helpful suggestion for improvement by recommending evaluation on more datasets and tasks. While the suggestion is broad and doesn't offer specific guidance on which datasets or tasks to choose, it is a valuable direction for future work and therefore helpful to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer implicitly suggests that the definition of 'relevant' auxiliary model weights needs to be more explicit. While they don't state an action directly, the vagueness of the current definition makes it difficult to understand what constitutes 'relevance'.", "grounding_specificity_rationale": "The reviewer points to Definition 2.1 as the specific part of the paper being addressed but doesn't specify which weights are 'relevant' or how their relevance is determined. This makes the grounding somewhat underspecific.", "verifiability_rationale": "The reviewer is not making a claim that something is wrong with the definition. They are pointing out a lack of clarity, which is more of a request for information than a definitive critique requiring verification. Therefore, it's difficult to classify this as verifiable or 1.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: to clarify the definition of 'relevant' auxiliary model weights. This directly addresses a potential point of confusion for the authors, making it a helpful comment."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer suggests a broader applicability of the paper's findings to kernel regression. While this could be a valuable direction for future research, it doesn't explicitly state a specific action or modification needed within the current paper. The suggestion is general and doesn't point to a particular section, table, or figure where the connection to kernel regression should be made. Therefore, while it expresses a potential action, it lacks the concrete details necessary for it to be considered actionable. It's more of a suggestion for future work than a direct critique of the current paper's content.", "grounding_specificity_rationale": "The reviewer's comment is highly general and does not specify any particular part of the paper (section, table, figure, or unique element) that needs addressing. They are suggesting a broader applicability rather than pinpointing a specific issue. Therefore, the grounding is weak as the authors cannot confidently determine which part of the paper the comment refers to.", "verifiability_rationale": "The reviewer's comment is a suggestion or a potential extension of the work to kernel regression. While it expresses an opinion or judgment about the potential applicability, it does not provide any specific evidence, justification, or references to support this suggestion within the provided text. The comment is a hypothesis for future work, not a critique of the current work with verifiable claims. Therefore, the claim is not supported by any verifiable evidence.", "helpfulness_rationale": "The reviewer's comment is a suggestion for future research, specifically extending the findings to kernel regression. While this is a relevant point for the broader field, it does not directly address any perceived weaknesses or errors within the current paper. It lacks specific, actionable feedback that would empower the authors to improve their draft. The comment is more of a potential application than a constructive critique of the current work. Therefore, it does not provide the kind of helpful feedback that would significantly improve the paper."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests adding references to existing studies. While this is a valid point, the action of adding references is not explicitly stated in the review point itself. The reviewer implies the need for references but doesn't provide specific instructions on how to add them. Therefore, the action is implicit.", "grounding_specificity_rationale": "The reviewer mentions specific factors (order sensitivity, complexity, diversity, style sensitivity) that affect the performance of chainofthought prompting. These factors are directly related to the content of the paper. However, the reviewer does not specify which particular studies or evidence within the paper supports the claim that these factors have been discussed in existing studies. The grounding is present, but it is not specific to the paper's content or the specific implementation of chainofthought prompting.", "verifiability_rationale": "The reviewer states that 'most of the above factors have been discussed in existing studies.' This is a claim that requires verification. However, the review point does not provide any evidence, references, or logical reasoning to support this claim. The claim is presented without sufficient justification.", "helpfulness_rationale": "The reviewer's suggestion to add references is relevant to the paper's topic and aims to improve the completeness and rigor of the research. However, the suggestion is quite general. It does not specify which references to add, where to add them, or how to integrate them effectively. While helpful, it lacks the specificity and actionable steps needed for significant improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests adding more unique tasks and variety to the dataset. While this is a valuable suggestion, it does not explicitly state what needs to be done to achieve this. The reviewer identifies a limitation (lack of unique tasks) but doesn't provide a concrete action for improvement. Therefore, it is not actionable as it lacks specific steps for the authors to follow.", "grounding_specificity_rationale": "The review point is general and does not specify which part of the paper or dataset the reviewer is referring to when mentioning the lack of unique tasks. It lacks specificity in identifying a particular section, table, figure, or unique aspect. Therefore, it is 1 as it doesn't pinpoint the relevant part for improvement.", "verifiability_rationale": "The review point suggests the need for more unique tasks and variety. This is a suggestion or a desire, not a claim that requires verification. The reviewer is pointing out a potential improvement but doesn't provide any evidence or justification for why the current tasks are lacking. Therefore, it is not verifiable as it doesn't present a claim supported by reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point expresses a desire for more unique tasks and variety in the dataset. While this is a valid point and could be helpful for the authors in terms of research directions, it is not a highly detailed or actionable suggestion. The reviewer doesn't provide specific steps or examples of how to achieve this. Therefore, it is 3 as it identifies a potential area for improvement, but it lacks the depth and specificity of a 5 comment."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the desired action: 'it should be reorganized'. This clearly indicates a direction for improvement. However, the comment lacks details on *how* the reorganization should be performed, making it less concrete.", "grounding_specificity_rationale": "The comment explicitly mentions 'Appendix H', which is a specific part of the paper. It also identifies a problem with this part ('difficult to follow'). This demonstrates strong grounding as the section is named, and the issue is clearly implied within that section.", "verifiability_rationale": "The comment contains a suggestion ('it should be reorganized') which can be interpreted as a claim that the current organization is problematic. However, the comment does not provide any external references or logical reasoning to support this claim. It simply states the desired outcome without justifying why the current state is an issue.", "helpfulness_rationale": "The comment directly suggests a concrete action ('reorganized') and points to a specific section (Appendix H) with a clear issue ('difficult to follow'). This provides the authors with a clear direction for improvement, making the review point 3 in guiding the authors towards a solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point suggests an experiment (using larger resolution) but does not explicitly state how to implement it or what actions need to be taken. The action is implicit. Therefore, it is not 5.", "grounding_specificity_rationale": "The review point does not specify where in the paper the suggestion relates to. It is a general suggestion about an experimental parameter. Therefore, it is 1.", "verifiability_rationale": "The review point contains a suggestion (a claim) about using larger resolution. However, it does not provide any justification or references to support this claim. The support is missing. Therefore, it is not 5.", "helpfulness_rationale": "The review point introduces a potential experiment (using larger resolution) but does not provide any guidance on how to conduct it, evaluate its impact, or connect it to the existing work. It lacks actionable information. Therefore, it is not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises a question about the significance of the problem they identified, implying they are unsure if it's a major issue for the current paper. While they don't explicitly state an action, the act of questioning itself can be considered an implicit action the authors might need to address by evaluating the importance of the problem. However, the reviewer doesn't provide a clear path or solution, making it only partially actionable.", "grounding_specificity_rationale": "The reviewer's description of the problem ('ODEs exhibiting inaccuracy while recomputing activations') is general and doesn't pinpoint a specific section, table, figure, or unique aspect of the paper. They mention a 'previous paper' but don't provide specific references or examples within the current paper. This lack of precise identification makes the grounding weak.", "verifiability_rationale": "The reviewer claims that the current paper 'appears a previous paper first reported this issue. The reviewer is not convinced about this problem. The current paper doesn't provide a convincing analytical argument or empirical evidence about this issue.' This statement contains a claim that needs to be verified. The reviewer is pointing out the *lack* of evidence, which is a form of verification. While the reviewer doesn't provide specific examples of missing evidence, their statement about the paper lacking evidence is a clear assertion that requires justification. Therefore, it's 2 as the claim is made but lacks detailed supporting evidence.", "helpfulness_rationale": "The reviewer's primary concern is about a specific problem (the inaccuracy of ODEbased weight evolution). While raising a concern is valuable, it doesn't directly offer a solution or a clear path forward for the authors. The reviewer is questioning the significance of the problem, not providing a direct recommendation for improvement. Therefore, it's borderline helpful as it raises a valid point but doesn't provide actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests a potential implication of the sampled policy usage but does not explicitly state an action or provide concrete steps on how to implement it. The suggestion is openended and lacks specific guidance.", "grounding_specificity_rationale": "The comment refers to 'these algorithms' and 'sampled policy', which are specific to the context. While it doesn't explicitly name a section, table, or figure, the reference is clear and points to a specific area of discussion within the paper. The grounding is present but could be more explicit.", "verifiability_rationale": "The comment contains a claim ('Might want to mention') but does not provide any specific justification or evidence to support this suggestion. The reasoning is vague and lacks references to external works or logical reasoning to back up the assertion.", "helpfulness_rationale": "The comment points out a potential area for improvement but lacks specific details on how to achieve this. It's a suggestion without concrete steps or evidence, making its helpfulness limited."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential issue in the model's development, stating 'shows evidence that some information is learned before the model is able to use the concepts.\" This is an explicit statement of a problem. However, the reviewer does not provide any specific actions or suggestions on how to address this issue. The reviewer only points out the gap in the model's development.", "grounding_specificity_rationale": "The reviewer refers to \"evidence\" and 'some information\" and \"model is able to use the concepts.\" While they don't explicitly name a specific section, table, or figure, they are referring to general aspects of the model's development. The reviewer's statement is not precise about which part of the paper they are referring to. They are referring to parts of the paper that are generally understood.", "verifiability_rationale": "The reviewer makes a statement about the model's development: 'shows evidence that some information is learned before the model is able to use the concepts.\" This statement is presented as a fact without any supporting evidence or reasoning. The reviewer is stating an observation, not making a claim that can be verified.", "helpfulness_rationale": "The reviewer points out a potential issue in the model's development. While they identify a problem, they do not offer any suggestions or guidance on how to address it. The reviewer's comment is focused on highlighting a gap in the model's capabilities rather than providing concrete improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point suggests improving the explanation of the bounds, which is an explicit action. However, it lacks specific details on how to achieve this improvement, making it only partially actionable.", "grounding_specificity_rationale": "The reviewer refers to 'the bounds' without specifying which particular bounds are being addressed. This lack of specificity means the grounding is weak. Additionally, the review does not detail what is wrong with the explanation of these bounds, making it not specific.", "verifiability_rationale": "The review point is a suggestion for improvement rather than a declarative statement that requires verification. Therefore, it does not contain a claim that needs to be supported by evidence.", "helpfulness_rationale": "The review point identifies a potential area for improvement (explanation of bounds) but does not provide specific, actionable steps on how to address it. This makes it a helpful suggestion but not a fully helpful solution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states: \"there are no results with larger models like ResNet101/152.\" This is a factual statement about the absence of results. It does not explicitly or implicitly suggest any action the authors should take based on this observation. The authors are left to wonder why these results are missing and what impact they might have on their work. Therefore, the review point lacks a clear action or suggestion for the authors.", "grounding_specificity_rationale": "The review point mentions \"imageNet classification with ResNet50/34/18\" and then introduces \"ResNet101/152.\" While it identifies the context of the results being discussed, it does not explicitly pinpoint the specific section, table, figure, or unique aspect of the paper where these results should be expected or analyzed. The reviewer is pointing out a potential gap in exploring larger models, but not within a specific, clearly defined part of the paper. Therefore, the grounding is weak. The review point also does not specify *what* is missing or wrong in the referenced part. It only states the absence of results for larger models. Therefore, the specificity is also low.", "verifiability_rationale": "The review point states: \"there are no results with larger models like ResNet101/152.\" This statement can be considered a claim, as it expresses an observation about the absence of specific results. This claim is 3 because the reviewer's statement is based on their own observation of the results they have seen. While it doesn't provide a logical reasoning or external reference, it is based on a direct observation. Therefore, the claim is somewhat supported by evidence, making it 3.", "helpfulness_rationale": "The review point identifies a potential area for improvement or further investigation for the authors by pointing out the absence of results for larger models. While it doesn't explicitly tell the authors what to do, it highlights a gap in their exploration or analysis. This provides some direction for the authors to consider and potentially address. Therefore, the review point is 3 in guiding the authors towards further exploration or analysis. It doesn't directly tell them how to improve their draft, but it points to a potential area for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer points out issues with the proof, the lack of detailed discussion, and the absence of new insights. While these are valid concerns, the reviewer does not explicitly state what specific action the authors should take to address these issues. The suggestions are more about identifying problems than providing concrete steps to solve them.", "grounding_specificity_rationale": "The reviewer makes general statements about the paper lacking detail and insight. They do not specify which part of the paper is unclear or missing. For example, they say 'lacks a detailed discussion' but don't point to a specific section or aspect of the discussion that is missing. Similarly, they state 'seemed not to give any new insight' without specifying what the new insight would be.", "verifiability_rationale": "The reviewer states that the paper 'lacks a detailed discussion and comparison with the previous work' and 'seemed not to give any new insight'. These are claims that need to be supported by evidence. However, the reviewer does not provide any references, examples, or logical reasoning to back up these statements. The claims are presented without sufficient justification.", "helpfulness_rationale": "The reviewer's comments are primarily critical, pointing out shortcomings in the paper's proof, discussion, and novelty. They do not offer specific, actionable suggestions for improvement. For example, they say 'confusing mistake' but don't explain what the mistake is or how it should be corrected. Similarly, they state a lack of novelty without suggesting what new insight could be provided. The feedback is more about identifying problems than offering solutions."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment identifies a relevant concept (adversarial loss) but does not specify how to implement it or its relevance to the author's work. It lacks concrete steps for the author to take.", "grounding_specificity_rationale": "The comment is very general and does not specify which part of the paper or data it is referring to. It lacks any grounding in a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The comment is a factual statement about a loss function and does not contain a claim, judgment, or suggestion. It does not require verification and is not a critique of the author's work.", "helpfulness_rationale": "The comment defines a loss function but does not provide any actionable advice on how to use it, its relevance to the author's work, or any potential improvements it might bring. It is a factual description, not a helpful critique or suggestion."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what action the authors should take. It simply suggests a comparison between two methods. There is no indication of how this comparison should be performed or what the expected outcome should be. The authors are asked to infer the action rather than being directly guided.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or method that needs improvement. It refers to the general concept of 'support of the solution obtained by the proposed scheme' and 'baseline methods' without pinpointing a particular section, table, figure, or unique aspect of the paper. The authors cannot determine the exact issue being addressed from this comment alone.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion to compare two methods, not a statement that needs to be supported by evidence. There is no logical reasoning, common knowledge, or external references provided to justify the suggestion.", "helpfulness_rationale": "The review point is relevant to the research process, as it encourages the authors to consider the comparison of different methods. It does not hinder their ability to proceed with their work. However, it lacks specific guidance on how to perform the comparison, making it less immediately helpful in terms of actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a performance difference between a generator with an RGCN discriminator and the proposed module, suggesting a potential weakness in the submission. While the reviewer points out this difference, they do not explicitly state the mechanism behind the proposed module's stability. The action is implicit, as the reviewer identifies a problem and suggests an improvement, but the specific action of explaining the mechanism is not directly stated.", "grounding_specificity_rationale": "The review point explicitly mentions 'Sec 5.3' and compares the performance of 'a generator equipped with a standard RGCN as discriminator' with 'the proposed module'. This allows for precise identification of the part of the paper being addressed. However, the reviewer does not specify *what* is causing the collapse in the RGCN case or the specific mechanism of stability in the proposed module. The grounding is explicit in terms of location, but the specificity regarding the underlying issues is lacking.", "verifiability_rationale": "The review point presents a claim: 'a generator equipped with a standard RGCN as discriminator tends to collapse after several (around 20), while the proposed module will not'. The reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The request to 'I would like to see why the proposed module can prevent a generator from collapsing' indicates a desire for verification, but no immediate evidence is provided. The claim is stated, but the supporting evidence is missing.", "helpfulness_rationale": "The review point directly identifies a performance discrepancy in a specific section of the paper and requests an explanation for this difference. This is a clear and actionable criticism that the authors would likely find helpful in understanding and improving their work. The reviewer's desire for clarification is a constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the suggestion to reorganize Sections 3 and 4, which constitutes an explicit action. The reviewer also provides specific details on how the reorganization should be done, making the action concrete. The suggestion is directly aimed at improving the organization of the paper.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3' and 'Section 4', providing clear grounding. They also specify the *content* of the reorganization, making the specificity high. The reviewer's comment is very precise in identifying the sections and the nature of the suggested change.", "verifiability_rationale": "The reviewer's suggestion implies a potential redundancy between Sections 3 and 4. While there's no direct evidence of redundancy within this review point, the suggestion itself is a logical consequence of observing such potential. The action (reorganizing) is verifiable based on the provided information.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improving the organization of the paper. The suggestion is directly related to a potential weakness (redundancy) and offers a concrete solution. This is a 5 comment for the authors as it directly addresses a potential issue and provides a clear path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the strong assumptions made about camera parameters and object segmentation. This directly points to an actionable limitation: the applicability of the methods in realworld scenarios where these assumptions might not hold. The reviewer clearly identifies the area where the method might struggle.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'extrinsics,' 'intrinsics,' and 'object segmentation' as the specific parts of the paper where the limitations are relevant. This demonstrates strong grounding as the reviewer accurately identifies the sections and terms directly related to the identified issue. The reviewer also explains *why* these are important, further enhancing grounding.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the methods due to the strong assumptions. This claim is supported by the explanation that these assumptions are common knowledge in the field and are often required for accurate camera pose estimation and object segmentation. The reviewer provides logical reasoning to support their claim, making it 5.", "helpfulness_rationale": "The reviewer provides a clear and actionable point of feedback. They explicitly state that the strong assumptions limit the applicability of the methods to realworld problems. This information is directly helpful for the authors to understand the scope and limitations of their work and potentially identify areas for improvement or further research. The feedback is specific and directly addresses a potential weakness."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point does not explicitly state an action or suggest how to improve the paper. It raises a question about the feasibility of a query in a realistic scenario, but does not provide concrete steps or modifications to achieve this.", "grounding_specificity_rationale": "The reviewer's comment is 1 in a specific part of the paper. They are speculating about a potential application of the work, but the paper itself does not explicitly discuss query feasibility or realistic scenarios in detail. The comment does not mention any specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is more of a suggestion or question for the authors to consider a realistic scenario. There are no logical statements, common knowledge assertions, or external references provided in this review point.", "helpfulness_rationale": "The comment raises a valid point about the limitations of the paper's discussion regarding realistic scenarios. It encourages the authors to consider a potential application of their work. While it doesn't provide a solution, it does point to a potential area for improvement by highlighting a gap in the paper's framing."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states that the authors do not analyze the security of the proposed framework. This directly points out an action the authors should take. However, it doesn't provide specific details on *how* they should perform this analysis, making it somewhat vague on the implementation. Therefore, while it's clear what action needs to be taken, the lack of concrete steps makes it 3.", "grounding_specificity_rationale": "The comment refers to 'the security (i.e., protection of the privacy) of the proposed framework' generally, without specifying a particular section, table, or unique element of the paper. While it mentions 'privacy', it doesn't pinpoint where this aspect is discussed in the paper. Therefore, the grounding is weak as the authors have to infer where the security aspect is being addressed.", "verifiability_rationale": "The comment points out a missing analysis but doesn't provide any justification or reasoning for why this is a problem or what steps should be taken to address it. It's a statement of what's missing, not a claim requiring verification. Therefore, it lacks sufficient evidence to be considered verifiable.", "helpfulness_rationale": "The comment clearly identifies a significant area for improvement \u2013 the lack of security analysis. It directly tells the authors what they *should* be doing. While it doesn't specify *how* to perform the analysis, it provides a clear direction for the authors to follow. Therefore, it provides a clear and actionable feedback, making it 5 in guiding the authors towards addressing the identified weakness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need to 'explain the forwardprediction model'. This is a clear and direct action for the authors to take. The reviewer also mentions 'equations,' indicating they are aware of the mathematical details and need to be addressed. This action is also concrete, as the authors know exactly what needs to be explained: the mechanics and implications of the forward prediction model.", "grounding_specificity_rationale": "The reviewer points to 'Figure 2(b)' and suggests a 'redraw' of the schematic representation of the forward prediction model. This demonstrates a clear understanding of which specific part of the paper is being referred to. The reviewer also mentions 'equations,' indicating they are aware of the mathematical details and need to be addressed. This shows a high level of specificity in identifying the relevant parts of the paper and the information that needs improvement.", "verifiability_rationale": "The reviewer states that 'Figure 2(b) does not really show the schematic representation of the forward prediction model' and that 'the figure should be redrawn'. This implies that the current figure is either not accurately representing the model or is difficult to understand. While the review point itself doesn't contain a claim that needs verification, the reviewer's statement about the figure's quality and the equations' lack of connection suggests a lack of clear justification and support for the presented information.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as 'explain the forwardprediction model' and 'redraw Figure 2(b)'. These are actionable and directly address the identified issues. The reviewer also mentions the difficulty in connecting the 'pieces of the text with the figure as well as the equations', which highlights a clear need for improvement in the presentation and clarity of the information. The suggestions are also specific and concrete."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests improvements and connections to reinforcement learning but does not explicitly state what needs to be done or how to implement these suggestions. The action is implied rather than explicit.", "grounding_specificity_rationale": "The review point generally discusses the limitations of baseline methods and suggests future directions but does not pinpoint a specific section, table, figure, or unique aspect of the paper that needs improvement. The grounding is at a higher level, referring to the overall approach rather than a specific element.", "verifiability_rationale": "The review point makes a claim about the weakness of baseline methods but does not provide any specific evidence or reasoning within the review point itself to support this claim. The justification relies on the reader's general understanding of research evaluation and the implied need for stronger baselines.", "helpfulness_rationale": "The review point raises valid concerns about the limitations of the current work and suggests a relevant direction for future research (connection to reinforcement learning). It provides some direction for the authors to consider, even though it doesn't offer concrete steps for improvement within the review itself."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a weakness in the novelty/contribution of the method but does not specify how the network design should be improved or what concrete steps the authors should take.", "grounding_specificity_rationale": "The comment refers to the 'method' and 'network design' in general, without specifying a particular section, table, or figure. It lacks the specificity needed to pinpoint the exact aspect being discussed.", "verifiability_rationale": "The comment contains a claim about the incremental contribution of the method, supported by the mention of 'inspirations from prior work'. While it provides some justification, it could be more robust with specific examples.", "helpfulness_rationale": "The comment identifies a potential area for improvement (incremental contribution) and suggests a direction (drawing inspiration). However, it lacks specific details on how to implement this inspiration or what concrete changes the authors should make, making it 3 but lacking in specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states a limitation of a method. The phrase 'seems to only work for' directly identifies a constraint. The reviewer is providing a clear action: 'This method cannot be used if it cannot be finetuned as an in/outpainting model.' This action is not only explicit but also very concrete, as it clearly identifies the condition under which the method is not applicable.", "grounding_specificity_rationale": "The review point does not specify which method is being discussed. It is a general statement about a class of methods (generative models that can be finetuned as in/outpainting models). The reviewer is making a claim about the capabilities of these methods, not about a specific aspect of a particular method. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point makes a claim about the limitations of a method. It states that the method 'seems to only work for generative models that can be finetuned as an in/outpainting model.' This is a claim that is not supported by any evidence or reasoning within the review point itself. There is no logical reasoning, common knowledge, or external references provided to back up this statement. Therefore, the verifiability is 1.", "helpfulness_rationale": "The review point identifies a limitation of a method but does not offer any suggestions or actionable steps for the authors. It states that the method has a constraint related to finetuning. While this information is useful for the authors to understand the scope of the method, it does not provide any guidance on how to overcome this limitation or adapt the method. Therefore, the review point is not particularly helpful in improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment states \"The experimental setup, tasks, and other details are also moved to the appendix which makes it hard to interpret this anyway.\" This is a statement of a problem (the location of details makes interpretation hard) but doesn't directly tell the author what to do or where to find the information. There's no actionable step implied. The comment is about a location change, which could be considered implicit \u2013 the author could infer they need to move details back, but it's not explicitly stated. Even if we infer the need to move details back, the *how* isn't specified. Is it a specific section? A certain number of pages? The level of detail is unclear. Therefore, it's 1.", "grounding_specificity_rationale": "The comment refers to \"the experimental setup, tasks, and other details.\" While it mentions these broadly, it doesn't pinpoint *which* section or subsection of the paper these details are located. It's a general statement about the *content*.", "verifiability_rationale": "The review point itself doesn't contain a direct claim or suggestion. It's a statement of a problem (the location of details makes interpretation hard) but doesn't provide any evidence or reasoning to support it. While the reviewer *implies* the need to move details back is a good idea (making it \"helpful\"), the point itself doesn't *state* that. Therefore, it has X and is classified as **X (X)**.", "helpfulness_rationale": "The reviewer points out a practical issue: the difficulty of interpreting the experimental setup due to its location in the appendix. This is a valid concern for the authors. It directly affects the authors' ability to understand and potentially reproduce their work. This is a legitimate feedback point. While helpful, the *degree* of helpfulness is subjective. It's a valid concern but doesn't offer a specific solution. Therefore, it's **3**. It highlights a practical issue that could hinder interpretation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point states \"It would be helpful if you provided glosses in Figure 2.\" This comment clearly identifies an action that needs to be taken (adding glosses) and specifies the location where these glosses should be added (Figure 2). While the comment doesn't explicitly state *how* to add the glosses, it does provide a clear direction for the author's revision. Therefore, it can be considered explicit in identifying the action and the location.", "grounding_specificity_rationale": "The review point states \"It would be helpful if you provided glosses in Figure 2.\" The comment explicitly refers to 'Figure 2' as the specific part of the paper where the glosses should be added. This direct reference allows the author to precisely identify the section being addressed. Therefore, the grounding is explicit and specific.", "verifiability_rationale": "The review point states \"It would be helpful if you provided glosses in Figure 2.\" This statement is a suggestion or recommendation, not a claim that something is wrong or needs fixing. There is no logical reasoning, common knowledge, or external references being made. The comment is simply stating a helpful suggestion. Therefore, it does not contain a claim that requires verification.", "helpfulness_rationale": "The review point states \"It would be helpful if you provided glosses in Figure 2.\" This is a direct and focused suggestion for the author to improve their draft by adding glosses to a specific figure. While it doesn't explain *why* this is helpful or *how* to add the glosses, it clearly identifies a specific area for improvement. Therefore, it is a helpful suggestion, although it could be more detailed."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a gap in the literature but doesn't explicitly state how the authors should address it. The action is implied but not directly stated.", "grounding_specificity_rationale": "The comment refers to 'Memb' without specifying which part of the paper or context it relates to. It also doesn't identify a specific issue within that part.", "verifiability_rationale": "The comment makes a claim about the lack of a reference but doesn't provide direct evidence or logical reasoning within the review point to support this claim.", "helpfulness_rationale": "The review point identifies a potential problem (lack of reference) but doesn't offer concrete solutions or actionable steps for the authors to take."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment suggests a *direction* for research but doesn't provide a specific *action* or *change* to be made in the current draft. It proposes studying the impact of the ratio of unseen classes, which is a suggestion for future experimentation rather than a direct instruction on how to improve the current draft.", "grounding_specificity_rationale": "The comment refers to \"unseen classes\" generally, without specifying which part of the reviewer's paper this relates to. It's a concept in machine learning but lacks a direct link to a specific section, table, figure, or unique element in the reviewer's paper.", "verifiability_rationale": "The point is a suggestion for future work, not a claim about the current paper's state or a problem it contains. It doesn't make any assertions about the current work's quality or identify any flaws based on the suggestion itself.", "helpfulness_rationale": "The review point identifies a valuable research direction (impact of unseen class ratios) and suggests potential improvements in handling imbalanced datasets. While it doesn't directly tell the author how to implement this, it points towards a relevant problem and a potential solution avenue, making it 4 for guiding future research."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "2: 3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states their overall assessment of the method's novelty. This is explicit. However, the reviewer does not specify *how* the combination of GCN and normalizing flow is implemented or where the Gaussian mixture modification fits in. The connection between these elements is implied but not explicitly stated. The reviewer also states their assessment of the method's novelty, which is a direct action.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a *specific* part of the paper where this lack of novelty is occurring. They offer a general assessment of the method. While they mention \"the ultimate transformed distribution,\" they don't explicitly link this to a specific part of the proposed method.", "verifiability_rationale": "The reviewer makes a claim about the \"lack of enough new stuffs here,\" which can be interpreted as a claim about the quality or contribution of the work. However, the reviewer does not provide concrete evidence or reasoning to support this claim. They don't point to specific implementation details or cite relevant literature to back up their assertion. The reasoning is speculative and lacks external references.", "helpfulness_rationale": "The reviewer provides a clear and concise critique. They identify a potential weakness in the method's novelty. This is directly helpful for the authors. The criticism is actionable and identifies a potential area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer states their opinion about the discussion section being 'vital' and 'needs more clarity'. This indicates a clear intention to improve the discussion. However, the reviewer does not explicitly state which part of the framework or the discussion section is lacking clarity or what specific action should be taken. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer refers to the 'discussion section' and the 'framework' when stating that the discussion section needs more clarity and differentiation. This shows a clear identification of the specific part of the paper being addressed, making it fully grounded. The reviewer also specifies what the discussion section should achieve ('help this paper to be distinguished from the other related work'), which adds to the specificity.", "verifiability_rationale": "The reviewer makes a claim that the discussion section needs more clarity and differentiation. This claim is verifiable if the paper's discussion section indeed lacks these qualities. The reviewer provides a reason for this lack of clarity ('I didn\u2019t find clear answer in the discussion') and suggests a goal ('to be distinguished from the other related work'). While the reasoning could be more detailed, the claim itself is stated and the elements of verifiability are present.", "helpfulness_rationale": "The reviewer's point directly addresses a potential weakness in the paper's presentation and impact. They are highlighting a lack of clarity in the discussion section, which could hinder the reader's understanding and the paper's ability to differentiate itself. This is a clear and actionable feedback for the authors, making it 5 in identifying a specific area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The reviewer identifies a weakness in the paper's analogy to HOI analysis and Harmonic analysis, stating that the link is 'quite weak'. While the reviewer points to specific areas of concern ('the limited number of \"basis\" in the paper's context' and 'the disconnect between the decomposition/integration steps and Fourier analysis'), they do not explicitly state what specific action the authors should take to improve the analogy. The reviewer suggests the analogy is 'interesting at first glance' but doesn't provide a concrete alternative or actionable suggestion within the review point itself.", "grounding_specificity_rationale": "The reviewer mentions \"HOI analysis\" and \"Harmonic analysis\" as the concepts being compared, which provides some level of grounding. However, they do not explicitly state which specific aspects of these analyses are weakly grounded in the paper's context. The connection to the paper's specific decomposition/integration steps is implied but not explicitly stated as a direct link within the review point. The reviewer points to 'the limited number of \"basis\"' and 'the disconnect between the decomposition/integration steps and Fourier analysis' as areas of weakness, which adds a degree of specificity to the grounding concern.", "verifiability_rationale": "The reviewer makes a claim by stating that 'The analogy between HOI analysis and Harmonic analysis is interesting at first glance, but the link is quite weak'. However, they do not provide any external references or logical reasoning to support this claim within the review point. The reviewer expresses a general disappointment with the paper's framing but does not offer any specific evidence or justification for why they believe the link is weak.", "helpfulness_rationale": "The reviewer's point is clearly critical. They express disappointment with the paper's analogy to HOI analysis and Harmonic analysis, stating that the link is 'quite weak'. They also highlight the disconnect between the decomposition/integration steps and Fourier analysis. This critique directly points to a deficiency in the paper's presentation and connection to existing work. The reviewer does not offer any suggestions for improvement or actionable steps for the authors. The overall tone and content of the review point strongly suggest it is not helpful for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation of a model but does not explicitly state how this limitation affects the reviewer's own work or propose a solution. The statement is a general observation about the model's behavior, not a specific actionable item for the reviewer to address in their own draft.", "grounding_specificity_rationale": "The reviewer mentions 'Figure 3 of INs,' which provides a specific reference point. However, they do not explicitly identify a specific part of the reviewer's own paper that is being addressed. The comment is about a general issue related to the referenced figure, not a specific element within the reviewer's own submission.", "verifiability_rationale": "The statement 'The number of entities is fixed and it's not clear how to generalize a model to different numbers of entities (e.g., as shown in figure 3 of INs)' presents a problem or limitation. However, it does not contain a claim that can be verified through logical reasoning, common knowledge, or external references. It's a statement of difficulty without further elaboration or evidence.", "helpfulness_rationale": "The reviewer is seeking clarification on a technical issue. While this can be helpful for understanding, it does not directly suggest improvements or actionable steps for the reviewer's own draft. The feedback is about a limitation rather than a critique or suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out the 'little novelty' and 'incremental improvement' of the work compared to KNN MT, suggesting that if there's no code release after revision, this weakness stands. While the reviewer identifies a weakness and links it to a potential consequence (code release), the suggestion to review the code is an implicit action rather than an explicitly stated action. The weakness itself is stated, but the connection to a concrete action isn't fully explicit.", "grounding_specificity_rationale": "The reviewer mentions 'KNN based MT approach' and 'incremental improvement,' which grounds the criticism to a specific technique and its nature. However, they do not specify which particular part of the KNN MT implementation or results is lacking. The weakness is described in general terms ('incremental improvement', 'little novelty'), making it somewhat specific but not fully specific.", "verifiability_rationale": "The reviewer states a weakness ('little novelty') and offers a hypothetical consequence ('if there's no code release after the revision process, then this weakness stands'). This statement is a claim. However, the reviewer does not provide any evidence, reasoning, or external references to support this claim. The connection to verifiability is implied but not explicitly stated or justified.", "helpfulness_rationale": "The reviewer clearly states their opinion about the weakness ('little novelty') and its impact on the authors ('nitpicking esp when I personally execution (replicable) beats idea (novelty)') and the importance of the weakness given the lack of code release. The reviewer's statement directly addresses the authors' work and its perceived limitations, making the feedback highly relevant and actionable for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests an action: 'I believe the FlippedQA is a general framework for various generative VideoQA models. However, the authors only apply this framework to LLMbased models. It would be better to further verify the effectiveness and universality to nonLLMbased models like HiTeA and InternVideo.' This direct suggestion of evaluating FlippedQA on HiTeA and InternVideo makes it 5.", "grounding_specificity_rationale": "The review point explicitly mentions 'nonLLMbased models like HiTeA and InternVideo'. This precise identification of the models being considered demonstrates strong grounding specificity.", "verifiability_rationale": "The review point presents a claim: 'However, the authors only apply this framework to LLMbased models. It would be better to further verify the effectiveness and universality to nonLLMbased models like HiTeA and InternVideo.' This claim, while not providing direct evidence, sets up a question for the authors to investigate and potentially verify through experimentation with the suggested models. Therefore, it is 3 as it points to a potential area for further investigation and validation.", "helpfulness_rationale": "The review point directly suggests a helpful next step for the authors: 'It would be better to further verify the effectiveness and universality to nonLLMbased models like HiTeA and InternVideo.' This clear and actionable suggestion makes the review point 5 in guiding the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point suggests an action (additional experiments) but lacks specifics on *how* to conduct these experiments or what results are needed. The suggestion is implied rather than explicitly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"realistic noisy datasets\" and provides a specific example, \"WebVision,\" clearly identifying the part of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim about the potential benefits of additional experiments but provides no supporting evidence, reasoning, or references to back this assertion.", "helpfulness_rationale": "The review point identifies a potential improvement (additional experiments) but lacks the specifics needed to be fully helpful. While it points in a useful direction, it doesn't provide concrete steps or criteria for success, making it somewhat, but not fully, helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states their concern about the importance of the result, which is an explicit action. However, the reviewer does not specify *how* the result is surprising or what specific aspect of the result is unexpected. The action is stated, but the details are missing, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions the iteration complexity result from 15 and explicitly states it's 'almostdimension free.' This demonstrates that the reviewer can identify the specific part of the paper being addressed (the iteration complexity result). Furthermore, the reviewer highlights the change in dimensionfree property in Theorem 3, which clearly specifies what needs to be addressed. This shows strong grounding and specificity.", "verifiability_rationale": "The reviewer states that the result is 'not surprising' and that the change in dimensionfree property is 'not surprising.' This constitutes a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support their claim. The claim is stated, but there is no justification provided.", "helpfulness_rationale": "The reviewer is concerned about the importance of the result and points out that the findings are similar to those in 15. This is a statement of concern and a potential lack of novelty. While the reviewer is trying to help the authors understand the significance of their work, they do not offer concrete suggestions or improvements based on this insight. The reviewer is more of a pointer than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out potential issues with 'soft labels' and its impact on 'AUC' and mentions 'subpar hyperparameters'. While these are areas of concern, the reviewer does not explicitly state that the authors are using subpar hyperparameters or that soft labels are negatively impacting performance. The reviewer is suggesting possibilities rather than directly identifying a specific action the authors should take. The connection between the reviewer's comments and concrete, actionable steps for the authors is not explicitly stated.", "grounding_specificity_rationale": "The reviewer mentions 'soft labels' and 'AUC', which could be interpreted as referring to specific sections or tables if the paper is wellorganized. However, the reviewer does not explicitly state which part of the paper they are referring to. The mention of 'subpar hyperparameters' and the interpretation of the plots as 'looking like a higher beta value would be directly on top' are general statements and lack specific grounding within the paper's content.", "verifiability_rationale": "The reviewer states concerns about 'soft labels' and its impact on 'AUC', and suggests 'higher beta values'. These are statements of concern and potential improvements, but the reviewer does not provide any specific evidence or references to support these claims within the review point itself. The statements are presented as possibilities rather than verifiable claims.", "helpfulness_rationale": "The reviewer raises concerns about the 'soft labels' implementation and its impact on the 'AUC' metric. They also suggest that the 'plots look like a higher beta value would be directly on top'. While these points highlight potential areas for improvement, they are not direct critiques of the presented methodology or results. The reviewer's suggestions are more about alternative approaches rather than a clear and actionable critique of the authors' work. The helpfulness is limited as the reviewer is more suggestive than critical."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly mentions the number of images in the VioT dataset (20 images per category) and then states their concern about this number. While they don't explicitly say 'improve the draft,' the implication is that this limitation should be addressed. The action is implied but not explicitly stated as a concrete action to be taken by the authors.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'VioT dataset' and its '20 images in each of the 4 categories'. They also directly link this to the 'text the validity of the approach'. This clearly identifies the specific part of the paper being addressed and what aspect of it is being questioned. The grounding is explicit and accurate.", "verifiability_rationale": "The reviewer states their concern about the dataset size affecting the 'validity of the approach' and the 'text the validity'. This is a claim that needs to be supported. However, the review point itself does not provide any logical reasoning, common knowledge, or external references to back up this claim. The claim is presented without sufficient evidence to verify it.", "helpfulness_rationale": "The reviewer points out a potential limitation of the study (small dataset size) and questions its impact on the evaluation. While this is a valid concern, the review point itself does not offer any specific suggestions or feedback on how the authors should address this limitation or improve their methodology. It's a general comment about the experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an \"ablation study\" and asks about the \"number of layers vs perf.\" While this is a concrete suggestion related to the technical aspects of the work, it doesn't directly instruct the authors on how to improve their current draft. The reviewer is proposing a future experiment rather than providing actionable feedback on existing weaknesses.", "grounding_specificity_rationale": "The review point is a general suggestion about an ablation study. It doesn't explicitly refer to a specific section, table, figure, or unique aspect of the authors' paper. The reviewer is making a comment about the general nature of sequence tagging models and their potential limitations, not about a specific issue within the authors' work.", "verifiability_rationale": "The review point itself doesn't contain a claim or assertion that requires verification. It's a suggestion for an experiment. The reviewer is making the claim that such an ablation study would be interesting, but the review point itself doesn't make that claim.", "helpfulness_rationale": "The review point suggests an interesting experiment but doesn't directly address potential weaknesses or improvements in the authors' current draft. While the suggestion is relevant to the field and could potentially lead to valuable insights, it doesn't immediately provide actionable feedback on how to enhance the authors' existing work. It's more of a suggestion for future research or analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need for 'more intuitive explanations' and 'additional explanations and legends'. These are direct actions the authors should take. While the level of detail isn't specified, the request is clear enough to guide action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure captions are lacking' and 'explain the colors in Fig. 2'. This directly identifies the specific parts of the paper (Figures 1 and 2) and what is missing (lacking captions and color explanations). The authors can easily identify the referenced parts and the specific issues.", "verifiability_rationale": "The reviewer states a need for 'intuitive explanations' and 'explanations and legends'. While the reviewer doesn't provide explicit justification for *why* these explanations are needed, the request itself is a claim that needs to be addressed. The impact on understanding is implied, but the *justification* for *why* these explanations are needed isn't deeply explored in the review point itself.", "helpfulness_rationale": "The reviewer clearly identifies areas for improvement in the paper's clarity and provides specific suggestions for addressing those areas. The request for intuitive explanations and figure legends are actionable and directly aimed at improving understanding. While the implementation details are left to the authors, the *nature* of the suggestions is clear and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point asks 'how sensitive are the empirical results to hyperparameter choices.' This is a question, not a direct instruction. While it points to a potential issue, it doesn't * tell the author *what to do*. For example, it doesn't say 'Check your learning rate' or 'Try different batch sizes.' Therefore, it's not explicitly stating an action to take, making it not fully actionable. However, it does point towards a potential area for improvement, making it borderly actionable.", "grounding_specificity_rationale": "The review refers to 'hyperparameter choices' generally. It doesn't specify *which* hyperparameters are being questioned. Were learning rates, batch sizes, optimizer settings, or something else involved? The paper doesn't provide enough detail to pinpoint the exact location. Similarly, while it mentions 'empirical results,' it doesn't specify *which* results or *why* they might be sensitive. While it implies a problem, it doesn't detail the nature of the sensitivity. Therefore, the grounding of the point is weak as it doesn't clearly identify the specific aspect of the hyperparameters or the results being discussed.", "verifiability_rationale": "The review point itself doesn't contain a claim or opinion. It's a question about the sensitivity of the results to hyperparameter choices. However, the reviewer *implies* that this is a concern, suggesting it *could* be an issue. While the point isn't a direct claim, the reviewer's willingness to reconsider their rating suggests they *believe* there's a problem. This makes it 2. A strong verifiable point would explicitly state something like, 'The reported accuracy is significantly lower than previous studies' or 'The model's performance drops when using batch sizes larger than 256.' The reviewer's statement is more of a deduction or inference rather than a direct claim supported by evidence within the review point itself.", "helpfulness_rationale": "The review point raises a crucial issue (hyperparameter sensitivity affecting results) and even offers a concrete suggestion: 'I will be willing to reconsider my rating if this particular issue is resolved.' This shows the reviewer is actively engaged and wants to address the problem. By offering a concrete action, they are providing a clear direction for the authors to investigate and potentially address the issue. This makes the review point 5 as it identifies a significant concern and offers a direct path for the authors to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the use of existing attack methods and the similarity to using the transferability of adversarial examples. This directly implies a need for the authors to highlight the novelty and contribution of their method. Therefore, it is an explicit statement that guides the authors to focus on their unique aspects.", "grounding_specificity_rationale": "The review point mentions 'existing attack methods,' 'surrogate model,' and 'transferability of adversarial examples.' While it identifies the concepts involved, it doesn't explicitly pinpoint a specific part of the paper where this similarity is a problem. The authors can infer the issue but cannot confidently determine the exact location. Therefore, the grounding is weak.", "verifiability_rationale": "The review point makes a claim about the use of existing attack methods and the similarity to using the transferability of adversarial examples. This claim can be supported by common knowledge in the field of adversarial attacks and transferability. The reasoning is based on established practices, making it verifiable.", "helpfulness_rationale": "The review point clearly identifies a potential weakness in the authors' approach by pointing out the reliance on existing methods and the similarity to known techniques. This directly guides the authors to focus on their novelty and unique contributions, making it 5 for their improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issues and the actions to be taken (increase font size, add gradient symbol). This is a direct and concrete action.", "grounding_specificity_rationale": "The reviewer mentions \"table 1\" and \"Algorithm 1,\" accurately identifying the specific sections. The issues within these sections are also specific.", "verifiability_rationale": "The reviewer states that the text is \"hard to read\" and the symbol is \"missing\" without providing any further explanation or evidence. There's X being supported by reasoning or references.", "helpfulness_rationale": "The reviewer points out specific issues with readability and missing elements. While actionable, the feedback lacks a broader explanation of why these issues are important or how they affect the work. It's a direct fix but not a comprehensive analysis."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point implicitly suggests an actionable point by asking a specific question about a technical detail (parameter sharing) and proposing a relevant baseline experiment. While it doesn't explicitly state 'how to fix this', the question and suggestion are actionable in the sense that they prompt the authors to consider a different design choice and potentially improve their work by incorporating insights from a related field. The reviewer is essentially asking how the current design could be improved by considering a different approach.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 7.1' and the 'ResNet' within that section, clearly identifying the part of the paper being addressed. They also specify the 'potential for a deeper ResNet with parameter sharing' and even connect it to a related field (ODEs). This demonstrates high grounding specificity as the authors can easily identify the referenced part and the issue being raised.", "verifiability_rationale": "The review point primarily asks a question and suggests a potential improvement or alternative approach. It does not make a claim that something is wrong with the current ResNet or explicitly state why it's a bad design. While the suggestion to compare with a deeper ResNet with parameter sharing could be considered verifiable by citing literature on ODE networks, the core of the point is a question and a suggestion, not a definitive statement requiring evidence. Therefore, it's more of a 2 point as it could be supported by external references but doesn't present a clear claim that needs verification.", "helpfulness_rationale": "The review point is 5 because it directly addresses a specific technical detail in the paper (parameter sharing in the ResNet) and suggests a relevant baseline experiment. By asking how the ResNet could be improved by considering a deeper ResNet with parameter sharing and connecting it to ODEs, the reviewer is encouraging the authors to think critically about their architectural choices and explore alternative approaches. This type of feedback is valuable because it prompts the authors to consider a different design and potentially improve their work by incorporating insights from a related field. It doesn't criticize the current approach but rather suggests a constructive direction for future work."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "Weakly Verifiable", "helpfulness_label": "1", "actionability_rationale": "The reviewer is asking for a specific explanation of how the proposed method produces the explanation in Figure 1, specifically identifying the NO2 group. While the paper describes the method's ability to identify patterns, it doesn't explicitly detail the mechanism for linking those patterns to the specific chemical group in the figure. The reviewer's suggestion of 'additional adhoc postanalysis' is not explicitly stated as necessary by the method description, making the action implicit rather than explicit. The concreteness of the action is also lacking as the exact steps for extracting the shared motifs are not provided.", "grounding_specificity_rationale": "The reviewer is asking the authors to identify the specific part of the paper where the explanation for Figure 1 can be found. The explanation is not explicitly linked to a specific section, table, or figure within the paper. While the reviewer might infer the explanation is related to Figure 1, they cannot confidently pinpoint the exact location. The specificity of the explanation is also lacking as the paper doesn't detail how the NO2 group is identified within the figure.", "verifiability_rationale": "The reviewer is making a claim about the proposed method's ability to produce an explanation for Figure 1, specifically identifying the NO2 group. However, the paper does not provide explicit verification or justification for this claim. The method description focuses on identifying patterns but doesn't detail how the specific chemical group is extracted or validated. There are no external references or logical reasoning provided to support the claim's verifiability.", "helpfulness_rationale": "The review point is unclear and requires additional steps to understand how the proposed method produces the explanation for Figure 1. The reviewer suggests an 'additional adhoc postanalysis' to extract shared motifs, which is not explicitly mentioned as necessary by the method description. This lack of clarity and the implied need for extra work make the review point unhelpful for the authors in directly improving their draft. The authors would need to spend more time deciphering the method's application to understand the reviewer's concern."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "None", "actionability_rationale": "The comment explicitly states that nonconvexity may not be an issue for SGD convergence if the function Z has 'good properties'. This is a direct identification of a potential action, but the action is vague as it doesn't specify what constitutes 'good properties'.", "grounding_specificity_rationale": "The comment explicitly mentions 'the function Z', which is a specific part of the paper. However, it does not specify which part of the paper 'Z' refers to, nor does it detail what constitutes 'good properties' for Z. Therefore, while it identifies the specific part, it doesn't fully ground the specific issue within that part.", "verifiability_rationale": "The comment contains a claim: 'Nonconvexity may not be an issue for the SGD to converge, if the function Z has some good properties.' However, it does not provide any specific examples or references to external works to support this claim within the review itself. The reasoning is presented as a suggestion rather than a verified statement.", "helpfulness_rationale": "The comment raises a valid point about the potential impact of nonconvexity on SGD convergence, which could be helpful for the author to consider. However, it lacks specific details and examples to be fully constructive and actionable for the author."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states \"The experimental settings are not mentioned properly\" and \"The author does not provide the code.\" These are clear statements identifying a problem and suggesting a concrete action: the authors should check the experimental settings and obtain the code. The lack of specific details about what is missing makes it somewhat vague, but the action is still identifiable.", "grounding_specificity_rationale": "The review point mentions \"experimental settings\" and \"code\" generally. While it points to a deficiency, it doesn't specify *which* experimental settings are missing or *which* specific code is missing. This makes the grounding somewhat weak.", "verifiability_rationale": "The review point contains a claim: \"The experimental settings are not mentioned properly\" and \"The author does not provide the code.\" However, it does not provide any evidence or justification for why these settings are improper or why the code is missing. It simply states the problem.", "helpfulness_rationale": "The review point identifies a critical issue: the lack of proper experimental settings and the absence of code, which is essential for reproducibility. While it doesn't provide specific guidance on how to check the settings or obtain the code, it highlights a significant missing piece of information that is crucial for the authors to be able to reproduce and build upon their work. This makes it moderately helpful."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests the main text should be clearer about the additional experiments in the supplement. While the reviewer proposes an action (improving clarity), they do not explicitly state *where* in the main text these experiments should be discussed or *what specific changes* should be made. The action is implied but not directly stated, making it less actionable for the authors.", "grounding_specificity_rationale": "The reviewer's comment implies that the additional experiments in the supplement are relevant. However, they do not explicitly identify the specific section, table, figure, or unique aspect of the paper where these experiments are discussed or summarized. The grounding is implied but not precise, making it weakly grounded.", "verifiability_rationale": "The reviewer's comment does not contain a claim that *something is wrong* with the main text. Instead, they are suggesting an improvement to the clarity of the presentation. Therefore, it does not fall under the 'Verifiability' aspect, which focuses on the presence and support of claims. The comment is a suggestion, not a critique requiring verification.", "helpfulness_rationale": "The reviewer's comment is valuable as it points out a potential area for improvement in the clarity of the paper. By suggesting that the main text should be clearer about the supplement, they are offering a constructive suggestion that could benefit the authors. However, the comment itself does not provide specific, actionable steps for the authors to take. It's a suggestion for improvement, not a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a discrepancy between the experimental results and a claim about the prompts' effectiveness. While it suggests the authors should reevaluate, it doesn't explicitly state the *how* of this reevaluation, making the action implicit and the implementation vague. Therefore, it's Partially Actionable.", "grounding_specificity_rationale": "The reviewer refers to \"our proposed prompts\" generally and points to Tables 6 and 7. While it mentions the tables, it doesn't specify the exact section or table within the prompt description where the issue lies. The grounding is present in identifying the general area and specific tables, but lacks pinpoint accuracy. Therefore, it's 2.", "verifiability_rationale": "The reviewer makes a claim about the experimental results not supporting the effectiveness claim. This claim requires external references (the data in Tables 6 and 7) or logical reasoning to be fully verified. Within the scope of this review point, there's no internal justification provided. Therefore, it's 1.", "helpfulness_rationale": "The reviewer raises a valid concern about the overstatement of the prompts' effectiveness based on the presented results. This highlights a potential area for improvement in the original paper's claims and could be helpful for the authors to consider. While it doesn't offer a direct solution, it points to a potential misinterpretation. Therefore, it's 3."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the current method of aligning features and suggests exploring alternative designs by varying sampling intervals and sample size. This provides a clear direction for improvement, making it actionable. The reviewer identifies the area of concern (Cycle FC alignment) and proposes a concrete way to address it by experimenting with different parameters.", "grounding_specificity_rationale": "The reviewer mentions 'sampling intervals' and 'sample size' as potential areas for improvement. This directly points to specific aspects of the model or experiments, providing strong grounding. The reviewer not only identifies the area of concern but also specifies the parameters to be analyzed.", "verifiability_rationale": "The reviewer presents a suggestion to explore alternative designs. This constitutes a claim that further experimentation is needed. The reviewer also provides specific examples of how to explore these designs, namely by conducting experiments or analysis with different sampling intervals and sample size, which serves as clear justification and guidance.", "helpfulness_rationale": "The reviewer provides a clear direction for the authors to explore alternative design choices. This is a valuable piece of feedback as it guides the authors to further investigate and potentially improve the model's architecture or training process. While it doesn't offer a definitive solution, it points towards a concrete next step for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the absence of standard deviations and the consequence of this absence on the certainty of the best method. The statement 'Thus, we are not sure if the best method is really the best or if many other RF configurations have performances close to the best one' is a direct consequence of the lack of standard deviations and implies a concrete action: to better understand the performance distribution, standard deviations are needed.", "grounding_specificity_rationale": "The reviewer explicitly states 'No standard deviations are displayed' which directly identifies the specific aspect of the paper being addressed. This is a literal mention of a specific part of the paper. The reviewer also implies the consequence for the 'best method', which is a specific issue within that part. Therefore, the grounding is fully grounded. The statement 'Thus, we are not sure if the best method is really the best or if many other RF configurations have performances close to the best one' clearly specifies what needs to be addressed (uncertainty about the best method).", "verifiability_rationale": "The reviewer makes a claim: 'No standard deviations are displayed' and infers a consequence: 'Thus, we are not sure if the best method is really the best or if many other RF configurations have performances close to the best one.' While the reviewer states the observation clearly, they do not provide a logical reasoning or external references to support the inference about the uncertainty of the best method. The connection is implied but not explicitly verified.", "helpfulness_rationale": "The reviewer points out a limitation in the presented information (lack of standard deviations) and suggests that this limits the ability to definitively identify the 'best method'. While the review highlights a valid concern, it doesn't offer specific, actionable steps for the authors to take based *solely* on the information provided in the review point. The suggestion to 'better understand the performance distribution' is a potential action but not a direct solution based on the lack of standard deviations alone."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a need for more implementation details, which is a helpful action for authors. However, it doesn't specify *how* to provide these details, making it only 3.", "grounding_specificity_rationale": "The review point is vague and doesn't specify *where* in the paper computation/algorithm/implementation details are missing. It also doesn't define the *nature* of these missing details, making it neither grounded nor specific.", "verifiability_rationale": "The review point is a suggestion for improvement, not a claim that needs verification. Therefore, it doesn't fall under the 'X' category.", "helpfulness_rationale": "The review point identifies a valid need for clarity and provides a helpful direction. However, the lack of specificity makes it less helpful than it could be."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the actions the authors should take: 'explain why there are negative numbers in Figure 1' and 'analyze the implications of Figure 2 and Figure 3.' These actions are direct and do not require inference. The reviewer also provides specific examples of what to explain and analyze, making the actions concrete.", "grounding_specificity_rationale": "The reviewer directly refers to 'Figure 1,' 'Figure 2,' and 'Figure 3' by name. This explicit referencing clearly identifies the specific parts of the paper being addressed. The reviewer also specifies what needs to be explained and analyzed within these figures, adding to the specificity of the comment.", "verifiability_rationale": "The reviewer makes a claim that the figures need explanation and analysis. While the review point itself doesn't provide the justification, the specific requests for explanation and analysis serve as implicit verification that the information presented in the figures is not readily apparent or understood. The reviewer provides clear reasoning and precise explanations of why these actions are needed.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper: the lack of explanation and analysis for the figures. The reviewer also provides a clear and actionable suggestion: 'explain why there are negative numbers in Figure 1' and 'analyze the implications of Figure 2 and Figure 3.' This is a 5 and specific suggestion that directly addresses the identified weakness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point mentions the absence of an ablation study but doesn't explicitly state what is missing or how to perform it. The action of 'learning with MMD' is implied, but the specific ablation being referred to is not clearly defined. The reviewer suggests alternatives, implying the current draft lacks something related to MMD ablation, but the exact nature of the missing ablation is not explicitly stated as an action.", "grounding_specificity_rationale": "The review point explicitly mentions 'ablation study' and then provides two specific examples of what could be ablated ('typical knowledge distillation loss' and 'distilling a Hydra architecture with MMD loss) in relation to the 'MMD component'. This clearly identifies the specific part of the paper being addressed and the issues with it.", "verifiability_rationale": "The review point makes a claim: 'Without an ablation study, it is hard to see the net effect of each component.' It then suggests alternative ablation targets ('typical knowledge distillation loss' and 'distilling a Hydra architecture with MMD loss) as ways to address this. While it doesn't provide a definitive proof that the current draft lacks an ablation study, it offers a suggestion for improvement, indicating a degree of verifiability.", "helpfulness_rationale": "The review point clearly identifies a potential weakness in the draft: the lack of an ablation study for the MMD component. It then offers concrete suggestions for what the ablation could involve. This directly addresses a likely area for the authors to need clarification or guidance on how to improve their experimental setup and analysis."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the 'shrinking' advantage and the 'remains to be seen' about the future scalability. This is an explicit statement of a trend and a question. While the reviewer points to a specific comparison and table, the action for the authors is not directly stated. The authors would need to infer that the data in Tab. 2 supports the claim about the shrinking advantage and that the question about scalability implies a need for further investigation.", "grounding_specificity_rationale": "The review point explicitly mentions 'RLCD,' 'RLAIF,' '7B,' '30B,' and 'Tab. 2.' This clearly grounds the comment in specific elements of the paper. The reviewer also implies a question about future scalability, which can be inferred from the mentioned elements. The authors can deduce that the data in this table is relevant to the comparison of model sizes.", "verifiability_rationale": "The review point makes a claim about the data in Tab. 2. This claim can be verified by examining the table itself. The reasoning is logical \u2013 if the table shows a shrinking advantage, that's the evidence. The claim is supported by the direct presentation of data in the table. The reviewer doesn't introduce external references, but the information is directly available in the paper.", "helpfulness_rationale": "The review point highlights a trend observed in Tab. 2 and raises a question about the scalability of RLCD. This observation is relevant to researchers working with large language models and understanding model capabilities. However, the review point does not directly instruct the authors on how to address the shrinking advantage or the implications of the question about scalability. The authors would need to interpret the meaning and relevance of this observation themselves."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the need to 'take into account the time for COLMAP and scenebyscene finetuning'. This is an explicit action. However, the reviewer does not specify *how* this time should be considered. The action is implied but not concretely defined.", "grounding_specificity_rationale": "The reviewer mentions 'COLMAP' and 'scenebyscene finetuning', which are specific terms related to the methods. However, the reviewer does not explicitly state which *section* of the paper describes these methods. The grounding is weak because the authors need to search for these terms to find the relevant section.", "verifiability_rationale": "The reviewer makes a judgment that 'rendering the method less efficient for these scenes'. This is a claim. However, the reviewer does not provide any specific evidence or logical reasoning to support this claim. It is presented as an observation rather than a welljustified statement.", "helpfulness_rationale": "The review point is clear and directly addresses a potential issue with the experimental setup. It suggests considering the time factor in the comparison, which is a relevant and actionable suggestion for the authors. While it doesn't provide a specific solution, it points towards a necessary consideration."}
{"actionability_label": "4", "grounding_specificity_label": "3: 4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point directly addresses a specific question about the contribution of different factors to the model's performance. It identifies 'noise' and 'exponential moving average' as key factors and asks about their individual contributions. This is an explicit action with clear instructions on how to identify the action: 'how much gain can be obtained by just using a noisefree exponential moving average compared to the current model with noise?' The action is also concrete as it specifies the comparison to be made.", "grounding_specificity_rationale": "The review point explicitly mentions the two factors being considered: 'noise' and 'exponential moving average'. It also asks a specific question about their individual contributions. This directly targets a specific part of the model and its behavior. The grounding is explicit as it names the specific elements being discussed.", "verifiability_rationale": "The review point poses a question that could potentially be answered through further experimentation or analysis. While it's not a definitive statement with immediate evidence, it's a suggestion for future work. The verifiability relies on the authors conducting further experiments to determine the individual contributions of 'noise' and 'exponential moving average'. The evidence is logical and based on the understanding of these factors in the context of model training. The review provides a clear direction for verification.", "helpfulness_rationale": "The review point raises a question that, if answered, could significantly improve the model. It highlights a potential area for improvement and encourages further analysis. While it doesn't directly *teach* them something, it *guides* them towards a valuable direction for investigation. The feedback is relevant to the model's design and performance. It encourages the authors to explore the impact of noise and the moving average component separately."}
{"actionability_label": "X", "grounding_specificity_label": "X", "verifiability_label": "X", "helpfulness_label": "X", "actionability_rationale": "The review point does not explicitly state what the authors should do. It highlights a limitation in the current reporting practice and proposes a hypothesis about early training. There is no direct instruction or action implied.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or concept being addressed. While the second part of the review mentions 'early in training' and 'model parameters', it doesn't pinpoint a specific section, table, or figure. The first part is also vague.", "verifiability_rationale": "The review point does not contain a claim that can be verified. The first part is a statement of fact about the current reporting practice. The second part is a hypothesis ('I presume'), which is not a verifiable claim.", "helpfulness_rationale": "The review point does not offer concrete, actionable feedback or suggestions that would empower the authors to improve their draft. It points out a limitation and proposes a hypothesis, but doesn't provide a clear path forward or specific advice on how to address the issues."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the performance gain is 'mostly from PBSD' and asks a direct question about 'any other motivations for PBSD?'. This provides clear guidance for the authors to investigate and explain the contribution of PBSD beyond its known benefits.", "grounding_specificity_rationale": "While the reviewer refers to the 'main contribution' and 'this paper', they also specify the 'ablation study results' and the 'motivation related to supervised contrastive learning and tail classes'. This indicates a degree of specificity in the area being discussed, although it doesn't pinpoint a specific section or table within the paper.", "verifiability_rationale": "The reviewer makes a claim based on the ablation study results ('From the ablation study, we can see the performance gain is mostly from PBSD') and poses a question ('any other motivations for PBSD?'). While the claim is supported by the ablation study, the question itself doesn't have direct evidence within the paper.", "helpfulness_rationale": "The reviewer raises a valid point about the potential mismatch between the stated motivation (supervised contrastive learning) and the actual contribution (primarily PBSD's performance gain). The question about other motivations for PBSD is constructive and encourages the authors to clarify their work's focus. However, the lack of clarity about the main contribution itself could make this point less immediately helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review states 'I did not carefully read additional experiments described in the Appendix (e.g. the Brusselator) out of time consideration.' While this identifies a potential weakness in the authors' process, it does not explicitly tell the authors what to do. The reviewer points out a lack of engagement with the Appendix but doesn't provide a specific action for the authors to take, such as 'Review the Brusselator experiment details' or 'Consider the implications of the Brusselator model for your work'. The action is implied but not stated directly.", "grounding_specificity_rationale": "The review explicitly mentions 'the Appendix' and even names a specific experiment within it, 'the Brusselator'. This clearly identifies the section being discussed. The authors can easily pinpoint the referenced part of the paper.", "verifiability_rationale": "The review states 'I did not carefully read additional experiments described in the Appendix (e.g. the Brusselator) out of time consideration.' This is a factual statement about the reviewer's own behavior. There is X being made about the quality or content of the Appendix itself. The statement is a description of an action the reviewer took.", "helpfulness_rationale": "The review provides information about a specific section of the paper (the Appendix and the Brusselator experiment) and the reviewer's reason for not engaging with it (time constraints). While it doesn't directly suggest improvements to the authors' work, it offers context and potentially highlights a practical limitation. It could be helpful for the authors to understand the reviewer's perspective and the reasons behind their actions, even if it doesn't directly guide them on how to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about the relationship between the described 'active learning pipeline' and traditional active learning. This directly points to an actionable step: verifying whether the described method aligns with the established understanding of active learning. The question is clear and directly addresses a potential point of confusion or misrepresentation in the paper.", "grounding_specificity_rationale": "The reviewer explicitly compares the described 'active learning pipeline' to 'traditional active learning that select informative samples to label'. This is a very specific comparison, directly pinpointing the aspect of traditional active learning being referenced. The reviewer can accurately identify the key characteristic being compared, indicating strong grounding. The specific example provided ('select informative samples to label') further enhances the specificity.", "verifiability_rationale": "The reviewer's question implicitly suggests a claim that the described 'active learning pipeline' might not be the same as traditional active learning. While not a direct statement of a problem, the question itself is a form of claiming something needs clarification or verification. The request for clarification implies a need for justification or evidence, indicating an attempt to verify the description.", "helpfulness_rationale": "The reviewer's question directly points out a potential area of confusion or misrepresentation in the authors' description of their active learning method. This is likely to be helpful for the authors in refining their explanation and ensuring clarity for readers. The specific question about the relationship to traditional active learning makes it a valuable feedback point."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly mentions actionable items like 'reading the text,' 'standardization of the pictograms,' and 'improving the clarity of the text.' It also points out a minor textual issue, which can be directly addressed by identifying the specific location and equation. These actions are clearly defined and can be implemented by the authors.", "grounding_specificity_rationale": "The review point explicitly refers to 'the very same' and 'standardization,' which implies a specific section or concept within the paper. It also refers to 'Figure 4' and a specific range of values (0/50 latency range, 2.5/4.0 MAE), indicating a clear identification of the part being addressed. The textual issues also refer to specific locations (pag. 4) and equations, making the grounding explicit.", "verifiability_rationale": "The reviewer's claim that there's a discrepancy between versions and a need for standardization is supported by the text. The claim about the overlapping symbols in Figure 4 is a logical deduction based on the description. The textual issues are also verifiable by reading the paper and locating the mentioned sections and equations. The reasoning is clear and based on direct observation of the text.", "helpfulness_rationale": "The review point provides several concrete suggestions for improvement, such as standardizing icons and addressing the identified issues. The textual issues are also helpful in pinpointing specific problems. The suggestions are actionable and directly address potential weaknesses in the paper or its presentation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a problem: a contradiction in the paper's description regarding the use of 300WLP. This is a clear and direct statement of an issue, making it explicit. The reviewer also clearly states what the potential problem is (unfair advantage), making it concrete.", "grounding_specificity_rationale": "The reviewer does not explicitly name a specific section, table, or figure in the paper where the contradiction is supposed to exist. They refer to the general methodology. Therefore, the grounding is weak. However, the reviewer clearly specifies the issue: the potential unfair advantage due to the use of 300WLP in training, which is specific to the problematic area.", "verifiability_rationale": "The reviewer is not presenting a claim that needs verification. They are pointing out a logical inconsistency or a gap in the paper's description. Therefore, the verifiability is not applicable, and the label is 'X'.", "helpfulness_rationale": "The reviewer is raising a valid concern about the experimental setup. While they are not suggesting a concrete fix, they are highlighting a potential flaw that could impact the fairness of the comparison. This insight could be helpful for the authors to understand the limitations of their approach. However, it is not a direct, actionable suggestion, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states a desire to improve the analyses of the method and experimental outcomes. However, they do not specify *how* these analyses should be improved, leaving the reader without concrete guidance. The request is clear and identifies a need for action, but the lack of detail makes it less actionable than a more specific suggestion.", "grounding_specificity_rationale": "The reviewer refers to 'the analyses of the method itself and the experimental outcomes' generally. While they hint at the *type* of analysis being questioned ('word level to the sense level'), they do not pinpoint a specific section, table, figure, or unique element within the paper that needs improvement. The grounding is implicit in the broad area of analysis, but lacks precision in identifying the exact part of the paper being criticized.", "verifiability_rationale": "The reviewer expresses an opinion about the comprehensiveness of the analyses and raises a question about the attribution of performance improvements. However, they do not provide any evidence, examples, or references to support their claim. The statement is presented as a question or assertion without any logical reasoning or external citations, making it 1.", "helpfulness_rationale": "The reviewer points out a potential weakness in the paper's analysis and questions the justification for a key claim. While this is a valid concern, the review lacks specific, actionable suggestions for improvement. It identifies a problem but does not offer concrete solutions or guidance on how to address it, making it only 2 in providing direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the absence of experiments on LLaMA and Falcon, which are specific and wellknown LLMs. The reviewer also implies that these models are important for more comprehensive benchmark baselines, indicating a concrete action to be taken.", "grounding_specificity_rationale": "The reviewer explicitly names LLaMA and Falcon, accurately pinpointing the specific models being referred to. This is a clear and direct identification of the section, table, figure, or unique aspect being addressed. The reviewer also explains the relevance of these models to have more comprehensive benchmark baselines, adding specificity to the grounding.", "verifiability_rationale": "The reviewer makes a claim that 'I think more experiments on different famous LLMs like LLaMA, Falcon, etc are needed'. This is a clear statement of a need. However, the reviewer does not provide specific reasons or references to support this claim beyond stating it as a need for more comprehensive baselines.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors to improve their draft. They identify a specific weakness (lack of experiments on famous LLMs) and propose a direct and concrete improvement (conducting more experiments). This directly addresses a potential area for enhancement in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the paper does not describe what hyperparameters are used by each defense nor how those hyperparameters are derived. While this points to a missing element, the reviewer does not explicitly state what action the authors should take. The authors still need to infer that they need to find or derive the missing hyperparameter information. The action is implicit rather than explicit.", "grounding_specificity_rationale": "The review point is a general statement about the missing information in the paper. It does not specify a particular section, table, figure, or unique element of the paper that is lacking. The grounding is at a general level, not a specific one.", "verifiability_rationale": "The review point itself does not contain a claim. However, the reviewer implies that the lack of hyperparameter information and their derivation makes it impossible to perform a maximally charitable evaluation. This implied claim is not supported by evidence within the review point itself. The reviewer is making an assumption about the implications of the missing information, but the review point doesn't provide any justification for this assumption.", "helpfulness_rationale": "The review point identifies a significant omission in the paper \u2013 the lack of information about hyperparameters and their derivation. However, it does not provide any guidance or suggestions to the authors on how to address this issue. The authors are left to figure out where to find or derive this missing information on their own, which does not directly help them improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests exploring different pooling strategies, which implies an action. However, it doesn't explicitly state how to implement these strategies or where to find relevant information. The suggestion is vague and lacks concrete steps for the authors to follow.", "grounding_specificity_rationale": "The review point is general and doesn't identify a specific part of the paper being addressed. It suggests exploring different pooling strategies in general, without pinpointing a particular section, table, or figure. The comment is vague and doesn't provide any specific context for the suggested exploration.", "verifiability_rationale": "The review point itself doesn't make a claim about the effectiveness of mean pooling. It's a suggestion for further investigation and experimentation. While it implies that mean pooling might be less effective than other strategies, it doesn't provide any evidence or reasoning to support this claim within the review point itself.", "helpfulness_rationale": "The review point is relevant to the authors as it points towards a potential improvement in their method. It encourages them to think critically and experiment with different pooling strategies. However, the lack of specific guidance on how to implement these strategies or where to find relevant information limits its immediate helpfulness. It's a good starting point for further discussion but requires more detail to be fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a limitation in the study's scope and the strength of its conclusions. While the comment doesn't explicitly tell the authors *what* to do, it highlights a *missing piece* in their analysis. The authors can infer that they need to focus more on the relationship between the top selected patches and the disease. However, the action is not directly stated, making it less actionable than a comment that says 'Focus on the patches listed in Section 3.2'.", "grounding_specificity_rationale": "The reviewer specifically mentions 'top selected patches' as the area lacking a clear relationship with the disease. This provides the authors with a specific section or concept to focus on. While the authors might not know *exactly* which patches or how to analyze them, the comment grounds the feedback in a particular part of the paper. The mention of 'top selected patches' is a specific descriptor within the context of the study, indicating a targeted area of concern.", "verifiability_rationale": "The reviewer states that the 'relationship between the top selected patches and the disease is not yet established'. This is a claim that the relationship is missing or requires further investigation. The reviewer doesn't provide external references or logical reasoning to support this claim within the review point itself. The claim is based on the current state of the study, implying a lack of evidence, but it lacks explicit justification or examples within the immediate context of the review.", "helpfulness_rationale": "The reviewer identifies a valid limitation in the study: the lack of established relationship between the top selected patches and the disease. This feedback is relevant to the authors as it points to a specific area where their analysis might be incomplete or where further research is needed. While the comment doesn't offer a complete solution, it highlights a concrete issue that the authors can investigate further. The suggestion to focus on these patches is a constructive piece of feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment states a fact (FedSP not being the best) but does not imply any action or suggest improvements. It's a descriptive statement, not a directive.", "grounding_specificity_rationale": "The comment mentions 'Table 1' and 'Table 2', providing some grounding. However, it also uses the vague phrase 'some datasets', which doesn't precisely identify the problematic areas. This can be considered weak grounding with some specificity.", "verifiability_rationale": "The comment presents a factual observation about the performance of FedSP in the tables. While it's based on the data, it doesn't provide external references or logical reasoning to support the claim. It's a statement of observation, not a claim requiring justification.", "helpfulness_rationale": "The comment identifies a factual issue (FedSP not being the best) which is helpful for the authors to know. However, it lacks specific details about the datasets, the nature of the suboptimal performance, and doesn't suggest concrete improvements. It's not actionable, and while it states a fact, it doesn't provide a clear path forward."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests *providing examples* to explain M_T, which is a direct and concrete action the authors can take to improve their understanding. This makes the review actionable.", "grounding_specificity_rationale": "The reviewer *identifies* the lack of clarity in the definition of M_T, directly pointing out where the information is lacking. This strong identification makes the comment grounded.", "verifiability_rationale": "The reviewer's suggestion to *provide examples* to explain M_T can be considered verifiable as it offers a concrete way to understand the concept. While it's not a direct claim, it provides a pathway for verification.", "helpfulness_rationale": "The reviewer's suggestion to *explain M_T with examples* is a constructive and helpful suggestion that directly addresses a potential point of confusion for the authors. It aims to empower them to better understand and implement changes."}
{"actionability_label": "3", "grounding_specificity_label": "Mostly Grounded and Specific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a potential issue ('abstention') and suggests a comparison ('compare their accuracies'). This is a direct action the authors can take. While it doesn't specify *how* the comparison should be done, it clearly identifies a direction for improvement.", "grounding_specificity_rationale": "The comment explicitly mentions 'ChatGPT' and compares it to 'other models'. This clearly identifies the specific models being discussed, making the grounding explicit and obvious to the authors. The reviewer is pointing out a specific performance difference between these models.", "verifiability_rationale": "The comment raises a question about the fairness of comparing ChatGPT's accuracy to other models due to its higher abstention rate. This is a statement of concern and opinion, not a claim that requires verification. The reviewer is expressing a belief that abstention might indicate a lack of confidence, which could affect the interpretation of accuracy.", "helpfulness_rationale": "The comment directly addresses a potential flaw in the evaluation methodology (the comparison of accuracy based on different abstention rates). It suggests an improvement by questioning the fairness of the comparison. This indicates a helpful suggestion, though it doesn't provide a definitive solution."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that a 'monotonic relationship is imposed between the degree of a singletask predictor participation and the weight of the corresponding task loss' and then suggests that 'the ensemble engenders a subspace that explicitly encodes tradeoffs and results in a continuous parameterization of the Pareto Front.' This clearly indicates an actionable point. The reviewer proposes an alternative approach (exploring other relationships) and provides a reason for this suggestion (limiting flexibility). The action is to question the monotonic relationship, and the suggestion is to explore alternatives, making it actionable. The reviewer also provides a concrete description of the current method and the potential improvement, making it 5.", "grounding_specificity_rationale": "The reviewer's comment focuses on the *mechanism* of how the monotonic relationship is implemented within the ensemble and the resulting Pareto Front. While the comment touches upon the 'ensemble' and 'weights of the corresponding task loss,' it doesn't explicitly point to a specific section, table, figure, or unique element of the paper being addressed. The reviewer is making a general comment about the implications of the monotonic relationship. Therefore, while the elements mentioned are parts of the paper, the reviewer doesn't provide a precise identification of *which* specific aspect of the paper they are referring to. The grounding is weak because the reviewer is not pinpointing a specific element being criticized.", "verifiability_rationale": "The reviewer's comment raises a question about the necessity of a monotonic relationship and suggests exploring alternatives. While the reviewer doesn't provide specific examples or evidence *within the paper* to support their claim that this relationship is limiting, they do offer a *reason* for questioning it (flexibility) and a *suggestion* for improvement (exploring other relationships). The reviewer is making an inference based on their understanding of the method and the potential benefits of more flexible parameterization. Therefore, the claim is 3 because the reviewer infers a limitation based on their understanding of the method and the potential benefits of more flexible parameterization, even without direct evidence within the paper.", "helpfulness_rationale": "The reviewer directly asks a question and suggests an improvement: 'Explaining this point may be better.' This is a clear call for action and a desire for clarification. The reviewer is pointing out a potential area for improvement in the explanation of a specific methodological choice. This is 5 because it directly addresses a potential weakness in the presentation and encourages a more detailed explanation, which would empower the authors to understand and potentially implement the method better. The reviewer is providing a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies the problem (unclear description) and implies the solution (using the final paragraph). While explicit, the need to act is slightly implied.", "grounding_specificity_rationale": "The reviewer mentions \"the section\" without specifying which part of the paper is unclear. This indicates a lack of precise identification of the problematic area.", "verifiability_rationale": "The reviewer is providing constructive feedback, not making a claim or assertion about the paper's quality or clarity.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement (reorganizing the section) and even offers a solution (starting with the clearer explanation). This is likely to be beneficial for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their understanding of tables being divided into three types versus one type for column headers and poses a question about this difference. This directly points to a specific area needing clarification, making the action relatively concrete. While the reviewer doesn't propose a solution, the action of investigating this difference is clear and actionable for the author.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Section 3 (line 247252)' and mentions 'tables are divided into three types' and 'one type (the column header)'. This precise referencing demonstrates strong grounding as the reviewer accurately identifies the section and a specific aspect within it.", "verifiability_rationale": "The reviewer is posing a question about the table structure, not making a claim that requires verification. Therefore, it doesn't fit into the verifiability categories. The closest category would be 'X' as there is no assertion being made.", "helpfulness_rationale": "The reviewer's point is asking for clarification on a specific detail (table division) rather than criticizing or pointing out a major weakness. While it might be helpful for the author to understand their table structure, it doesn't directly address a significant flaw or lack of clarity in their work. Therefore, it's 3 as it encourages clarification on a specific detail, but it doesn't offer a concrete solution or highlight a major issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests a change to the calculation of the baseline kmeans objective by proposing using the minimum value obtained across multiple seeds instead of the average. This is a clear and direct action to be taken based on the comment. The reviewer also specifies the exact component of the baseline (kmeans objective) and the method of implementation (minimum over multiple seeds). This makes the action both explicit and concrete.", "grounding_specificity_rationale": "The reviewer directly addresses the calculation of the baseline kmeans objective. They specify that the baseline is the 'average of k means objectives with multiple seeds' and then explicitly proposes using the 'minimal k means objective'. This clearly identifies the specific part of the paper (the baseline calculation) being addressed. The reviewer provides a clear and unambiguous definition of the baseline, making the grounding fully explicit and specific.", "verifiability_rationale": "The reviewer makes a claim that the 'minimal k means objective over multiple seeds is more reasonable' than the average. This is a claim that can be supported by evidence. The reviewer provides two references: 1 Jin, Chi, et al. 'Local maxima in the likelihood of gaussian mixture models: Structural results and algorithmic consequences.' Advances in neural information processing systems 29 (2016): 41164124. and 2 Fr\u00e4nti, Pasi, and Sami Sieranoja. 'Kmeans properties on six clustering benchmark datasets.' Applied Intelligence 48.12 (2018): 47434759. These references support the claim by citing prior work that has shown the minimum objective to be more robust and less sensitive to initialization than the average.", "helpfulness_rationale": "The reviewer's suggestion is directly relevant to the calculation of a baseline metric used in kmeans clustering. This is likely to be of direct interest to authors working with or implementing kmeans. The suggestion is also concrete, as it specifies the exact change to be made (using the minimum instead of the average). This makes the comment actionable and directly helpful for improving the draft by clarifying a potentially confusing aspect of the baseline calculation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point offers an opinion about the nature of the task (Argument Mining vs. Summarization) but does not provide a direct action or suggestion for the authors to improve their draft. It's a statement of perspective, not a directive.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or task it is addressing. It's a general statement about the nature of the work being discussed. Therefore, it lacks grounding in the paper's specific sections, tables, or figures.", "verifiability_rationale": "The review point is an opinion and does not contain a claim that requires verification or evidence. It's a subjective assessment of the task's nature.", "helpfulness_rationale": "The review point offers a perspective on the task's nature and suggests further clarification. While it doesn't directly identify a flaw or improvement needed in the current draft, it raises a valid point that could lead to improvements if the paper explicitly addresses the differences between Argument Mining and Summarization. It provides a suggestion for future work, which can be helpful in guiding authors towards a more refined understanding of the task."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for an intuitive explanation of the objective and constraints in the linear program. This constitutes an explicit action to improve the draft. While the action is clear, the lack of clarity in the original explanation makes it 3 but not fully actionable.", "grounding_specificity_rationale": "The reviewer directly refers to 'Theorem 3' and the linear program (3) as the specific part of the paper being addressed. This indicates a high level of grounding. Furthermore, the reviewer specifically asks for clarification on the 'objective' and 'constraints' within this section, adding a layer of specificity to the identified area.", "verifiability_rationale": "The reviewer's statement about the helpfulness of the explanation is a subjective assessment of the value of the review point. While the reviewer identifies a weakness (lack of explanation), the verifiability of this weakness in the original text is not explicitly stated or evaluated in the review point itself.", "helpfulness_rationale": "The reviewer explicitly states that the request for an intuitive explanation would significantly improve their understanding and work. This is a clear expression of the value and helpfulness of the review point."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'how does scratchGAN do if you *do* pretrain?' which is a direct, actionable question about a specific experiment. The reviewer is suggesting a concrete investigation into the impact of pretraining on a particular model.", "grounding_specificity_rationale": "The review point explicitly mentions 'scratchGAN' and the action of 'pretraining'. This directly identifies a specific model and a specific action to investigate. However, it does not explicitly state where in the paper scratchGAN is discussed or used, making the grounding implicit.", "verifiability_rationale": "The review point makes a claim about a missing ablation study and asks a question. While it doesn't provide evidence or references to support the claim about the missing ablation, it clearly identifies a potential area of investigation and a specific question, making the claim 3.", "helpfulness_rationale": "The review point is 5 because it directly suggests a concrete experiment (testing scratchGAN with pretraining) and a specific question to investigate. This provides a clear direction for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the absence of comparison against baselines as a weakness. This is a direct and clear identification of a missing component. While the reviewer doesn't delve into the *why* behind this omission, the *what* (lack of comparison against baselines) is clearly stated and actionable.", "grounding_specificity_rationale": "The reviewer specifically mentions 'comparison against baselines' as the missing element. They also identify the area as 'binary analysis application' and the type of comparison as 'functionality similarity comparison'. This is a very clear and specific identification of the missing piece, making it fully grounded.", "verifiability_rationale": "The reviewer claims that the paper reports 'accuracy across optimization levels of binaries, but no baselines are considered'. This is a factual statement about the reported results. While the reviewer doesn't explicitly state *why* baselines are important, the *claim* that baselines are missing is verifiable from the description provided.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'To improve the evaluation, it would be beneficial to include comparisons against established baselines in the functionality similarity comparison study. This would provide a clearer understanding of the proposed method's performance relative to existing approaches and help contextualize the reported accuracy scores.' This is a direct and useful piece of feedback that would help the authors improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the change in evaluation methodology for SI 6.5, indicating an implicit action: the authors should adjust their evaluation to exclude human starts. While not directly stating the action, it implies the need to implement this change. The comment is concrete as it specifies the exact change: 'no human starts are used' as the alternative evaluation method.", "grounding_specificity_rationale": "The comment explicitly mentions 'SI 6.5' and '7 Mnih et al.', providing clear grounding within the paper and references external work. The information is directly relevant to the section being discussed.", "verifiability_rationale": "The comment makes a claim: 'the evaluation is slightly different'. It also provides justification: 'as no human starts are used' and refers to a previous work. This makes the claim verifiable.", "helpfulness_rationale": "The review point directly addresses a methodological choice the authors are likely to be making. It provides a clear and actionable change: 'no human starts are used' as the alternative evaluation method. The explicit mention of 'SI 6.5' and '7 Mnih et al.' makes the information directly relevant to their work. The justification for the change is also provided, making it a valuable piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "4: Mostly Grounded and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The reviewer states 'The contribution is not enough,' which is an explicit action. However, the reviewer does not specify what the contribution is or what makes it insufficient. The vagueness makes it less actionable for the author.", "grounding_specificity_rationale": "The reviewer mentions 'overfitting problem of training GAN with limited data' and 'differentiable augmentation.' This grounds the comment in specific aspects of the paper. However, the reviewer does not specify which part of the GAN training is overfitting or how the differentiable augmentation is implemented, making it less specific about the issue.", "verifiability_rationale": "The reviewer makes a claim 'The contribution is not enough.' While they provide context ('This paper addresses overfitting with limited data and proposed differentiable augmentation. I think it is important factor, but still limited'), this claim is not wellsupported by explicit evidence or references. The reviewer is making an opinion rather than a verifiable statement.", "helpfulness_rationale": "The reviewer's comment primarily criticizes the contribution without offering specific, actionable feedback or suggestions for improvement. They are evaluating the contribution rather than guiding the author on how to make it better."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer criticizes the choice of object detection as a downstream task, suggesting that LiDARbased segmentation might be more suitable, especially for benchmarks using IoUbased metrics. While the reviewer identifies a potential limitation of object detection, the specific action the authors should take to improve their draft is not explicitly stated. The suggestion to consider segmentation is a critique of the *task*, not a direct instruction on how to *modify* their current object detection task.", "grounding_specificity_rationale": "The reviewer mentions 'LiDARbased segmentation' and 'KITTI and Waymo' metrics, which are specific aspects of the paper. They explicitly state that object detection needs accurate locations and poses, particularly for IoUbased metrics, which are relevant to the benchmarks they mention. The reviewer clearly identifies the specific aspect of the paper being addressed and provides relevant context.", "verifiability_rationale": "The reviewer states that 'colorizationbased pretraining mainly learns the semantics in my opinion, but object detection needs accurate locations and poses especially in the benchmark using IoUbased metrics such as KITTI and Waymo.' This statement presents a claim about the suitability of different pretraining methods for object detection. However, the reviewer does not provide specific examples, references, or logical reasoning to support this claim. The claim is presented as a general opinion without concrete evidence.", "helpfulness_rationale": "The reviewer provides a critique of the chosen downstream task (object detection) and suggests an alternative (LiDARbased segmentation). They explain why they believe the alternative is better, particularly for benchmarks using IoUbased metrics. This critique offers a valuable perspective on the limitations of the current approach. However, the reviewer does not provide specific, actionable steps for the authors to take to improve their object detection task or transition to segmentation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential issue with the objective of Eq (12) in relation to IPO. While it doesn't explicitly state the objective of Eq (12) or how it's supposed to contribute to IPO, it presents a *suspicion* of a contradiction. The reviewer doesn't offer a specific action or a clear explanation of what the contradiction might be. Therefore, it's 2 as it identifies a potential problem but doesn't provide a concrete step for the authors to take.", "grounding_specificity_rationale": "The comment explicitly mentions 'Eq (12)' and 'IPO', which are specific parts of the paper. However, it doesn't explain *why* there might be a contradiction. The reviewer identifies the parts being discussed but doesn't elaborate on the nature of the potential issue. Therefore, it's underspecific in terms of explaining the issue.", "verifiability_rationale": "The comment expresses a *suspicion* or *doubt* about a potential contradiction between the objective of Eq (12) and IPO. To be verifiable, a review comment needs to provide evidence or reasoning. The reviewer doesn't offer any specific examples or data to support their claim. The statement itself is a subjective opinion rather than a claim supported by evidence. Therefore, it's 1.", "helpfulness_rationale": "The comment raises a concern about the objective of Eq (12) potentially contradicting the IPO. This is a valid point that could influence the authors' understanding of the paper's direction and impact. While the reviewer doesn't provide a specific solution, they have identified a potential issue that the authors should consider. This makes the comment 3 as it points to a potential problem that needs attention."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a discrepancy between the statement in the abstract and the authors' clarification in the text. While it points out the issue, it doesn't explicitly state how the authors should modify the abstract. The reviewer asks for clarification, which is a form of implicit action, but lacks concrete steps.", "grounding_specificity_rationale": "The review point explicitly mentions 'the abstract' as the location where the requirement to upper bound the target is stated. This is a clear and specific reference to a part of the paper.", "verifiability_rationale": "The review point makes a claim about the authors' intentions regarding the abstract. While the reviewer's statement about the authors' clarification is based on their own reading of the paper, it doesn't provide direct evidence or references within this review point itself to support the claim. The claim is based on the reviewer's interpretation of the paper's content.", "helpfulness_rationale": "The review point points out a potential issue in the abstract that could lead to confusion or misinterpretation. While it's constructive to point out potential problems, it doesn't offer a specific solution or actionable steps for the authors to take. The reviewer's comment is more of a deduction based on the paper's content rather than a direct suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the choice of using link prediction accuracy for early stopping and asks for a clear justification for this decision. This is a direct and actionable point, making it 5.", "grounding_specificity_rationale": "The reviewer explicitly names 'link prediction accuracy' and 'type accuracy' and asks a specific question about their relationship. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The comment asks a question about a design choice but does not present a claim that requires verification. It's a request for clarification, not a statement demanding proof.", "helpfulness_rationale": "The reviewer directly asks for a justification for a methodological choice, which is a valuable and helpful request for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies two potential weaknesses: the rudimentary nature of the ChatGPT baseline and the lack of testing of fewshot approaches. While these are valid observations, they do not explicitly state what the authors should do next. The suggestions for including discourse relations in prompts are vague and lack concrete steps for implementation. Therefore, while the observations are relevant, the lack of explicit actions makes them 2.", "grounding_specificity_rationale": "The reviewer states that the ChatGPT baseline is 'rudimentary' and that 'fewshot approach isn\u2019t tested.' However, the review does not specify which particular baseline or fewshot approach is being referred to. This lack of specificity makes it difficult for the authors to pinpoint the exact issue and understand how to address it. Therefore, the grounding is weak in both cases.", "verifiability_rationale": "The reviewer's claims about the rudimentary nature of the ChatGPT baseline and the lack of testing of fewshot approaches are subjective statements. While these could potentially be supported by evidence (e.g., citing low performance metrics for the baseline or stating the absence of specific experiments), the review point itself does not provide any concrete examples or references to back up these claims. Therefore, the verifiability of these statements is low.", "helpfulness_rationale": "The review point offers suggestions for improvement, such as testing fewshot approaches and exploring the use of discourse relations in prompts. However, these suggestions are presented as general ideas without specific guidance on how the authors should go about implementing them. The reviewer also states that these suggestions are 'extraneous' to the paper's evaluation, meaning they don't directly address the identified issues. Without clear steps and a connection to the paper's goals, the suggestions are not particularly helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the paragraph is unclear and suggests a specific algorithm (Gittins strategy) as a potential solution. While the explanation of the Gittins strategy is brief, it directly points to a possible improvement. The comment also identifies a lack of clarity in a figure, indicating an actionable issue. The reviewer is not inferring the need for improvement but directly pointing to it.", "grounding_specificity_rationale": "The comment explicitly refers to 'this paragraph' and then specifically mentions 'a figure'. It also names a specific concept ('Gittins strategy') within the context of the paragraph and the figure. While the explanation of the Gittins strategy is brief, the reviewer clearly identifies the specific area where the concept is discussed (the paragraph) and the specific element within that area (the figure) that needs clarification.", "verifiability_rationale": "The comment contains a claim ('I can barely understand this paragraph') and provides a suggestion ('First of all, there /are/ bandit algorithms that plan to explore. Notably the Gittins strategy...'). While the suggestion is not fully elaborated with references or concrete examples, the claim itself is supported by the reviewer's statement of difficulty. The reviewer also mentions 'Dashed lines indicate that the agent can plan ahead...' which is a claim that requires justification (vaguely explained).", "helpfulness_rationale": "The comment identifies a genuine issue (lack of clarity) and offers a concrete alternative (Gittins strategy). While the explanation of the Gittins strategy is brief, it provides a potential solution. The reviewer also points out the figure's lack of clarity, which is a valid feedback point. The comment is not vague or general enough to be considered 'X'."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that Algorithm 2 does not specify how to determine n_t and that the term 'appropriate number' in line 225 is unclear and lacks justification in reference 30. This provides clear, actionable feedback for the authors to understand and implement the algorithm correctly. The reviewer identifies the missing information and the ambiguity, making it 5.", "grounding_specificity_rationale": "The reviewer directly points to Algorithm 2 and line 225, making the grounding very explicit. They also explain what is missing ('how to determine n_t') and why it's unclear ('appropriate number'), adding to the specificity of the feedback.", "verifiability_rationale": "The reviewer does not make a claim about the paper's content. Instead, they point out a lack of information in Algorithm 2 and a missing justification in reference 30. While there isn't a claim to verify, the identification of a missing piece of information and a gap in justification makes the feedback 3. The reviewer highlights a gap that needs to be filled, which can be considered a form of implicit verification.", "helpfulness_rationale": "The reviewer clearly states that this feedback is crucial for the authors to understand and improve the implementation of Algorithm 2. The lack of information about n_t and the ambiguity of 'appropriate number' are significant hurdles for the authors, making this feedback 5 in addressing these specific issues."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes a claim ('in practice the mixing time is even better') but does not provide explicit or concrete actions for the author to take. While it identifies a potential issue with the claim, it doesn't specify how the author should address it or what steps they should follow. The suggestion to 'provide more support' is implicit.", "grounding_specificity_rationale": "The review point refers to 'the claims that 'in practice the mixing time is even better''. It does not explicitly identify which specific claim is being referred to within the paper. It also does not specify what is wrong with that claim or where it is located in the document.", "verifiability_rationale": "The review point makes a claim: 'the claims that 'in practice the mixing time is even better' are not nearly sufficiently supported by the experiments'. This claim is not explicitly supported by any logical reasoning, common knowledge, or external references within the review point itself. The reviewer suggests the experiments are insufficient but doesn't provide specific examples of what is missing or cite external work to support this criticism.", "helpfulness_rationale": "The review point identifies a potential issue with a claim and suggests improving the support for it. However, it does not offer concrete, actionable steps or specific guidance on how the author should go about improving the support. It criticizes the claim but doesn't provide a clear path forward for the author."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the lack of clarity regarding the numbers of parameters used in each approach. This is an explicit action that the authors should take to understand this implementation detail. The action is also concrete as the missing information is a specific detail about the experimental setup or methodology.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section B.3' when stating their lack of clarity. This allows the authors to identify the specific section where this information should be found, making the grounding strong. However, the reviewer does not specify *within* Section B.3 where the numbers of parameters are documented. This lack of specificity makes the grounding 'Weakly Grounded'. The information is present but not precisely located.", "verifiability_rationale": "The review point does not contain a claim. It is a statement of lack of clarity, not an assertion about what is correct or incorrect. Therefore, it does not have verifiability in the sense of supporting a claim. The output 'X' indicates X.", "helpfulness_rationale": "The review point identifies a specific area of confusion (the numbers of parameters in Section B.3). While it doesn't provide a solution, it points to a concrete piece of information that the authors should seek. This makes the review point 3 as it directs the authors to a specific location and detail they need to understand."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests *what* would be helpful (an example/figure) but doesn't explicitly state *how* to create or use it. This leaning towards 'implicit' is key. While the reviewer identifies a potential improvement, the lack of a clear action or method makes it 2. It points towards a need for clarification, but doesn't actively instruct the author.", "grounding_specificity_rationale": "The review point is very general. It doesn't specify *where* the confusion about uniform shattering lies. It doesn't mention a specific section, table, figure, or element of the paper. The reviewer is making a broad statement about the definition of uniform shattering, not pinpointing a specific area within it or the paper that needs clarification. Therefore, it is 1.", "verifiability_rationale": "The review point itself is not a declarative statement of a claim that requires verification. It's a suggestion for improvement. There's no 'this is wrong' or 'you should do this.' Since there's X, there's no need to evaluate its verifiability. The review is about *what* to do than *why* it's needed. Therefore, it doesn't fit neatly into the 'claim verification' category. A score of 'X' (X) would be appropriate.", "helpfulness_rationale": "The review point clearly identifies a potential area for improvement (an example/figure making uniform shattering clearer). While it lacks specific *how*, the suggestion is still relevant and directly addresses a likely need for better understanding. It's a suggestion for a concrete improvement. The reviewer is pointing out a likely weakness and offering a relevant solution."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states their belief about the novelty of the method, which is a direct and clear action. They identify the area of related work (selftraining in semisupervised learning) which provides a basis for the authors to consider the connection.", "grounding_specificity_rationale": "The reviewer attempts to ground their claim by mentioning 'selftraining methods in semisupervised learning.' However, they do not explicitly identify a specific section, table, figure, or unique aspect of the paper where this connection is relevant. The mention is general, implying a potential overlap without specifying the exact nature of the similarity.", "verifiability_rationale": "The reviewer makes a claim about the method's novelty but does not provide any evidence or justification to support this claim. They suggest a connection to selftraining but do not elaborate on how the proposed transductive method is related to or different from selftraining techniques. There is no logical reasoning, common knowledge, or external references provided to verify the claim.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the novelty of the method. However, they do not offer any specific suggestions or insights on how to improve the authors' draft based on this observation. The comment is a statement of opinion rather than a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The comment explicitly states the use of the word 'equivalent' at specific line numbers, which can be considered an explicit action. However, it doesn't provide concrete details on how to implement this action or what specific changes are needed. The reviewer suggests a more cautious usage, implying a lack of clarity on the intended improvement.", "grounding_specificity_rationale": "The comment explicitly mentions the specific lines (8, 56, 70, 93) where the word 'equivalent' is used. This clearly identifies the specific part of the paper being addressed, making it fully grounded. However, the comment doesn't specify what is wrong with the usage or what alternative should be used, making it not specific about the issue.", "verifiability_rationale": "The comment contains a claim suggesting a more cautious usage of the word 'equivalent'. However, it does not provide any evidence, justification, or references to support this claim. The reasoning is purely based on the reviewer's suggestion, lacking logical reasoning or external references.", "helpfulness_rationale": "The comment identifies a potential issue with the use of the word 'equivalent' at specific locations. While this points to a weakness, it doesn't provide actionable feedback on how to address it. The reviewer's suggestion for a more cautious usage is a suggestion but lacks concrete steps or justifications, making it less helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the architecture is not clearly explained and refers to another paper for details. While the reviewer identifies an area needing improvement, the specific action (asking for clarification) is implicit, and the lack of concrete details makes it vague.", "grounding_specificity_rationale": "The reviewer explicitly states that the architecture details are missing and points to Jiang et al. (2019) as the source. This allows the authors to identify the specific part that is lacking, thus achieving full grounding. However, the reviewer does not specify *what* is unclear about the architecture, making the specificity low.", "verifiability_rationale": "The reviewer makes a claim that the architecture is not clearly explained and refers to another paper. This claim is not supported by any logical reasoning, common knowledge, or external references within the review itself. The lack of explanation is presented as a problem, not a deduction or inference.", "helpfulness_rationale": "The reviewer identifies a weakness in the paper (lack of architecture explanation) and suggests the authors ask for clarification. While the reviewer points out a need for improvement, they do not provide any specific suggestions or ask any concrete questions. The request is vague and lacks actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the metrics (BertScore and BLEURT) and suggests standardizing their naming. This is a clear and actionable suggestion for the authors.", "grounding_specificity_rationale": "The comment explicitly mentions the specific metrics (BertScore and BLEURT) and clearly identifies the issue (inconsistent typesetting) and the desired solution (standardization). This is 5.", "verifiability_rationale": "The comment contains a claim (BertScore and BLEURT are inconsistently typeset) but does not provide any evidence or justification for this claim. It only suggests a solution (standardization) without explaining why this is a problem or how to fix it.", "helpfulness_rationale": "The comment identifies a potential formatting issue and suggests a solution (standardization). While relevant, it's a minor point and lacks specific evidence or a detailed solution. It's helpful but not a major breakthrough or a solution to a critical problem."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'I\u2019d be interested to know if other multilingual pretraining setups also struggle with Greek.' This indicates an explicit question about a potential issue. However, the reviewer does not provide a concrete action or suggestion for the authors to take based on this information. They are simply posing a question.", "grounding_specificity_rationale": "The reviewer mentions 'multilingual pretraining setups' generally and then specifically focuses on 'other multilingual pretraining setups also struggle with Greek.' This demonstrates a strong grounding as the reviewer accurately identifies the type of pretraining model and the specific issue (struggle with Greek) they are interested in. However, the reviewer does not specify *which* multilingual pretraining setups or *how* they struggle with Greek, making it underspecific regarding the nature of the struggle.", "verifiability_rationale": "The reviewer states 'I\u2019d be interested to know if other multilingual pretraining setups also struggle with Greek.' This can be interpreted as a claim or a request for clarification. However, the reviewer does not provide any evidence, references, or logical reasoning to support this claim. The statement is presented as a question or interest, lacking verification.", "helpfulness_rationale": "The reviewer offers a question: 'I\u2019d be interested to know if other multilingual pretraining setups also struggle with Greek.' This is a form of feedback that encourages the authors to consider the possibility of the issue being related to the specific multilingual model used. While it doesn't directly tell the authors what to do, it prompts them to investigate further, which can be helpful in identifying potential weaknesses. The question is relevant to understanding the issue with Greek in multilingual models."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment implies an action (identifying a difficulty in understanding), but it lacks explicitness and concreteness. The phrase 'It would be difficult for readers to understand and evaluate' doesn't specify *what* needs to be improved or *how* the clarity should be enhanced. The action is implied but vague.", "grounding_specificity_rationale": "The comment explicitly mentions 'the text in line 293295,' providing strong grounding. However, it does not specify *what* is unclear or *how* the manual observation helps. The issue being pointed out is not detailed, making the comment only 2.", "verifiability_rationale": "The comment contains a claim ('It would be difficult for readers to understand and evaluate the results'), but it lacks supporting evidence or justification. There is no logical reasoning, common knowledge, or external references provided to back up this statement. The claim is made without any verifiable basis.", "helpfulness_rationale": "The comment points out a potential issue with the clarity of a specific section, which could be helpful for the authors. However, the criticism is vague and lacks specific details about what is unclear. While the suggestion to 'manually observed' is specific, the preceding criticism is general and doesn't provide actionable feedback. The helpfulness is limited due to the lack of specificity."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests using realworld datasets, providing a clear and actionable step for the authors to improve their experimental setup. The action is concrete, instructing them to change the type of datasets used.", "grounding_specificity_rationale": "The review point does not specify a particular part of the paper it is addressing. It is a general suggestion about the experimental setup, making it 1 in terms of identifying a specific section or table.", "verifiability_rationale": "The review point makes a claim about the benefits of realworld datasets for evaluating a realistic scenario. While it doesn't provide specific examples or citations within the review point itself, the suggestion is based on a reasonable understanding of evaluation practices.", "helpfulness_rationale": "The review point is highly relevant to the paper's stated goal of evaluating disentangled representation learning in a realistic scenario. It provides a clear and actionable suggestion for improving the experimental setup, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2: 4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential area for improvement (vague explanation) but does not specify how to make the explanation less vague. It points to a specific section but lacks concrete action for the author.", "grounding_specificity_rationale": "The comment explicitly mentions \"the last paragraph of Section 3 (lines 207210) on the single image case,\" clearly identifying the specific part of the paper being addressed.", "verifiability_rationale": "The comment is a suggestion and does not make a claim that requires verification. It's a constructive comment about the clarity of an explanation.", "helpfulness_rationale": "The comment identifies a valid issue (vague explanation) and directs it to a specific part of the paper. While it doesn't provide specific actionable steps, it highlights a genuine concern and suggests a direction for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a specific issue: the confusion surrounding the number of biases (C) and the missing hyperparameter `num_bayases` in the code described in section 3.4. They suggest that changing `num_bayases` to `C` will resolve this confusion. This is an explicit action the authors should take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 3.4' and the hyperparameter 'num_bayases'. They clearly identify the issue as the discrepancy between the expected hyperparameter and the observed number of biases (C). This strong reference to a specific part of the paper and the required change demonstrates high grounding specificity.", "verifiability_rationale": "The reviewer identifies a claim: 'we only found this hyperparameter for the feed forward models that are described in section 3.4. The fact that they have C biases is confusing.' This claim is supported by the location of the hyperparameter in the code and the expected behavior of the model. While not explicitly backed by external references, the logical reasoning is present.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'change num_bayases to C'. They directly address a potential point of confusion for the authors by pointing to the discrepancy between the expected hyperparameter and the observed number of biases. This is very specific and directly helpful."}
{"actionability_label": "4", "grounding_specificity_label": "4: 5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly suggests 'showing the smoothed GT shapes' in 'Figure. 3 and Figure. 5'. This is a clear action the reviewer proposes. While the reviewer doesn't specify how this will be done or what specific changes will be made, the suggestion itself is a concrete action. The reviewer also mentions 'improving the quality of the reconstruction', which implies a potential outcome of this action.", "grounding_specificity_rationale": "The reviewer refers to 'smoothed GT shapes' and 'Figure. 3 and Figure. 5'. The 'smoothed GT shapes' are specific elements within the paper. The reviewer also explicitly mentions 'Figure. 3 and Figure. 5', providing the specific location of the relevant figures. This demonstrates strong grounding as the reviewer not only identifies the 'what' but also the 'where'.", "verifiability_rationale": "The reviewer's comment is a suggestion or recommendation ('suggests showing the smoothed GT shapes'). It doesn't present a claim that requires verification or evidence. There's no logical reasoning, common knowledge, or external references provided to support the benefit of showing these shapes. It's a suggestion based on a desire to improve understanding.", "helpfulness_rationale": "The reviewer provides a clear and relevant suggestion. The desire to 'improve the quality of the reconstruction' is a valid and actionable goal for the authors. While the suggestion lacks specifics on how to show the smoothed GT shapes, it clearly points towards a concrete improvement. The reviewer's intention is understandable and directly addresses a stated concern."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the *claim* about the importance of language modeling and the *weakness* of the current experiments. This is an explicit statement of an action: 'The authors may consider to include tasks...'. Therefore, it's explicitly stated. The reviewer also identifies *specific* tasks that would be more appropriate. This provides concrete guidance. It's not just a vague suggestion; they name the tasks. The reviewer provides both a diagnosis (the experiments are weak) and a prescription (use different tasks). This is 5.", "grounding_specificity_rationale": "The reviewer *mentions* the importance of language modeling as a stated motivation of COCOLM. While they don't *explicitly* say 'Section 5.3', they imply it's a relevant part based on the tasks discussed. This is weak grounding \u2013 they can infer the connection but don't pinpoint the exact section or element. However, the reviewer *does* specify the *type* of tasks that would be more relevant (language modeling, machine translation, text summarization). This adds a degree of specificity to their critique.", "verifiability_rationale": "The reviewer makes a clear claim: 'The authors may consider to include tasks...'. This is a suggestion, which can be interpreted as a constructive suggestion aimed at improving the evaluation. However, the reviewer doesn't *prove* that these new tasks are *definitely* better. They offer a *suggestion*. While the suggestion is based on a reasonable understanding of language modeling capabilities, it's not a completely arbitrary suggestion. Therefore, it's 3.", "helpfulness_rationale": "The reviewer provides a clear diagnosis and a concrete suggestion. While they don't *prove* the new tasks are *definitely* better, they offer a *specific* direction for improvement. This is 5. The suggestion is actionable and directly addresses the identified weakness."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review points out an actionable item: 'cite and discuss'. This directly instructs the authors on what needs to be done. However, it lacks specific details on *which* references are important and *how* they should be discussed.", "grounding_specificity_rationale": "The reviewer mentions 'important references for domain adaptation' but does not specify which section, table, figure, or unique element of the paper these references relate to. The mention is general and doesn't pinpoint a specific part of the work.", "verifiability_rationale": "The review contains a claim: 'This paper lacks some very important references for domain adaptation.' The suggestion to 'cite and discuss' provides a direction for improvement but does not offer concrete evidence or references to verify the claim about missing important references.", "helpfulness_rationale": "The review identifies a significant weakness (lack of references) and provides a clear action (cite and discuss). This directly addresses a potential bottleneck for the authors and guides them on how to improve their work. While the specifics are missing, the direction is helpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a concern about the 'lucky' outcome and suggests investigating the 'distance to the next best model'. While this points to a potential issue, the reviewer does not explicitly state how to verify this or what specific hyperparameters to check. The suggestion to 'look at the distance to the next best model' is a good starting point, but not a complete action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the SCNN model' and 'domain pricing', clearly identifying the specific part of the paper being referenced. However, the reviewer does not specify *why* they suspect something is suspicious beyond the 'lucky' outcome and the 'large distance to the next best model'.", "verifiability_rationale": "The reviewer presents a claim about the suspicious outcome and suggests investigating the 'distance to the next best model'. However, the reviewer does not provide any external references or logical reasoning to support this claim. It is presented as a hypothesis based on observation, lacking verifiable evidence.", "helpfulness_rationale": "The reviewer's review points to a potential issue with the SCNN model's performance on domain pricing and suggests investigating the 'distance to the next best model'. While this raises a valid concern and provides a starting point for further investigation, the review itself does not offer a concrete solution or a clear methodology for the authors to follow. It is more of a question and observation than a direct instruction."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the potential for confusion regarding the use of 'r' for two different concepts (risk and primal risk). They suggest a concrete action: 'clarify the distinction'. This action is directly identifiable and actionable for the authors.", "grounding_specificity_rationale": "The reviewer explicitly identifies the problematic notation 'r' and specifies the confusion arising from its dual use (risk and primal risk). This directly grounds the comment to a specific part of the paper and clearly identifies the issue within that part. The reviewer can confidently pinpoint the section and the specific problem.", "verifiability_rationale": "The reviewer claims that using 'r' for two different things is 'confusing'. While this claim is subjective, it implies that the lack of clarity could hinder understanding. The reviewer identifies a potential area for improvement but doesn't provide external references or logical reasoning to support this claim. Therefore, it's difficult to definitively label it as fully 1, but the reviewer's statement suggests a lack of clarity that could be supported by evidence for some readers.", "helpfulness_rationale": "The reviewer's suggestion to 'clarify the distinction' is a direct and actionable piece of feedback for the authors. It provides a clear next step they can take to improve their understanding of the problem formulation. The suggestion is specific, pointing to the notation 'r' and its dual use. This makes the feedback immediately useful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential weakness in the paper's evaluation by suggesting the lack of analysis on other datasets. While the reviewer doesn't explicitly state an action, the implication is clear: the authors should consider expanding their experiments to include more complex datasets like ImageNet derivatives. The reviewer doesn't provide concrete steps on how to do this, making the action implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'ImageNet derivatives' as a specific area for analysis. This demonstrates a clear identification of the specific part of the paper being addressed, fulfilling the 'grounding' criteria. The reviewer also identifies a 'lack of analysis or results' in this area, specifying the issue within the identified part.", "verifiability_rationale": "The reviewer makes a claim about the 'lack of analysis or results on other datasets'. This claim is verifiable by examining the paper's experimental section. The reviewer doesn't provide specific examples or references to external works to support this claim, making the evidence somewhat general. However, the claim itself is clear and points to a deficiency in the presented evidence.", "helpfulness_rationale": "The reviewer identifies a potential gap in the paper's evaluation by pointing out the lack of analysis on other datasets. This is a valuable piece of feedback for the authors as it highlights a potential limitation in the presented results and encourages them to explore the framework's performance on more complex datasets. While the reviewer doesn't explicitly suggest *how* to analyze these datasets, they implicitly suggest that the authors should investigate this further."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out a weakness in the paper's discussion of applying DIMES to the TSP and suggests a comparison with other methods. This directly identifies a missing element or area for improvement, making it actionable for the authors. The suggestion to compare with other methods, while not a specific step, implies a concrete action: to include such a comparison in the paper.", "grounding_specificity_rationale": "The reviewer's comment is somewhat implied. While they don't explicitly state 'Section 3.2' or 'Figure 4', the context of discussing the 'generalization gaps' and the 'finetuning step in DIMES' strongly suggests they are referring to a specific part of the paper's method description. However, the suggestion to compare with other methods is a broader point about the experimental setup and doesn't directly pinpoint a specific element within a section or table. Therefore, it's somewhat grounded in the method description but not a precise reference.", "verifiability_rationale": "The reviewer's suggestions are logical and relevant to the TSP. They point out a potential area for improvement in the paper's clarity regarding the generalization gaps. The reviewer's statements are based on logical reasoning and the expected behavior of RL methods. While they don't provide specific examples or references, the suggestions are verifiable and point to a potential weakness in the paper's explanation or presentation.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: to include a comparison with other methods on TSP100. This directly addresses a potential weakness in the paper's experimental evaluation and provides a concrete direction for improvement. The suggestions are welldefined and directly relevant to enhancing the paper's contribution and clarity."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks \"Do you have any evidence that the geometry of the space you end with is meaningful?\" This indicates an intention to identify a weakness or an area for improvement. However, the reviewer does not specify *which* embeddings or analyses they are referring to, making the action somewhat implicit. The reviewer also suggests a method for verification (\"It would be nice to have some analysis...\") but does not provide a concrete stepbystep action on how to perform this analysis. Therefore, while the reviewer identifies a potential issue, the explicitness and concreteness of the action are lacking.", "grounding_specificity_rationale": "The reviewer's question is general and does not point to a specific part of their paper or the model being discussed. They are asking about the *meaningfulness* of the geometry of the learned space in general. While the question is relevant to their work, it does not identify a specific section, table, figure, or unique aspect of their paper or the model. The reviewer is asking a question about the model's output in general, not about a specific element of their work. Therefore, the grounding is weak as the reviewer cannot confidently determine which part they are addressing.", "verifiability_rationale": "The reviewer poses a question about the meaningfulness of the learned space and suggests a method for verification: \"e.g. does \"looking\"  \"look\" + \"walk\" = \"walking\"?\" This constitutes a claim that the geometry of the space is meaningful. The reviewer also provides a suggestion for how to verify this claim by performing a specific calculation. While the suggestion is not a detailed analysis, it provides a concrete method for investigation. Therefore, the claim is present and the reviewer offers a method to verify it, making it 3.", "helpfulness_rationale": "The reviewer's question directly relates to the potential utility of the model's output for understanding semantic relationships and the geometry of the embedding space. They are asking whether the model's learned space is meaningful in the context of morphological variants. This is a relevant question for the authors if they are using such a model. While the question is not a direct solution or fix, it is a valuable piece of feedback that could guide further development or application of the model. Therefore, the review point is helpful in identifying a potential area for further investigation or clarification."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the change made to the quantum operation (replacing the first column of Qo with vo) and the consequence of this change (the first state is no longer reachable but becomes a terminating state). This constitutes an explicit action. However, the reviewer does not provide concrete steps or guidance on how the author should implement this change or address the potential issue of the first state becoming a terminating state. The action is identified, but the implementation details are missing.", "grounding_specificity_rationale": "The reviewer refers to 'the first column of Qo' and 'the first state' in their review point. While they don't provide a specific section number, the reference is precise and directly identifies the part of the paper being discussed. The reviewer also specifies that the state becomes a terminating state due to the change. This level of specificity allows the reader to pinpoint the relevant aspect of the paper. The reviewer also mentions 'Assumption 1' and 'Assumption 2', which further grounds the reference to specific assumptions.", "verifiability_rationale": "The reviewer makes a claim that 'I assume that either Assumption 1 (finite length of an option) or Assumption 2 (some other assumption) is responsible.' This is a claim that requires justification. However, the reviewer does not provide any logical reasoning, examples, or external references to support this assumption. The connection between the change in the quantum operation and the specific assumptions is not clearly explained or justified. The reviewer presents the assumption without sufficient evidence or explanation.", "helpfulness_rationale": "The reviewer points out a potential issue with the theoretical construction by showing how a change in the quantum operation could lead to the first state becoming a terminating state. While this identifies a potential problem, it does not offer concrete advice or steps for the author to take to address this issue. The reviewer assumes that either Assumption 1 or Assumption 2 is responsible for this change but does not explain how these assumptions relate to the quantum operation or provide any guidance on how the author should proceed. The reviewer's point raises a concern but does not provide actionable feedback for improvement."}
{"actionability_label": "Low", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states that the comment is 'unclear' regarding the 'scoring function' and its components. This lack of clarity makes it difficult for the authors to understand the basis for the comment and how to improve their work based on it. The absence of explicitness and concreteness in the reviewer's statement further reduces the actionability of the comment. The authors cannot identify what aspect of the scoring function is unclear or what specific changes are being suggested.", "grounding_specificity_rationale": "The reviewer does not explicitly state which components of the 'scoring function' are unclear or provide specific examples. The criticism is general, stating that the 'scoring function' is unclear without pinpointing the exact issue. Therefore, the grounding of the comment is weak as it does not clearly identify the specific part of the paper or method being questioned. The lack of specificity makes it difficult to understand the nature of the problem.", "verifiability_rationale": "The reviewer makes a claim that the 'scoring function' is unclear and that the thresholds and components are not welldefined. However, the reviewer does not provide any evidence or justification for this claim. They state the lack of clarity but do not explain *why* it is unclear or *how* it was supposed to work. Therefore, the verifiability of the comment is low as there is no supporting evidence for the claim made by the reviewer.", "helpfulness_rationale": "The reviewer's statement that the comment is 'unclear' directly impacts the helpfulness of the review point. If the authors cannot understand the basis of the comment, they cannot effectively use it to improve their draft. The lack of clarity makes the review point unhelpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the problem: 'making the factors in a table does not help convey more messages than pure text.' This is a clear and concrete action the authors should take (improve table design). Therefore, it is 5.", "grounding_specificity_rationale": "The reviewer makes a general statement about tables not being effective. They do not specify which table or section they are referring to. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim ('making the factors in a table does not help convey more messages than pure text') but does not provide any evidence, examples, or references to support it. Therefore, the claim is 1.", "helpfulness_rationale": "The reviewer identifies a potential issue with table design but does not offer any solutions or suggestions for improvement. They are simply stating that tables aren't effective. Therefore, the review point is not helpful to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the risk of false positives as a consequence of the dropout probe. This constitutes an explicit action or suggestion. However, the reviewer does not provide concrete details on how this risk manifests or how it should be addressed. The phrase 'all other things being equal' adds a layer of vagueness, making it difficult to fully grasp the actionable steps.", "grounding_specificity_rationale": "The reviewer mentions the risk of false positives but does not explicitly link this risk to a specific part of the paper or methodology. They do not mention a specific section, table, figure, or unique element where this risk might be more pronounced. The concern is presented generally, without pinpointing the source of the issue.", "verifiability_rationale": "The reviewer presents a claim: 'This also increases the risk of false positives.' This is a clear statement requiring justification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. They state it as a concern without explaining *why* or *how*.", "helpfulness_rationale": "The reviewer raises a valid concern about the potential increase in false positives due to the dropout probe. This is a relevant point for the authors to consider and discuss. While the reviewer does not offer specific solutions, they highlight a limitation of the approach, which is valuable information for improvement. The comment prompts the authors to think critically about the tradeoffs of their method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the regret bound is claimed to be in the appendix but then states they did not find it. This indicates an explicit claim about the location, but the lack of finding makes the action implicit or vague.", "grounding_specificity_rationale": "The reviewer mentions 'supplementary' and 'appendix' as potential locations, which can be interpreted as grounding. However, the reviewer actively searched and did not find the regret bound, indicating the information was not clearly presented or easily accessible within those sections.", "verifiability_rationale": "The reviewer claims the regret bound is in the appendix and then states they did not find it. This is a clear claim that is not supported by evidence, making it 1.", "helpfulness_rationale": "The reviewer directly points out a potential issue with the paper's organization or presentation by claiming the regret bound is in the appendix and then stating they couldn't find it. This is a clear and actionable feedback for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the use of two SIRENs and questions the necessity of this design choice, suggesting a simpler network for 'd'. This is an explicit statement with a clear action: 'Suggest a simpler network for d'.", "grounding_specificity_rationale": "The reviewer doesn't explicitly point to a specific section or figure number. However, the context of discussing 'f' and 'd' suggests they are referring to the network components described in the paper. While not perfectly explicit, the grounding is reasonably clear.", "verifiability_rationale": "The reviewer makes a claim about the potential inefficiency of using two SIRENs and suggests an alternative. This claim could be supported by comparing performance or citing literature on network efficiency, making it 3.", "helpfulness_rationale": "The reviewer points out a potential design choice and suggests an alternative, directly helping the authors understand a potential area for improvement and make informed decisions about their network architecture. This is a constructive suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point is not actionable. It is a request for clarification, not a directive for the author to make changes. Explicit vs. Implicit: Implicit. Grounding Specificity: 3. Verifiability: 3. Helpfulness: Not Helpful.", "grounding_specificity_rationale": "The reviewer mentions a specific area of related work ('semantic face editing') and provides a citation. However, the exact paper is not mentioned, and the reviewer does not explicitly state how their work differs from the mentioned area. Explicit vs. Implicit: Implicit. Grounding Specificity: 3. Verifiability: 3. Helpfulness: Not Helpful.", "verifiability_rationale": "The claim is that 'there are also some other works focusing on the semantic face editing and they show the ability to achieve continuous control over different attributes, like 1'. This is generally verifiable by referencing the field and the provided citation. Explicit vs. Implicit: Implicit. Grounding Specificity: 3. Verifiability: 3. Helpfulness: Not Helpful.", "helpfulness_rationale": "The review point is a question seeking clarification, not a constructive critique or suggestion on how to improve the author's draft. Explicit vs. Implicit: Implicit. Grounding Specificity: 3. Verifiability: 3. Helpfulness: Not Helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'move important content to the main body' and 'move details around parameter settings etc. to the appendix'. These are direct instructions on how to improve the paper. The reviewer also implies an action on the footnote issue by stating it's 'too extensive and distracting', which suggests a desire for better organization. However, the action on the footnote issue is not explicitly stated as a concrete action to take. The actions are implicit in the suggestions.", "grounding_specificity_rationale": "The review point explicitly mentions 'footnotes', 'important content', and 'details around parameter settings etc.', which are specific parts of the paper. The reviewer also refers to a specific location in the paper (e.g., 'L468'), which further grounds the reference. The actions to move these elements are also grounded in specific locations. The grounding is strong as the reviewer clearly identifies the sections and types of content involved.", "verifiability_rationale": "The review point contains a claim: 'it's actually very distracting'. This is a judgment about the impact of the footnotes. The reviewer also provides suggestions: 'much of the content is actually important' and 'details around parameter settings etc. can be moved into the appendix to make space'. These suggestions are based on common knowledge about the need for clarity and conciseness in academic writing. The claim is supported by the reviewer's observation about the distraction, and the suggestions are logical and common sense. The evidence is logical and commonsense based on the reviewer's observation.", "helpfulness_rationale": "The review point provides clear and actionable feedback on a specific issue (excessive footnotes) and offers concrete solutions (move important content to the main body, move details to the appendix). The suggestions are directly linked to improving the clarity and organization of the paper. The reviewer is not just pointing out a problem but also suggesting a solution, making it 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors used their own defined 'vanilla metric' and criticizes this approach for lacking 'fairnessaware metrics like Equality odds (EO)'. This is a clear and actionable suggestion. The authors are directly pointed to a specific area of improvement and a concrete alternative. The reviewer is not inferring the need for standard metrics, but rather stating it explicitly.", "grounding_specificity_rationale": "The review point mentions 'related fairnessaware metrics like Equality odds (EO)' and suggests 'conducted more experiments on more datasets like COMPAS and Drug Comsumptionm'. This demonstrates some grounding as the authors are referred to specific concepts and potentially specific experimental setups. However, the review does not explicitly state which part of the paper (e.g., methodology, results) needs improvement in relation to these metrics or datasets. The grounding is implicit rather than explicit.", "verifiability_rationale": "The review point makes a claim that the authors 'use their own defined vanilla metric' and 'lack related fairnessaware metrics like Equality odds (EO)'. This claim is verifiable as it is a direct statement about the authors' methodology and a recognized concept in fairness evaluation. Furthermore, the reviewer suggests 'conducting more experiments on more datasets like COMPAS and Drug Comsumptionm', which provides a clear justification for the criticism. The reviewer also recommends citing a specific paper, which further supports the claim. The reasoning is logical and the reference to Equality Odds is explicit.", "helpfulness_rationale": "The review point is 5 as it directly identifies a specific weakness in the authors' methodology (using a custom metric instead of standard fairness metrics) and provides a clear suggestion for improvement (using established fairness metrics like Equality Odds). The reviewer also offers practical advice (conducted more experiments on more datasets) and even suggests a relevant research paper. The criticism is specific and actionable, providing the authors with a clear path to enhance their work. The reviewer's suggestions are not just general but are tied to specific concepts and methodologies."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'Authors don\u2019t verify the stability of the OGEAug on OOD benchmarks such as DrugOOD'. This clearly indicates an implicit action: the authors should be verifying this stability. The suggestion to use DrugOOD and validate with SPE further clarifies the intended action. Therefore, the action is explicit, even though the reviewer doesn't name it directly.", "grounding_specificity_rationale": "The review point mentions 'stability of the OGEAug' and suggests 'DrugOOD'. While it implies that the authors should be looking at the OOD performance, it doesn't explicitly name the section or table where this information would be located. The suggestion to 'validate this with SPE' is a concrete action but doesn't specify *how* they should perform the validation on DrugOOD. Therefore, the grounding is weakly implied and the specificity of the grounding is underspecific.", "verifiability_rationale": "The review point presents a claim: 'Authors don\u2019t verify the stability of the OGEAug on OOD benchmarks such as DrugOOD'. This claim is supported by the suggestion to use DrugOOD and validate with SPE, which provides a concrete external reference (the DrugOOD dataset and the method SPE). Therefore, the claim is fully supported by explicit, sufficient, and robust evidence, such as: Clear reasoning and precise explanations. Specific references to external works. Logical and unassailable commonsense arguments. (While the reasoning isn't deeply technical, the reference to a validated dataset provides a strong basis).", "helpfulness_rationale": "The review point directly points out a potential weakness (lack of OOD testing) and provides a concrete suggestion (DrugOOD and validation with SPE). This is likely to be 5 for the authors as it directly addresses a potential area for improvement and provides a clear next step. The suggestion is actionable and directly linked to a relevant benchmark and a validation method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for the *motivation* behind the choice of distributions, which is an implicit request for justification. While they are not directly asking for a calculation or a stepbystep explanation of *how* to choose these distributions, understanding the *why* is crucial for the author to grasp the significance of these choices. The reviewer is essentially prompting the author to explain the reasoning behind their methodological decision.", "grounding_specificity_rationale": "The reviewer is asking about the *angle and magnitude* of the target vector, which is a specific aspect of the method. However, they are not explicitly pointing to a specific section, table, or figure in the paper where these concepts are discussed. They are referencing a general methodological choice, making the grounding somewhat weak. The reviewer is asking *what* about the distributions, which is specific, but they are not naming a section or element.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are simply stating that they are unclear about the *motivation* behind the choice of distributions. There is no assertion of a fact or a request for evidence to support a claim. The reviewer is pointing out a lack of explanation, not a claim that needs to be proven.", "helpfulness_rationale": "The reviewer is asking a question that is likely to be helpful for the author. They are seeking clarification on a methodological choice, which is a valuable piece of feedback. While they are not providing a solution, they are prompting the author to explain their reasoning, which could lead to a better understanding of the method. The helpfulness lies in the potential for the author to gain insight."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states that it is not clear how the quantitative results are obtained. This directly implies a lack of clarity regarding the methodology used to generate these results. The reviewer is asking for specific details about the process, which is an explicit action. The concreteness of this action depends on the level of detail provided about the steps involved in obtaining the quantitative results.", "grounding_specificity_rationale": "The reviewer needs to know what data is used for training, validating, and testing. This implies that the paper should explicitly identify the specific parts of the paper where this information is supposed to be found. The grounding of this information depends on whether the paper points to specific sections, descriptions, or external references related to the data splitting strategy.", "verifiability_rationale": "The reviewer makes a claim that it is not clear how the quantitative results are obtained. The verifiability of this claim depends on whether the paper provides sufficient justification or evidence to support the claim that the results are clear. This could involve citing relevant literature, providing logical reasoning, or referencing external sources.", "helpfulness_rationale": "The reviewer's inability to understand how the quantitative results are obtained is a significant hindrance to their ability to improve their draft. The helpfulness of the information provided (or lack thereof) depends on whether the paper offers sufficient details about the data splitting and the methodology used to obtain the results. If the information is completely missing, the reviewer's ability to understand the results is severely limited."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their desire to see the system generalize to more views. This is an explicit action. Once the action is identified (generalize to more views), the reviewer provides a reason (it feels like it shouldn't be too difficult), making it concrete.", "grounding_specificity_rationale": "The reviewer mentions 'views' in the system but doesn't specify which views or provide details about the existing two. The reviewer's statement is about the *number* of views and the *ability* to generalize, which is a highlevel concept. While the reviewer has identified a specific area (views), they haven't pinpointed the exact part of the system or the existing views being referred to.", "verifiability_rationale": "The reviewer states that the system *should* be able to generalize to more views. This is a claim. However, the reviewer does not provide any evidence, reasoning, or external references to support this claim. The statement is based on a feeling or intuition rather than a logical argument or citation.", "helpfulness_rationale": "The reviewer expresses a desire for the system to generalize to more views. This is a valid point that could be helpful for the authors. However, the reviewer does not provide any specific suggestions or justifications for why this generalization should be possible. The comment is a statement of desire rather than a concrete suggestion or justification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: 'these metrics are not suitable for the datasets provided'. This is a clear and direct identification of a problem. The reviewer also explains *how* they are unsuitable: 'they are designed for the datasets where either the task boundaries are not known or there are no hard task boundaries to be identified'. This provides a clear action for the authors: they should consider metrics suitable for scenarios with known task boundaries.", "grounding_specificity_rationale": "The reviewer explicitly identifies the 'metrics used for evaluating continual learning, loss after switch and recovery time after switch' as the specific part of the paper being addressed. They also specify the *type* of datasets 'provided' as the context. This strong identification of the specific metrics and dataset type demonstrates high grounding specificity.", "verifiability_rationale": "The reviewer makes a claim: 'these metrics are not suitable for the datasets provided'. The reviewer then provides a justification for this claim by explaining the design principles of the mentioned metrics (continual learning, loss after switch, recovery time after switch) and how they are specifically suited for scenarios with *known* task boundaries. This logical reasoning makes the claim verifiable.", "helpfulness_rationale": "The reviewer provides a clear critique of the chosen metrics and their suitability for the given datasets. They explain *why* these metrics are not appropriate. This critique is actionable for the authors, guiding them towards alternative evaluation strategies. The reviewer's feedback is directly aimed at improving the methodology and potentially the results presented in the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly identifies the potential confounding factor of 'head location' as an issue in the ablation study and provides a clear suggestion to create a 'controlled baseline' by ablating heads at different locations. This directly addresses a gap in the methodology and offers a concrete action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'head location' as the confounding factor and suggests a 'controlled baseline' by ablating heads at different locations within the model. This clearly identifies the specific part of the paper (ablation study) and the issue within it (head location), demonstrating strong grounding specificity.", "verifiability_rationale": "The reviewer provides a specific suggestion for an improvement: creating a controlled baseline by ablating heads at different locations. While it doesn't provide a novel research question, it offers a concrete and actionable method to address the identified issue, making it 3.", "helpfulness_rationale": "The reviewer clearly identifies a valid concern regarding the potential influence of head location on ICL performance when ablating induction heads versus FV heads. They provide a specific and relevant suggestion for improving the experimental design by introducing a controlled baseline. This directly addresses a potential weakness in the methodology and offers a clear path for improvement, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they would like simplification and better explanation, which are direct actions the authors can take. They also point to specific sections and lines (3964) and Figure 7, Section 8 as areas needing improvement, indicating a clear focus on these parts. The suggestion to reduce content further reinforces the actionable nature of the feedback.", "grounding_specificity_rationale": "The reviewer accurately identifies specific sections (Figure 7, Section 8) and lines (3964) within the paper that need improvement. They not only identify the section but also point to a specific part within that section (lines 3964) requiring clarification. Furthermore, they provide a specific suggestion for improvement within that identified area (simplifying the architecture and computations). This precise identification and targeted suggestion demonstrate strong grounding and specificity.", "verifiability_rationale": "The review point primarily focuses on identifying areas where the paper is unclear and suggesting improvements. There is X being made that requires verification or evidence. The reviewer is not stating 'This is definitely wrong' but rather suggesting ways to make the paper easier to understand. Therefore, it does not fall under the category of verifiability.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improving the paper's clarity and reducing its density. They specifically point to areas that require simplification and better explanation, and they suggest a concrete way to achieve this by reducing content. This targeted and constructive feedback is highly valuable for the authors and directly addresses a stated concern, making it 5."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment explicitly states 'Figure 4 is confusing.' This is an explicit action that points to a specific area needing improvement. However, it doesn't provide concrete steps on how to address the confusion. It identifies a problem but doesn't offer a direct solution within the comment itself.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 4' as the source of confusion. This indicates that the author can identify the specific part of the paper being addressed. However, the comment does not specify what is confusing within Figure 4 (e.g., the columns, the data, the labels). Therefore, while grounded, it is not specific about the issue.", "verifiability_rationale": "The comment states 'Figure 4 is confusing' without making a definitive claim about *why* it is confusing or *whether* it is an error. While the lack of explanation could be considered a claim in some interpretations (that something is unclear), it doesn't provide a basis for verifiable evidence. The reviewer is expressing a concern, but not a claim that requires justification.", "helpfulness_rationale": "The comment identifies a specific area of the paper (Figure 4) that needs improvement and asks for clarification. This is a form of actionable feedback that empowers the authors to address the confusion. While it doesn't provide a complete solution, it points to a genuine issue that needs attention and encourages the authors to seek more information or clarification."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review explicitly states the findings of experiment 2 and connects it to the use of 'Th.', indicating an explicit action. However, it doesn't specify which theorem or threshold is being referred to, and the 'how' of using it isn't detailed.", "grounding_specificity_rationale": "The review explicitly refers back to 'experiment 2', grounding the discussion in a specific result. The condition ('number of classes > 8') also provides a clear reference point. However, the review doesn't explain the significance of this finding.", "verifiability_rationale": "The review mentions 'Th.' but doesn't provide any justification or context for its use. There's no explanation of why a theorem/threshold is relevant in this context, nor is there a reference to external sources.", "helpfulness_rationale": "The review points to a specific experimental result and suggests a potential area for further analysis ('use Th.'). While this can be valuable, the lack of detail on *which* theorem and *how* to apply it makes it difficult for the authors to act on this suggestion."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential confusion in Eq. 3 regarding the use of p_m in the numerator and p_c in the denominator. While this is a symptom of a potential issue, it doesn't explicitly state an action the authors should take. However, the reviewer's suggestion to 'add the variance for further improvement' in Alg. 2 and the suggestion to use \u03bc_g for consistency with Eq. are both explicit actions the authors could undertake. The reviewer also states 'By the way, it is better to use \u03bc g , which is consistent with Eq.', which is an explicit action. The reviewer's point is partially actionable as it points out a potential issue and suggests concrete improvements.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Eq. 3', 'Alg. 2', 'p m', 'p c', '\u03bc f', and '\u03bc g'. This indicates a strong grounding as the reviewer is pointing to specific elements within the paper. The reviewer's suggestions are directly tied to these specific elements, further strengthening the grounding.", "verifiability_rationale": "The reviewer states 'In Eq. 3, it is confusing to use p m in the numerator but use p c in the denominator. What is the reason?' This is a claim that requires justification. The reviewer also states 'In Alg. 2, only the mean \u03bc f is used for the fusion prototype. Have the authors considered adding the variance for further improvement?' This is a claim that suggests a potential improvement. Finally, the reviewer states 'By the way, it is better to use \u03bc g , which is consistent with Eq.', which is a claim that suggests a change for consistency. All these claims are verifiable as they point out potential issues or suggest improvements that could be supported by evidence or experimentation.", "helpfulness_rationale": "The reviewer's point is 5. By pointing out the potential confusion in Eq. 3, they are directly informing the authors about a potential area of misunderstanding. The suggestion to add variance in Alg. 2 is a concrete improvement idea that could directly benefit the authors. The suggestion to use \u03bc_g for consistency with Eq. is also a concrete and actionable suggestion that could improve the clarity and correctness of the method. All aspects of the reviewer's point are suggestions that directly address potential issues or propose concrete improvements, making it 5 to the authors."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their desire for a more comprehensive discussion on computational cost and complexity, which is an explicit action. They also raise a question about scalability, further indicating an action to explore this aspect. The phrase 'I believe the paper deserves a more comprehensive discussion' directly implies an action to improve the discussion.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific area for improvement as 'computational cost' and 'computational complexity'. They also mention a specific point within this area: 'it is not clear why the paper mentions the additional cost didn't lead to 'significant delays in computation\"'. This precise identification of the section and the issue within it demonstrates strong grounding specificity. The reviewer is not just making a general comment; they are pointing to a specific location and a specific problem within that location.", "verifiability_rationale": "The reviewer makes a claim about the *absence* of discussion regarding 'significant delays in computation'. This is a claim that needs to be supported. However, the review *itself* does not provide any evidence or reasoning to support this claim. The reviewer is highlighting a gap in the existing information, but the *review* itself doesn't offer a verifiable statement. While the reviewer's suggestion to discuss it is helpful, the current review point doesn't *verify* the claim about the missing information.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'I believe the paper deserves a more comprehensive discussion about the computational complexity of the proposal. Also, I wonder if the proposed approach becomes prohibitive in some settings.' This is a direct and constructive suggestion for improvement. The reviewer is not making a subjective judgment about the paper's quality; they are pointing out a specific area where the paper could be improved and suggesting a concrete way to do so. This makes the review point helpful for guiding the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that 'Similar methods have already been proposed...'. This indicates an explicit action or suggestion. However, the reviewer does not specify the exact nature of the similarity or the specific aspects of multitask learning that are missing. Therefore, while the action is stated, the lack of detail makes it somewhat vague.", "grounding_specificity_rationale": "The comment does not explicitly identify any specific part of the paper being addressed. It is a general statement about the paper's content and a related topic (multitask learning). Therefore, the grounding is weak as the authors cannot confidently determine which section, table, figure, or unique aspect the comment refers to.", "verifiability_rationale": "The comment criticizes the lack of discussion of similar methods in multitask learning. While this is a claim, the paper does not explicitly state that similar methods have not been discussed. Therefore, the claim is not fully supported by evidence within the paper. The verifiability is low because the paper itself contradicts the reviewer's statement.", "helpfulness_rationale": "The comment points out a potential weakness in the paper by highlighting the absence of discussion on similar methods in multitask learning. This can be helpful for the authors to identify a gap in the related work and potentially expand their discussion. However, the comment itself does not provide specific guidance on how to address this weakness or what aspects of multitask learning might be relevant. Therefore, the helpfulness is somewhat limited as it lacks concrete suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is prompting for a comparison of the computational cost of FedMITR with other methods. While this is a valid suggestion, it is not an explicit action or statement that the author should take. The reviewer is essentially asking 'Did you consider the computational cost of FedMITR compared to others?'", "grounding_specificity_rationale": "The reviewer is not explicitly pointing to a specific section, table, figure, or unique element of the paper. They are making a general comment about the computational cost of a method. Therefore, the grounding is weak.", "verifiability_rationale": "The comment is a question about a potential implementation detail (computational cost) and does not present a claim that requires verification. It's a request for information rather than a statement that needs to be proven.", "helpfulness_rationale": "The reviewer is asking a question that directly addresses a potential implementation detail (computational cost) that could be relevant for practical use or comparison. This highlights a potential gap in the information provided and is therefore helpful for the author."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that 'the experimental results do not contain standard deviations'. This is a direct identification of a specific issue that the authors should address. The reviewer clearly points out the missing information and its potential impact on the interpretation of the results. Therefore, the action is clearly defined and concrete.", "grounding_specificity_rationale": "The review point refers to 'the experimental results' as the part of the paper being addressed. While this identifies the general area, it doesn't specify which subsection, table, figure, or specific analysis within the experimental results is lacking standard deviations. The reviewer mentions the *type* of information missing but not the *exact location* of the missing information. This is a 'Weak Grounding' because the authors can't confidently pinpoint the referenced part. However, the reviewer does specify what is missing ('standard deviations') and what the consequence is ('making it hard to judge the significance'), providing some level of 'Specificity'. Therefore, it's 'Somewhat Specific' as the grounding is weak but the issue is clear.", "verifiability_rationale": "The review point makes a claim: 'the experimental results do not contain standard deviations and therefore it is hard to judge the significance of the results'. This is a clear statement of a problem and its consequence. While the reviewer doesn't provide external references to support this claim, the absence of standard deviations is a factual observation, and the difficulty in judging significance is a logical consequence of this omission. The claim is supported by the information provided in the review point. Therefore, it can be considered 'Partially Verifiable' as the claim is supported but lacks external references.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the authors: 'The experimental results do not contain standard deviations and therefore it is hard to judge the significance of the results'. This directly points out a crucial piece of information that is missing and its direct impact on the authors' ability to interpret their results. The reviewer's comment is directly relevant to improving the authors' understanding and analysis of their experimental data. Therefore, the review point is 5 and directly addresses a significant issue for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is about suggesting improvements to the presentation and analysis of results, which is a *desire* rather than a direct instruction on how to *change* the paper. The authors are not being asked to *do something* to the paper based on this comment, but rather to *consider* certain aspects. Therefore, it's not an explicit action or a concrete instruction on how to apply the suggestion.", "grounding_specificity_rationale": "The review point expresses a desire for *qualitative* results and a *zoomedin view* but does not explicitly identify a specific part of the paper where these improvements are needed. It's a general suggestion about the overall presentation and analysis, without pinpointing a particular section, table, figure, or unique aspect of the paper. The authors are not told *where* the problem lies, only *what* kind of improvements they should be looking for.", "verifiability_rationale": "The review point is a suggestion or a desire for certain types of results, not a claim that needs to be verified. There is no explicit assertion that the current method is flawed or lacking specific details. It's a suggestion about future work or analysis, not a statement that requires evidence to support it.", "helpfulness_rationale": "The review point suggests improvements in presentation and analysis, which could be helpful for the authors in terms of understanding and interpreting their results. However, the lack of specific grounding and actionability means the authors don't immediately know *how* to implement these suggestions based on the paper itself. It's a potential direction for future work, but not a direct and actionable improvement for the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a missing analysis of the time complexity of the proposed policies. While it doesn't explicitly state how to analyze the time complexity, it clearly points out a potential improvement area. The authors can directly identify the need to analyze the time complexity of the policies mentioned in Section 4.", "grounding_specificity_rationale": "The reviewer points out the requirement to analyze the time complexity of policies in Section 4 but does not explicitly identify which specific policy or section within the paper this refers to. The authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point makes a statement about what is missing (the time complexity analysis) and suggests what should be done (analyze the time complexity). This can be considered a suggestion or recommendation. While it doesn't provide specific examples or references, it is logically implied that this analysis is necessary for a thorough evaluation of the policies.", "helpfulness_rationale": "The review point identifies a clear weakness in the original draft \u2013 the lack of time complexity analysis for the proposed policies. It suggests a potential improvement by directing the authors to analyze this aspect. While it doesn't provide specific details on how to perform the analysis, it is a valuable piece of feedback that guides the authors towards a necessary improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer states \"The paper overclaims the strength of the proposed BC loss in theoretical analysis.\" This is an implicit statement, as the reviewer is not directly instructing the authors on what to do. While they identify potential areas of overclaiming (geometric interpretability, Theorem 1, high/low entropy representations, hardnegative mining), they do not explicitly state what needs to be changed or how the overclaiming manifests. The action remains for the authors to investigate and potentially address these potential issues. Therefore, the actionability is somewhat limited as it requires the authors to take initiative rather than being directly told what to do. The reviewer's point is more about prompting a critical review of their own claims rather than directly instructing a specific action.", "grounding_specificity_rationale": "The reviewer's comment is 1 in the paper. They are making a general statement about the potential overclaiming of the BC loss's strength without specifying which section, table, figure, or unique aspect of the paper they are referring to. The reviewer is speculating about the nature of the overclaiming (geometric interpretability, Theorem 1, etc.) but does not provide any direct references or specific details within the paper to support this claim. Therefore, the grounding specificity is low as the authors cannot confidently identify the part of the paper being discussed.", "verifiability_rationale": "The reviewer's claim that the paper overclaims the strength of the BC loss is not 5. While they offer potential explanations for the overclaiming (geometric interpretability, Theorem 1, etc.), they do not provide specific examples, references, or logical reasoning to support their claim within the paper. The reviewer is speculating about the relationships between these concepts rather than providing concrete evidence. Therefore, the verifiability is borderline as the reviewer hints at a potential issue but lacks strong supporting evidence within the paper itself.", "helpfulness_rationale": "The reviewer's comment is 3 as it points to a potential area for improvement in how the authors present their theoretical analysis. By highlighting the potential overlap between different concepts (geometric interpretability, Theorem 1, etc.), the reviewer encourages the authors to critically examine their claims and potentially provide more distinct and rigorous justifications. While it doesn't directly tell the authors what to change, it prompts a more thorough and nuanced discussion of their theoretical contributions. Therefore, the helpfulness is moderate as it encourages selfreflection and potential improvement in the presentation of the theoretical analysis."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the reason for using focal loss in classification (class imbalance and lower gradients) and then points out the potential issue with using it for regression (inaccurate gradients). They also hypothesize that the authors might be taking a unified approach without considering the differences between classification and regression tasks. This provides a clear action for the authors to consider: investigating alternative loss functions or modifications to focal loss specifically for regression tasks.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific aspect of the paper being discussed: 'focal loss is used in regression tasks' and then narrows it down to 'IoU regression.' They also specify the potential issue: 'lower weight for easy samples may cause inaccurate problem.' This precise identification of the part of the paper being addressed and the specific problem is a strong demonstration of grounding specificity.", "verifiability_rationale": "The reviewer provides a logical argument for why focal loss might be problematic for regression, based on its known properties. However, they do not provide direct evidence or citations to support their claim that the authors are taking a naive unified approach. The reasoning is sound, but the lack of direct proof makes it partially verifiable.", "helpfulness_rationale": "The reviewer's point is insightful and raises a valid concern about the potential mismatch between focal loss and IoU regression. This is helpful because it highlights a potential flaw in the authors' approach and suggests a direction for further investigation or experimentation. While it doesn't provide a direct solution, it prompts the authors to consider the implications of their choice of loss function for the specific task."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a concern about the impact on predictive model performance but does not explicitly propose a solution or action to address it. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer mentions 'severely damaging the performance of predictive model' but does not specify which part of the paper this refers to. The connection is implied but not explicit.", "verifiability_rationale": "The reviewer makes a claim about the paper's approach ('severely damaging the performance of predictive model') but does not provide any specific evidence or references to support this claim within the review point itself.", "helpfulness_rationale": "The reviewer offers a suggestion to show how to achieve fair policy learning without severely damaging predictive model performance. This highlights a potential weakness in the paper's presentation or justification regarding the tradeoff. While not a direct solution, it's a constructive comment aimed at improving clarity and addressing a potential lack of justification."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of a definition for the 'contrastive gap' and suggests a 'clear, formal definition'. This is a direct and actionable request for the authors to improve their draft.", "grounding_specificity_rationale": "The reviewer identifies the 'contrastive gap' as the unclear area and suggests a 'clear, formal definition'. While they don't pinpoint a specific section or table, they clearly identify the concept that needs clarification. The suggestion to provide a 'clear, formal definition' adds some level of specificity to the area of the paper that needs improvement. The reviewer also implies that the authors can deduce the need for a definition based on the mention of the 'contrastive gap'.", "verifiability_rationale": "The reviewer does not present a claim or assertion about the paper's quality or correctness. They are pointing out a deficiency and suggesting a specific type of improvement. This does not involve logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer clearly identifies a problem ('lack of clarity') and provides a direct suggestion for improvement ('a clear, formal definition'). This actionable feedback is helpful for the authors to understand what needs to be addressed."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two explicit actions: (1) pointing out an inaccuracy in the description of reward in standard MDP formulations at line 143 and (2) identifying a lack of clarity in the definition of actions at line 154. These are clear and actionable suggestions for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions the lines in the paper they are referring to ('section 3.1, line 143' and 'line 154'). They also clearly specifies the issues at each line ('inaccurate for standard MDP formulations' and 'unclear if each action is a single feature or the power set'). This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer makes claims about the inaccuracies in the MDP description. The claim about line 143 being inaccurate for standard MDP formulations is verifiable based on common knowledge of MDPs. The claim about the unclear definition of actions at line 154 is also verifiable by pointing to the ambiguity of 'action'. The reviewer provides logical reasoning to support these claims.", "helpfulness_rationale": "The review point is 5 as it directly points out specific issues in the text and suggests concrete improvements. The reviewer clearly identifies inaccuracies in the MDP description and the lack of clarity in the definition of actions, providing the author with actionable feedback to improve their work. The suggestions are clear and directly address potential misunderstandings."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies the phrase 'to meet' as unclear. While they suggest changing it, the action of *identifying* the unclear phrase itself is implicit. The reviewer doesn't specify *how* to change it or what alternative phrasing is better, making the action vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions the phrase 'a response candidate can meet each utterace' and the specific part of the sentence containing 'to meet'. They are pointing to a specific location in the text, indicating strong grounding. They are not making a general comment about the paper but rather focusing on a specific instance.", "verifiability_rationale": "The reviewer makes a claim about the phrase 'to meet' being difficult to understand. This claim is verifiable by examining the sentence itself. The lack of clarity is a logical reasoning that can be observed in the text. While no external reference is provided, the evidence is present within the sentence.", "helpfulness_rationale": "The reviewer identifies a problem ('difficult to understand') and provides the line number. This directly points to an area for improvement. However, the reviewer does not offer a specific solution or suggestion on how to improve the clarity of the phrase. The feedback is identified but not fully constructive in terms of providing a direct action."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue and suggests a correction. This is a clear, actionable piece of feedback. The reviewer identifies the Perceptual Metric and the lines they believe should be connected, indicating a direct action the authors can take to improve the figure's clarity.", "grounding_specificity_rationale": "The reviewer explicitly identifies the Perceptual Metric in Figure 2 and the specific lines they believe should be connected. This demonstrates a high level of specificity in pinpointing the relevant part of the paper and the issue within it.", "verifiability_rationale": "The reviewer makes a claim about the figure's accuracy. While they don't provide external evidence to support this specific claim, the claim itself is verifiable by examining Figure 2. The reviewer states a belief about the correct connections, which can be checked against the figure.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by pointing out a potential error in Figure 2. This directly addresses a potential source of confusion for the authors and would significantly enhance the clarity of the paper. The suggestion is concrete and directly actionable."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an action (exploring alternatives) and critiques a specific implementation (training many models). However, the justification for the alternative is presented as a drawback of the original approach, making the action somewhat indirect and not fully actionable for the authors in its current form.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or methodology it is criticizing. It presents a general idea for an alternative approach rather than focusing on a particular aspect of the authors' work.", "verifiability_rationale": "The review point presents suggestions and critiques without clear claims that can be verified using logical reasoning, common knowledge, or external references. The critique about training many models lacks specific justification or references.", "helpfulness_rationale": "The review point offers a potential improvement (exploring alternatives) and highlights a practical drawback (the cost of training many models). This provides some context and suggests an alternative direction, making it 3 in guiding the authors towards considering different approaches. However, it doesn't offer a direct solution or specific steps on how to implement the alternative."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point lacks specific actionability. While it identifies areas for improvement ('The experiments are not sufficient enough'), it doesn't explicitly state what needs to be done. For example, it mentions 'limited types of teacher architectures' and 'proposed before 2019' but doesn't provide concrete steps for improvement. The actions are implicit, requiring the authors to infer the necessary changes. This makes it difficult for the authors to directly apply the feedback.", "grounding_specificity_rationale": "The review point is 1. It broadly criticizes the experiments and specific aspects of them (limited teacher architectures, outdated methods) without clearly identifying the specific parts of the paper being addressed. For instance, it refers to 'the experiments' generally and doesn't specify which sections or tables are affected. This makes it hard for the authors to understand the scope and relevance of the criticism.", "verifiability_rationale": "The review point contains claims that are not wellsupported. The statement 'The experiments are not sufficient enough' is a claim that lacks specific justification. Similarly, '21) There are limited types of teacher architectures' and '22) Most compared methods are proposed before 2019 (see Tab.' are claims that are not adequately explained or supported by evidence or references. The lack of verifiability makes it difficult for the authors to understand the basis of the criticism and how to address it.", "helpfulness_rationale": "The review point is not helpful because it lacks both actionability and verifiability. The implicit actions and 1 claims make it difficult for the authors to understand the criticism and take meaningful steps to improve their work. The authors are left without clear guidance on what is wrong and how to fix it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point does not explicitly state what the authors should do. It criticizes the lack of evaluation, implying a need for more, but doesn't specify how to achieve this. The action is implied rather than explicit.", "grounding_specificity_rationale": "The review point explicitly mentions 'CIFAR10' and 'lower label scenarios', providing a clear reference point within the paper. This indicates strong grounding specificity as the authors can easily identify the referenced part.", "verifiability_rationale": "The review point is a statement of opinion ('More evaluation would have been welcome') rather than a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support a specific assertion. Therefore, it is 1.", "helpfulness_rationale": "The review point identifies a weakness in the draft (lack of evaluation) and suggests an improvement ('more evaluation'). While it doesn't provide specific guidance on how to improve the evaluation, it points to a clear area for enhancement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two potential issues. First, it states 'It is not clear how named entities were extracted from the datasets.' This is an implicit action, as the reviewer points out a problem but doesn't explicitly state what needs to be done to fix it. Second, it suggests 'An Englishproofreading would significantly improve the readability of the paper.' This is an explicit action, and it is concrete as it directly suggests a specific task for the author. Therefore, while one part is implicitly actionable, the other is explicitly and concretely actionable, making the overall actionability 3.", "grounding_specificity_rationale": "The review point mentions 'named entities' and 'datasets' in the context of the first issue, but it doesn't explicitly identify the specific section, table, figure, or unique aspect of the paper where this extraction occurs. For the second issue, 'Englishproofreading' is mentioned without specifying the type of errors or the sections that need proofreading. Therefore, both parts lack specific grounding, making the grounding specificity weak and not specific.", "verifiability_rationale": "The review point makes suggestions and recommendations. The first part, 'It is not clear how named entities were extracted from the datasets,' is a statement of a problem without proposing a solution or claim that requires verification. The second part, 'An Englishproofreading would significantly improve the readability of the paper,' is also a suggestion without a claim that needs justification. Therefore, neither part contains a claim that can be evaluated for verifiability, making the verifiability score X for both.", "helpfulness_rationale": "The review point offers suggestions for improvement. The first part, 'It is not clear how named entities were extracted from the datasets,' suggests that the author should investigate the extraction process. While helpful, it's a somewhat vague suggestion. The second part, 'An Englishproofreading would significantly improve the readability of the paper,' is a very helpful and concrete suggestion. Therefore, the overall helpfulness is 3 as it provides actionable feedback, but the vagueness of the first part slightly reduces the overall impact."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem (L and E should be defined) and suggests a concrete action (define L and E). This makes the comment actionable. The reviewer also points out the inconsistency in the formatting of L and E, which is a clear indication of an actionable item for the authors.", "grounding_specificity_rationale": "The reviewer explicitly points to lines 296 and 302 as the location of the issue. This demonstrates strong grounding as the authors can easily identify the specific part of the paper being addressed. The reviewer also specifies the nature of the issue (inconsistent formatting of L and E), which is highly specific.", "verifiability_rationale": "The reviewer makes a claim about the inconsistency in the formatting of L and E. This claim is verifiable by examining the specified lines. The lack of definition for L and E is a clear issue that can be supported by logical reasoning (the need for clarity and consistency) and common knowledge (standard mathematical notation preferences).", "helpfulness_rationale": "The reviewer's point is 5 for the authors. By explicitly stating that L and E should be defined, the reviewer provides a clear and actionable suggestion to improve the clarity and correctness of the paper. This directly addresses a potential source of confusion and ambiguity."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The action of comparing is implied, but the specifics are missing. The suggestion to 'beyond LoRA and SPP' is vague and lacks detail on how to implement this comparison.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper being addressed. It is a general suggestion for improvement.", "verifiability_rationale": "The review point itself is not a claim. It is a suggestion for improvement, not a statement that requires verification.", "helpfulness_rationale": "The suggestion to compare with a wider range of models and techniques is a valid and constructive comment. It provides a direction for future work and could be valuable for the authors in understanding different approaches, even without specific details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'Mistakes in Eqs.' which directly points to a problem area in the equations. While it doesn't provide a specific correction, it directs the author to investigate the equations. This is an explicit action that is somewhat concrete as it points to a specific area of the paper (equations) that needs attention. However, it doesn't tell the author *how* to fix the mistake, making it less actionable than a comment that provides a specific change.", "grounding_specificity_rationale": "The comment explicitly mentions 'W4 \u2013 Mistakes in Eqs.' This clearly identifies the specific part of the paper being addressed. The reviewer is not making an inference; they are directly pointing to a specific equation number. This is fully grounded as the section, table, figure, or unique aspect being addressed is explicitly mentioned. The comment also specifies what needs to be addressed, which is the potential mistake in the equations.", "verifiability_rationale": "The comment does not contain a claim. It is a question posed to identify a potential error in the equations. There is no assertion of something as true or false. Therefore, it falls under 'X'.", "helpfulness_rationale": "The comment is highly relevant as it points to a potential error in the equations. By asking a specific question about the content of the equations, the reviewer is prompting the author to carefully review and potentially correct a mistake. This is helpful in identifying and addressing an issue in the paper, even though it doesn't provide a direct solution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment is a general assessment of the paper's novelty and suggests it's a 'straightforward extension' without specifying what is lacking or how to improve. It lacks explicitness and concreteness, making it 1.", "grounding_specificity_rationale": "The comment is a general assessment of the paper's overall contribution and methodology, not focusing on a specific section, table, figure, or unique aspect of the paper. It lacks explicit identification of the part being addressed, making it weakly grounded.", "verifiability_rationale": "The comment is a statement of opinion ('somewhat incremental') rather than a claim requiring evidence. It does not present a specific problem or suggestion that needs justification, resulting in X.", "helpfulness_rationale": "The comment is a general assessment and lacks specific, actionable feedback. It does not identify meaningful weaknesses or suggest improvements, making it 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks 'Could you explain why this occurs?' which is a request for a reason or justification. While the reviewer doesn't explicitly state an action to be taken, the request implies a desire for an explanation to understand the unexpected result. Therefore, it can be considered somewhat explicit as it directly points to a missing explanation. However, the vagueness of 'why' makes it somewhat vague in terms of how to apply this explanation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Sections 6.1 and 6.2' when stating the observation about the treesliced Wasserstein distance. This clearly identifies the specific part of the paper being addressed, making the grounding fully grounded. The specificity is about the direct comparison of the two distances within that section, which is clearly defined.", "verifiability_rationale": "The reviewer states a finding ('It appears in Sections 6.1 and 6.2 that the treesliced Wasserstein distance outperforms the original optimal transport distance') without providing any immediate justification or reasoning within the review point itself. The request for an explanation ('which is surprising') indicates a desire for a reason, but the verifiability of this claim relies on external knowledge or the reader's ability to find the information. Therefore, it is 1 based solely on the information within this review point.", "helpfulness_rationale": "The reviewer asks a question to understand why a result is surprising. This is a direct request for clarification and a desire for a reason. While it's not an explicit instruction on how to act on the finding, it's a clear request for information that could be helpful for the authors to understand and potentially address the unexpected result. Therefore, it is 3 as it directly addresses a potential area of confusion for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states an action: 'I suspect the latter human interpretability but some slight rephrasing would be great.' This indicates a clear intention to improve the text. The suggestion 'rephrasing' is also a concrete action to take.", "grounding_specificity_rationale": "The reviewer does not explicitly state which part of the paper 'ceterus paribus convexity' refers to. However, they do specify the area of concern: 'the word 'confident' threw me off a little here, as I was not sure if this is about model confidence or human interpretability.' This clarifies the potential ambiguity, even if the initial comment lacks explicit grounding.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are pointing out a potential source of confusion ('the word 'confident' threw me off a little here') but are not making a definitive statement that needs to be supported by evidence. There is no suggestion, critique, or judgment being made about the paper itself.", "helpfulness_rationale": "The reviewer provides a suggestion ('some slight rephrasing would be great') to improve the clarity of the text. While the suggestion is helpful, it is not very specific or detailed. The reviewer is directly addressing the author's potential confusion, which is a valuable piece of feedback."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the absence of a comparison against existing text GANs. While they don't explicitly state what the authors *should* do, they identify a missing element in the evaluation. This can be considered an implicit action. However, the action is vague as the reviewer doesn't specify which GANs to compare against or the specific reasons for this comparison.", "grounding_specificity_rationale": "The reviewer mentions 'existing text GANs' and 'SeqGAN'. While they name the types of GANs, they don't specify the *exact* implementation or detail of SeqGAN being referenced. The issue identified is the 'lack of comparison', which is clear, but the specific part of the paper being addressed isn't fully pinpointed.", "verifiability_rationale": "The reviewer makes a clear claim: 'there is no comparison against existing text GANs'. They provide context by mentioning SeqGAN and its opensource implementations. This provides a basis for the authors to verify the absence of a comparison and potentially justify why it's important in the context of SeqGAN.", "helpfulness_rationale": "The reviewer highlights a significant omission in the evaluation \u2013 the lack of comparison against relevant baselines like GANs. This is a valuable piece of feedback as it points to a potential gap in the paper's analysis or justification. While it doesn't directly tell the authors *what* to do, it identifies a crucial area for improvement."}
