{"actionability_label": "1", "grounding_specificity_label": "None", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue with the dataset but does not explicitly state what the authors should do to address it. It raises a concern about the artificial nature of the dataset and the potential for noise and inaccuracies, but it doesn't provide concrete steps for the authors to take. Therefore, it is not actionable in a direct sense.", "grounding_specificity_rationale": "The review point mentions potential issues with the dataset, such as 'misinformation' and 'outofcontext images,' but it does not specify a particular section, table, figure, or unique aspect of the paper or dataset that is affected. While it points to general types of problems, it lacks the specificity to identify a precise location for improvement. Therefore, it is only weakly grounded.", "verifiability_rationale": "The review point makes a claim about the potential noise and inaccuracies in the dataset. However, it does not provide any evidence, references, or logical reasoning to support this claim. It presents a hypothesis about the dataset's quality without backing it up. Therefore, it is 1.", "helpfulness_rationale": "The review point raises a valid concern about the potential noise and inaccuracies in the artificially created dataset. It highlights a potential flaw in the data collection process and points out issues that could affect the reliability of results. This serves as a helpful pointer for the authors to be aware of potential problems with their data. While it doesn't provide a solution, it identifies a significant issue that needs attention."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the lack of 'dig into the theory' and 'show the convergence properties' of the proposed algorithm. This is an explicit statement of what is missing, making it actionable for the authors to focus on these aspects. The reviewer clearly identifies the specific areas where the paper falls short.", "grounding_specificity_rationale": "The review point explicitly mentions 'theory' and 'convergence properties' as the areas where the paper lacks. This strong wording directly identifies the specific parts of the paper being addressed, providing full grounding. The reviewer clearly specifies the nature of the deficiency.", "verifiability_rationale": "The review point contains a claim: 'The paper does not dig into the theory and show the convergence properties of the proposed algorithm.' This is a statement of a deficiency that could be verified by examining the paper's content. While the reviewer doesn't provide external references or detailed explanations within this review point, the claim itself is verifiable by looking at the paper's theoretical sections and attempting to find any discussion of convergence.", "helpfulness_rationale": "The review point clearly identifies a significant gap in the paper's theoretical analysis, which is a valuable piece of feedback for the authors. The reviewer is specific about the type of theoretical analysis missing, making the feedback quite targeted and actionable. While the reviewer doesn't provide specific suggestions, the identification of the problem is 5."}
{"actionability_label": "1", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point itself does not contain an explicit action or suggestion for the authors. The reviewer is asking a question about the methodology used to calculate the overall score, not proposing a specific step they should take. Therefore, it lacks explicitness and concreteness required for actionability.", "grounding_specificity_rationale": "The reviewer explicitly mentions '261&272' in the `results` section, indicating they have identified the specific part of the paper being addressed. This demonstrates strong grounding as they are pointing to a specific location in the provided text. The comment also clearly specifies *why* they are pointing to these lines \u2013 to ask about the scoring method. This adds specificity to the identified section.", "verifiability_rationale": "The reviewer claims the comment is not verifiable because they are stating their understanding of the scoring method (elementwise min/max) and asking why the authors didn't consider the alternatives (AND/OR with logical operators). They are not providing explicit reasoning, common knowledge, or external references to support their claim about the unverifiability of the current approach. The justification is implied rather than explicitly stated and supported.", "helpfulness_rationale": "The reviewer's comment is helpful because it clarifies a potential misunderstanding about the scoring method and encourages the authors to perform a more thorough review. The reviewer is actively engaging with the results and seeking clarification, which is a valuable piece of feedback. The comment prompts the authors to consider alternative interpretations and approaches, which can lead to improved understanding and potentially better results. Therefore, it has a clear benefit for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is implicitly suggesting that the sampling method used to select 10 answers is a potential limitation. While they don't explicitly state an action to take, the question implies that this selection process might not represent all correct answers equally. This is an implicit suggestion, as the action isn't directly stated but is inferred.", "grounding_specificity_rationale": "The reviewer's question is general and doesn't specify which part of the paper or methodology is being criticized. They are referring to the 'sampling of correct answers' in general, without pointing to a specific figure, table, or section. Therefore, the grounding is weak as the specific part being addressed is not clearly identified.", "verifiability_rationale": "The reviewer is raising a potential issue about the sampling method. While it's a plausible concern, there's no explicit claim being made that is directly supported or unsupported by evidence within this review point itself. The concern is more of a suggestion for improvement rather than a claim requiring verification. Therefore, it's 3 as a potential issue, but without further justification, it's not 5.", "helpfulness_rationale": "The reviewer is pointing out a potential limitation in the study's methodology. While it's not directly telling the authors *how* to improve their draft based on this point, it raises a valid concern about the representativeness of the sample. This is helpful in the context of understanding the study's limitations, but it's not a direct action for the authors to take *based on this specific point*. Therefore, it's 3 as it highlights a potential area for improvement in future research related to answer selection."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "1", "actionability_rationale": "The reviewer asks a question about the content of Table 1, which is a direct request for information. While not explicitly stating an action to be taken, the question implies a desire for clarification on an existing element. Therefore, it can be considered implicit actionability.", "grounding_specificity_rationale": "The reviewer asks about the purpose of the average duration reported in Table 1. While the context implies it's Table 1, the reviewer doesn't explicitly state 'Table 1 shows the average duration...'. The request is for information about the content, which could be considered underspecific as the reviewer doesn't pinpoint a specific detail within the table.", "verifiability_rationale": "The reviewer states 'There is no supporting explanation about it.' This is a claim that requires verification. The reviewer also implies that this lack of explanation is a problem, suggesting it's a relevant detail that should be present. This indicates a logical reasoning element to support the claim.", "helpfulness_rationale": "The reviewer's point is primarily about seeking clarification on an existing element. While this can be helpful for the authors, the reviewer does not provide any specific actionable suggestions or identify a concrete problem that needs to be addressed. The request is more about finding information rather than guiding the authors on how to improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer implies they want the results to be presented in a more precise way, but does not explicitly state what needs to be done. The action is implied but not directly stated.", "grounding_specificity_rationale": "The comment is a general statement about the results and does not specify which part of the paper or experiment is being addressed. It is 1 specifically.", "verifiability_rationale": "The comment is a subjective opinion about the interpretation of the results and does not provide any logical reasoning, common knowledge, or external references to support it. It is not verifiable.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the current presentation (the 'on par or better' phrasing) and provides a specific, actionable suggestion to improve clarity. This directly addresses a perceived lack and is therefore 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point asks a question about interpreting results in Table 3 and makes comparative statements about different models. While it implies the reviewer has identified an area for clarification, it doesn't explicitly state an action or provide a solution. The reviewer doesn't tell the author how to interpret the results or what changes to make based on the comparison.", "grounding_specificity_rationale": "The reviewer refers to specific models (Chinese MOSQ, NVSB, GT Mel A, Baseline) and MOS types (Chinese and English). However, the grounding is somewhat weak. While the names are mentioned, the *specific aspects* of these models being compared are not explicitly detailed. The reviewer doesn't explain *why* these models are being compared or *what* specific features are being assessed. The specificity is limited to the models and MOS types.", "verifiability_rationale": "The review point presents interpretations based on the comparison of models and the overlapping 95% confidence intervals. This involves some level of logical reasoning and interpretation of statistical results. However, it doesn't explicitly state the *method* used to calculate the confidence intervals or provide *examples* of how to interpret the overlapping intervals. The verifiability is present but could be more explicit.", "helpfulness_rationale": "The review point raises a valid question about the interpretation of results in Table 3. However, it does not provide any actionable feedback or suggestions for the author. It doesn't tell the author what to do or how to improve their work based on the comparison of the models. The request is more about clarification than providing concrete guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem (inconsistent spacing) but does not provide explicit or implicit instructions on how to fix it. The authors are left to figure out the solution themselves, which reduces the actionability of the comment.", "grounding_specificity_rationale": "The review point explicitly mentions 'Table 2 and Table 3', which grounds the comment to specific sections of the paper. However, it does not specify which cells or elements within those tables are affected by the spacing issue. Therefore, while grounded, it is not fully specific about the location of the problem.", "verifiability_rationale": "The review point identifies a problem (inconsistent spacing) that is observable within the tables. However, it does not provide external references or logical reasoning to support why this inconsistency is a significant issue. The justification is implicit, requiring the reader to infer the importance of consistent formatting.", "helpfulness_rationale": "The review point identifies a formatting issue that could be beneficial for the authors by improving the readability and organization of their paper. While it doesn't provide a solution, it points out a potential area for improvement, making it 3 in guiding the authors to refine their presentation."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states 'Lack of novelty' and provides a reason ('Adversarial attacks by perturbing text has been done on many NLP models and imagetext models.'). This is an explicit statement of the problem. However, the action of addressing this lack of novelty is not clearly defined. The reviewer does not specify what needs to be done to make the work more novel.", "grounding_specificity_rationale": "The reviewer mentions 'related work of this paper' and 'NLP models and imagetext models' as reasons for the lack of novelty. This is a weak grounding as it does not pinpoint the specific section, table, figure, or unique aspect of the paper being addressed. The specificity of the problem is also low as the reviewer does not specify what is lacking novelty in the videotext model application.", "verifiability_rationale": "The reviewer makes a claim ('Lack of novelty') and provides a reason ('Adversarial attacks by perturbing text has been done on many NLP models and imagetext models.'). This provides some justification for the claim. However, the reasoning is general and does not specifically address the novelty of the application to videotext models. The verifiability is partially verifiable as there is some support, but it lacks key elements like specific examples or references to the videotext model domain.", "helpfulness_rationale": "The reviewer clearly identifies the weakness ('Lack of novelty') which is helpful for the author. However, the suggestion for improvement ('taking similar ideas and applying it on videotext models') is too vague and does not provide specific actions or detailed advice on how to make the work more novel. The helpfulness is limited because the suggestions are not concrete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem of confusing intertwined explanations and provides a clear suggestion to separate the discussion into lexical and sentencelevel features. This is an explicit action, and the suggestion is concrete, stating exactly what should be done. Therefore, it is 5.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 3.2' where the explanations are intertwined. This is a clear and precise identification of the specific part of the paper being addressed. The suggestion is also specific, proposing to separate the discussion into lexical and sentencelevel features. Therefore, it is 5.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for improvement rather than a statement of what is wrong or needs justification. Therefore, it has X and is classified as 'X'.", "helpfulness_rationale": "The review point directly addresses a potential issue authors might face when reading Section 3.2 and offers a concrete solution. This is a valuable suggestion that can help authors understand the content better. Therefore, it is 5."}
{"actionability_label": "None", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a lack of clarity regarding a specific baseline (MST) and suggests including more baselines. While the reviewer identifies a gap in the discussion, the action to take is implicit: 'improve the paper by including more baselines'. The level of specificity in this action could be improved by stating 'improve the paper's comparison to models that consider different senses but not sememes'. The concreteness of the action is also tied to the specificity of the baseline being addressed. The reviewer's statement is clear and identifies a need for improvement, but the action itself is somewhat vague and depends on the specifics of the MST baseline.", "grounding_specificity_rationale": "The reviewer's comment is general, focusing on the 'related work' section and the need for 'more baselines' without specifying a particular section or element of the paper. The referenced part is not a specific section, table, figure, or unique aspect. The comment is more of a suggestion for improvement than a direct criticism of a specific part of the paper. The grounding is weak because the reviewer doesn't pinpoint where the lack of clarity is.", "verifiability_rationale": "The reviewer claims that the proposed models 'are unclear how the proposed models compare to models that only consider different senses but not sememes. Perhaps the MST baseline is an example of such a model? If so, this is not sufficiently described (emphasis is instead put on soft vs. hard word sense disambiguation). The paper would be stronger with the inclusion of more baselines based on related work.' This statement contains a claim: 'the proposed models are unclear how the proposed models compare to models that only consider different senses but not sememes'. The verifiability of this claim depends on whether the paper provides sufficient details about the MST baseline and other relevant baselines. The reviewer's assessment of the MST baseline's description and the emphasis on word sense disambiguation are also part of the claim, requiring evidence from the paper to be verified. The claim is 3 if the paper lacks sufficient detail about the MST baseline and could benefit from a clearer explanation of the comparison to models considering only senses.", "helpfulness_rationale": "The reviewer suggests that the paper would be stronger with the inclusion of more baselines based on related work. This is a suggestion for improvement that directly addresses a perceived weakness in the current discussion. The reviewer's comment is clear and identifies a specific area for enhancement. The suggestion is actionable and directly relates to the content of the paper (related work and baselines). The helpfulness is moderate as the suggestion is specific but relies on the assumption that the current baselines are indeed insufficient."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the selection process for frame similarity factors and attributes similarity factors is unclear. However, it does not specify what aspects of the selection process are unclear or how the selection should be done. This makes it somewhat vague and not fully actionable for the authors.", "grounding_specificity_rationale": "The comment mentions 'frame similarity factors' and 'attributes similarity factors' but does not explicitly identify the specific part of the paper or methodology where these factors are discussed. Therefore, the grounding is weak as the authors cannot precisely pinpoint the referenced part. While the comment identifies a potential issue, it doesn't specify *which* part of the paper is affected.", "verifiability_rationale": "The comment contains a claim that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The verifiability is low because the reasoning is implicit and lacks concrete evidence.", "helpfulness_rationale": "The comment identifies a potential area of confusion in the methodology (the selection of similarity factors). However, it does not provide any specific suggestions or guidance on how to address this lack of clarity. The helpfulness is moderate because the authors are informed about a potential issue, but they are left to figure out the specifics on their own."}
{"actionability_label": "Partly Actionable", "grounding_specificity_label": "Partly Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the reporting of results for model (B) on two tasks. While it doesn't explicitly state an action, the criticism implies an action: the authors should investigate and report the results for model (B) on both tasks. The vagueness of 'check' makes it less explicit than a direct instruction. The criticism about the 'latent in verbs' task being 'not mentioned' is vague and doesn't specify what needs to be done to address it.", "grounding_specificity_rationale": "The review point mentions 'the results for the task of inferring knowledge on objects' and 'model (B)'. This partially identifies a specific part of the paper. However, it doesn't explicitly state which section or table contains these results. The criticism about the 'latent in verbs' task being 'not mentioned' for model (B) is specific to a particular task and model, but it doesn't pinpoint the exact location within the paper where this information should be found.", "verifiability_rationale": "The review point makes a claim: 'as mentioned above' (referring to the results for model (B) on the two tasks) and 'it would be better if you used the same terminology for the model in Tables 1 and 2'. The claim about the missing results is verifiable by checking the tables. The claim about consistent terminology is a suggestion that could be supported by explaining why it's beneficial. However, the claim about the missing results is not fully supported by examples or references.", "helpfulness_rationale": "The review point provides feedback on the reporting of results. The criticism about the missing results for model (B) on two tasks is helpful for the authors to identify potential gaps in their reporting. The suggestion to use consistent terminology for models in tables is also helpful for improving clarity and understanding. While the feedback is present, it could be more specific about what the authors should do to address the missing results and why consistent terminology is important."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential discrepancy between the text description in the paper (line 212) and the reviewer's understanding or the description in Figure 2. This suggests an implicit action for the authors: to verify the description of the GRU output and ensure it aligns with the actual implementation or the reviewer's understanding of bidirectional encoders. While the action is implied, it is a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer directly points to line 212 as the specific part of the paper being discussed. Furthermore, the reviewer offers a specific alternative interpretation of what the bidirectional encoder outputs (a set of vectors) compared to the paper's description. This indicates a strong grounding of the issue in a specific section and a clear specification of the potential problem.", "verifiability_rationale": "The reviewer makes a claim that the sentence in line 212 is not strictly correct and suggests that the output of the GRU is a set of vectors, as seen in Figure 2 and potentially in the reviewer's understanding of bidirectional encoders. This claim is verifiable by comparing the text to the figure and potentially by examining the implementation details or external knowledge about bidirectional encoders. The reviewer provides a basis for investigation and potential clarification.", "helpfulness_rationale": "The reviewer's suggestion to clarify the description in line 212 is a direct and actionable step for the authors. By pointing out the potential inaccuracy and suggesting an alternative interpretation, the reviewer provides a clear direction for the authors to seek clarification or further understanding of the implementation details. This directly addresses a potential source of confusion or lack of clarity."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The comment identifies weaknesses in the baseline models but does not explicitly state what should be improved or how to implement the suggested changes. The suggestion to add a citation and rephrase a sentence is present but lacks specific guidance. The comment about the missing comparisons is implied but not explicitly stated for a specific part of the paper.", "grounding_specificity_rationale": "The comment does not explicitly identify the specific part of the paper being addressed when referring to the weakness of the baselines, the missing comparisons, or the need for a citation and rephrasing. The reviewer uses general terms like 'first of all' and 'in this section' without pinpointing the exact location.", "verifiability_rationale": "The comment contains claims about the weakness of the baselines and the need for comparisons, but these claims are not supported by logical reasoning, common knowledge, or external references. The reviewer states what they believe is missing but does not provide evidence or justification for these beliefs.", "helpfulness_rationale": "The comment identifies areas for improvement but lacks concrete suggestions or guidance on how to achieve these improvements. The reviewer suggests adding a citation and rephrasing a sentence but does not specify how to do so. While the feedback points to weaknesses, it does not offer actionable steps for the author."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a relevant concern (societal biases) and suggests a general approach (reasoning chains). However, the reviewer doesn't provide specific, actionable steps for the authors to take or clarify the scope of the bias issue.", "grounding_specificity_rationale": "The reviewer raises a general concern about societal biases in knowledge bases without specifying *which* knowledge base or *where* in the paper the issue might arise. The suggestion to use reasoning chains is a general method.", "verifiability_rationale": "The reviewer raises a concern about societal biases and suggests reasoning chains but doesn't provide any evidence or reasoning to support the effectiveness of this approach in addressing the stated issue. The 'not yet convinced' part highlights the lack of verifiable support.", "helpfulness_rationale": "The reviewer raises a relevant concern and suggests a general approach. While the concern is valid, the review lacks specific, actionable steps for the authors to take or a clear explanation of how the suggested method directly addresses the identified issue."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the missing strong baselines and the need for justification for the MCNC component in Table 3. It provides a clear action: to justify the MCNC component. This action is concrete as it specifies the type of justification required.", "grounding_specificity_rationale": "The comment explicitly mentions 'Table 3' and 'MCNC', clearly identifying the specific part of the paper being addressed. The request is to 'justify the MCNC component', which is a clear action to be taken on this identified part. The grounding is full as the section and table are explicitly mentioned.", "verifiability_rationale": "The comment itself does not contain a claim. It is a request for information and justification. Therefore, it does not have verifiability in the sense of a claim being made and needing support. However, if the authors were to make a claim about the baselines in 1 being strong, this review point could provide verifiable evidence by citing the relevant literature and explaining their importance.", "helpfulness_rationale": "The comment identifies a valid concern: the lack of strong baselines and the need for justification for the MCNC component. However, it does not provide specific, actionable steps for the authors to take to address this issue. It requests information and justification but doesn't offer concrete guidance on how to implement this justification or what changes are needed. Therefore, while it highlights a problem, it doesn't offer a direct solution, making it less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly mentions the references to supplementary material (e.g., 'Sup. Fig. 6', 'model comparison', 'span vs. sentence investigation') and implies a problem with the paper's organization and referencing. This indicates an implicit action: the authors need to reorganize their paper to avoid these references or add a supplementary section to address these specific points. The action is also concrete as the reviewer identifies the specific elements that need addressing.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific elements of the paper that are being referenced (e.g., 'Sup. Fig. 6', 'model comparison', 'span vs. sentence investigation'). This indicates strong grounding. However, the reviewer does not explicitly state what is *wrong* with these references or how they should be fixed. The specificity is somewhat lacking as the reviewer identifies the *what* but not the *why* or the *how*. The reviewer implies the issue is with the referencing making the paper not 'truly independent'.", "verifiability_rationale": "The reviewer makes a claim about the paper not being 'truly independent' due to the references to supplementary material and provides examples (e.g., 'S3.1 reference to Sup. Fig. 6', 'model comparison', 'span vs. sentence investigation'). However, the reviewer does not provide any specific examples or references to external works to support this claim. The claim is presented as a statement of fact without any logical reasoning or external evidence.", "helpfulness_rationale": "The reviewer points out a significant issue with the paper's referencing, specifically the reliance on supplementary material. This directly informs how the authors should reorganize their paper and potentially add a supplementary section. While the reviewer does not suggest a specific alternative format, they clearly identify a problem that needs to be addressed to improve the paper's usability and clarity. The feedback is directly actionable in terms of paper structure and organization."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is suggesting that concept map extraction might be redundant and offering a reason related to readability. While the reviewer doesn't explicitly state an action to be taken, the question implies a potential area for improvement. The reviewer does provide a reason (readability), which suggests a potential action: investigating the readability of concept maps compared to summaries. However, the action is not explicitly stated, making it implicit.", "grounding_specificity_rationale": "The reviewer is talking about 'concept map extraction' in general, without specifying a particular paper or section. They are also not referring to a *specific* concept map. The reviewer mentions 'readability' as a reason, but they don't specify *which* concept maps or *how* they are being evaluated for readability. The grounding is at a high level, referring to the general task of concept map extraction.", "verifiability_rationale": "The reviewer presents a claim: 'Is it necessary to treat concept map extraction as a separate task?' and then provides a reason: 'On the one hand, many generic summarization systems build a similar knowledge graph and then generate summaries accordingly. On the other hand, with the increase of the node number, the concept map becomes growing hard to distinguish. Thus, the general summaries should be more readable.' The reviewer offers a logical argument for their claim, explaining the potential drawbacks of treating concept map extraction as a separate task and suggesting that general summarization might be sufficient. While the reviewer doesn't provide specific examples or external references to support their claim, the reasoning is based on common knowledge in NLP and the relationship between summarization and knowledge graph generation. The claim is supported by logical reasoning and common knowledge, but lacks specific examples or references.", "helpfulness_rationale": "The reviewer raises a valid point about the potential redundancy of concept map extraction and offers a potential alternative (general summarization) based on the readability of concept maps. This is a constructive critique that could guide the authors towards more efficient methods. The reviewer's point could lead to valuable discussions about the relationship between summarization and knowledge graph generation. While the reviewer doesn't provide a direct solution, the suggestion to consider general summarization as an alternative is a helpful direction for the authors to consider. The feedback is relevant and points towards a potential improvement in the workflow."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests concrete actions for the authors, such as describing the traits of experts and justifying the need for expert annotation. The reviewer provides specific suggestions on how the authors should approach this task, indicating a clear and actionable direction.", "grounding_specificity_rationale": "The review point asks specific questions about the identity of the experts (linguistic or domain), the differences in annotation between experts and nonexperts, and the linguistic challenges involved. These questions directly address the specific part of the paper being discussed and provide clear information about the issue.", "verifiability_rationale": "The reviewer requests justification for the need for expert annotation. While not a direct claim, this request implies a need for logical reasoning and external references to support this point, making it verifiable.", "helpfulness_rationale": "The review point directly addresses a need for improvement in the draft by suggesting how to enhance the annotation process. The reviewer provides a clear purpose for their feedback, indicating its helpfulness to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point points to a specific location in the paper (lines 102106) and criticizes the writing style ('misleading'). It *could* be considered actionable if the reviewer explicitly suggested how the authors should improve the draft. However, the reviewer only states the problem without offering a solution. The suggestion is implicit, requiring the authors to infer the necessary changes. The criticism is vague. It doesn't specify *what* is misleading or *how* it is misleading.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'lines 102106' which grounds the comment to a specific part of the paper. They then describe the issue as 'misleading' and further specify it's about the discussion of 'distribution'. This clearly identifies the area of concern. The reviewer explicitly names the section being discussed and the specific element within that section.", "verifiability_rationale": "The reviewer states that the discussion in lines 102106 is 'misleading' and that the term 'such distribution' is used. This is a claim that something is misleading. However, the reviewer does *not* provide any evidence or justification for this claim. There is no explanation of why the discussion is misleading or why 'such distribution' is problematic. The claim is stated without supporting evidence or justification.", "helpfulness_rationale": "The reviewer identifies a potential issue with the writing style and points to a specific section. However, they don't offer any concrete suggestions for improvement. The comment is diagnostic but lacks constructive guidance. The authors are left wondering what exactly is wrong and how they should fix it. The feedback is not actionable."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a suggestion for improvement, but it doesn't tell the author *where* to add examples, *what kind* of examples, *how* the comparison should be made, or *why* this comparison is important. It's a request for clarification rather than a directive action.", "grounding_specificity_rationale": "The review point doesn't mention any specific part of the paper. It's a general suggestion about demonstrating the system's capabilities.", "verifiability_rationale": "The review point itself is a statement of preference, not a claim that needs verification. While the *suggestion* within it ('It will be nice to see...') could be considered a claim if the authors interpret it as a requirement for improvement, the *review point itself* doesn't make a claim about what *should* be in the paper.", "helpfulness_rationale": "The suggestion is relevant to improving the paper's demonstration of the system's capabilities. It points towards a specific area for improvement. However, it's very general and lacks specific details, making it 3 but not fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "1", "actionability_rationale": "The reviewer is asking for clarification on how the Challenge Set (CS) is used. While the action of seeking clarification is explicit, the *how* is not. The reviewer is implicitly asking for a description of the CS's role in the evaluation process. Therefore, the action is somewhat explicit but lacks concrete details.", "grounding_specificity_rationale": "The reviewer is asking very specific questions about the CS and its usage. They are asking for a definition and how it's used for evaluation. The authors can identify the specific part of the paper (the evaluation process) and understand the issue (lack of clarity). This is strong grounding. The questions are also specific about *what* is being used and *how* it's used.", "verifiability_rationale": "The reviewer is asking a question about the CS. The answer would likely involve referencing the definition of the CS or potentially external documentation. This information is generally verifiable within the community. The reviewer is asking for a definition, which is a logical step. While a direct link might be missing, the concept is generally known. Therefore, it's 4.", "helpfulness_rationale": "The reviewer's questions are about a lack of clarity on how the CS is used. While the questions themselves are not inherently helpful, the *answer* to these questions would be highly beneficial for the authors. The reviewer is asking for a specific explanation, which is not provided. Therefore, the review point itself is not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states they don't understand the abstract discussion in section 5.2 and asks for examples of spurious structures. This indicates an implicit request for clarification. While the reviewer identifies a specific area (section 5.2), the request for 'examples' is vague and doesn't provide immediate actionable steps. Therefore, it is implicitly stated but vague on how to execute it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 5.2', which grounds the comment. However, they ask for 'examples of spurious structures' without specifying which ones or how to identify them within that section. This lack of specificity means the reviewer can identify the section, but not the specific issue or how to address it.", "verifiability_rationale": "The reviewer states they 'don't get the insights' and 'can you provide examples'. This is a statement of a problem or a suggestion for improvement, but it doesn't contain a claim that requires verification. Therefore, it falls under the 'Normal Statement' category.", "helpfulness_rationale": "The reviewer's statement that they 'don't get the insights' and their request for 'examples' directly address a potential weakness in the paper's explanation. This feedback is valuable for the authors and points to a specific area needing improvement. While it doesn't introduce a new insight, it's a clear and actionable feedback point."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action of adding a baseline PCFG with a smaller state size and directly parameterizing the matrices. They also specify how this change would be made (by changing the state size and matrix parameterization) and what the comparison would be (perplexity). This provides a clear and actionable direction for the authors.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific PCFGs being compared (one with rank r and one with rank R) and what aspect of the comparison is being made (perplexity). This demonstrates a strong grounding in the specific components of the proposed experiment.", "verifiability_rationale": "The reviewer makes a claim about the potential incomparability of parsing F1 due to different state sizes and then correctly identifies that perplexity can still be compared. This claim is supported by logical reasoning about the impact of state size on the parsing process.", "helpfulness_rationale": "This review point is highly relevant to authors working with PCFGs. It provides a concrete experimental setup (comparing perplexity) to investigate the impact of state size on parsing performance. This is a valuable piece of feedback that directly addresses a common concern and offers a clear, measurable way to evaluate the impact of state space size."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desired information ('maximum number of tasks done by any annotator') and implies the need for a recommendation ('It would also be good to state'). This indicates an intention to guide the authors. The suggestion is also quite concrete, specifying the type of information needed.", "grounding_specificity_rationale": "The reviewer implies the need for information related to 'tasks' and 'annotator'. While not explicitly stating 'maximum number of tasks done by any annotator', the context strongly suggests they are referring to annotation details. The reviewer also specifies the *type* of information they want, which enhances grounding specificity.", "verifiability_rationale": "The reviewer's point is not a direct claim but rather a suggestion for improvement. However, the implication is that stating this information would be beneficial for clarity and understanding of the annotation process. This provides some level of logical reasoning and common knowledge, making it 3.", "helpfulness_rationale": "The reviewer directly points out a potential oversight and provides a specific suggestion ('It would also be good to state the maximum number of tasks done by any annotator'). This is a clear and actionable feedback that would likely be helpful for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem: 'I still found it difficult to get the whole picture' and suggests a solution: 'What is it exactly that the experiments in the paper tell us about the underlying research question in general, and the specific hypothesis tested in particular? How do the different pieces of the puzzle that they present fit together?'. This directly identifies an actionable issue and provides a clear direction for improvement. The reviewer is not just stating a problem but also suggesting a specific way to address it. The action is explicit: 'clarify the connection between the experiments and the research question'. The implementation is also explicit: 'understand how the different pieces of the puzzle fit together'. The reviewer is directly pointing out what needs to be done.", "grounding_specificity_rationale": "The reviewer states: 'I still found it difficult to get the whole picture' and then asks specific questions about the connection between experiments and the research question. While the reviewer doesn't explicitly name a specific section or table, they clearly indicate the *type* of information missing. They are pointing to a general lack of clarity in how the empirical results relate to the core research question. This can be considered 'weakly grounded' because the reviewer can make an educated guess about the missing information. The reviewer also specifies the *nature* of the missing information: the connection between the experiments and the research question. This specificity makes it 'specific'. The reviewer is identifying a gap in the paper's presentation, which is a clear indication of what needs to be addressed.", "verifiability_rationale": "The reviewer's comment is not a direct claim but rather an observation and a suggestion for improvement. While they imply a need for better clarity, they don't explicitly state that 'The paper needs to better explain the connection between the experiments and the research question'. The reasoning behind this suggestion is implied but not explicitly stated. There are no external references or logical reasoning provided to support this observation. Therefore, it can be considered '1'. The reviewer is pointing out a lack of clarity, which is an opinion or judgment, but the claim itself is not explicitly stated.", "helpfulness_rationale": "The reviewer states: 'I still found it difficult to get the whole picture' and then asks specific questions about the connection between experiments and the research question. While the reviewer identifies a problem and suggests a solution, the description of the problem ('I still found it difficult to get the whole picture') is somewhat vague. The reviewer doesn't provide specific examples of what is unclear. The suggestion to 'clarify the connection between the experiments and the research question' is a good suggestion, but without specific examples, it might not be immediately actionable for the authors. The reviewer is expressing a desire for better understanding, which is helpful, but the lack of concrete examples makes it somewhat limited in its immediate helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the 'lack of numerical results' and then suggests 'apply it to some popular algorithms' and 'compare with existing DP algorithms.' While the actions are clear, the specifics are missing.", "grounding_specificity_rationale": "The reviewer mentions 'numerical results,' 'popular algorithms,' and 'existing DP algorithms,' indicating an attempt to ground the comment. However, the 'nature' of the numerical results is unspecified, and the suggestions are general.", "verifiability_rationale": "The reviewer states a problem ('lack of numerical results') and suggests a solution ('apply it to popular algorithms and compare with existing DP algorithms'). This constitutes a claim. However, the specific algorithms and the nature of the comparison are missing.", "helpfulness_rationale": "The reviewer clearly identifies a problem ('lack of numerical results') and offers a concrete suggestion ('apply it to some popular algorithms and their performance compared with existing DP algorithms'). However, the lack of specificity in the suggested actions and comparisons makes the helpfulness less impactful."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment expresses a negative opinion about the probabilistic connection without providing any specific actions or suggestions for improvement. It's a statement of feeling, not a directive.", "grounding_specificity_rationale": "The comment explicitly mentions \"the probabilistic connection,\" which is a specific part of the paper. However, it doesn't explain *why* this connection is problematic or how it should be improved, leaving the authors to infer the issues.", "verifiability_rationale": "The comment makes a claim about the probabilistic connection (\"I don't think...\") but provides no evidence, reasoning, or references to support this opinion. It's an assertion without justification.", "helpfulness_rationale": "The comment is a negative statement about the probabilistic connection without offering any specific feedback or suggestions for improvement. It's a critique without offering improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'It would be good to show some empirical evidence...'. This is a direct request for information, making it explicit. However, it lacks specific details about *where* to find the evidence or *what* kind of evidence is needed, making it vague. Therefore, it is 2.", "grounding_specificity_rationale": "The review point mentions 'the third contribution of the paper' which implies an identification of a specific part of the work. However, the request 'show some empirical evidence' is general and does not specify the exact nature of the evidence needed (e.g., specific datasets, metrics, baselines). Therefore, it is weakly grounded but not specific.", "verifiability_rationale": "The review point does not contain a claim that needs verification. It is a suggestion for new empirical evidence rather than a critique or assertion about the current work. Therefore, it has X and is not verifiable.", "helpfulness_rationale": "The review point directly addresses the third contribution of the paper and suggests a concrete way to improve it by providing empirical evidence. While the request is general and lacks specific details, it clearly points the authors in the direction of gathering more evidence related to the claimed contribution. Therefore, it is helpful, albeit not fully comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment implies an action (implying the impossibility of applying the method) but doesn't explicitly state what needs to be done or how to do it.", "grounding_specificity_rationale": "The comment explicitly mentions 'practical datasets' and 'highdimensional domains', which are specific parts of the paper or concepts, thus fully grounding it. However, it doesn't specify *why* applicability is unlikely or what aspects of the method need adjustment.", "verifiability_rationale": "The comment contains a claim ('the applicability...seems unlikely') and attempts to support it with a reasoning element ('the accuracy would scale unfavorably unless the size of V scales exponentially with the dimension'). However, the reasoning is somewhat general and lacks specific examples or references.", "helpfulness_rationale": "The comment identifies a relevant issue (scalability of the robust training scheme) and suggests a direction for improvement (investigating the scalability). While the reasoning for why it might not scale is somewhat general, the point itself is clear and actionable for the authors."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "Not Verifiable", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer is implicitly suggesting that their work might be affected by changes in academic style over time. While they don't explicitly state what changes to make or how to analyze the data, the questions imply a desire to understand the impact of these shifts. However, the reviewer does not provide concrete steps or guidance on how to address this potential issue in their own work.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'style shifts in academic writing' and asks for justification and examples. This clearly identifies the area of concern and provides a specific context for discussion. While it doesn't pinpoint a specific part of a paper, it clearly specifies the type of change being considered.", "verifiability_rationale": "The reviewer is posing a question and asking for information about style shifts in academic writing over a 4year period. They are not making a claim or assertion that requires verification. The request is for factual information, not a judgment or suggestion about the authors' current draft.", "helpfulness_rationale": "The reviewer is asking about the relevance of a 4year dataset for studying style shifts and what these shifts might be. While this is a relevant question for researchers, it doesn't directly provide actionable feedback or suggestions for improving the authors' specific draft. It asks about the context of their data rather than addressing potential weaknesses in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of 'comparisons with SketchRNN' and explains the reasoning behind it, making it a concrete and actionable suggestion.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'SketchRNN' as a baseline for comparison, providing a clear and accurate reference point for the authors.", "verifiability_rationale": "The review point presents a claim ('The paper should include comparisons with SketchRNN') and provides a justification ('The paper reports only self comparisons. The paper also doesn't explain why this is so, which adds to the poor motivation problem.') to support it.", "helpfulness_rationale": "The review point directly addresses a potential weakness ('only self comparisons') and offers a concrete solution ('comparisons with SketchRNN') linked to a stated problem ('poor motivation'). This provides clear and actionable feedback."}
{"actionability_label": "3. **3**", "grounding_specificity_label": "1. **1**", "verifiability_label": "2. **2**", "helpfulness_label": "2. **2**", "actionability_rationale": "The comment explicitly states an action: 'point out that the techniques are not widely known'. However, it does not specify how this impacts the authors' work or provide concrete steps for improvement.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper being addressed. It refers to 'the results' and 'standard techniques' in a general way.", "verifiability_rationale": "The comment itself is more of a statement of opinion about the nature of the results and the techniques used, rather than a direct claim about a specific issue in the paper. While it implies a concern, it doesn't explicitly state *what* is wrong or *why* it's a problem, and it lacks specific examples or references.", "helpfulness_rationale": "The comment is somewhat critical but lacks specific details. While it identifies a potential weakness (lack of clarity for nonexperts), it doesn't offer concrete suggestions for improvement or specific areas of the paper that need attention."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a specific action: 'I think it would make sense to make a distinction between hard prompt work updates the frozen model (Schick and Sch\u00fctez, etc) from ones that don't.' This is an explicit action. While it doesn't explicitly state how to *implement* this distinction, the reviewer implies a further action: '...from ones that don't.' This suggests a clear direction for the authors. Therefore, it is 4 as it points to a concrete goal, even if the implementation details are not fully specified.", "grounding_specificity_rationale": "The review point explicitly refers to 'hard prompt work updates' and 'frozen model (Schick and Sch\u00fctez, etc)'. This directly identifies a specific part of the paper and even names a specific area of related work. This demonstrates strong grounding specificity as the authors can easily pinpoint the referenced section and the context of the discussion. The use of specific terminology like 'hard prompt work updates' and naming a specific paper further reinforces this grounding.", "verifiability_rationale": "The review point makes a claim: 'I think it would make sense to make a distinction between hard prompt work updates the frozen model (Schick and Sch\u00fctez, etc) from ones that don't.' This claim is 3 as it is based on a common understanding within the field \u2013 that there is a distinction between trainable and frozen layers in prompt tuning. While it doesn't provide specific examples or citations within the review point itself, the general knowledge of the area supports the suggestion. Therefore, it is 3 as it is based on logical reasoning and common knowledge, but lacks specific evidence within the review point.", "helpfulness_rationale": "The review point clearly identifies a potential improvement for the authors by suggesting a clearer distinction between different types of prompt updates. It provides a concrete suggestion ('I think it would make sense to make a distinction...') that directly addresses a potential area of confusion or lack of clarity. This actionable feedback is 5 as it directly points the authors towards a specific area for improvement and offers a concrete direction for them to follow. Therefore, it is 5 as it provides clear and actionable feedback that would likely be beneficial for the authors."}
{"actionability_label": "Partially Actionable (3)", "grounding_specificity_label": "5 (5)", "verifiability_label": "3 (4)", "helpfulness_label": "3 (3)", "actionability_rationale": "The comment states \"the difference between the two proposed systems is only a few percentage points.\" This is an explicit statement of a fact. However, it does not specify what constitutes a \"few percentage points\" or provide concrete guidance on how to address this difference. The action is implicit \u2013 the reviewer implies that this difference is significant \u2013 but it requires the author to infer the implications. The action is concrete (identifying a difference in performance), but the guidance is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The comment mentions \"the text disambiguation model\" and \"the endtoend system.\" This indicates a level of specificity in identifying the systems being discussed. However, it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. The grounding is through the general description of the systems, and the specificity is in the context of the performance difference. The comment doesn't mention specific elements of the paper that are affected by this difference. The grounding is explicit in mentioning the systems, and the specificity is in the context of the performance difference, making it 5.", "verifiability_rationale": "The comment contains a claim: \"Given that the difference between the two proposed systems is only a few percentage points, it brings into question the conclusion that the direct model is clearly the better of the two (but they still are both demonstrably superior to the baseline).\" This is a judgment about the significance of the observed difference. The comment provides some justification by stating \"the difference between the two proposed systems is only a few percentage points.\" However, it lacks specific examples of where this data discrepancy might have caused the issue or cites external literature to support this claim about the impact of data difference. The claim is somewhat supported by the reasoning, but it lacks key elements (e.g., examples, references).", "helpfulness_rationale": "The comment raises a valid concern about the evaluation methodology. It points out a potential weakness in the direct model based on the data difference. However, it doesn't offer specific, actionable feedback on how the author should improve their draft based on this observation. The comment is more of a critique of the experimental setup than a direct suggestion for improvement. The comment identifies a weakness (potential overfitting due to data difference) but doesn't provide concrete steps for the author to address it. The feedback is more of a question than a direct suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the lack of motivation for GaRare and the need for a more detailed algorithmic presentation. This makes the action explicit. However, the reviewer does not specify *why* there is no motivation or what the advantages of GaRare are over GaLore, making the action vague.", "grounding_specificity_rationale": "The reviewer mentions 'GaRare' and 'projected gradients' in the context of needing a more detailed algorithmic presentation. While they don't point to a specific section, table, or figure, the mention of these terms suggests a specific area of the paper they are referring to, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer states a claim that there is a lack of motivation for GaRare and that GaRare has advantages over GaLore. However, the reviewer does not provide any evidence or justification to support this claim within the review point itself. The reasoning is presented as a statement of opinion rather than a logical argument supported by facts or references.", "helpfulness_rationale": "The reviewer points out specific areas for improvement in the paper, namely the motivation for GaRare and the clarity of the algorithmic presentation. While the motivation is not welldefined, the request for a more detailed explanation of a specific technical aspect (parameter recovery from projected gradients) is a concrete suggestion that could significantly improve the paper. Therefore, the helpfulness is somewhat high, as it points towards actionable improvements, even if the specifics are lacking."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a *missing* link to relevant work. While not explicitly stating an *action* like 'Add a citation', identifying a missing element is a concrete observation that can guide the author. The reviewer also hints at a potential *action* by suggesting the related work might be relevant to the current paper's structure or inference capabilities.", "grounding_specificity_rationale": "The reviewer explicitly names the authors of the relevant papers (Ristovski 2013 and Baltrusaitis 2014) and describes the specific characteristics of the work (Continuous Conditional Random Fields and ability to perform exact inference). This clearly grounds the comment in the specific paper and its features.", "verifiability_rationale": "The reviewer claims there's a *missing link* to similar work. While they don't provide a *new* piece of evidence within the review itself to *verify* this claim, they point to the *structure* and *ability* of the cited works, which are established in the literature. This provides some basis for the reviewer's judgment, even if it's not a direct citation within the review.", "helpfulness_rationale": "The reviewer's comment is highly *helpful* because it directly points out a specific area where the author's work might be situated and potentially improved upon. By highlighting the existence of similar work, the reviewer guides the author to relevant literature and encourages them to consider alternative approaches or model structures. The suggestion to look at the structure and inference capabilities of the cited works is a concrete action the author can take."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a future experiment ('It would be interesting to try...') and asks questions about the model's behavior with different inputs ('predicting model output with...'). While it implies an action (conducting the experiment), it doesn't explicitly state what needs to be done or how to implement it. The questions are more about understanding than direct action.", "grounding_specificity_rationale": "The review point starts with a general statement about the lack of insights on how WPA works. It doesn't specify which section, table, or unique aspect of the paper it's referring to. The mention of Figure 2 is general and doesn't point to a specific element within the figure. The critique is about the *overall* analysis rather than a specific detail.", "verifiability_rationale": "The review point makes a claim about the lack of insights on how WPA works and suggests that the model might not generalize well ('why?'). It doesn't provide specific evidence or references to support these claims within its own text. While it refers to Figure 2, it doesn't delve into the specifics of the figure's findings or provide external references to back up its critique.", "helpfulness_rationale": "The review point identifies a potential weakness in the authors' understanding (lack of mechanistic insights) and suggests a concrete experiment ('predicting model output with...'). It's relevant and constructive, offering a direction for the authors to explore. However, it's a general critique and doesn't pinpoint a specific, actionable issue within the authors' work. The suggestion to try `np.ones` is good, but the broader point about the lack of mechanistic understanding is more general."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the method seems similar to a related work, indicating an action the authors should take: investigate and clarify. While the reviewer doesn't specify *how* the method is similar, they do point to a concrete area of comparison. This makes the action somewhat explicit but lacking detail.", "grounding_specificity_rationale": "The reviewer mentions a specific related work ('Generating Adversarial Disturbances for Controller Verification'), which allows for precise identification of the area being referenced. However, the reviewer does not specify *what* aspects of the method are similar to this work, making the specificity low. The comment clearly identifies the *section* of the paper (method) and the *unique aspect* (similarity to a specific related work).", "verifiability_rationale": "The reviewer makes a claim that the method seems similar to a related work. While they provide a potential source for this claim, they do not offer any specific examples or logical reasoning to support the similarity. The claim is stated directly, making it verifiable. However, the lack of supporting evidence makes it only '3'. The reasoning is based on the definition that a claim is verifiable if supported by logical reasoning, common knowledge, or external references. In this case, the reviewer provides a potential external reference (the related work) but no specific examples or logical reasoning within the review point itself.", "helpfulness_rationale": "The reviewer's comment highlights a potential issue (similarity to related work) that could hinder the authors' perception of originality. While the reviewer's intent is helpful in pointing out a potential problem, they do not actively propose a solution or ask a specific question to address this issue. The helpfulness is moderate as the reviewer identifies a potential area for improvement but doesn't actively guide the authors on how to proceed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a gap in the experimental section by stating that the parameters (minimum cluster size and conductance threshold) and their sensitivity are not discussed. While the point points to a missing piece of information, it doesn't explicitly state how to set these parameters or provide guidance on how to determine their optimal values. The action is implied but not explicitly stated. The concreteness is also lacking as the reviewer doesn't specify the exact values or methods for determining sensitivity.", "grounding_specificity_rationale": "The review point identifies a lack of information in the experimental section regarding the setting of parameters. It doesn't explicitly mention a specific part of the paper (e.g., 'In Section 3.2, the parameters are not discussed...'). The grounding is at the level of the entire experimental section, indicating a general lack of detail rather than a specific omission. The specificity is also lacking as the reviewer doesn't pinpoint a particular table, figure, or unique aspect of the experimental setup.", "verifiability_rationale": "The review point makes a claim about the experimental section by stating that it 'did not mention or discuss how these parameters are set and how sensitive the performance is with respect to these parameters.' This claim is supported by the statement that the experimental section does not contain information about the parameter settings or their sensitivity analysis. The support is present in the form of a direct statement about the missing information.", "helpfulness_rationale": "The review point is highly relevant to the authors as it points out a significant gap in the experimental section. By stating that the parameters and their sensitivity are not discussed, the reviewer highlights a crucial piece of information that is missing for the authors to understand and potentially improve their work. This lack of information directly hinders the authors' ability to interpret the experimental results and make informed decisions about their parameters. The impact on the authors is substantial."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential weakness regarding the use of reinforcement learning for a static VQA task. While they don't explicitly state an action, the suggestion to consider gradient descent is implicit, indicating a degree of actionability.", "grounding_specificity_rationale": "The reviewer's comment is general and doesn't specify a particular section, table, or figure in the paper. The concern is about the overall approach, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer states a potential weakness but provides no evidence, citations, or logical reasoning to support their claim. This makes the comment a claim without verifiable support.", "helpfulness_rationale": "The reviewer raises a valid point about the potential limitations of the chosen methodology. This could be helpful for the authors to consider alternative approaches. However, the feedback is general and lacks specific, actionable advice, making it 3 but not highly so."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point states a fact about the dataset's availability but does not provide any instructions or actions for the authors to take.", "grounding_specificity_rationale": "The reviewer refers to \"the promised dataset\" without specifying which dataset is being referred to or providing details about its characteristics.", "verifiability_rationale": "The statement is a prediction, not a claim that can be directly verified from the paper's content.", "helpfulness_rationale": "The review point identifies a potential issue (dataset availability) but does not offer any specific actions or suggestions for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out a claim about stateoftheart results and suggests a comparison with detection methods. While this is a suggestion for improvement, it doesn't explicitly state what needs to be changed or how to implement this comparison. The reviewer identifies a potential issue with the authors' claims but doesn't provide concrete steps for the authors to take. The suggestion to compare with detection methods is a direction, not a specific action.", "grounding_specificity_rationale": "The review refers to the authors' claim about 'stateoftheart results' and the 'first step'. While it mentions these elements, it doesn't specify which exact part of the paper or result is being criticized. The reviewer mentions the 'first step' but doesn't clearly define what this step entails or what problem it's supposed to address. The reference to 'stateoftheart results' is general and doesn't pinpoint a specific area of concern.", "verifiability_rationale": "The review contains claims about the authors' results being 'stateoftheart' and 'outperforms deeplearning based approaches', which are opinions or judgments. However, it doesn't provide specific examples, references, or logical reasoning to support these claims within the review itself. The reviewer suggests the performance is 'majorly' due to the 'first step', but this is a hypothesis without external references or detailed explanation within the review.", "helpfulness_rationale": "The review raises a valid concern about the authors' claims and suggests a comparison with a different approach. However, it doesn't provide concrete, actionable feedback on how the authors should investigate or address this concern. The suggestion to compare with detection methods is a direction, but it lacks specific guidance on what experiments or analyses the authors should perform to validate their claims. The review points to a potential issue but doesn't offer a clear path forward for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that applying CBN to layer 2 *deteriorates* performance for GuessWhat?! compared to when CBN is applied to layers 3 and 4 only. It also asks the authors to explain *why* this might be happening. The authors can directly identify the modification they should apply \u2013 investigating the impact of adding CBN to layer 2. Furthermore, they know exactly what needs to be done and how to apply the action by comparing the performance in the two scenarios. The request for explanation further enhances the actionability.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific experimental setup where CBN is applied to layer 2. This allows the authors to accurately pinpoint the section being addressed. The comparison to the performance of GuessWhat?! when CBN is applied to layers 3 and 4 only further clarifies the issue being identified. The reviewer also asks for an explanation regarding the performance difference, which implies a clear specification of what needs to be addressed.", "verifiability_rationale": "The reviewer makes a claim that applying CBN to layer 2 *deteriorates* performance for GuessWhat?! compared to when CBN is applied to layers 3 and 4 only. This claim requires justification. The reviewer asks the authors to explain *why* this might be happening, indicating an attempt to provide logical reasoning or references. While the review point itself doesn't provide explicit examples or references, the request implies a need for further investigation and explanation.", "helpfulness_rationale": "The review point directly identifies a performance issue with GuessWhat?! when CBN is applied to layer 2 and highlights it by comparing it to a betterperforming configuration. The reviewer explicitly asks the authors to explain *why* this deterioration occurs, which is a proactive step towards improving the draft. While the review point doesn't offer a solution, it clearly points to a problem and encourages further investigation, making it helpful in guiding the authors' attention to a relevant area."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification on a 'Witness oracle' without specifying what that is or how it relates to the paper. While the intent is to provide helpful information, the lack of a direct action or instruction makes it not fully actionable. The reviewer is expressing a need for more information, but not a clear direction on what to do with that information.", "grounding_specificity_rationale": "The reviewer refers to a 'Witness oracle' without explicitly identifying its location or definition within the paper. This makes the grounding weak. The request for clarification is also general, lacking specifics on what is unclear about the 'Witness oracle'.", "verifiability_rationale": "The review point is a request for clarification, not a statement containing a claim or assertion. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The review point is a request for clarification, which can be helpful, but it is vague and lacks specific details. Without more information, it is difficult to determine how this clarification will directly improve the draft. It is not a negative comment, but it is not highly specific or actionable."}
{"actionability_label": "Actionable", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states a limitation of the proposed method (handling headpose) and asks a question ('why is it not possible...') about why this limitation exists. This indicates a clear desire for clarification and a desire for the authors to understand the limitations of their method. The 'why' question implies that the reviewer is not just pointing out a problem, but also seeking an explanation for it, which requires the authors to reflect on their method and potentially identify a gap or difference. This level of engagement and inquiry suggests a degree of actionability, as the reviewer is prompting the authors to take a closer look at a specific aspect of their work.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'a previous work (e.g., Gafni et al. ICCV 2021)' and asks 'why is it not possible to condition the headpose parameters in the NeRF beyond the facial expression similar to Gafni et al. ICCV 2021?' This demonstrates a clear identification of the specific work and the specific aspect of that work being excluded from the current method. The reviewer is not just mentioning a previous work; they are *comparing* their method to it and asking a very specific 'why' question about the difference in capability. This strong identification of the relevant work and the specific limitation being pointed out, along with the direct question, indicates that the authors can confidently identify the area being addressed.", "verifiability_rationale": "The reviewer states a claim: 'While this paper defers this problem to a future work, a previous work (e.g., Gafni et al. ICCV 2021) is already able to control both facial expression and headpose. Why is it not possible to condition the headpose parameters in the NeRF beyond the facial expression similar to Gafni et al. ICCV 2021?' However, the reviewer does not provide any evidence, logical reasoning, or external references to support this claim. They are posing a question rather than making a definitive statement that requires verification. The lack of supporting evidence means the claim is not welljustified, and the reasoning is missing.", "helpfulness_rationale": "The reviewer points out a limitation of the proposed method (handling headpose) and suggests an alternative approach (conditioning headpose like Gafni et al.). While this is valuable information for the authors, it doesn't directly provide actionable feedback on how to improve their current draft. The reviewer is asking a question ('why') rather than proposing a concrete solution or suggesting specific changes to the authors' work. The helpfulness is in informing the authors of a limitation and a potential direction, but it doesn't directly guide them on how to *fix* their current submission. It's more of a suggestion for future work than a direct improvement to the existing work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a similarity between spurious features and backdoor triggers. While this is a valid observation, the review does not explicitly state what the authors should do with this information. The reviewer mentions 'a large impact on the trained model' but does not provide specific steps or experiments to investigate this impact. Therefore, the reviewer identifies a potential issue but lacks a clear action or recommendation, making it only partially actionable.", "grounding_specificity_rationale": "The reviewer refers to 'spurious features in Section 3.1 and 3.2,' which clearly identifies the specific part of the paper being discussed. This indicates 'full grounding.' However, the reviewer does not specify the exact nature of the spurious features or the specific impact of their similarity to backdoor triggers within this section. While the section is identified, the details are not fully elaborated, making it 'underspecific'.", "verifiability_rationale": "The reviewer states, 'It is wellknown that a few training examples with such triggers... would have a large impact on the trained model.' This statement is a claim that can be verified. The reviewer provides examples of prior work (Chen et al., 2017; Gu et al., 2019) that use similar triggers, which serves as external references supporting this claim. The references are relevant and directly relevant to the topic. Therefore, the claim is wellsupported by evidence, making it '5'.", "helpfulness_rationale": "The reviewer connects the findings to existing knowledge about backdoor triggers. This is a relevant observation that could help the authors understand the broader context of their work. However, the reviewer does not provide specific, actionable advice on how the authors can address this similarity. While the insight is valuable, the lack of concrete guidance makes it '3'."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the optimization algorithm is 'directly from some previous works'. This is an explicit action identified by the reviewer. However, the reviewer does not specify which previous works or provide details on how this information is derived. Therefore, while the action is identified, the lack of detail makes it somewhat vague and less actionable for the authors.", "grounding_specificity_rationale": "The reviewer mentions 'optimization algorithm' in the context of reducing contribution. While the reviewer implicitly refers to a specific component of the work, they do not explicitly identify the section, table, figure, or unique aspect of the paper where this algorithm is discussed. The mention is general and does not pinpoint the exact location or nature of the algorithm. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim that the optimization algorithm is 'directly from some previous works'. However, the reviewer does not provide any evidence, citations, or logical reasoning to support this claim. There is no verification provided to back up the assertion. Therefore, the claim is 1 based on the information provided.", "helpfulness_rationale": "The reviewer raises a valid concern about the unclear contribution of the optimization algorithm. This is a helpful comment as it points out a potential weakness or area for improvement in the work. By highlighting this issue, the reviewer is providing actionable feedback for the authors to consider and potentially address."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of including related work A and provides a clear reason why it's crucial. The action is directly identified and the authors are told exactly what to do.", "grounding_specificity_rationale": "The review point explicitly mentions the specific related work A and emphasizes its importance by stating 'A is crucial'. This clearly identifies the specific part of the paper being addressed and provides a specific reason for its relevance.", "verifiability_rationale": "The review point makes a claim that 'A is crucial' for the introduction of modular networks for VQA. This claim is directly supported by the statement 'A is crucial' which acts as the justification.", "helpfulness_rationale": "The review point is 5 because it directly identifies a missing related work and explains its importance. This provides a clear and actionable direction for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment implies an action (contrasting methods) but doesn't explicitly state it. The phrasing 'do not contrast their method with several other subsequent methods' suggests a desired state but doesn't provide clear instructions on how to achieve it.", "grounding_specificity_rationale": "The comment mentions specific methods (thresholded subspace clustering (TSC), greedy subspace clustering by Park, etc), providing some grounding. However, it doesn't explicitly state *why* these methods are missing the comparison or *how* the comparison should be made.", "verifiability_rationale": "The comment states a fact ('the authors mainly seem to focus on SSC, and do not contrast their method with several other subsequent methods') but doesn't provide any evidence or justification for this claim. It also doesn't suggest any improvements or alternative approaches based on this observation.", "helpfulness_rationale": "The comment points out a potential gap in the discussion by highlighting the lack of contrast with specific methods. This could be helpful for the authors to consider alternative approaches and potentially improve their work. While it doesn't explicitly tell them what to do, it raises a valid point that could lead to further investigation and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The reviewer explicitly states the finding ('the performance without reinforcement learning dropped lower than without dependency tree') and clearly identifies the components involved ('reinforcement learning' and 'dependency tree'). While the reviewer doesn't explicitly state how to *improve* the model based on this finding, the implication is that the lower performance suggests a need for improvement. The reviewer also points out the absence of specific cases in the tables, which could be seen as an implicit action to investigate further. However, the connection between this finding and a *specific* actionable improvement isn't explicitly stated, making it somewhat vague on how to apply it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the ablation experiment', 'performance without reinforcement learning', and 'performance without dependency tree', clearly grounding the comment in the specific experimental setup and components being discussed. However, the reviewer does not specify *what* is wrong with the performance or *how* the tables are missing the cases. The specificity is limited to the *location* of the missing information rather than the *nature* of the missing information.", "verifiability_rationale": "The reviewer makes a claim ('The two tables do not list the cases where dependency tree and RL are not used') and identifies the *specific* missing information ('cases where dependency tree and RL are not used'). However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The claim is presented as an observation based on their examination of the tables, but without further justification, it remains 1.", "helpfulness_rationale": "The reviewer's comment is highly critical, pointing out a significant deficiency in the experimental reporting by stating that the tables lack crucial information ('the cases where dependency tree and RL are not used'). This directly hinders the authors' ability to understand and potentially reproduce the experiment. The reviewer's criticism is clear, direct, and points to a concrete issue that needs to be addressed."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the 'experiments section' is the main weakness and provides concrete examples of what is missing, such as the lack of consideration for other datasets from Federated learning benchmarks (e.g., LEAF) and specific papers like (FedProx) and (FedMAX). This indicates a clear understanding of the specific area needing improvement and the nature of the deficiency.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the experiments section' as the area being addressed. They also specify the 'CIFAR10 dataset' and the 'lack of consideration for other datasets from Federated learning benchmarks (e.g., LEAF)' as the specific issue. Furthermore, they name relevant papers (FedProx and FedMAX) as examples of missing resources. This demonstrates a high level of specificity in identifying the problem and the nature of the deficiency.", "verifiability_rationale": "The reviewer makes a claim about the 'experiments section' being the main weakness and the 'limited dataset usage'. They provide examples and suggestions, such as considering 'other datasets from Federated learning benchmarks (e.g., LEAF)' and referencing 'relevant works like (FedProx) and (FedMAX)'. This provides verifiable information that supports the claim and offers guidance for improvement.", "helpfulness_rationale": "The reviewer clearly identifies the 'experiments section' as the main weakness and provides specific suggestions for improvement, such as 'considering other datasets from Federated learning benchmarks (e.g., LEAF)' and referencing 'relevant works like (FedProx) and (FedMAX)'. This actionable feedback is directly relevant to the authors and provides concrete steps they can take to address the identified weakness."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the claim 'It can be seen from the table that our proposed modules improve in both accuracy and completeness' and suggests an alternative experimental setup. This is an explicit action as the reviewer directly addresses the presented claim and proposes a change. The suggestion to use another dataset is a concrete action that the authors can take.", "grounding_specificity_rationale": "The reviewer's comment directly refers to 'the table' as the source of the claim. While the claim also refers to 'our proposed modules,' the primary focus and the element being questioned is explicitly tied to the table. This indicates a strong grounding as the reviewer clearly identifies the relevant part of the paper. The claim also specifies the metrics 'accuracy and completeness,' adding to the specificity.", "verifiability_rationale": "The reviewer's comment questions the validity of a claim made in the paper based on the table. The comment does not provide any logical reasoning, common knowledge, or external references to support the claim being questioned. The reviewer is essentially stating a claim ('the claim is not valid') without providing any justification. This fits the '1' category as the comment contains a claim without any supporting evidence or justification.", "helpfulness_rationale": "The reviewer's comment is primarily diagnostic, questioning the validity of a claim made in the paper and suggesting an alternative experimental setup. While this points out a potential issue, it doesn't directly tell the authors what to do or how to improve their draft. It's more of a suggestion for further investigation rather than a direct action item. Therefore, it's not 5 as it doesn't provide a clear path forward for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of the methodology (single vulnerability at a time, ecological validity concerns, difficulty in interpreting results). These are clear, actionable criticisms. The reviewer doesn't explicitly state how to improve it, but the implications are clear.", "grounding_specificity_rationale": "The reviewer points out a lack of grounding by not mentioning specific parts of the paper where the ecological validity is questioned or the comparison to multiVulnerability approaches. The reviewer is making a general statement about the methodology's limitations without pinpointing the exact section or table.", "verifiability_rationale": "The reviewer makes a claim about the *lack of ecological validity* and the *difficulty in interpreting results*. While these are valid points, the *justification* is general ('I am not sure about the ecological validity...') and doesn't provide specific examples or references. The claim is valid, but the supporting evidence is weak.", "helpfulness_rationale": "The reviewer provides a clear and actionable criticism of the methodology. They highlight specific areas for improvement (comparison to multiVulnerability approaches, clearer interpretation of results). The implications are clear, and the reviewer doesn't just state a problem; they point out a gap in the current approach."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the areas where more details are needed and provides concrete suggestions for improvement. The reviewer suggests providing 'definitions of the resistance distance' and 'more explanations on Alg. 1 with brief sentences defining A_t, Y_t,...'. These are direct actions the authors can take to address the identified weaknesses.", "grounding_specificity_rationale": "The review point identifies specific aspects of the paper that need clarification, such as the 'resistance distance' and 'Algorithm 1'. While it broadly mentions 'many graph notions', it also pinpoints specific elements within that area, indicating a degree of grounding. The request for 'brief sentences defining A_t, Y_t' adds further specificity to the explanation needed.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for the authors to provide more details and explanations regarding specific concepts and algorithms. There is no assertion of correctness, improvement, or critique that needs supporting evidence.", "helpfulness_rationale": "The review point is 5 as it directly points to specific areas where the authors can improve their draft. By requesting definitions of the 'resistance distance' and more detailed explanations of 'Algorithm 1' with 'brief sentences', the reviewer provides clear and actionable feedback. This empowers the authors to make concrete changes to their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their desire for quantitative results on testing images, which is a direct and actionable request related to the evaluation of the shape model invariance study. The action is to look for these results in the testing phase.", "grounding_specificity_rationale": "The reviewer mentions 'testing images' and 'quantitative results' as specific aspects of the evaluation they are interested in. This demonstrates an attempt to ground the comment in specific details related to the evaluation process.", "verifiability_rationale": "The reviewer poses a question about the existence of quantitative results on testing images. This is a claim that could be verified by examining the paper's content. While the request itself is a potential gap in the presented evidence, it is not inherently 1 within the context of the paper.", "helpfulness_rationale": "The reviewer's request for quantitative results on testing images is a constructive suggestion aimed at improving the understanding of the model's generalization capabilities. It highlights a potential limitation in the current evaluation approach and proposes a way to address it. While it doesn't directly critique the presented content, it points to a specific area for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly names the AAAI 15 paper by Ghoshdastidar and Dukkipati and suggests a concrete action: 'discuss and compare against'. This directly points to a specific area for improvement in the authors' work. The action is also relatively concrete, indicating the desired outcome of the comparison.", "grounding_specificity_rationale": "The review point explicitly mentions the paper title 'Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications' and the conference year 'AAAI 15'. This allows the authors to directly identify the specific work being referred to. The grounding is explicit, and the review also provides context by highlighting the paper's focus on 'hypergraph data with tensors', which directly relates to the authors' mention of tensors. This specificity helps the authors understand the relevance of the suggested work.", "verifiability_rationale": "The review point contains a claim: 'This AAAI 15 paper deals with hypergraph data with tensors as well so it should be discussed and compared against to provide a better understanding of the stateoftheart.' While the reviewer doesn't provide a detailed proof within the review point, the statement itself is verifiable by looking at the mentioned paper's content. The claim is clear and points to a specific aspect of the paper's contribution.", "helpfulness_rationale": "The review point is 5 as it directly identifies a relevant piece of related work and provides a clear action for the authors to take: 'discuss and compare against'. This is a specific and actionable suggestion that directly addresses the authors' need to understand the stateoftheart, particularly in the context of tensors. The reviewer is not just pointing out a related work but also suggesting a concrete next step."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point presents several questions and observations. The question about scalability is implicit, asking for clarification on how the method performs with fewer cores. The question about the Sinkhorn algorithm's output is also implicit, suggesting a need for clarification on how to obtain the exact optimal transport plan. While the reviewer identifies specific areas for improvement, the actions required to address these points are not explicitly stated. The reviewer points out potential areas for further investigation rather than directly instructing specific actions to be taken.", "grounding_specificity_rationale": "The review point mentions 'a 36core machine' when discussing computational cost, which can be considered weak grounding as the reviewer doesn't explicitly identify the *specific* part of the paper being addressed in relation to this machine. However, the reviewer does point to specific aspects of the method (computational cost, scalability, Sinkhorn output) which can be considered grounded. The specificity of the comment regarding the Sinkhorn algorithm's output is high as it directly asks about the transition from the doubly stochastic matrix to the exact optimal transport plan. Overall, the grounding is mixed.", "verifiability_rationale": "The claim about the computational cost of optimal transport is verifiable as the reviewer provides a general statement and an example of timing on a specific machine. The claim about the Sinkhorn algorithm's output being a doubly stochastic matrix is also verifiable as it's a known property of the algorithm. The claim about the need to investigate scalability is verifiable by suggesting an experiment. The claims are supported by logical reasoning and common knowledge (general understanding of computational costs and the properties of the Sinkhorn algorithm).", "helpfulness_rationale": "The review point provides valuable information about the computational cost and scalability of the method, which is helpful for the authors to understand the limitations of their approach. The reviewer also identifies a specific technical detail regarding the Sinkhorn algorithm, which is helpful for clarifying a potential misunderstanding. While the review doesn't directly suggest concrete improvements, it points to areas where the authors should investigate further. The feedback is informative and points towards actionable next steps for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the limitations of the experiments to image data and ViT models. It directly points out the absence of NLP experiments and the lack of exploration of CNNs in the image domain. This is a clear and actionable feedback for the authors.", "grounding_specificity_rationale": "The review point clearly refers to \"parameters in Table 1,\" \"model and the experiments,\" \"image data and ViT.\" This provides specific references within the paper and the methodology. The reviewer also mentions \"NLP\" and \"CNNs,\" which are general areas but still point to specific types of models and data.", "verifiability_rationale": "The reviewer states a fact about the current focus on stateoftheart performance, particularly with ViTs. This is a claim that could be supported by evidence of the paper's current focus and a suggestion for future exploration. While the statement itself isn't a claim that needs verification within the paper's content, the reviewer's suggestion to broaden the scope is a constructive suggestion based on this observation. The lack of external references is noticeable.", "helpfulness_rationale": "The review point is valuable as it highlights limitations and suggests future directions for the method. It provides constructive feedback that can help the authors understand the scope of the method and motivate further research or experimentation with different model architectures and tasks. While it doesn't directly improve the current draft, it offers useful insights."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a lack of explanation regarding the significance of using tensor networks for PMF in the context of machine learning. While they don't explicitly state what needs to be done, they point out a clear weakness in the paper's communication. This suggests an implicit action of clarifying the connection, but the lack of concrete steps makes it less actionable than a comment that directly suggests specific changes.", "grounding_specificity_rationale": "The reviewer's comment is grounded in the paper's focus on PMF and its connection to machine learning. They directly relate the technique to the paper's topic, indicating a clear identification of the specific part being addressed. However, they do not specify *how* the significance is useful for ML algorithms or how to analyze the algorithms, making the grounding somewhat specific but lacking detail.", "verifiability_rationale": "The reviewer states that the significance of the results is 'poor' and the connection to machine learning is 'not clear.' This statement directly criticizes the lack of justification for the paper's contribution's relevance to machine learning. There is no external reference or logical reasoning provided within the review point itself to support this claim, making it 1 based on the point alone.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper \u2013 the lack of explanation regarding the significance of using tensor networks for PMF in the context of machine learning. They offer a suggestion to 'elaborate on the significance of their findings in the context of machine learning algorithms or provide examples of how these results can be used to analyze the algorithms.' This demonstrates a clear understanding of the problem and offers a direction for improvement, even if the specifics are missing, making it helpful."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states a limitation of the study. While it points out a *potential* area for future work, it doesn't directly instruct the authors on *what* to do or *how* to address it. Therefore, it's not explicitly actionable in its current form.", "grounding_specificity_rationale": "The review point refers to \"fewshot learners beyond Prototypical Networks.\" This is a specific area, but it's a broad category and doesn't pinpoint a specific section, table, figure, or unique aspect within the paper. It's more of a general statement about the scope of evaluation.", "verifiability_rationale": "The review point makes a claim about the limitations of the evaluation scope: \"The extent to which the observations presented generalize to fewshot learners beyond Prototypical Networks is not evaluated.\" This claim is presented as a fact without any supporting evidence or justification. There is no logical reasoning, common knowledge, or external references provided to back up this statement.", "helpfulness_rationale": "The review point identifies a limitation of the study's evaluation scope but does not offer any suggestions or further analysis to help the authors improve their current draft. It is a critique of the evaluation's scope rather than a constructive suggestion for improvement within the submitted work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue with Equation 3 and its direct removal of the modal subset. While the reviewer identifies the *problem* (unequal contribution) and the *action* (Equation 3), they don't explicitly state where in the paper this equation is located or what it represents. The action is implied but not directly stated as 'remove the modal subset of all instances'.", "grounding_specificity_rationale": "The reviewer refers to 'Equation 3' without explicitly stating where in the paper this equation is located or what it represents. This makes it difficult for the authors to pinpoint the exact issue. The reviewer also describes the action as 'directly removes the modal subset of all instances' which is somewhat general and doesn't specify which modality or instance is being referred to.", "verifiability_rationale": "The reviewer makes a claim about the potential unfairness of Equation 3 and suggests considering the strength of different modalities. The reviewer's claim is that the contribution of different modalities might be different, and Equation 3 might not be the best approach. The reviewer provides a logical argument for this claim by suggesting a different approach. However, they do not provide specific references or examples to support their claim about the varying strengths of modalities.", "helpfulness_rationale": "The reviewer raises a valid concern about the potential bias introduced by Equation 3. They suggest considering the strength of different modalities as a potential improvement. While the reviewer identifies a problem and suggests a possible solution, they do not explicitly state where in the paper Equation 3 is located or what it represents. The suggestion is general and lacks specific details about which modality or instance to consider."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a *lack* of information (how the idea was evaluated and the outcome) but does not provide a specific action or suggestion for the authors to take. The reviewer identifies a gap in the abstract but doesn't offer a concrete fix or direction.", "grounding_specificity_rationale": "The reviewer discusses the abstract's explanation of the proposed idea but does not specify which part of the paper (e.g., a section, table, figure) this explanation refers to. The reference is general and does not identify a specific element.", "verifiability_rationale": "The reviewer makes statements about the abstract's quality (does a good job, lacks description) and suggests improvements. These are opinions, judgments, and suggestions, not claims that require verification or evidence. The reviewer is pointing out a weakness, not making a claim that needs to be supported.", "helpfulness_rationale": "The reviewer identifies a valid issue with the abstract (lack of evaluation details) but does not provide a specific action or solution for the authors to take. The feedback is more about *identifying* the problem than *solving* it. While the feedback is relevant, it doesn't directly empower the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a lack of clarity and potential confusion in the description of the MFDA setting. While the general idea of a source and target domain is mentioned, the specific details regarding the target domain's labeling and the use of source domain data are not explicitly stated. The reviewer implies an action of identifying a potential issue in the paper's description, but the comment itself doesn't directly instruct the authors on what to do. The lack of explicitness makes it difficult to pinpoint the exact action the authors should take.", "grounding_specificity_rationale": "The reviewer explicitly states that the target domain is unlabeled and questions the use of source domain data during training. This directly addresses the grounding of the problem description. While the paper mentions 'target distribution p_T(x, y)', the reviewer correctly points out that the notation for the target domain (\tau) is unlabeled, which contradicts the typical MFDA setting. The reviewer also asks whether the unlabeled data in source domains is used, further highlighting a lack of specific grounding in the method's details. The comment clearly identifies the specific aspect of the problem description that needs clarification.", "verifiability_rationale": "The reviewer raises a point about the discrepancy in the problem setting compared to the original MFDA paper (Yue et al., 2021a). The reviewer mentions that in the original paper, the target data is unlabeled, while the current paper mentions a 'target distribution p_T(x, y)'. The reviewer also asks whether the unlabeled data in source domains is used during training, which requires verification against the cited paper. While the reviewer doesn't explicitly state that the claim is false, the questions raised suggest a need for further investigation and logical reasoning to confirm the consistency of the described method with the original work. The claim is that the problem setting description is confusing and deviates significantly from the original paper, which requires verification.", "helpfulness_rationale": "The reviewer's confusion and questions about the method's clarity and consistency with the original paper make this a not helpful comment. While the reviewer identifies a potential issue in the paper's description, they don't directly tell the authors *what to do* or *how to improve their draft*. The comment is more of a clarification request and a pointer to a potential inconsistency, rather than a direct actionable suggestion. The lack of clarity makes it difficult for the authors to understand the specific problem and how to address it."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a type of analysis (epochwise) and *specific investigations* (batch size, sampling strategies) but does not explicitly state what needs to be done next. It implies the need for epochwise analysis and exploring specific parameters but lacks concrete instructions on implementation.", "grounding_specificity_rationale": "The review point does not specify a particular section, table, figure, or unique element of the paper. It suggests a general approach for analysis without identifying the relevant data or context within the paper.", "verifiability_rationale": "The review point contains a claim about the potential benefits of epochwise analysis and provides logical reasoning and specific examples (batch size, sampling strategies) to support this claim.", "helpfulness_rationale": "The review point offers a suggestion for gaining insights into optimization algorithm behavior, which could be valuable for the author. It provides a general direction for analysis but lacks specific implementation details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "2", "actionability_rationale": "The reviewer provides suggestions for improvement, but these are not explicitly stated as concrete actions. For example, instead of saying 'add baselines,' they could have suggested specific baselines like GraphRAG or RAGCare and how to implement them. Similarly, instead of 'cite papers,' they could have pointed to specific missing citations. The suggestions are broad and lack specific implementation details, making them less actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'many key baselines were not cited' and names specific missing papers like GraphRAG and RAGCare. This clearly identifies the specific part of the paper being addressed and provides details about what is missing. The comment is grounded and specific.", "verifiability_rationale": "The reviewer makes a claim that 'many key baselines were not cited' and provides a justification based on their understanding of the field and the work of others. They also identify specific missing papers, which serves as evidence to support their claim. The reasoning and common knowledge are present.", "helpfulness_rationale": "The reviewer provides some information about potential issues with the paper's contribution and workload. They also offer suggestions for improvement, such as adding missing baselines and citing relevant papers. However, these suggestions are general and lack specific, actionable steps for the authors. For example, they could have suggested specific ways to implement the missing baselines or how to find the relevant citations. The information is present, but it doesn't provide the detailed, actionable guidance that would be considered 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly points out two areas for improvement: mathematical correctness and notation clarity. While the reviewer doesn't directly state an action, the suggestions they make ('change to be mathematically correct', 'why is it L_l instead of just L?') are clear actions the authors should take. The reviewer also suggests a potential solution ('That notation should be introduced beforehand'), which is a concrete action. The reviewer's point is not just about identifying a problem, but also about suggesting a path towards a solution.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'mathematical correctness' and 'notation clarity' as areas for improvement. They also point to 'L_l' as a specific example of unclear notation. The reviewer's suggestions are directly tied to these specific areas. While the reviewer doesn't explicitly state which section of the paper is affected by the notation issue, the mention of 'L_l' implies a specific location. The reviewer's comment is focused on specific aspects of the paper.", "verifiability_rationale": "The reviewer is not making a claim that needs verification. They are pointing out areas for improvement and suggesting actions. The reviewer's point is about providing feedback and guidance, not about making a statement that requires evidence or justification.", "helpfulness_rationale": "The reviewer identifies two specific areas for improvement: mathematical correctness and notation clarity. They also provide suggestions for addressing these issues. The reviewer's point is actionable and constructive, directly suggesting concrete steps the authors can take to improve their work. The suggestions are specific and aim to enhance the quality and clarity of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point states a fact ('When trained and evaluated with the same timestep, Figure 5 shows similar performance...') but doesn't offer a concrete suggestion *on what to do next*. The reviewer expresses a concern and suggests a potential scenario where the method *might* be useful, but doesn't actively propose an improvement. While the statement of the fact is explicit, the concern about the implications is implicit. The reviewer points out a lack of difference in performance under specific conditions. While they *suggest* a different scenario, the current point itself doesn't offer a concrete action based on this observation.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 5' and specifies the conditions ('same timestep for training and evaluation'). This allows the authors to identify the specific part of the paper being discussed. However, the reviewer does not specify *what* is similar in Figure 5. They leave it openended ('similar performance'). This lack of detail makes the specificity somewhat weak.", "verifiability_rationale": "The reviewer states a fact ('When trained and evaluated with the same timestep, Figure 5 shows similar performance...'). There is no explicit claim, judgment, or suggestion being made. The statement is a description of an observation. The reviewer is reporting what the figure shows, not making a claim that requires verification.", "helpfulness_rationale": "The review point identifies a potential limitation (similar performance under specific conditions) but doesn't offer a concrete, actionable improvement or suggest a different experimental setup. It raises a concern but doesn't provide a clear path forward. The reviewer suggests a potential scenario where the method *might* be useful, but the current point itself doesn't offer a concrete action based on the observation of similar performance under the specified conditions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the problem: 'Disentanglement. It is not clear how disentanglement is guaranteed.' It also points to the 'Broader Impacts and Limitations' section as the area where this issue is discussed. This makes the point explicit in identifying the problem and the relevant section. However, it doesn't specify the exact mechanism or steps taken to ensure disentanglement within that section. Therefore, while it identifies a problem, the lack of detail makes it less actionable for the authors to understand and potentially improve the explanation.", "grounding_specificity_rationale": "The review point explicitly mentions 'Broader Impacts and Limitations' as the section where the disentanglement issue is discussed. This clearly grounds the point in a specific part of the paper. However, the point doesn't specify which subsection or detail within that section is causing the confusion or lack of clarity regarding disentanglement. Therefore, while it's grounded in a section, it's not specific enough to pinpoint the exact issue within that section.", "verifiability_rationale": "The review point is a statement of a lack of information. It doesn't propose a claim that something is wrong or needs to be improved. It's a statement of a gap in the explanation. Therefore, it doesn't have a claim to be verified.", "helpfulness_rationale": "The review point identifies a clear area for improvement in the paper. It points out that the explanation of how disentanglement is guaranteed is lacking. This is a valuable piece of feedback for the authors as it highlights a specific aspect that needs clarification. While it doesn't directly propose a solution, it points to a significant gap in the explanation, making it 3 for the authors to understand the limitations and seek further details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a problem and asks for clarification on a specific aspect of the method, which directly informs the authors. The action is clear: consider the implications of optimizing both parameters. The reviewer identifies a potential issue that could affect the model's capacity and how it differs from prior work. This is a direct and actionable feedback.", "grounding_specificity_rationale": "The reviewer points to a specific part of the paper (Eq. 2 and the optimization problem) and asks for clarification on a related implementation detail (parameter count). While the reviewer doesn't explicitly state 'which part' they are referring to initially, the focus is clearly on the optimization problem and its relation to prior work. The grounding is somewhat implicit but becomes clear once the optimization is understood. The specificity is about the *optimization problem* and its relation to prior work.", "verifiability_rationale": "The reviewer makes a claim about the optimization having implications for the number of parameters and that this needs to be discussed. The reviewer states this concern but doesn't provide external references or logical reasoning *within the review point itself*. The reasoning is external to this specific point. The claim is present, and the concern is logical, but the *justification* for the parameter implications would require external knowledge.", "helpfulness_rationale": "The reviewer's point directly affects the authors' understanding of the method's implementation and potential tradeoffs. The reviewer highlights a potential issue that could hinder adoption or understanding. This is a constructive feedback point that directly impacts the authors' ability to implement and understand the method."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly asks a question about the relationship between equations, which is an explicit action. While the question could be phrased more formally, it clearly points to a specific area for improvement.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Eq. 4' and 'Eq. 3' and mentions 'Table 5' and 'OfficeHome' dataset. This demonstrates a clear understanding of the paper's structure and content, making the grounding specific. The reviewer accurately identifies the relevant parts of the paper.", "verifiability_rationale": "The reviewer points out a factual observation about the significance of the improvement in Table 5. The lack of significant improvement is a verifiable fact based on the provided data. The reviewer's statement 'For example, on OfficeHome, the CSAC achieves 64.35, and the proposed solution achieves 64.71, which is a marginal improvement' is a clear and verifiable claim.", "helpfulness_rationale": "The reviewer's point is highly valuable. They are directly addressing a potential limitation of the presented results by highlighting the lack of significant improvement on some datasets. This encourages the authors to discuss the practical significance of their improvements and the criteria for determining significance. The reviewer's question about the relationship between equations also directly prompts the authors to clarify their methodology. This feedback is actionable and directly addresses potential weaknesses in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'some stateoftheart references are missing' and provides a specific example ('Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\"). This clearly identifies a deficiency in the related work section. While it doesn't directly tell the author *how* to fix it, it points to a concrete area for improvement. Therefore, it can be considered 3 as it highlights a specific type of missing information.", "grounding_specificity_rationale": "The review point explicitly mentions a specific stateoftheart work ('Baidu' work \"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\") and highlights a specific technique used in that work (triplet loss). It also mentions a relevant dataset (LFW) that is often used in face recognition research. This strong grounding allows the authors to understand precisely what kind of reference might be missing and why it's relevant. The specificity is high as it names a concrete example and connects it to a specific aspect of the research (the comparison with WebFace).", "verifiability_rationale": "The review point makes a claim by stating that the VRF can achieve 98.65% on LFW, which is better than the result in Table 3. This claim is supported by the fact that the VRF uses triplet loss, a technique also used in the cited work, and achieves a high accuracy on the LFW dataset, a standard benchmark. The evidence is logical and based on common knowledge in the field. Therefore, the claim is 5.", "helpfulness_rationale": "The review point is 5 as it directly points out a specific weakness in the related work section (missing stateoftheart references) and provides a concrete example of a relevant paper and its performance. This helps the authors identify what information is missing and potentially improve their work by including such references. The specific result mentioned (98.65% on LFW) provides a clear benchmark for comparison. The reviewer also implicitly suggests that including this information would improve the comparison with WebFace, which is a valuable piece of feedback."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the issue: \"the question answering requires the template mapping to transform the question into a masked statement\". This clearly identifies an action (the transformation) that needs to be addressed. The reviewer also explains how this transformation might cause a problem (poor generalization to nonWh questions), making the action concrete.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific part of the paper being criticized: \"the question answering requires the template mapping to transform the question into a masked statement\". This demonstrates strong grounding as the reviewer can accurately pinpoint the section being discussed. The reviewer also specifies the *type* of question and the *way* the transformation limits generalization (masked statement, nonWh questions), adding further specificity.", "verifiability_rationale": "The reviewer makes a claim: \"this approach might cause the poor generalization to questions that are not 'Whtypes'/transformable\". This claim is supported by a logical reasoning: \"because it restricts the model's ability to handle questions that cannot be easily framed as who, what, where, when, or why\". While the reviewer doesn't provide external references, the logical connection between the transformation and the limitation is clear and verifiable.", "helpfulness_rationale": "The reviewer points out a potential *problem* (poor generalization) arising from the proposed method. While the reviewer identifies an issue, they do not offer a solution or alternative. The impact is negative rather than positive for the authors, making it less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the flaw in the original paper's evaluation (only pretrained on synthetic data) and proposes an alternative evaluation strategy (pretrained on synthetic, finetuned on realworld with different losses). This clearly indicates an explicit action the authors should take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'synthetic data' and 'realworld datasets' and proposes a specific evaluation *setup* involving pretraining on synthetic data and finetuning on realworld data with different losses. This clearly identifies the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer provides a clear suggestion for an alternative evaluation approach. While they don't provide specific examples of the 'different losses' or 'realworld datasets', the suggestion is logically sound and points to a valid area for improvement. The claim that the proposed projection errors are important is supported by the suggestion to evaluate them in this new way.", "helpfulness_rationale": "While the reviewer identifies a valid weakness in the original paper's evaluation and proposes a valuable alternative, the review point lacks specific details. The reviewer doesn't specify which 'different losses' should be used, which 'realworld datasets' should be employed, or how to determine the 'importance' of the projection errors. This lack of specificity makes it less immediately actionable for the authors compared to a more detailed critique."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the paper's approach of using the first subword token's embedding and directly suggests an alternative, more common method of averaging subword embeddings. It also provides a citation to support the commonality of the alternative approach. This makes the comment 5 as it directly points to a potential improvement or a more standard practice that the authors can easily adopt.", "grounding_specificity_rationale": "The comment explicitly mentions the paper's proposed method of using the embedding of the first subword token, which is a clear indication of the specific part of the paper being addressed. Furthermore, it suggests a specific alternative (averaging subword embeddings) and even provides a citation, making the grounding very specific to the identified method and its potential issues.", "verifiability_rationale": "The comment contains a claim that the paper's approach of taking the embedding of the first subword token is a common practice, which is supported by the provided citation. The suggestion to average subword embeddings is a logical consequence of this claim, and the citation serves as evidence for the commonality of this alternative approach, making the claim verifiable.", "helpfulness_rationale": "The comment is 5 as it provides a clear, actionable suggestion for improving the embedding representation by proposing an alternative to the paper's current method. It is not critical but offers a valuable piece of guidance that authors can readily implement. The suggestion is specific and supported by a reference, making it a constructive comment."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "Partially Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests improvements to the AUC calculation and proposes using calibration curves and discussing differences with traditional methods. While the reviewer doesn't explicitly state what specific changes to make to the AUC calculation, they clearly point out a potential limitation (AUC not showing consistency with actual risk) and offers alternative approaches. This implies a clear direction for action, even if the exact action isn't explicitly stated. The reviewer is suggesting concrete improvements to the evaluation process.", "grounding_specificity_rationale": "The reviewer mentions 'related studies' and 'this paper' when suggesting improvements. They also refer to 'consistency' in the context of the clinical scoring system. While the reviewer implies a connection to their own work and the concept of consistency, they don't explicitly name the specific study or detail the exact nature of the consistency they are referring to. The grounding is present but not fully explicit.", "verifiability_rationale": "The reviewer makes claims about the importance of calibration curves and the need to discuss differences with traditional methods. They provide reasoning for why these suggestions are valuable, such as 'may be more crucial to the clinical scoring system' and 'the difference between the traditional method and our method can also be discussed in this paper.' While the reviewer doesn't provide direct evidence or citations within this review point, the claims themselves are wellsupported by general knowledge of model evaluation and clinical development.", "helpfulness_rationale": "The reviewer's point directly addresses a potential limitation of AUC (not showing consistency with actual risk) and offers concrete suggestions for improvement, such as calibration curves and a discussion of differences with traditional methods. The suggestions are relevant to the field and provide a clear path for the authors to enhance their scoring system. The reviewer's suggestions are actionable in the sense that they provide specific directions for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific issue (no change in ranges/mean) and a lack of discussion (how to ensure conditions). This directly suggests a potential problem and a missing explanation, which are actionable for the authors to investigate and address.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"Figure 4\" and \"Lemma 2\", clearly identifying the specific parts of the paper being addressed. They also specify the issue with the ranges and mean and the lack of discussion on conditions. This demonstrates strong grounding.", "verifiability_rationale": "The reviewer makes claims about the lack of change in ID/OOD ranges and the mean assumption in Lemma 2, and points out the absence of discussion on how to ensure these conditions are met. While the claims about the ranges/mean are directly observable, the claim about the missing discussion lacks immediate evidence within this review point, making it partially verifiable.", "helpfulness_rationale": "The reviewer's point is likely to be helpful for the authors. They are highlighting a potential issue with their implementation/experiment (lack of change in ranges/mean) and pointing out a missing piece of information in their analysis (lack of discussion on conditions). This encourages them to investigate their experimental setup and analysis."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides a clear and actionable list of suggestions. They explicitly state *what* is missing and *why* it's a problem. This immediately suggests high actionability. The reviewer directly names the issues (position kernels, default settings, missing BO baselines, limitations, societal impacts) and suggests concrete improvements (using default settings, including missing baselines, discussing limitations).", "grounding_specificity_rationale": "The reviewer's points are quite general. They talk about the \"experiments,\" \"baselines,\" and \"limitations\" without pinpointing specific sections or tables. While they name *types* of issues (experimental, baselinerelated, impactrelated), they don't explicitly state which *part* of the paper these issues relate to. For example, they say \"the baselines use position kernels,\" but don't say *which* baseline or *where* in the paper this is relevant. They also don't specify *which* BO baselines are missing for discrete/categorical variables.", "verifiability_rationale": "The reviewer makes several claims: \"Besides, the experiments seem not too strong and fair to me,\" \"I don't understand why all the baselines use the position kernels,\" \"it seems like some baselines related to BO with discrete & categorial variables are missing,\" \"The paper also needs to compare its proposed approach with these baselines,\" \"I think the paper does not mention much about the limitations or the societal impacts of their proposed approach.\" While the reviewer provides *reasons* for their claims (e.g., \"because it's not standard practice,\" \"because it limits the applicability of BO\"), they don't provide specific *examples* of missing baselines or *references* to literature that supports their claims about standard practices. The claims about limitations and societal impacts are also not wellsupported with specific examples or references.", "helpfulness_rationale": "The reviewer clearly identifies a problem with the experimental setup and the baselines used. They also suggest concrete improvements, such as using default settings and including missing baselines. While the reviewer's points are general, they are specific to the paper being reviewed. The authors are likely to understand the concerns about their experimental design and the limitations of their baselines. The reviewer's suggestions for improvement are actionable and directly address the identified weaknesses."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two explicit points: (1) the claim that 'this methodology requires significant additional assumptions' is too extreme, and (2) the inequality on line 310 has the wrong sign. While the first point is somewhat subjective, the second point is a clear, actionable suggestion for improvement. The reviewer explicitly states the location of the inequality and its incorrect sign, making it easy for the authors to understand and potentially address.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3.2' and the specific claim about 'significant additional assumptions'. They also point to the specific inequality on line 310. This strong grounding makes it clear which part of the paper the reviewer is referring to.", "verifiability_rationale": "The reviewer identifies two claims: (1) the claim that 'this methodology requires significant additional assumptions' is too extreme, and (2) the inequality on line 310 has the wrong sign. The reviewer provides reasoning for the first point by stating that the assumption of the test set being drawn from the same distribution as the query set is natural for many machine learning settings. For the second point, the reviewer directly compares the inequality on line 310 with the inequality on line 227, providing a clear verification of the error.", "helpfulness_rationale": "The reviewer provides specific feedback on two distinct issues: the claim about 'significant additional assumptions' and the error in the inequality on line 310. By pointing out the location of these issues and suggesting potential improvements (or at least clarifying the assumption), the reviewer provides actionable and constructive feedback to the authors. The reviewer's assessment of the assumption on line 227 as 'natural' provides a basis for understanding why the reviewer found the claim on line 310 to be too extreme."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing the perspective taken in Section 6 to prior efforts. This is an explicit action, as the authors are directly instructed to perform a comparison. While the specific details of the comparison are not provided, the action itself is clear and directly actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 6' as the part of the paper being addressed. This is a literal mention, indicating strong grounding. The authors can accurately pinpoint the section being referred to.", "verifiability_rationale": "The review point contains a claim that 'Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts.' This is a statement of suggestion and implies a perceived weakness. However, the review point does not provide any evidence, reasoning, or references to support this claim. There is no logical reasoning or justification provided to back up the suggestion.", "helpfulness_rationale": "The review point identifies a potential area for improvement in the manuscript by suggesting a comparison in Section 6. While this is a valid suggestion and could be helpful for the authors, the review point does not provide any specific guidance on how to carry out this comparison. The authors would still need to follow up and perform the comparison themselves based on the suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly states the action of 'examine the performance with different numbers of scenarios'. This indicates a clear intention to explore a potential impact. However, it lacks specific details on *how* this examination should be conducted, such as varying specific factors or using particular analysis methods. Therefore, while the action is clear, the lack of concrete implementation details makes it somewhat vague.", "grounding_specificity_rationale": "The review point refers to 'scenarios' generally and suggests examining 'different numbers' of them. While it points to a specific area of the paper (the experimental setup), it doesn't pinpoint a specific section, table, figure, or unique element within that area. The reference to 'scenarios' is broad and doesn't provide a precise location within the paper. The suggestion to vary 'different numbers' is clear, but the lack of specificity about *which* scenarios are being varied makes it somewhat underspecific.", "verifiability_rationale": "The review point begins with the statement 'I would assume that the performance is closely related to the number of scenarios used for training...'. This is a subjective assumption or opinion, not a claim that can be directly verified by the current paper's content. The review doesn't present any evidence or logical reasoning to support this assumption within the context of the paper itself. Therefore, it doesn't meet the criteria for verifiability.", "helpfulness_rationale": "The review point suggests an *exploratory* experiment by proposing to examine the performance with different numbers of scenarios. While this is a valuable suggestion for future research, it doesn't directly address a perceived weakness or limitation in the current draft. It doesn't provide specific, actionable feedback on how to improve the current work based on the current state of the paper. Therefore, its helpfulness in the context of improving the current draft is limited."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer proposes investigating the impact of disturbances on the model's ability to predict quality labels. While the intent is to provide guidance, the suggestion itself is quite general and lacks specific details about the type of disturbances or how they might affect the model's predictions. Therefore, it is not fully actionable, but the intent behind it is actionable.", "grounding_specificity_rationale": "The reviewer's intent is to improve understanding by investigating disturbances. However, the reviewer does not explicitly identify the specific part of the model or training data being affected by these disturbances. The grounding is implied but not concrete. The specificity is also lacking as the reviewer does not specify the type of disturbances or how they impact the quality label. Therefore, the grounding is weak and the specificity is low.", "verifiability_rationale": "The reviewer poses a question about whether investigating disturbances is a valuable step. While this suggests a potential area for improvement, it does not provide any concrete evidence or reasoning to support the claim that this investigation will lead to better understanding or actionable steps. The claim is presented as a question rather than a verifiable statement. Therefore, the verifiability is low as there is no clear justification provided.", "helpfulness_rationale": "The reviewer suggests investigating disturbances as a way to improve the model's understanding of quality labels. While this is a relevant suggestion, it does not provide specific, actionable steps for the authors. It is a higherlevel recommendation rather than a direct instruction on what changes to make. Therefore, it is 3 in identifying a potential area of improvement, but it lacks concrete guidance on how to achieve that improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point states that Appendix A.2 does not illustrate the state space representation of the environment clearly. While it identifies a problem, it does not explicitly state how the authors should improve the illustration. It suggests an improvement but lacks specific details on how to achieve it.", "grounding_specificity_rationale": "The review point explicitly mentions 'Appendix A.2' and 'state space representation of the environment', which are specific parts of the paper and a specific aspect of that part. This indicates that the authors can easily identify the referenced section and the issue being addressed.", "verifiability_rationale": "The review point is a statement of a problem ('does not illustrate...clearly') without providing any justification or evidence. There is no logical reasoning, common knowledge, or external references offered to support the claim that the illustration is indeed unclear.", "helpfulness_rationale": "The review point identifies a potential weakness in the appendix but does not offer concrete suggestions for improvement. It does not specify how the authors should illustrate the state space representation or provide evidence to support their claim that the current illustration is unclear. Therefore, it lacks actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the bounded noise assumption is 'somewhat restrictive' and mentions 'several efforts to extend these noise conditions'. This indicates an awareness of limitations and suggests further reading. However, the reviewer does not explicitly state what aspects of the bounded noise assumption are restrictive or how the mentioned papers directly address this limitation. The action is implied but not explicitly stated and detailed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'bounded noise assumption' and refers to specific papers and their titles, such as 'A. Khaled and P. Richt\u00b4arik. Better theory for sgd in the nonconvex world. TMLR 2023.' and 'R. Gower, O. Sebbouh, and N. Loizou Sgd for structured nonconvex functions: Learning rates, minibatching and interpolation. AISTATS 2021.' This clearly identifies the specific part of the paper being addressed and provides specific references, making it 5.", "verifiability_rationale": "The reviewer makes claims about the bounded noise assumption being 'somewhat restrictive' and that 'there have been several efforts to extend these noise conditions'. These are claims that require justification. The reviewer then provides specific references to papers that address these extensions, such as 'A. Khaled and P. Richt\u00b4arik. Better theory for sgd in the nonconvex world. TMLR 2023.' and 'R. Gower, O. Sebbouh, and N. Loizou Sgd for structured nonconvex functions: Learning rates, minibatching and interpolation. AISTATS 2021.' These references serve as verifiable evidence supporting the claims.", "helpfulness_rationale": "The reviewer points out the limitations of the bounded noise assumption and suggests exploring related work. While this is a valid direction for research, it does not provide concrete, actionable feedback on how the author should improve their current draft. The reviewer does not specify what changes the author should make based on this information, making the feedback somewhat general and less directly helpful for improving the specific draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review points out a weakness but doesn't tell the authors *what* to do or *how* to improve their draft based on this lack of clarity. It identifies a problem but doesn't provide a specific action.", "grounding_specificity_rationale": "The review point refers to 'characteristic function regularization' generally. It doesn't specify *which* part of the paper this refers to (e.g., a specific section, table, or figure). It also doesn't explain *why* this lack of clarity is a problem for the authors.", "verifiability_rationale": "The statement is an opinion about the clarity of the motivation, not a claim that requires evidence or verification.", "helpfulness_rationale": "The review point identifies a genuine weakness in the authors' draft \u2013 the lack of clarity in the motivation for using characteristic function regularization. This is likely to be helpful for the authors as it highlights an area that needs attention and further explanation. While it doesn't provide a solution, it points to a specific area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the paper combines existing techniques, which can be seen as an implicit suggestion for improvement. However, the reviewer does not specify *how* this combination is a problem or what needs to be improved. The suggestion lacks concrete details on what specific aspects of the combination are lacking or how it falls short of existing standards.", "grounding_specificity_rationale": "The reviewer mentions specific papers (Lykouris et al., 2018; Zhou et al., 2021) and concepts (weighted version of OFUL, contextual linear bandits) when describing the limitations. This demonstrates a degree of grounding by identifying specific sections or elements of the paper being discussed. However, the reviewer does not pinpoint a specific part of the paper (e.g., a particular section, table, or figure) that exhibits the limitation. The grounding is at a more conceptual level.", "verifiability_rationale": "The reviewer makes a claim about the contribution being incremental based on the combination of techniques. The reviewer attempts to support this claim by stating that the results can be combined together. This provides some logical reasoning. However, the claim lacks specific examples or references to external works that would strengthen the verifiability. The justification is present but could be more robust with concrete evidence.", "helpfulness_rationale": "The reviewer expresses a negative opinion about the paper's contribution, suggesting it might be incremental. While this is a valid critique, the reviewer does not provide specific, actionable feedback on what aspects of the paper need improvement or what changes could be made to address the perceived incrementality. The feedback is primarily a statement of opinion rather than constructive suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'what does 100 steps here mean?' indicating an action (clarification) is desired. However, the term 'steps' is not explicitly defined, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'Search models comparison 5.1', providing some grounding by mentioning a specific section. However, the exact comparison being discussed within that section is not explicitly identified, making the grounding less than full. The question itself is specific about the ambiguity of '100 steps'.", "verifiability_rationale": "The review point is a question seeking information, not a statement containing a claim that needs verification. Therefore, it does not fall under the verifiability criteria.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific implementation detail ('100 steps'). This directly points to a potential area of confusion for the authors and is therefore helpful in identifying a need for further explanation or detail in the original paper."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a gap in exploration (energy models vs. GANs/VAEs) and suggests further exploration. It also mentions a similarity to a prior VAE paper. While the motivation is stated, the exact action to take based on this motivation is not explicitly laid out. The reviewer suggests exploring related work, but doesn't provide a concrete stepbystep action for the authors.", "grounding_specificity_rationale": "The reviewer mentions \"energy models\" and even suggests a potential related work (\"prior VAE paper\"). This provides a degree of grounding as the specific area of research is identified. Furthermore, the reviewer explicitly mentions the similarity to a prior VAE paper, which grounds the specific area of related work. While the connection to \"logical combination of concepts learned through data subsets\" is more implicit in the motivation, the initial identification of energy models and the suggestion of a related VAE paper are quite specific.", "verifiability_rationale": "The review states a position: \"the use of energy models for image generation is much more unexplored compared to GANs and VAEs\". This is a claim that needs to be supported. However, the reviewer does not provide any evidence or justification for this claim within the review point itself. They suggest it's unexplored based on common knowledge, but don't cite a specific source or provide a logical argument to back it up.", "helpfulness_rationale": "The review offers context for the authors' work by highlighting a potential area of research and pointing out a similarity to existing work. This suggests a potential direction for improvement, even if the exact steps aren't laid out. The reviewer's point about the similarity to a prior VAE paper, while not a direct solution, offers a potential avenue for the authors to explore or improve their work. It doesn't completely ruin their idea, but it does point out a limitation."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "High", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states the method is evaluated *only* on Meta World and suggests an *action* to improve generalizability by recommending Atari. This indicates a clear and direct action the reviewer believes is needed. The reviewer doesn't leave ambiguity about what action is needed.", "grounding_specificity_rationale": "The reviewer mentions 'Meta World, a robotic manipulation domain' and then further specifies 'Atari' as a benchmark for testing generalizability. While 'Meta World' isn't a specific section, it's a wellknown benchmark, making the grounding relatively strong. The reviewer also specifies the type of observations (highdimensional) and actions (discrete), adding to the specificity of the criticism. The reviewer doesn't just state a problem; they also point to a specific area for improvement.", "verifiability_rationale": "The reviewer makes a claim: 'The method is evaluated only on the tasks from Meta World...'. They then provide a *reason* for this limitation: 'Hence, it is difficult to judge whether the results will generalize to other domains.' This reasoning is logical and based on common sense in research. The reviewer doesn't just state a fact; they also explain *why* it's a concern. The reviewer also suggests a *specific* way to address this, by recommending Atari.", "helpfulness_rationale": "The reviewer points out a potential limitation in the evaluation and suggests a concrete improvement. This is a helpful comment because it directly addresses a potential weakness and offers a clear next step. The reviewer's suggestion is actionable and specific."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point states a desire for 'analysis on what the model does'. This indicates an explicit action of seeking further analysis. However, the specifics of this analysis are not provided, making it somewhat vague. The reviewer knows they want an analysis, but the 'how' is missing.", "grounding_specificity_rationale": "The review point is very general and does not specify which part of the paper or model it is referring to. It simply states a desire for 'analysis on what the model does'. There is no mention of a specific section, table, figure, or unique aspect of the paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point is a suggestion for further analysis, not a claim that something is true or needs verification. It does not contain a claim that requires logical reasoning, common knowledge, or external references. Therefore, it does not fit the definition of a verifiable statement.", "helpfulness_rationale": "The review point directly addresses a potential weakness (the lack of model analysis) and suggests a concrete improvement (providing analysis). This is a relevant suggestion that can help the authors improve their understanding of their model. While the suggestion is broad, it is still a helpful direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the modulator is 'heuristically designed' and that there is a 'potential issue with scalability and hyperparameter tuning.' While it identifies a problem, it does not explicitly state what action the author should take or how to implement it. The reviewer implies a problem but lacks concrete, actionable steps for the author. The level of detail is highlevel and lacks specific guidance on how to address the potential scalability issue.", "grounding_specificity_rationale": "The review point mentions 'training data' generally and 'diverse training data' without specifying which part of the paper or model this refers to. The reviewer can infer that the issue relates to the training data, but they cannot pinpoint the specific data or the specific model being trained. This makes the grounding weak. While the issue is about training data and scalability, the specificity is limited to a general concern about diversity. There's no detail about specific data points, features, or model components.", "verifiability_rationale": "The review point states that the modulator is 'heuristically designed' and that there is a 'potential issue with scalability and hyperparameter tuning.' These statements are presented as claims without any supporting evidence or justification. The reviewer does not provide any logical reasoning, common knowledge, or external references to back up these claims. The claims are presented without any verification.", "helpfulness_rationale": "The review point identifies a potential issue with the modulator's design and scalability. However, it does not offer any specific suggestions or guidance on how to address this issue. The reviewer points out a problem but doesn't provide any actionable steps or insights for the author. The potential for improvement is limited as there are no concrete recommendations for the author."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "6: X (X)", "helpfulness_label": "4", "actionability_rationale": "The review point mentions \"f_R and f_P can be adapted over time\" and \"A less informed f_R/f_P might require an impractical amount of data to learn.\" While this implies a problem with directly using f_R/f_P, it doesn't explicitly state what needs to be done or how to do it. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The review point discusses \"f_R and f_P\" and their 'structure\" and the \"requirement of impractical amount of data.\" It does not explicitly identify a specific part of the paper being addressed, nor does it specify what is meant by \"practical amount of data.\"", "verifiability_rationale": "The review point does not contain a claim or assertion. It describes the potential limitations of f_R/f_P without providing evidence or references. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The review point identifies a potential practical limitation of f_R/f_P but does not offer concrete advice on how to address it or how to make the models less datahungry. The suggestion is vague and lacks specific guidance. While it points out a problem, it doesn't provide actionable steps or constructive suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the necessity of obtaining labeled data for imitation learning. However, it does not provide specific actions or concrete details on how to achieve this. The reviewer identifies a potential gap in the method's applicability but lacks a direct solution or detailed steps.", "grounding_specificity_rationale": "The review point mentions 'imitation learning' and 'labeled data' in a general sense. It does not specify a particular aspect of the paper, a method, or a unique element within the paper that it is addressing. The reviewer's comment is broad and lacks specificity.", "verifiability_rationale": "The review point makes a claim about the necessity of labeled data for imitation learning and criticizes the lack of experiments on data difficulty and performance impact. While the reviewer does not provide explicit evidence to support this claim, it identifies a potential area for further investigation, making it 3.", "helpfulness_rationale": "The review point identifies a potential gap in the experimental validation of imitation learning's applicability. It points out a missing piece of information that could be relevant for someone considering using imitation learning. While it doesn't provide a direct solution, it highlights a potential area for further research, making it 3."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "Partially Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a gap in the paper's argument regarding the connection between overparameterization, memorization, and generalization, specifically concerning generalization bounds. While the reviewer identifies a problem, the action is to clarify the existing argument rather than directly suggest a change in the paper's methodology or experiments. The action is explicit in identifying the missing link but lacks detail on how to address it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'generalization bounds' as the area where the paper's constructions of ReLU networks for robust memorization might lead to robust generalization. They clearly identify the specific part of the paper being addressed (the connection to generalization bounds) and specify what is being questioned. This indicates a high level of grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity in the paper's discussion regarding the connection to generalization bounds. This claim can be verified by examining the paper's discussion on this topic. The reviewer provides their understanding of the concepts and the potential disconnect, which can be logically reasoned upon.", "helpfulness_rationale": "The reviewer's point directly addresses a potential weakness in the paper's argument and suggests a way to improve it by clarifying the connection to generalization bounds. This is a clear and actionable suggestion aimed at improving the paper's clarity and completeness."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the weakness of the OOD experiments and suggests a comparison with untrained networks. The phrase 'It maybe good to mention this in the paper' indicates an action to improve the paper by including this comparison. The suggestion to 'Ideally, also compare with those class of methods' is a direct action to address the identified weakness.", "grounding_specificity_rationale": "The reviewer refers to 'OOD experiments' and 'untrained NNs (like deep image prior)'. The mention of 'inverse problems' further specifies the context. The reviewer explicitly names a specific method ('deep image prior') within that context. This shows a clear identification of the relevant part of the paper and the specifics of the suggested comparison.", "verifiability_rationale": "The review point contains a claim: 'It maybe good to mention this in the paper...'. The reviewer suggests a concrete action: 'Ideally, also compare with those class of methods...'. While the suggestion is grounded in specific methods, the reviewer doesn't provide a logical reasoning or external references to support why this comparison is necessary or beneficial. The suggestion is presented as a potential improvement.", "helpfulness_rationale": "The review point identifies a potential area for improvement in the OOD experiments and suggests a concrete comparison with a relevant class of methods. The reviewer's suggestion is actionable and directly addresses the identified weakness. While the review doesn't provide a definitive reason *why* the current method is lacking in OOD generalization, it offers a clear direction for the authors to enhance their work by comparing with untrained networks used for inverse problems."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the need for 'more experiments' and specifies the types of networks ('deeper networks' and 'other network structures'). It also provides a reason for these experiments ('to further strengthen the paper'). While the specific *implementation* of these experiments isn't detailed, the core action of conducting more experiments is clear. The reviewer suggests exploring specific architectures (ResNet50 and MobileNet) and even provides references related to these architectures, making the action quite concrete.", "grounding_specificity_rationale": "The comment explicitly mentions the need for 'more experiments on deeper networks' and 'other network structures'. This clearly identifies the specific part of the paper being addressed. The reviewer doesn't need to infer which part is being discussed. The comment also specifies the *types* of networks, making the grounding quite explicit. The reviewer even suggests leveraging existing research on network architectures, further enhancing the specificity.", "verifiability_rationale": "The comment contains a claim: 'More experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to further strengthen the paper'. This claim is supported by the reasoning 'References: 1 MoBiNet: A Mobile Binary Network for Image Classification, in WACV 2020. 2 Dynamic Channel Pruning: Feature Boosting and Suppression, in ICLR2019. 3 Learning Dynamic Routing for Semantic Segmentation, in CVPR2020.' These references provide examples of relevant research and suggest a direction for improvement. While not a direct citation within the review itself, the references offer a basis for verifying the claim.", "helpfulness_rationale": "The review point is 5. It directly addresses a potential weakness (limited architectural exploration) and provides clear suggestions for improvement (experiments with ResNet50 and MobileNet). The inclusion of references further strengthens the helpfulness by providing concrete examples and methodologies to consider. The reviewer is not just pointing out a problem but also offering a path towards a solution."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states a lack of clarity but does not provide any suggestions or actions for the authors to take. It is a statement of uncertainty, not a directive.", "grounding_specificity_rationale": "The review point refers to 'the proposed sample selection mechanism' and 'label distribution' without specifying which section or table of the paper these concepts relate to. The author can only make an educated guess about the referenced parts.", "verifiability_rationale": "The review point contains a claim ('It is not clear...') but does not provide any supporting evidence or justification for this claim. The reasoning is vague and lacks specific examples or references.", "helpfulness_rationale": "The review point identifies a potential area for improvement in the paper's explanation of a specific mechanism. It highlights a lack of clarity, which is valuable information for the authors to understand and potentially address."}
{"actionability_label": "1", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what needs to be improved or provide actionable feedback on the limitations of the evaluation. It describes the scope of the evaluation as limited to two old and small models, but doesn't suggest how this limitation should be addressed or how the authors should proceed. The reviewer points out a fact rather than a directive.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or the evaluation process that is being criticized. It is a general statement about the scope of the evaluation. The reviewer mentions 'two relatively old and small models' but doesn't specify which analysis or finding within the paper this refers to. There is no clear grounding of the criticism within the paper's content or structure.", "verifiability_rationale": "The review point makes a claim about the evaluation's scope and limitations. While the statement itself might be verifiable (two models are indeed old and small), the *claim* that this limitation is a problem and needs to be addressed is not explicitly supported by evidence or reasoning within the review point itself. The reviewer states a fact about the evaluation's scope but doesn't provide a logical justification or external references for why this is a significant issue.", "helpfulness_rationale": "The review point provides information about the limitations of the evaluation. While it doesn't directly suggest improvements to the evaluation itself, it informs the authors about the scope of the assessment. This information can be helpful for the authors to understand the context of the evaluation and potentially focus their work accordingly. The reviewer provides a factual observation that could aid in their understanding, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks 'can authors please throw light on why' regarding the performance degradation. This is a direct request for an explanation of a phenomenon, making it an explicit action. The reviewer also identifies the specific information being added ('missing/wrong/redundant') and asks how its inclusion causes degradation, making the action concrete.", "grounding_specificity_rationale": "The reviewer's request is about the performance of the FBN results when using additional information. The reviewer specifically mentions 'missing/wrong/redundant' information, which allows for precise identification of the part of the information being discussed. The request is also about 'why' the performance degrades, which implies a desire for a clear connection between the added information and the observed outcome. This makes the grounding specific.", "verifiability_rationale": "The reviewer makes a claim: 'the performance degrades when using the additional information about missing/wrong/redundant'. This is a statement that requires justification. The request for 'light' on why is a request for explanation and reasoning, which is verifiable through analysis of the FBN model's behavior with different types of information. The claim itself is verifiable by examining the model's performance with and without the specified information.", "helpfulness_rationale": "The reviewer's request for an explanation regarding the performance degradation is directly relevant to improving the draft. Understanding *why* performance degrades when adding specific information can help authors identify and address weaknesses in their approach. This provides actionable feedback and insight, making the review helpful. While it prompts further investigation, it is a valuable starting point for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states two areas where they found the paper unclear and provides specific examples of what was confusing. The reviewer points to specific sections (1 and 2), figures (Fig 2), and equations (1 and 2) within those sections. While the reviewer doesn't provide a *direct* action or solution, the questions posed are clear and point to specific areas needing improvement. The reviewer identifies the *action* the authors should take: 'understand why the stacked LSTM in Fig 2(a) is \"trivial\" to convert to the sequential LSTM Fig2(b)' and 'understand the phrase \"our lower hierarchical layers zoom in time\"'.", "grounding_specificity_rationale": "The reviewer explicitly mentions the sections (1 and 2) and even refers to specific elements within those sections like figures and equations. They also point to specific phrases that are unclear. The reviewer doesn't need to *guess* which part they are referring to. They are accurately pinpointing the location and the specific issue.", "verifiability_rationale": "The reviewer states that the first two sections are hard to read and points to specific instances of confusion. However, the reviewer does not provide any external references, logical reasoning, or examples to *justify* why these sections are unclear. The reviewer is stating an opinion about the clarity of the writing, but lacks the supporting evidence to back it up. The reviewer is asking questions, not providing solutions or evidence.", "helpfulness_rationale": "The reviewer identifies areas where the paper is unclear and provides specific examples of what is confusing. While the reviewer is asking questions and pointing out potential areas of weakness, they are not offering any concrete suggestions or solutions. The reviewer is not providing actionable feedback that would empower the authors to improve their draft. The feedback is diagnostic rather than prescriptive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states \"The motivation is not clear at all.\" While this is an explicit statement, it lacks specificity. It doesn't identify *what* aspect of the motivation is unclear or provide a concrete action for the authors to take. The authors are left wondering where the lack of clarity lies and how to address it. Therefore, it is not fully actionable as it does not provide clear guidance on how to improve the paper's motivation.", "grounding_specificity_rationale": "The comment \"The motivation is not clear at all.\" does not identify a specific part of the paper or section that is lacking clarity. The reviewer is making a general statement about the introduction's motivation without pinpointing a particular element (e.g., a specific claim, argument, or section) that needs improvement. Therefore, the grounding is weak as the authors cannot confidently determine the area of concern.", "verifiability_rationale": "The review point \"The motivation is not clear at all.\" does not contain a claim that requires verification. It is a statement of observation about the paper's motivation. There is no suggestion, recommendation, or judgment that necessitates supporting evidence or logical reasoning. Therefore, it does not meet the criteria for verifiability, as there is X to be evaluated.", "helpfulness_rationale": "The review point \"The motivation is not clear at all.\" identifies a potential issue with the paper's motivation but does not provide specific guidance or suggestions for improvement. While it points out a weakness, it lacks actionable steps for the authors to take. The authors are left with a diagnosis (lack of clarity) but no prescription. Therefore, the review point is not particularly helpful in providing concrete directions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a difference in how features are used across categories but doesn't explicitly state what needs to be changed or how to implement this difference.", "grounding_specificity_rationale": "The review point mentions 'features' and 'categories' without explicitly identifying a specific part of the paper being addressed. It describes a general observation about the structure of the features across different categories but doesn't pinpoint a particular section, table, figure, or unique element.", "verifiability_rationale": "The review point contains claims, such as 'it is intuitive that including multiple local prompts helps' and 'for different categories, the features and their positions are not the same', but it doesn't provide sufficient justification or evidence for these claims within the review point itself.", "helpfulness_rationale": "The review point provides some relevant information about the differences in feature usage across categories. However, it lacks the specific, actionable steps needed to improve the draft. The feedback is somewhat general and doesn't offer concrete suggestions for how to adjust the feature positions or categorizations."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the *problem* (insufficient validation) but doesn't provide specific *actions* or *how* to address it. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The comment mentions *relabelled reward data* and *human annotator judgments*, providing some grounding. However, it doesn't specify *which* aspects of the alignment or *which* data points are problematic, making the grounding underspecific.", "verifiability_rationale": "The comment itself doesn't contain a claim that needs verification. It's a statement of a problem. Therefore, it doesn't fit into the verifiability categories.", "helpfulness_rationale": "The review point identifies a weakness (insufficient validation) but doesn't offer specific, actionable suggestions for improvement. The suggestion is implied but not explicitly stated, making it less helpful."}
{"actionability_label": "2", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a potential limitation in the method's value due to the limited number of molecules and indistribution testing. However, it does not explicitly state how the authors should address this limitation or provide concrete steps for improvement. The reviewer points out a concern but lacks a direct instruction on how to proceed.", "grounding_specificity_rationale": "The review point explicitly mentions 'a very limited number of molecules' and 'only provides indistribution testing for these samples.' These are specific aspects of the paper being criticized. The reviewer directly addresses the dataset size and the type of testing performed, indicating a clear understanding of the relevant sections.", "verifiability_rationale": "The review point expresses a concern about the method's value if it needs to be trained individually for each molecule. However, it does not provide any evidence or reasoning to support this concern. The statement is a claim about the method's potential limitations without any logical justification or references to external sources. The reviewer states a potential issue but doesn't explain why it's a significant problem.", "helpfulness_rationale": "The review point is critical of the method's potential limitations due to the limited number of molecules and indistribution testing. While it identifies a potential weakness, it does not offer any constructive suggestions or solutions for the authors. The feedback is primarily negative and lacks actionable improvements. The reviewer criticizes the method's potential lack of generalizability but doesn't propose any concrete steps to address it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for an explanation of the red line in Figure 3. This constitutes an explicit action, as the reviewer is directly asking for information to be applied. The expectation is for a concrete explanation of the source of the test data and how the ground truth is determined.", "grounding_specificity_rationale": "The reviewer directly asks about the source of the test data and the nature of the ground truth. This directly addresses the 'grounding' aspect of the figure. The request is specific about what information is needed to understand the red line, indicating high specificity.", "verifiability_rationale": "The reviewer's request itself is not a claim. It is a request for information. Therefore, the verifiability score for the review point itself is 'X'. However, the request implies a lack of clarity, suggesting the *explanation* provided *will* be a verifiable claim.", "helpfulness_rationale": "The reviewer's request directly addresses a potential point of confusion for the authors regarding Figure 3. By asking for clarification, they are seeking to improve their understanding and potentially the clarity of the paper. This request is inherently helpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment is a general statement about the writing quality and does not specify any particular aspect of the paper that needs improvement. It lacks explicit instructions on how the authors should revise the paper. While it identifies a problem, the action required is not clearly defined.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper being addressed. It is a general statement about the overall writing quality. The authors cannot confidently determine which section, table, figure, or unique aspect of the paper is being criticized. The grounding of the comment is weak.", "verifiability_rationale": "The comment contains a claim ('The paper is not very wellwritten...') but does not provide any supporting evidence or justification for this statement. There are no logical reasons, common knowledge, or external references provided to back up the criticism. The claim is presented without sufficient support.", "helpfulness_rationale": "The comment is a general criticism of the writing quality and does not offer any specific suggestions or guidance on how the authors should improve the paper. It lacks the necessary specificity and actionability to be helpful. The authors are left wondering what exactly needs to be changed and how they should go about it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the paper's contribution as removing double descent in 'certain anisotropic settings' in relation to prior work on samplewise multiple descent. This provides a clear and direct action for the authors to take.", "grounding_specificity_rationale": "The reviewer refers to 'prior work already theoretically shows that samplewise multiple descent can occur in linear regression' and the paper's contribution as 'optimal regularization can remove double descent even in certain anisotropic settings'. This explicitly grounds the contribution in existing literature and specifies the exact nature of the improvement.", "verifiability_rationale": "The reviewer states 'I am not too familiar with the particular techniques and tools used in the paper and could not verify the claims but they seem correct.' This is a factual statement about their verification process, fitting the 'X' category as it describes a descriptive statement without an opinion or suggestion.", "helpfulness_rationale": "The reviewer states 'I am not too familiar with the particular techniques and tools used in the paper and could not verify the claims but they seem correct.' This statement directly addresses the value of the comment to the authors, indicating it is helpful."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks 'Why the results of Table 6 is not aligned with Table 1 (MCTpair)'. This is an implicit request for an action, specifically to understand the discrepancy. While not explicitly stating 'how to fix it', the reviewer implies a need for clarification and explanation. The second part of the review asks 'Also what about the ablation studies of MCT without the adaptive metrics'. This is an explicit request for an action, specifically to request the results of ablation studies. Both parts of the review point to a need for the authors to take action to understand and address a potential issue.", "grounding_specificity_rationale": "The reviewer asks 'Why the results of Table 6 is not aligned with Table 1 (MCTpair)'. While the reviewer mentions specific tables and MCTpair, they do not explicitly identify the section or table within the paper that contains the relevant information. The reviewer implies a discrepancy but doesn't pinpoint the exact location. The second part of the review asks 'Also what about the ablation studies of MCT without the adaptive metrics'. The reviewer explicitly asks for ablation studies related to MCT and without adaptive metrics, which directly points to a specific section and element within the paper. Therefore, the first part is weakly grounded, while the second part is fully grounded.", "verifiability_rationale": "The reviewer asks 'Why the results of Table 6 is not aligned with Table 1 (MCTpair)'. This is a claim that there is a discrepancy. The reviewer is asking for verification of this claim. The second part of the review asks 'Also what about the ablation studies of MCT without the adaptive metrics'. The request for ablation studies is a claim that such studies exist and are relevant. Both parts of the review involve claims that can be verified through examination of the paper's content and methodology. Therefore, both parts are 5.", "helpfulness_rationale": "The reviewer asks 'Why the results of Table 6 is not aligned with Table 1 (MCTpair)'. This is a valid question that could lead to a helpful improvement if the authors provide an explanation for the discrepancy. However, the explanation might not be immediately obvious and requires further investigation. The second part of the review asks 'Also what about the ablation studies of MCT without the adaptive metrics'. This is a very specific and actionable request. Requesting ablation studies directly addresses a potential methodological choice and its impact. This is a 5 question as it directly prompts the authors to provide specific information that could clarify their methodology and potentially lead to improvements. Therefore, the first part is 3, while the second part is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer is implicitly suggesting that the simplicity of the subtasks is a problem, but they don't explicitly state what action should be taken. They could say something like, 'You should discuss the limitations of the subtasks...' but they don't. Therefore, it's 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the 10 subtasks of the bAbi experiment' which is a specific part of the paper. They are not making a general comment about the entire experiment. Therefore, it is grounded. The reviewer is also specific about the 'simplicity' of these subtasks. Therefore, it is specific.", "verifiability_rationale": "The reviewer makes a claim ('The 10 subtasks are rather simplistic') but does not provide any evidence or justification for this claim within the review point itself. They are stating an opinion without supporting it. Therefore, it is not verifiable.", "helpfulness_rationale": "The reviewer points out a potential weakness in the experimental design (the simplicity of the subtasks). This could be helpful for the authors to consider and potentially improve their work. However, the reviewer does not provide specific suggestions or actions for the authors to take. Therefore, it is 3 but lacks concrete suggestions."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a difference in classification (ablation study vs. parameter variation) regarding the subdomain size study. This is a direct statement of what the authors should have done, even if the reviewer doesn't provide specific suggestions on what they *should* have done. Therefore, it is an explicit action that needs to be taken.", "grounding_specificity_rationale": "The reviewer directly addresses the *classification* of the subdomain size study. They identify the specific aspect being criticized (the mislabeling as an ablation study). This allows the authors to confidently identify the section being discussed. Therefore, the grounding is full.", "verifiability_rationale": "The reviewer's point is about the *definition* of an ablation study, not about a claim requiring evidence or justification. It's a clarification of terminology, not a critique of a result or method. Therefore, it doesn't fit into the 'claim verification' categories, and the appropriate label is 'X'.", "helpfulness_rationale": "The reviewer raises a valid point about the terminology used in the paper. While it doesn't directly point out a specific flaw in their methodology or results, it clarifies a potential misunderstanding for the authors. This can be helpful in understanding how the subdomain size study was interpreted. Therefore, it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment implicitly suggests an action: exploring the integration of AccNet into a larger predictor system. While it doesn't explicitly state 'how to do this,' the mention of 'a larger predictor' and 'similar operators' implies a concrete direction for improvement. The reviewer is suggesting a specific way to potentially enhance the existing work.", "grounding_specificity_rationale": "The comment mentions 'AccNet,' 'a larger predictor,' and 'similar operators.' While it doesn't explicitly state the *exact* larger predictor or the *exact* operators, it provides enough context for the reviewer to understand the general idea being proposed. The reviewer is not stating a specific section to address but rather a general direction for future work. This suggests weak grounding as the authors would need to infer the specific components.", "verifiability_rationale": "The comment proposes a potential research direction: investigating the effectiveness of combining AccNet with a larger predictor for semantic segmentation. While it doesn't provide a definitive answer or cite external references, the suggestion is based on logical connections between existing concepts (AccNet, predictors, semantic segmentation). The reviewer is suggesting a plausible next step, making it 3 through experimentation and further research. There's no immediate logical contradiction or obvious flaw in the proposed idea.", "helpfulness_rationale": "The comment offers a suggestion for future research: exploring the integration of AccNet into a larger predictor system for semantic segmentation. This is a valuable idea as it proposes a concrete direction for extending the work. However, it's presented as a question and lacks specific details on how to implement this integration or what challenges might arise. While it has the potential to be helpful, the lack of concrete details makes it less directly actionable for immediate improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a limitation of the metric's evaluation scope, which can be seen as an implicit action to bring attention to this issue. While not explicitly stating how to improve the metric, the identification of the limitation implies a need for more comprehensive testing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the new proposed metric' and 'a single dataset', providing clear grounding to the specific aspect being discussed. The terms are directly relevant and the connection is obvious.", "verifiability_rationale": "The reviewer makes a clear claim about the metric's evaluation being limited to a single dataset. This claim can be directly verified by examining the metric's documentation or experimental setup, making it 5.", "helpfulness_rationale": "The reviewer points out a potential limitation that could help authors make informed decisions about the applicability of the metric. By highlighting the lack of broader evaluation, the review provides context and can guide authors in their usage, thus being helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'AutoDial and AdaBN that are direct competitors to TN.' This is a clear and direct suggestion for improvement, making the action explicit. The reviewer also implies that evaluating against these methods would provide a more comprehensive understanding of TN's effectiveness, making the action concrete by identifying a specific area for comparison.", "grounding_specificity_rationale": "The reviewer states 'AutoDial and AdaBN that are direct competitors to TN.' While the reviewer identifies the *methods* to compare against, they do not explicitly state which *part* of the paper this evaluation should be performed. The reviewer also does not specify *why* these methods are important comparisons or provide examples of how this evaluation should be conducted. Therefore, while the *action* is clear, the *grounding* of this action within the paper is missing.", "verifiability_rationale": "The reviewer states 'It would be stronger if the base DA methods were similarly evaluated with/without the architectural competitors such as AutoDial and AdaBN that are direct competitors to TN.' The claim is that the evaluation is a 'good start,' but the *verifiability* of this claim is not addressed. The reviewer does not provide any logical reasoning, common knowledge, or external references to support the claim that evaluating against these methods would be a significant improvement. The statement is presented as a suggestion for improvement without evidence.", "helpfulness_rationale": "The reviewer suggests 'It would be stronger if the base DA methods were similarly evaluated with/without the architectural competitors such as AutoDial and AdaBN that are direct competitors to TN.' This statement clearly identifies a weakness in the current evaluation (lack of comparison with key competitors) and proposes a concrete, actionable improvement (evaluating against these methods). This constitutes a claim that is directly aimed at improving the authors' work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states what is missing ('definitions', 'superscript notation', 'citations') and implies the authors should add them. Furthermore, the reviewer explicitly states how to add the citations by providing examples. This makes the action very concrete and directly actionable.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific location of the undefined abbreviation ('L73') and the missing definition of the superscript notation ('Eq 6'). The suggestions to add specific citations also point to specific locations. This strong identification of the specific part of the paper being addressed and the specific issues within it constitutes full grounding. The reviewer also clearly specifies what needs to be addressed in this part (definitions, superscript notation, citations).", "verifiability_rationale": "The reviewer provides suggestions for improvement, such as 'add definitions for NE', 'add explanation for superscript notation', and 'add citations to the papers listed'. These suggestions are clear and logical, and the authors can easily verify them by adding the requested information. While the suggestions don't directly point to external references, they are verifiable and actionable.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as adding definitions, explaining the superscript notation, and citing relevant papers. These suggestions are directly aimed at improving the clarity and completeness of the paper. While the suggestions are quite specific, they are still actionable and will likely be helpful for the authors to address the identified issues."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement 'the evaluation is weak' is explicit, indicating a perceived deficiency. However, it lacks specific details on what constitutes the weakness, making it somewhat vague.", "grounding_specificity_rationale": "The comment 'the evaluation is weak; the baselines used in the paper are not even designed for fair classification' does not specify which part of the evaluation or the baselines are being criticized. It makes a general statement about the evaluation's weakness and the baselines' inadequacy.", "verifiability_rationale": "The claim 'the baselines used in the paper are not even designed for fair classification' is presented as a statement of opinion without providing any specific examples or references to support this claim. Therefore, it lacks sufficient evidence for verification.", "helpfulness_rationale": "The review point is a critique of the evaluation's weakness and the baselines' inadequacy. It does not offer specific suggestions or actionable steps for improvement, making it unhelpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the action they want to see: 'spelling out the setting'. This action is concrete as it specifies the exact location in the paper (first three paragraphs of section 2) and the nature of the information needed (details of the setting).", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific part of the paper being addressed: 'the first three paragraphs of section 2'. This is a strong form of grounding as the authors can directly locate the relevant section. While the term 'setting' is general, in the context of specific paragraphs and section, it provides a clear direction for where to look for clarification. Therefore, it can be considered somewhat specific as it points to the relevant section and the general area of exposition.", "verifiability_rationale": "The reviewer's comment suggests a change to improve clarity: 'In the first three paragraphs of section 2, the setting needs to be spelled out more clearly.' This can be considered a claim that the current presentation of the setting is unclear. While the reviewer doesn't provide specific examples of what is unclear or how to improve it, the intent is to improve the paper's exposition, which is generally verifiable through direct reading and understanding. However, without concrete examples, the verifiability is limited to the expectation that better clarity will be achieved.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential area of confusion for the authors regarding the setting in the specified section. By suggesting that the setting needs to be spelled out more clearly, the reviewer provides a clear direction for improvement. While it doesn't offer a definitive solution, it guides the authors on where to look for clarification and what kind of information might be missing. Therefore, it is 3 in pointing towards a potential issue and a direction for investigation."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the concern about the choice of baselines (R3D and C3D) and suggests improvements (comparing to modern 3D CNNs like X3D and SlowFast, and highlighting the advantages of the proposed method). This indicates an intention to guide the authors towards a more comprehensive evaluation. However, the reviewer does not provide specific details on how to implement these suggestions, such as the exact comparison method or the nature of the advantages.", "grounding_specificity_rationale": "The reviewer raises a general concern about the experiments but does not specify a particular section, table, or unique aspect of the paper that is affected. The reference is broad and does not pinpoint the exact location of the issue.", "verifiability_rationale": "The reviewer makes a claim about the weakness of the chosen baselines (R3D and C3D) and poses a question about the advantages of the proposed method compared to more advanced 3D CNNs. While a claim is present, the reviewer does not provide any evidence, references, or logical reasoning to support this claim. The suggestion to compare with X3D and SlowFast is mentioned but not elaborated upon with specific comparison methods or expected advantages.", "helpfulness_rationale": "The reviewer raises a relevant point about the limitations of the chosen baselines and suggests a direction for improvement by comparing with more advanced models. However, the lack of specific details and supporting evidence makes it difficult for the authors to fully understand and act upon the suggestions. The reviewer's intent is clear, but the review point is incomplete and lacks the necessary information to be fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'marginal' improvements and suggests 'further analysis', providing a clear action for the authors to take. While 'marginal' is somewhat vague, the intention is clear.", "grounding_specificity_rationale": "The comment refers to 'improvements on three tasks' and 'previous works and baselines', indicating some level of grounding. However, it doesn't specify which particular improvements or which specific tasks or baselines are being compared in this way, making it weakly grounded.", "verifiability_rationale": "The comment contains a claim ('marginal' improvements) but lacks any supporting evidence or justification. It doesn't provide any logical reasoning, common knowledge, or external references to back up the assertion of marginal improvements.", "helpfulness_rationale": "The comment identifies a limitation ('marginal' improvements) but doesn't offer any specific suggestions or directions for improvement. The suggestion to 'further analysis' is general and lacks specificity, making it not very helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a limitation of the paper's theoretical result (the Gaussian assumption) and suggests a change (not using the Gaussian assumption). It also asks a question (how the rates achieved by their procedure to existing rates in the literature), which is a clear action the authors should take. The suggestion to not use the Gaussian assumption is also explicit.", "grounding_specificity_rationale": "The review point explicitly refers to the 'main (and only) theoretical result' and the 'features and noise are Gaussian' assumption. It also asks a question about 'existing rates in the literature'. This clearly identifies the specific part of the paper being addressed and asks a specific question about it.", "verifiability_rationale": "The review point makes a claim about the limitations of the Gaussian assumption in the theoretical result. While it doesn't provide direct evidence *within this review point*, it clearly identifies a potential area for improvement and suggests an alternative approach (not using the Gaussian assumption). The action to investigate this further is implied.", "helpfulness_rationale": "The review point is highly specific about a limitation of the theoretical result and suggests a concrete improvement (not using the Gaussian assumption). It also points out a gap in comparison to existing literature. This provides clear direction for the authors to improve their work. While it doesn't *prove* the limitations, it strongly suggests a potential avenue for future research and highlights a specific area for improvement. It's slightly less helpful than a point that directly identifies a bug, but it's still very valuable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests comparing the proposed extension with the original approach of Schiratti et al. (2015). While the suggestion is explicit in its goal (comparison), it lacks specific details on *how* to perform this comparison. The reviewer implies this comparison would be beneficial, but the action is not fully defined. Therefore, while the intent is clear, the lack of concrete steps makes it somewhat vague.", "grounding_specificity_rationale": "The reviewer suggests comparing with the work of Schiratti et al. (2015). This comment explicitly refers to a specific piece of prior work. The reviewer does not, however, specify *which* aspect of Schiratti et al.'s approach should be compared or what specific details of the comparison are expected. While the paper is mentioned, the focus is on the *idea* of comparison rather than a precise reference to a specific section, table, or figure. Therefore, the grounding is present but lacks the precision of identifying a unique element within the paper.", "verifiability_rationale": "The reviewer suggests comparing the proposed extension with the original approach of Schiratti et al. (2015). This is a claim that would likely be verifiable through direct implementation and comparison of the methods. The reviewer implies that this comparison would reveal insights into the effectiveness or differences between the approaches. While the suggestion itself isn't a direct comparison, the *act* of comparing would be verifiable. Therefore, the claim is somewhat inferable but has the potential for verification once the comparison is performed.", "helpfulness_rationale": "The reviewer suggests comparing the proposed extension with the original approach of Schiratti et al. (2015). This is a relevant and potentially valuable suggestion for the authors. Understanding how the proposed extension relates to the original method can help contextualize its contribution, identify potential improvements, and validate its effectiveness. While the suggestion is broad, it points in a direction that is likely to be helpful for the authors. Therefore, the review point has the potential to be helpful, even if it lacks specific details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the limitation of the experimental section and provides concrete suggestions for improvement. The reviewer mentions the small number of baselines and suggests adding more relevant works, which is a clear and actionable point.", "grounding_specificity_rationale": "The reviewer implies the experimental section is relevant but doesn't explicitly name it. However, the reviewer clearly specifies the missing baselines as a weakness, making the action concrete.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the experimental section and suggests adding more relevant baselines. While the claim itself might be debatable (is the lack of comparison a verifiable claim?), the suggestions for improvement are verifiable in the sense that the authors can verify the relevance of the suggested works.", "helpfulness_rationale": "The reviewer clearly identifies a valid weakness in the experimental section and provides concrete suggestions for improvement. The suggestion to add more baselines directly addresses a specific aspect of the work and is a constructive critique."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer suggests downplaying the distraction of the zeroshot version and density estimation. While this is a suggestion, it lacks a specific, actionable step. The reviewer doesn't provide a concrete 'how' to achieve this. The suggestion is present, but the explicitness and concreteness are lacking.", "grounding_specificity_rationale": "The reviewer's point is about the general 'main point' of the paper, which is the prototypes for fewshot learning. They do not explicitly identify a specific section, table, figure, or unique aspect of the paper. The reference to the 'main point' is broad and doesn't pinpoint a concrete location within the paper.", "verifiability_rationale": "The reviewer makes a claim that the zeroshot version and density estimation are distracting. This is a subjective opinion. While the reviewer states this as a fact ('I find'), the justification for this claim is not provided. There are no logical reasons, common knowledge, or external references to support this opinion. The claim is presented without sufficient backing.", "helpfulness_rationale": "The reviewer offers a suggestion to improve the presentation of the paper by downplaying certain aspects. While this could be helpful for the authors, the suggestion itself is vague and lacks a clear mechanism for implementation. The reviewer doesn't provide specific guidance on how the authors should adjust their focus or present their work. The suggestion is broad and doesn't offer concrete steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that 'Details around the filtering process used to create the Arabic climate change QA dataset are lacking.' This directly points to a missing piece of information that the authors need to understand to improve their draft. The reviewer is implicitly suggesting that the authors should look into the filtering process to assess the dataset quality. While the action is somewhat implicit, the reviewer clearly identifies the need for more information.", "grounding_specificity_rationale": "The review point mentions 'filtering process' and 'translation and filtering methodology' in the context of the 'Arabic climate change QA dataset'. While it doesn't explicitly name a specific section, table, or figure of the paper, it clearly refers to aspects of the dataset creation process. The reviewer is pointing to specific areas within the dataset that require further explanation. Therefore, while the grounding is somewhat weak in pinpointing a specific element, it is specific in terms of the process and the type of dataset.", "verifiability_rationale": "The review point states that 'More information on the translation and filtering methodology is needed to assess the dataset quality.' This is a claim that requires justification. The reviewer is stating that without understanding the methodology, the authors cannot properly evaluate the dataset. The verifiability is somewhat lacking because the reviewer doesn't provide specific examples or references to support this claim. The reasoning is present, but the evidence is not explicitly detailed.", "helpfulness_rationale": "The review point clearly identifies a significant gap in the information provided about the Arabic climate change QA dataset. The reviewer directly points out the lack of detail regarding the 'filtering process' and the need for information on 'translation and filtering methodology' to assess 'dataset quality'. This is a direct and helpful comment for the authors, as it highlights a crucial area that requires further clarification. The reviewer is empowering the authors to take action by identifying a specific need for more information."}
{"actionability_label": "1", "grounding_specificity_label": "3. 3", "verifiability_label": "1. 1", "helpfulness_label": "3. 3", "actionability_rationale": "The review point asks a question about the impact of specific experimental choices but does not explicitly state what needs to be done or how to interpret the results. The question is framed as a request for information rather than a directive to improve the draft.", "grounding_specificity_rationale": "The review point explicitly mentions a line in the paper (L170) and asks a specific question about the performance difference resulting from using different image sizes and ResNet variations. While the exact content of L170 is not specified, the intent is clear, and the question is directly related to the content mentioned. Therefore, it can be considered grounded. The question also specifies what needs to be addressed (performance difference).", "verifiability_rationale": "The review point is a question posed to the authors, asking for information about the performance difference. It does not contain a claim that requires verification or support. It is a request for data or analysis, not a statement that needs to be proven.", "helpfulness_rationale": "The review point asks a question directly relevant to understanding the impact of specific experimental choices. This information is valuable for the authors to assess the significance of their results and potentially adjust their approach. While it doesn't provide a direct solution, it points to a crucial area for further investigation, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment states the benefit of detailing the algorithm but does not provide explicit or concrete actions on how to achieve this. It suggests a desirable feature rather than a directive improvement.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper or element that requires improvement. It is a general suggestion about the value of detailing the algorithm.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a statement of opinion about the value of detailing the algorithm, not a critique or assertion that needs evidence.", "helpfulness_rationale": "The comment encourages the authors to improve their work by making it more understandable. While it doesn't provide specific, actionable steps, it offers a constructive suggestion that can be helpful in guiding the authors towards better communication of their method."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'it would have been interesting to see a runtime comparison at test time.' This action is concrete, as it specifies the type of comparison and the point at which it should be performed. There is no ambiguity about what needs to be done.", "grounding_specificity_rationale": "The review point refers to 'the paper mentions the possibility to use Chebyshev polynomials.' While it doesn't provide a specific section number, it clearly identifies a concept within the paper that the authors can likely identify. The suggestion to perform a 'runtime comparison at test time' is also specific, indicating a clear area for improvement. Therefore, the grounding is weakly grounded as the authors can infer the relevant part but don't have a precise reference. However, the specificity of the action is high as it clearly states what should be done and where.", "verifiability_rationale": "The review point contains a claim: 'it would have been interesting to see a runtime comparison at test time.' This claim is verifiable through implementation. While the suggestion itself doesn't require external references, the idea of a runtime comparison is a logical and testable suggestion. The reviewer is proposing a concrete experiment or analysis that can be carried out by the authors.", "helpfulness_rationale": "The review point is 5 as it provides a clear and actionable suggestion for the authors. It encourages them to explore a specific optimization (Chebyshev polynomials) and evaluate its impact through a runtime comparison. This is a constructive and positive feedback point that directly guides the authors towards a potential improvement in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desire for existing work on approximations and suggests a specific addition, making it 5.", "grounding_specificity_rationale": "The reviewer refers to a specific section of the paper and asks a very specific question about existing work, indicating full grounding and specificity.", "verifiability_rationale": "The reviewer asks a question and suggests a specific addition, implying a belief in the value of this information, but the actual verifiability of the missing work is not explicitly addressed, making it 3.", "helpfulness_rationale": "The reviewer directly addresses a point in the paper and offers a concrete suggestion with a potential solution, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The questions are present, but the request to explain BYOL is vague. The impact of the number of images is also not explicitly stated.", "grounding_specificity_rationale": "The reviewer does not explicitly state which part of the paper they are referring to when asking about the impact of the number of images. The request to explain BYOL is also not specific.", "verifiability_rationale": "The claim is a question about a model's behavior, which is not verifiable without further context or experimental details.", "helpfulness_rationale": "The questions are relevant to understanding model behavior, but the paper does not provide the requested information, limiting the helpfulness."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states an action: 'understand why the method works,' but does not provide a concrete step on how to achieve this. The request is for a *justification* or *explanation* rather than a direct instruction. Therefore, while an action is identified, it is not fully explicit or concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'L_pixel' component, indicating a strong grounding as they are directly referring to a specific part of the method. However, the reviewer does not specify *what* is wrong with it or *how* it contributes to the observed effects. The explanation of the component's role is missing, making it underspecific.", "verifiability_rationale": "The reviewer is not making a claim that needs to be verified. They are asking a question about the underlying reasons. While the lack of explanation could be seen as a potential weakness, the request itself doesn't present a verifiable statement. Therefore, verifiability is not directly applicable to this type of comment.", "helpfulness_rationale": "The reviewer's request is likely to be helpful for the authors as understanding the underlying reasons for the method's effectiveness is crucial for improvement. However, the request is vague and lacks specific guidance, making it less directly helpful than a concrete suggestion. It encourages the authors to *figure out* the reasons themselves, which can be a valuable learning experience but is less immediately actionable."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The binary classification label itself doesn't provide specific actions or suggestions on how to improve the draft. It only indicates whether something is an error or not, which is a very general and vague feedback. Authors need more specific guidance on what to fix and how to fix it, which a binary label cannot provide.", "grounding_specificity_rationale": "The binary classification label does not specify the type of error or the location of the problem within the draft. It treats all errors as a single category, which is a very weak grounding. For example, it doesn't specify if the error is a grammatical mistake, a logical fallacy, or a clarity issue. It also doesn't pinpoint the exact section or table where the error occurs. This lack of grounding makes it difficult for authors to understand the nature of the problem and how to address it.", "verifiability_rationale": "The binary classification label lacks sufficient justification or evidence to support the claim that something is an error. There is no clear reasoning or explanation provided to back up the classification. For example, if the label says 'Error', it doesn't explain *why* it's an error, what kind of error it is, or what specific issues need to be addressed. This lack of verifiability makes it difficult for authors to trust the feedback and understand the basis of the criticism.", "helpfulness_rationale": "The binary classification label is not particularly helpful for authors because it lacks specific details and actionable steps. It only tells the author that there is an error, but it doesn't provide any guidance on what the error is or how to fix it. This lack of helpfulness means authors are left without clear direction and may not be able to effectively improve their draft based on this feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests 'LLM evaluation' and points to a specific paper 2, indicating an intention to provide feedback. However, the request to 'compare SynTextBench metric with other metrics proposed in the literature' is vague and lacks specific details. The action is present, but the implementation is not fully concrete, making it 2.", "grounding_specificity_rationale": "The reviewer mentions 'LLM evaluation' and a specific paper 2. While the paper provides grounding, the reviewer doesn't explicitly state which section or unique element of the paper they are referring to. The mention of a specific paper grounds the general topic, but the lack of specificity within the paper makes it only weakly grounded. The request for comparison is also vague and doesn't pinpoint a specific aspect of the paper or metrics.", "verifiability_rationale": "The reviewer states that 'there has been a large amount of work on LLM evaluation' and that 'it would still be good to see how SynTextBench metric compares to the other metrics proposed in the literature.' This is a clear claim. The reviewer mentions a specific paper 2, which provides some evidence, but the request for a comparison is not a 5 statement on its own. The claim is present, but the supporting evidence is incomplete, making it 3.", "helpfulness_rationale": "The reviewer identifies a relevant area of research (LLM evaluation) and suggests a comparison of SynTextBench with other metrics. This is a valuable piece of feedback for researchers working in this area. However, the request for a comparison is vague and lacks specific details, making the feedback less actionable and potentially less helpful. The feedback is relevant, but the lack of specificity limits its helpfulness."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is vague and doesn't identify specific areas for improvement. 'Poor writing' and 'annotations are hard to follow' are general statements without concrete details on what needs to be changed. The authors can't infer any specific actions from this comment. The lack of specificity makes it difficult to apply the feedback. Therefore, it is 1.", "grounding_specificity_rationale": "The reviewer refers to 'the writing' and 'annotations' generally, without specifying a particular section, table, figure, or unique element of the paper. This lack of specificity makes it difficult for the authors to pinpoint the exact issue. The comment is 1 at all as it doesn't identify a specific part of the paper being addressed. Therefore, it is 1.", "verifiability_rationale": "The reviewer makes claims about the writing and annotations ('poor writing', 'hard to follow') but does not provide any specific examples, references, or logical reasoning to support these claims. The feedback is a diagnosis without evidence. Therefore, it is 1.", "helpfulness_rationale": "The feedback is a diagnosis of issues ('poor writing', 'hard to follow annotations') without offering any specific suggestions or guidance on how to improve. The authors are left wondering what exactly needs to be changed and how. This type of feedback is not constructive and does not empower the authors to make improvements. Therefore, it is not helpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggestion for the authors. While it points out a performance issue and asks a question, it doesn't directly tell the authors what to do or how to improve their method. The reviewer states a fact about the performance and then asks a question about the discrepancy in F1 scores. Neither of these elements directly instructs the authors on how to modify their draft. The reviewer points out that the method achieved SOTA in only 8 out of 14 metrics, which is a factual statement. The reviewer then asks why the method achieves the best overall F1 but not the best F1 in all single types. This is a question prompting further analysis, but it does not directly suggest an action or improvement for the authors.", "grounding_specificity_rationale": "The review point does not explicitly refer to any specific part of the paper (e.g., a method, a table, a figure). The reviewer is discussing the overall performance of the proposed method and comparing it to SOTA results and its performance on different evaluation metrics. The reviewer is asking a question about the discrepancy in F1 scores between overall and singletype evaluations. This question is about a general observation about the method's performance across different settings, not about a specific element within the paper. The reviewer's statement about the method's performance is a general observation about the method's overall effectiveness across different metrics, not a specific reference to a particular section or table. The reviewer's question is about a general trend in the evaluation results, not about a specific detail within the paper.", "verifiability_rationale": "The claim in the review point is that the proposed method achieves SOTA in only 8 out of 14 evaluation metrics. This is a claim that is supported by the data presented in Table 2. The reviewer also claims that the proposed method achieves the best overall F1 but not the best F1 in all single types. This claim is also supported by the data presented in Table 2. The reviewer provides evidence (the data in Table 2) to support their claims about the method's performance. The reviewer states a claim about the performance of the proposed method based on the data in Table 2. The reviewer also states a claim about the discrepancy in F1 scores between overall and singletype evaluations, again referencing the data in Table 2. The reviewer provides the data from Table 2 to support their claims about the method's performance.", "helpfulness_rationale": "The review point is informative and raises a valid question about the discrepancy in F1 scores. It points out a potential area for further investigation and encourages the authors to analyze their results more closely. While it doesn't directly provide a solution, it highlights a potential weakness or area for improvement in the proposed method. The reviewer points out a factual observation about the method's performance and then asks a question about the discrepancy in F1 scores. This question is about a general trend in the evaluation results. The reviewer's statement about the method's performance is a factual observation about the method's overall effectiveness across different metrics. The reviewer's question is about a general trend in the evaluation results, not about a specific detail within the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their expectation that including all reports would be easier than focusing on segments with one label. This is a clear and direct statement of their understanding and a suggestion for improvement. The reviewer identifies the action: 'include all reports' and provides a clear explanation of why this might be beneficial.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific type of ECG segments being discussed: 'ECG segments with one label assigned to them'. They also explain *why* this specific type is being considered, linking it to the expectation of easier associated reports. The reviewer accurately pinpoints the part of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim: 'I would expect that the associated reports would be significantly easier than including all reports.' They then provide a logical reasoning: 'This implies the original intention was likely to include all reports, regardless of the number of labels.' This reasoning is clear and directly supports the claim.", "helpfulness_rationale": "The reviewer directly addresses a potential limitation or a specific choice made by the authors (or the system) regarding how they handle ECG segments. They offer a suggestion: 'This implies the original intention was likely to include all reports, regardless of the number of labels.' This is a clear, actionable suggestion that is likely to be beneficial for the authors in understanding and working with the data."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The statement is explicit about the limitation of LLMs to generating instances with fewer than 8 variables. However, it does not provide any concrete actions or suggestions on how to address this limitation. The reviewer points out a constraint but doesn't offer a solution or direction for improvement.", "grounding_specificity_rationale": "The reviewer mentions the limitation of LLMs to generating instances with fewer than 8 variables. While they implicitly refer to the 'variables' as a specific aspect, they do not explicitly identify a specific section, table, or unique element of the paper where this limitation is discussed. The grounding is weak because the reviewer cannot confidently determine which part of the paper they are addressing beyond a general statement about the number of variables.", "verifiability_rationale": "The review point is a statement of a concern or limitation regarding the capabilities of LLMs. It does not present a claim that requires verification or support. There is no evidence or reasoning provided to back up this statement.", "helpfulness_rationale": "The review point raises a concern about the limitations of LLMs. While it highlights a potential issue, it does not offer any suggestions or insights on how to overcome this limitation. The feedback is a problem statement rather than a solutionoriented comment."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'display the performance' and provides concrete suggestions for improvement, such as 'involving some other baselines' and 'modifying the original SGM formulation'. These suggestions are directly actionable and provide clear directions for the authors to enhance their work.", "grounding_specificity_rationale": "The reviewer suggests improvements by involving 'some other baselines' and 'modifying the original SGM formulation'. While the general idea of involving more baselines is not specifically targeted at a particular part of the paper, the suggestions are quite concrete regarding the *type* of baselines and modifications. The reviewer does not explicitly identify a specific section or table in the paper that needs improvement, making the grounding somewhat weak. However, the suggestions are specific enough to guide the authors' efforts.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a suggestion for improvement rather than a statement that needs to be supported by evidence. Therefore, it does not fit into the verifiability scale.", "helpfulness_rationale": "The review point clearly identifies a weakness in the authors' approach (the lack of diverse baselines) and provides a constructive suggestion to address it. This actionable feedback is directly helpful for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding a conclusion and summary to the paper. While it indicates what needs to be done, it does not specify the exact location, format, or content of these elements. Therefore, while it points towards an improvement, the lack of concrete details makes it 3 but not fully actionable.", "grounding_specificity_rationale": "The review point refers to 'this paper' and suggests adding a 'conclusion' and 'summary' without specifying which section, table, figure, or unique aspect of the paper this refers to. It lacks a precise identification of the referenced part of the work.", "verifiability_rationale": "The review point is a suggestion for the authors to include a conclusion and summary, which is a descriptive statement rather than a claim requiring verification. It does not present an opinion, judgment, or suggestion that needs supporting evidence.", "helpfulness_rationale": "The review point suggests adding a conclusion and summary, which are common and valuable elements in academic papers. This provides the authors with a clear direction for improving their paper's structure and presentation. While it lacks specific details, it is a helpful suggestion overall."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a question about the relationship between the data distribution and the model's nonlinearity in a nonseparable case. While the question implicitly suggests a need for clarification and a missing explanation, it doesn't explicitly state an action or instruction for the authors. The authors would need to infer that the reviewer is asking how the model's nonlinearity allows it to handle the nonseparable data distribution.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 1' but doesn't explicitly point to a specific element within the figure, such as the data points, the decision boundary, or the model's output. They also don't explicitly define what they mean by 'nonseparable case' within the context of the figure. This makes the grounding of the referenced element weak.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question seeking understanding of a relationship between concepts. Therefore, there is X to evaluate for verifiability.", "helpfulness_rationale": "The reviewer's question is valuable for the authors as it seeks to clarify a potentially confusing aspect of the experiment. Understanding the relationship between the data distribution, model nonlinearity, and nonseparability can enhance their comprehension of the experimental setup and potentially inform improvements to their own models. While it doesn't directly provide a solution, it contributes to a deeper understanding."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out a difference between the standard sigmoid and the sigmoid used in URNNs, specifically mentioning the dependence on the maximum slope. They also suggest elaborating on Theorem 4.1, which is an implicit action. The reviewer provides a clear statement of what is different and why it matters.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Theorem 4.1' and also mentions the 'maximum slope' of the sigmoid. This clearly identifies the specific part of the paper being addressed, making the grounding fully grounded. The comment also specifies what is different (the dependence on max. slope) and what needs to be understood (Theorem 4.1).", "verifiability_rationale": "The reviewer makes a claim about a potential misunderstanding or a need for clarification regarding the sigmoid and the theorem. This claim is supported by logical reasoning, explaining why the difference in the sigmoid is important and suggesting explaining the theorem in the context of convergence.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors. They point out a specific mathematical difference and offer a concrete direction for improvement by elaborating on Theorem 4.1 and its connection to the convergence behavior of RNNs. This is a 5 comment as it directly addresses a potential point of confusion and guides the authors towards a deeper understanding."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review points out a factual observation about the common practice of reporting results on a single test set. It does not explicitly instruct the authors on what action to take.", "grounding_specificity_rationale": "The review refers to 'experiments' and 'results' generally, without specifying a particular section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The review makes a factual statement about the reporting of results. It does not make a claim that requires verification.", "helpfulness_rationale": "The review highlights a potential limitation of the experimental setup and suggests a more robust approach. While it doesn't tell the authors how to implement the suggestion, it raises a valid concern about the reliability of the results."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The comment 'force the neural network to memorize them' is somewhat vague. While it implies an action, it doesn't specify *how* to achieve this memorization or what constitutes a 'critical point' in this context. The lack of concrete details makes it 3 but not fully actionable.", "grounding_specificity_rationale": "The comment 'force the neural network to memorize them' is not strongly grounded. While it might implicitly refer to the neural network's behavior, it doesn't explicitly point to a specific section, table, figure, or unique aspect of the paper. The reviewer then mentions 'TopoNet 24' which could be considered grounded, but the initial statement lacks this specificity.", "verifiability_rationale": "The comment contains a claim ('force the neural network to memorize them') but it is not 5. The reviewer immediately qualifies it with 'in my understanding, the neural network does not memorize an exact \"critical point\" as such in TopoNet 24'. This qualification weakens the verifiability as it introduces a counterargument and relies on the reviewer's understanding rather than a universally accepted fact within the paper.", "helpfulness_rationale": "The review point is not 5. While it identifies a potential misunderstanding regarding the neural network's behavior, it lacks concrete, actionable feedback on how to improve the method or the writing. The qualification 'I would tone down this statement' further reduces its impact as it doesn't offer a specific alternative or improvement. The minor points about the method section and grammatical errors are also negative aspects."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "Somewhat Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a lack of clarity and asks a specific question about implementation details, making the action clear and concrete.", "grounding_specificity_rationale": "The reviewer is addressing a general concern about clarity and is asking for information related to a specific implementation (line 211) without explicitly linking it to a specific section or element of the authors' work.", "verifiability_rationale": "The review point is a question asking for information about a specific implementation and its accuracy, not a statement making a claim or assertion.", "helpfulness_rationale": "The review point is a question seeking specific implementation details and accuracy information, which could be helpful, but it doesn't directly provide actionable advice or solutions to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the need for citations to recent MARL work, which is a direct action. However, it doesn't specify *which* papers or sections to cite, making it somewhat vague in terms of concrete action.", "grounding_specificity_rationale": "The comment identifies the *area* of missing citations (recent papers on selfplay and population play) which allows for grounding. However, it doesn't specify *which* section or table within that area needs citation, making it underspecific.", "verifiability_rationale": "The comment contains a claim (the paper lacks citations) and provides *reasons* (exploration and coordination) for this claim, which can be considered implicit evidence. While it doesn't cite specific papers, the examples provided offer a basis for verification.", "helpfulness_rationale": "The comment directly points out a clear weakness in the paper (lack of relevant citations) and provides a clear direction for improvement (adding citations). While it doesn't specify *which* papers, it identifies the *area* where citations are needed, making it helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action (comparing with other selfsupervised learning methods) but lacks concrete details on how to implement this comparison, such as specific methods to consider or evaluation metrics to use. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The comment explicitly mentions 'selfsupervised learning methods' and 'contrastive learning,' providing a clear reference point within the paper. It is obvious to the authors which part of the paper this comment addresses. However, the comment does not specify what needs to be addressed in this part (i.e., why the current comparison is insufficient or what the limitations of contrastive learning are in the context of the author's work).", "verifiability_rationale": "The comment contains a claim ('It would be better to compare...') and provides some justification by stating that the comparison is 'based on contrastive learning.' However, it lacks specific references to external works or detailed reasoning about why other selfsupervised learning methods might be more suitable. The evidence is somewhat vague and lacks depth.", "helpfulness_rationale": "The comment identifies a potential improvement area (comparing with other selfsupervised learning methods) and provides a general suggestion. While relevant, it lacks specific details on *why* this comparison is beneficial or *how* the authors should go about it. The suggestion is somewhat vague and doesn't offer concrete guidance, making it less helpful than a suggestion with more detail."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The statement about Megatron's performance being 'overrated' is a direct criticism, but it lacks specific details on what is meant by 'overrated' and how it compares to other models. The question about the impact of switching BPE vocabulary is framed as a question rather than a clear action item, making it less actionable. While the reviewer points out a potential issue, the lack of concrete suggestions or specific section references makes it somewhat difficult to act upon immediately.", "grounding_specificity_rationale": "The comparison with other models like RoBERTa, ELECTRA, and DeBERTa is general and doesn't specify a particular section, table, or unique aspect of the paper being addressed. The question about BPE vocabulary is also vague, referring to 'vocabulary' without specifying which part of the paper or what specific issue is being questioned. The grounding is weak because the reviewer doesn't clearly identify the specific element being discussed.", "verifiability_rationale": "The statement that Megatron's performance is 'overrated' is a claim, but it lacks supporting evidence or justification within the review point itself. The question about the impact of switching BPE vocabulary is more of a request for clarification than a verifiable claim. The verifiability is low because the reviewer's opinion is not backed by specific reasoning or references.", "helpfulness_rationale": "The review point raises a valid concern about the overstatement of Megatron's performance and asks a relevant question about BPE vocabulary. However, the critique is somewhat general, and the question is framed as a query rather than a clear suggestion for improvement. The helpfulness is moderate because the reviewer identifies a potential issue and asks a pertinent question, but lacks concrete guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the weakness 'lack of meaningful baselines' and suggests a concrete action to address it: 'comparing with a chainofthought prompting approach'. This directly points to an actionable recommendation.", "grounding_specificity_rationale": "The review point refers to 'various model criticism techniques' mentioned in Section 2. However, it does not explicitly name a specific technique or location in the paper where this lack of baselines is an issue. The suggestion to compare with 'chainofthought prompting' is a general recommendation, not a specific fix within a defined section.", "verifiability_rationale": "The review point identifies the weakness 'lack of meaningful baselines' and suggests a solution 'comparing with a chainofthought prompting approach'. However, it does not explicitly claim that this comparison is a valid or wellsupported suggestion. The focus is on identifying the problem rather than validating the proposed solution.", "helpfulness_rationale": "The review point clearly identifies a weakness ('lack of meaningful baselines') and offers a specific, actionable suggestion ('comparing with a chainofthought prompting approach'). The reviewer's language is direct and constructive, providing a clear path for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point directly asks two specific questions about the training process and its implications. The first question identifies an action (pretraining on the entire dataset) and asks for details on how it was done. The second question infers an action (generalization without labels) and asks for an assessment of its potential. The questions are clear and point to specific aspects of the method. While the second question is more of a deduction, it still implies an action and asks for an assessment, making it 3.", "grounding_specificity_rationale": "The review point explicitly mentions 'pretrain the cardiac signal representation learning model' and 'the entire dataset', which are specific parts of the paper. The reviewer then asks about the generalization of the model 'without the associated labels'. This demonstrates strong grounding as the reviewer can accurately pinpoint the section and table (if applicable) being discussed and identify the specific issue related to generalization without labels. The questions are directly linked to the method and its potential limitations.", "verifiability_rationale": "The review point contains a claim: 'How well does this generalize to setting where you don\u2019t have the associated labels?' This claim is asking for an assessment or evaluation of a potential limitation. While the claim itself isn't explicitly supported by a reference, the reviewer is pointing to a logical consequence of pretraining on the entire dataset, which could be argued as verifiable through common knowledge of potential overfitting or domain shift issues. The reviewer is making a logical deduction about a potential problem.", "helpfulness_rationale": "The review point directly addresses a key methodological choice (pretraining on the entire dataset) and raises a relevant concern about the model's generalization ability in a labelfree setting. This is a valuable piece of feedback for the authors as it highlights a potential limitation of their approach and encourages them to consider the implications of their training data. The questions are clear and directly related to the method's practical application. While the reviewer doesn't provide a definitive answer, the questions themselves are actionable and informative."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point states a fact about potential hardware/software dependencies but does not provide explicit instructions or actions for the authors to take. It highlights a limitation but doesn't guide the authors on how to address it.", "grounding_specificity_rationale": "The review point is a general observation about the potential for hardware/software dependencies in design decisions. It does not specify which part of the paper or element is affected, making it 1. It also does not detail what needs to be addressed, so it is not specific.", "verifiability_rationale": "The review point is a statement of observation, not a claim that requires verification. It does not contain a claim that needs supporting evidence or references.", "helpfulness_rationale": "The review point identifies a potential area for improvement (considering hardware/software) but does not provide specific, actionable advice or identify a concrete problem that the authors need to solve. It is a suggestion for future consideration, not a direct improvement."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states \"No new evaluation metrics are proposed. Only existing evaluation metrics are proposed.\" This is a clear, direct statement of what the reviewer is suggesting. The action is to not propose new metrics, and the scope is \"evaluation metrics\" which is specific enough to understand the area of concern. The language is direct and leaves no ambiguity about what needs to be done.", "grounding_specificity_rationale": "The comment explicitly mentions \"evaluation metrics.\" This is a specific technical term within the context of research evaluation. While it doesn't pinpoint a *section* or *table*, it clearly identifies the area. The authors can infer the specific aspect being addressed as it's a wellknown concept in the field. The comment specifies what needs to be addressed in this part, which is the limitation of relying solely on existing metrics.", "verifiability_rationale": "The comment contains a claim: \"No new evaluation metrics are proposed. Only existing evaluation metrics are proposed.\" This claim is supported by common knowledge within the research community. The implications are generally accepted. The reasoning is clear and precise. The evidence is logical and wellunderstood.", "helpfulness_rationale": "The comment identifies a potential area for improvement in experimental analysis by suggesting the focus should be on existing metrics rather than proposing new ones. However, it doesn't offer a constructive suggestion for how to address this limitation or what specific improvements could be made. It's a statement of a problem rather than a solution or a direction for improvement. The authors might need to seek further clarification or explore alternative approaches to overcome this limitation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific issue (abuse of notation) and suggests a potential improvement (using different notation). While the reviewer doesn't explicitly state the *exact* new notation, they clearly identify the conflicting uses of 'K', which implies a concrete action. The suggestion to use different notation indicates a clear direction for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly identifies the *specific* issue: the overloaded notation 'K'. They point to specific line numbers (L166 and L176) as evidence of where this abuse occurs. This demonstrates a clear understanding of the location and nature of the problem, making the comment highly grounded. The reviewer also explains *why* this is a problem (abuse) and *what* the likely consequence is (potential confusion).", "verifiability_rationale": "The reviewer makes a claim: 'The notation K is abused too...'. This is a subjective opinion about a potential issue. The reviewer then provides *support* for this claim by suggesting that this abuse could lead to confusion for the reader. While the reviewer doesn't provide a citation, the reasoning is logical and inferential, linking the overloaded notation to a potential problem. The reviewer infers the consequence (confusion) from the identified issue (abuse).", "helpfulness_rationale": "The reviewer's point is clear and directly addresses a potential source of confusion for the authors (or readers). It highlights a specific, actionable issue (abuse of notation) and suggests a potential solution (using different notation). While the reviewer doesn't explicitly define the new notation, the point is likely to be helpful for the authors if they are struggling with the clarity of the notation. The suggestion is constructive and points towards a concrete improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitation of the weak recovery problem being primarily of theoretical interest and the potential lack of usefulness of the AMP algorithm for nonGaussian problems. This directly identifies an action the authors should take: consider the theoretical nature and practical limitations of the AMP algorithm, especially for nonGaussian data. The action is clearly defined and actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the AMP algorithm' and describes the weak recovery problem as 'primarily of theoretical interest.' This strong explicit grounding clearly identifies the specific aspect of the paper being addressed and the nature of the issue. The algorithm is named directly, and the problem is linked to its theoretical nature.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the AMP algorithm for nonGaussian problems. However, this claim is not supported by any evidence, examples, or references within the review point itself. There is no logical reasoning or external references provided to back up the assertion that the AMP algorithm might not be useful for nonGaussian problems. The justification is missing.", "helpfulness_rationale": "The reviewer's comment is primarily critical, pointing out a potential limitation in the practical impact of the work. While it encourages the authors to consider the theoretical nature of their problem, it doesn't offer a direct solution or alternative approach. The feedback is primarily critical and doesn't offer a constructive path forward beyond considering the theoretical aspects. There are no specific suggestions for improvement or alternative methods provided."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests that the authors should clarify their conceptual framework regarding the connection to human cognition. While they don't explicitly point to a specific line number, they strongly imply that the current framing is unclear and needs improvement. The reviewer's suggestion to seek citations for comparison against 'previously appreciated' mechanisms further indicates a lack of clarity in the current understanding or justification of the chosen approach. Therefore, the reviewer is suggesting an actionable improvement, but it's not a direct instruction to modify a specific part of the paper.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly directed at a specific section, table, or figure of the paper. They are commenting on the overall conceptual framing and the relevance of incorporating human cognition. While they identify a potential area for improvement, they do not pinpoint the exact location within the paper that needs clarification. Therefore, the grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer makes a claim: 'Unclear whether bringing connections to human cognition makes sense' and 'It would be fairly surprising if any behavioral economist trying to study this problem would ignore either of these things and needs more citation for comparison against 'previously appreciated'.' The reviewer provides a reason for this claim ('the authors themselves state that the problem is fairly reductionist and does not allow for mechanisms like bargaining and negotiation that humans use') and suggests a source of comparison ('behavioral economists'). However, the reviewer does not provide specific examples of missing citations or a detailed explanation of why the cited work is surprising. The claim is present, and there's a basis for verification, but the lack of specific examples makes it somewhat underjustified. Therefore, the claim is verifiable, but not 5.", "helpfulness_rationale": "The reviewer's feedback is constructive and points out a potential area for improvement in the conceptual framing of the paper. They suggest that the authors should clarify their understanding of the interaction between cognitively basic adaptation mechanisms and the structure of the CPR itself, and provide more context by citing relevant work from behavioral economics. While the feedback is helpful, it is somewhat general and does not pinpoint specific sections or issues within the paper that need addressing. Therefore, the feedback is helpful but could be more specific to elicit more actionable suggestions from the authors."}
{"actionability_label": "4", "grounding_specificity_label": "Mostly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the absence of comparison to simple feature acquisition baselines as a weakness. While it doesn't provide concrete suggestions for what baseline to use, it clearly identifies a specific area where the paper is lacking. This makes the comment actionable in the sense that it points towards a concrete improvement.", "grounding_specificity_rationale": "The review point identifies the lack of comparison to simple feature acquisition baselines as a weakness. While it doesn't explicitly point to a specific section, table, or figure, it clearly specifies the type of baseline that is missing. This allows the reviewer to understand what kind of improvement is being suggested, making the comment somewhat grounded and specific in its focus.", "verifiability_rationale": "The review point makes a claim that the paper lacks a specific type of comparison, which requires justification. The reviewer argues that this makes the effectiveness of the proposed approach unclear. While the reviewer doesn't provide external references to support this claim, they do provide a logical argument for why this comparison is important. This makes the claim 3.", "helpfulness_rationale": "The review point identifies a clear weakness in the paper: the lack of comparison to simple feature acquisition baselines. This is a constructive criticism aimed at improving the paper. While it doesn't tell the authors exactly what baseline to use, it points towards a specific area for improvement, making the feedback 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The paper mentions 'separate embedding and addition with positional encoding' but does not explicitly state how these embeddings are combined or fed into the CSCM. The reviewer is asking for clarification on this specific action, which is not explicitly detailed in the paper.", "grounding_specificity_rationale": "The paper mentions 'separate embedding and addition with positional encoding' but does not explicitly state how the embeddings are combined and fed into the CSCM. While the individual components are mentioned, the exact process is not clearly defined, making it less grounded. The reviewer is asking for clarification on how the unique aspect (the combination) is identified, which is a weak grounding.", "verifiability_rationale": "The paper mentions 'separate embedding and addition with positional encoding' but lacks details on how the embeddings are combined and fed into the CSCM. While a claim is made about the combination, the supporting evidence (reasoning, common knowledge, or external references) is missing, making it 1. The reviewer is pointing out a gap in the provided information.", "helpfulness_rationale": "The review points to a specific technical detail (how embeddings are combined and fed into CSCM) that is crucial for understanding and implementing the method. While the paper mentions related concepts, the lack of clarity on this specific action makes the review helpful in identifying a gap in the explanation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point poses a question about the expressiveness of 'fast SMP' compared to 'SMP' and suggests a desire for more discussion on different architectures. While it implicitly suggests that 'fast SMP' might be less expressive, it doesn't explicitly state this as an actionable item for the authors to implement or analyze. The reviewer is prompting for a comparison and a deeper exploration of architectural choices.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or the authors' draft. It is a general question about the expressiveness of different architectures. Therefore, it is 1 in a specific section, table, figure, or unique aspect of the paper. The reviewer is making a general comment about the field rather than directly addressing a specific weakness in the authors' work.", "verifiability_rationale": "The review point raises a question about the expressiveness of 'fast SMP' compared to 'SMP'. While it suggests a desire for more discussion, it doesn't provide a claim that needs to be verified with evidence or references. It's a question posed to the reviewers, not a statement that the authors can immediately verify or refute.", "helpfulness_rationale": "The review point directly asks a question about a specific technical aspect ('fast SMP' vs. 'SMP') and encourages a discussion on the power of different architectures. This is a highly valuable piece of feedback for the authors as it points them towards a specific area for improvement and frames it for the reviewers. It provides a clear direction for further exploration and analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential issue with the experimental setup by suggesting evaluating across different trainvaltest splits instead of just different initialization seeds. While it doesn't explicitly state an action to be taken, the suggestion implies a desire for more robust results. The action is implicit.", "grounding_specificity_rationale": "The review point suggests evaluating across different trainvaltest splits. It doesn't explicitly state which part of the paper this refers to (e.g., a specific section or table). The mention of 'splits' is general, and the paper doesn't specify the unique element being addressed. Therefore, the grounding is weak.", "verifiability_rationale": "The review point states that evaluating across different trainvaltest splits would lead to more reliable results. This is a logical and verifiable claim. The reasoning is based on the understanding that different data splits can highlight variations in performance and provide a more stable evaluation. The claim is supported by logical reasoning.", "helpfulness_rationale": "The review point identifies a potential limitation in the experimental methodology (reliance on a single initialization seed) and suggests a more robust approach (evaluating across different trainvaltest splits). This provides the authors with a concrete suggestion for improvement and encourages them to think critically about their experimental design. While it doesn't provide a stepbystep solution, it offers a valuable insight that can lead to better results. The feedback is directly relevant to improving the paper's evaluation."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The phrase 'can be combined together' is an explicit instruction. It tells the author what to do. It's also concrete because it specifies *where* to make the change (the first two bullets of the introduction) and *what* to do (combine them).", "grounding_specificity_rationale": "The comment explicitly mentions 'the first two bullets about contributions (at the end of the intro)'. This is a clear and accurate reference to a specific part of the paper. While it doesn't detail *why* they should be combined, it clearly identifies the *what*. The parentheses help in identifying the specific section.", "verifiability_rationale": "The review point is a suggestion for improvement, not a declarative statement containing a claim. There's no 'yes' or 'no' question, no assertion of a problem, and no recommendation based on external evidence.", "helpfulness_rationale": "The suggestion to combine the bullets is actionable and directly addresses a practical formatting issue. It's a concrete piece of advice that the authors can easily implement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer states the need to refer to 'more recent trends in the vision community' to improve the algorithm. While this is an action, it is not explicitly defined or how to implement it.", "grounding_specificity_rationale": "The reviewer mentions the need to refer to 'more recent trends in the vision community' but does not specify which part of the paper this improvement should address or why it is lacking in the context of these trends.", "verifiability_rationale": "The reviewer makes a claim about the importance of showing closed contours and robustness to weak boundaries and provides a reason (referencing recent trends). However, the specific trends are missing, making it not 5.", "helpfulness_rationale": "The reviewer provides a clear direction for improvement (referencing recent vision work) and highlights a specific area of weakness (robustness to weak boundaries). This is a good starting point for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the perceived lack of novelty and the nature of the work (application of DeCorr). This is explicit.", "grounding_specificity_rationale": "The reviewer's statement is somewhat vague. They mention 'limited novelty,' 'application domain,' and 'overcorrelation in recommender systems,' but they don't explicitly point to a specific section, table, figure, or unique aspect of their own paper being addressed. While the general topic is relevant, the connection isn't sharply defined.", "verifiability_rationale": "The reviewer presents a claim ('Limited novelty') that is supported by some reasoning, but lacks the detailed, specific evidence *within the paper itself* to support the claim of limited novelty. The reviewer is offering an *opinion* about the paper's contribution.", "helpfulness_rationale": "The reviewer's point is that the paper doesn't provide enough new insights or actionable suggestions for the authors to improve their work. They suggest the paper is an 'application' and misses the 'unique challenges' of overcorrelation in recommender systems. This points to a potential weakness in the paper's contribution and offers a valid concern for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the importance of unsupervised pretraining and suggests its emphasis. The action is to emphasize, which is a clear and direct instruction for the authors. The reviewer also points out that unsupervised pretraining is 'much more important than other modules presented in this paper', which provides a clear direction for improvement.", "grounding_specificity_rationale": "The comment explicitly mentions 'unsupervised pretraining' and implicitly refers to its lack of detailed discussion in the main paper. While it doesn't specify a unique element within unsupervised pretraining (e.g., a specific algorithm or dataset), it clearly identifies the area and the nature of the missing detail. This can be considered partially grounded as the section, table, figure, or unique aspect being addressed is implied, but not explicitly named. The comment specifies what needs to be addressed in this part (detailed discussion).", "verifiability_rationale": "The comment contains a claim: 'there is no detailed discussion on the unsupervised pretraining in the main paper, which might be a problem.' The reviewer provides some justification by stating that the experimental results (Table 4) indicate its importance and that the ablation study (Table 5) further highlights its significance. While the justification is present, it could be more robust by providing specific examples of where the discussion is lacking or suggesting concrete ways to improve the discussion. The claim is supported but lacks key elements (e.g., examples, references).", "helpfulness_rationale": "The comment clearly identifies a weakness in the paper (lack of detailed discussion on unsupervised pretraining) and provides a constructive suggestion for improvement (emphasize it in the main paper). The reviewer also highlights the importance of unsupervised pretraining based on experimental results, making the suggestion highly relevant and actionable for the authors. The comment is specific about the area of improvement and the nature of the deficiency."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks a question ('How would we choose which ELM to pick?') and raises a concern ('This seems like a drawback...'). This directly points to a practical decision the authors need to make. While the action itself (choosing an ELM) is not performed, the suggestion to survey or benchmark is a concrete action based on the information provided. The concern about accuracy in the pipeline, though not an explicit action, is a suggestion for improvement that could guide the authors' choice.", "grounding_specificity_rationale": "The reviewer asks a general question about choosing an ELM based on gender. While they mention 'ELM' and 'gender,' they don't specify a particular ELM or a specific section of the paper. The mention of 'vocal traits' is also somewhat general. The reviewer doesn't explicitly identify a specific part of the paper they are referring to.", "verifiability_rationale": "The reviewer states a claim ('This seems like a drawback...') about the accuracy of gender detection models in a pipeline. However, this claim is not supported by any evidence or reasoning within the review point itself. The reviewer doesn't provide any references or logical arguments to back up this assertion.", "helpfulness_rationale": "The review point is helpful as it directly addresses a practical decision the authors need to make (choosing an ELM). The suggestion to survey or benchmark is a concrete action based on the information provided. However, the concern about accuracy in the pipeline, while a valid point, is presented as a general observation rather than a specific, actionable suggestion. The lack of specific information about ELMs and the unsupported claim about accuracy make the helpfulness somewhat limited."}
{"actionability_label": "BA", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests having 'some intuition of the proof of Theorem 1' which is an implicit action. However, the reviewer also asks specific questions about the relationship between the invertible function $f^*$ and the fixed distribution $P^*$. These questions are explicit actions aimed at clarifying these aspects for the authors. While the initial suggestion is 2, the subsequent questions are fully actionable.", "grounding_specificity_rationale": "The reviewer explicitly states 'Also, the invertible function $f^*$ would depend on the fixed $P^*$' and asks specific questions about this relationship. This clearly grounds the discussion in the theoretical framework and asks for clarification on a specific aspect.", "verifiability_rationale": "The reviewer makes a factual statement 'Does certain distributions $P^*$ make it easier to determine $f^*$' which is verifiable. They also ask questions 'In practice, how should you determine which $P^*$ to fix?' which can be answered through further investigation or by asking for clarification from the authors.", "helpfulness_rationale": "The review point provides specific questions that directly address potential areas of confusion for the authors regarding the theoretical underpinnings. While the initial suggestion about intuition is less direct, the subsequent questions are very helpful in guiding the authors. The questions are specific and point to actionable steps they can take to better understand the material."}
{"actionability_label": "2", "grounding_specificity_label": "4: 5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the difference between two equations and their terms. It does not explicitly or implicitly tell the authors what to do or how to fix the issue. The action is implied but not clearly stated or actionable.", "grounding_specificity_rationale": "The review point refers to 'Eqs. (7) and (10)' and their terms 'X' and 'H^(1)'. This provides a clear reference to specific parts of the paper and explicitly mentions the terms being discussed. The grounding is literal and specific.", "verifiability_rationale": "The review point is a question asking for clarification, not a claim that needs verification. There is no assertion of correctness or missing information. It's a request for understanding.", "helpfulness_rationale": "The review point is a question seeking clarification about the relationship between two equations and their terms. While it is relevant to the authors' work and could help them understand the material better, it does not directly provide a solution or actionable steps. It's a valid inquiry that could lead to improved understanding but doesn't immediately empower the authors to fix any issues."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out the 'main concern with the paper is the applicability of the model to realworld diffusion process'. While this identifies a problem, it doesn't explicitly state how the authors should address this concern. The reviewer suggests 'providing empirical evidence', but doesn't specify the steps the authors should take to do so. Therefore, the action is implied but not explicitly stated, making it 2.", "grounding_specificity_rationale": "The reviewer mentions 'the main concern with the paper is the applicability of the model to realworld diffusion process'. While they identify a specific area of concern, they don't pinpoint a specific part of the paper (e.g., a section, table, figure) that is affected by this lack of applicability. The concern is general to the model's applicability, not a specific instance within the paper. Therefore, the grounding is present but not fully specific, making it 2.", "verifiability_rationale": "The reviewer states a 'claim' about the 'main concern with the paper is the applicability of the model to realworld diffusion process'. However, within the review point itself, there is no evidence provided to support this claim. The reviewer suggests 'providing empirical evidence', but this is a suggestion for improvement, not a verifiable statement within the review. Therefore, the claim is stated but not supported, making it 1.", "helpfulness_rationale": "The review identifies a relevant and important area for improvement, highlighting the lack of realworld applicability of the model. However, it does not provide specific, actionable steps for the authors to take to address this concern. The reviewer suggests 'providing empirical evidence', but this is a general suggestion without concrete guidance on how the authors should go about it. Therefore, the review points out a problem but doesn't offer clear guidance on how to solve it, making it 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the perceived limitation of the paper's novelty and provides a specific alternative (factorizing M_v into D and slicing Phi_v) as the incremental contribution. This directly identifies an actionable area for the authors to address.", "grounding_specificity_rationale": "The reviewer mentions 'methodology aspect,' 'novelty of paper,' 'ENCODE part,' and '10' (presumably a citation). While the ENCODE part is somewhat general, the reviewer doesn't explicitly identify a specific section, table, figure, or unique element within the paper being addressed. The citation doesn't directly link to a specific part of the reviewed paper.", "verifiability_rationale": "The review point contains a claim ('the novelty of paper appears to be rather limited') and provides some justification by stating that the ENCODE part is already proposed in 10 and the incremental contribution lies in the decomposition part. This provides some support for the claim, making it 3.", "helpfulness_rationale": "The review point is helpful in identifying a potential area for improvement by suggesting a specific alternative to the authors' current approach. While it doesn't demand a complete overhaul, it provides a concrete point of reference for the authors to consider."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks 'What is the domain of the inputs?' and provides a specific example ('they are lying in the same sphere') as a potential issue. This is an explicit action and a concrete suggestion.", "grounding_specificity_rationale": "The reviewer asks a general question about the 'domain of the inputs' without explicitly pointing to a specific section, table, or figure in the paper. While they imply it relates to the input data, the connection is not explicitly stated. The suggestion 'lying in the same sphere' is vague and doesn't pinpoint the exact issue within that domain.", "verifiability_rationale": "The reviewer poses a question ('What is the domain of the inputs?') and offers a potential explanation ('they are lying in the same sphere... not mentioned in the paper'). This can be interpreted as a claim or suggestion. However, the claim that the domain is 'the same sphere' and that it's 'not mentioned in the paper' lacks specific evidence or references to support it.", "helpfulness_rationale": "The reviewer points out a potential redundancy in the input data by suggesting they are in the same domain. While this raises a valid concern about the input space, it doesn't directly provide actionable steps for the authors beyond identifying the problem. It encourages the authors to consider the implications of their input choices but doesn't offer concrete solutions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks for a performance comparison with the CLN algorithm proposed in paper A. This is a clear and direct request for action.", "grounding_specificity_rationale": "The reviewer refers to 'A' and 'CLN (region proposal generation algorithm)' as specific references. This demonstrates strong grounding as the paper and method are explicitly mentioned. The request is also specific to 'performance comparison', indicating a clear focus on a particular aspect of the method.", "verifiability_rationale": "The reviewer states a suggestion ('What's about performance comparison...') which constitutes a claim. However, the review point does not provide any logical reasoning, examples, or references to support why this comparison is needed or beneficial. The request is presented without justification.", "helpfulness_rationale": "The reviewer directly points to a potential weakness in paper A (the lack of performance comparison) and suggests a concrete improvement (comparing performance). This is a focused and actionable suggestion that directly relates to the content of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem of 'equationdriven and notation, especially in chapter 3, quite convoluted and hard to follow' and suggests a concrete action: 'an illustrative figure of the key concepts in section 3 would have been helpful'. This clearly indicates an explicit and concrete action that the authors can take to improve their draft.", "grounding_specificity_rationale": "The review point explicitly mentions 'chapter 3' when suggesting an 'illustrative figure of the key concepts in section 3 would have been helpful'. This precise mention of a section indicates that the authors can accurately identify the part of the paper being addressed, which aligns with the definition of 'full grounding'. The suggestion is also specific to this section.", "verifiability_rationale": "The review point makes a statement about the 'presentation being at times too equationdriven and the notation ... quite convoluted and hard to follow'. This statement describes a verifiable state of affairs regarding the clarity of the presentation. While the suggestion to use an 'illustrative figure' is a proposed solution, the underlying observation about the difficulty of the current presentation is verifiable.", "helpfulness_rationale": "The review point clearly identifies a weakness in the presentation ('equationdriven and notation ... quite convoluted and hard to follow') and provides a direct suggestion for improvement ('an illustrative figure of the key concepts in section 3 would have been helpful'). This type of feedback is 5 and directly addresses a likely bottleneck for authors when working with mathematical content."}
{"actionability_label": "5", "grounding_specificity_label": "Highly Grounded", "verifiability_label": "Highly Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential conflict between the definition of 'minimal conditional dependence' and Equation (7). The definition states that a set of variables Z is minimally conditionally dependent on W if for every proper subset Z' of Z, x and y are independent given W U Z'. The reviewer proposes that if Z' is the empty set, then x and y should be independent given W. However, Equation (7) suggests they are not. This is a clear instance of an implicit action that needs to be inferred. The reviewer is suggesting that the authors should understand that if Z' is the empty set, then Z is also the empty set, and the condition applies to the empty set itself. This requires a level of inference that is not explicitly stated in the definition.", "grounding_specificity_rationale": "The reviewer directly addresses the definition of 'minimal conditional dependence' and Equation (7). They clearly identify the specific parts of the paper being discussed. The reviewer states, 'Taking Z' in this definition to be the empty set, we should have that x and y are independent given W, but Eq. (7) says otherwise.' This demonstrates a precise identification of the relevant concepts and a clear articulation of the issue.", "verifiability_rationale": "The reviewer presents a claim: 'Second rule in Lemma 2, i.e., Eq (7) and the definition of minimal conditional dependence seem to be conflicting.' This is a clear statement of a claim requiring verification. The reviewer provides a specific scenario (Z' being the empty set) to illustrate the potential conflict. The claim is verifiable by examining the definitions and Equation (7) in the original paper. The reviewer has provided sufficient information to assess the verifiability of their claim.", "helpfulness_rationale": "The reviewer's comment is 5 because it directly points out a potential inconsistency in the paper's definitions and equations. By highlighting the conflict between the definition of 'minimal conditional dependence' and Equation (7) when Z' is the empty set, the reviewer provides a concrete example that could help the authors understand and correct a potential flaw in the theoretical framework. The reviewer's suggestion to consider Z' as the empty set is a clear and actionable point for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly mentions 'subscripts' and suggests 'enhanced readability and aesthetic appeal' as areas for improvement. While the exact action isn't fully explicit, the reviewer clearly identifies the problematic element and the desired outcome, making it actionable. The reviewer could reasonably infer the need for clearer labeling or formatting of the subscripts to improve readability.", "grounding_specificity_rationale": "The reviewer identifies the issue specifically within 'figure3' and then narrows it down to the 'subscripts'. This demonstrates a clear understanding of the location of the problem within the paper. The reviewer also specifies 'subscripts' as the *exact* element needing improvement, which is highly specific.", "verifiability_rationale": "The review point does not contain a claim or assertion. It simply states a suggestion for improvement. Therefore, it does not meet the criteria for verifiability, which requires a claim to be supported by evidence or reasoning. The output 'X' indicates that X is present.", "helpfulness_rationale": "The review point identifies a specific visual element ('subscripts') within a figure and suggests a general improvement ('enhanced readability and aesthetic appeal'). While the exact *type* of enhancement isn't specified, the reviewer provides a clear direction for the authors to follow. This level of specificity and direction is generally helpful as it gives the authors a concrete target for their attention, even if the exact implementation isn't defined."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "6", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly states \"W1. The authors have clearly reduced whitespace throughout the paper...\" This indicates an explicit action being taken. However, the comment stops there. While it identifies a change that needs to be addressed, it doesn't provide specific guidance on how the authors should go about reducing the whitespace. It points to a general area for improvement but lacks concrete steps.", "grounding_specificity_rationale": "The review point explicitly mentions \"W1\" and refers to \"whitespace throughout the paper.\" This directly identifies a specific section and a characteristic of the content. The reviewer is very clear about the location and the issue being addressed within that location.", "verifiability_rationale": "The review point states a fact: \"The authors have clearly reduced whitespace throughout the paper.\" This is a factual statement, not a claim that requires verification or justification. While it points to a problem, it doesn't present a judgment or suggestion that needs supporting evidence.", "helpfulness_rationale": "The review point identifies a formatting issue (\"whitespace throughout the paper\"). However, it doesn't provide any actionable steps or guidance on how the authors should address this issue. It simply states the problem without offering any solutions or direction. Therefore, it's not particularly helpful in improving the authors' draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point is a direct question asking for clarification on the concept of 'local interactions'. This falls under the category of explicit action, as the reviewer is prompting the author to define a specific term. The action is clear: the author needs to explain what 'local interactions' means in the context of the paper.", "grounding_specificity_rationale": "The review point does not explicitly name a specific section, table, figure, or unique element of the paper. While the reviewer is asking about 'local interactions', the paper section where this concept is discussed is not mentioned. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point is not a claim or a suggestion. It is a question seeking clarification. Therefore, it does not contain a claim that requires verification. The label 'X' indicates that there is X.", "helpfulness_rationale": "The review point is a direct question seeking clarification on a potentially ambiguous concept ('local interactions'). This is helpful because it directly addresses a potential point of confusion for the author and encourages them to provide more specific details about their work. While it doesn't present a claim, it is a clear and actionable request for information."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the paper claims better results in Table 3 and then points out that adding the constrained method yields lower validity and diversity. This directly identifies a discrepancy and suggests a specific area for improvement. The reviewer provides a clear action: 'Look at Table 3 and compare the results with and without the constrained method to verify the claim and identify the issue.' This action is direct and requires the authors to take a specific step.", "grounding_specificity_rationale": "The reviewer refers to 'Table.3' and mentions 'validity' and 'diversity' as the specific aspects of the results that are affected. This indicates a clear grounding of the comment on the experimental results and specific metrics. The reviewer is not just saying 'Table 3 shows something,' but rather pinpointing the specific columns (validity and diversity) within that table. This provides a clear reference point for the authors to understand the specific issue.", "verifiability_rationale": "The reviewer states a claim: 'The paper claims better results in the Molecule generation experiment (Table.3)'. They then provide the data in Table 3 to support this claim. While the reviewer does not explicitly state why the constrained method yields worse results, the data itself serves as the verification of the claim. The reviewer's suggestion to 'look at Table 3' directly leads to the verification of the claim and the observation of the discrepancy. The claim is supported by the provided evidence.", "helpfulness_rationale": "The reviewer clearly identifies a contradiction in the paper's claims and the experimental results. They directly point out the impact of the constrained method on validity and diversity. This is a significant and actionable feedback for the authors. The reviewer's suggestion to 'look at Table 3' is a direct and helpful next step for the authors to understand and address this issue. This feedback is clear, specific, and directly addresses a potential error in the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for clarification on how the archetype positions are updated after initialization. While the initialization method (FurthestSum) is mentioned, the *action* of updating is not explicitly stated. The reviewer infers the need for this update and asks for details, indicating a lack of explicit information in the algorithm description. Therefore, while the need for update is clear, the explicit action and details are missing, making it 3 but requiring inference.", "grounding_specificity_rationale": "The reviewer correctly identifies the relevant parts of the paper (Algorithm 2, coreset C, query Q, and archetype positions z_1...z_k). However, the *specificity* of the information provided about the update mechanism is lacking. The reviewer knows *where* the information should be, but the *details* of how the archetypes are updated are not explicitly given. This makes the grounding somewhat specific but incomplete.", "verifiability_rationale": "The reviewer makes a claim that the paper lacks clarity on how the archetype positions are updated. This claim is based on the absence of explicit details in the algorithm description. While the claim is stated clearly, the *evidence* for its verifiability is weak because the relevant section (Algorithm 2) is not fully provided. Therefore, the claim is 3 but relies on an assumption about the missing details.", "helpfulness_rationale": "The reviewer's point is highly relevant to the understanding and implementation of the algorithm. The lack of clarity on how archetypes are updated is a significant omission. While the information is likely present elsewhere or can be inferred, the absence of this crucial detail makes the review 5 for the authors who are likely implementing or building upon this work. The reviewer's request for clarification is a direct call for essential information."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point asks the authors for specific details about their empirical study, such as recording parameters, preprocessing steps, and experimental conditions. This is a request for information, not a direct instruction on how to improve their draft. The authors are not explicitly told what to do with this information, but rather what kind of information they should provide.", "grounding_specificity_rationale": "The review point explicitly mentions the specific information the authors should provide, including 'recording parameters for the MRI', 'preprocessing steps', 'whether the restingstate was recorded under eyesopen or eyesclosed condition', and 'a brief explanation of the harmonization technique'. The reviewer also specifies the 'number of regions in the parcellation' they should mention. This provides clear guidance on where and what information to include.", "verifiability_rationale": "The review point makes a claim that the authors are missing important information about their empirical study. This claim is supported by logical reasoning, as missing information is a valid reason to request it. Furthermore, the reviewer provides specific examples of what constitutes 'important information', such as 'recording parameters for the MRI', 'preprocessing steps', and 'whether the restingstate was recorded under eyesopen or eyesclosed condition'. The claim is wellsupported by examples and references to standard practices in empirical research.", "helpfulness_rationale": "The review point requests information that is likely to be highly beneficial for the authors, particularly those involved in empirical research. Providing details about their experimental setup, preprocessing, and analysis pipelines is crucial for reproducibility and understanding their work. The reviewer is essentially asking for the core methodological details that are essential for others to understand and potentially build upon their research."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of methods exploiting action unit relationships being datasetspecific and suggests a solution by performing crossdataset experiments. They also provide a reason for why this is important and an example of the visual difference they expect to see in Figure 1. The reviewer clearly identifies a weakness and proposes a concrete action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'crossdataset experiments' and connects it to the problem of datasetspecific relationships. They also mention a specific example of the issue with Figure 1. The reviewer not only identifies the type of problem but also how to test it, and even provides an example of what the cooccurrence would look like in different datasets. This shows strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a clear claim that the paper is 'lacking' in crossdataset experiments and provides a specific reason for this deficiency ('to test the generalization of such work'). They also give an example of what the crossdataset experiments would involve. This claim is wellsupported by logical reasoning and a concrete suggestion, making it 5.", "helpfulness_rationale": "The reviewer clearly identifies a significant limitation of the work being reviewed (the lack of crossdataset validation) and provides a concrete and actionable suggestion for improvement. This is a valuable piece of feedback for the authors, directly addressing a potential gap in their evaluation. The reviewer's point is not just about identifying a problem but also about how to address it, making it 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states they 'would have liked more description' of the Starcraft environment. While this implies a desire for improvement, the specific action of 'more description' is not explicitly defined. The reviewer doesn't specify what aspects of the environment need more detail. Therefore, while the reviewer indicates a need for action, the lack of specificity makes it difficult to pinpoint the exact action to be taken.", "grounding_specificity_rationale": "The reviewer refers to 'the Starcraft environment' as the specific part of the paper being addressed. This demonstrates a degree of grounding as the reviewer can identify the section. However, the reviewer does not specify *which* part of the Starcraft environment (e.g., rules, map, units, technology tree) requires more description. The grounding is present, but it lacks the specificity to pinpoint the exact element needing improvement.", "verifiability_rationale": "The review point 'I would have liked more description of the Starcraft environment' does not contain a claim that requires verification. It is a suggestion for improvement rather than a statement that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The reviewer explicitly states they 'would have liked more description'. This indicates a desire for improvement, suggesting the feedback has the potential to be helpful. However, the feedback is vague and does not specify *what* information is missing or *how* to provide it. Therefore, while the feedback has the intention of being helpful, the lack of concrete guidance limits its practical impact."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies limitations of the method and suggests areas for improvement, such as efficiency and comparison with existing work. While it points out problems, it doesn't explicitly instruct the authors on how to address them. For example, it mentions the pixellevel training but doesn't detail how the authors should modify their approach based on this. The suggestions are general and lack concrete steps.", "grounding_specificity_rationale": "The review point mentions 'the shape model' and 'the parsing model,' which are specific components of the work. It also refers to the 'training process' and 'four types of factors' in the parsing model, indicating some grounding. However, it doesn't pinpoint a specific aspect within the training process (e.g., pixellevel vs. characterlevel training) or a particular factor in the parsing model. The grounding is somewhat broad.", "verifiability_rationale": "The review point makes a claim about the 'processing efficiency of training and testing' and states that it 'should be described and compared with existing work.' This is a claim that needs evidence. While it identifies a problem, it doesn't provide specific examples or references to support the claim that the efficiency is lacking or how it compares to existing work. The claim is present, but the supporting evidence is missing.", "helpfulness_rationale": "The review point points out limitations of the current approach and suggests areas for improvement, such as addressing efficiency and comparing with existing work. It highlights problems that the authors should be aware of. While it doesn't offer concrete solutions, it identifies issues that need to be addressed, which can be helpful for guiding the authors' thinking and focus. The feedback is relevant and points out areas for selfimprovement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests using 'other domain adaptation methods' to improve performance. This is a clear and explicit action pointing towards a specific improvement. The reviewer directly identifies a potential weakness (the use of an 'old and simple' method) and proposes a concrete solution (using 'other' methods). This action is directly tied to the identified weakness and offers a clear path for improvement.", "grounding_specificity_rationale": "The reviewer states that the 'adversarial attack or correction method and the domain adaptation method used by the authors are proposed by prior work' and that the 'adopted domain adaptation method here is a very old and simple method'. While the reviewer identifies a potential issue (the use of an old method), they do not explicitly state the section, table, figure, or unique aspect of the paper where these methods are discussed. The reviewer's statements are about the methods themselves, not their specific location within the paper. Therefore, the grounding is weak as the reviewer cannot confidently pinpoint the referenced part of the paper.", "verifiability_rationale": "The reviewer makes claims about the methods used in the paper, stating that they are 'proposed by prior work' and that the 'adopted domain adaptation method here is a very old and simple method'. These are claims that require verification. The claim about prior work could be verified by checking the citations in the paper. The claim about the method being 'old and simple' could be verified by checking the publication date and description of the method used. While the claims are about the paper's content, they lack specific references to support the claims about the methods' age and simplicity.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential weakness in the paper: the lack of innovation and the use of an 'old and simple' domain adaptation method. The reviewer suggests using 'other domain adaptation methods' to 'further improve the performance'. This is a clear and actionable suggestion that directly tackles the identified weakness and proposes a concrete improvement. The reviewer's comment is not just a critique but also a constructive suggestion for improvement, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states the paper is \"difficult to follow the motivation\" and \"incremental engineering paper.\" While this points to a potential weakness, the reviewer does not explicitly state what part of the motivation is unclear or how the paper is incremental. The reviewer implies an action (understanding the motivation better) but doesn't provide specific details on how to achieve it. Therefore, while the comment has an implicit action, it lacks the specificity needed for high actionability.", "grounding_specificity_rationale": "The reviewer's comment is about the overall motivation and contribution of the paper, not a specific section, table, figure, or unique aspect. They do not identify a specific part of the paper that needs improvement. Therefore, the comment is 1 in a specific part of the paper.", "verifiability_rationale": "The reviewer makes subjective claims about the paper's difficulty and nature, stating \"Very difficult to follow the motivation of this paper\" and \"And it looks like an incremental engineering paper.\" These claims are not supported by verifiable facts or references. The reviewer's assessment is based on their perception, not on evidence within the paper itself. Therefore, the claims are 1.", "helpfulness_rationale": "The reviewer's comment identifies potential weaknesses in the paper's motivation and contribution. While this feedback is relevant, it lacks specific guidance on how to address these weaknesses. The reviewer does not pinpoint specific areas that need improvement or suggest concrete steps for the authors. Therefore, while the feedback is 3 in prompting reflection, it is not 5 and lacks specific direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the action of 'ablate the crossentropy loss weighting' and the goal of 'see if this might help' with the issue mentioned about repetitive background sounds in Atlantis. The action is clear and direct, allowing the authors to implement it.", "grounding_specificity_rationale": "The reviewer is not explicitly pointing to a specific part of the paper (e.g., a figure or table) but is making a general suggestion based on a previous observation about the method. The grounding is in the context of the previous point about Atlantis's method. The specificity is in the *general area* of the method rather than a specific element.", "verifiability_rationale": "The review point makes a claim by stating 'The authors note for example that in Atlantis their method underperforms because 'the game has repetitive background sounds'. This is a scenario I'd expect the weighting might have helped remedy.' This claim is supported by the previous observation about Atlantis and the expectation that weighting might address the sound issue. However, it doesn't provide direct empirical evidence or specific references to back up this expectation.", "helpfulness_rationale": "The review point is clear, actionable, and directly addresses a potential issue raised in the previous point. The suggestion to ablate the weighting is a concrete action the authors can take, and the reviewer anticipates it might improve performance in the specific scenario. This makes the review point quite helpful for guiding the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out a general weakness (lack of novelty) and suggests some directions for improvement (new dataset, synthetic benchmark) but does not specify *how* the authors should address this weakness. The suggestions are highlevel ideas rather than concrete actions with implementation details.", "grounding_specificity_rationale": "The review mentions general areas of the paper (column operations, TexttoSQL, semantic parsers) but does not specify a particular section, table, figure, or unique element that needs improvement. The suggestions are very broad and lack specificity.", "verifiability_rationale": "The review makes a claim about the lack of novelty but does not provide any evidence, data, or references to support this claim. The suggestions are presented as potential solutions rather than verifiable criticisms of the existing work.", "helpfulness_rationale": "The review offers some general ideas for improvement but lacks the specificity and evidence needed to be truly helpful. The suggestion about the 'critical weakness' is not backed up, and the proposed solutions are too broad to provide actionable guidance."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action the authors should take: 'explain' and 'provide' (implying 'solid examples'). This is a clear and direct instruction. The reviewer also specifies the type of examples needed, which makes the action even more concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions the assumptions 'bounded variance and bounded gradients' as the area of the paper being addressed. This is a clear and precise identification of the specific part of the paper. Furthermore, the reviewer specifies the type of explanation needed: 'via solid examples'. This adds to the specificity of the feedback.", "verifiability_rationale": "The reviewer states a requirement for the authors to 'explain' their contribution 'via solid examples'. This is a claim that needs to be supported. While the request itself doesn't provide specific citations, it implies that the authors should be able to find or construct examples that demonstrate the importance of their relaxed assumptions. This claim can be verified through logical reasoning and common knowledge within the field of optimization.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the original draft: the lack of explanation for the significance of the relaxed assumptions. The reviewer also provides a concrete direction for improvement by suggesting the use of 'solid examples'. This directly addresses a potential area for enhancement and provides a clear path for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a problem ('slow' and 'low accuracy') and provides specific numbers. This suggests it *could* be actionable. However, the reviewer doesn't explicitly *say* what needs to be changed. For example, they might be suggesting a different architecture, optimization, or implementation detail, but they don't point to a specific location in the code or description. While the problem is stated, and the evidence is quantitative, the specific action isn't clearly defined.", "grounding_specificity_rationale": "The reviewer mentions \"ImageNet\" and \"AlexNet\" and \"ResNet18\". These are specific terms. The reviewer can identify the parts of the paper being addressed (ImageNet, AlexNet, ResNet18). They also specify the *slow* speed and *low accuracy* for ImageNet with these specific architectures. They provide *quantitative* evidence (1 day, 2.5 days, 70%).", "verifiability_rationale": "The reviewer states a fact: \"Although the authors claim they implement ImageNet for the first time, it is very slow and accuracy is very low\". This is a claim that needs to be verified. The provided numbers (\"SHE needs 1 day and 2.5 days to test an ImageNet picture by AlexNet and ResNet18, respectively\" and \"accuracy is around 70%\") serve as evidence. The reviewer provides specific timing and accuracy figures for specific models.", "helpfulness_rationale": "The reviewer points out a clear performance issue with a specific implementation and provides quantitative evidence. This directly informs potential improvements. Knowing the implementation is slow and inaccurate would likely prompt the authors to investigate their implementation details, potentially leading to performance optimizations or exploring alternative architectures. While the reviewer doesn't specify *how* to improve, the identified problem is actionable. The authors know *what* is wrong."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer poses a question about the potential of using labeled data for consistency training in graph anomaly detection. While this suggests a direction for improvement, it doesn't explicitly state an action or propose a concrete change to the current method. The reviewer asks 'I wonder if it would be beneficial to utilize labeled data for consistency training as well.' This is a question, not a direct instruction.", "grounding_specificity_rationale": "The reviewer mentions 'labeled data for consistency training' and 'graph anomaly detection' and cites specific papers. This indicates a clear identification of the area and provides specific examples. The reviewer also asks a question about the potential of this approach.", "verifiability_rationale": "The reviewer suggests that labeled data could be beneficial for consistency training in graph anomaly detection. This is a claim that could be supported by logical reasoning about the potential of labeled data. However, the reviewer does not provide specific examples of how this could be implemented or cite external references to support this claim.", "helpfulness_rationale": "The reviewer's point is about suggesting a new technique and its potential application. This is a valuable insight for the authors working on graph anomaly detection, as it opens up a new avenue for exploration. While it doesn't directly solve a problem, it offers a potential improvement strategy by suggesting a different training paradigm. The reviewer asks a question about a potential technique and its application, which is a valuable suggestion for future research."}
{"actionability_label": "3", "grounding_specificity_label": "1: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests reorganizing the experimental section, which is an explicit action. However, the specific changes or how to implement this reorganization are not detailed, making it only implicitly actionable.", "grounding_specificity_rationale": "The review mentions the 'experimental part' of the paper, indicating a weak grounding as it doesn't identify a specific section, table, figure, or unique aspect being addressed.", "verifiability_rationale": "The review states 'The experimental part needs to be reorganized and further improved,' which is a statement of a problem and a desire for improvement, not a claim requiring verification.", "helpfulness_rationale": "The review identifies the need for reorganization but lacks specific details or concrete suggestions on how to achieve this. This makes it only 3 as the authors might not know where to start or what exactly to change."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises two questions. The first question asks for clarification on the experimental setup and results, which could be seen as implicitly asking for an action to better understand the findings. However, the second question is a suggestion for code publication, which is not an actionable item. The lack of explicit direction makes the overall comment less actionable.", "grounding_specificity_rationale": "The reviewer mentions the 'German and Law school dataset' and 'Gerrymandering' and 'Independent' datasets, showing some grounding. However, the connection between these datasets and the specific issue of training time is not explicitly stated. The reviewer also mentions 'ERM and plugin' and 'Kearns et al.' without explicitly linking them to specific parts of the paper. The grounding is weak because the exact sections or tables being referred to are not clearly identified.", "verifiability_rationale": "The reviewer points out an observation about training time without providing any external references or logical reasoning to support this claim within the review point itself. The suggestion to publish code is a request for information rather than a claim requiring verification. The lack of supporting evidence makes the claim 1.", "helpfulness_rationale": "The reviewer's questions are relevant to understanding the experimental results and potentially improving the method. The suggestion to publish code is a valuable point that could encourage further research and reproducibility. While the questions are not directly actionable, they are pertinent to the work and suggest areas for improvement, making the overall comment 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point asks for alternative formulations of Confidence Diversity (CD) and questions the suitability of entropy for a specific description of CD. While it doesn't explicitly state an action to be taken, it clearly identifies a gap in the explanation and encourages the authors to consider different ways to define and measure CD. The reviewer is prompting the authors to elaborate on the concept and justify their choice of entropy. This is a direct request for more information and clarification, which is actionable in the sense that it encourages the authors to revisit and expand their discussion of CD.", "grounding_specificity_rationale": "The review point asks for alternative formulations of Confidence Diversity (CD) and questions the suitability of entropy for a specific description of CD. The reviewer does not explicitly identify a specific part of the paper being addressed. The questions are general and openended, asking for a broader understanding of CD and its measurement. Therefore, the grounding is weak as the reviewer is not pinpointing a specific section or element of the paper.", "verifiability_rationale": "The review point asks for alternative formulations of Confidence Diversity (CD) and questions the suitability of entropy for a specific description of CD. The reviewer does not present a claim that can be verified. They are asking questions and seeking information, not making a statement that requires justification or evidence. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The review point asks for alternative formulations of Confidence Diversity (CD) and questions the suitability of entropy for a specific description of CD. This is a valuable contribution to the discussion. By prompting the authors to consider different ways to define and measure CD, the reviewer encourages a deeper understanding of the concept and potentially leads to improvements in the paper. The questions about entropy demonstrate a genuine attempt to understand the underlying mechanisms and justify methodological choices. This is a valuable piece of feedback that can help the authors refine their work."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the difference in followup time between the human and model baselines and how this impacts the perceived strength of the human baseline. They also explicitly state the CER and BLEU scores and criticize the comparison in the abstract. All aspects of the actionability criteria are met: the action (identifying the followup time difference and its impact) is explicit, and the details are concrete.", "grounding_specificity_rationale": "The reviewer refers to the 'human baseline' and 'model baseline' mentioned in the abstract and Section 4.1. While the specific section isn't named, the concepts are introduced and the CER/BLEU scores are referenced. The reviewer also explicitly mentions the misleading nature of the comparison in the abstract, which implies a degree of grounding. However, the reviewer doesn't explicitly state which section of the paper the comparison is made within, making it not fully 'Fully Grounded'.", "verifiability_rationale": "The reviewer makes a clear claim in the abstract: 'already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources' which is a bit misleading given the 1 hour vs. The reviewer then provides a logical explanation for why this comparison is misleading, focusing on the difference in followup time. This explanation is based on common knowledge and logical reasoning, making the claim verifiable.", "helpfulness_rationale": "The reviewer's point is 5 because it directly challenges the authors' interpretation of their own results. By pointing out the misleading comparison, the reviewer provides a concrete suggestion for the authors to reevaluate their conclusions and potentially adjust their understanding of their human baseline performance. This actionable feedback is directly aimed at improving the authors' understanding of their work."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review points out a problem ('strong assumptions') and a consequence ('high labeling cost'). While it identifies an issue, it doesn't explicitly state a concrete action or suggestion for improvement. The connection between the assumptions and the cost is implied but not explicitly stated as an action. The vagueness of 'strong assumptions' also contributes to this.", "grounding_specificity_rationale": "The review mentions 'termination states' and 'manual labeling,' which provides some grounding. However, it doesn't explicitly identify a specific section, table, or figure. The mention of 'manual labeling' is general and doesn't specify what aspect of the data requires labeling or provide examples of what is being labeled. Therefore, it can be considered weakly grounded. The comment specifies the *type* of labeling (manual) but not the *specific* data element being labeled.", "verifiability_rationale": "The review contains a claim: 'it is very expensive to label a large number of data manually.' This claim is supported by common knowledge in the field of machine learning and data science, where manual annotation is often a resourceintensive process. The reasoning is based on the practical challenges of data labeling, and external references (like common knowledge or experience in the field) could support this claim.", "helpfulness_rationale": "The review identifies a practical issue: the high cost of manual labeling for defining 'termination states.' This is a relevant concern for researchers and practitioners working with data that requires such definitions. While it doesn't offer a solution, it highlights a significant bottleneck in the data acquisition process. The reviewer points out a realworld challenge that authors might face."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "6", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies the ambiguity surrounding the term 'Efficient Proxy' but does not explicitly state a concrete action or suggestion to resolve this ambiguity. While the reviewer points out the lack of clarity, they don't provide a specific direction for the authors to clarify their usage of the term.", "grounding_specificity_rationale": "The reviewer points out the ambiguity of the term 'Efficient Proxy' and suggests it could refer to a particular proxy or a family of proxies. While the reviewer identifies the *content* of the paper (the concept of efficient proxies) as being discussed, they do not explicitly identify the *specific* section, table, or unique aspect of the paper where this ambiguity occurs. The grounding is implied rather than explicitly stated.", "verifiability_rationale": "The reviewer states a fact about the ambiguity of the term 'Efficient Proxy' in the authors' paper. They do not make a claim that requires verification or justification. The statement is a description of a lack of clarity, not a proposition that needs to be proven.", "helpfulness_rationale": "The reviewer identifies a weakness in the authors' paper regarding the clarity of the term 'Efficient Proxy'. However, the reviewer does not offer any specific suggestions or actions for the authors to take to address this weakness. The comment is a diagnosis of a problem, not a prescription for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment 'The model seems overly simple' does not explicitly state what needs to be done. It expresses an opinion about the model's simplicity, but lacks specific instructions on how to address this. The authors are left to interpret what 'overly simple' means in the context of their work, which is not helpful for guiding concrete changes.", "grounding_specificity_rationale": "The comment 'The model seems overly simple' does not identify a specific part of the paper or analysis that is being addressed. It is a general statement about the model's overall complexity, without pinpointing any specific element of the work. Therefore, it does not ground the feedback in a specific location or aspect of the paper.", "verifiability_rationale": "The comment 'The model seems overly simple' is an opinion, not a claim that requires verification. It does not present a statement that can be supported by evidence or logical reasoning. It is a subjective assessment of the model's complexity.", "helpfulness_rationale": "The comment 'The model seems overly simple' is a helpful suggestion that points towards exploring more complex models. However, it does not provide specific guidance on how to achieve this or identify which aspects of the current model need modification. It offers a highlevel direction but lacks the specificity needed for actionable improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the suggestions and their intended purpose, making the action clear. The reviewer suggests mentioning the appendix and including runtime examples, which are concrete actions the authors can take.", "grounding_specificity_rationale": "The reviewer provides specific instructions on where to find the information (appendix) and what to include (runtime examples). This is a form of grounding, and the information is quite specific.", "verifiability_rationale": "The reviewer makes a claim about how the information will help motivate the method and aid application, and provides a logical reason for this. While not explicitly citing external references, the logical connection is clear.", "helpfulness_rationale": "The reviewer's suggestions directly address a practical concern (computational cost) and aim to improve the reader's understanding and potential adoption. The suggestions are clear and directly related to the stated goals."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the purpose of Figure 3 and asks for clarification, indicating a direct intention to improve the authors' understanding. The request to elucidate the procedure and understand the role of sensor arrangement are concrete actions the authors can take to address the ambiguity.", "grounding_specificity_rationale": "The reviewer directly mentions 'Figure 3' by name, providing clear grounding. They also specify the issue as the 'spatial arrangement of the EEG sensors,' adding further specificity to the point being addressed.", "verifiability_rationale": "The reviewer's statement about Figure 3 leading to ambiguity is a claim. However, they do not provide any external references or logical reasoning to support this claim within this specific review point. The comment is primarily a suggestion for improvement rather than a definitive statement requiring verification.", "helpfulness_rationale": "The reviewer provides specific and actionable feedback directly related to the paper's content. They ask the authors to elucidate a specific procedure and to understand the role of a specific component (EEG sensors). This directly addresses a potential point of confusion and suggests a concrete improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states the consequence ('raises questions about generalizability') and suggests further investigation ('understand the criteria...'). However, the reviewer doesn't explicitly state what the criteria are or what alternative tasks/datasets are being considered, making the action implicit.", "grounding_specificity_rationale": "The reviewer is referring to the 'Massive Text Embedding Benchmark (MTEB)' and its 'subset' but doesn't specify which subset or provide the criteria for its selection. The reviewer is pointing to a general concern about generalizability, which is a broad issue. They haven't pinpointed a specific element within the MTEB subset that's problematic.", "verifiability_rationale": "The reviewer makes a claim ('the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB) raises questions about generalizability') but doesn't provide any specific evidence or references to support this claim within the review point itself. The claim is presented as a statement of concern without justification.", "helpfulness_rationale": "The reviewer raises a valid point about a potential limitation of the evaluation methodology. However, the review point lacks specific details about the criteria for the subset or concrete suggestions for improvement. The reviewer's message is somewhat general and openended, making it helpful in identifying a potential issue but not in providing specific guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a weakness ('it is not immediately obvious what is being modelled') but does not provide concrete details on how the authors should proceed. The suggestion is present, but the implementation is vague.", "grounding_specificity_rationale": "The comment explicitly mentions the 'second paragraph of the introduction' (grounding), but it does not specify the exact element within that paragraph that needs clarification (e.g., the specific variables being modelled, the type of model used, or the data being fitted). The specificity of the issue is lacking.", "verifiability_rationale": "The comment contains a suggestion ('It is not immediately obvious what is being modelled') which can be considered a claim. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion is made, but the reasons for it are not explained.", "helpfulness_rationale": "The comment identifies a valid weakness in the introduction ('modelling curves' is not clearly defined') and suggests the authors should clarify this. While it doesn't provide a solution, it points towards an area for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests improvements by stating 'expected' and 'this paper should provide more explanation'. It also proposes exploring 'different optimization strategies and the corresponding results'. While the reviewer doesn't explicitly state how to implement these suggestions, the actions are relatively direct. The reviewer asks a specific question about minimizing terms in Eq 3, which implies a concrete action. However, the reviewer doesn't provide a concrete action on how to implement the suggestions about the CBR or the optimization strategies. The reviewer suggests exploring different optimization strategies but doesn't specify how to do this. The reviewer asks a question about minimizing terms in Eq 3, which implies a concrete action. However, the reviewer doesn't provide a concrete action on how to implement the suggestions about the CBR or the optimization strategies.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'explanation' and 'optimization strategies' as areas for improvement. They also refer to 'Eq 3' as a specific part of the paper. This indicates a strong grounding as the reviewer is pointing to specific sections and concepts within the paper. The reviewer is not making a general statement about the paper but is focusing on specific areas.", "verifiability_rationale": "The reviewer provides a claim that 'different optimization strategies and the corresponding results should discussion' and asks a question 'what will happen by minimizing both of the inter and intra terms in Eq 3 or only minimizing the first term?'. The suggestion to explore different optimization strategies is a claim that can be supported by external knowledge or further experimentation. The question about minimizing terms in Eq 3 is a request for evidence that can be verified. The reviewer provides a claim and suggests a way to verify it by exploring different optimization strategies and asking a question about a specific equation. The claim is about suggesting improvements and exploring optimization strategies. The suggestion to explore optimization strategies is a claim that can be supported by external knowledge or further experimentation. The question about minimizing terms in Eq 3 is a request for evidence that can be verified. The reviewer provides a claim and suggests a way to verify it by exploring different optimization strategies and asking a question about a specific equation.", "helpfulness_rationale": "The review point clearly identifies areas for improvement by stating 'expected' and 'this paper should provide more explanation'. It also suggests exploring 'different optimization strategies and the corresponding results'. The reviewer asks a specific question about minimizing terms in Eq 3, which directly addresses a potential area for improvement. The suggestions are actionable and point to concrete next steps for the authors. The reviewer provides a clear and actionable feedback on weaknesses and areas for improvement, though it could be expanded or refined to be fully comprehensive and impactful. The reviewer provides a clear and actionable feedback on weaknesses and areas for improvement, though it could be expanded or refined to be fully comprehensive and impactful. The reviewer provides a clear and actionable feedback on weaknesses and areas for improvement, though it could be expanded or refined to be fully comprehensive and impactful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need to 'include a formal or intuitive definition of the treewidth' and suggests this definition should be placed 'since it is central to all the proofs in the paper'. This is a clear and direct action that the authors can readily implement. The reviewer identifies a specific area of the paper (definitions) and a specific location (around the proofs) where the information should be added. The action is also concrete, as the reviewer provides a specific location for the definition. Therefore, the reviewer provides a clear and actionable suggestion.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'treewidth' and its role in the 'proofs'. The mention of 'treewidth' is precise and directly refers to a specific concept within the paper. The reviewer also states the location where this definition should be included, further grounding the suggestion. While the reviewer doesn't provide examples, the reference to 'central to all the proofs' implies a clear understanding of the importance of this concept within the paper's framework. Therefore, the reviewer's suggestion is grounded in the paper's content and the reviewer's understanding of its significance.", "verifiability_rationale": "The reviewer makes a claim that 'treewidth is central to all the proofs in the paper'. While the paper itself would be the primary source of verification, the reviewer provides a clear statement of what they believe is important. The reviewer's suggestion to include a definition is a direct request for improvement. The claim is actionable and points to a specific area for the authors to address. The reviewer doesn't provide external references in this specific point, but the claim itself is verifiable by examining the proofs. Therefore, the reviewer provides a claim that is verifiable, even if the verification requires access to the proofs.", "helpfulness_rationale": "This review point directly addresses a crucial element of the paper: the concept of 'treewidth' and its importance to the proofs. The reviewer provides a clear and specific suggestion: 'include a formal or intuitive definition of the treewidth'. This is a 5 piece of feedback. The authors can immediately understand the reviewer's concern and take steps to address it. The reviewer's suggestion is not just a comment; it's a concrete direction for improving the paper's clarity and accessibility. The reviewer also specifies where the definition should be included ('since it is central to all the proofs in the paper'), further enhancing the actionable nature of the feedback. This review point is very helpful for the authors as it clarifies a key concept and guides them towards a specific improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the 'convergence to permutations as local minima' and implicitly suggests analyzing the 'quality' of these local minima. While the 'permutations' aspect adds a degree of specificity, the general nature of 'Algorithm 1' and the lack of a direct action on how to analyze the quality make it only weakly actionable. The reviewer identifies a gap and suggests a direction for improvement, but doesn't provide a concrete stepbystep action.", "grounding_specificity_rationale": "The reviewer refers to 'Algorithm 1' generally, which does not provide strong grounding. While they mention 'permutations' as a specific aspect of the local minima, the general reference to 'Algorithm 1' and the lack of a specific section or table number weakens the grounding. The specificity comes from asking about the 'quality' of these local minima, but the grounding itself is not very precise.", "verifiability_rationale": "The reviewer makes a claim by stating that the paper 'only analyzed' the convergence to permutations and suggests 'it will be better if the quality of this kind of local minima could be analyzed'. This is a claim that can be verified by examining the paper's content. The suggestion to analyze the 'quality' (approximation ratio) is a specific and verifiable suggestion based on established concepts in theoretical computer science.", "helpfulness_rationale": "The reviewer points out a specific limitation in the paper's analysis and offers a concrete suggestion for improvement by analyzing the 'quality' of the local minima. This directly addresses a potential weakness and provides a clear direction for the authors to enhance their work. The suggestion is specific and actionable."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "2 (Weakly Grounded and UnderSpecific)", "verifiability_label": "1 (1)", "helpfulness_label": "4 (4)", "actionability_rationale": "The reviewer states that the supplementary material is necessary to understand large parts of the main paper, indicating an implicit need for it. While the reviewer doesn't explicitly state the specific action to take with the supplementary material, the need for it is a clear action.", "grounding_specificity_rationale": "The reviewer states that the paper is not selfcontained and that the supplementary material is necessary to understand large parts of the main paper. While the reviewer identifies the need for the supplementary material, they do not explicitly pinpoint a specific section or element in the main paper that is unclear or requires the supplementary. The statement is more about the general lack of understanding.", "verifiability_rationale": "The reviewer states that the paper is not selfcontained and that the supplementary material is necessary to understand large parts of the main paper. This is a claim that the paper lacks selfcontainment. However, the reviewer does not provide any evidence or justification for this claim. They do not cite specific examples, logical reasoning, or external references to support why the paper is not selfcontained.", "helpfulness_rationale": "The reviewer clearly identifies a significant issue (lack of selfcontainment) and provides a concrete suggestion for improvement: requesting the release of the source code. This is a direct and actionable suggestion that would directly address the reproducibility issue highlighted by the lack of selfcontainment."}
{"actionability_label": "1", "grounding_specificity_label": "Weakly Grounded", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks for the mechanism of how information redundancy is built into the algorithms. While the paper mentions the 'weight pool' and its role in implementing redundancy, it doesn't explicitly state whether the redundancy is explicit or implicit. The paper describes the algorithms but doesn't detail how the weight pool is structured or how it ensures redundancy. Therefore, the reviewer cannot directly identify modifications they should apply to their draft based on this information alone.", "grounding_specificity_rationale": "The reviewer asks how information redundancy is built into the algorithms. The paper mentions the 'weight pool' as a component that implements redundancy. However, it doesn't explicitly state which part of the paper (e.g., a specific section or table) contains this information. The reviewer has to infer that the 'weight pool' is relevant to the algorithms. Therefore, the grounding is implicit.", "verifiability_rationale": "The reviewer asks how information redundancy is built into the algorithms. The paper states that the robustness of Cans comes from the information redundancy implemented in the weight pool. However, the paper does not provide any external references or logical reasoning to support this claim. It is purely based on the observation of experimental results. Therefore, the claim is not fully supported by evidence.", "helpfulness_rationale": "The reviewer asks how information redundancy is built into the algorithms. The paper mentions the 'weight pool' and its role in implementing redundancy. However, it does not provide a detailed explanation of how the weight pool is structured or how it ensures redundancy. The reviewer would need to consult the paper to understand the mechanism, which is not a direct and comprehensive explanation. Therefore, the feedback is not as helpful as it could be."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to justify their choice of the REINFORCE algorithm. This is an explicit action that the authors should take. The reviewer directly states the need for justification, making it a clear and actionable suggestion.", "grounding_specificity_rationale": "The reviewer explicitly mentions the REINFORCE algorithm and the alternative algorithm (PPO). While they don't provide a specific section or table reference, the mention of 'algorithm' itself can be considered a weak grounding. The reviewer also mentions 'attention model paper,' which provides a general context, but not a specific section or table. The specificity of the *reason* for the choice isn't fully elaborated.", "verifiability_rationale": "The review point itself does not contain a claim that needs verification. It's a request for information and justification. Therefore, it doesn't fit the criteria for verifiability.", "helpfulness_rationale": "The review point is 5. The reviewer explicitly asks for justification of a methodological choice (algorithm selection). This directly addresses a potential gap in the authors' understanding or the paper's clarity. It encourages the authors to think critically about their methodology and provides a concrete action for them to take \u2013 to seek further explanation or reasoning behind the algorithm choice. While it doesn't critique the algorithm itself, it prompts a crucial step in understanding *why* a particular algorithm was chosen."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desired experiment: 'there should be experimental results of excluding such mixup technique from the proposed method in order to demonstrate its pure contribution;'. This is a clear and direct action that the authors can readily implement. The reviewer identifies the specific issue (the lack of evidence isolating the mixup technique) and proposes a concrete solution (an additional experiment).", "grounding_specificity_rationale": "The reviewer mentions 'Sec. 4.2', 'mixup technique', and 'LUMP'. While they don't explicitly state the *exact* location within Section 4.2 where the mixup technique is described, this provides a clear reference point. The reviewer's suggestion to 'exclude such mixup technique' is specific to the experimental setup. The grounding is present, but it's more about locating the problem rather than pinpointing the exact element within a specific subsection. The suggestion itself is the primary point of grounding.", "verifiability_rationale": "The reviewer makes a claim: 'the current experiments don't isolate the mixup technique's contribution'. This claim is verifiable by the suggested experiment. The reviewer provides a logical reasoning for their claim: the current experiments don't demonstrate the individual impact of the mixup technique. The suggested experiment directly addresses this gap by providing a controlled comparison. While the reviewer doesn't provide specific examples or references to back up this claim, the logical reasoning is clear and the suggested experiment serves as the verification. The claim is 3 because the reasoning is present, but it lacks specific examples or references to external works.", "helpfulness_rationale": "The reviewer's suggestion is highly constructive and directly addresses a potential weakness in the paper's experimental validation. By proposing an additional experiment to isolate the impact of the mixup technique, the reviewer is providing a concrete and actionable improvement for the authors. This suggestion has the potential to significantly enhance the clarity and robustness of the paper's findings. The reviewer is not just pointing out a problem but also offering a clear solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question about a specific technical aspect of the paper (Fourier features and NTK convergence in the highfrequency range). This constitutes an explicit action, as the reviewer is directly asking for clarification or confirmation. While not proposing a change, the question is a clear indication that the author should provide more detail or analysis on this specific point.", "grounding_specificity_rationale": "The reviewer directly references a specific technical aspect of their paper (Fourier features and NTK convergence in the highfrequency range) when asking if they overlooked something. This strong grounding makes it clear which part of the paper the reviewer is referring to. The question also asks if something is missing, directly specifying the potential issue (lack of analysis or clarity).", "verifiability_rationale": "The reviewer's question is a direct inquiry about a specific technical aspect of the paper. While not a statement of opinion, the question implicitly suggests a potential gap in the paper's presentation or analysis of this aspect. If the paper does not adequately explain or analyze Fourier features and NTK convergence in the highfrequency range, the reviewer's uncertainty is an 1 claim in the sense that the paper lacks sufficient justification or evidence for its claims related to this specific area.", "helpfulness_rationale": "The reviewer's question is specific and directly addresses a potential area of confusion or lack of clarity in the paper's technical details. While it doesn't propose a solution, it highlights a point that needs further explanation or analysis. A helpful response would clarify the technical details and address the reviewer's uncertainty, making the paper more accessible and potentially improving the author's understanding."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their desire for more information, which is a direct action. However, the specifics of where to find this information are not provided, making it vague. Therefore, it is 3 but lacks concrete details.", "grounding_specificity_rationale": "The reviewer refers to 'the network,' 'the residual,' 'the input,' and 'the output' without explicitly naming a section, table, figure, or unique aspect of the paper. While they imply a connection to standard concepts, the exact location or detail is not specified. This indicates a lack of precise identification of the part being addressed. The comment is not a general comment but rather points to a specific area of the method description. Therefore, it is not weakly grounded as the reviewer has a general idea of the area, but it is not fully grounded as the specific part is not explicitly named. It is also not specific as the details are missing.", "verifiability_rationale": "The reviewer states a lack of details without providing any external references, logical reasoning, or examples to support their claim. This indicates a lack of verifiable evidence. The claim is that the paper does not explain how the network fits the residual. The reviewer is stating this is a gap in the paper's explanation. Therefore, it is 1 as there is no supporting evidence within the review point itself.", "helpfulness_rationale": "The reviewer's comment highlights a genuine gap in the paper's explanation regarding a specific training detail. While the information might be present elsewhere, the reviewer's inability to find it hinders their understanding or ability to reproduce the work. This points to a lack of clarity or completeness in the paper's description. Therefore, it is 3 as it points to a missing detail, but it does not offer a solution or alternative approach, making it not fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer is implicitly asking for information about the experiment setup, which is a missing element. While they don't explicitly state 'You should add a section on experiment setup,' the request implies a desire for improvement by asking for missing details. However, the request lacks specific instructions on how to provide this information.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3.3' of the paper, which grounds the comment. However, they do not specify *what* is missing or what information is needed within that section. The request is general about the missing experiment setup details.", "verifiability_rationale": "The reviewer is making an implicit claim that the paper is missing information about its experiment setup. This claim is somewhat supported by the fact that the paper should contain details about data augmentation methods and learning rates. However, the reviewer does not provide specific examples or references to back up their claim.", "helpfulness_rationale": "The review point identifies a valid area for improvement by highlighting the missing details of the experiment setup. However, the feedback is somewhat vague and lacks specific instructions on what information is needed or how it should be presented. This makes the feedback less actionable and potentially less helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The comment raises a potential issue related to the algorithm but doesn't explicitly state what is wrong or how to fix it. The suggestion to cite the RVC paper is a concrete action, but the comment itself lacks a clear action on its own. The reviewer is asking a question rather than directly pointing out a flaw.", "grounding_specificity_rationale": "The comment refers to 'steps 1 & 2' of the RVC algorithm, which can be considered a specific part of the paper. The comment also identifies a 'speed disparity' between 'RSPs and FDs,' which can be considered a specific issue within that part. The comment is also asking a question, which can be interpreted as a deduction or inferred observation about the algorithm's performance.", "verifiability_rationale": "The comment raises a hypothesis about a potential cause for the observed speed disparity. While it suggests a possible explanation, it doesn't provide any external references or logical reasoning to support this claim. The suggestion to cite the RVC paper is a potential verification point, but the comment itself lacks concrete evidence.", "helpfulness_rationale": "The review point raises a potential issue and suggests a relevant citation. While the suggestion to cite the RVC paper is helpful, the comment itself is more of a question than a direct solution or actionable insight. It doesn't provide a clear path for the authors to address the speed disparity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: \"it does not become clear how those emission distributions affect inference.\" This is a clear, actionable statement. Furthermore, the reviewer names specific inference tasks (filtering, smoothing, marginal observation likelihood) which further clarifies the scope of the issue. The reviewer also requests clarification on which of these tasks can be computed exactly/approximately with an NPSPECHMM, indicating a clear action to be taken.", "grounding_specificity_rationale": "The reviewer explicitly names the specific inference tasks (filtering, smoothing, marginal observation likelihood) that are relevant to the discussion of the impact of emission distributions on inference. This demonstrates strong grounding as the reviewer can accurately pinpoint the sections, table, figure, or unique aspect being addressed. The request for clarification on which of these tasks can be computed exactly/approximately with an NPSPECHMM further reinforces the grounding by specifying the exact part of the paper that needs attention.", "verifiability_rationale": "The reviewer presents a question as a request for information, which falls under the \"Suggestions or requests for changes\" category of claims. While the reviewer is asking for clarification, the paper does not provide a claim that can be verified. The request itself is the \"claim\" to be addressed.", "helpfulness_rationale": "The reviewer is asking a very specific and targeted question. They are trying to understand the implications of their emission distribution choice on the computational aspects of their model. This is a valuable piece of information for improving the paper. The request for clarification on specific inference tasks directly addresses a potential gap in the reader's understanding and provides actionable feedback for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "Weakly Grounded and UnderSpecific (4)", "verifiability_label": "1 (1)", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the authors 'only mention that the scope prompting method shows poor performance on GPT3.5turbo, but they do not provide any analysis of the underlying reasons behind this outcome.' This directly points out a lack of action on the authors' part regarding this specific finding. The reviewer also implies that the authors should perform this analysis, making the action clear and direct.", "grounding_specificity_rationale": "The reviewer mentions 'the scope prompting method' and 'GPT3.5turbo'. While 'GPT3.5turbo' is a specific element, 'the scope prompting method' is a more general description. The reviewer does not explicitly refer to a specific section, table, or figure in the paper where this analysis is lacking. The issue is the *lack of analysis* itself, not a specific reference to a part of the paper.", "verifiability_rationale": "The reviewer makes a claim that 'the authors only mention that the scope prompting method shows poor performance on GPT3.5turbo, but they do not provide any analysis of the underlying reasons behind this outcome.' This is a statement of opinion and a suggestion for improvement. While the reviewer implies that the analysis is lacking, they do not provide any external references or logical reasoning to support this claim. The claim is present, but the supporting evidence is missing.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors: 'they should provide an analysis of the underlying reasons behind this outcome'. This is a specific and constructive piece of feedback that directly addresses a weakness in the authors' work. The reviewer is not asking for clarification or a general question, but rather a specific improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for a justification for a specific limitation in the experimental setup (using only 10 datasets instead of 120). While they are not directly asking for an action to be taken, they are prompting for a clarification regarding a methodological choice. This can be considered an implicit action or a request for clarification, making it actionable.", "grounding_specificity_rationale": "The reviewer is pointing out a discrepancy between the paper's claim (120 datasets) and the actual implementation (10 datasets). This implies an attempt to understand the paper's methodology in relation to its stated scope. While the reviewer doesn't explicitly state *which* 10 datasets were used, the implication is clear, suggesting a level of grounding. However, the lack of explicit identification weakens the specificity.", "verifiability_rationale": "The reviewer is making a claim about the paper's methodology \u2013 that only 10 out of 120 datasets were considered and asking for a reason. This constitutes a claim. However, the paper itself doesn't explicitly state the reason for this limitation, nor does it provide external references to justify this choice. Therefore, the claim is not fully supported by evidence within the paper, making it 3.", "helpfulness_rationale": "The reviewer is highlighting a potential gap in the paper's reporting. While the paper presents results, the lack of explanation for the limited dataset comparison reduces the helpfulness for the reader trying to understand the generalizability of the findings. The reviewer is essentially pointing out a missing piece of information that would be valuable for understanding the paper's conclusions. While it doesn't directly suggest an improvement, it highlights a potential area for clarification, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer identifies two potential issues: the unclear calculation of the \u03bb parameter and the unclear meaning of ELLA not increasing sample efficiency in a COMBO environment. While the reviewer points out these problems, they do not explicitly state what action the authors should take to address them. The reviewer's questions are valid and point to potential areas of confusion, but they don't demand immediate action from the authors.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Page 9, lines 310313' and 'Page 8 lines 281285' when discussing the \u03bb parameter and the explanation of ELLA's sample efficiency, respectively. This clearly indicates that the reviewer has identified the specific sections of the paper being referred to. The reviewer also states the issues, such as 'how is \u03bb computed from step here?' and 'I don't quite understand what it means,' which specifies the nature of the problem. The reviewer's questions are directly related to the content of the mentioned sections.", "verifiability_rationale": "The reviewer states that 'performance and sample efficiency are sensitive to \u03bb parameters' and that 'it seems that performance and sample efficiency are sensitive to \u03bb parameters.' They also state that 'the process of calculating the \u03bb is done' and 'I don't understand how the process of calculating the \u03bb is done.' Furthermore, the reviewer claims that 'ELLA does not increase sample efficiency in a COMBO environment' and 'I don't quite understand what it means.' However, the reviewer does not provide any evidence, citations, or logical reasoning to support these claims. The reviewer is stating their own confusion and observations, but without any verification.", "helpfulness_rationale": "The reviewer raises valid concerns about the clarity of the \u03bb parameter calculation and the explanation of ELLA's sample efficiency. These concerns could potentially hinder the authors' ability to understand and improve their work. However, the reviewer does not provide any concrete information or solutions to these problems. The questions posed are relevant and point to potential issues, but without further information or clarification, the reviewer's comments are more like questions than actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the specific alternating direction method used. While this implicitly suggests an area for improvement (the lack of clarity about the method), it doesn't directly tell the author what to do or how to apply this information. The action of identifying the method is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer mentions 'alternating direction method' and 'minmin problem' generally, without specifying the exact section or table within the paper where this information is mentioned. This indicates weak grounding as the authors cannot confidently determine the referenced part. However, the issue (lack of clarity about the method) is somewhat specific.", "verifiability_rationale": "The reviewer states a fact ('It is briefly mentioned...') and then poses a question. The question itself is not a claim that needs verification. It's more of a request for clarification. Therefore, it's not 5 as it lacks a clear statement of what needs to be verified and how it should be supported.", "helpfulness_rationale": "The review point is a question prompting the authors to provide more information about the specific alternating direction method. While this can be helpful in encouraging the authors to be more precise, it doesn't directly guide them on how to improve their draft or suggest any specific changes. Therefore, it's 3 as it provides some context, but it lacks direct actionable feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer expresses doubt about the effectiveness of a specific algorithm and points out observed performance decreases in certain environments. While the reviewer identifies areas for improvement, the suggestions are implicit rather than explicit. For example, the reviewer states 'in MsPacman of Figure2, the algorithm shows slight performance decrease of Clipped DDQN' which is a specific observation, but doesn't explicitly state how to address this decrease. Similarly, the reviewer mentions 'in some environment such as WizardOfWor, Zaxxon RoadRunner and BattleZone, these algorithms seems converge into same solutions' which identifies a potential issue but doesn't provide a concrete solution. The statement 'Besides, the algorithm would cause the overestimate the true maximum value' is a general concern without specific action items.", "grounding_specificity_rationale": "The reviewer mentions 'lower bound double qlearning' and 'MsPacman of Figure2' which attempts to ground the comments in specific parts of the paper. However, the reference to Figure 2 is 1 as the actual Figure 2 is not provided in the text. The specific environments 'WizardOfWor', 'Zaxxon RoadRunner' and 'BattleZone' are grounded. The concern about 'overestimate the true maximum value' is 1 as it doesn't refer to a specific part of the paper.", "verifiability_rationale": "The reviewer states observations about the performance of the algorithm and the convergence behavior but does not provide any verifiable evidence or reasoning to support these claims. The statements are presented as 'suspicions' rather than wellsupported claims. For example, the statement 'in MsPacman of Figure2, the algorithm shows slight performance decrease of Clipped DDQN' is an observation without any supporting data or justification. Similarly, the statement 'in some environment such as WizardOfWor, Zaxxon RoadRunner and BattleZone, these algorithms seems converge into same solutions' is a generalization without specific evidence. The concern 'Besides, the algorithm would cause the overestimate the true maximum value' is also presented as a suspicion without any backing.", "helpfulness_rationale": "The reviewer's review point raises concerns about the performance and stability of a specific algorithm based on experimental observations. While the reviewer identifies potential issues, the review lacks concrete suggestions or actionable steps for the authors to address these problems. The suggestions are implicit, such as 'doubt about the effectiveness' and 'concern about similar convergence', rather than providing specific recommendations for improvement. The lack of concrete suggestions makes the review point less helpful in guiding the authors towards potential solutions."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment does not explicitly state how the lack of novelty impacts the authors' work or suggest specific actions they should take. While it identifies a potential issue, it doesn't provide concrete guidance on how to address it within the context of the authors' specific submission. The comment is somewhat vague and lacks detail on how to apply it to the authors' draft.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific aspect of the paper being addressed (e.g., a particular method, result, or section). It makes a general statement about the field of interpretability. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment refers to. The comment is not specific about what needs to be addressed in this general area of interpretability.", "verifiability_rationale": "The comment does not contain a claim that can be verified. It is a statement of opinion about the novelty of a technique, not a specific assertion that requires evidence. Therefore, it doesn't fit into the 'claim extraction' and 'verifiability verification' process described in the prompt.", "helpfulness_rationale": "The comment raises a valid concern about the novelty of the approach used for interpretation. However, it does not provide specific, actionable feedback on how the authors can address this limitation in their work. It lacks concrete suggestions or guidance on how to make their approach more novel or effective. While it points out a potential area for improvement, it doesn't offer a constructive critique of the authors' specific submission."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states their observation about the performance difference between DNN+MMA and vanilla DNN as lambda becomes small and provides a clear direction of expectation (approaching from above). They also reference specific figures (fig.34) which implies they are pointing to a specific part of the paper. This makes the reviewer's point very clear and actionable.", "grounding_specificity_rationale": "The reviewer refers to 'DNN+MMA' and 'vanilla DNN' in a general way, but they are clearly referring to the models being compared in the paper. While they don't explicitly point to a specific section or table, the context of comparing two models with a hyperparameter strongly implies they are referring to a specific part of the paper where these models and the hyperparameter are discussed. This can be considered weak grounding. The reviewer also specifies what is wrong: 'it becomes worse than vanilla DNN', which is specific to the performance metric. However, they don't provide a specific example of what needs to be addressed in this part.", "verifiability_rationale": "The reviewer states their expectation about the performance trend (approaching from above) as a claim that needs to be verified. However, they do not provide any justification or explanation for this expectation. They are simply posing a question based on their observation of the figures. There is no logical reasoning, common knowledge, or external references provided to support their claim.", "helpfulness_rationale": "The reviewer has a clear question about a specific experimental result and points to figures where this result is shown. However, they do not explain *why* they expect the performance to approach vanilla methods from below. This lack of explanation makes it difficult for the author to understand the issue and potentially debug their implementation or experimental setup. The reviewer is essentially challenging a baseline result without providing any context or guidance on how to address it. This makes the review point less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of comparison with earlier research work from 2020. This is an explicit action the authors should take. The reviewer also identifies the specific area of comparison and even names one specific paper (Taghipour and Ng (2016)). This makes the action quite concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions the absence of comparison with earlier research work from 2020. This directly identifies the specific part of the paper (the experimental evaluation or related work section) where this omission occurs. Furthermore, the reviewer names a specific paper (Taghipour and Ng (2016)), adding detail to the identified area. The reviewer also states the impact of this omission on the authors' understanding, which is a clear specification of the issue.", "verifiability_rationale": "The reviewer makes a claim about the paper's lack of comparison with earlier research work from 2020. This claim can be verified by examining the paper's related work section or experimental evaluation. While the paper might not explicitly state this limitation, the reviewer's statement is a valid observation that can be supported by external knowledge of the field.", "helpfulness_rationale": "The reviewer points out a clear deficiency in the paper: the lack of comparison with earlier research work from 2020. This deficiency directly suggests an actionable improvement for the authors: conducting or referencing such comparisons. The reviewer's statement is clear and identifies a concrete area for improvement, making it 3 in guiding the authors."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the conditions for Hoeffding's inequality (independent samples) and suggests the paper might be overlooking them. This is an explicit statement of a potential issue, making it actionable. The reviewer also implies that the authors should doublecheck their analysis, further strengthening the actionable nature of the comment.", "grounding_specificity_rationale": "The reviewer refers to 'Hoeffding's bounds' and 'samples,' which are directly related to the paper's analysis. They are also referencing specific parts of the paper (line 124125, though the exact content isn't provided, the line numbers suggest the context). This indicates a reasonable level of grounding. The reviewer is also very specific about the type of condition being violated (independence of samples) and connects it to the applicability of Hoeffding's inequality, making it highly specific.", "verifiability_rationale": "The reviewer presents a claim about the conditions for Hoeffding's inequality and the impact of stochasticity. This claim is supported by the conditions for Hoeffding's inequality and the general understanding of stochastic algorithms. However, the reviewer doesn't explicitly state *why* the paper might be overlooking these conditions, making it 3 rather than 5.", "helpfulness_rationale": "The reviewer directly points out a potential error in the paper's theoretical analysis, which is a valuable piece of feedback. The comment is clear and directly addresses a specific aspect of the paper's methodology. While the reviewer doesn't explicitly ask the authors to implement a specific fix, they imply that the authors should doublecheck their work, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly suggests adding a specific optimizationbased metalearning approach (MAML/implicitMAML) to Table1. This is a direct instruction on what improvement to make.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific section, table, or figure in the paper when making the suggestion. While they imply it relates to Table1, this is not a direct reference, making the grounding weak.", "verifiability_rationale": "The reviewer is making a suggestion rather than stating a claim that needs verification. The suggestion itself doesn't require logical reasoning or external references to be considered valid.", "helpfulness_rationale": "The reviewer suggests adding a metalearning approach to Table1. While the suggestion is not a direct solution, it points to a relevant area for improvement and is therefore relevant to the authors' work."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"I would like to see an ablation study...\" and provides a *potential* reason for it, \"e.g., fewshot examples for CoT might improve performance.\" This indicates a clear desire to understand the impact of different prompt choices on the model's performance. While the *specific* nature of the ablation study isn't detailed, the *action* of exploring different prompt choices is clear and actionable. The reviewer is directly addressing a potential weakness in the paper by suggesting a standard experimental technique.", "grounding_specificity_rationale": "The reviewer mentions \"an ablation study\" and \"prompt in this specific way,\" but lacks specificity. While the reviewer can infer that the ablation study is related to prompt engineering, they cannot pinpoint the exact prompt or the reasoning behind its selection. The example provided, \"fewshot examples for CoT,\" is a general concept and not a specific part of the paper being addressed. Therefore, the grounding is weak, and the specificity is underspecified.", "verifiability_rationale": "The reviewer states \"I would like to see an ablation study...\" which can be considered a claim (a suggestion for a specific type of experiment). While not a direct criticism of a claim, it's a suggestion for a *process*. However, the reviewer also states \"e.g., fewshot examples for CoT might improve performance.\" This is a statement that *could* be supported by external knowledge about prompt engineering, making it verifiable. The claim is not definitively proven, but it's a plausible hypothesis.", "helpfulness_rationale": "The reviewer's comment directly addresses a common weakness in research papers: the lack of thorough experimentation and justification for methodological choices. By suggesting an ablation study, the reviewer is providing a concrete and actionable suggestion to improve the rigor and completeness of the work. This is a valuable and helpful comment for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1: Not Verifiable", "helpfulness_label": "2", "actionability_rationale": "The comment points out a potential issue with terminology but doesn't explicitly state what the author should do. It suggests a clarification or a different approach to using the terms. The action is implied but not directly stated.", "grounding_specificity_rationale": "The comment mentions 'causal mechanisms' and 'causality', indicating some level of grounding. However, it doesn't specify *which* part of the paper or *how* these terms are being used. The specificity is limited to the concepts themselves, not their application within the paper.", "verifiability_rationale": "The comment is a suggestion or recommendation, not a claim that requires verification. It doesn't present a statement that needs to be proven or supported by evidence. Therefore, it doesn't fit the criteria for verifiability.", "helpfulness_rationale": "The comment raises a valid point about the distinction between 'causal mechanisms' and 'causality'. However, it doesn't provide concrete guidance on how the author should use these terms. It's a suggestion for improvement rather than a detailed explanation or actionable advice. While it identifies a potential issue, it doesn't fully address the author's needs for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they would like a discussion of a specific paper and a specific concept within that paper. The suggestion is clear and directly addresses a potential area for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions a specific paper ('On the Complexity of Learning with Kernels') and a specific concept within that paper ('kernel learning using lowrank approximation'). This provides strong grounding as the authors can directly identify the referenced part. The comment also specifies what needs to be addressed in this part \u2013 a discussion of the theoretical results.", "verifiability_rationale": "The reviewer's suggestion to discuss the results in the mentioned paper can be considered a claim that this discussion is valuable. The reasoning supporting this claim is the general principle that related work is important for a comprehensive literature review. While not explicitly providing examples of how the results relate, the suggestion is logically sound and verifiable by reading the paper.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors. They are directly pointing out a missing piece of related work that, if included, would significantly improve the paper's context and completeness. This is a 5 suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point is a question and a request for clarification. While it could be framed as an explicit instruction (e.g., 'Can you please explain...'), the current form is primarily a question, making it difficult to pinpoint an explicit action the author should take. The reviewer is asking for clarification on the assumptions of PCA and the significance of the results, but the exact action or step the author should take is not explicitly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'PCA to reduce interaction count' and asks about the 'assumptions met'. This provides a clear grounding point in the author's work. The request for clarification about 'how well the assumptions are met' is also quite specific.", "verifiability_rationale": "The review point does not contain a claim that needs verification. The reviewer is seeking clarification and understanding, not making a statement that requires justification or evidence. Therefore, it does not fit the criteria for verifiability.", "helpfulness_rationale": "The review point directly addresses potential weaknesses for the author, such as the incremental novelty of the method and the unclear significance of the results. By asking for clarification on the assumptions of PCA, the reviewer is encouraging the author to engage with the limitations of their approach. This feedback is directly relevant to improving the paper's impact and addressing concerns about the validity of the results. The request for clarification is a valuable piece of feedback that can help the author refine their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states a weakness ('not stateoftheart') and suggests a concrete action (comparison with relation extraction/generation models). This is an explicit action with a clear goal.", "grounding_specificity_rationale": "The reviewer mentions 'fewshot RC models,' which partially grounds the reference. However, the suggestion to compare with 'relation extraction/generation models' is general and doesn't specify a unique part of the paper being addressed. The authors cannot confidently determine which part the comment addresses, and the comment does not specify what needs to be addressed in this part.", "verifiability_rationale": "The reviewer makes a claim ('the fewshot RC models... are not stateoftheart') without providing any supporting evidence or justification within the review point. There is no logical reasoning, common knowledge, or external references provided to support this claim.", "helpfulness_rationale": "The reviewer offers a suggestion ('how does the performance compare...'). While there is a suggestion, it is vague and lacks specifics on how to compare the performance. The authors do not know what they should do after reading the comment."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a limitation regarding the scope of the results in section 4. It clearly identifies the *type* of network (shallow fullyconnected ReLU networks) and the *nature* of the limitation (apply only to). This is actionable for the authors as it helps them understand the constraints of the work and potentially extend it to other network architectures. The reviewer is directly identifying a modification the authors should consider.", "grounding_specificity_rationale": "The comment explicitly mentions 'section 4\" of the paper. This is a clear and specific identification of the part of the work being addressed. The reviewer is not making a general comment about the paper's structure but rather pointing out a limitation *within* section 4. This strong identification of the section grounds the comment well.", "verifiability_rationale": "The comment itself does not contain a claim in the sense of an opinion or suggestion. It is a factual statement: \"the results in section 4 apply only to...\". While this statement is true and verifiable, the review point itself does not provide any logical reasoning, common knowledge, or external references to support this fact. Therefore, it is not considered '1' or '5'. It falls under the category of 'X' (X) as it is a factual statement without accompanying justification within the review point.", "helpfulness_rationale": "The comment is 5 because it identifies a clear limitation regarding the scope of the results. By pointing out that the findings apply only to shallow fullyconnected ReLU networks, the reviewer provides the authors with a concrete direction for future research or a specific area where the work might need to be extended or contextualized. The comment is actionable and directly addresses a potential constraint, making it a valuable piece of feedback. It guides the authors to focus their attention on a specific aspect of their work and potentially explore the generalizability of their findings."}
{"actionability_label": "1", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states 'no results were shown' and asks 'could the authors speak a bit about what was observed?'. This is a request for information, not a critique of what should have been done. There is no actionable step the authors should take *now* based on this comment. They are being asked to provide more information, which is a request, not an action.", "grounding_specificity_rationale": "The reviewer mentions 'the discussion of using sequential MCB vs a single MCT layers for the decision head'. While they don't provide a specific section number, the mention of 'MCB' and 'MCT' is quite specific. They are pointing to a *conceptual* comparison within the method description. However, they *don't* tell the authors *where* in the paper this discussion took place or what specific aspect of the comparison they observed. The reference is implicit.", "verifiability_rationale": "The reviewer's comment is a request for information ('could the authors speak a bit about what was observed?'). It doesn't make a claim about what *should* have happened, what *is* happening, or what *isn't* happening. It's a question seeking clarification, not a statement that requires verification.", "helpfulness_rationale": "The comment is a request for more information. While it encourages the authors to provide more detail, it doesn't *guide* them on what to do or *identify* a problem. It's a call for clarification, not a diagnostic or prescriptive critique. There is no clear indication of a problem or a solution being offered."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that the choice of 20 distribution sets is unclear. While the reviewer knows the number is 20, they don't understand the reasoning behind it. This makes the information provided as an action (knowing the number) 3, but the lack of justification makes it less helpful in terms of understanding the underlying decision. However, the reviewer's request to control the number makes the *ability* to manipulate it more concrete.", "grounding_specificity_rationale": "The reviewer's comment is general and does not specify which part of the paper or process is unclear regarding the choice of 20 distribution sets. They are broadly stating that it is not clear. Therefore, the information is 1 in a specific section, table, or unique aspect of the paper.", "verifiability_rationale": "The reviewer suggests that the number of distribution sets can be controlled. This is a suggestion or recommendation, which implies a claim. However, the reviewer does not provide any justification or references to support this claim. The suggestion is presented without any logical reasoning, common knowledge, or external references, making it 1 at this point.", "helpfulness_rationale": "The reviewer's comment is vague and lacks specific details. They are asking a question about the choice of 20 distribution sets without providing any context or explanation. This leaves the authors with ambiguity and a request for more information, making the review not particularly helpful in addressing their needs."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the perplexity experiments are carried out on 'obsolete language models' and suggests that the authors should use 'transformerbased (masked) language models'. This is an explicit action, as the reviewer directly points out the problem and suggests a solution. However, the action is vague because the reviewer does not specify which transformer models should be used or how the experiments should be adapted. The lack of detail makes it difficult for the authors to directly apply this action.", "grounding_specificity_rationale": "The reviewer identifies a specific problem: the perplexity experiments being conducted on 'obsolete language models'. This clearly points to a specific part of the paper (the perplexity experiments section) and highlights an issue with it. Furthermore, the reviewer suggests a specific solution: using 'transformerbased (masked) language models'. This suggests a concrete change to the methodology. Therefore, the reviewer not only identifies the area being addressed but also specifies the nature of the problem and the proposed solution, making it highly specific.", "verifiability_rationale": "The reviewer makes a claim: 'The perplexity experiments are carried out on obsolete language models...'. This is a factual statement about the methodology. While the reviewer doesn't provide explicit evidence within the review point itself to definitively prove the models are obsolete, they present it as a premise for their suggestion. The suggestion itself, to use transformer models, is a recommendation based on current trends. The claim is supported by the reviewer's statement of using 'ngram HMM, RNN' and suggesting 'transformerbased (masked) language models', which implies a contrast and a justification for the change. However, the claim itself doesn't have strong external references or logical reasoning to definitively prove the models are obsolete within the review point itself.", "helpfulness_rationale": "The reviewer's comment is 5 because it directly addresses a potential weakness in the paper's methodology. By pointing out the use of obsolete language models for perplexity experiments and suggesting the use of more current transformer models, the reviewer provides a clear and actionable direction for the authors. This directly addresses the concern of aligning the paper with current NLP trends, which is likely a significant point of interest for the authors. The suggestion is concrete and directly relevant to improving the paper's timeliness and impact."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the problem of estimating mu and suggests a potential solution (it *should* be estimable). While the suggestion is not a concrete action, it indicates an awareness of a potential issue and a desire for clarification. The reviewer also mentions the difficulty of estimation, which implies an action to address it.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"mu\" and \"proportion of missing observations\" and states that it is \"estimated.\" This clearly identifies the specific aspect of the paper being addressed. The mention of \"estimated\" also specifies the nature of the issue.", "verifiability_rationale": "The reviewer states a claim about the difficulty of estimating mu but does not provide any specific method, formula, or citation to support this claim. Therefore, it is 1 as is. The reviewer's suggestion that it *should* be estimable is a potential action rather than a direct assertion of verifiability.", "helpfulness_rationale": "The reviewer points out a lack of clarity regarding the estimation of mu. While they offer a potential solution (it *should* be estimable), this is a suggestion for improvement rather than a direct solution to the identified problem. The lack of clarity is the primary impact on the authors' ability to proceed."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests a change to the experimental setup by proposing to evaluate performance as a function of the distance of initialization M^0 to the ground truth M^*. This is a clear and direct action. The reviewer proposes a method to implement this by varying the distance 'c' and reporting the performance. This provides a concrete action for the authors to follow.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'distance of initialization M^0 to the groundtruth M^*' and uses the Frobenius norm 'c' to quantify this distance. They also suggest 'randomly sample a matrix M^0 so that M^0  M^* _F < c' and 'report the performance accordingly'. This demonstrates a clear understanding of the parameters and the desired outcome, making the grounding fully specific.", "verifiability_rationale": "The reviewer provides a clear methodology for their suggestion. They specify the range of 'c' values (0.01:0.01:0.1), the process of random sampling, and the desired output (performance metrics). This methodology is logically sound and provides a clear framework for the authors to replicate and evaluate the suggestion. The reviewer also anticipates the expected outcome, stating that 'the mean error and variance increases as the quality of initialization decreases', which adds further verifiability.", "helpfulness_rationale": "The reviewer's suggestion is highly relevant to understanding the sensitivity of the method to the initialization of M^0. By evaluating performance as a function of the distance to the ground truth, the authors can gain insights into the robustness of their method and potentially identify strategies to improve initialization. This is a valuable and actionable piece of feedback that directly addresses a potential area for further analysis and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a potential simplification in the Frobenius norm definition by pointing out the unnecessary absolute value. It also identifies the specific location (line 77) where this redundancy might exist. The reviewer suggests removing the absolute value as a concrete action.", "grounding_specificity_rationale": "The comment explicitly references 'line 77' in the Frobenius norm definition, providing a precise location. It also specifies the reason for the potential removal of the absolute value: 'because tensor entries are real numbers'. This precise identification of the location and the reason demonstrates high grounding specificity.", "verifiability_rationale": "The comment contains a claim that the absolute value is unnecessary. However, it does not provide a reference or a detailed explanation of why tensor entries are real numbers in this specific context. While the claim is likely true, the lack of explicit justification makes it 3 rather than 5.", "helpfulness_rationale": "The comment is 5 because it points out a potential simplification in a mathematical definition, which could save the author time and effort in their calculations. The suggestion is clear, specific, and actionable. The reviewer directly addresses a potential point of confusion or inefficiency."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the lack of highprobability bounds and suggests using ensemble methods. This is a clear, actionable suggestion aimed at improving the results. The reviewer identifies a weakness (lack of highprobability bounds) and proposes a solution (ensemble methods).", "grounding_specificity_rationale": "The reviewer states 'Only bounds in expectation are provided' and then suggests 'highprobability bounds'. While the *concept* of highprobability bounds is implied, the reviewer doesn't explicitly *mention* which specific part of the paper (e.g., the bounds calculation, the experimental setup) lacks this. The suggestion of ensemble methods points to a potential issue with the current methodology, but the specific section isn't named. The reviewer can identify the *type* of bound they want, but not the exact location within the paper.", "verifiability_rationale": "The reviewer states a fact ('Only bounds in expectation are provided') and then offers a solution and a potential improvement ('Would it be possible to get highprobability bounds? For instance by using ensemble methods...'). This is a clear claim supported by the context and a suggestion for improvement. The reviewer provides a logical reasoning for why highprobability bounds are desirable and suggests a concrete method (ensemble methods) to achieve them.", "helpfulness_rationale": "The reviewer clearly identifies a limitation of the current approach (lack of highprobability bounds) and offers a concrete solution (highprobability bounds via ensemble methods). This directly addresses a potential weakness and suggests a way to improve the results. The reviewer provides a clear and actionable suggestion. The claim about the lack of highprobability bounds is verifiable by examining the current methodology. The suggestion to use ensemble methods is a logical next step. The reviewer provides a clear and actionable suggestion."}
{"actionability_label": "Partially Explicit", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states their lack of expertise in pruning, which implicitly suggests a lack of clarity in the paper's motivation or results. However, the reviewer does identify the area of pruning as the focus, providing some level of explicitness. The criticism that the results are 'less impressive' and the suggestion to evaluate 'actual latency on target device, the memory consumption during the inference time and the actual network size' are not explicitly stated in the paper, making the criticism somewhat vague. Therefore, the comment is partially explicit but somewhat vague in its actionable suggestions.", "grounding_specificity_rationale": "The reviewer's statement about the motivation being 'quite good' is a subjective assessment and doesn't directly address the grounding of a specific part of the paper. However, the reviewer *does* specify the *aspects* they believe the results should be evaluated on (latency, memory, network size). This provides some level of specificity regarding the *type* of evaluation needed, even though the paper doesn't explicitly mention these sections or tables. Therefore, the comment is somewhat specific in identifying the areas of evaluation that are missing.", "verifiability_rationale": "The reviewer presents a claim: 'the results seem to be less impressive' and 'I believe the results should be evaluated from more aspects'. However, the reviewer does not provide any external references or logical reasoning to support these claims within the review point itself. The claims are presented as beliefs without justification. Therefore, the claims are not supported by the review point.", "helpfulness_rationale": "The reviewer's comment is somewhat vague. While they identify a potential weakness in the paper's evaluation (the lack of detailed evaluation aspects), they don't provide specific, actionable suggestions for improvement. The suggestion to evaluate more aspects is a general comment and doesn't offer concrete guidance on how to enhance the paper. Therefore, the comment is not very helpful in terms of providing specific directions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1: Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a discrepancy between the lower and upper bounds, which can be considered an explicit action or statement. However, it does not provide concrete steps or specific actions on how to address this gap. The suggestion to consider the independence number is a potential action but lacks detail on how to implement it. Therefore, while it points to a problem, the lack of specific guidance makes it partially actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'lower bound,' 'upperbound,' 'independence number,' 'adaptive adversary,' and 'counterfactual feedback.' These terms clearly refer to specific aspects of the theoretical analysis and related concepts within the paper. While it doesn't pinpoint a specific section or table, the combination of these terms strongly suggests a focus on these specific areas. Therefore, the grounding is strong, although it doesn't provide an exact location. The mention of 'in particular' for some graphs further emphasizes the specificity of the concern.", "verifiability_rationale": "The review point states a fact about the relationship between different bounds. It doesn't present a claim that requires verification or provide new evidence. It's more of a critique or suggestion for improvement based on existing results. Therefore, it doesn't contain a claim that can be verified, making it not verifiable.", "helpfulness_rationale": "The review point identifies a potential issue with the existing bounds and suggests considering the independence number. While this is a valuable observation, it doesn't provide specific, actionable steps for the authors to take to address the gap. It's a suggestion for improvement but lacks concrete guidance on how to implement it. Therefore, it's 3 in pointing out a problem but lacks the depth of a fully helpful suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their concern about the novelty of the work and asks specific questions to understand the differences between their paper and the cited work. The questions are clear and directly address the potential lack of significant methodological contribution. This makes the reviewer's point **explicit** and the action **concrete** as they are asking for a direct comparison.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific paper (https://aclanthology.org/2021.findingsacl.57.pdf) for comparison. This demonstrates a clear grounding of the comment in the relevant work. Furthermore, the reviewer directly asks a question about the differences in methodology, making the specificity high as they are pinpointing the exact area of comparison.", "verifiability_rationale": "The reviewer states a claim: \"Novelty seems incremental to me.\" They then provide suggestions for how to verify this claim by asking questions about the differences in methodology and the novelty of the approach. While the reviewer doesn't provide direct evidence within the review point itself, the *act* of asking these questions indicates an attempt to verify their claim by prompting the authors to provide more information about their work and the cited work. This makes the claim 3.", "helpfulness_rationale": "The reviewer's point is helpful because it directly addresses a potential weakness in the authors' work \u2013 the lack of clear novelty. By asking specific questions, the reviewer encourages the authors to clarify their contributions and potentially engage in a more detailed comparison with related work. This feedback, while not directly pointing out a flaw, is valuable for guiding the authors to improve their manuscript."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a problem: 'In the reported ablation studies in Table 2, for CUB and SOP datasets, the complete loss function performed even worse than those with some terms missing. That does not appear to make sense.' This is a clear and direct identification of a potential flaw in the experimental results. The reviewer also mentions 'why' this is the case, indicating an attempt to understand the underlying issue. The reviewer's statement is a direct identification of a problem and a request for explanation, which is an actionable step for the authors.", "grounding_specificity_rationale": "The reviewer provides specific details about the issue. They mention 'the reported ablation studies in Table 2', 'CUB and SOP datasets', and 'complete loss function performed even worse than those with some terms missing'. This demonstrates a strong grounding of the issue within the paper's content and a clear identification of the specific experimental setup and datasets involved. The reviewer is not just stating a general problem but pinpointing a specific discrepancy in a particular section of the paper.", "verifiability_rationale": "The reviewer makes a claim: 'In the reported ablation studies in Table 2, for CUB and SOP datasets, the complete loss function performed even worse than those with some terms missing. That does not appear to make sense.' This claim is verifiable because the reviewer points to the specific ablation studies in Table 2 and the observed counterintuitive result. While the reviewer doesn't provide the data, they *claim* to see this discrepancy, which can be verified by examining Table 2. The reviewer's statement is a clear claim that can be supported or refuted by examining the referenced table.", "helpfulness_rationale": "The reviewer provides a helpful insight by pointing out a potential issue with the ablation studies on the CUB and SOP datasets. They highlight the unexpected result where the complete loss function performs worse than the partial ones. This is a valuable piece of information for the authors to investigate and potentially resolve. The reviewer's comment directly points to a specific area of concern within their own experimental results, which can guide further analysis and debugging."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the comment asks for clarification on a specific part of the abstract: 'what does this mean? The abstract should be more highlevel. Such technicalities are not necessary.' This constitutes an explicit action and a concrete suggestion on how to improve the abstract. The reviewer identifies the need to clarify the interaction between the lowrank feature subspace, attacked samples, and assumptions. The suggestion to make the abstract more highlevel and remove technical details directly addresses the identified weakness.", "grounding_specificity_rationale": "The reviewer identifies the unclear section of the abstract and specifies the nature of the confusion: 'with a lowrank feature subspace, a small number of attacked samples, and other mild assumptions'. This allows for precise identification of the problematic area. The reviewer also identifies the need for clarification on the *interaction* between these elements, adding further specificity to the identified issue.", "verifiability_rationale": "The reviewer identifies a weakness in the abstract ('what does this mean?') and provides a suggestion for improvement ('The abstract should be more highlevel and remove technical details'). This constitutes a claim that is supported by a clear reasoning and a concrete suggestion. The reviewer identifies a specific area for improvement and provides a specific solution, making the claim verifiable.", "helpfulness_rationale": "The reviewer provides a specific and actionable suggestion for improvement: 'The abstract should be more highlevel and remove technical details.' This directly addresses the identified weakness and offers a clear path for the authors to follow. The suggestion is specific and directly related to the identified problem. The reviewer's comment is not just a critique; it's a constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point is a suggestion for future work, not a prescription for improvement. It doesn't tell the authors *how* to get these results or what steps they should take.", "grounding_specificity_rationale": "The review point is vague. \"Other modalities\" is a broad term and doesn't point to a specific section, table, figure, or unique aspect of the paper. There's no indication of what \"other modalities\" refers to in the context of the paper.", "verifiability_rationale": "The review point is a suggestion for future work, not a claim that needs verification. There's no assertion that something is correct or incorrect in the current work.", "helpfulness_rationale": "The review point is a suggestion for future work and doesn't directly address any identified weaknesses or provide actionable steps for the authors to take based on this suggestion. It's more of a comment on the current work's limitations rather than a constructive critique."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the paper 'defines and creates a fewshot situation for graph link prediction, but the proposed method does not consider how to effectively use \u201cfewshot\u201d and how to guarantee the trained model can be generalized well to new tasks with 0/few training steps.' This clearly identifies an actionable shortcoming: the lack of a concrete implementation or discussion on how the fewshot learning framework is practically utilized and its effectiveness is ensured. The reviewer directly points out a missing piece of information that the authors should provide.", "grounding_specificity_rationale": "The reviewer states 'This paper defines and creates a fewshot situation for graph link prediction, but the proposed method does not consider how to effectively use \u201cfewshot\u201d and how to guarantee the trained model can be generalized well to new tasks with 0/few training steps.' While the reviewer identifies the *topic* of the paper (fewshot learning for graph link prediction) and the *specific area of concern* (the application of fewshot and generalization), they do not explicitly name a specific section, table, figure, or unique aspect of the paper being addressed. The reference to 'this paper' is general, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer makes a claim: 'This paper defines and creates a fewshot situation for graph link prediction, but the proposed method does not consider how to effectively use \u201cfewshot\u201d and how to guarantee the trained model can be generalized well to new tasks with 0/few training steps.' This is a statement of what the paper lacks. However, the reviewer does not provide any logical reasoning, examples, or external references to support *why* this is a problem or *how* it impacts the model's performance. The claim is presented as a factual observation rather than a welljustified assertion.", "helpfulness_rationale": "The reviewer clearly identifies a specific area for improvement in the paper: the lack of explanation on how the fewshot learning method is applied and how the model is guaranteed to generalize. This provides the authors with a concrete target for their revision. The reviewer directly points out a missing element that is crucial for understanding and replicating the proposed method. By addressing this, the authors can significantly improve the clarity and reproducibility of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a weakness ('naive') but doesn't explicitly state what is naive or how to improve the GP usage. It's a general statement about the method's simplicity and a reference to more complex models, but lacks concrete steps for the author to take.", "grounding_specificity_rationale": "The comment refers to 'the way of using GP' generally, without specifying a particular section, table, figure, or unique aspect of the paper being addressed. It mentions the GP community and related models but doesn't pinpoint the exact location of the issue.", "verifiability_rationale": "The comment contains a claim ('the GP method is kind of straightforward and naive') and provides some implicit justification by mentioning 'dynamical modeling' and 'Gaussian Process Dynamical Model'. While it doesn't offer specific examples or references, it does state a point that could be verified by comparing the author's method to established models.", "helpfulness_rationale": "The comment identifies a potential area for improvement ('straightforward and naive GP usage') and points to related work ('dynamical modeling', 'Gaussian Process Dynamical Model'). It offers a direction for the author to explore, even if it lacks specific actionable steps, making it more than just a negative comment."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their disagreement with a specific claim in the appendix (D.4) regarding the necessity of smaller architectures for language models compared to GANs to avoid overfitting. They also ask a very specific question about whether dropout is applied to the hidden states, making the actionable part highly concrete.", "grounding_specificity_rationale": "The reviewer directly references section D.4 of the appendix, providing strong grounding. They also ask a very specific question about the regularization method, further enhancing the specificity of the criticism.", "verifiability_rationale": "The reviewer makes a claim that the baseline models are not properly regularized and provides a counterexample (Zaremba et al. 2014) and a specific question related to the regularization method (dropout on hidden states), making the claim verifiable but not definitively proven.", "helpfulness_rationale": "The reviewer's point is direct and constructive, pointing out a specific issue in the appendix and asking a targeted question. They offer a potential explanation (overfitting) and a direction for the authors to investigate (checking regularization), making the feedback 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment mentions 'ablations' and 'previous sections' and criticizes the writing in that part. While it implicitly points to a potential issue, it doesn't explicitly state what needs to be done or how to apply the suggestion. The lack of a clear action makes it difficult for the authors to take any specific steps.", "grounding_specificity_rationale": "The reviewer identifies the specific part of the paper as 'that specific part' where the ablations are mentioned. This indicates some level of grounding as they are referring to a specific area. However, they do not specify *what* is hard to locate within that part, making the grounding not fully specific.", "verifiability_rationale": "The comment contains a claim ('Some of the ablations mentioned in previous sections are hard to locate in the following contents') but does not provide any evidence or justification for this claim. There is no logical reasoning, common knowledge, or external references to support the statement, making it 1.", "helpfulness_rationale": "The review point criticizes the writing in a specific part of the paper but does not provide any specific suggestions or guidance on how to improve it. The criticism is general and lacks actionable feedback, making it not helpful for the authors to make concrete changes."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer indicates a concern about the differential privacy application, suggesting it needs more work. However, the action is implicit, meaning the reviewer implies improvement without explicitly stating the specific actions to be taken.", "grounding_specificity_rationale": "The reviewer refers to the 'differential privacy application' in general, without specifying a particular section or detail. This lack of specificity makes it difficult to understand exactly what needs improvement.", "verifiability_rationale": "The reviewer makes a judgment about the 'halfbaked' nature of the differential privacy application. However, this judgment is not supported by any evidence, examples, or logical reasoning within the review point.", "helpfulness_rationale": "The reviewer points out a general issue with the differential privacy application but doesn't provide specific, actionable steps or details on how to improve it. The feedback is more of a direction than a concrete solution."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests that 'just using robotic manipulation could be more appropriate' and provides a specific alternative ('bimanual manipulation'). This indicates a clear action the authors should take, making the comment actionable. The reviewer is directly pointing out a potential area for improvement in the methodology's specificity.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'robotic manipulation' and further specifies it with 'bimanual manipulation'. This demonstrates strong grounding as the reviewer not only identifies the area of concern but also provides a specific alternative, indicating a clear understanding of the terminology and its potential implications.", "verifiability_rationale": "The comment is more of a suggestion for clarification rather than a claim requiring verification. While it points out a potential issue, it doesn't present a definitive statement that needs to be proven. Therefore, it doesn't fit neatly into 'verifiable' or 'not verifiable'.", "helpfulness_rationale": "The reviewer directly addresses a potential lack of clarity regarding the methodology's specificity and offers a concrete alternative. This is a clear and actionable piece of feedback that directly helps the authors improve their draft by clarifying their methodology's scope."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem of comparing Geffects of unlearning objectives studied in isolation and highlights its potential impact on the generalizability of the results. The action is clear: the authors should be cautious about comparing isolated Geffects. The reviewer also identifies the potential for misinterpretation of the results. The action is concrete and directly addresses a methodological concern.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Section 4' and the 'Geffects of each unlearning objective independently and in isolation'. This is a precise and accurate identification of the relevant part of the paper and the specific issue being addressed. The grounding is literal and unambiguous.", "verifiability_rationale": "The reviewer raises a concern about the comparability of Geffects but does not provide any evidence, citations, or logical reasoning to support this claim. The statement is presented as a concern or suggestion, without any backing. The reviewer is not claiming that the Geffects are definitively wrong or based on established literature. The evidence provided is purely speculative.", "helpfulness_rationale": "The reviewer identifies a potential methodological limitation in the paper, specifically the study of Geffects in isolation. This is a valid concern that could affect the interpretation of the results and the generalizability of the conclusions. The reviewer provides a clear explanation of the potential issue and its implications for the authors. While the reviewer does not offer a solution, the identification of a potential weakness is 5 for the authors."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "4 (5)", "verifiability_label": "2 (2)", "helpfulness_label": "4 (4)", "actionability_rationale": "The reviewer points out a specific observation in the experimental results (UNIFORM not always better in 1shot) and asks a question. While this points to a potential area for improvement, it doesn't explicitly state what action the authors should take. The reviewer could have been more direct in suggesting an investigation or a specific change to the method.", "grounding_specificity_rationale": "The reviewer mentions ' Advantage of UNIFORM over other procedures is not consistent. The tables show that UNIFORM does not always offer a clear advantage over the results, especially in the 1shot setting.' This statement clearly identifies a specific part of the paper (the results related to UNIFORM in the 1shot setting) and what is wrong with it (lack of consistent advantage). The reviewer also asks a question, which implies a desire for clarification on this specific aspect. Therefore, the grounding is good.", "verifiability_rationale": "The reviewer states an observation about the results without providing a clear explanation or justification for why UNIFORM is not as effective in the 1shot setting. While the reviewer asks a question ('Do the authors have a theory for why the method is not as effective on the 1 shot setting?'), the point itself lacks a verification method. The reviewer identifies a claim (the inconsistency) but doesn't provide evidence or reasoning to support it.", "helpfulness_rationale": "The reviewer identifies a specific weakness in the experimental results (UNIFORM's inconsistent performance in the 1shot setting) and asks a question to encourage further investigation. This provides some value to the authors by highlighting an area that needs attention. However, the point lacks a clear suggestion of what the authors *should* do to address this issue. The reviewer acknowledges the clarity and design of the experiments, which suggests they understand the overall quality but are focusing on a specific limitation."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the 'reason why' information value is a stronger predictor, rather than explicitly stating an action or improvement the authors should take. While the question is relevant, it doesn't directly guide the authors on how to improve their work, making it less actionable in the defined sense. The reviewer is prompting for further investigation rather than providing a concrete step.", "grounding_specificity_rationale": "The reviewer's question about the 'reason why' and 'mechanism' is specific to the claim about information value being a stronger predictor. However, they do not explicitly identify a specific part of the paper (e.g., a section, table, or figure) where this mechanism is discussed. The grounding is present in the *topic* of the question but not in a precise reference to a specific element of the paper.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question and suggesting exploring linguistic theories. Since there is no assertion of a fact or opinion that needs supporting evidence, the verifiability score is not applicable and should be marked as 'X'.", "helpfulness_rationale": "The reviewer's suggestion to explore linguistic theories to understand the 'reason why' information value is a valuable and actionable suggestion for the authors. It directly guides them towards a deeper analysis and potential improvements in their understanding of dialogue. While it doesn't provide a specific 'howto' step, it offers a concrete direction for further work, making it 3 in the context of guiding research and analysis."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states they want to know the 'biggest takeaways' from the AutoML findings, implying they can identify an action: to read the relevant section and extract these takeaways. However, the phrase 'unfortunately the authors did not spend much time commenting on these aspects' suggests the action is not fully explicit or concrete enough for the reviewer. The reviewer understands the *what* (AutoML, architecture design) but the paper's discussion of *how* and *why* these aspects are important is lacking, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer clearly points to the specific area of 'AutoML approaches' and 'design of new network architectures' when stating the paper didn't spend much time commenting on these aspects. This indicates the authors can identify the specific part of the paper being addressed. The reviewer also claims the authors did not spend much time *commenting on these aspects*, which implies the paper's discussion is not specific enough regarding the takeaways from AutoML for future architecture design.", "verifiability_rationale": "The reviewer states the authors did not spend much time commenting on the 'aspects' related to AutoML. This implies the reviewer believes the paper's discussion lacks sufficient justification or support for these claims. The claim itself (AutoML is relevant for future architecture design) is not inherently 1, but the paper's *discussion* of this claim is not supported by evidence or reasoning, making it 1.", "helpfulness_rationale": "The reviewer explicitly states they 'unfortunately the authors did not spend much time commenting on these aspects' but then immediately claims, 'I would find these aspects interesting and potentially useful for future work.' This indicates the reviewer has identified a weakness in the paper (lack of discussion on AutoML) and believes this weakness provides a valuable opportunity for future research. The claim is present, and the reviewer believes it has potential, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the variable T_a(t) is used in Section 3.1 but is only defined in Section 4. This is an explicit action pointing out a discrepancy. While the reviewer doesn't directly state what should be done (i.e., define T_a(t) in Section 3.1), the action is clear and actionable. The reviewer implies the need for a definition in the section where the variable is first used.", "grounding_specificity_rationale": "The review point explicitly mentions the sections where the issue arises and where the definition is located. It states: 'T_a(t) is used in Section 3.1, but only defined in Section 4.' This is both weakly grounded because the authors can infer the relevant parts (the sections where T_a(t) is used and defined). However, it is also specific because the reviewer clearly identifies the variable T_a(t) and the sections involved. The lack of clarity in how to define T_a(t) in Section 3.1 contributes to the 'somewhat' label.", "verifiability_rationale": "The review point makes a claim: 'T_a(t) is used in Section 3.1, but only defined in Section 4.' This claim is 1 because the reviewer doesn't provide any evidence or reasoning to support this claim. They simply state it as an observation. There's no logical reasoning, common knowledge, or external references provided to back up the claim that T_a(t) is used in Section 3.1.", "helpfulness_rationale": "The review point points out a potential issue with the paper's structure and clarity. It highlights a lack of definition for a variable used in an earlier section. This is a helpful comment because it identifies a potential source of confusion for the authors and suggests a concrete improvement (defining the variable earlier). While the reviewer doesn't provide the definition, they clearly point out where the problem lies."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitation of using only 'two typical games' and suggests testing on 'more complex problems, especially those with larger depth...'. This is an explicit action to identify a weakness. The suggestion to test on more complex problems with larger depth is concrete, indicating a clear action to be taken.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'ReBeL's performance' and 'more complex problem' as areas for improvement. This is a clear identification of the specific part of the paper being addressed. The reviewer also specifies the nature of the complex problems as 'bigger depth' and mentions the potential impact on 'huge inputs', adding to the specificity.", "verifiability_rationale": "The reviewer makes a claim about the limited scope of the experiments and its potential impact on the generalizability of the results. However, the reviewer does not provide specific examples of where the current experiments are lacking, how increased depth would cause issues with value and policy functions, or cite any specific literature to support this claim. The reasoning is present at a high level, but lacks concrete evidence.", "helpfulness_rationale": "The reviewer clearly identifies a significant limitation in the experimental evaluation and provides a concrete suggestion for improvement by testing on more complex problems. This actionable feedback is directly helpful for the authors to understand the scope of their work and how it might be extended."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states the paper's contribution is 'an incremental advancement in efficiency over the TACTiS approach.' While this identifies a potential improvement, it doesn't explicitly recommend an action or provide concrete steps for the authors to take to achieve this. The reviewer focuses on the *what* (efficiency improvement) and *comparison* (TACTiS), but lacks a clear *how* or *what to do next*. The statement is explicit about the nature of the advancement but implicit in how to implement it.", "grounding_specificity_rationale": "The review point mentions 'the TACTiS approach' as a point of comparison. This is a specific part of the paper being referenced. The reviewer explicitly names a specific part of the paper being compared, which falls under the definition of 'Full Grounding'. However, the reviewer does not specify *what* aspect of the TACTiS approach needs improvement or *what kind* of efficiency improvement is being suggested. The specificity lies in identifying the comparison point but not detailing the improvement itself.", "verifiability_rationale": "The review point states 'The paper's primary contribution seems to be an incremental advancement in efficiency over the TACTiS approach' and 'more substantial evidence or arguments are needed to establish this as a significant contribution to the field.' The first part is a claim about the nature of the contribution. The second part is a claim that requires justification (the lack of evidence). The reviewer provides a reason for their claim (lack of evidence), making the claim 3.", "helpfulness_rationale": "The review point critiques the paper's contribution as an 'incremental advancement in efficiency over the TACTiS approach' and suggests it's 'not established as a significant contribution to the field.' While this provides a critique, it lacks concrete suggestions for the authors on how to demonstrate this advancement or how to improve their contribution. The reviewer focuses on the lack of substantial evidence but doesn't offer specific steps or directions for the authors to take. The critique is present, but the lack of actionable recommendations makes it only 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing element: 'the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of original QUBO'. This is a clear and direct identification of what is lacking. The reviewer is not inferring this, but rather pointing out a gap in the paper's discussion. The action is 'to discuss this theoretical guarantee', which is concrete.", "grounding_specificity_rationale": "The review point explicitly mentions several key components: 'theoretical guarantee,' 'approximation ratio,' 'hierarchical strategy,' 'global optimal,' and 'QUBO'. These are all specific terms and concepts directly related to the paper's topic. The reviewer is not making an educated guess but rather pinpointing a specific area where more information is needed. The grounding is strong because the relevant terms are either literal mentions or directly imply the relevant parts of the paper.", "verifiability_rationale": "The review point itself is a factual statement about the absence of a specific type of discussion in the paper. While the reviewer is implying that this is a valuable addition, the *review point itself* is not making a claim that requires verification. The information provided in the review point is verifiable by checking the paper for discussions on the mentioned topics. The reviewer is providing external knowledge about the importance of such theoretical guarantees in optimization problems.", "helpfulness_rationale": "The review point is concise and directly identifies a gap in the paper's discussion. The suggestion is specific and actionable: 'to discuss this theoretical guarantee'. This is a clear and constructive comment that would likely be beneficial for the authors, helping them understand the theoretical underpinnings of their hierarchical strategy. The reviewer is not just pointing out a problem but also suggesting a concrete improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a desired improvement ('generally lacking a quantitative measure') but does not explicitly state how to achieve it. The action is implied but not clearly defined. While the desired outcome is clear, the means are not, making it 3 but lacking concrete details.", "grounding_specificity_rationale": "The review point mentions 'VCEs' but does not specify which part of the paper or unique element is lacking the measure. It's a general criticism without pinpointing the exact area. The authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point criticizes the evaluation method ('visual inspection') as 'not wellsuited' for quantifying VCEs. While it identifies a weakness, it doesn't provide a specific alternative or justification for why visual inspection is inadequate. There are no explicit claims or supporting evidence provided in the review point itself.", "helpfulness_rationale": "The review point criticizes the evaluation method ('visual inspection') as 'not wellsuited' for quantifying VCEs. While it identifies a weakness, it doesn't provide a specific alternative or justification for why visual inspection is inadequate. The feedback is about the *process* of evaluation rather than direct, actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states 'Only marginal improvements over baselines,' which implies an expectation of significant gains. However, the reviewer does not explicitly state what specific aspect or section of the method is improved. The lack of specificity makes it difficult for the author to understand the exact nature of the improvement and how to replicate or build upon it. The reviewer also states 'Although the authors claim the method performs better than the baselines,' which creates a conflict, as the reviewer acknowledges the claim but also points out the lack of significant improvement. This suggests the reviewer's action is to question the significance of the claimed improvement, rather than directly suggesting an actionable change.", "grounding_specificity_rationale": "The reviewer makes a general statement about 'marginal improvements over baselines' and 'high error bar range.' While the reviewer touches upon the overall performance, they do not explicitly identify a specific section, table, or figure where the improvements are supposed to be found. The reviewer's statement is about the *overall* significance of the results, not about pinpointing a specific issue within the paper. The reviewer also mentions 'improves,' which is a general statement and lacks specificity.", "verifiability_rationale": "The reviewer states 'Only marginal improvements over baselines' and 'high error bar range,' which can be considered a claim about the method's performance. However, the reviewer does not provide any logical reasoning, external references, or specific examples to support this claim. The reviewer also states 'Although the authors claim the method performs better than the baselines,' which creates a conflict, as the reviewer acknowledges the claim but also points out the lack of significant improvement. The reviewer's statement is a statement of observation, not a justified claim.", "helpfulness_rationale": "The reviewer's comment primarily focuses on the lack of significant improvement and the uncertainty surrounding the method's performance due to the high error range. The reviewer does not offer any specific suggestions or actionable advice to the authors on how to address these issues. The reviewer's statement is more of a critique of the results rather than a helpful suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer directly asks about the unclear aspects, making it explicit and concrete. They are asking for details on how to make the method more diverse and representative, and how to select the images. This provides clear guidance on what needs to be addressed.", "grounding_specificity_rationale": "The reviewer mentions 'the previous method' and 'images' when asking for clarification. While not a complete reiteration of the paper, it grounds the discussion by referencing specific aspects of the method and the data used. They are asking about the selection process for 'representative images' and the criteria for 'more diverse'.", "verifiability_rationale": "The reviewer is not making a claim that needs verification. They are asking a question about how something was done, not why it was done or if it was done correctly. The request itself doesn't require logical reasoning, common knowledge, or external references to be understood or accepted.", "helpfulness_rationale": "The reviewer directly asks about aspects that might be unclear for the authors (how to make the new method more diverse and representative, and how to select those representative images). This is a direct request for improvement and clarification, which is inherently helpful. The uncertainty suggests a need for further explanation, indicating a lack of immediate helpfulness, but the *request itself* is helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a question about the relevance of a specific paper to their work, which doesn't explicitly state an action but asks for clarification.", "grounding_specificity_rationale": "The reviewer mentions a specific paper, showing they can identify the source. They also ask about the relevance, showing they understand the specific aspect of interpretability.", "verifiability_rationale": "The reviewer is asking a question, not making a claim that needs verification.", "helpfulness_rationale": "The question is directly relevant to the topic of interpretability and seeks to connect the authors' work to a specific area of research, making it 3 in guiding their focus."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "Unhelpful", "actionability_rationale": "The review point states a fact about the limitations of the experiments but does not provide any explicit or direct actions for the authors to take. While it identifies a problem, it doesn't tell the authors what to do next. The action is implicit, meaning the authors would need to infer the need for more diverse datasets or a broader evaluation framework, which is not ideal for providing actionable feedback.", "grounding_specificity_rationale": "The review point mentions 'MNIST' and 'a single realworld dataset' as limitations. While it identifies a specific area of the paper (the experiments section and the datasets used), it does not explicitly pinpoint a subsection, table, or figure. The grounding is weak because the authors can only *infer* the specific part of the paper being addressed. The specificity is also lacking as it doesn't detail *why* these datasets are limiting or what specific aspects of the evaluation are affected.", "verifiability_rationale": "The review point makes a claim by stating that the experiments are 'limited' to specific datasets. This is a subjective judgment about the scope and potential impact of the experiments. This claim is verifiable through common knowledge in the field of machine learning, where MNIST and a few popular realworld datasets are frequently used for benchmarking. The verifiability comes from the general understanding of standard practices in the field.", "helpfulness_rationale": "The review point identifies a valid limitation of the experiments. However, it does not offer any suggestions or recommendations for improvement. It points out a problem but doesn't provide any actionable steps for the authors to take. Therefore, while it highlights an issue, it doesn't empower the authors to address it."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X (X)", "helpfulness_label": "1", "actionability_rationale": "The review point implicitly suggests that the method in 10 might not effectively utilize side information, but it does not explicitly state what aspect of 10's method is lacking or how to improve it. The phrasing 'why 10 cannot use these side information?' implies a lack of understanding or effectiveness rather than a direct instruction on how to act.", "grounding_specificity_rationale": "The review point explicitly mentions a specific related work (10) and specific aspects of that work (scoring causal predictions, interventional data). This demonstrates a clear grounding of the comment in the specific paper and its components. The reviewer is asking about a specific capability of a specific method.", "verifiability_rationale": "The review point is a question, not a declarative statement that makes a claim. While the question implies a justification for why 10 might not use side information, it doesn't present a verifiable statement with logical reasoning, common knowledge, or external references within the review point itself.", "helpfulness_rationale": "The review point is a question prompting for an explanation about a potential limitation of a related method. It does not directly identify a weakness in the reviewed paper or suggest a concrete improvement. It's more of a request for information or a diagnostic question."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'lacks a sparsity constraint' and 'leading to increasing number of factors and increased computation with more tasks.' These are direct statements about what will happen, indicating an actionable issue for the authors. The action is to be aware of this limitation and consider its implications.", "grounding_specificity_rationale": "The reviewer points out a limitation of the proposed method but does not specify which part of the paper or model architecture this limitation directly applies to. They mention 'the number of factors used by subsequent tasks' generally without pinpointing a specific section, table, figure, or unique aspect. While the *type* of limitation is specific, the *area* isn't clearly identified.", "verifiability_rationale": "The reviewer makes a claim about the expected behavior of the model: 'As such, the model will not be incentivized to use less factors, leading to increasing number of factors and increased computation with more tasks.' This claim is supported by logical reasoning about the absence of a sparsity constraint. While the reviewer doesn't provide specific citations, the reasoning is generally sound and can be verified through theoretical understanding of model optimization. The claim is about the model's behavior, which can be logically deduced.", "helpfulness_rationale": "The reviewer's point is a critique of a potential limitation of the proposed method. While they identify a specific issue ('lack of sparsity constraint'), the impact is negative, suggesting that the model might not be efficient. The feedback is focused on a potential problem rather than a direct suggestion for improvement. It could be more helpful if it suggested alternative approaches or ways to mitigate the problem."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the need for 'experiments on distributed deployment' and 'a larger model'. These are direct actions that the author can take. However, the reviewer does not specify *how* to conduct the experiments or *how* the larger model should be implemented, making the action only partially concrete. The reviewer also doesn't provide any suggestions or requests for changes, making it not fully actionable.", "grounding_specificity_rationale": "The reviewer refers to 'distributed deployment' and 'a larger model'. While the reviewer doesn't explicitly name a specific section or table, the phrasing strongly implies a desire for improvement in these general areas. This can be considered a form of implicit grounding, as the reviewer can infer the specific parts of the paper or work that need improvement. However, the reviewer does not specify *what* is wrong with the distributed deployment or the larger model, making it underspecific.", "verifiability_rationale": "The review point contains a claim: 'The evaluation needs experiments on distributed deployment and a larger model.' However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The reviewer simply states the need without explaining *why* it is needed or providing *examples* of how it should be done. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The review point identifies specific areas for improvement ('distributed deployment' and 'a larger model') and suggests a direction for future work ('evaluation needs'). While this provides a general direction, it lacks specific details or actionable steps. The reviewer does not offer concrete suggestions on *how* to conduct the experiments or *how* the larger model should be implemented. Therefore, while the feedback is 3 in pointing out areas for improvement, it lacks the specific guidance needed for maximum actionable improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2: 4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a claim about the consistency between training and inference and suggests providing more explanations. While the reviewer identifies the area needing more explanation (smoothness of neural models), the *how* of providing more detailed explanations is not specified. The action is stated, but the concrete implementation is missing.", "grounding_specificity_rationale": "The reviewer refers to specific line numbers (9597 and 308310), indicating a clear identification of the relevant part of the paper. They also mention 'smoothness of neural models,' which is a specific concept related to the claimed issue. The grounding is explicit, and the specificity is tied to a relevant concept.", "verifiability_rationale": "The reviewer makes a claim about the consistency between training and inference being easily satisfied and suggests more explanations. This claim could potentially be supported or refuted by examining the cited lines and the discussion around the 'smoothness of neural models'. While the claim itself is verifiable, the specific *justification* for why it's easily satisfied is not provided.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'I would suggest giving more explanations on this.' This directly points to a specific area for improvement and offers a concrete direction for the authors to follow."}
{"actionability_label": "4", "grounding_specificity_label": "3: 4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question about the impact of larger word embedding and LSTM parameters on the proposed model's performance. This directly suggests an action: to investigate and potentially demonstrate the effect of these parameter changes. The action is quite clear and directly addresses a potential weakness or area for improvement.", "grounding_specificity_rationale": "The reviewer refers to '1' and asks about 'word embedding size' and 'LSTM size'. This strongly suggests they are referring to specific sections, tables, or unique aspects of the cited paper. While they don't explicitly state the exact values, the context implies they are looking for that specific information. Therefore, I consider this 'fully grounded'. The request is specific and points to particular parameters.", "verifiability_rationale": "The reviewer presents a claim: 'it could be authors in 1 just test model with standard parameter setting.' This is a statement that requires further investigation. They are not providing a definitive answer but are prompting the authors to consider an alternative interpretation of the baseline results. The request for an experiment to test this claim provides some level of support, even if it's a request for future work rather than a direct verification. The logical reasoning is that if the proposed model is significantly better with fewer parameters, it's worth testing if the baseline could achieve similar results with larger parameters.", "helpfulness_rationale": "The reviewer's request is directly relevant to evaluating the significance of the proposed model's parameter efficiency. It challenges the interpretation of the baseline results and encourages further investigation. The request is specific about *which* parameters to change in the proposed model. This feedback is valuable as it directly addresses a key question related to the parameter efficiency claim and encourages further analysis. While it doesn't provide a direct solution, it prompts a crucial investigation into the baseline's methodology."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a discrepancy in the regularization method used for LN models and suggests a potential improvement (reproducing previous models). This can help the authors understand and potentially adjust their experimental design. Therefore, it is actionable.", "grounding_specificity_rationale": "The reviewer refers to 'the LN model' and 'the GLM model' generally and doesn't specify the exact models or sections. They also mention regularization generally before specifying the Pillow et al. method. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim about a discrepancy in regularization methods and suggests reproducing previous models. They provide some context (cropped stimulus, L1, lowrank) but don't point to specific evidence *within this review point*. Therefore, it is 3.", "helpfulness_rationale": "The reviewer highlights a potential inconsistency in the regularization method and suggests a way to improve the comparison. This could help the authors identify and address a potential flaw in their methodology. Therefore, it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests discussing 'failure cases' but doesn't explicitly state what needs to be done or how to approach this discussion. While it points to a potential area for improvement, the specific actions or modifications are not clearly defined.", "grounding_specificity_rationale": "The review point mentions 'failure cases' as an area for discussion but doesn't specify which part of the paper or section this refers to. The authors would need to infer the location of potential failure cases, making the grounding implicit.", "verifiability_rationale": "The review point contains the claim that 'It will be good to see some failure cases and related discussion' but doesn't provide any justification or evidence for why this is a necessary or beneficial improvement. It lacks specific examples or references to support the suggestion.", "helpfulness_rationale": "The suggestion to include a discussion of 'failure cases' is a relevant and potentially valuable point for authors working on experimental research. It highlights a common area for improvement and points towards a specific direction for future work, making it a helpful suggestion, albeit not with specific implementation details."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies an unclear aspect (base layer GNN encoding) and suggests an action (ablation study). However, it doesn't specify *why* it's unclear or *how* the ablation study would be conducted, making it somewhat, but not fully, actionable.", "grounding_specificity_rationale": "The reviewer mentions \"base layer GNN encoding\" but doesn't explicitly state which section, table, or figure this refers to, making the grounding weak.", "verifiability_rationale": "The review point offers a suggestion (\"An ablation study... would be helpful\") but doesn't state a claim that requires verification. It's a constructive comment, not a claim.", "helpfulness_rationale": "The review points out a potential issue and suggests a concrete action (ablation study), indicating a direction for improvement. However, it lacks specific details, reducing its full helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem of the lack of discussion on computational complexity and provides concrete suggestions for improvement, such as explicitly stating the upper bounds and elaborating on empirical runtimes. This indicates a clear understanding of the weakness and a direct path for the authors to address it.", "grounding_specificity_rationale": "The reviewer mentions 'computational complexity' and 'homomorphism counts,' which are directly related to the paper's topic. They also reference a specific line (145), indicating they've located the relevant area. The reviewer further specifies the desired discussion by mentioning 'the upper bounds of counting' and 'elaborate on empirical runtimes,' adding detail to the expected content. This demonstrates a strong understanding of where the information should be located and what specific aspects are relevant.", "verifiability_rationale": "The reviewer does not make a claim about the results of the homomorphism counting or suggest a specific outcome. Instead, they are pointing out a lack of discussion and providing suggestions for improvement in the presentation of this information. Therefore, there is X being verified or refuted.", "helpfulness_rationale": "The reviewer's suggestion to explicitly add the upper bounds of counting homomorphisms and to elaborate on empirical runtimes is directly relevant to the paper's technical content. This information would improve the reader's understanding of the computational aspects and potentially aid in the practical implementation of the work. The suggestion directly addresses a potential gap in the paper's clarity or completeness, making it highly beneficial for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states an action: 'line 108, the first 'f' should be 'g''. This action is concrete as it directly specifies the location and the correct character. The reviewer is not asking for clarification or inferring the need for a change, but rather pointing out a specific error. Therefore, the action is clearly defined and the modification is straightforward to implement.", "grounding_specificity_rationale": "The review point explicitly mentions 'line 108', which is a specific part of the paper. The issue is also clearly defined as a typo. The reviewer does not need to infer the location or the nature of the problem. The grounding is explicit, and the issue within that part is clear. While the typo itself is a minor issue, the grounding is specific.", "verifiability_rationale": "The review point contains a claim: 'For the baseline MCL with deep learning, how did the author ensure that each of the networks have converged to a reasonable results.' This claim is not explicitly stated as a question, but the reviewer is asking for justification or evidence related to the convergence of the baseline. While the reviewer doesn't provide a direct solution, the claim is present and the request for justification is a logical reasoning to verify the claim. The verifiability is somewhat high as the request for justification is a logical step. However, without specific references or examples, the verifiability is not fully robust.", "helpfulness_rationale": "The review point regarding the typo correction ('line 108, the first 'f' should be 'g'') is 5. It provides a clear, actionable suggestion that directly addresses a potential issue. The reviewer explicitly states the location and the correction, making it easy for the author to implement. The helpfulness is high because the feedback is direct and actionable. For the convergence question, while it raises a valid concern, it doesn't offer a solution. The helpfulness is somewhat low because it doesn't provide concrete guidance. It's more of a question prompting further information rather than a direct improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a missing element (inference time study) and suggests a reason for its absence (the method's direct nature) and a potential solution (comparing to other methods). While the suggestion could be more direct about how to conduct the study, it does propose a concrete action.", "grounding_specificity_rationale": "The review point does not specify a particular part of a paper or a specific issue within that part. It mentions 'this is a pose estimation method' and 'previous topdown and bottomup pose estimation method' in a general sense, without pinpointing a specific section, table, figure, or unique element of a hypothetical paper. Therefore, the grounding is weak.", "verifiability_rationale": "The review point contains a claim: 'No study of inference time.' It also provides a justification for this claim by stating that the method is 'direct' and that 'it is worth to compare its inference speed to previous topdown and bottomup pose estimation method.' This justification, while not exhaustive, provides logical reasoning and suggests a relevant comparison, making the claim verifiable.", "helpfulness_rationale": "The review point identifies a valid weakness (the lack of an inference time study) and provides a suggestion for improvement (comparing to other methods). While the suggestion is somewhat general and lacks specific details on how to conduct the comparison, it does offer a concrete direction for the authors to take. The reviewer's intent is clear and actionable, even if the specifics are not fully elaborated."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of evolutional dropout regarding its effect on lowvariance units and suggests batch normalization as a more effective alternative. The actions and suggestions are direct and clear.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'internal covariate shift,' 'evolutional dropout,' 'lowvariance units,' 'batch normalization,' 'standardization,' and 'centering.' This indicates a high level of grounding as the specific parts of the paper are clearly identified. The specificity is also high as the reviewer explains how batch normalization addresses the limitations of evolutional dropout regarding variance.", "verifiability_rationale": "This review point does not contain a claim that requires verification. It is a critique of a specific claim in the paper and a suggestion for an alternative approach. Therefore, it does not fit into the verifiability framework.", "helpfulness_rationale": "The reviewer provides a direct critique of a specific claim in the paper and offers a concrete alternative (batch normalization) to address the identified limitations of evolutional dropout. This directly helps the authors understand a potential weakness in their approach and improve their work by considering a more established technique."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action: 'add more description about the contribution of this paper'. However, it does not specify how to achieve this action, making it implicit rather than explicit.", "grounding_specificity_rationale": "The comment refers to the 'contribution of this paper' generally, without identifying a specific part of the paper or detailing what is missing. Therefore, it is 1. It also does not specify what needs to be described, so it is not specific.", "verifiability_rationale": "The comment is a suggestion ('add more description') rather than a claim that something is wrong or needs a specific treatment. Therefore, it does not require verification and has no verifiability.", "helpfulness_rationale": "The comment identifies a valid area for improvement (adding more detail) but lacks specific guidance on how to achieve this. It is a suggestion rather than a directive, making it only 3 as it points to a need for more detail."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the intention to organize the attention mechanisms and suggest separate sections. This constitutes an explicit action. However, the reviewer does not specify *how* to implement this organization. The action is stated, but the concrete steps or details for implementation are missing.", "grounding_specificity_rationale": "The reviewer mentions 'layerwise attention mechanism' and 'common tricks like normalization or feature scaling'. While they identify the *type* of attention and the *general* idea of referencing common techniques, they do not explicitly point to a specific section, table, figure, or unique aspect of the paper. The grounding is at a general level, not tied to a precise location or detailed explanation within the paper.", "verifiability_rationale": "The reviewer makes claims about the current structure being 'unhelpful' and the value of referencing common techniques. These are claims that require justification. However, the review point does not provide any specific evidence or references to support these claims. The reasoning is present but lacks concrete examples or supporting literature.", "helpfulness_rationale": "The reviewer explicitly states the intention to improve clarity and organization by suggesting a different structure and referencing common techniques. This is a clear and actionable goal that directly benefits the authors. The suggestions are intended to make the paper easier to understand and implement."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the *what* (missing supervised baselines) but lacks specifics on the *how* or *which* ones to include. It identifies a gap in the experimental evaluation.", "grounding_specificity_rationale": "The comment does not specify a particular section, table, figure, or unique aspect of the paper where the supervised baselines are missing. It is a general call for improvement.", "verifiability_rationale": "The comment makes a claim about the availability of full annotations for large datasets, presenting it as a reasonable assumption. However, it does not provide explicit evidence or justification for this claim within the review point itself.", "helpfulness_rationale": "The review point identifies a relevant gap in the experimental evaluation (missing supervised baselines) and suggests a standard improvement (including them). However, the lack of specificity makes it difficult for the authors to know *exactly* what to do, reducing its overall helpfulness."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides three explicit actions: (1) questioning the novelty of the method on deterministic systems, (2) suggesting evaluation on nondeterministic domains, and (3) pointing out the missing BEAR baseline. While the questions are relevant, they lack specific guidance on how to address them. For instance, the reviewer doesn't suggest specific nondeterministic environments or a methodology for comparing against BEAR.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Hopper' and 'stochastic environments' as areas for further investigation. While 'Hopper' is a specific environment, 'stochastic environments' is a general category. The reviewer also mentions 'empirical efficacy' and 'BEAR baseline' as missing elements, which are specific aspects. Therefore, the grounding is somewhat specific, but could be more precise by naming a specific stochastic environment.", "verifiability_rationale": "The reviewer presents several suggestions and questions. While these can be interpreted as claims or requests for information, they are based on common sense and understanding of the problem. For example, the reviewer suggests evaluating on stochastic environments because the method reduces to actionconditional masking on deterministic ones. This is a logical inference, but it lacks explicit justification or references. The suggestion to include the BEAR baseline is also logical but doesn't provide a concrete reason beyond the missingness.", "helpfulness_rationale": "The reviewer's suggestions are relevant and point to concrete improvements. They highlight potential limitations of the method (its behavior on deterministic systems) and suggest concrete ways to address them (evaluation on stochastic environments and comparison with relevant baselines). These suggestions are actionable and directly address potential weaknesses, making them helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a concrete action: 'cotraining and weight averaging can improve results'. While the 'theocratical justification' part might be interpreted as less specific, the core of the suggestion is clear and actionable. The reviewer is pointing out a need for further explanation regarding the effectiveness of these methods.", "grounding_specificity_rationale": "The reviewer directly refers to 'cotraining and weight averaging', which are specific techniques used in the paper. This explicit mention of the section or method being discussed constitutes full grounding. The reviewer is not just mentioning a general area of concern but specifically naming the methods being used in the paper.", "verifiability_rationale": "The review point makes a claim: 'It would be better if the author could provide some theocratical justification in terms of why cotraining and weight averaging can improve results'. This claim is not explicitly supported by external references or logical reasoning within the review itself. While the reviewer identifies a gap in the paper's explanation, they don't provide evidence to back up their assertion that cotraining and weight averaging *always* improve results. The claim is presented as a suggestion for improvement rather than a statement supported by evidence.", "helpfulness_rationale": "The review point is highly specific and directly addresses a key weakness in the paper: the lack of justification for the effectiveness of cotraining and weight averaging. By highlighting this specific area, the reviewer guides the author to improve their work by providing more detailed explanations and reasoning. This specific feedback is very valuable for the author."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for more details about how the implicit distribution characterizes uncertainty and how the model mitigates this uncertainty. This is a direct and clear request for information, making it 5 for the authors.", "grounding_specificity_rationale": "The reviewer provides specific details about what part of the method they are asking for clarification on: 'how the implicit distribution characterize the uncertainty of each label value' and 'how the model mitigrate the uncertainty of the label distribution'. This precise identification of the issue demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer is not making a claim about what should be in the paper. Instead, they are pointing out a lack of information. Therefore, this review point does not contain a verifiable claim.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential area for improvement in the paper's description. They are asking for clarification on a specific methodological aspect, which is likely to be helpful for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation of the proposed method but does not provide specific steps or guidance on how to address it. The suggestion is general and lacks detail.", "grounding_specificity_rationale": "The reviewer does not explicitly mention a specific part of the paper or a specific issue related to the proposed method. The limitation is described in general terms.", "verifiability_rationale": "The reviewer makes a claim about the method's potential struggle but does not provide any evidence, references, or logical reasoning to support this assertion.", "helpfulness_rationale": "The reviewer identifies a potential weakness of the method, which could be valuable feedback for the authors. However, the feedback lacks specific suggestions or actionable steps."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem: 'It is unclear how these theoretical findings relate to realworld deep learning models.' It then provides a clear and actionable suggestion: 'I would suggest the authors verify the conclusion about the label noise and model size on MNIST and CNN'. This is an explicit statement of what needs to be done, and it is concrete, detailing the specific experiment to perform. Therefore, the review point is 5.", "grounding_specificity_rationale": "The reviewer mentions 'realworld deep learning models' which is a general statement. While the suggestion to 'verify the conclusion about the label noise and model size on MNIST and CNN' provides some grounding by specifying the context (MNIST and CNN), the initial statement about realworld models lacks precise identification of a specific section, table, or unique aspect. Therefore, the grounding is weakly grounded but somewhat specific to the suggested experiment. The specificity of the conclusion about label noise and model size is not explicitly detailed within the context of realworld models.", "verifiability_rationale": "The review point states a claim: 'It is unclear how these theoretical findings relate to realworld deep learning models'. However, it does not provide any evidence, reasoning, or references to support this claim. There is no logical reasoning explaining why this is unclear, no common knowledge being referenced, and no external references provided. Therefore, the claim is 1.", "helpfulness_rationale": "The review point identifies a weakness in the paper: the lack of clarity regarding the connection to realworld deep learning models. It provides a clear and actionable suggestion to address this weakness by verifying the conclusion on MNIST and with CNNs. This directly helps the authors improve their draft by providing a specific direction for further investigation. The suggestion is concrete and directly related to the identified problem. Therefore, the review point is 5."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point points out a *potential* issue (large training loss with suboptimal weight decay) and suggests a *consequence* (suboptimal cosine similarities for large weight decay parameters). It also mentions the *lack of reporting* of cosine similarities for *large* weight decay strengths. While it identifies areas of concern, it doesn't explicitly *recommend* an action like investigating training loss or exploring alternative weight decay strategies. It also doesn't provide a concrete *fix*.", "grounding_specificity_rationale": "The reviewer mentions \"cosine similarities for such large weight decay strengths are not reported\" and \"the plots end at a weight decay strength where cosine similarities are still close to optimal.\" The term 'such\" is vague. The ending point of the plots is also unspecified.", "verifiability_rationale": "The reviewer states a *potential issue* and a *consequence* of that issue. This constitutes a claim: \"As (suboptimally) weight decay is applied to all layers, we would expect a large training loss and thus suboptimal cosine similarities for large weight decay parameters.\" The suggestion to investigate is also a form of claim. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. The ending of the plots is mentioned as *evidence* against the reviewer's expectation, but this is presented as a *potential explanation* for the lack of reported cosine similarities, not as verification of the initial claim.", "helpfulness_rationale": "The review points out a potential issue and suggests investigating it. While it doesn't offer a definitive solution, it *does* point towards a direction for improvement. It identifies a *potential problem* related to weight decay and suggests exploring training loss or alternative strategies."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper does not explain that the results are for unsupervised random forests in the title, abstract, introduction, and discussion. This is an explicit action the paper should take. The reviewer also provides a clear explanation of what this omission means (potential for casual readers to misinterpret results) and how it should be addressed (clarification in the paper). The action is also concrete as the reviewer specifies *where* the explanation is missing.", "grounding_specificity_rationale": "The reviewer points out the specific sections (title, abstract, introduction, and discussion) where the use of unsupervised random forests is missing. This is a strong form of grounding as the reviewer can confidently identify the referenced part of the paper. Furthermore, the reviewer explains *why* this information is important (correct interpretation of results) and *what* is missing (explanation of the method). This specificity makes it clear what needs to be addressed in this part.", "verifiability_rationale": "The reviewer makes a claim: 'the results are for unsupervised random forests.' This is a clear statement of a claim. The reviewer also provides a logical reasoning for why this claim is important ('casual readers would remember the wrong conclusions') and suggests a concrete solution ('fix publication'). While the reviewer does not provide external references, the reasoning is clear and the suggestion is specific. Therefore, the claim is verifiable, though perhaps lacking in external support.", "helpfulness_rationale": "The reviewer highlights a critical omission in the paper that directly affects the understanding and interpretation of the results. The reviewer provides clear suggestions for improvement, such as adding a clarification regarding the use of unsupervised random forests. This makes the reviewer's point 5 and directly helpful for the authors to improve their draft. The reviewer's concern about potential misinterpretation due to this omission is also a significant point that the authors should address."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about computational complexity and requests a comparison. This immediately suggests it *could* be actionable, but needs more detail. The reviewer is asking for a comparison, which is an explicit action. However, the vagueness of 'other methods' makes it less concrete.", "grounding_specificity_rationale": "The reviewer refers to 'other methods' without specifying which ones, making the grounding weak. The reviewer also asks to 'compare the computational complexity' without specifying what aspects of complexity, making the specificity weak.", "verifiability_rationale": "The review point contains a claim: 'Is it true that the proposed method requires much more computation than other methods?'. The reviewer also provides a method for verification by asking to 'compare the computational complexity with other methods'. This makes the verifiability 3, as a comparison method is suggested, but lacks detail.", "helpfulness_rationale": "The review point raises a relevant concern about computational cost and suggests a way to address it by comparing complexity. However, it lacks specific details on which 'other methods' to compare and what aspects of computational complexity to consider. This makes the helpfulness somewhat limited as the authors need more guidance to act on the suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests *specific analyses* to perform (impact of cost, reward incentives, collective return) and *specific scenarios* to explore (different alpha values, roles of winners/cooperators). However, the reviewer does not explicitly state an action or a concrete step the authors should take *based on these analyses*. The suggestion is more about exploring potential research directions rather than providing a direct action for the authors to follow.", "grounding_specificity_rationale": "The reviewer raises concerns about the roles of 'winners' and 'cooperators' and the 'collective return' without specifying a particular section of the paper or detailing the exact issue. The reviewer does not explicitly identify a specific part of the paper being addressed, making the grounding weak. While the issues raised are specific, the lack of a direct reference to a section or table makes the grounding weak.", "verifiability_rationale": "The reviewer presents a claim about the emergence of roles between 'winners' and 'cooperators' and the impact of cost on 'collective return'. However, the reviewer does not provide any specific evidence, references, or logical reasoning to support these claims. The statement is presented as a hypothesis based on intuition rather than verifiable information.", "helpfulness_rationale": "The review point suggests a potential research direction and raises a specific concern about the roles of agents. While the concern is valid and could be interesting, the reviewer does not provide concrete steps or specific examples for the authors to implement based on this suggestion. The review is more about proposing a future research area than offering direct, actionable advice for improving the current draft."}
{"actionability_label": "4", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'no significance testing is done' and provides a clear action: 'check the distribution and accounting for multiple comparisons'. This action is both direct and specific, indicating a clear intention to address the identified issue.", "grounding_specificity_rationale": "The reviewer identifies specific claims being questioned (ChatGPT vs. GPT4 performance and FeedME2 vs. PPO performance) and points to specific lines (line 486 as an example). They also specify the metrics used (dBLEU and humeval scores). This demonstrates strong grounding as the specific parts of the paper being addressed are clearly identified, and the issue being raised is welldefined.", "verifiability_rationale": "The reviewer identifies a claim: 'the difference between zh>en ChatGPT... and GPT4... is minimal and it's hard to say whether it is significant *without proper testing*'. They also suggest a method to verify this claim: 'check the distribution and accounting for multiple comparisons'. While the suggestion is present, it could be more detailed (e.g., mentioning specific statistical tests). Therefore, the claim is verifiable but lacks complete justification.", "helpfulness_rationale": "The reviewer directly points out a potential weakness in the paper (lack of statistical significance testing for performance claims) and offers a concrete suggestion for improvement (performing significance tests). This feedback is clear, actionable, and directly addresses a potential area for enhancement in the authors' work. The reviewer also highlights the importance of this test, making the feedback highly relevant."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states a desire for more evidence and analysis, indicating a need for further research or experimentation, but it does not provide a concrete action for the authors to take on their current draft.", "grounding_specificity_rationale": "The review point is about the importance and usecases of the dataset, not specifically addressing a part of the authors' current draft.", "verifiability_rationale": "The review point is a suggestion for more research or analysis, not a claim that can be verified based on the current draft.", "helpfulness_rationale": "The review point highlights the importance of the dataset, which is relevant to the authors' work. However, it doesn't provide specific steps or guidance on how to improve their current draft based on this observation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they 'would like to see more details about the two baselines presented in Figure 5'. This is a direct and clear request for information, making it 5. The reviewer identifies the specific element they need more information about (the baselines in Figure 5), which further enhances the actionability.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 5' and the 'two baselines presented in Figure 5'. This indicates a strong grounding of the comment in a specific part of the paper. Furthermore, the reviewer specifies what they need more information about within that figure (the baselines), adding to the specificity of the feedback.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. Instead, they express a desire for more information about the baselines in Figure 5. While the reviewer's intention is helpful, the review point itself does not contain a verifiable claim or suggestion based on evidence. The request is for more data, not an critique or recommendation based on existing information.", "helpfulness_rationale": "The reviewer explicitly states they 'would like to see more details about the two baselines presented in Figure 5'. This clearly indicates the reviewer perceives this as a valuable piece of information that would improve the authors' understanding and potentially the quality of their work. The desire for more information suggests the authors would benefit from this feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: \"improve the literature review\". However, it lacks specific details on how to achieve this. The suggestion to provide a \"more explicit and comparative analysis\" is a hint but not a concrete action. Therefore, the action is stated, but the implementation is vague.", "grounding_specificity_rationale": "The reviewer mentions \"unclear literature review\" and \"how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation.\" While the general area of the literature review is identified, the specific part of the paper causing the issue is not pinpointed. The mention of GFlowNet adds a bit of specificity, but the exact element within the literature review related to GFlowNet that's unclear remains ambiguous. The reviewer can infer the relevance of GFlowNet but not the precise location within the literature review.", "verifiability_rationale": "The review point makes a claim: \"The paper should provide a more explicit and comparative analysis of related work.\" This is a statement of what the authors *should* do. While the suggestion itself doesn't provide specific evidence or references, it implies a lack of this type of analysis in the current version, suggesting a need for improvement. The reviewer is indicating a *need* for a certain type of analysis, which can be seen as a form of implicit justification.", "helpfulness_rationale": "The review point is clear and directly addresses a potential weakness in the literature review. It provides a general direction for improvement by suggesting a \"more explicit and comparative analysis\". While the specifics are missing, the general suggestion is actionable and helpful for the authors to understand what needs to be improved. It guides the authors towards a specific area of the literature review."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "Both suggestions are explicit and concrete. The reviewer directly states the actions to take and provides specific details. For example, they suggest adding performance evaluations on word similarity and sentence translation tasks, and they even mention specific languages (Finnish, Hebrew) for the lowresource language suggestion. This clarity allows the authors to directly implement the recommendations.", "grounding_specificity_rationale": "Both suggestions have weak grounding. While the reviewer mentions 'word similarity and sentence translation tasks' and 'morphologically rich languages,' they don't explicitly point to a specific section, table, or figure in the paper. The authors would need to infer the intended areas based on their general understanding of NLP tasks and language characteristics.", "verifiability_rationale": "Both suggestions are 3. The reviewer provides a reason for why these additions would be beneficial. For the performance evaluation, they state it would 'lend more credibility to the robustness and effectiveness of the framework.' For the language suggestions, they mention it would be 'good to have.' While the reasoning is generally logical and wellunderstood in the field, it could benefit from more specific justification or references to existing work.", "helpfulness_rationale": "The review point is 3. Both suggestions are concrete and directly address potential weaknesses or areas for improvement. The reviewer provides clear directions for the authors to follow. However, the second suggestion, being a 'minor point,' reduces the overall impact slightly. The first suggestion is quite strong and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks 'how node importance can be used?' and 'why the experiment part in the paper does not include the 1shot paper setting?'. These are direct requests for clarification and explanation, indicating an **Explicit** action. However, the questions are general and lack specific details about the paper's methodology, making the action **Vague**. The reviewer is asking for information that is not readily apparent in the paper.", "grounding_specificity_rationale": "The reviewer's questions are about the paper's methodology and implementation details, specifically regarding the use of node importance in a 1shot scenario, and the absence of a 1shot experiment. The paper does not explicitly state how node importance is used in a 1shot scenario, and the absence of a 1shot experiment is also not explicitly mentioned. Therefore, the grounding is **Weak**. The reviewer is asking for information that is not clearly defined in the paper.", "verifiability_rationale": "The reviewer asks a question about the paper's content: 'The paper consider the node importance among nodes with same label in support set. In 1shot scenario, how node importance can be used? I also find that the experiment part in the paper does not include the 1shot paper setting, but related works such as RALE have 1shot setting, why?'. This constitutes a **Claim** that the paper does not include a 1shot experiment. The paper's lack of a 1shot experiment is a factual statement, but the reviewer is asking for confirmation. The reasoning and common knowledge are present in the understanding of 1shot settings in related works, but the paper's actual implementation is what's being questioned.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific aspect of the paper's methodology (node importance in 1shot) and pointing out a discrepancy in the experimental setup compared to related works. This is a direct request for improvement guidance, indicating a **Claim** that the paper's explanation is lacking. The paper's lack of clarity on this specific point makes the feedback incomplete and potentially hindering the authors' understanding and ability to improve their work. The helpfulness is limited by the lack of concrete information."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'more discussions' regarding the limitations of LLMs with finegrained hard constraints and proposes 'how to address these problems'. This is a direct and concrete action that the authors can take to improve their understanding and potentially their model's behavior. The action is not inferred but clearly stated.", "grounding_specificity_rationale": "The review point explicitly mentions 'finegrained hard constraints' as the specific aspect of LLMs being discussed. This allows the authors to precisely identify the section or aspect being addressed, demonstrating 'full grounding'. The comment also clearly identifies the issues ('why LLMs struggle') and the desired outcome ('how to address these problems'), providing a degree of 'specificity'.", "verifiability_rationale": "The review point contains a claim in the form of a request for more discussion on a specific topic. While it doesn't provide external references or logical reasoning to *prove* the struggle, it clearly identifies a gap in the current understanding and suggests an improvement by adding more discussion. This makes it 'partially verifiable' as it points to a need for further investigation and understanding.", "helpfulness_rationale": "The review point directly addresses a potential weakness the authors might have (struggle with finegrained constraints) and suggests a concrete way to improve their understanding and potentially their model's behavior (by discussing this area). This is a clear and actionable suggestion that empowers the authors to expand their knowledge and potentially address a specific limitation. Therefore, it is '5'."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'it would be better to provide some ablation experiments of these tricks' which clearly indicates an action the authors should take. The phrase 'these tricks' further clarifies the specific area of improvement. The action is also concrete, specifying 'ablation experiments' and 'validate the model performance further'.", "grounding_specificity_rationale": "The comment explicitly refers to 'Section 3.4', which is a clear and precise identification of the part of the paper being discussed. While the comment uses the general term 'tricks', the context of Section 3.4 likely implies specific techniques. The grounding is strong because the section number is explicitly mentioned. The specificity is also high as the comment clearly identifies the need for ablation experiments on the 'tricks' mentioned in that section.", "verifiability_rationale": "The comment contains a claim: 'it would be better to provide some ablation experiments of these tricks'. This is a suggestion for improvement. While the comment states what should be done, it does not provide any logical reasoning, external references, or specific examples to support this claim. The suggestion is clear and actionable, but lacks the verifiability of being backed by evidence or detailed explanations.", "helpfulness_rationale": "The comment identifies a valid gap in the experimental validation by pointing out the absence of ablation studies for the mentioned 'tricks'. It suggests a concrete way to improve the model performance. While the comment doesn't provide the ablation experiments themselves, it clearly indicates the need and direction for further investigation, making it helpful for the authors to understand what to focus on. The suggestion is actionable and directly addresses a potential weakness."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their intention to compare the performance of their KDE method on datasets with decision spaces beyond binary classification. They are also asking if this is a problem compared to the other approach mentioned. This is a clear and direct action that can be carried out. The action is also concrete as the reviewer is suggesting a specific comparison.", "grounding_specificity_rationale": "The reviewer mentions 'datasets that the decision space is beyond binary' but does not explicitly identify a specific section, table, figure, or unique aspect of the paper where this is discussed. While the concept is mentioned, the exact location or details are not provided. Therefore, the grounding is weak. The specificity of the issue is clear, but the grounding is not.", "verifiability_rationale": "The reviewer poses a question about a potential limitation of their KDE method and suggests an experiment to investigate it. This constitutes a claim that requires verification. The claim is 3 as the *idea* of the experiment is clear, but the *details* of the experiment and the paper's content to support it are not provided in the prompt. Without further information, it's difficult to definitively assess the verifiability.", "helpfulness_rationale": "The reviewer is asking a question and suggesting an experiment. This is a request for information that could be 5 for the authors. However, the helpfulness depends on the clarity and informativeness of the suggested experiment and the paper's content to support it. Without further details, it's '3' as the request has the potential to provide valuable information."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point asks questions about the impact of the SR model's capacity on FID and the unexpected artifacts, rather than providing explicit instructions or actions to take. While the questions are relevant, they don't directly tell the authors what to do or how to address the issues.", "grounding_specificity_rationale": "The reviewer mentions 'the SR model's capacity' and 'unexpected artifacts', which provides some grounding. However, they don't specify a particular layer, module, or metric within the capacity, nor do they pinpoint the exact nature of the unexpected artifacts. This lack of specificity makes the grounding weak.", "verifiability_rationale": "The review point poses questions about the impact of capacity and the artifacts, but it doesn't make any claims that can be verified through logical reasoning, common knowledge, or external references. The questions are exploratory rather than declarative.", "helpfulness_rationale": "The questions are relevant to understanding the model's behavior and its impact on FID. They could help the authors diagnose issues and potentially identify areas for improvement. While not a direct solution, the questions provide a starting point for further investigation and are therefore 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the purpose of Proposition B.1 and identifies a missing element (the 'proof'), which are concrete actions for the authors to take. The reviewer also infers that the proposition might be unnecessary, which can be considered an implicit action.", "grounding_specificity_rationale": "The comment explicitly mentions 'Appendix B' and specifically 'Proposition B.1', providing clear grounding. It also details the issues with this specific part of the paper and suggests improvements, making the grounding very specific.", "verifiability_rationale": "The comment contains a claim about the unclear purpose and missing proof of Proposition B.1. It provides logical reasoning by referencing the wellknown nature of the partitioning principle in Kmeans and the expectation of formal proofs. While it doesn't provide a specific external reference, the common knowledge and logical deduction make it verifiable.", "helpfulness_rationale": "The comment identifies a specific weakness in the appendix (unclear purpose and missing proof) and suggests a concrete improvement (clarifying the purpose or adding the proof). This directly addresses potential areas for improvement in the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential weakness related to the approximations (i iii) and suggests a deeper analysis of the assumptions. While the weakness is stated explicitly, the reviewer does not provide specific details about which approximations are problematic or how they leave loose ends. The suggestion to expand the analysis is general and lacks concrete action.", "grounding_specificity_rationale": "The reviewer mentions 'approximations (i iii)' and 'feasible set' but does not explicitly identify the specific part of the paper being addressed. The reference to the feasible set is vague and does not point to a specific section, table, or unique aspect of the paper. While the reviewer implies a concern, they do not specify what needs to be addressed in this part.", "verifiability_rationale": "The reviewer presents a suggestion to expand the analysis of the assumptions but does not provide any specific evidence or reasoning to support this suggestion. The comment is framed as a question ('It could be expanded...') rather than a definitive statement that can be verified. There are no external references or logical reasoning provided to justify the suggestion.", "helpfulness_rationale": "The reviewer's comment is relevant to the paper, as they point out a potential area for improvement related to the approximations and assumptions. However, the suggestion to 'expand the analysis' is general and lacks specific details. The comment does not directly address the 'loose ends' mentioned in the review point, making it 3 but not highly so."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests 'more careful analysis' is needed, which implies an action. However, the specifics of this analysis are not detailed, making the action implicit and vague.", "grounding_specificity_rationale": "The reviewer mentions 'some pretty 'old' benchmarks' but does not specify which ones or why they are relevant. This lack of specificity means the grounding is weak.", "verifiability_rationale": "The review points out a potential issue with the model's evaluation ('impressive performance on many benchmarks') and suggests 'more careful analysis' is needed. This is a claim, but the reviewer does not provide any evidence or reasoning to support why this analysis is necessary or what it should entail.", "helpfulness_rationale": "The review identifies a potential weakness in the evaluation methodology and suggests a more thorough investigation. This is a constructive suggestion aimed at improving the model's robustness. While it lacks specific details, it is a valuable piece of feedback that could guide the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding a new element (collaborative games) to the experiments. This implies a concrete action: *design and implement* such games. The comment doesn't just say 'add something'; it suggests *what kind* of something. This suggests a clear direction for the authors to act.", "grounding_specificity_rationale": "The comment is very general. It doesn't specify *where* in the existing experiments this suggestion fits. It's a highlevel suggestion, not a direct critique of a specific section or finding. The comment doesn't critique the *specifics* of the current experiments. It's a suggestion for future work, not a critique of the current methodology.", "verifiability_rationale": "The comment is a suggestion, not a claim requiring verification. It's a suggestion for future work, not a critique of the current methodology. There is X being made or supported in this review point.", "helpfulness_rationale": "While the suggestion is valuable in the long run, it's not immediately actionable within the context of improving the *current draft*. The authors need to *design* and *implement* the games first. The immediate impact is limited. It offers a *direction* but requires further steps to be directly helpful to the current state of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the experimental settings are missing for Figures 1 to 9. While it doesn't directly tell the author what the missing experimental settings are, it clearly identifies a problem with the presentation of the experimental details. This makes the action somewhat explicit. The action is also somewhat concrete as the comment specifies the figures involved.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figures 1 to 9'. This is a clear and specific reference to the figures in the paper. The reviewer is directly pointing to the location of the potentially problematic information. Therefore, the grounding is fully explicit. The comment also specifies what is missing: 'experimental settings'. This adds further specificity to the referenced part.", "verifiability_rationale": "The comment contains a claim: 'the absence of experimental settings for Figures 19 makes them unconvincing.' This claim is supported by the general understanding that experimental details are crucial for the interpretation and reproducibility of results. While the reviewer doesn't provide specific examples of why the figures are unconvincing *without* the experimental settings, the claim itself is a logical deduction. The lack of information about how the data was collected and analyzed generally reduces confidence in the results presented. Therefore, the verifiability is somewhat high, as the claim is based on a generally accepted principle of scientific reporting.", "helpfulness_rationale": "The comment clearly identifies a specific problem: the missing experimental details hindering the assessment of the figures. This is a concrete piece of feedback directly related to the visual presentation of results. The reviewer is likely trying to help the authors understand why the figures are difficult to interpret and what information is needed to improve them. While the comment doesn't offer specific solutions, it points the authors to a critical area that needs attention, making it 5 in terms of guiding further investigation and improving the clarity of the figures."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential contradiction in the motivation and suggests a lack of clarity about how the proposed method avoids hindering the learning of new task knowledge. While the reviewer doesn't explicitly state an action, the suggestion to clarify this point implies a desire for the authors to take a specific step to address a potential issue. The ambiguity makes it less clear what the authors should do to implement the suggested clarification.", "grounding_specificity_rationale": "The reviewer's comment is general and doesn't explicitly identify a specific aspect of the paper being addressed. They mention 'parameter isolation methods' broadly and don't specify which method or part of the method they are referring to. This lack of specificity makes it difficult for the authors to pinpoint the relevant section or element. The reviewer also highlights an ambiguity about how the proposed method avoids hindrance, which further weakens the grounding.", "verifiability_rationale": "The reviewer states a potential contradiction: 'current parameter isolation methods often hinder the acquisition of new task knowledge' and 'some parameter isolation methods are specifically tailored to leverage this sparsity'. This can be considered a claim. However, the reviewer highlights an ambiguity about how the proposed method avoids this hindrance, which weakens the support for the claim. The reviewer doesn't provide specific examples or references to back up the claim, making the verifiability lower.", "helpfulness_rationale": "The reviewer's comment highlights a potential issue and suggests a lack of clarity. While it points to a potential problem, the ambiguity makes it less helpful for the authors to understand and address the issue. The reviewer doesn't provide specific, actionable feedback, making the overall impact less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the desired improvement: \"Integrating benchmark comparisons against stateoftheart fairness algorithms would significantly enhance the paper.\" This clearly identifies an action the authors should take. However, the review point lacks specific details on *how* this comparison should be conducted. For example, it doesn't mention which specific fairness algorithms are being referred to, which metrics will be used for evaluation, or how the results will be presented. This lack of detail makes the action somewhat vague.", "grounding_specificity_rationale": "The review point refers to \"existing fairness algorithms\" generally. It does not specify which particular algorithms are being discussed or point to a specific section, table, or unique element in the paper where these algorithms are relevant. The reviewer is making a broad statement about the need for comparisons without pinning down the exact scope or location within the authors' work. Therefore, the authors cannot confidently determine which part of their paper this comment is addressing.", "verifiability_rationale": "The review point contains a claim: \"Integrating benchmark comparisons against stateoftheart fairness algorithms would significantly enhance the paper.\" This claim states a benefit (enhanced paper) without providing immediate justification or references within the review point itself. While the reviewer states the *what* (benchmark comparisons), they don't explicitly explain *why* this is a valuable addition or how it would be implemented. The claim is somewhat supported by the stated benefit, but lacks the depth of explanation or references expected for full verifiability.", "helpfulness_rationale": "The review point identifies a valid weakness in the authors' work: the lack of benchmark comparisons against existing fairness algorithms. It suggests a concrete and valuable improvement that would likely enhance the paper's impact and position within the field. While the review point doesn't provide specific implementation details, it clearly articulates a direction for improvement and explains the potential positive consequences. This makes the comment 4 as it points towards a significant area for development."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential issue (negative transfer) with supervised pretraining but doesn't explicitly state how the authors should address it. While it implies a problem, the specific steps or modifications needed are not clearly outlined. Therefore, it is partially actionable, as the authors can infer the need for further investigation or different pretraining strategies, but lack concrete guidance on implementation.", "grounding_specificity_rationale": "The review point mentions 'TransformerM' and 'QM9 dataset' as examples, which provides some grounding. However, it doesn't specify *which* model or *which* experiments within the QM9 dataset are being referred to. The mention is general, making it weakly grounded. It doesn't explicitly detail the *issue* with the homolumo gap prediction, so it's not fully specific.", "verifiability_rationale": "The review point presents a potential concern about negative transfer and provides an example with TransformerM on QM9. While it *could* be considered a claim, the review point itself doesn't explicitly state this as a claim or provide direct evidence or references within its text. The verifiability would require the authors to independently investigate the TransformerM paper and the QM9 dataset. Therefore, it's not explicitly verifiable within the review point itself.", "helpfulness_rationale": "The review point raises a valid concern about a potential limitation of the proposed approach (supervised pretraining for homolumo gap). It highlights a potential issue that could affect downstream performance. While it doesn't provide a solution, it points to a problem that the authors should be aware of and potentially investigate. Therefore, it is 3 in identifying a potential area for concern."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer correctly points out that the authors state on lines 8082 that the center correlation was not insightful for discriminating model defenses, and then use this metric in Figure 4 A&B. This implies an implicit action or suggestion, as the authors do not explicitly state how they came to use the metric despite the statement. While the reviewer doesn't specify what the authors *should* have done, the lack of a clear action or instruction makes the point 3.", "grounding_specificity_rationale": "The authors can identify the specific part of the paper being addressed, as they mention the context of model defenses and the center correlation on lines 8082. They also clearly specify what they are critiquing \u2013 the insufficiency of the center correlation for discriminating model defenses. This indicates a level of grounding where the section and the specific issue are identified, but the lack of explanation for the statement on lines 8082 makes it somewhat grounded and specific.", "verifiability_rationale": "The authors make a claim on lines 8082 stating that the center correlation was not insightful for discriminating model defenses. However, the paper does not provide any external references, logical reasoning, or examples to support this claim. The assessment of the metric's insufficiency appears to be based on the authors' own interpretation without further justification. This indicates a lack of verifiable support for the claim.", "helpfulness_rationale": "The reviewer's confusion about the authors' statement on lines 8082 and their subsequent use of the center correlation in Figure 4 A&B is a valid point that could improve the paper. However, the reviewer does not explicitly state what the authors *should* have done or how they could have improved their explanation. This lack of a clear next step makes the review point 3 but not entirely clear or actionable for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "X", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests a specific alternative name ('distributional convergence') for the phenomenon described, indicating an explicit action to change terminology. They also imply that the current name ('distributional generalization') is overstated based on limited evidence, which is a concrete suggestion for improvement. The reviewer directly proposes a change in terminology, making the action clear and actionable for the authors.", "grounding_specificity_rationale": "The reviewer's comment is general and does not specify a particular section, table, or figure in the paper where the issue lies. They are criticizing the name of a phenomenon and the claim about its strength based on limited evidence, without pointing to a specific part of the paper. The comment is about the concept itself, not a specific issue within a section or table.", "verifiability_rationale": "The reviewer makes a claim about the name 'distributional generalization' being 'strong' and based on 'a few test functions'. This claim is verifiable because the reviewer provides a reason (limited test functions) that could be checked against the definition or empirical results of the phenomenon. The reviewer offers a specific reason for their claim, making it verifiable.", "helpfulness_rationale": "The reviewer's comment is helpful because it suggests a specific change in terminology ('distributional convergence') and challenges a potentially misleading perception ('strong') based on limited evidence. The suggestion is direct and actionable for the authors. The reviewer provides a clear direction for improvement, making the comment valuable for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests removing the '45 degree' line and adding a 'thin gray diagonal' line. This is a clear, direct action with concrete details on how the change should be implemented.", "grounding_specificity_rationale": "The reviewer refers to the specific visual element of the plot and the annotation area ('above/below diagonal'). This is a clear and precise identification of the part of the paper being addressed.", "verifiability_rationale": "The reviewer suggests a change to the plot annotation, implying that the current method is a 'nitpick' or difficult to interpret. While this is a suggestion without a direct claim of superiority, it does point to a potential area for improvement, making it 3 through the action it suggests.", "helpfulness_rationale": "The reviewer directly addresses a potential 'nitpick' or area of difficulty for the author (the current annotation method). By suggesting an alternative that is claimed to be easier to interpret, the reviewer is directly addressing a perceived weakness or area for improvement, making the review 5."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The statement 'is sufficient' is vague and lacks specific context. It's unclear what is being referred to as 'sufficient' and what it is supposed to be sufficient for. This makes the action implicit and the specificity of the action unclear.", "grounding_specificity_rationale": "The reviewer points to specific line numbers (L240 and L428), indicating a degree of grounding. However, the *content* being referred to at those lines is not defined in the review point itself. We can infer the context, but the *specific* section or element isn't explicitly named. The specificity of the grounding is limited by the lack of clarity in the surrounding text, making it difficult to pinpoint the exact issue being discussed.", "verifiability_rationale": "The reviewer makes a claim that the statement 'is sufficient' is unclear or needs clarification. However, they do not provide any evidence or reasoning to support this claim. The verifiability verification steps require a claim to be identified, and in this case, the reviewer is making a statement about the lack of clarity without offering any justification or examples.", "helpfulness_rationale": "The reviewer's point is that the statement at lines 240 and 428 is unclear and needs clarification. While this points to a potential improvement in the paper, the review point itself does not offer any concrete suggestions or actions to achieve this clarification. The helpfulness is limited as the reviewer identifies a problem but doesn't provide a solution within their review point."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their lack of understanding and asks for evidence, which can be seen as an implicit action. However, the action of seeking clarification is not directly stated, making it less actionable than a direct suggestion. The reviewer is essentially prompting the authors to provide more information, rather than being given a specific task to perform.", "grounding_specificity_rationale": "The reviewer mentions 'this model (as formulated in Section 2.3)' which indicates some level of grounding in the model being discussed. However, the core of the issue \u2013 the lack of scientific insight and the need for comparison to taskoptimized approaches \u2013 is a general question about the presented formalism, not a specific reference to a particular table, figure, or unique element within the paper. The authors need to infer which part of the paper is being questioned.", "verifiability_rationale": "The reviewer explicitly states that the paper lacks evidence and a comparison, and is asking for justification for this claim. This provides a clear basis for the claim and a logical reasoning for why it is a valid point. While the reviewer doesn't provide specific examples of where the evidence is missing or how the comparison should be made, the *need* for this evidence and comparison is clearly stated, making it 3.", "helpfulness_rationale": "The reviewer directly asks for clarification on a core issue (scientific insight and model comparison) that the authors are struggling with. This is a clear and actionable request that directly addresses a potential bottleneck in the authors' understanding or progress. While it doesn't provide a solution, it directly points to a need for more information, which is helpful."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer directly asks a question about the action of how the groundtruths are built and how the network can predict all keypoints of the pose. This is a clear call for clarification on a specific action related to the model's training and prediction process. The reviewer is asking for details on how the model handles the relationship between different parts and keypoints, which is crucial for understanding the model's architecture and implementation.", "grounding_specificity_rationale": "The reviewer is asking specific questions about the grounding of their review point. They are asking about the *source* (groundtruth construction) and the *mechanism* (how all keypoints are predicted) of a specific action (processing parts and predicting keypoints). This shows a clear focus on understanding how the action is grounded in the paper. The reviewer is asking about the *specifics* of how the model processes information from different parts to predict keypoints, indicating a high level of grounding and specificity.", "verifiability_rationale": "The reviewer is pointing out a potential inconsistency or lack of clarity in the paper's description. They are questioning the logical connection between the training objective (offsets within radius `r`) and the desired outcome (predicting all keypoints). This highlights a potential gap in the explanation. While the paper *claims* this connection, the *justification* for how this training objective leads to the prediction of all keypoints is not clearly explained. The reviewer is asking for a logical reasoning to support this claim.", "helpfulness_rationale": "The reviewer is asking clarifying questions about the implementation details of the model. While they are not proposing a solution, their questions are aimed at improving the understanding and potentially fixing the model. Their input is focused on addressing a specific issue (how the model predicts all keypoints) and seeks clarification on the implementation details. This is a helpful input for the authors as it points to a potential area of confusion or a potential bug in the model."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a tradeoff between computational efficiency and information richness, indicating an implicit action: the reviewer is asking for information. The information about the tradeoff is also explicit. The reviewer could have stated the tradeoff directly, making it more concrete, but they chose to imply it through the description of the methods. Therefore, it's 3 as the reviewer is seeking information.", "grounding_specificity_rationale": "The reviewer refers to '10' and 'ACI' and discusses the outputs of these methods (DAGs vs. ancestral graphs). While the names of the methods are mentioned, the specific section of the paper being discussed is not explicitly stated. The reviewer is asking a question about the relationship between the outputs, implying a desire for clarity regarding the paper's content. However, the specific section isn't named. The information about the outputs is specific, but the section of the paper being discussed is not explicitly mentioned. Therefore, it's 3.", "verifiability_rationale": "The reviewer states a fact ('This means that the output of ACI...') and poses a question ('How much information...'). This constitutes a claim that can be verified by comparing the definitions of DAGs and ancestral graphs. While the reviewer doesn't explicitly claim to know the answer, the question itself is a claim that can be verified. Therefore, it's 4 as the claim is verifiable, although the answer is not provided.", "helpfulness_rationale": "The reviewer is directly asking for information about the information content of ancestral graphs compared to DAGs. This is a valuable piece of information for someone considering using the ACI method. The question is clear and directly addresses a potential limitation. While the reviewer doesn't explicitly state they are improving the ACI method, they are seeking information that could aid in its application. Therefore, it's 4 as the information is likely to be beneficial for understanding the method's output."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The suggestion is explicitly stated: 'it may be worth including a brief discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one as in Section 4.2.' Furthermore, the suggestion is concrete, proposing investigating 'the effect on the volatility of \u03b1 t and also on the average lengths of the predictive intervals when we let Q ^ t and S t vary with time?' This provides a clear direction for the authors to act and improve their draft.", "grounding_specificity_rationale": "The comment explicitly mentions the parameters Q ^ t and S t , which are specific to the model being discussed. It states, 'it may be worth including a brief discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one as in Section 4.2.' This directly identifies the specific part of the paper being addressed. While it doesn't provide a detailed explanation of what is wrong with the current approach, it clearly specifies the area for improvement by focusing on the empirical motivation for timevarying parameters. Therefore, while it could be argued that the grounding is somewhat implied by the parameters being discussed, the reviewer explicitly points to these parameters as the focus of the discussion.", "verifiability_rationale": "The comment contains a claim: 'it may be worth including a brief discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one as in Section 4.2.' This is a suggestion for improvement. The comment also provides some justification by stating 'For example, what is the effect on the volatility of \u03b1 t and also on the average lengths of the predictive intervals when we let Q ^ t and S t vary with time?' This provides a basis for logical reasoning and suggests empirical investigation as a way to verify the potential benefits of the suggestion. While it doesn't provide specific references to external works, the suggestions for investigation provide a pathway for the authors to gather their own evidence.", "helpfulness_rationale": "The comment provides a clear and actionable suggestion for the authors to consider. It directly addresses a potential limitation of the model (fixed parameters) and proposes a concrete way to explore potential improvements (empirical investigation of effects). The reviewer explicitly states the *what* of the investigation (volatility of \u03b1 and lengths of predictive intervals), providing a clear direction for the authors to take. This makes the comment highly valuable for guiding the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises a valid point about the technical difference between anchorbased regression and regression in RepPoints. While both aim to predict bounding box parameters, the *mechanism* and *output* differ. Anchorbased methods directly predict the width and height (or deltas) of the bounding box relative to predefined anchor boxes. In contrast, RepPoints regress the location of a hypothetical 'receptive point' on a feature map, and this point is then used to generate the final bounding box. The reviewer correctly points out that RepPoints regress the distance to the feature map location, not directly to a bounding box. This difference in the regression target and the way the final proposal is generated could be considered actionable. The reviewer also correctly notes that RetinaNet uses a oneshot regression, and ATSS has shown that the specific regression method has minimal impact. However, the *technical distinction* between regressing to a fixed grid point (RepPoints) versus regressing based on predefined anchors (RetinaNet) could still be a valid point of discussion, especially if the authors are trying to justify a specific design choice or highlight the benefits of their approach. The reviewer's concern about the lack of a clear difference leading to a solid motivation is a valid point that needs to be addressed.", "grounding_specificity_rationale": "The reviewer's point about grounding specificity is valid. While the core idea of RepPoints is to regress to a fixed grid of locations, the *implementation* and *details* can significantly impact grounding specificity. The reviewer correctly identifies that the paper mentions regressing to the location of feature maps, which is a form of grounding. However, the *clarity* of the grounding can be improved. For example, specifying *which* feature map locations are being regressed to and *how* the regression targets are determined would enhance grounding specificity. The reviewer's suggestion to mention the unique elements being addressed is also relevant. For instance, if the paper is addressing a specific type of object or a particular aspect of an object's appearance, explicitly mentioning this would improve grounding specificity. The reviewer's point about the need for a clear mapping between the regression output and the final proposal is crucial for grounding specificity. The reviewer's suggestion to mention the unique elements being addressed is also relevant. For instance, if the paper is addressing a specific type of object or a particular aspect of an object's appearance, explicitly mentioning this would improve grounding specificity.", "verifiability_rationale": "The reviewer's point about verifiability is partially valid. The paper mentions regressing to the location of feature maps, which provides a basis for verifiability. However, the *details* of how this regression is implemented and how the regressed location is used to generate the final proposal are crucial for verifiability. The reviewer's suggestion to provide specific examples or references would strengthen the verifiability. For instance, if the paper uses a specific loss function or a particular method to map the regressed location to the bounding box parameters, this should be clearly stated. The reviewer's point about the need for a clear mapping between the regression output and the final proposal is also relevant for verifiability. The reviewer's suggestion to provide specific examples or references would strengthen the verifiability. For instance, if the paper uses a specific loss function or a particular method to map the regressed location to the bounding box parameters, this should be clearly stated.", "helpfulness_rationale": "The reviewer's point about the lack of a clear difference between the two regression methods and the potential lack of novelty is a valid concern. The reviewer correctly points out that the technical distinction between regressing to a fixed grid point (RepPoints) versus regressing based on predefined anchors (RetinaNet) might not be significant enough to justify a paper. While the reviewer acknowledges the ATSS finding that regression methods do not influence a lot, the authors need to clearly demonstrate the *technical novelty* and *practical impact* of their approach. The reviewer's concern about the lack of a clear difference leading to a solid motivation is a valid point that needs to be addressed. The reviewer's suggestion to provide a clear justification for the chosen approach and demonstrate its effectiveness is crucial for improving the helpfulness of the paper. The reviewer's point about the need for empirical validation to show the effectiveness of the proposed method is also valid."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out that the paper is 'not particularly easy to follow' and that the 'presentation lacks a clear intuition for how the pieces fit together.' While this identifies a problem, it doesn't explicitly state what the authors should do to address it. The reviewer suggests improvements but doesn't provide concrete steps. Therefore, the comment is not fully actionable, as the action is not explicitly stated. However, the reviewer does point towards a direction for improvement, making it more than 1.", "grounding_specificity_rationale": "The reviewer refers to the 'paper,' 'intuition,' and 'pieces fit together' when describing the lack of clarity. This indicates that the reviewer can identify the specific part of the paper being addressed, even if the nature of the problem is general. The authors can infer that the lack of clarity is related to the presentation of the paper and the connections between its components. Therefore, the grounding is present, but the specificity is low as the issue is not pinpointed to a specific detail.", "verifiability_rationale": "The reviewer states that the paper is 'not particularly easy to follow' and that the 'presentation lacks a clear intuition.' These statements are claims or judgments about the paper. However, the reviewer does not provide any evidence, references, or logical reasoning to support these claims. There is no external reference or logical deduction provided to back up the assertion that the paper is difficult to follow. Therefore, the claim is not supported by any verifiable information.", "helpfulness_rationale": "The reviewer's comment highlights a significant issue with the paper's clarity, which could hinder the authors' ability to effectively communicate their work and potentially the reproducibility of their results. This is a relevant concern for the authors. However, the reviewer does not offer any specific suggestions or actions the authors should take to address this lack of clarity. The authors would still need to interpret the reviewer's statement and figure out how to improve the paper's presentation. Therefore, while the comment is relevant, it lacks specific guidance, making it less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly states a potential benefit ('may improve the performance of the teacher network') and suggests a method ('simultaneous training'). However, it doesn't specify *how* the comparison is unfair, leaving the action somewhat vague.", "grounding_specificity_rationale": "The comment explicitly mentions 'simultaneous training' and 'teacher network', allowing for precise identification of the networks being discussed. However, it doesn't specify *why* the comparison might be unfair, making the grounding complete but the specificity incomplete.", "verifiability_rationale": "The comment contains a claim ('may improve the performance of the teacher network') but provides no logical reasoning, common knowledge, or external references to support this claim. The request for KID/FID is a request for evidence rather than a verification of the claim itself.", "helpfulness_rationale": "The comment points out a potential issue ('may improve the performance of the teacher network') but doesn't offer any suggestions or insights into how this might be addressed or how the comparison can be made fair. It's essentially raising a concern without providing a solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point is 5 because it directly identifies a potential improvement to the method described. The authors can easily implement the suggested addition of a scaling variable before the attention weight. The point is also concrete, as the suggested change is a specific modification to the existing formula.", "grounding_specificity_rationale": "The review point is fully grounded because it explicitly refers to 'line 157' and the specific formula involving u_i, attention_weight, and v_i. The authors can clearly identify the element being discussed. It is also specific because the reviewer directly points out the potential issue with the scaling factor and suggests a concrete solution.", "verifiability_rationale": "The review point is 3. While the reviewer doesn't provide a specific example of where this might be an issue in practice, the reasoning is based on an understanding of how attention weights and vector scaling work. The potential benefit of the scaling variable is logically presented, and the reviewer suggests it could help in scenarios where attention weights are close to 1, potentially leading to redundant contributions from multiple regions. This requires some level of logical reasoning and understanding of the underlying concepts.", "helpfulness_rationale": "The review point is 5. It identifies a potential area for improvement in the method and offers a concrete suggestion for how to address it. The idea of adding a scaling variable before the attention weight is a constructive suggestion that could potentially lead to more controlled and effective region contributions. This directly empowers the authors to refine their method."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies the issue of 'goal misspecification' as a cause of failures on the ALFRED benchmark. This points to an actionable area for improvement, suggesting that authors should focus on better specifying their goals. However, the point lacks specific details on *how* this misspecification occurs or what aspects of the goal are problematic. It suggests improving goal specification but doesn't provide concrete steps on how to achieve this.", "grounding_specificity_rationale": "The review point mentions 'goal misspecification' and 'ALFRED benchmark'. While it identifies the *type* of misspecification, it doesn't explicitly state which part of the paper or the system is being referred to. The connection to the ALFRED benchmark is implied through the context of failures *due* to this misspecification. However, the point doesn't specify the exact location or nature of the misspecification within the ALFRED framework.", "verifiability_rationale": "The review point states that 'failures on the ALFRED benchmark often occurred due to goal misspecification'. This is a claim that needs to be addressed. However, the point does not provide any evidence, reasoning, or references to support this claim. It simply states the cause without any justification or examples.", "helpfulness_rationale": "The review point identifies a potential weakness in the ALFRED benchmark evaluation process, specifically the issue of 'goal misspecification'. While it points out a problem, it doesn't provide any specific guidance on how to diagnose or fix this issue. The point identifies a problem but lacks the necessary details and evidence to be truly helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'present differences in FPR'. It also suggests investigating specific models, which implies a concrete next step. The suggestions are directly related to the paper's findings, making them grounded. However, the review point lacks specific details on *how* to present the FPR differences or *how* to investigate the specific models, making the action somewhat vague.", "grounding_specificity_rationale": "The review point explicitly mentions 'specific models (e.g., GPT4o vs. InternVL2)' and 'differences in FPR'. This clearly identifies the specific part of the paper being addressed. The suggestions are also quite concrete, suggesting a direct investigation. Therefore, the grounding is strong as the specific models and the metric (FPR) are mentioned.", "verifiability_rationale": "The review point makes a claim: 'a deeper investigation into how specific models (e.g., GPT4o vs. InternVL2) behave differently when ReGuide is applied could add nuance to the conclusions.' This claim is supported by the logical reasoning that investigating specific models can reveal modelspecific behaviors. The suggestion to 'present differences in FPR' provides a concrete way to verify this claim. Therefore, the claim is verifiable and supported by a logical reasoning.", "helpfulness_rationale": "The review point provides specific suggestions for the authors to investigate, such as 'present differences in FPR' and 'investigating specific models'. These suggestions are directly related to the paper's findings and offer concrete directions for further analysis. The suggestions are actionable and build upon the paper's conclusions, making them helpful for improving the comparison and understanding modelspecific behaviors. While not groundbreaking, these suggestions are valuable additions to the analysis."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'should be supplemented,' indicating a direct action the authors should take. While it doesn't specify *what* should be supplemented, it clearly identifies the need for more information on the comparison between the search methods. This makes it 3 as the authors know they need more details, but the exact nature of the missing information isn't defined.", "grounding_specificity_rationale": "The comment explicitly mentions 'Iteratively greedy Search,' 'random search,' and 'model structure.' This allows the authors to precisely identify the parts of the paper being referenced, making it fully grounded. However, it doesn't specify *what* aspects of the comparison are lacking, making it underspecific regarding the *what*.", "verifiability_rationale": "The comment itself does not contain a claim or assertion. It's a request for more information. Therefore, it doesn't fit into the verifiability categories as it lacks a definitive statement that can be verified.", "helpfulness_rationale": "The comment identifies a relevant area (the comparison of search methods) and suggests providing more information. While it doesn't provide the specific details, it clearly points to a need for improvement in that area. This makes it 3 as it guides the authors towards a specific area for refinement, even if the guidance is broad."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states that the axes of Figure 1 are unclear. This is a direct and actionable piece of feedback for the authors.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1', which is a specific part of the paper. It also clearly identifies the issue as the axes being unclear. This is 5.", "verifiability_rationale": "The comment itself does not contain a claim in the sense of a definitive statement requiring justification. However, the lack of understanding of the axes can be interpreted as an implicit claim that the figure is not welllabeled. This claim is 3 because the lack of understanding serves as evidence, although it doesn't point to a specific error or missing element.", "helpfulness_rationale": "The comment directly points out a specific area of confusion (the axes of Figure 1) and encourages the authors to look at the figure. This is a clear and actionable piece of feedback that directly addresses a concrete issue."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that '2 Direct runtime comparisons with existing methods are missing' and suggests a reason for this absence ('The proposed approach is based on implicit differentiation which usually requires additional computational costs.'). This clearly identifies an actionable item for the authors to address, specifying both the type of comparison and the reason for its absence. The action is explicit, and the details are concrete.", "grounding_specificity_rationale": "The review point mentions 'direct runtime comparisons' as a missing element. While it identifies the *type* of comparison, it doesn't specify *which* runtime comparisons are needed or *why* they are important in the context of the authors' work. The grounding is weak because it doesn't pinpoint the exact missing information within the broader category of 'direct runtime comparisons'.", "verifiability_rationale": "The review point makes a claim that 'direct runtime comparisons with existing methods are missing'. It also provides a justification for this claim by stating that 'the proposed approach is based on implicit differentiation which usually requires additional computational costs'. This justification, while not a direct citation, is a logical deduction based on the information provided. Therefore, the claim is verifiable through logical reasoning.", "helpfulness_rationale": "The review point directly identifies a significant omission in the evaluation of the authors' method by pointing out the lack of direct runtime comparisons. This is a crucial aspect for assessing the practical applicability of the proposed approach. The point is clear, concise, and directly suggests a concrete improvement for the authors, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the comparison between focusing on 'best' clusters and analyzing differences in representation, making the action clear. The reviewer directly identifies the two aspects being compared and the perceived inconsistency.", "grounding_specificity_rationale": "The comment refers to 'clusters' and 'representation,' which are general terms. While it doesn't explicitly point to a specific section, table, or figure, these concepts are central to the paper's topic. The grounding is weak because the reviewer is making a general point about the approach rather than referring to a specific element of the paper. The specificity is high as the reviewer clearly identifies the two aspects being compared.", "verifiability_rationale": "The comment contains a claim ('Focusing on which clusters are \"best\" rather than what the differences in representation are between them, seems an odd choice'), but it lacks justification or reasoning. There are no logical arguments, examples, or references to external sources provided to support why the reviewer finds this approach 'odd'. The evidence is purely subjective and based on the reviewer's interpretation of the paper's motivation.", "helpfulness_rationale": "The comment raises a potential inconsistency in the paper's approach. By highlighting the difference in focus, it implicitly suggests that the paper might be missing a more detailed analysis of the differences in representation. This could be helpful for the authors to understand if they are missing a key aspect of their work. However, the comment itself doesn't directly suggest a solution or provide a clear direction for improvement, making it 3 but not fully constructive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of 'discuss case studies and error studies' and provides a specific example of how this might be done in relation to the paper's concepts. The reviewer also explains the benefit of this approach (to highlight effectiveness). This makes the action clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'case studies and error studies' and provides a specific example related to a concept discussed in the paper ('Elementlevel Graph Pretraining abandons the strategy of capturing the complex structure but focuses directly on the core elements'). This demonstrates a clear understanding of the specific aspects of the paper being discussed and provides concrete examples.", "verifiability_rationale": "The reviewer makes a claim ('It could be convincing to discuss case studies and error studies to highlight the effectiveness of each proposed component') and provides logical reasoning ('to demonstrate effectiveness') and a specific example ('by contrasting Elementlevel Graph Pretraining with complex structure capture') to support this claim. The reasoning is clear and provides a basis for understanding the reviewer's point.", "helpfulness_rationale": "The review point is 5 as it directly addresses a common challenge for authors: demonstrating the practical effectiveness of their proposed components. By suggesting concrete methods like case studies and error studies, the reviewer provides a clear path for authors to strengthen their work. The specific example further enhances the helpfulness by illustrating how this might be applied in a relevant context."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer is implicitly suggesting that explicitness (E) and size (S) should be considered as extra evaluation aspects. While they don't explicitly state 'Consider E and S,' the context implies this action. Therefore, it's 2.", "grounding_specificity_rationale": "The reviewer refers to specific concepts like 'DCI framework,' 'ES,' 'probing capacity,' 'latent size,' and 'disentanglement (D) of different representation methods.' This demonstrates strong grounding as they identify specific parts of the paper and how the suggested aspects relate to them. The reviewer also provides examples like 'changing the capacity of probing or the latent size then the DCI evaluation also changes correspondingly,' which further clarifies the grounding.", "verifiability_rationale": "The reviewer makes a claim that 'DCI and ES may be entangled with each other.' They provide examples like 'For instance, to evaluate the disentanglement (D) of different representation methods, you may need to use a fixed capacity of probing (f), and the latent size should also be fixed. DCI and ES may be entangled with each other. For instance, if you change the capacity of probing or the latent size, then the DCI evaluation also changes correspondingly.' This claim is supported by logical reasoning and examples, making it highly verifiable.", "helpfulness_rationale": "The reviewer's point is highly relevant to researchers working on representation learning. By highlighting the potential entanglement of DCI and ES with probing capacity and latent size, they are providing a concrete suggestion for improvement. This directly addresses a potential ambiguity for researchers trying to understand how to evaluate their methods. Therefore, the review is 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a potential weakness ('practical and safe for querying in the real world') but does not explicitly state what needs to be done or how to achieve this. While it implies a concern, the action is not clearly defined.", "grounding_specificity_rationale": "The comment does not specify which 'types of interventions' are being referred to, nor does it point to a specific section or table in the paper. The reference is general and lacks specificity.", "verifiability_rationale": "The comment contains a claim ('it would be important to think about whether they are practical and safe for querying in the real world') but does not provide any supporting evidence, reasoning, or references to back it up. It is presented as a statement of concern without justification.", "helpfulness_rationale": "The comment raises a valid concern about the practicality and safety of the interventions but does not offer any suggestions or guidance on how to address this concern. It is a statement of a problem without proposing solutions."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their opinion ('I am not convinced') and proposes a concrete alternative ('they can be interchangeable'). This indicates an explicit action and a clear suggestion, making it 3. While the reviewer doesn't detail the exact steps to take, the suggestion itself is a clear action point.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly refer to a specific part of the paper (e.g., a section, table, figure, or a unique element). They are making a general comment about a methodological choice. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer's point is a matter of opinion and interpretation of a methodological choice. There is X that requires external verification or justification. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The reviewer directly challenges a specific idea and offers a clear alternative. This provides the authors with a point of contention and a potential direction for improvement, making the review 3. While it doesn't demand a specific change, it offers a concrete suggestion that can guide the authors' thinking."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the uncertainty regarding the contribution of each component and proposes a specific action: 'evaluate on baseline detection or parsing techniques separately'. This is an explicit and concrete action that authors can readily follow to understand the impact of each component.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed method' and its 'two major components' but does not explicitly identify a specific section, table, or figure within the paper. While they suggest 'evaluating on baseline detection or parsing techniques separately', this is a general methodological suggestion and not a specific element within the paper being criticized. Therefore, the grounding is not fully explicit.", "verifiability_rationale": "The review point contains a claim: 'It is unclear which component contributes to the performance gain.' The reviewer then suggests a method to verify this claim by 'evaluating on baseline detection or parsing techniques separately'. This is a suggestion for verification, although it might not be the only or most comprehensive way to verify the claim. Therefore, the claim is verifiable but not definitively proven by this suggestion alone.", "helpfulness_rationale": "The review point clearly identifies a potential issue (unclear contribution of components) and provides a concrete suggestion for improvement (evaluating on baselines). This directly addresses a potential weakness and offers a clear path for the authors to gain more insight into their method's performance. The reviewer's feedback is directly actionable and addresses a specific concern."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue with the manual disentanglement process and the specific placement of the semantic segmentation network. While it doesn't explicitly state what action should be taken, it points to a *specific* aspect of the pipeline that could be improved. The reviewer suggests exploring a fully learned pipeline, implying a desire for a different approach. This indicates a degree of explicitness by focusing on a specific part of the paper (the manual disentanglement and the first module). However, the reviewer doesn't provide concrete steps on how to *fix* the issue, making it less actionable than a point that directly tells the authors what to do. The reviewer identifies the *problem* (manual disentanglement) and suggests an *alternative* (a fully learned pipeline), but lacks specific guidance on how to implement the alternative.", "grounding_specificity_rationale": "The review point explicitly mentions the 'manual disentangling' process and specifically identifies the 'semantic segmentation network' as the first module in the pipeline. This allows the reviewer to *identify* the specific part of the paper being addressed. The reviewer then asks 'Why is that? Why not something else?', indicating a desire for justification and a suggestion for a different approach. This demonstrates a strong sense of grounding specificity as the reviewer is not just stating a general problem but pinpointing a specific aspect of the methodology. The reviewer provides a *unique* element (the specific module being the first in the pipeline) as evidence of their focus on this specific part of the paper. The reviewer's question and suggestion for an alternative further emphasize the grounding of the identified issue.", "verifiability_rationale": "The review point does not contain a claim in the sense of stating an opinion or a suggestion that requires justification. It's a question and an observation about the manual disentanglement process. While the reviewer identifies a potential issue and suggests an alternative, they do not provide any logical reasoning, common knowledge, or external references to support their point. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The review point raises a valid concern about the manual disentanglement process and suggests an alternative approach. The reviewer's question about 'why' and 'why not something else' indicates a desire for a deeper understanding and a potential improvement. While the review point doesn't directly tell the authors what to do, it identifies a potential area for improvement and offers a direction for future work. The reviewer's suggestion to explore a fully learned pipeline is a concrete and potentially impactful idea. Therefore, the review point is 3 as it points out a potential limitation and offers a constructive suggestion, even if it doesn't provide a definitive solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment explicitly states a question about the method's behavior without the Lipschitz Hessian assumption. This directly points to a missing piece of information. However, it doesn't provide concrete steps or details on how the method behaves in this scenario. The action is implied but not explicitly stated and explained.", "grounding_specificity_rationale": "The comment asks a question about the method's behavior, implicitly referencing a general aspect of the method. It doesn't explicitly name a specific section, table, figure, or unique element. While it identifies a potential area for improvement (lack of clarity), it doesn't pinpoint the exact location within the method's description where this behavior is discussed. The grounding is implied rather than explicitly stated.", "verifiability_rationale": "The comment is a question posed to the authors, asking about the method's behavior without a specific assumption. It does not contain a claim that requires verification. The question itself is a request for information rather than a statement that needs to be proven.", "helpfulness_rationale": "The comment identifies a potential area for improvement (lack of clarity regarding the method's behavior without the Lipschitz Hessian assumption) but does not provide concrete guidance or steps for the authors to take. It's a question that highlights a potential weakness but doesn't directly instruct or provide solutions. Therefore, it's not 5 as it doesn't directly address how to improve the draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem (jumbledness) but does not specify how the author should address it. It lacks concrete steps or instructions for improvement.", "grounding_specificity_rationale": "The review point mentions 'writing / presentation' generally but does not specify which part of the paper is jumbled or what specific issues are present. It lacks precision in identifying the problematic section or element.", "verifiability_rationale": "The review point is a statement of opinion ('I found the writing / presentation a bit jumbled') without providing any evidence or justification. It does not make a claim that requires verification or support.", "helpfulness_rationale": "The review point identifies a valid issue (jumbledness) but does not offer specific actionable steps or suggest improvements. It lacks constructive guidance for the author."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a concern about computational complexity and power demand, which can be directly addressed by modifying the paper. The reviewer also identifies 'Woodbury flow' and 'mobile device' as specific aspects of the paper being addressed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Woodbury flow' and 'computational complexity' specifically, and also mentions 'mobile device' and 'power demand'. This clearly identifies the specific parts of the paper being addressed.", "verifiability_rationale": "The reviewer is asking for information (computational complexity comparison, power demand) that is not currently present in the paper. They are *asking for* this information, not making a claim that *can be verified* with existing knowledge.", "helpfulness_rationale": "The reviewer identifies a relevant problem (potential power demand for mobile devices) and points to a lack of information (computational complexity) in the paper. However, the review does not actively suggest how to address the power demand or recommend alternative methods within the paper itself. It's a call for external information rather than direct constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a limitation ('not seem to be scalable') and suggests a concrete solution ('developed. It's not reasonable to expect a single instance can hold all the training data that the real world datasets ususally contain.'). While the suggestion is broad, it points to a clear direction for improvement. The action is explicit, and the potential action (developing a distributed version) is concrete, even if the details are not fully elaborated. The comment implies the current method is limited by this scalability issue, which is an inference but still points to a actionable improvement.", "grounding_specificity_rationale": "The comment identifies a limitation of the method in the context of realworld datasets but does not explicitly point to a specific section, table, figure, or unique aspect of the paper it is reviewing. While it mentions 'training data' generally, it doesn't specify which part of the paper the method is struggling with in relation to its training data requirements. The grounding is implied rather than explicit. The specificity is limited to the general issue of handling large datasets, without detailing specific components of the paper being reviewed.", "verifiability_rationale": "The comment states a limitation ('not seem to be scalable') and suggests a solution ('developed. It's not reasonable to expect a single instance can hold all the training data that the real world datasets ususally contain.'). This is a statement of observation and suggestion, not a claim that requires verification or justification based on evidence. The comment does not present a logical reasoning, common knowledge, or external references to support the identified limitation. It's a statement of fact about the method's limitations in the context of realworld data.", "helpfulness_rationale": "The comment identifies a practical limitation of the method ('not seem to be scalable') and offers a suggestion ('developed. It's not reasonable to expect a single instance can hold all the training data that the real world datasets ususally contain.'). This points to a clear area for improvement and provides a direction for the authors to consider. While it doesn't provide specific details on how to implement the distributed version, it does suggest a concrete action that could address the identified problem. The feedback is relevant and actionable, even if it lacks specific implementation details. It helps the authors understand a limitation of their method and what they could potentially do to overcome it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential issue in the results (lack of significant difference) and points to a missing theoretical component (lack of justification for Algorithm 1). However, it doesn't explicitly state what needs to be done to address these issues. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The comment refers to 'Fig.5' and 'StableDiffusion' when discussing the performance difference, indicating some level of grounding. However, it doesn't specify which part of Fig.5 or which StableDiffusion implementation is being referred to. Similarly, when mentioning 'Algorithm 1', it's unclear which specific algorithm is being discussed. This lack of specificity weakens the grounding.", "verifiability_rationale": "The comment makes claims about the results (lack of significant difference) and the methodology (lack of justification for Algorithm 1). However, it doesn't provide any evidence or reasoning to support these claims. The claims are presented without sufficient justification or references, making them 1.", "helpfulness_rationale": "The comment points out a potential issue in the results (lack of significant difference) and highlights a missing theoretical component (lack of justification for Algorithm 1). While it identifies a gap, it doesn't offer specific suggestions or directions for investigation. The feedback is present but lacks concrete guidance, making it 3 in pointing out areas needing improvement but not in providing actionable steps."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly suggests a change to the notation of triples at line 122. The suggestion is to replace the set notation with a tuplelike structure, which is a specific action. While the 'why' isn't explicitly stated, the implication is that the current notation is less clear or useful for demonstrating the tuplelike structure. The reviewer provides a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer explicitly points to line 122 as the location of the triples being discussed. This is a strong indication of grounding as the reviewer can accurately pinpoint the referenced part of the paper. The reviewer also explains *why* the triples are being discussed (to show their tuplelike structure), which further grounds the comment by providing context and a specific reason for the issue.", "verifiability_rationale": "The reviewer presents a suggestion for improvement: changing the notation of triples at line 122. This constitutes a claim that the current notation is an issue. The reviewer provides a specific suggestion (replacing set notation with a tuplelike structure) to address this issue. However, the reviewer does not provide any external references or logical reasoning to support why the current notation is problematic or why the suggested change is the best solution. The justification is implicit, relying on the reader's understanding that set notation might not be the most appropriate for this specific purpose.", "helpfulness_rationale": "The reviewer provides a specific suggestion for improvement: changing the notation of triples at line 122. This is a clear and actionable piece of feedback directly related to the identified issue. The suggestion is easy to understand and directly addresses the problem described. While the reviewer doesn't provide a justification for *why* this change is beneficial beyond the current notation being unclear, the suggestion itself is concrete and directly actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a limitation of the proposed method (quantization's scalability issues) and connects it to the paper's stated goal (fast convergence). However, it does not provide concrete suggestions on how to overcome this limitation or alternative approaches. The action is stated, but the implementation details are missing.", "grounding_specificity_rationale": "The comment does not explicitly refer to any specific part of the paper (e.g., a particular section, table, or figure). It is a general critique about the method's limitations in the context of the paper's goal. Therefore, the grounding is weak as the authors cannot pinpoint the exact area being discussed.", "verifiability_rationale": "The comment presents a critique about the scalability of quantization and its impact on the paper's goal. While it identifies a problem, it doesn't provide any evidence or references to support this claim. The claim is stated, but the justification is lacking.", "helpfulness_rationale": "The review point raises a valid concern about the limitations of quantization in the context of the paper's goal. It challenges the authors to consider the scalability issues and whether alternative methods might be more suitable. While it doesn't offer a specific solution, it prompts the authors to critically evaluate their chosen method and its implications for their work. This encourages a deeper reflection on their approach."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for a comparison to contrastive decoding methods and highlights the potential notational issues. This indicates a clear action the authors should take. However, the specifics of the comparison and the nature of the notational issues are not detailed, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'existing methods, such as contrastive decoding' and 'notations issues' generally. While they identify a category of methods and a general problem, they don't pinpoint a specific section, table, figure, or unique aspect of the paper that needs improvement regarding these issues. The notational issues are also described generally without specifying which notations are problematic or why they are problematic.", "verifiability_rationale": "The reviewer makes a statement about the paper needing a 'contrastive response tuning: as part of the core methodology, the paper should compare its effectiveness against existing methods, such as contrastive decoding'. This is a claim that requires justification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a requirement or a suggestion without any backing.", "helpfulness_rationale": "The reviewer raises concerns about the lack of a comparative evaluation against existing methods and the potential notational issues. These are valid points that could be helpful for the authors to consider. However, the reviewer's statements are general and lack specific details or justifications. While the concerns are valid, the reviewer doesn't provide concrete reasons *why* these issues are critical or *how* they impact the methodology. The suggestions are present but lack depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a limitation of the algorithm (its dependence on the full training dataset) and criticizes the lack of analysis. While these are valid concerns, the review point itself does not explicitly instruct the authors on how to address these issues. The reviewer's statement is more of a problem identification than a direct action. To be actionable, the review point should provide a clear next step for the authors to take, such as 'Implement a minibatch approach' or 'Analyze the computational complexity of your algorithm'. The current point identifies a problem but doesn't offer a concrete solution or a clear path forward beyond discussing it.", "grounding_specificity_rationale": "The reviewer mentions 'the algorithm' and 'training dataset' as areas of concern. While they point to specific components, they don't pinpoint a specific section, table, figure, or unique aspect within the paper. The reviewer is broadly referring to the algorithm's dependence on the full dataset and the lack of analysis. They could have been more specific, for example, by saying 'The description of the algorithm in Section 3.2 needs to be more detailed' or 'The experimental setup in Section 4.1 should include a discussion of computational cost'. The current point identifies broad areas but lacks the specificity to clearly locate the issue within the paper.", "verifiability_rationale": "The reviewer makes claims about the algorithm's limitations (requiring access to the entire training dataset) and the lack of technical contribution. These are claims that could potentially be supported with evidence. For example, the reviewer could have provided a citation to support the claim about the algorithm's dependence on the full dataset or cited existing work on minibatch algorithms to suggest an alternative. However, the *review point itself* does not provide any evidence to support these claims. The reviewer is stating observations, but without backing, it's difficult to assess the verifiability within the review point. The reviewer's claims are general and could apply to many algorithms, making it hard to pinpoint specific verifiable information within the review point.", "helpfulness_rationale": "The reviewer raises valid concerns about the algorithm's limitations and the need for a more technical contribution. This feedback is relevant and constructive, as it points out areas where the authors could improve their work. The reviewer suggests considering alternative scenarios (no full dataset) and elaborating on the technical contribution. While the reviewer doesn't provide specific solutions, their suggestions are actionable and directly address potential weaknesses. The feedback is focused on the algorithm's design and its practical implications, offering the authors a direction for further development. The reviewer's comments are pertinent to improving the paper and provide a clear direction for the authors to consider."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a specific technical inaccuracy regarding the representational power of neural networks in relation to Reproducing Kernel Hilbert Spaces (RKHS). They state that for RBF kernels, the RKHS is famously infinitedimensional, requiring an NN with infinite width to represent it. This directly identifies a limitation in the paper's claim that every kernel can be described by a feature space parameterized by a neural network. The reviewer suggests making this limitation more clear, which is an explicit and actionable point for the authors.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'every kernel can be described by a feature space parameterized by a neural network' and provides a specific example: 'For instance, for RBF kernels, the RKHS is famously infinitedimensional, such that one would need an NN with infinite width to represent it.' This clearly identifies a specific area within the paper being discussed. The reviewer then elaborates on the limitation, stating 'So at most, NNs can represent finitedimensional RKHSs in practice.' This demonstrates a clear understanding of the specific issue and provides a detailed explanation, making the grounding fully specific.", "verifiability_rationale": "The reviewer provides a clear explanation of the technical issue, stating that RBF kernels have infinitedimensional RKHSs, which cannot be represented by finitewidth neural networks. While they don't explicitly cite a paper, the reasoning is wellestablished within the field of kernel methods and neural networks. The reviewer's explanation is logical and precise, making the claim 5.", "helpfulness_rationale": "The reviewer's point is 5. They identify a specific technical limitation in the paper's claim and provide a concrete example (RBF kernels and infinitedimensional RKHSs). They also suggest making this limitation clearer, which is a direct and useful piece of feedback for the authors. This type of specific and actionable feedback is 5 for improving the clarity and accuracy of the paper."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point directly asks a question about the behavior of linear attention during inference, which is an explicit action. The reviewer is seeking clarification on how the model handles autoregressive decoding with long input sequences during training and shorter sequences during generation. This directly points to a potential action the authors might take.", "grounding_specificity_rationale": "The review point explicitly mentions 'linear attention,' 'autoregressive decoding,' and the difference in token dimensions during training and generation. This clearly grounds the comment to a specific part of the paper and the issue being addressed. The reviewer is asking about the implications of these specific factors.", "verifiability_rationale": "The review point is a question and does not contain a claim or assertion that needs verification. It is asking for information rather than making a statement that requires supporting evidence. Therefore, it does not fit the criteria for verifiability.", "helpfulness_rationale": "The review point is highly relevant to the authors. It directly addresses a practical concern about the efficiency and effectiveness of using linear attention with varying sequence lengths during inference. The reviewer is asking for clarification on a specific aspect of their model's behavior, which can be very helpful for improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "4: Mostly Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a question and suggests further exploration, which implies a desire for more specific guidance. However, the exact action to be taken is not explicitly stated, making it only implicitly actionable.", "grounding_specificity_rationale": "The reviewer refers to 'Fig. 4', 'GPI', 'noise added', 'behavioral data', 'behavioral trajectories', 'time to goal', and 'pattern separation tasks'. These are specific elements, indicating a clear identification of the area being discussed and the variables involved.", "verifiability_rationale": "The reviewer suggests exploring 'alternative measures' and discussing the suitability of GPI for 'pattern separation tasks'. While these suggestions are relevant, they lack specific justification or examples, making it 3 but not fully so.", "helpfulness_rationale": "The reviewer provides concrete suggestions and questions aimed at improving the understanding of GPI's applicability and limitations. This directly contributes to the helpfulness of the review."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action: 'I would be very interested to see how the \u201csmall learning rate for attention parameters\u201d benchmark ... would compare with the proposed approach.' This action is concrete as it specifies the type of experiment and the comparison to be made. The authors know exactly what needs to be done and how to apply the action.", "grounding_specificity_rationale": "The comment explicitly mentions 'small learning rate for attention parameters,' which directly points to a specific aspect of the paper. This can be achieved through literal mentions of sections, tables, figures, etc., or through general comments that clearly imply the relevant parts without explicitly naming them. In this case, the mention of 'attention parameters' strongly implies a specific location within the paper. Therefore, the authors can accurately pinpoint the section, table, figure, or unique aspect being addressed.", "verifiability_rationale": "The comment contains a claim: 'I would be very interested to see how the \u201csmall learning rate for attention parameters\u201d benchmark ... would compare with the proposed approach.' This claim requires verification through the authors' own implementation and comparison of results. The reasoning is logical: the authors can run the suggested experiment and compare the outcomes to validate the proposed approach. External references are not directly needed as the comparison is between two internal experiments.", "helpfulness_rationale": "The comment is 5 as it provides a concrete experiment to validate the proposed approach. The authors can directly take this suggestion and run the experiment, which will provide valuable feedback on the effectiveness of the proposed method. The request for a comparison is also a helpful direction for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the paper 'carelessly resolves a debate' (an explicit action) and suggests 'specific experiments' to be conducted to disentangle distribution shifts from the removal of information (a concrete action). The reviewer's suggestion is a direct and actionable improvement to the paper.", "grounding_specificity_rationale": "The reviewer refers to 'a previously careful to leave open (L29)' which implies they are identifying a specific location in the paper where the debate was previously handled, thus grounding the issue. The reviewer then 'clearly specifies' the potential issue (distribution shift) and 'suggests specific experiments' to address it, making the grounding and specificity high.", "verifiability_rationale": "The reviewer makes a claim about the paper's 'careless resolution' and suggests 'experiments' as a way to verify it. While the reviewer doesn't provide direct evidence or references to support this claim, the suggestion of experiments provides a basis for verification. The claim is somewhat inferable from the suggested experiments.", "helpfulness_rationale": "The reviewer raises a significant point about the paper's methodology and suggests concrete actions to improve it. While the reviewer doesn't provide direct evidence to support their claim about the paper's careless handling, the suggestions for experiments offer a clear path forward. The reviewer's point has the potential to be very helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the difference in training settings (AdamW with cosine LR vs. Adam with fixed LR) used for the proposed method and the baselines. This is a clear and direct action identified by the reviewer.", "grounding_specificity_rationale": "The reviewer mentions 'AdamW with cosine lr for training' as a specific detail related to the training process. While they don't explicitly point to a specific section or table in the paper, they clearly identify a unique aspect of the experimental setup. The mention of 'unique aspect' suggests they are aware of a specific detail being discussed.", "verifiability_rationale": "The reviewer makes a claim that 'Directly comparing with their numbers in paper is unfair' due to the different training settings. They further explain that 'most of the recent methods have their code released' and suggest 'reproducing their results using the same setting'. This claim is supported by logical reasoning (different training settings can significantly impact performance) and the suggestion to use a common setting makes it verifiable.", "helpfulness_rationale": "The reviewer's point is 5 for the authors. They provide a concrete piece of information (different training settings) that could help the authors understand and reproduce the experiments more accurately. This directly addresses a potential gap in the authors' understanding of the experimental setup."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problems with the plots (terrible, too small, hard to distinguish, poorly labeled, visually similar) and implies an action by stating 'should be much clearer.' The reviewer also provides specific details about the issues and suggests concrete changes (larger, better contrast, clear labels, different labels). This demonstrates a clear understanding of what needs to be addressed and how.", "grounding_specificity_rationale": "The reviewer explicitly identifies the 'plots' as the area of concern and even specifies the exact plots being referred to ('sdropout(tr)' and 'edropout(tr)'). They go beyond identifying the plots and detail the specific problems within them (size, color contrast, labeling, label similarity) and even suggest what the improved plots should look like (larger, better contrast, clear labels, different labels). This demonstrates a high level of precision in identifying the problem.", "verifiability_rationale": "The reviewer makes a claim about the quality of the plots ('These plots are terrible') and provides reasons for this assessment ('They are too small, the colors are hard to distinguish...'). While the reasons are subjective, they offer a logical explanation for why the plots are considered poor. The reviewer doesn't claim external references are necessary to understand why these are bad plot design choices.", "helpfulness_rationale": "The review point is 5 because it directly addresses a significant weakness in the paper's presentation (plot clarity) and provides very specific and actionable suggestions for improvement. The reviewer not only identifies the problem but also explains *why* the plots are problematic and *how* they should be improved. This level of detail is very valuable for the authors to understand and implement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state an action or suggestion for the feedback network. It raises a question about the utility of specific feedback information, but does not propose a concrete change or improvement based on this information. Therefore, it lacks explicit and direct actionable feedback.", "grounding_specificity_rationale": "The reviewer asks about the utility of 'information about incorrect phrase / corrected phrase and the information about the type of the mistake'. While they don't specify a *part* of the paper where this information is located, they are asking about the *information itself*. This is a step towards grounding, but not a full grounding as it doesn't pinpoint a specific element within the paper (e.g., a section, table, or figure). Therefore, it is only somewhat grounded.", "verifiability_rationale": "The review point is a question, not a statement containing a claim. There is X being made or supported by evidence within the review point itself. Therefore, it does not have verifiable content.", "helpfulness_rationale": "The review point questions the value and utility of specific feedback information for a feedback network. It does not provide a suggestion or improvement for the authors based on this information. Therefore, it is not inherently helpful in its current form as it doesn't offer actionable advice to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that Table 1 does not show standard deviations. However, it does not specify how the authors should go about adding them. The action is stated, but the implementation details are missing, making it somewhat vague.", "grounding_specificity_rationale": "The comment refers to 'Table 1,' which is a specific part of the paper. However, it does not specify *which* Table 1 or provide a unique identifier. Therefore, the grounding is weak as the authors need to infer the intended table.", "verifiability_rationale": "The comment states that 'Table 1 does not show standard deviations' without providing any justification or reasoning. There is X made, so the verifiability is not applicable to this specific statement. However, if we consider the reviewer's intention behind stating 'this includes,' they are likely implying a lack of rigor in reporting statistical data, which could be considered implicitly verifiable knowledge in the field. But based *only* on the given statement, there is no explicit claim or supporting evidence.", "helpfulness_rationale": "The comment points out a factual error in the paper (missing standard deviations in Table 1). This is a valid observation that could help the authors improve their work. However, the comment is brief and lacks specific details about *why* this is a problem and *how* it affects the results. Without further clarification from the reviewer, the authors cannot effectively address the issue."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question about the interpretation of the results, which can be directly addressed by reevaluating the data. The suggestions to 'reevaluate the results' and 'explore a different baseline' are clear actions the authors can take. The specificity of the suggestions (reevaluating, trying a different baseline) makes the action concrete.", "grounding_specificity_rationale": "The reviewer refers to 'LinearTop,' 'NLTop,' and 'Unary' in the context of the experimental results. While the *content* of these models is relevant to the discussion, the reviewer does not explicitly state which table or section of the paper these correspond to. This makes the grounding weak. However, the reviewer does specify the models being compared, which adds some level of specificity to the *content* of the potential issue.", "verifiability_rationale": "The reviewer poses a question about the interpretation of the results without providing specific evidence or references to support their claim. The suggestion to 'try a different unary baseline' is a direction for further investigation but doesn't offer a definitive answer or a specific experiment to try. The claim is that the interpretation of the results is flawed, but the reviewer doesn't provide the 'why' or the 'how' to verify this claim.", "helpfulness_rationale": "The reviewer raises a valid concern about the interpretation of the experimental results and suggests exploring a different baseline. This directly points to a potential area for improvement in the paper. The suggestions are actionable and relevant to the authors' work. However, the reviewer does not provide a specific solution or a clear path to verify their claim, making the feedback somewhat general and requiring further investigation from the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The suggestions are implied and broad, making the actionability low.", "grounding_specificity_rationale": "The reviewer can identify the sections and figures being referred to, but the specific nature of the improvement is missing, making grounding specificity low.", "verifiability_rationale": "The reviewer's suggestions are recommendations for improvement, not statements that can be verified as true or false based on the paper's content. They are *suggestions*.", "helpfulness_rationale": "The suggestions are relevant and actionable for the authors, directly addressing potential weaknesses and proposing concrete improvements."}
{"actionability_label": "1", "grounding_specificity_label": "4: 5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is not directly telling the authors what to do. They are asking for information (final learning rates) rather than providing a direct action. While this points to a weakness in the paper (lack of information), it doesn't provide an actionable step for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'deep models, particularly CIFAR10 and CIFAR100', which clearly identifies the specific part of the paper they are referring to. This demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are simply stating a factual request about the experimental setup. There is no logical reasoning, common knowledge, or external references being provided to support a claim.", "helpfulness_rationale": "The reviewer is highlighting a missing detail (final learning rates) that could be relevant for understanding and potentially improving the results. While it doesn't directly provide a solution, it points to a potential area for clarification or improvement in the paper. Therefore, it has some level of helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their disagreement with the 'transformer free of localitybias' model and suggests an alternative ('neighborhood agents'). This is a clear and actionable suggestion for the authors to consider a different model architecture. The reviewer identifies a specific aspect of the model and proposes a concrete change.", "grounding_specificity_rationale": "The reviewer mentions 'transformer free of localitybias' but does not specify which part of the paper this refers to. They do not provide a unique identifier like a section, table, or figure number. While they suggest an alternative, they don't explain *why* this specific model is problematic within the context of the paper. The grounding is weak because the authors cannot pinpoint the exact location of the issue.", "verifiability_rationale": "The reviewer makes a claim: 'I am not convinced that transformer free of localitybias is indeed the best option.' However, they do not provide any specific evidence or reasoning to support this claim within this review point. They suggest an alternative but do not justify why the current model is problematic. The verifiability is low because the claim is presented without sufficient backing or explanation.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the model choice and offers a constructive suggestion for improvement by proposing a model with locality bias. This demonstrates an attempt to help the authors by pointing out a potential area for adjustment. While the reviewer doesn't provide concrete evidence for their claim in this point, the suggestion itself is a helpful direction for the authors to consider. The feedback is present, even if the justification for the claim is missing."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out that the proposed approaches only outperform the baselines in 1 out of 3 setups. While this identifies a limitation of the proposed methods, it doesn't explicitly state what action needs to be taken to address this. The reviewer suggests additional experiments or more indepth analysis, but doesn't provide specific, actionable steps within the review itself.", "grounding_specificity_rationale": "The reviewer mentions 'Table 2' and 'setup' when criticizing the results. This indicates an attempt to ground the comment to a specific part of the paper. However, they don't specify which exact part of Table 2 or which specific setup is problematic. The reference is somewhat general.", "verifiability_rationale": "The reviewer states that the results are 'insufficient to prove the benefits of the proposed methods' and provides some reasoning by pointing out the limited positive results and inconsistent trends. This claim is supported by logical reasoning (the lack of consistent positive results) and common knowledge (the need for robust evidence). However, it lacks external references to back up the claim.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the experimental evaluation (limited positive results, inconsistent trends) and suggests improvements (additional experiments, more indepth analysis). This directly helps the authors understand a problem with their current work and provides a direction for future work. While the suggestions are broad, the identification of the problem is clear and actionable."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the \"impact of these heuristic components\" but does not provide explicit instructions or actions for the author to take. It identifies a potential area for further analysis but doesn't guide the author on how to analyze or address it.", "grounding_specificity_rationale": "The review point mentions \"NonAmbiguous Query Generation procedure\" and \"filtering template,\" which are specific elements within the paper. However, it doesn't explicitly point to a specific line number, algorithm, or example within those sections. While it names a section, it doesn't pinpoint the exact element within it.", "verifiability_rationale": "The review point presents a helpful suggestion (\"It would be helpful if the author could clarify...\") but doesn't make a claim that requires verification. It's a suggestion for further investigation rather than a statement of a problem or a missing element.", "helpfulness_rationale": "The review point identifies a potential area for improvement (the heuristic components) and asks a relevant question about their impact. It points the author towards a specific part of the paper and suggests further analysis. While it doesn't provide a solution, it prompts the author to think critically about a specific aspect."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their doubt about the method's reliance on camera information and the necessity of 'knowledge of CAD model correspondences' for ray marching. They directly reference Line 223 and the specific term, indicating a clear and actionable point of concern. The reviewer is suggesting that the method might not be applicable without this information, which is a concrete and actionable suggestion for the authors.", "grounding_specificity_rationale": "The reviewer directly references 'Line 223, the so called \"knowledge of CAD model correspondences\")' in their comment. This explicit mention of a specific line and a key component of the method demonstrates strong grounding. The reviewer is not making an educated guess but rather pointing to a specific location in the paper where their concern arises.", "verifiability_rationale": "The reviewer expresses a doubt about the proposed method's ability to perform ray marching without camera information. This statement can be considered a claim that needs verification. While the reviewer doesn't provide external references or logical reasoning within their comment, the question itself points towards a potential limitation or a point of clarification that could be supported by arguments or evidence. The claim is not inherently 1, but the current state of the review point doesn't fully demonstrate its verifiability.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the method's reliance on camera information. This could be helpful for the authors to understand the method's limitations and assumptions. However, it also presents a potential point of criticism or doubt, which might not be universally helpful. The helpfulness is moderate as it provides a point for discussion but doesn't offer a direct solution or improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the paper would benefit from a more detailed comparison with related work. This is a clear indication of an actionable suggestion. Furthermore, the reviewer specifies the *what* of this comparison, mentioning 'time complexity' and 'competitiveness,' which provides concrete details on how this detailed comparison should be conducted.", "grounding_specificity_rationale": "The reviewer mentions 'related work,' 'time complexity,' and 'competitiveness.' While the exact section or table isn't specified, the focus on these specific aspects of related work indicates a degree of grounding. The reviewer also clearly identifies the *what* that needs to be addressed within these areas, contributing to some level of specificity.", "verifiability_rationale": "The reviewer states a suggestion for a more detailed comparison with related work. However, the review point lacks specific examples of *how* this comparison should be done, or references to existing literature that could guide this process. The 'minor' aspect mentioned is also vague and lacks grounding. Therefore, the claim is not wellsupported by evidence or justification.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper (lack of detailed comparison with related work) and provides a suggestion for improvement (adding a more detailed comparison). This indicates that the review has a meaningful impact on the authors' work. While the suggestion is somewhat general, it points towards a concrete change. The 'minor' aspect, however, lacks clarity and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the action \"conducing experiments,\" which is a clear indication of an explicit action. However, the suggestion is quite general and doesn't specify *how* the experiments should be conducted, making it somewhat vague on how to implement it.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"more datasets,\" which grounds the comment in a specific part of the paper. They also specify \"datasets,\" which clearly identifies the issue. This indicates a high level of grounding as the authors can easily identify the referenced part.", "verifiability_rationale": "The reviewer makes a suggestion \"I suggest conducting experiments on more datasets,\" which implies a limitation in the current work. However, they don't explicitly *explain* *why* more experiments are needed or provide specific examples or references. This makes the claim 3 as there is an implicit justification.", "helpfulness_rationale": "The reviewer's suggestion to add experiments on more datasets is clear and directly points to a way to improve the evaluation of the proposed method. While it could be more detailed, it is a valuable and actionable suggestion that empowers the authors to significantly improve their draft."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out that the paper lacks clarity regarding the purpose of the generic and random argument tasks in relation to the claims being made. While the reviewer identifies a problem (lack of clarity), they do not explicitly state how the tasks or the experimental setup should be modified to address this. The reviewer suggests making the connection clearer, but the specific actions or modifications are not detailed.", "grounding_specificity_rationale": "The reviewer mentions the 'generic argument task,' 'random argument task,' and the 'entire dataset transformation and the ensuing experimental setup' but does not explicitly identify the specific part of the paper being addressed. The connection between these elements and the 'claims' is implied but not clearly stated. The reviewer does specify what needs to be clarified (lack of connection), but not the precise section or element.", "verifiability_rationale": "The reviewer states that the paper 'proves what the authors claimed' was not clear. This is a claim made in the review point. The reviewer's statement about the lack of clarity can be considered a deduction or inferred observation based on their reading of the paper's structure and language. However, the reviewer does not provide specific examples or references from the paper to support this claim about the lack of clarity.", "helpfulness_rationale": "The reviewer suggests that the paper 'proves what the authors claimed' was not clear. This is a general comment about the clarity of the paper. While the reviewer identifies a problem, they do not offer a specific suggestion or solution to improve the clarity. The feedback is about the lack of information, not about how to provide it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a missing element and suggests a concrete improvement by stating 'the authors should provide this analysis for a fair comparison with the baseline 31, 33, *'. This is an explicit suggestion for action.", "grounding_specificity_rationale": "The reviewer mentions 'the impact of adding additional parameters and additional computational effort', which is a general statement about the process. While they identify a specific area, they don't explicitly identify the *part* of the paper being addressed (e.g., method, experiments). Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a clear statement: 'there is a complete lack of discussing the impact of adding additional parameters and additional computational effort'. This is a claim that can be verified by checking the paper for such discussions. While no external references are provided, the claim itself is verifiable within the context of the paper. The lack of discussion is a verifiable fact.", "helpfulness_rationale": "The reviewer clearly identifies a missing element in the paper and suggests a concrete improvement by stating 'the authors should provide this analysis'. This is a helpful comment as it directly points out a weakness and encourages the authors to address it. The suggestion is specific and actionable."}
{"actionability_label": "5", "grounding_specificity_label": "fully grounded", "verifiability_label": "partially verifiable", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem: 'It is not clear if this trend holds across different model architectures' and 'no theoretical evidence is advanced for this correlation'. It also suggests a solution: 'investigate different architectures' and 'seek theoretical explanations'. These are clear actions the authors can take.", "grounding_specificity_rationale": "The reviewer refers to 'the analysis of the correlation between dataset size and the Frobenius norm and the singular values.' This clearly identifies the specific part of the paper being discussed.", "verifiability_rationale": "The reviewer makes a claim: 'It is not clear if this trend holds across different model architectures' and 'no theoretical evidence is advanced for this correlation'. While the reviewer identifies a gap in the existing evidence, they do not provide specific examples or references to support this claim within the review point itself.", "helpfulness_rationale": "The review point is 5 because it directly guides the authors to investigate the identified issue by suggesting specific model architectures and a theoretical approach. This provides concrete directions for improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the issues: 'duplicates' and lists specific problems ('missing publication venues', 'missing publication years'). This is a direct and clear indication of what needs to be addressed.", "grounding_specificity_rationale": "The comment mentions the 'references list' but doesn't specify the exact section, table, figure, or unique aspect being addressed. It also doesn't clearly identify what is missing in the referenced part (e.g., specific examples of missing information). This is weak grounding. The comment specifies what is missing (duplicates, missing venues, missing years) but doesn't pinpoint the exact location.", "verifiability_rationale": "The comment contains a claim ('The references list contains duplicates and the publication venues and/or the publication years of many of the papers are missing.') but does not provide any justification or reasoning for why these are problems or how they should be addressed. It also doesn't suggest any external references or examples to support these observations. The claim is presented without sufficient evidence or explanation.", "helpfulness_rationale": "The comment identifies concrete issues with the references section, specifically pointing out the presence of duplicates and missing venue and year information. This directly informs the authors about areas that need correction. While it doesn't explain *why* these are problems or *how* to fix them, it provides a clear starting point for action."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'The theoretical analysis in Theorem 1 is unclear and weak' and provides a clear action: 'analyze and compare the theoretical results to other comparable methods'. The action is concrete, identifying the need to clarify the error bound and compare with other methods.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'The theoretical analysis in Theorem 1' and then specifies the issue as 'the error bound in Theorem 1'. They also suggest an improvement by 'comparing the theoretical results to other comparable methods'. This demonstrates a high level of grounding as the specific part of the paper and the issue within it are clearly identified. The suggestion for comparison is also specific.", "verifiability_rationale": "The reviewer makes a claim that 'the theoretical analysis in Theorem 1 is unclear and weak' and that 'the error bound in Theorem 1 means' and that 'the analysis needs to be compared with other comparable methods'. These are claims that could be supported by evidence, but the reviewer does not provide any justification or examples to back up these claims. Therefore, while the claims are present, they lack sufficient verification at this point.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement by stating 'the theoretical analysis in Theorem 1 is unclear and weak' and recommending 'analyzing and comparing the theoretical results to other comparable methods'. This directly addresses a potential weakness and offers a concrete next step for the authors, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "4: Mostly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the limitations of using lowresource language pairs and the R3F method, implying a need to explore alternatives. While they suggest considering other methods, the exact steps or datasets are not explicitly stated, requiring the author to infer the next steps. The lack of concrete action makes it 3 but not fully explicit.", "grounding_specificity_rationale": "The reviewer refers to 'lowresource language pairs' and 'improvement of 0.8', indicating a focus on specific aspects of the model and its performance. However, they do not explicitly name a specific section, table, or figure in the paper. While the context suggests they are referring to the experimental setup and results related to lowresource language pair finetuning, the lack of direct references makes it somewhat grounded but not fully specific.", "verifiability_rationale": "The reviewer makes a claim about the 'insignificance of the improvement' in a 'practical sense' and mentions a 'missing reference' as evidence. While the missing reference is a supporting element, the reviewer does not elaborate on why this specific reference supports their claim. The lack of a clear connection between the missing reference and the claim makes it 3 but not 5.", "helpfulness_rationale": "The reviewer identifies a potential issue with the reported improvement and suggests exploring alternative methods. While they provide a specific example of a missing reference, they do not offer concrete steps or suggestions for the author to take. The reviewer's point is relevant to the author's work, but the lack of a clear path forward makes it 3 rather than fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a question about the discrepancy between the claim of broad applicability and the limited experimental results. They ask 'Is there any particular reason for the same?' which is a direct and explicit action to seek clarification. The action is also concrete as the reviewer is asking about the reason for using only Gaussian noise when claiming applicability to various noise types. The reviewer is not inferring the need for justification, but directly asking for it.", "grounding_specificity_rationale": "The reviewer directly asks about the reason for the discrepancy between the claim of broad applicability and the limited experimental results. They are specifically asking about the connection between the claim made in the paper and the evidence presented. The reviewer is also asking about the *specific* reason for using only Gaussian noise. This directly addresses the 'grounding' aspect by linking the claim to the experimental setup. The request is also very specific, asking for the 'particular reason'.", "verifiability_rationale": "The reviewer is asking a question about the authors' decision to limit their experiments to Gaussian noise. This is not a statement of opinion or a claim that requires verification. The reviewer is seeking information or justification for a design choice made by the authors. While the request could be considered 3 if the authors explicitly state the reason, within the review point itself, there is no explicit justification provided by the reviewer or implied through logical reasoning, common knowledge, or external references. The reviewer is asking for a deduction or inference about the authors' methodology.", "helpfulness_rationale": "The reviewer's question is directly relevant to understanding the authors' methodology and the scope of their experiments. It could potentially lead to a better understanding of why the authors chose to focus on Gaussian noise. While it's not a direct critique or suggestion, it's a valuable question for the authors to consider and potentially address in future work. The question is specific and directly related to the paper's claims."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point directly addresses a specific claim in the paper (Corollary 10) and asks a clear question about the relationship between two concepts: 'Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss; this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate.' This allows the authors to directly verify the claim and understand the reviewer's point about the distinction between minimizing different loss functions. The action is explicit (identifying the claim and the question), and the implementation is clear (verifying the distinction).", "grounding_specificity_rationale": "The review point explicitly refers to 'Corollary 10' and the concepts of 'uncertainty sampling,' 'expected 01 loss,' and 'expected convex surrogate.' The reviewer names these specific elements, making it fully grounded. The grounding is explicit and obvious to the authors who would be familiar with the paper's content.", "verifiability_rationale": "The review point presents a claim about the relationship between minimizing the expected 01 loss and the expected convex surrogate in the context of uncertainty sampling. While the paper doesn't explicitly state this specific claim, the reviewer is making a logical deduction based on their understanding of these concepts. The evidence to verify this claim is implicit but can be inferred by understanding the definitions of descent directions and surrogate losses. The reasoning is logical, and the claim is supported by common knowledge in optimization theory.", "helpfulness_rationale": "The review point directly challenges a technical claim in the paper and asks a specific question that can lead to a deeper understanding of the theoretical underpinnings. The reviewer is pointing out a nuance that could be important for the authors' interpretation and application of their method. This is a valuable piece of feedback that encourages the authors to consider the distinction between different loss functions. The impact on the authors' work is significant as it prompts them to reevaluate their assumptions and potentially refine their approach."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of the reassignment probability (1/n) and the resulting slow dynamics, and they also explicitly state that the evolution model only changes edges related to the changing cluster. These are direct statements of what needs to be addressed and how it should be implemented.", "grounding_specificity_rationale": "The reviewer mentions 'the reassignment probability' and 'edges with the (on average) 1 node changing cluster' as areas of concern. While they point to aspects of the model, they do not explicitly identify a specific section, table, figure, or unique element of the paper being addressed. The criticism is about the model's behavior rather than a specific part of the paper.", "verifiability_rationale": "The reviewer makes claims about the limitations of the model, specifically stating that it produces only one node changing cluster per time step on average due to the reassignment probability and that the evolution model is simplistic by only changing edges related to the changing cluster. They provide logical reasoning to support these claims.", "helpfulness_rationale": "The reviewer provides clear and actionable feedback, explicitly pointing out the limitations of the model's dynamics and evolution model. They suggest potential improvements, such as considering a higher reassignment probability or a more complex evolution model, which directly addresses the identified weaknesses."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states what is missing (details about the train/test split) and implicitly suggests what needs to be done (provide the numbers and explain the splitting method). While the reviewer doesn't specify *what* the numbers should be or the exact splitting method, they clearly indicate the information is needed and how it should be presented. This makes it 3.", "grounding_specificity_rationale": "The reviewer does not explicitly mention a specific section, table, figure, or unique aspect of the paper being addressed. They are referring to the general process of splitting the data. However, the reviewer is quite specific about *what* is missing (train/test split details) and *how* it should be described (numbers and explanation). This specificity is in the content of the missing information, not in pinpointing a specific location within the paper.", "verifiability_rationale": "The reviewer is not making a claim that needs verification. They are simply stating that certain details are missing. There is no logical reasoning, common knowledge, or external references provided to support a claim. The statement is a factual observation about the lack of information.", "helpfulness_rationale": "The reviewer points out a valid weakness in the review process \u2013 the lack of specific details about the train/test split. This information is crucial for reproducibility and proper evaluation. While the reviewer doesn't provide the missing information, they clearly identify the area where the paper is lacking. This is a valuable piece of feedback that could help the authors improve their reporting."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the need for human labor in building text descriptions and identifies the lack of clarity regarding the optimal textual format for policy learning. These are direct actions or suggestions that authors should take or consider. While the reviewer doesn't specify *what* the optimal format is, they clearly point to the *areas* that need improvement, making the action somewhat explicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'text descriptions' and 'optimal textual format' as areas needing attention. This clearly identifies the specific part of the paper or the specific issue being addressed. The reviewer also mentions 'scalability of this framework' which implicitly refers to the longtext input. While the reviewer doesn't provide specific examples of what is wrong with the text descriptions or the format, they clearly pinpoint the *specific* aspects that require improvement, making the grounding strong.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a suggestion for improvement. Therefore, it does not fit into the verifiability categories.", "helpfulness_rationale": "The reviewer provides specific areas for improvement, such as building text descriptions and determining the optimal textual format for policy learning. They also highlight the scalability issues with longtext inputs. These suggestions are directly relevant to improving the draft and are likely to be helpful for the authors. The reviewer is not presenting a claim but rather pointing out actionable areas for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points to a potential improvement ('performance improvement') and mentions a specific value (0.02). However, it doesn't explicitly state what action the authors should take based on this observation. The suggestion to use 'tables' is a good idea but lacks specific guidance on how to use them.", "grounding_specificity_rationale": "The review explicitly mentions 'the bank dataset' and 'figure 3', clearly identifying the specific parts of the paper being referenced. This can be achieved through:  Literally mentions sections, tables, figures, etc.  Mentions unique elements of the paper. The comment specifies what is being addressed in the referenced part.", "verifiability_rationale": "The review contains a claim ('the performance improvement of proposed methods seems not so significant, the biggest improvement in the bank dataset was ~0.02') and provides a numerical value. However, it doesn't explicitly state *why* the improvement is not significant or provide a reference for this claim. The reasoning is implied but not explicitly stated.", "helpfulness_rationale": "The review points out a potential weakness (lack of significant improvement) and suggests an alternative way to present the data. However, it doesn't explain *why* the improvement isn't significant or provide specific guidance on how to interpret the results in Figure 3. The suggestions are highlevel and lack concrete steps."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a lack of theoretical results, which is a clear statement of a weakness. The reviewer explicitly states 'this work does not prove any new theoretical results', which is an explicit action. While the reviewer identifies the missing theoretical results as the weakness, the specific type of theoretical results is not specified, making it somewhat vague. Therefore, the comment is 3 as the authors know they need to focus on the theoretical properties of their loss function, but the specific action is not fully clear.", "grounding_specificity_rationale": "The reviewer refers to 'this work' and 'this setting' but does not specify which part of the paper or what the 'setting' is. They mention 'a known loss function' but do not elaborate on its specifics. The lack of explicit labeling makes the grounding weak. The criticism is about the lack of theoretical results, which is a general statement about the paper without pinpointing a specific part. Therefore, the comment is weakly grounded as the authors cannot confidently determine which part the comment addresses. The specificity is also low as the comment does not detail what needs to be addressed in this part.", "verifiability_rationale": "The reviewer states 'this work does not prove any new theoretical results'. This is a claim about a deficiency in the paper. However, the reviewer does not provide any evidence or justification for this claim. They are stating an observation, not offering a solution or evidence. Therefore, the claim is not supported by any reasoning, common knowledge, or external references, making it 1. The comment is a statement of fact, not a verifiable claim.", "helpfulness_rationale": "The reviewer identifies a valid weakness in the paper by pointing out the absence of new theoretical results. This is a relevant piece of feedback for the authors as it highlights a gap in the paper's theoretical understanding. However, the reviewer does not provide any specific suggestions or guidance on how the authors should approach this weakness. The feedback is limited to identifying the problem without offering concrete solutions. Therefore, while the criticism is valuable, the lack of specific guidance makes it somewhat limited in its helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of 'adding fullysupervised baselines for small models in table 1'. This is a clear and direct instruction on what the authors should do. The action is not inferred but rather explicitly mentioned, making it less vague. The specific details, such as 'fullysupervised baselines,' 'small models,' and 'table 1,' further enhance the concreteness of the action. Therefore, the action is highly concrete and directly actionable.", "grounding_specificity_rationale": "The review point explicitly refers to 'table 1' as the location for adding the baselines. This is a literal mention of a specific part of the paper. The reviewer clearly identifies the issue: the absence of 'fullysupervised baselines' in this table. The grounding is strong because the exact section is mentioned. The specificity is also high as the reviewer clearly states what should be added to this specific table. The unique aspect being addressed is the content of table 1.", "verifiability_rationale": "The review point contains the suggestion to 'add fullysupervised baselines for small models in table 1'. This can be considered a claim, even if it's a suggestion for improvement. The reviewer provides a justification for this suggestion by stating that these baselines will be 'useful in understanding the gap between full supervision and SSL for these models'. This justification, while not a direct citation, provides a logical reasoning for why the suggested action is valuable. Therefore, the claim is wellsupported by the provided reasoning.", "helpfulness_rationale": "The review point directly suggests a concrete and actionable improvement: adding specific baselines to a clearly identified location in the paper. This directly addresses a potential weakness the authors might be facing \u2013 understanding the performance gap between full supervision and SSL. The suggestion is specific enough for the authors to implement and is likely to be helpful in addressing the stated goal. The reviewer's suggestion is clear and directly targets a relevant aspect of the work."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer clearly states the concern about the computational cost of hypervolume calculation in LaMOO and its implications for scalability, especially with a large number of objectives. The language is direct and understandable, making the point actionable for the authors who might be concerned about the practicality of the algorithm. The reviewer directly identifies a potential limitation of the algorithm.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'hypervolume calculation' and 'LaMOO algorithm' in the review point. While they don't pinpoint a specific section or table, they clearly identify the component of the algorithm being discussed. This can be considered 'weak grounding' as the authors can infer the specific part being addressed. The reviewer also provides some detail by explaining *why* hypervolume calculation is a problem (timeconsuming, especially for many objectives), which adds some specificity to the identified area.", "verifiability_rationale": "The reviewer poses a question about the practicality of LaMOO for problems with many objectives due to the hypervolume calculation. This constitutes a claim that needs to be supported. However, the review point itself does not provide any evidence or reasoning to verify this claim. The justification would come from the reviewer's understanding of the computational complexity of hypervolume calculation and its implications for scalability.", "helpfulness_rationale": "The reviewer raises a valid concern about the potential impracticality of LaMOO for problems with many objectives due to the computational cost of hypervolume calculation. This is a relevant issue for authors using the algorithm. While the review point itself doesn't offer a solution, it highlights a potential limitation that could be helpful for the authors to be aware of, prompting them to consider alternative approaches or algorithms with lower computational demands. The reviewer's point is relevant to the practical application of the algorithm."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review points out a problem (small datasets) but doesn't explicitly recommend an action or solution. It suggests looking at larger datasets but doesn't specify how to do that or what to expect. The reviewer also adds a personal opinion ('it will not affect the overall quality of the paper') which is not directly actionable for the authors.", "grounding_specificity_rationale": "The review criticizes the datasets used in the experiments in general. It doesn't specify a particular section, table, figure, or unique aspect of the paper that is problematic. The criticism is broad and doesn't pinpoint a specific detail within the paper.", "verifiability_rationale": "The review makes a claim ('the dataset used in the experiments are all very small') and suggests a solution ('It would be more convincing to see some result on medium or even large dataset such as ImageNet'). However, the reasoning is speculative and lacks concrete evidence or references. The reviewer doesn't provide any logical reasoning, common knowledge, or external references to support their claim about the impact of dataset size on the results.", "helpfulness_rationale": "The review identifies a valid concern (small datasets) and suggests a relevant direction (larger datasets). However, the suggestion is vague and doesn't provide specific steps or expectations for the authors. The reviewer also downplays the importance of addressing the problem ('it will be just a minor issue'), which reduces the helpfulness of the feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out limitations of evolutionary methods and suggests considering state, reactiveness, and learning during an episode. While these are valid points, the reviewer does not explicitly state how the authors should apply these suggestions or what specific changes are needed. The suggestions are broad and openended, requiring the authors to interpret and implement them themselves. Therefore, while the reviewer identifies actionable areas, they do not provide concrete steps for the authors to follow.", "grounding_specificity_rationale": "The reviewer mentions 'evolutionary methods,' 'state, reactiveness, and learning,' and 'DeepRL methods' in general terms. They do not specify which sections, tables, or figures of the paper these limitations refer to. The reviewer's suggestions are broad and lack specific references to the authors' work. While the general areas of improvement are clear, the lack of pinpointing makes the grounding weak.", "verifiability_rationale": "The reviewer criticizes the title as 'way too generic and vague' and asks for clarification on 'brittle convergence properties.' While the reviewer expresses a concern, they do not provide any evidence or justification for why the title is vague or why 'brittle convergence properties' are a significant issue. The reviewer's statements are opinions or judgments about the paper without offering logical reasoning, common knowledge, or external references to support these claims. The reviewer is stating their perspective but not providing verifiable information.", "helpfulness_rationale": "The reviewer offers broad suggestions for improvement, such as considering state, reactiveness, and learning, and recommending 'honest and direct' feedback. They also point out the generality of DeepRL methods and suggest considering the research landscape 10 years ago. While these suggestions are relevant and could be helpful, they lack specific action items for the authors. The reviewer does not provide concrete steps or examples of how the authors should implement these suggestions. The feedback is more about raising questions and areas for improvement rather than providing direct, actionable guidance. The request for clarification on the title and 'brittle convergence properties' is also not a direct improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the claim about the algorithm's efficiency but does not specify how to demonstrate this claim. While the reviewer identifies a missing element (empirical justification), they don't provide a concrete action or method for the authors to take. The action is implicit: the authors need to provide evidence, but the *how* is not defined.", "grounding_specificity_rationale": "The reviewer explicitly mentions the specific claim about the algorithm's efficiency, grounding the comment in a particular part of the paper. However, the reviewer does not specify *what* aspect of the algorithm or analysis needs to be grounded. The grounding is present, but it's not very specific about the *details* of the claim.", "verifiability_rationale": "The reviewer states a claim about the algorithm's efficiency but provides no supporting evidence or reasoning. There is no logical reasoning, common knowledge, or external references provided to back up this claim. The claim is presented without any justification.", "helpfulness_rationale": "The reviewer directly points out a weakness in the paper (lack of empirical justification) and clearly states what would be beneficial (empirical evidence). This directly addresses a potential gap in the authors' understanding and strengthens the review's impact on the authors."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the concern about the similarity to RMED and suggests an action (discuss the comparison). This is a clear and direct identification of a potential issue.", "grounding_specificity_rationale": "The reviewer mentions 'RMED (Komiyama et al. 2015)' which provides a specific reference point within the paper. While the reviewer also mentions 'the proposed S1DBED algorithm' and 'the novelty of this part', the direct grounding is through the specific algorithm and citation. The grounding is strong but could be slightly more explicit about the 'novelty of this part'.", "verifiability_rationale": "The reviewer makes a claim about the similarity to RMED and suggests a need for discussion. This claim is generally verifiable by comparing the algorithms. However, the specific details of the similarity are not provided, limiting the verifiability to a general level.", "helpfulness_rationale": "The reviewer directly addresses a potential weakness in the paper's presentation of its novelty by pointing out the similarity to an existing algorithm and suggesting a discussion. This provides a clear direction for the authors to improve their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point implies a need for the authors to discuss previous work, but it doesn't explicitly state what they should do or how to do it. The action is implicit.", "grounding_specificity_rationale": "The comment mentions 'previous work' which is a specific area of the paper. However, it does not specify which particular aspect or study within the previous work needs to be discussed. This makes the grounding weak and the specificity underspecific.", "verifiability_rationale": "The review point itself doesn't contain a direct claim. However, the suggestion to 'give a comprehensive discussion' can be interpreted as an implicit recommendation or a desired state. The verifiability is borderline because the comment doesn't provide specific examples or references to support the need for a comprehensive discussion.", "helpfulness_rationale": "The review point identifies a valid weakness in the authors' draft \u2013 the lack of a comprehensive discussion of previous work. It suggests an improvement by recommending this discussion. While it doesn't provide specific instructions on how to do this, it is still helpful as it points to a relevant area for enhancement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a question about limitations and asks for clarification about handling continuous/infinite spaces. This is an explicit action. However, the reviewer doesn't identify a specific area within the paper that needs improvement, making it vague and not fully actionable. Therefore, it's partially actionable.", "grounding_specificity_rationale": "The reviewer refers to 'limitations of its' and asks about 'any general POMDP formulations (continuous or infinite spaces)'. While the intent is clear, the connection to a specific section or table in the paper being reviewed isn't explicitly stated, making the grounding somewhat weak. However, the reviewer is asking about a specific aspect of POMDPs, which adds to the specificity.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a question posed to gain information or clarification. Therefore, it falls under the 'X' category.", "helpfulness_rationale": "The reviewer is asking a valid question about the limitations of a unified framework for POMDPs, specifically regarding continuous or infinite spaces. This question seeks clarification and could potentially improve the paper being reviewed by highlighting a gap in its understanding. Therefore, it is 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "Not Verifiable", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point criticizes the *process* of dataset creation but does not explicitly state an action the authors should take to improve their own dataset creation. While it mentions the Kialo dataset as a better alternative, it doesn't provide specific steps or actions for the authors to adopt or improve their own approach. Therefore, the actionability is not explicitly stated, making it borderline.", "grounding_specificity_rationale": "The review point does not specify which part of the paper or process the criticism of dataset creation refers to. It's a general criticism of the dataset creation process itself. Therefore, the grounding specificity is not explicitly mentioned, making it 1.", "verifiability_rationale": "The review point criticizes the dataset creation process but does not contain any specific claims that require verification. It's a general statement about the perceived usefulness of the dataset. Therefore, verifiability is not applicable as there are no claims to verify, making it Not Verifiable.", "helpfulness_rationale": "The review point criticizes the dataset creation process as 'optional' and 'not needed' because a better alternative exists (Kialo dataset). While it acknowledges the dataset's potential usefulness, it doesn't provide concrete, actionable feedback on how the authors can improve their own dataset creation process. The criticism is more about the *process* than specific weaknesses in the authors' current approach. Therefore, the review point is not particularly helpful in guiding the authors to improve their dataset creation, making it Not Helpful."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly states the limitations of using a transformer (nonnovelty), criticizes the crosslayer attention modification as not bringing significant ML insight, and highlights the limited improvement of selfcross attention. It also points out that the main improvements come from using a naive transformer. These are all direct statements that the authors can use to understand the issues and make necessary changes. The reviewer provides clear information on what is wrong and what the results were.", "grounding_specificity_rationale": "The reviewer makes several claims about the limitations of the method but does not explicitly identify the specific part of the paper being addressed. For example, when mentioning the 'transformer has been adopted for lots of NLP and vision tasks', it is unclear which section or table this refers to. Similarly, when stating that the 'crosslayer attention brings limited improvement (<1%)', the reviewer does not specify which table or section within the ablation study contains this information. The lack of specific references makes it difficult for the authors to pinpoint the exact issues.", "verifiability_rationale": "The reviewer states that the transformer is not novel, which is a general statement and not verifiable without specific citations or examples. The claim that the crosslayer attention modification doesn't bring significant ML insight is also not supported by evidence or references. The observation that selfcross attention brings limited improvement is presented as a fact without explanation or justification. Finally, the claim that the main improvements come from using a naive transformer is a statement of fact but lacks a clear explanation of why this is the case. There is no logical reasoning or external references provided to support these claims.", "helpfulness_rationale": "The review point criticizes the transformer's nonnovelty and the crosslayer attention modification as not bringing significant ML insight. It also notes the limited improvement of selfcross attention and suggests that the main improvements come from using a naive transformer. While these are valid observations, the reviewer does not provide specific, actionable feedback on how the authors can address these issues. The criticism of the modification is not constructive, and the observation of limited improvement is presented without suggesting concrete steps to overcome this limitation. The reviewer points out a difference in performance between the naive and proposed transformers but doesn't explain the difference or suggest how to make the proposed method better. The lack of constructive feedback makes the review point less helpful."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Partially Grounded", "verifiability_label": "Partially Verifiable", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests adding sentence inference tasks like MNLI and RTE to the evaluation. While this is a specific suggestion, the reviewer doesn't explicitly state how to implement this change or what specific actions the authors should take. The suggestion is clear and points to a concrete improvement, but the lack of detailed guidance makes it less actionable.", "grounding_specificity_rationale": "The reviewer mentions 'sentence similarity tasks' and 'open domain QA tasks' as the current scope of experiments. They also suggest adding 'sentence inference tasks like MNLI and RTE'. While the reviewer doesn't explicitly state which *part* of the paper is being addressed, they provide specific examples of tasks within that part. This indicates a degree of grounding, but it could be stronger by explicitly stating the section or table where these tasks are discussed.", "verifiability_rationale": "The reviewer states that the experiments are 'limited'. They provide examples of the current tasks (sentence similarity and open domain QA) to illustrate this limitation. However, the reviewer doesn't provide any justification for why these experiments are limited or how expanding to sentence inference tasks would address these limitations. While they provide examples of the current tasks, they don't explain *why* these tasks are insufficient or what specific problems they reveal. Therefore, the verifiability is partial as it lacks a clear explanation of the limitations and the benefits of the suggested improvement.", "helpfulness_rationale": "The reviewer identifies a limitation in the experimental evaluation (limited task scope) and suggests a specific improvement (adding sentence inference tasks). This points to a weakness in the current assessment and offers a clear direction for improvement. While the reviewer doesn't explicitly state *how* to implement this change or *why* it's crucial, the suggestion is actionable and directly addresses a potential weakness in the evaluation. The reviewer provides examples of relevant tasks, making the suggestion concrete."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about why only the last convolutional layer is analyzed, implying that the authors should understand this choice. While the reviewer doesn't explicitly state what the authors should do, they are prompting for justification. This is an implicit action, making it 3.", "grounding_specificity_rationale": "The reviewer refers to 'the last convolutional layer' without explicitly naming a section or providing a unique identifier. While the term 'last' implies a specific layer, it's still vague and not a precise reference, making it weakly grounded. However, the reviewer is also asking about 'numerosity' within that layer, which provides a specific context, making it somewhat specific.", "verifiability_rationale": "The reviewer is questioning the assumption that numerosity is not present in earlier convolutional layers. This is a claim that needs to be supported by evidence or justification. While the reviewer is asking for clarification, the underlying claim about the location of numerosity requires some level of verification, making it 3. There's no explicit evidence or reference provided in the review point itself to support this claim.", "helpfulness_rationale": "The reviewer is asking a question to gain information about the presence of numerosity in different convolutional layers. While this is a valid question and relevant to understanding the model's behavior, it doesn't directly tell the authors what to do or provide concrete steps for improvement. It's more of a request for clarification than a direct solution, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states their preference for human evaluation, which constitutes an explicit action. However, the rationale provided (human evaluation is more convincing) lacks specific details about the limitations of automatic metrics, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer's suggestion is a general call for change in evaluation methods. It doesn't specify which part of the paper or element of the caption generation process is being criticized, nor does it provide any details about why automatic metrics are insufficient. The comment is 1 at all. It does not identify a specific area in the paper. The comment is highly unspecific.", "verifiability_rationale": "The reviewer makes a claim by stating their preference for human evaluation. However, they do not provide any logical reasoning, common knowledge, or external references to support this claim, making it 1. The claim exists, but it lacks supporting evidence or justification.", "helpfulness_rationale": "The reviewer's suggestion, while relevant to improving caption generation, is vague and lacks specific details about the issues with automatic evaluation or the benefits of human evaluation. This lack of clarity makes the feedback less helpful than a more specific critique. The comment identifies a weakness or improvement area but is vague, lacks clarity, or provides minimal guidance, making it only slightly beneficial for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues with the convergence proof, identifying the i.i.d. assumption in Assumption 4.1 and its implications for the covariance matrix of Z. They also point to Modification 1 in Appendix C as a way to adapt previous theorems. This provides clear guidance for the authors on how to address the perceived triviality. While the reviewer doesn't delve into the exact mathematical details of the covariance, they clearly indicate the *specific* area of the paper they are referring to, making the action clear.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Assumption 4.1' and 'Modification 1 in Appendix C'. This directly points to specific sections of the paper, making the grounding very clear. They also explain the implications of the i.i.d. assumption for the covariance matrix of Z, providing a detailed explanation of what needs to be addressed.", "verifiability_rationale": "The reviewer makes a claim about the convergence proof's lack of 'substantial novelty and rigor'. They support this claim by pointing to the i.i.d. assumption, the resulting 'clear covariance matrix' for Z, and the possibility of 'straightforward modifications' to previous theorems. While the reviewer doesn't provide external references to back up their claim about the lack of novelty, they do provide logical reasoning and references to specific parts of the paper to support their assessment of the proof's limitations.", "helpfulness_rationale": "The reviewer's point is directly relevant to the theoretical soundness of the paper. By highlighting the potential issue with the i.i.d. assumption and suggesting a specific modification, they provide a concrete direction for the authors to take. While the reviewer doesn't demand a complete overhaul, they offer a clear and actionable suggestion that could improve the robustness of the convergence analysis. The reviewer's focus on a specific aspect of the paper makes the feedback highly targeted and potentially impactful."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete change to be made. It raises a question about the interpretation of results rather than proposing a direct improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the claims regarding the multienvironment model' and points out a specific issue ('a potential contradiction in the paper's claims'). This demonstrates a clear identification of the relevant part of the paper and the specific issue.", "verifiability_rationale": "The reviewer points out a logical inconsistency in the paper's claims. While the resolution of this inconsistency might require further investigation or external knowledge, the statement itself is verifiable as a logical conflict between the two claims.", "helpfulness_rationale": "The reviewer identifies a genuine ambiguity or potential error in the paper's claims regarding the multienvironment model. By highlighting this conflict, they provide the authors with a chance to clarify their findings and reasoning, which is a valuable piece of feedback."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer's point primarily focuses on the lack of explanation and citation for the metrics used in the paper. While the metrics themselves might be implicitly understood within the paper's context, the reviewer feels the need for explicit definitions and citations to ensure clarity and facilitate actionability. The lack of explicitness could lead to ambiguity, making it difficult for the authors to know exactly what the metrics represent and how they should be interpreted or used. This lack of clarity hinders the actionability of the point, as the authors might not know what specific actions to take based on the metric values.", "grounding_specificity_rationale": "The reviewer's point does not explicitly address the grounding specificity of the metrics. The point focuses on the lack of explanation and citation, which relates to the 'actionability' aspect, not necessarily the 'grounding' aspect. If the metrics are implicitly understood within the paper's context, the reviewer might not perceive a lack of grounding specificity. However, if the reviewer is suggesting that the metrics are not clearly linked to specific sections or elements of the paper, that could be considered a point of low grounding specificity. Without more detail on the nature of the metrics, it's difficult to definitively assess this aspect.", "verifiability_rationale": "The reviewer's point does not directly address the verifiability of the metrics. The point focuses on the lack of explanation and citation, which are related to the 'helpfulness' and 'actionability' aspects. If the metrics are presented without sufficient context or justification, their verifiability could be questionable. However, the reviewer's primary concern seems to be about the lack of *explanation* and *citation*, which are more directly related to 'helpfulness' and 'actionability'. The verifiability of the metrics would depend on the nature of the metrics themselves and whether the paper provides sufficient information to understand and validate them.", "helpfulness_rationale": "The reviewer rates the point as '1' due to the lack of explanation and citation for the metrics. This is because the reviewer feels the point is incomplete and lacks the necessary context for the authors to understand and act upon the information. Without knowing what the metrics represent and how they are calculated, the authors cannot effectively use this feedback. The missing explanation and citation prevent the reviewer from gaining a clear understanding of the information, hindering its helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the lack of motivation and the use of static datasets as issues. These are direct and clear observations about the paper's content and methodology. The suggestions for improvement, such as 'motivating the applications' and 'using streaming datasets,' are direct and actionable.", "grounding_specificity_rationale": "The reviewer's point about the lack of motivation and the use of static datasets is not explicitly tied to a specific section or element of the paper. While the motivation is implied, the reviewer doesn't pinpoint *which* part of the paper needs to be motivated or *why* it's important. The reviewer also doesn't specify the importance of the applications or the relevance of streaming datasets. The lack of specificity makes it harder for the authors to understand the *why* and *how* of the work.", "verifiability_rationale": "The reviewer makes a clear claim about the lack of motivation and the use of static datasets. The reviewer provides a logical reason for this issue, stating that the static datasets undermine the motivation. However, the reviewer does not provide specific examples or references to external works to support this claim. The reasoning is present but lacks concrete evidence.", "helpfulness_rationale": "The reviewer provides a clear and actionable critique of the paper. They identify specific weaknesses, such as the lack of motivation and the use of static datasets, and offer concrete suggestions for improvement. This feedback is directly relevant to the authors and has the potential to significantly improve the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a problem: 'the scope of the study is underspecified.' It then provides an implicit suggestion: 'If that is not the case, additional relevant CoT baselines for incontext learning of Large Language Models (for text003 and ChatGPT) are missing in Table 2 and 3 (See Question A).' While the suggestion is not immediately actionable, it clearly points towards a specific area for improvement.", "grounding_specificity_rationale": "The comment identifies a general issue ('the scope of the study is underspecified') but does not explicitly name a specific part of the paper or methodology that is affected. However, it implicitly suggests that the CoT baselines for LLMs are missing, which points to a specific area of the study. The grounding is weak because the exact location of the underspecification is not clear, but the suggestion implies a focus on the experimental setup and baseline comparisons.", "verifiability_rationale": "The comment contains a claim: 'the scope of the study is underspecified.' While the reasoning is not explicitly stated, the suggestion to include CoT baselines for LLMs in Tables 2 and 3 provides a basis for logical reasoning and verification. The common knowledge aspect lies in the understanding that comparing different incontext learning methods is a relevant evaluation aspect. The external reference (CoT baselines for LLMs) is a specific example that could be verified against existing literature.", "helpfulness_rationale": "The comment identifies a clear weakness ('the scope of the study is underspecified') and offers a relevant suggestion ('additional relevant CoT baselines for incontext learning of Large Language Models (for text003 and ChatGPT) are missing in Table 2 and 3 (See Question A)'). This provides the authors with a specific direction to improve their work by considering additional relevant baselines. The feedback is directly linked to potential improvements in the experimental evaluation."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the problem with Figure 3 ('Figure 3 is very hard to read anything on the figure') and suggests an action to improve it ('improve its readability'). This is a clear and direct indication of what needs to be addressed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 3' in their comment. This is a clear and specific reference to the part of the paper being addressed, making it fully grounded. The comment also specifies what is wrong with this part ('very hard to read anything on the figure').", "verifiability_rationale": "The comment contains a claim ('Figure 3 is very hard to read anything on the figure') that identifies a weakness in the paper. However, it does not provide any specific evidence or justification for this claim. There are no references to external works, logical reasoning, or examples to support the assertion that Figure 3 is indeed difficult to read. Therefore, while the claim is about a specific part of the paper, the lack of supporting evidence makes it 1.", "helpfulness_rationale": "The comment identifies a clear weakness in the paper (the readability of Figure 3) and suggests a concrete action to improve it (improve its readability). This actionable feedback empowers the authors to take some steps towards enhancing their work. While the suggestion is broad and doesn't specify *how* to improve the figure, it is still a helpful direction."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks 'How is this connected?' which is a direct request for an explanation of the relationship between two statements. This action is both explicit (asking a question) and concrete (requesting a specific type of explanation).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the fact that tensor decomposition is in general harder in the symmetric than in the nonsymmetric case' and 'the recent findings about the `nice' landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors.' This clearly identifies the specific parts of the paper being addressed, making the grounding fully explicit.", "verifiability_rationale": "The reviewer presents a statement ('In the introduction the authors mention... How is this connected with...') and asks for an explanation. This constitutes a claim that a connection exists and that it should be explainable. While the reviewer doesn't provide specific evidence within the review point itself, the request implies a belief in the verifiability of the connection based on the provided context.", "helpfulness_rationale": "The reviewer's question directly addresses a potential point of confusion or further research for the authors. They are asking for a specific connection between two concepts, which is likely to be valuable information. The request for explanation is a clear indication of the reviewer's need and the potential benefit for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the actions to be taken: replace a specific expression with a parameter and set a learning rate. The actions are concrete, detailing *how* to make the changes.", "grounding_specificity_rationale": "The review point explicitly mentions \"lines 119121\" and \"line 164\", indicating a clear understanding of the location. It then describes the *content* of these sections being relevant: a calculation on line 119/120 and a learning rate specification on line 164.", "verifiability_rationale": "The review point makes a claim about the arbitrariness of the parameter and the learning rate. However, it lacks a clear justification or reference for why this is the case. It simply states the observation.", "helpfulness_rationale": "The review point directly tells the authors *what to do*. It provides specific, actionable steps. While it doesn't *explain* *why* these changes are beneficial, it clearly identifies the *actions* to be taken. The reviewer is empowering the authors to make a specific modification."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point is general and lacks specific actions or details. While it suggests analyzing the domain gap, it doesn't specify how to do so or what aspects to focus on. The suggestion about finetuning is also vague.", "grounding_specificity_rationale": "The review point is 1 in specific details. It broadly refers to the 'paper' and doesn't identify a specific section, table, figure, or unique aspect related to the domain gap.", "verifiability_rationale": "The review point contains a claim about the need to discuss the domain gap. It also offers a suggestion, which can be considered some level of verification, even if it's highlevel.", "helpfulness_rationale": "The review point identifies a problem area (domain gap) and offers a general suggestion. However, it lacks specific, actionable steps for the authors to take. It provides a direction but not a concrete solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including a comparison with at least one NCEbased method, which is an explicit action. However, it lacks specific details on which method to compare or how to perform the comparison, making it somewhat vague.", "grounding_specificity_rationale": "The review point suggests including a comparison with at least one NCEbased method, which is an explicit action. However, it does not specify which NCEbased method is relevant or the context of the comparison, making it weakly grounded. While the suggestion is clear about the *what* (comparison), it lacks the *where* and *why* in terms of specific methods or the research question.", "verifiability_rationale": "The review point includes a claim that '1 shows that with a strong noise distribution, this line of work is possible to learn EBM on natural images.' This claim is verifiable as it refers to a specific finding in a cited paper, providing a basis for the authors to understand a relevant technique and its potential application.", "helpfulness_rationale": "The review point provides a specific example of a finding in a related area (NCE methods for EBMs) and links it to a specific paper. This is generally helpful for the authors as it provides context and potential avenues for comparison, even though the suggestions are broad."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment implicitly points to a potential research direction by highlighting the absence of justification for a new curriculum learning method. While it doesn't explicitly state what needs to be done, it suggests an area where the authors could potentially contribute. The reviewer is essentially suggesting the authors investigate why existing methods might not be suitable for text graphs.", "grounding_specificity_rationale": "The comment explicitly mentions 'Section 1' and the general concept of 'text graphs' (though not explicitly named as a distinct entity). This provides a clear reference point for the reviewer, indicating they are addressing a potential gap in the paper's discussion of curriculum learning methods.", "verifiability_rationale": "The comment makes a claim that 'the need for designing a new curriculum learning method for text graphs is not justified' and 'the research gap ... e.g., why existing methods can\u2019t be applied, is not discussed.' This claim is supported by the lack of explicit discussion about the limitations or inapplicability of existing methods in the paper, making it **4**.", "helpfulness_rationale": "The comment identifies a significant gap in the paper by pointing out the lack of justification for a new method and the absence of discussion about existing methods' limitations. This directly encourages the authors to explore this area, making the review 5 and valuable for guiding their research. It highlights a potential area for novel contributions."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the suggestion to use pretrained language models as a base encoder and compare the transfer parts, which is a clear and actionable next step.", "grounding_specificity_rationale": "The reviewer explicitly names specific pretrained language models (BERT, XLNet) and the concept of domain shift, clearly identifying the relevant part of the field and explaining its benefit.", "verifiability_rationale": "The reviewer suggests a relevant improvement based on general knowledge about pretrained models and transfer learning, although it lacks specific examples or references.", "helpfulness_rationale": "The reviewer's suggestion is directly relevant to the task of domain adaptation in NLP and provides a clear direction for improvement, moving beyond simpler ngram features."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'this requires more explanation' and asks a direct question ('Why exactly...'). This indicates an expectation for further clarification. While the reviewer identifies a gap in explanation, the specific nature of this gap is not immediately clear, making the action somewhat implicit.", "grounding_specificity_rationale": "The reviewer refers to 'two quantities' without specifying which part of the paper or context these quantities relate to. They do not point to a specific section, table, or figure. This suggests a lack of precise identification, making the grounding weak. However, the reviewer's question about the difference is specific, indicating a degree of specificity in their request for clarification.", "verifiability_rationale": "The reviewer states 'this requires more explanation' and asks a question ('Why exactly...'). This can be interpreted as a claim that the current explanation is insufficient. The reviewer then asks for justification, implying a belief in the existence of a difference that needs explanation. While the initial statement is somewhat vague, the subsequent request for justification suggests a degree of verifiability.", "helpfulness_rationale": "The reviewer states 'I think NIPS should have room for a few 'pure theory' papers' and 'I still lean toward acceptance'. These statements show a consideration of the implications of the comment and a personal opinion on the matter. While not a direct critique of the paper's content, these statements provide context and relevance to the discussion, making the review 3 in guiding the decisionmaking process."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point asks the authors to discuss the sensitivity of fixed tuning parameters. While it implies an action (analyzing sensitivity), it doesn't explicitly state what needs to be done, making it implicitly actionable but not explicitly actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'fixed tuning parameters' and asks about their 'sensitivity'. This directly refers to a specific aspect of the model, allowing the authors to identify the relevant section and understand the specific issue being addressed. The comment provides a clear target for the authors' analysis.", "verifiability_rationale": "The review point is a question prompting the authors to discuss a specific aspect of their model. It doesn't contain a claim that requires verification. Therefore, it is not verifiable in the sense of providing a definitive answer or critique.", "helpfulness_rationale": "The review point encourages the authors to explore the impact of their fixed tuning parameters. While it doesn't provide a readymade solution, it guides them towards a valuable analysis that can potentially improve their model. This direction is helpful for the authors' understanding and development of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the framework's compatibility with different policy gradient approaches and requests experimental details. While it identifies an area for potential improvement (clarifying experimental setup), it does not explicitly state what needs to be done or suggest an alternative. The request for information about random seeds is explicit, but the overall point lacks a clear, actionable step for the authors.", "grounding_specificity_rationale": "The review point directly asks about the number of random seeds used in experiments. This is a specific detail about the implementation of the experiments. The reviewer is asking for a precise piece of information directly related to the experimental setup, making it fully grounded. The question is also very specific about the *number* of random seeds.", "verifiability_rationale": "The review point is a question seeking information about the experimental setup, specifically the number of random seeds used. It does not contain a claim that requires verification. There are no logical reasoning, common knowledge, or external references provided in this review point as it is a factual question.", "helpfulness_rationale": "The review point is a question seeking information about the experimental setup, specifically the number of random seeds used. While this information could be helpful for the authors to understand and reproduce the experiments, the review point itself does not directly identify a weakness in the framework or suggest a concrete improvement. It is more of a request for clarification or implementation details rather than a critique or suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a lack of clarity in a specific definition, which could be interpreted as an implicit action for the authors to seek clarification. While the reviewer doesn't explicitly state what to do, the request implies a need for action on their part to understand the definition better. This lack of explicit actionability makes it less impactful in directly guiding the authors' improvement efforts.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'definition 2.1,' indicating an attempt to ground the feedback in a specific section. While they don't specify *what* is wrong with the auxiliary model weights, they are pointing to a specific area of the paper, which can be considered a form of grounding. However, the lack of specificity in the criticism means the grounding is not fully effective.", "verifiability_rationale": "The reviewer makes a claim about the clarity of definition 2.1, which could be supported by examining the definition itself. The reviewer is making a statement that requires justification (clarity), which falls under the category of specificity. The claim is that the definition is unclear, and this could be verified by looking at the definition. Therefore, it is 3.", "helpfulness_rationale": "The reviewer highlights a lack of clarity in a specific definition, which directly helps the authors understand and potentially improve that aspect of their work. By pointing out a specific area of confusion, the reviewer empowers the authors to investigate and clarify the definition, contributing to their understanding and potential improvements. Therefore, it is 3 in guiding their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the weakness of MIA testing and recommends a specific alternative, ULiRA.", "grounding_specificity_rationale": "The reviewer clearly identifies 'MIA testing' and suggests 'ULiRA' as a solution, explaining the issue with MIA testing.", "verifiability_rationale": "The reviewer makes a claim about the limitations of MIA testing and offers ULiRA as a potential solution. While the reasoning is brief, the suggestion of ULiRA implicitly supports the point.", "helpfulness_rationale": "The review identifies a specific methodological weakness (MIA testing) and offers a concrete alternative (ULiRA), which directly helps the authors improve their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desired improvement: 'This paper could be improved by explicitly showing the settings for the various knobs of this algorithm...'. This is a clear and direct action the authors should take. The suggestion is not just a general comment but a specific direction for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'various knobs of this algorithm' and specifically mentions 'prior work: Dagger, searn, etc...'. This clearly identifies the specific part of the algorithm being discussed and provides concrete examples of relevant prior work. The reviewer is not just saying 'improve the paper,' but pinpointing a specific area for improvement and providing context.", "verifiability_rationale": "The reviewer makes a claim: 'This paper could be improved...'. This claim is verifiable because the reviewer suggests a concrete improvement: 'explicitly showing the settings...to mimic prior work.' This is a specific and actionable suggestion that the authors can investigate and potentially implement. The reviewer is not making a subjective judgment about the paper's quality but rather pointing out a specific area for improvement with a clear direction.", "helpfulness_rationale": "The reviewer's comment is 5 because it directly addresses a potential weakness in the paper (lack of clarity regarding algorithm settings and connections to prior work) and suggests a concrete improvement. The reviewer anticipates the impact of this suggestion on the community's ability to understand and build upon the work. This is a valuable and constructive criticism."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of clarity regarding the generalizability of the discussed biases and prediction shifts. While they identify a gap in the paper's discussion, the exact nature of this gap and what needs to be clarified is not explicitly stated. The reviewer implies that the authors know the bias exists, but they are unsure where it occurs, making the action implicit.", "grounding_specificity_rationale": "The reviewer mentions 'section 3.2' and 'Theorem 1', indicating some level of grounding as they are referring to specific parts of the paper. However, they do not explicitly state what is unclear within these sections. The comment identifies the location where the issue lies, but doesn't specify the exact problem or what needs to be addressed within that section.", "verifiability_rationale": "The reviewer raises a question about the generalizability of the presented information. They are not making a claim that requires verification or providing evidence. The statement is more of an observation about the scope of the presented findings rather than a definitive assertion that needs to be proven.", "helpfulness_rationale": "The reviewer points out a potential weakness in the paper's presentation by highlighting the lack of clarity regarding the generalizability of the discussed biases and prediction shifts. While this could be helpful for the authors in understanding the limitations of their work, the review point itself does not offer a concrete solution or suggestion. It's a question about scope rather than a direct critique or improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "6", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the desire for 'a few more datasets' and highlights 'especially concerning the crosstask transferability'. While it identifies the need for more data, it doesn't specify how this should be implemented or what aspects of the current draft this new data would address. The suggestion is general and lacks concrete details on the 'how'.", "grounding_specificity_rationale": "The comment refers to 'datasets' and 'crosstask transferability' generally, without directly linking it to a specific section, table, figure, or unique element of the paper. It implies that the authors are looking at their work in this area. While it identifies a general area for improvement, it doesn't specify the exact datasets or the specific aspects of the current draft that would benefit from this additional data. The comment is vague about the precise location and nature of the improvement.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for more datasets and crosstask transferability, but it does not make a definitive statement about what the authors should do or why the current draft needs more datasets for crosstask transferability. There are no logical reasoning, common knowledge, or external references provided to support the suggestion itself.", "helpfulness_rationale": "The review point suggests having 'a few more datasets' especially for 'crosstask transferability'. This is a relevant and potentially valuable piece of feedback for improving the draft. It points to a clear area for improvement and a potential avenue for future work. However, it lacks specific details on how to achieve this. The suggestion is general and doesn't provide concrete steps or guidance on what aspects of the current draft would benefit from this additional data."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests improvements to the tasks but does not explicitly state an action or provide concrete steps on how to implement these suggestions. While it implies a desire for more unique and challenging tasks, it lacks the direct guidance needed for actionability.", "grounding_specificity_rationale": "The review point discusses the nature of the tasks (figure captioning, matching) but does not specify which part of the paper or dataset it is referring to. It is a general critique of the current tasks, lacking specific identification of an area that needs improvement.", "verifiability_rationale": "The review point offers suggestions for new tasks but does not provide any justification or evidence for why these suggestions are valuable or how they relate to the existing tasks. It is a suggestion without any supporting reasoning or references.", "helpfulness_rationale": "The review point offers suggestions for new tasks, which could be beneficial for the authors in exploring more complex and diverse image processing tasks. However, the suggestions are vague and lack specific details, making it only 3 but not 5 as it doesn't provide concrete guidance on implementation or evaluation."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that the method in Section 3.1 follows the previous work, Luciddreamer. This is an implicit statement of a potential lack of novelty. While the reviewer identifies a potential issue, they do not explicitly state what action needs to be taken to address this. The reviewer's statement is a claim about the method's origin, not a direct instruction on how to improve it.", "grounding_specificity_rationale": "The reviewer mentions 'Sec. 3.1' and 'Luciddreamer' when questioning the novelty. While they identify a section, they do not explicitly pinpoint the specific part of Section 3.1 that they believe is directly copied from Luciddreamer. The reference to 'Luciddreamer' is general, and the section number is the extent of their specific reference. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim that the method follows the previous work, Luciddreamer. To verify this claim, we would need to examine Section 3.1 of the paper in question and compare it to Luciddreamer. The reviewer does not provide any evidence or reasoning to support this claim. Therefore, the claim is 1 based on the information provided.", "helpfulness_rationale": "The reviewer's primary statement is that the method in Section 3.1 follows the previous work, Luciddreamer. This raises a valid concern about the novelty of the approach. However, the reviewer does not offer any suggestions or actions to address this concern. They simply state their observation. Therefore, the review lacks actionable suggestions and is not helpful in terms of providing concrete improvements."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'This seems to be a severe drawback to me.' This indicates a clear action being taken \u2013 the reviewer is pointing out a perceived limitation. The reviewer then proceeds to elaborate on the *reasons* for this perception, which are actionable items the authors could address. The reviewer identifies the lack of an exact reformulation, the looseness of the bound due to dropping nonnegativity, and the restrictive assumption about the loss function belonging to the RKHS as specific issues.", "grounding_specificity_rationale": "The reviewer refers to 'MMD DRO,' 'Theorem 3.1,' and 'RKHS' in their review point. While they don't explicitly name a specific section or table, they are referring to specific concepts and results within the paper. This indicates that the reviewer has identified specific areas where the potential drawback lies.", "verifiability_rationale": "The reviewer provides specific reasons *why* they believe MMD DRO has these drawbacks. They point to the lack of an exact reformulation, the looseness of the bound due to dropping nonnegativity, and the RKHS assumption. These are concrete statements about the method and its theoretical properties. The reviewer is not just stating an opinion but providing specific examples of potential issues.", "helpfulness_rationale": "The reviewer's comment is clearly aimed at improving the understanding or application of MMD DRO. They are providing context and highlighting potential issues. This is a valuable piece of feedback for the authors as it helps them understand the limitations of the method and the potential need for further constraints or assumptions. The reviewer is not just pointing out a problem but also suggesting potential areas for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "None", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'what if we sparsify the trained models'. While it doesn't specify *how* to sparsify, the act of sparsifying is a clear and actionable suggestion. The comparison to the 'proposed model' is also an explicit action. Therefore, the action is clearly defined, making it 4.", "grounding_specificity_rationale": "The comment refers to 'the baselines on the left hand side' of Figure 3. This is a specific reference to a subset of the models being evaluated. Furthermore, it suggests a comparison of accuracy, which is a specific metric. This strong reference to a particular part of the paper and a specific comparison makes it 5.", "verifiability_rationale": "The comment does not contain a claim in the sense of stating an opinion or judgment. It is more of a suggestion for an experiment. Therefore, it does not have supporting evidence or justification. This aligns with the 'X' category, which would be represented by 'X' in the provided scale.", "helpfulness_rationale": "The comment suggests a concrete experiment: sparsifying the trained models and comparing accuracy. This directly relates to understanding and potentially improving the performance of the baseline models. While the suggestion is valuable, the lack of detail on *how* to sparsify makes it less directly actionable for the reviewer. Therefore, it is '4' as it points towards a useful direction but lacks immediate implementation details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the paper is written for an intuitive understanding rather than for reproducibility. They identify the missing technical details as the reason for this lack of reproducibility. This provides a clear action for the authors: to improve the technical details and make the paper reproducible.", "grounding_specificity_rationale": "The reviewer states that the paper is written for an intuitive understanding and contrasts this with the need for reproducibility. The paper and supplementary material lack the specific technical details required for reproduction. The reviewer cannot confidently determine which part of the paper they are addressing, making the grounding weak. However, the comment clearly specifies what needs to be addressed: the technical details for reproducibility.", "verifiability_rationale": "The reviewer makes a claim about the paper's intended purpose (not written to be reproduced) but does not provide any evidence or justification for this claim. There are no logical reasoning, common knowledge, or external references supporting this assertion. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer directly points out a significant deficiency in the paper: it is not written to be reproduced. This is a highly relevant and helpful comment for the authors, as it highlights a crucial aspect that needs improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a potential issue ('might introduce biases') and links it to a specific aspect of the method ('utilitybased eviction decisions'). This makes the action explicit. However, they don't provide concrete steps on how to address this, making it implicit.", "grounding_specificity_rationale": "The reviewer mentions 'FIITED' and 'utilitybased approach to determine chunk significance', clearly identifying the specific part of the paper being addressed. However, they do not specify a particular detail or chunk within this aspect that needs improvement, making it underspecific.", "verifiability_rationale": "The reviewer makes a claim about a potential bias in the FIITED method and provides a plausible explanation ('temporary high utility of recent chunks') but does not offer concrete evidence or citations to support this claim. Therefore, it is verifiable but lacks strong support.", "helpfulness_rationale": "The reviewer identifies a potential issue with the FIITED method that could affect the author's work. However, they do not provide specific suggestions or detailed explanations of how to address this issue, making the feedback somewhat general and less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer's criticism is somewhat implicit. While they state the framework's performance is unclear, the suggestion to conduct more experiments is a direct action. However, the lack of detail in the suggestion makes it vague. The criticism doesn't explicitly demand the authors to perform specific actions, only that they should. Therefore, it leans towards implicit actionability with vague details.", "grounding_specificity_rationale": "The reviewer mentions 'the different part of this framework' and 'algorithms' but doesn't specify which parts or algorithms are problematic. They state that the framework's performance is unclear, but this is a general statement. The criticism lacks specific details about *why* certain parts or algorithms might be underperforming. The grounding is weak because the specific elements being criticized are not clearly identified.", "verifiability_rationale": "The reviewer identifies a gap in the information: the lack of quantitative experiments and comparisons. This constitutes a claim that the framework's performance evaluation is incomplete. The reviewer provides some evidence for this claim by pointing out the absence of such experiments. However, the claim is not fully supported by explicit references or logical reasoning within the review point itself. The evidence provided is somewhat vague (lack of quantitative experiments and comparisons).", "helpfulness_rationale": "The reviewer clearly states their lack of understanding and the need for more information about the framework's performance and contribution. The criticism directly points out the missing elements (quantitative experiments, comparisons) that are crucial for understanding the framework. The reviewer's statement is a clear call for more detail and evidence, making it 5 for the authors to improve their draft by addressing these gaps. The reviewer is directly prompting for specific improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the potential of the model, rather than providing a direct instruction on how to improve the draft. While the question is relevant, it doesn't specify a concrete action or modification that the authors should undertake. The reviewer is seeking clarification on the model's capabilities, which is a valid point of inquiry but not an actionable suggestion for improvement.", "grounding_specificity_rationale": "The review point asks a question about the model's potential and testability, referencing a specific aspect of the paper (neuron data). However, it doesn't explicitly identify a specific section, table, or figure within the paper. While the question is about a particular aspect, the reviewer doesn't pinpoint the exact location of this aspect in the submitted work. Therefore, while the topic is grounded, the specific part being addressed is not.", "verifiability_rationale": "The review point is a question, not a claim that requires verification. While the question about the model's potential and testability is relevant and could be addressed by referencing existing literature, the review point itself doesn't present a claim that needs to be supported by evidence. The reviewer is asking for clarification, not making a statement that requires justification.", "helpfulness_rationale": "The review point raises a valid and important question about the significance and potential impact of the work. It encourages the authors to consider the broader context of their research and the implications of their model. While it doesn't directly tell them how to change their model, it prompts them to think critically about its contribution and testability. This is a valuable point of discussion that can guide further development and research."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a question prompting a simplification of a theorem, not a directive with explicit instructions on how to improve the draft. It asks what should be simplified, not how to simplify it.", "grounding_specificity_rationale": "The review point does not specify a particular section, table, or figure within the paper where the simplification of theorem 2 is being suggested. It refers to the theorem in general.", "verifiability_rationale": "The review point is a suggestion or recommendation (presenting a simplified version of theorem 2) but does not explicitly state a claim that requires verification. It's a request for clarification on a potentially complex topic, not a statement that needs to be proven or justified.", "helpfulness_rationale": "The review point is a question prompting a simplification, not a directive with concrete information on how to improve the draft. It lacks specific guidance on what needs to be done."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests an experiment (using larger resolution) but does not explicitly state how to implement this change. While it implies an action, the lack of concrete steps makes it difficult for the authors to directly apply this suggestion. The action is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The comment explicitly mentions the resolution (224*224) and asks about the impact of using a larger resolution. This clearly identifies the specific part of the paper and the issue being addressed, making it fully grounded. It also specifies what needs to be addressed (performance impact), making it specific.", "verifiability_rationale": "The comment presents a suggestion (running an experiment with larger resolution) and a question (how performance will be) but does not provide any justification or evidence to support this claim. It lacks logical reasoning, common knowledge, or external references to back up the suggestion.", "helpfulness_rationale": "The review point identifies a potential improvement (larger resolution) and asks a relevant question but does not provide any guidance on how to implement this or why it might be beneficial. It lacks concrete steps or reasoning to empower the authors to significantly improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states the action: \"just multiply each feature map element wise by H_psi?\". This is a clear instruction on what calculation to perform on the feature map.", "grounding_specificity_rationale": "The review point directly references \"KeyQN section What is the keypoint mask averaged feature vector?\". This clearly identifies the section and the concept being discussed, allowing the authors to accurately pinpoint the relevant part.", "verifiability_rationale": "The review point suggests a specific mathematical operation (\"multiply each feature map element wise by H_psi\") based on the described components in the KeyQN section. This claim can be verified by examining the implementation details of the feature map and H_psi.", "helpfulness_rationale": "The review point directly identifies a potential issue in the KeyQN section by suggesting a specific calculation. It offers a clear, actionable suggestion for the authors to verify their implementation and potentially simplify their approach."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer expresses doubt about the significance of the problem they are highlighting, suggesting they are not convinced about the inaccuracy of neural ODEs while recomputing activations. While they point to a previous paper reporting this issue, the current paper doesn't provide a convincing analytical argument or empirical evidence to address this concern. The reviewer is questioning the validity of the problem itself, rather than suggesting a specific action the authors should take to address it. Therefore, the actionability is low as the reviewer doesn't explicitly state an action or a clear path forward.", "grounding_specificity_rationale": "The reviewer's comment is a general question about the significance of a problem related to neural ODEs and weight evolution using ODEs. They do not explicitly identify a specific part of the paper or methodology being discussed. The mention of 'ODEs exhibiting inaccuracy while recomputing activations' is a general statement without pinpointing a section, table, figure, or a unique aspect of their work. Therefore, the grounding specificity is low as the reviewer does not clearly identify the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer makes a claim about their lack of conviction regarding the problem of neural ODEs exhibiting inaccuracy while recomputing activations. This claim is not supported by specific evidence or logical reasoning within the review point itself. The reviewer is expressing a subjective opinion rather than providing a verifiable statement. Therefore, the verifiability is low as the reviewer's statement is not backed by sufficient evidence or justification.", "helpfulness_rationale": "The reviewer raises a valid concern about a core methodological aspect of the paper, specifically the modeling of weight evolution using ODEs and the potential inaccuracy during recomputation. This raises a legitimate question for the authors and could be helpful in identifying potential weaknesses in their approach. However, the reviewer does not provide a solution or specific guidance to the authors, making it 3 but not entirely constructive. The lack of a direct solution makes it less than maximally helpful."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a potential improvement by mentioning the sampled policy, which is an explicit action. However, it doesn't provide concrete details on how to implement this improvement, leaving the authors with a general direction but lacking specific guidance. The suggestion to clarify the 'awhile' duration is implicit, as the authors would need to determine what constitutes 'awhile' based on their own understanding and experimentation.", "grounding_specificity_rationale": "The review point explicitly refers to 'these algorithms,' grounding the comment to a specific part of the paper. However, it doesn't specify a particular section, table, figure, or unique element within the algorithms. The suggestion to follow the 'sampled policy' for 'awhile' is a general behavior, and the authors would need to infer where this behavior is occurring and what the potential issue is.", "verifiability_rationale": "The review point doesn't contain a claim in the sense of criticizing an aspect or making a definitive statement about the algorithms. It's more of a suggestion for clarification. Therefore, it doesn't have verifiable content as it doesn't present a statement that can be supported or refuted.", "helpfulness_rationale": "The review point offers a suggestion for clarification regarding the algorithms' behavior. While it doesn't directly critique or criticize anything, it points towards a potential area for improvement by suggesting the authors investigate the 'awhile' duration. This suggests a constructive direction for the authors, making it 3. However, it lacks the specificity and actionable details of a fully helpful comment."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggestion. The reviewer is expressing a desire for more experiments and then providing feedback on a potential limitation of the current method. While the reviewer acknowledges the author's response, the core of the comment is about future directions and limitations, not a direct instruction on how to improve the current draft.", "grounding_specificity_rationale": "The reviewer does not explicitly identify a specific part of the paper being addressed. They are broadly commenting on the need for more experiments and then suggesting a potential issue with the method. The comment lacks a precise reference to a section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer's comment contains a claim: \"I still think maintaining the probabilities might become an issue, in particular at large batch size, but I don't think this aspect is critical.\" This claim is 3 as the reviewer states a potential limitation of the method. However, the reviewer also states \"but I don't think this aspect is critical,\" which introduces a subjective element and weakens the verifiability. The lack of specific examples or references makes it somewhat underspecific.", "helpfulness_rationale": "The review point is 3. While the initial suggestion for 'additional experiments on larger data sets' is not directly actionable for the current paper, the reviewer's subsequent comment about the limitations of maintaining probabilities and their positive feedback of the author's response indicate a valuable, albeit indirect, critique. The reviewer acknowledges the author's response and provides feedback on a potential issue related to the paper's content, suggesting a desire for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the performance gap between the submitted model and GLaMM and UNINEXT. While it doesn't provide specific actionable steps, it identifies a clear area for improvement by pointing to the specific metrics (REC and RES) and models that are performing better. This provides the authors with a target for further investigation and potential improvement.", "grounding_specificity_rationale": "The review point explicitly refers to 'Table 4' and mentions specific models ('GLaMM' and 'UNINEXT') and their performance on specific datasets ('RefCOCO TestA' and 'RefCOCOg Test'). This demonstrates strong grounding as the authors can directly identify the referenced part of the paper and the specific elements being discussed. The mention of metrics like 'RES cIoU' and 'REC accuracy (IoU>0.5)' further specifies the areas of comparison.", "verifiability_rationale": "The review point contains a claim ('Table 4: The performance on REC and RES are clearly behind more recent models') and provides supporting evidence by mentioning specific models ('GLaMM' and 'UNINEXT') and their performance on specific datasets ('RefCOCO TestA' and 'RefCOCOg Test'). The comparison to these models provides a basis for logical reasoning and external references, making the claim verifiable.", "helpfulness_rationale": "The review point identifies a clear performance gap between the submitted model and more recent models. This is a valuable piece of feedback for the authors as it highlights areas where their model could be improved. While it doesn't offer specific solutions, it provides a clear direction for further investigation and potential enhancements to the model. The information is directly relevant to the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point is an implicit suggestion that the authors should investigate the performance of their method on cluttered scenes. While the action is not explicitly stated, the reviewer implies a need for testing on such scenes. However, the specific steps or criteria for this investigation are not provided, making it somewhat vague.", "grounding_specificity_rationale": "The review point explicitly refers to 'this method' and focuses on a specific aspect of it \u2013 its potential performance in 'cluttered scenes'. The authors can easily identify the relevant part of the paper and understand the specific issue being raised. The comment is clearly targeted at a specific component of the method.", "verifiability_rationale": "The review point contains a claim that the weakness of the method might be more prominent in 'cluttered scenes'. The reviewer also suggests an experiment ('It would be very interesting to compare this approach to previous ones on such a dataset!') as a way to verify this claim, providing some justification for the suggestion. However, the exact nature of the experiment and how the results would be analyzed are not detailed.", "helpfulness_rationale": "The review point is relevant to the paper's core contribution, which is fewshot classification. The reviewer identifies a potential limitation of the method and suggests a concrete experiment to investigate it. While the suggestion is not fully detailed, it provides a clear direction for further research and is directly related to the paper's topic. Therefore, it is helpful in guiding the authors towards further investigation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the implementation framework (OpenAI's Triton) and suggests a level of conciseness. While it doesn't specify *how* to implement it with Triton, it implies the need for a change in implementation details. The suggestion to be concise is also explicit.", "grounding_specificity_rationale": "The comment refers to the 'kernels' in general, which can be reasonably inferred to be a specific part of the implementation. However, it doesn't pinpoint a specific section, table, figure, or unique element. The justification for the conciseness is based on the general concept of 'wellknown engineering improvements' rather than a specific example.", "verifiability_rationale": "The comment contains a claim that a fullpage explanation is unnecessary. It provides a justification for this claim by stating that the implementation is with 'wellknown engineering improvements'. This justification, while not a direct citation, provides a logical reasoning for why the explanation might be considered excessive.", "helpfulness_rationale": "The review point directly addresses a specific technical detail (the implementation framework) and offers a clear suggestion for improvement (being concise). The justification for the conciseness is provided, explaining why a fullpage explanation might be unnecessary. The reviewer is addressing a specific issue and providing a practical suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer criticizes the zeroshot claim but does not propose an alternative action or suggest how to improve the transferability. They are pointing out a flaw in the *claim* itself rather than offering a concrete action to take. Therefore, the actionability is low as the reviewer doesn't identify a specific step the authors should follow to address the identified issue.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'zeroshot', 'real difficulty', 'target task', 'source task', 'walkerrun', 'walkerwalk', '3prong task', 'counterclockwise rotations', '4prong task', and 'target task'. This demonstrates a clear grounding of the criticism in specific elements of the paper. The reviewer is not just stating a general concern but is specific about the tasks and experimental setup involved. This indicates a high level of grounding specificity.", "verifiability_rationale": "The reviewer makes claims about the difficulty of the tasks and the sufficiency of the experimental setup. While they don't provide direct evidence *within this review point* to support these claims, they are making logical arguments based on their understanding of the tasks. For example, they argue that the difficulty gap between 'walkerrun' and 'walkerwalk' makes the zeroshot transfer less reliable. They also suggest that the 3prong and 4prong tasks provide enough information. These are logical arguments, but without external references or specific data within this review point, the verifiability is somewhat limited. However, the reviewer is making a clear argument based on their understanding, which makes it 3.", "helpfulness_rationale": "The reviewer provides a clear explanation of why they believe the zeroshot claim is problematic. They highlight the potential limitations due to the difficulty gap between source and target tasks and suggest that the experimental setup might already provide sufficient information for transfer. This critique is specific and actionable for the authors, guiding them to reconsider their approach and potentially explore alternative methods. The reviewer is not just pointing out a flaw but is also suggesting potential directions for improvement. This makes the review point 5."}
{"actionability_label": "4", "grounding_specificity_label": "4: 5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The statement explicitly states that the analysis of neural networks contributes less and describes the limitations: 'With the existing NTK theorem, the extension from linear models to wide fullyconnected neural networks is trivial' and 'only considers the easy wide fullyconnected neural networks'. This clearly indicates the lack of significant contribution in this area.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Sections 3.2, 3.3' and 'wide fullyconnected neural networks' when describing the scope of the analysis. This provides clear grounding in the specific parts of the paper and the type of neural networks being discussed. Furthermore, the reviewer also mentions 'overparametrized neural networks' which further specifies the context.", "verifiability_rationale": "The reviewer makes a claim about the triviality of the extension and the limited scope of the analysis. This claim is supported by the reasoning that 'With the existing NTK theorem, the extension from linear models to wide fullyconnected neural networks is trivial' and by specifying the 'easy wide fullyconnected neural networks' considered. These elements provide logical reasoning and specific details to support the claim.", "helpfulness_rationale": "While the review points out a limitation in the analysis of neural networks, it does not offer specific suggestions or guidance on how to improve the analysis. The reviewer criticizes the contribution but does not provide actionable steps for the authors to take. Therefore, while it identifies a weakness, it lacks the constructive feedback needed for helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the connection between the abstract and the introduction, which is a clear indication of an explicit action. However, the specific actions or modifications the authors should apply based on the terms 'relatively inexpensive' and 'expensive to evaluate' are not explicitly stated. The authors would need to infer that they need to clarify the cost thresholds and the computational methods being discussed.", "grounding_specificity_rationale": "The reviewer mentions the paper 'Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al. 2017)' as a relevant work. This indicates a weak grounding as the authors can make an educated guess about the relevance of the paper. However, the reviewer does not specify which section, table, or unique aspect of the Stroh et al. 2017 paper is directly related to the multifidelity framework and sequential design for learning quantities of interest. The reviewer also identifies the terms 'relatively inexpensive' and 'expensive to evaluate' as areas needing improvement, but does not specify what exactly is missing or unclear in these terms.", "verifiability_rationale": "The reviewer states that the terms 'relatively inexpensive' and 'expensive to evaluate' are confusing. This constitutes a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as an assertion without any justification.", "helpfulness_rationale": "The reviewer attempts to provide context by mentioning the multifidelity framework and sequential design for learning quantities of interest. They also point out a potential point of confusion with the terms 'relatively inexpensive' and 'expensive to evaluate'. While this provides some context, the lack of specific grounding and verifiable reasoning makes it difficult for the authors to act on this feedback. They would not know exactly what is causing the confusion or what specific aspects of the cost thresholds or computational methods are problematic."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a *potential* advantage of the method and then criticizes its practical limitations. While it identifies a *problem* (sparse rewards, subtask rewards), it doesn't *explicitly* tell the author *how* to fix it or what specific changes are needed. The connection to the proposed method is implied but not directly actionable.", "grounding_specificity_rationale": "The review refers to 'sparse reward problems\" generally. While it mentions 'subtaskspecific rewards,\" it doesn't pinpoint a specific section, table, or figure in the paper where this issue is discussed or how it relates to the proposed method. The connection is implied but not explicitly stated.", "verifiability_rationale": "The review makes a claim: \"From the experiments, this does not support well.\" It also raises a question: \"minor comments: specific question about subtask rewards and dense rewards.\" While the claim is made, the reviewer doesn't provide *any* specific evidence or reasoning to support it. The question further indicates a lack of verification.", "helpfulness_rationale": "The review points out a potential issue with the proposed method and raises a question about its practicality compared to an alternative. While it highlights a potential limitation, it doesn't offer concrete solutions or comparisons to help the author understand the tradeoffs. The lack of a direct comparison to Qmix makes it less helpful in addressing the specific problem."}
{"actionability_label": "3", "grounding_specificity_label": "2: 4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification on whether the AH36M dataset is used for training. While it implies an action (clarification), it doesn't explicitly state what action needs to be taken or how to identify the issue if it exists. The reviewer is asking for information, not guiding the authors on a specific action to improve their draft.", "grounding_specificity_rationale": "The review point explicitly mentions 'AH36M dataset' and asks about its usage during training. This clearly identifies the specific part of the paper being addressed, providing strong grounding. The questions are directly about this specific dataset and its usage.", "verifiability_rationale": "The review point presents questions about the AH36M dataset and its usage. These are declarative statements that require the authors to provide information or clarification, rather than making a claim that needs verification through logical reasoning, common knowledge, or external references. Therefore, it lacks a verifiable claim.", "helpfulness_rationale": "The review point asks questions about the AH36M dataset and its usage during training. While this points to a potential implementation detail that could be important for reproducibility and fair comparison, it doesn't directly identify a weakness in the authors' draft or provide actionable feedback on how to improve it. It's a request for clarification rather than a statement of a problem with a solution offered."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "Not Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests comparing the results to a specific benchmark (COOC leaderboard) on a specific dataset (blind test set). While this is a clear direction for the authors to follow, it doesn't explicitly tell them *how* to make this comparison or what specific changes they should make to their draft to achieve this. The action is implied rather than explicitly stated with concrete steps.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'official COOC leader board on the blind test set' and provides a link to relevant prior work that has used this benchmark. This clearly grounds the suggestion in a specific evaluation metric and dataset, making it highly specific to the experimental setup.", "verifiability_rationale": "The reviewer's suggestion to compare results to the COOC leaderboard is implied rather than explicitly stated with supporting evidence within the review point itself. While the benefits of such a comparison (demonstrating improvement, comparing against established benchmarks) are generally understood, the review point doesn't provide a logical reasoning, common knowledge, or external reference to *prove* the value of this comparison.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'For the captioning experiment, the paper compares to related work only on some not official test set or dev set, however the final results should be compared on the official COOC leader board on the blind test set'. This is a 5 suggestion as it directly points the authors to a specific and relevant benchmark for comparison, which is a crucial step in validating their experimental results and demonstrating their method's effectiveness against established standards. This provides a clear direction for the authors to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer is suggesting a change to improve the clarity of the explanation at line 248. This is an explicit action, as the reviewer directly states what they believe is wrong and offers a solution. The action is also concrete, as the reviewer suggests clarifying the meaning of 'wrong'. This provides a clear direction for the authors to follow.", "grounding_specificity_rationale": "The reviewer is pointing out a potential issue with the clarity of the explanation at line 248. While the reviewer doesn't explicitly state which section or paragraph is problematic, the implication is that the explanation around the word 'wrong' needs improvement. This makes the grounding somewhat weak as the authors can't confidently pinpoint the exact location. However, the reviewer clearly specifies what needs to be addressed: the definition of 'wrong'. This adds a layer of specificity to the feedback.", "verifiability_rationale": "The reviewer is not making a claim that something is wrong with the paper in a way that requires justification. Instead, they are suggesting an improvement to the clarity of an explanation. While the suggestion itself could be considered verifiable if the authors agree on the definition of 'wrong', the reviewer's point does not directly involve making a claim that needs supporting evidence. Therefore, it's not 5 in the sense of pointing out a flaw that requires logical reasoning or references. The suggestion is more of a constructive suggestion than a claim requiring verification.", "helpfulness_rationale": "The reviewer provides a specific suggestion for improvement: clarifying the meaning of 'wrong' in the explanation at line 248. This is a direct and actionable piece of feedback that the authors can readily implement. The suggestion is clear and directly addresses a potential weakness in the paper's clarity. Therefore, it is 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the *missing* element of the experimental comparison (MVF results) and clearly identifies the *problem* (lack of sufficient evidence to prove schema superiority). The action is to request the MVF results, and the details are to show how ELF's schema is better than MVF's. The action is explicit and concrete.", "grounding_specificity_rationale": "The review point explicitly mentions the *specific* missing part of the paper (MVF results) and clearly states the *issue* (lack of comparison). The comment directly points to the relevant section and explains *why* it's needed. The grounding is literal and precise.", "verifiability_rationale": "The review point claims that the *absence* of the MVF comparison *proves* the superiority of ELF's schema. This is a claim that needs justification. While the MVF comparison is relevant, its absence doesn't logically *prove* superiority. The claim is presented as a deduction or inferred observation that goes beyond merely stating facts. The evidence provided is the *lack of* something, not a direct verification of the claim.", "helpfulness_rationale": "The review point directly identifies a significant weakness in the experimental validation (lack of MVF comparison) and provides a clear *what's missing* and *why it's important*. It's immediately actionable and relevant to the authors' goal of demonstrating their contribution. The feedback is directly targeted at improving the experimental section."}
{"actionability_label": "3", "grounding_specificity_label": "2: 4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point asks the authors to provide more information about the types of activities in the datasets and their importance. While it implies an action (providing more detail), it doesn't explicitly state how the authors should do this. The reviewer is asking for more information, not necessarily a specific method of providing it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'types of activities,' 'importance,' 'occupant comfort,' and 'energy efficiency.' This clearly identifies the specific aspects of the paper being addressed and explains why they are relevant. The authors can easily pinpoint the section and the issues being raised.", "verifiability_rationale": "The reviewer states that the authors have not covered more on the types of activities and their importance, particularly from the perspective of occupant comfort and energy efficiency. This constitutes a claim that the paper lacks sufficient discussion on these points. The reviewer provides some justification by specifying the perspectives (occupant comfort and energy efficiency).", "helpfulness_rationale": "The review point asks the authors to provide more information about the types of activities in the datasets and their importance, particularly regarding occupant comfort and energy efficiency. While this is a valid suggestion for improvement, it is a broad request and does not directly instruct the authors on how to achieve this. The reviewer is identifying a gap in the discussion, but not providing a specific solution or method for addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their understanding of 'state' and asks a direct question about the relationship between 'elements' and their understanding of 'state'. This action is clear and points to a specific area in the paper (lines 186187). The reviewer is also providing a concrete example of what they perceive 'state' to be (agent position).", "grounding_specificity_rationale": "The reviewer explicitly mentions lines 186187, which clearly indicates a strong grounding in the specific part of the paper being discussed. The reviewer also clearly specifies what they are asking about ('elements' and their understanding of 'state'), making the grounding specific.", "verifiability_rationale": "The reviewer makes a claim by asking a question about the relationship between 'elements' and their understanding of 'state'. This claim could be verified by examining the description in lines 186187 and comparing it to the reviewer's interpretation of 'state'.", "helpfulness_rationale": "The reviewer identifies a potential point of confusion regarding the term 'state' and asks a relevant question. This feedback is helpful in identifying areas where the paper could be clearer. While it doesn't provide a solution, it does point the authors to a specific area for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "The review point is a question about comparing support, which implies a desired outcome but doesn't provide explicit instructions on how to achieve it. It lacks the explicit 'do X' component, making it 2.", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the theoretical comparisons to adaptive learning of GPRGNN are unclear. This indicates an explicit action that needs to be taken \u2013 to clarify these comparisons. However, the comment does not provide specific guidance on how to achieve this clarity. The action is implied but not explicitly defined.", "grounding_specificity_rationale": "The comment explicitly mentions 'theoretical comparisons to adaptive learning of GPRGNN'. This indicates that the authors can accurately pinpoint the specific part of the paper being addressed, making it 'Fully Grounded'. The comment also specifies what is unclear \u2013 'theoretical comparisons', making it 'Specific'. Therefore, it is '5'.", "verifiability_rationale": "The comment contains a claim ('theoretical comparisons to adaptive learning of GPRGNN is not clear') and provides some justification by stating that it's 'not clear'. However, it lacks specific examples or references to support this claim. The reasoning is present but lacks depth and specific evidence. Therefore, it is '3'.", "helpfulness_rationale": "The comment clearly identifies a weakness in the paper (lack of clarity in theoretical comparisons) and directly points to its impact on the authors' understanding. This provides valuable information for the authors to improve their work. Therefore, it is '3'."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their intention to suggest an alternative evaluation method, making the action clear and direct. They propose using a confidence score, which is a concrete and actionable suggestion.", "grounding_specificity_rationale": "The reviewer identifies the specific issue of yes/no responses not proving comprehension, demonstrating a clear understanding of the problem. They propose using confidence scores as a solution, making the suggestion very concrete. While the reviewer doesn't explicitly point to a specific section or table within the paper where this limitation might be documented, the *review point itself* identifies the *problem* clearly. The reviewer's suggestion is directly related to the identified problem.", "verifiability_rationale": "The reviewer makes a claim: 'Yes response does not necessarily indicate that the model comprehends the presence of the object in the image.' This is a clear statement that can be verified. They provide a reason for this claim: 'as it may still produce incorrect objects when undertaking other tasks.' This provides some justification for the claim.", "helpfulness_rationale": "The reviewer's suggestion to use a confidence score is a relevant and actionable improvement to the evaluation process. It directly addresses the limitations of yes/no responses in measuring object hallucination. While it doesn't solve *every* potential issue with yes/no responses, it's a valuable contribution to the discussion and provides a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the proposed FRM is a 'simple combination' of channel and spatial attention. However, they do not specify how this combination is achieved or what the specific innovative aspect is. While the action is identified (pointing out a lack of detail), the implementation details are missing, making it vague on how to apply this feedback.", "grounding_specificity_rationale": "The reviewer mentions 'channel attention' and 'spatial attention,' which provides some grounding by referencing specific techniques. However, they do not pinpoint a specific part of the proposed FRM or a unique element being addressed. The criticism is about the approach rather than a specific flaw in a section, making the grounding weak. While the specificity of the criticism (lack of indepth detail) is clear, the grounding is weak because it doesn't target a specific part of the proposed method.", "verifiability_rationale": "The reviewer makes a claim: 'The proposed FRM is a simple combination of channel attention and spatial attention.' They support this claim by stating that the 'innovative should be given in detail.' This provides logical reasoning and a clear justification for why the proposed method might be lacking. The evidence is based on the description of the method as a 'simple combination' and the absence of detailed innovation. The evidence is somewhat strong in identifying the lack of detail as a potential issue.", "helpfulness_rationale": "The reviewer's point is helpful in highlighting a potential weakness in the proposed FRM \u2013 its lack of indepth detail. This could be a valid concern for researchers looking to build upon existing work. However, the criticism is primarily negative, pointing out a lack of detail rather than offering a specific alternative or improvement. Therefore, while it provides value by identifying a potential area for improvement, it lacks the constructive elements of suggesting a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of connection between the two mentioned concepts and provides an example of an implicitly stated action (identifying the lack of connection) and an action that can be inferred (the potential reason for the lack of connection, 'in part due to poor clarity').", "grounding_specificity_rationale": "The reviewer mentions 'improved variance control of prediction y^ or the smoothness of loss landscape' but does not specify which part of these concepts is being referred to in relation to 'zeroshot learning effectiveness'. The comment is vague about what needs to be addressed in the mentioned concepts.", "verifiability_rationale": "The reviewer states a claim that there is no clear connection and provides a potential reason ('in part due to poor clarity'). However, this claim is not fully supported by explicit evidence or justification. The reasoning is vague and lacks specific examples or references.", "helpfulness_rationale": "The reviewer points out a potential disconnect between two related but distinct areas. While it's a valid observation, it might not immediately guide the authors on *how* to improve their model. The connection isn't explicitly stated, making it difficult to derive actionable feedback immediately."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer suggests a 'deeper analysis' of the paper's findings. This is an implicit suggestion for action, as the paper doesn't explicitly state *how* to perform this analysis. The action itself (further analysis) is clear, but the lack of detail makes it vague.", "grounding_specificity_rationale": "The reviewer's suggestion is broad and doesn't specify which methods to analyze or how to analyze them. They are essentially stating a problem (lack of deeper analysis) without pinpointing the exact area of investigation. This lack of specificity means the comment is 1 in the paper's content.", "verifiability_rationale": "The reviewer identifies a gap in the paper's analysis, which can be considered a claim. However, they don't provide any justification or reasoning for why this gap exists or how it could be addressed. The claim is present, but it's not supported by evidence or logical reasoning.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement by pointing out a missing element in the paper and offering a constructive suggestion to address it. While the suggestion lacks specifics on *how* to perform the analysis, the *content* of the suggestion is valuable and directly addresses a weakness in the paper."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks for a citation regarding the kmax problem, which is a direct request for information. The action is to provide a citation, making it actionable.", "grounding_specificity_rationale": "The reviewer asks 'Where else was the kmax problem discussed?' and 'Please provide a citation for this.' While they don't explicitly name a section or table, their request is clearly directed towards finding information about the kmax problem in general. This implies a need to ground the discussion in prior work, but the grounding is not specific to a particular part of the paper being reviewed.", "verifiability_rationale": "The reviewer is asking for a citation, which is a claim that the kmax problem has been discussed in the literature. While the paper being reviewed might not explicitly mention it, the reviewer's request implies that such a discussion exists, making it verifiable through external references.", "helpfulness_rationale": "The reviewer is identifying a potential gap in the discussion of the kmax problem and is asking for evidence to support or address this gap. This is a helpful suggestion for the author to consider and improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "Not Very Helpful", "actionability_rationale": "The comment identifies a missing piece of information (estimation of the function) but does not explicitly state how to obtain or implement it. The action is implicit (inferring the missing information) rather than explicit (providing a direct link or formula).", "grounding_specificity_rationale": "The comment does not specify which part of the paper or which function is missing. It only mentions 'the function for the optimal sequence length'. This implies a lack of precise identification, making it 1.", "verifiability_rationale": "The comment points to Equation 1 as the source of the missing information. This provides a reference, making it 3. However, it does not explain how the function was estimated or why the model is reliable, leaving gaps in the justification.", "helpfulness_rationale": "The comment identifies a valid concern (lack of information) but does not provide any suggestions or guidance on how to address it. The authors still need to go back to Equation 1 and try to understand it on their own, making the feedback less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X  X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two issues: forward referencing in the paper and the placement of key components in the appendix. While it points out these problems, it doesn't explicitly state how the authors should address them. The suggestions are present but lack specific implementation details.", "grounding_specificity_rationale": "The review point mentions 'Figure 1' as an example of unexplained material. While it identifies a specific part of the paper, it doesn't pin down the exact section, table, or unique aspect being referred to. The reviewer's identification of Figure 1 suggests a degree of grounding, but the comment itself is general.", "verifiability_rationale": "The review point describes the paper's structure and content organization. It states facts about the forward referencing and the location of key components (appendix). There are no claims being made or challenged in this review point.", "helpfulness_rationale": "The review point clearly identifies two distinct weaknesses: the issue with forward referencing and the lack of main section placement for key components. It suggests potential solutions, such as improving the explanation in the introduction and relocating content to the main sections. While the suggestions are present, they are somewhat general and could be more specific."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that Table 1 only shows results on the discriminative setting and asks for the results on the generative setting. The reviewer then explains why the generative setting is important for realworld applications. This is an explicit statement of a missing action and a clear request for improvement. The reviewer directly identifies the action needed: to provide results for the generative setting.", "grounding_specificity_rationale": "The reviewer directly refers to 'Table 1' and specifies the missing information as 'the result on generative setting'. This demonstrates a clear understanding of where the information can be found and what is being requested. The reviewer can accurately pinpoint the section and the specific missing detail.", "verifiability_rationale": "The reviewer makes a claim that the discriminative setting is not applicable to real applications and asks for results on the generative setting, which is more relevant. This claim is based on common knowledge within the field. However, the reviewer does not provide specific examples or external references to support this claim. The claim is present, and there is a basis for understanding its relevance, but the evidence provided is not robust.", "helpfulness_rationale": "The reviewer points out a potential gap in the evaluation by highlighting the absence of results for the generative setting, which is considered more relevant for realworld applications. This is a constructive suggestion for improvement. While the reviewer identifies a problem, they are not directly critiquing a flaw or ambiguity within the paper's content itself. They are suggesting an improvement to the evaluation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point is a statement of opinion or a suggestion for improvement, but it lacks a direct instruction on what the author should do. It's more of a 'why' than a 'how to do it'.", "grounding_specificity_rationale": "The comment is vague. It refers to 'a query of the type SEARCH' and 'some realistic scenario' without specifying *which* query or scenario. There's no reference to a specific section, table, figure, or unique element of the paper.", "verifiability_rationale": "The comment is more of a suggestion for improvement or a point for discussion rather than a definitive claim that needs to be proven or disproven. It doesn't state something is *definitely* true or *definitely* false.", "helpfulness_rationale": "The comment identifies a potential area for improvement (convincing scenarios) but doesn't provide a specific *howto* or concrete suggestions. It's a suggestion for improvement, not a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a limitation: 'The effectiveness of the proposed approach for other language families remains unknown.' While it doesn't directly suggest an action, the statement itself points to a clear area that needs addressing. The reviewer is implicitly suggesting that this unknown effectiveness is a problem or a point for improvement.", "grounding_specificity_rationale": "The comment mentions 'other language families,' which is a specific category of language. However, it doesn't pinpoint a specific section, table, figure, or unique aspect within that category. The reviewer is asking about the applicability of the approach across different linguistic structures, but the comment doesn't provide details on how to assess this for a specific instance.", "verifiability_rationale": "The comment states a fact: 'The effectiveness of the proposed approach for other language families remains unknown.' This is a statement of observation, not a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided to support or refute this statement.", "helpfulness_rationale": "The comment identifies a missing piece of information: the effectiveness of the approach for other language families. This is a valid point that highlights a limitation in the current research. While it doesn't offer a solution, it points to a clear area where further investigation or clarification is needed, making it 3 in guiding future work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment states that the related work could be improved but does not specify what needs to be changed. The action 'improved' is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The comment explicitly mentions 'related work' as the area needing improvement, providing clear identification of the specific part of the paper. It also specifies that the issue is the lack of description of the differences between the mentioned related works.", "verifiability_rationale": "The comment does not contain a claim or suggestion. It is a statement of a problem ('some related work are mainly named...') without proposing a solution or making a judgment.", "helpfulness_rationale": "The comment identifies a valid weakness in the related work section ('lack of description') and provides a clear direction for improvement ('improved'). While it doesn't offer specific steps, it guides the authors to focus on enhancing the clarity of the related work section."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The review point does not explicitly state an action or suggestion for the authors. It raises a question about the interpretation of PPP maps, which could be seen as implicitly suggesting an action (understanding the maps), but this is not clearly stated or followed by concrete guidance. Therefore, the actionability is low.", "grounding_specificity_rationale": "The reviewer does not explicitly identify a specific part of the paper being addressed. The comment is a general question about the interpretation of PPP maps. Therefore, the grounding specificity is low as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer raises a point about the paper's content but does not provide any evidence or justification for their claim. They are asking the authors to explain something, but not providing any basis for their assertion. Therefore, the verifiability is low as there is X or supporting evidence provided by the reviewer.", "helpfulness_rationale": "The reviewer points out a potential area for improvement in the paper \u2013 adding an explanation of PPP maps. However, the reviewer's comment itself does not directly provide actionable feedback to the authors on how to improve their current draft. They are raising a question that could be addressed in future revisions, but the current review doesn't offer specific steps the authors should take to address this issue in their existing work. Therefore, the helpfulness is low as the reviewer's point is about a future improvement, not a direct critique or suggestion for improvement of the current draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking for clarification on the definition of 'sublinear' in the context of regret. This is an implicit action asking the authors to define a term that is central to their claim. While the authors *could* have explicitly stated the definition, the reviewer's question implies they are unsure of the intended meaning, making the action implicit.", "grounding_specificity_rationale": "The reviewer is directly asking about the grounding of the claim 'the regret cannot be sublinear'. They are asking which specific part of the paper this claim refers to, indicating a clear attempt to identify the relevant section. The phrasing 'lines 32  37' suggests they believe this claim is made within that specific section, indicating a degree of grounding.", "verifiability_rationale": "The reviewer points out a potential inconsistency: the paper claims regret cannot be sublinear, but then proves a T^(1/2) regret. This is a verifiable issue. The reviewer is asking for justification for the claim, and the paper's own proof provides some justification, but the reviewer is questioning the initial claim's validity in light of the proof. This suggests the claim is not fully supported by the reasoning provided.", "helpfulness_rationale": "The reviewer's question is directly aimed at improving the clarity and precision of the paper. By asking for a definition of 'sublinear', they are seeking actionable feedback that would help the authors communicate their ideas more effectively. This is a valuable and specific piece of feedback for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need to 'explain the forwardprediction model'. This is a clear and direct action the authors should take. The reviewer also provides a concrete suggestion: 'redraw Figure 2(b)'. This indicates a clear and actionable improvement. The reviewer's suggestion to 'connect the pieces of the text with the figure as well as the equations' is also a specific action to be taken. The reviewer's statement is precise and directly addresses a missing element.", "grounding_specificity_rationale": "The reviewer states that Figure 2(b) 'does not really show the schematic representation of the forwardprediction model'. This indicates that the authors have not specifically identified the relevant part of the paper being addressed. While the topic is the model, the specific element (Figure 2(b)) is not correctly identified as a schematic. The reviewer's statement implies that the authors need to make an educated guess about where the issue lies, rather than directly pointing to Figure 2(b).", "verifiability_rationale": "The reviewer states that the comment 'clearly specifies what needs to be addressed in this part' (referring to Figure 2(b)). However, the reviewer also notes that 'the connection between the text, figure, and equations is hard to connect'. This implies that while the *topic* of the issue is clear, the *specific details* and *how* the text, figure, and equations relate are not wellestablished. The reviewer's suggestion to 'redraw Figure 2(b)' and 'connect the pieces of the text with the figure as well as the equations' indicates a lack of sufficient justification or explanation. The reviewer's statement is somewhat clear but lacks key elements like examples or references.", "helpfulness_rationale": "The reviewer provides concrete and actionable suggestions: 'explain the forwardprediction model', 'redraw Figure 2(b)', and 'connect the pieces of the text with the figure as well as the equations'. These suggestions are directly aimed at improving the clarity and understanding of the model and its representation. The reviewer's statements are specific and provide clear directions for the authors to take. The reviewer's suggestions are directly tied to the identified issues and offer a clear path for improvement. The reviewer's statements are precise and directly address a missing element."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of training only on rewarded actions in the RBI framework. They suggest that the absence of supervision from rewardless actions, such as the feedback 'No, the answer is Timothy Dalton.' in Task 3, could be a significant factor contributing to the improved performance of FP+RBI over RBI alone. This is a clear and direct identification of a potential weakness in the baseline method.", "grounding_specificity_rationale": "The reviewer accurately identifies the 'RBI' framework as the specific part of the method being discussed. They further specify the issue as the lack of training on 'rewardless actions' that provide useful supervision. This precise identification of the methodological component and the nature of the missing information demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the potential impact of the missing rewardless supervision on the performance difference between FP+RBI and RBI. This claim could be verified by analyzing the performance of both methods with and without the feedback from rewardless actions, or by referencing existing literature on the importance of diverse training data in reinforcement learning. The claim is supported by logical reasoning and the potential impact on the results.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors to strengthen their baseline by including supervision from rewardless actions. This is a valuable and constructive comment that directly addresses a potential limitation of their current method. The suggestion is specific and points towards a relevant area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states two points: (1) the multiscale statement is misleading regarding physical time scales, and (2) the benefit of the slow RNN is reduced gradient path mitigation. These are direct statements of what the reviewer believes is incorrect or needs clarification. The reviewer also implies that the slow RNN's benefit is not fully explained, suggesting a lack of explicit action on physical time scales. Therefore, while the reviewer identifies potential areas for improvement, the actions are not fully explicit or concrete.", "grounding_specificity_rationale": "The reviewer refers to 'multiscale statement,' 'slow RNN,' and 'vanishing gradients,' which are specific technical terms within the context of RNNs and graphbased processing. They also explicitly state the benefit of the slow RNN in mitigating vanishing gradients. The reviewer clearly identifies the specific part of the paper (the multiscale statement) and the issue within that part (the potential confusion regarding time scales). This indicates strong grounding.", "verifiability_rationale": "The reviewer makes claims that can be verified. The claim about the 'logical time scale' can be supported by explaining how sequential stacking in a graph leads to a logical sequence of operations. The claim about the slow RNN's benefit can be supported by referencing the vanishing gradient problem. The reviewer provides clear reasoning and identifies a specific benefit, making the claims verifiable.", "helpfulness_rationale": "The reviewer provides a clear critique and identifies a potential point of confusion for the authors regarding the multiscale statement. They also highlight a specific benefit of the slow RNN. This feedback is directly actionable and addresses a potential misunderstanding. The reviewer's suggestions for improvement are clear and specific, making the feedback helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes 'baseline methods' generally and 'reinforcement learning' as a potential connection for the conclusion. It doesn't explicitly state what specific aspects of the baseline methods are weak or what concrete steps the authors should take to improve them. While it identifies a weakness, the action to address it is vague.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or method being addressed. It refers to 'baseline methods' broadly and 'reinforcement learning' as a potential connection without pinpointing a specific section, table, or figure. The grounding is weak because the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point makes claims such as 'baseline methods are weak' and 'there is no discussion of limitation' without providing specific evidence or justification. It doesn't reference external works or logical reasoning to support these claims. The claim is underspecified as it doesn't detail *why* the baselines are weak or *how* the lack of discussion of limitations is a problem.", "helpfulness_rationale": "The review point identifies potential weaknesses in the baselines and suggests a connection to reinforcement learning for the conclusion. However, it lacks specific guidance on how to address these weaknesses or implement the suggested connection. The feedback is general and lacks actionable steps for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks 'What is $e_l$?' in the context of Eq. (3), which is an explicit action asking for a definition. While the reviewer doesn't immediately follow up with the definition, the question itself is a clear instruction for the authors to clarify a specific aspect of their method. The second part of the review points out an implicit action related to Corollaries 1, 2 and 3 and Theorem 4, which is the observation that these results have an exponential dependence on the diameter $M$. The authors are implicitly asked to consider the implications of this dependence and how it might affect their results. While the action of identifying this issue is present, the reviewer doesn't explicitly suggest how to address it, making it somewhat implicit.", "grounding_specificity_rationale": "The review point mentions the diameter $M$ and its impact on the performance and constant factor. While it doesn't explicitly state the section or subsection where the definition of $e_l$ is (or isn't) located, it clearly refers to the corollaries and theorems mentioned. The reviewer also provides a brief description of the issue (exponential dependence). However, the reviewer doesn't provide a specific example of how this dependence manifests in their particular experiments or how it affects the constant factor in their case. The general impact is mentioned, but the specific location and detailed implications are not pinpointed.", "verifiability_rationale": "The review point contains claims. The first claim is 'What is $e_l$?' which is a question about a specific aspect of the paper. The second claim is about the exponential dependence of the corollaries and theorems on the diameter $M$ and its implications for the constant factor and performance. The reviewer provides a logical reasoning for the claim about the exponential dependence, stating that it affects the constant factor and leads to worse performance. While the reviewer doesn't provide specific external references to support this claim, the reasoning based on the theoretical results is logical and wellsupported by the information provided in the review point itself.", "helpfulness_rationale": "The review point is 5. The question about $e_l$ directly points the authors to a missing definition, which is a concrete action they can take. The observation about the exponential dependence on the diameter $M$ is a significant theoretical limitation that the authors should be aware of. This has the potential to impact the practical performance of their method, and the reviewer highlights this potential negative consequence. By pointing out this issue, the review provides valuable information about a potential weakness of the proposed approaches or theoretical results."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Partially Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a weakness ('poor longrange modelling ability of DGNs') and attributes it to a specific cause ('oversquashing and vanishing/exploding gradients'). It also mentions an alternative explanation ('oversmoothing'). While the point identifies potential causes, it doesn't explicitly state what the authors *should* do to address these issues. The suggestions are presented as possibilities rather than concrete actions.", "grounding_specificity_rationale": "The review point mentions 'DGNs' (Deep Graph Networks) and 'longrange modelling ability' and specifically names 'oversquashing and vanishing/exploding gradients' as a potential cause. It also mentions 'oversmoothing' as an alternative. While the point does identify the specific model and the aspect of performance being discussed, the connection between the identified causes and the weakness in longrange modeling isn't explicitly elaborated upon. The reviewer presents the causes as possibilities but doesn't deeply explain *how* these phenomena relate to the identified weakness.", "verifiability_rationale": "The review point makes a claim: 'the poor performance could also be due to oversmoothing'. This is a claim that requires justification. The reviewer names a specific paper as evidence ('Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning, In AAAU'18') to support this claim. The connection between oversmoothing and poor longrange modeling ability in DGNs is a logical inference based on the understanding of these phenomena.", "helpfulness_rationale": "The review point identifies a potential weakness in DGNs and offers a plausible alternative explanation ('oversmoothing') and cites relevant literature. While it doesn't provide a definitive solution, it raises a valid point about a potential cause and offers a relevant piece of information for the authors to consider. It helps the authors understand a potential limitation of their model."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a problem ('the problem formulation is somewhat unclear') but does not explicitly state the action the authors should take to address it. While the areas where the unclearness is located ('statement and introduction examples') can be inferred, the specific steps to improve the formulation are not provided. Therefore, it is not fully actionable, as the authors need to infer the necessary steps.", "grounding_specificity_rationale": "The comment mentions specific parts of the paper ('statement and introduction examples'), indicating a degree of grounding. However, it does not explicitly identify a *unique* element within those sections that is unclear. The comment is also somewhat vague in its description of the unclearness itself. Therefore, it is 2.", "verifiability_rationale": "The review point is a statement of observation ('The problem formulation is somewhat unclear in the statement and introduction examples.') and does not contain a claim that requires verification. There are no suggestions, judgments, or requests for changes. Therefore, it does not fit the criteria for verifiability.", "helpfulness_rationale": "The review point identifies a weakness in the paper ('the problem formulation is somewhat unclear') but does not provide any specific guidance on how to address it. The authors are left to figure out what needs to be done, which makes the review point somewhat incomplete in terms of providing actionable feedback. Therefore, it is 2 as it points out a problem but doesn't offer a solution."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states the action to be taken (conduct experiments) and provides specific models to use, making it 5.", "grounding_specificity_rationale": "The review point suggests exploring different LLM families but doesn't specify which part of the submitted paper needs improvement or which experiment to conduct. It's a general suggestion for future work.", "verifiability_rationale": "The review point is a suggestion for future work and doesn't contain a claim about the current paper's quality or shortcomings.", "helpfulness_rationale": "The review point offers a valuable direction for future research (exploring different LLM families). However, it doesn't directly pinpoint areas where the current paper *might* be lacking, so its immediate helpfulness to the author is limited. It's more of a suggestion for improvement than a direct critique or actionable fix for the current work."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'Let me know if this clarification helps!'. However, it does not provide concrete steps on how to implement this clarification or suggest specific changes to the draft. The action is implied rather than explicitly stated with details.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper it is referring to (e.g., a section, table, or figure). The reference to 'the curve finding method' and 'FGE' is general and does not point to a specific location in the paper. Therefore, the grounding is weak. The comment also does not specify what is wrong with the current understanding or how the alternative interpretation should be implemented. It lacks specificity in both grounding and the suggested improvement.", "verifiability_rationale": "The comment does not contain a claim that requires verification or justification. It is an interpretation and a suggestion for improvement, not a statement that needs to be supported by evidence. Therefore, it does not fall into the 'Claim Extraction' category. The comment is not verifiable because it doesn't present a statement that needs to be proven.", "helpfulness_rationale": "The comment identifies a potential misunderstanding between the reviewer's initial expectation of the 'curve finding' method and the actual implementation related to FGE. This is a valuable piece of feedback for the authors, as it highlights a point of confusion. The comment also suggests an alternative interpretation of the 'curve finding' method, which could be helpful for the authors to better understand the method's purpose. However, the comment lacks specific details on how to implement this clarification or the alternative interpretation. It doesn't provide concrete steps or examples, making it less helpful in terms of actionable improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the disagreement with the choice of baselines and provides a clear suggestion to include Concorde. It identifies the problem: the exclusion of a strong heuristic solver for singleobjective TSP and its potential impact on the interpretation of results given the observed Pareto front. The suggestion to include 'linear scalarization + Concorde' is a concrete action the authors can take.", "grounding_specificity_rationale": "The comment refers to the 'Pareto front' and 'linear scalarization' without explicitly naming the section or table where these are presented. While the concepts are related to the experimental results, the reviewer doesn't point to a specific location within the paper. The comment specifies *what* is potentially problematic (the nonconvex Pareto front and its implications for Concorde's performance) but doesn't pinpoint the exact location of the Pareto front within the paper.", "verifiability_rationale": "The comment contains a claim: 'However, for the single objective TSP, the SOTA heuristicsolver (e.g., Concorde) usually has the best performance.' The reviewer attempts to support this claim by stating that 'Since the obtained Pareto front is not highly nonconvex (as in Figure 2), the results for linear scalarization + Concorde should be included for a better comparison.' While the reviewer provides a logical argument, they do not explicitly cite a specific external reference to support the claim about Concorde's performance. The reasoning is present, but the direct evidence is missing.", "helpfulness_rationale": "The comment is highly relevant to the experimental setup and provides a clear and actionable suggestion for improvement. The reviewer identifies a potential flaw in the current comparison of learningbased solvers by the exclusion of a strong heuristic baseline (Concorde) for the singleobjective TSP. The suggestion to include 'linear scalarization + Concorde' is a concrete step the authors can take to address this issue and potentially obtain a more comprehensive evaluation of the proposed method. The logical argument connecting the observed Pareto front to the relevance of Concorde is wellarticulated."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point is not explicitly stating what the authors should do. It is a statement of observation that some general ideas are already present in other methods. While it implies a suggestion to ground the method in neuroscience, it doesn't directly instruct the authors on how to do this. The language is more about identifying a gap rather than providing a clear action.", "grounding_specificity_rationale": "The authors can confidently identify the specific part of the paper being addressed by mentioning 'general ideas' and naming specific methods like 'generalized Voronoi graph, semantic maps, pose graphs, curiositydriven exploration, graphbased SLAM'. However, the reviewer does not specify *how* these methods relate to or differ from the proposed method. The reference to the appendix makes it difficult to pinpoint the exact area of overlap or difference. Therefore, while the grounding is weak, the specificity of the grounding is lacking.", "verifiability_rationale": "The claim that 'some of the general ideas are already present in other methods for exploration' is verifiable as the reviewer names specific methods. However, the explanation provided is brief and lacks detailed justification or examples of how these methods relate to the proposed approach. The reference to the appendix further limits the clarity and depth of the verifiable claim.", "helpfulness_rationale": "The review point identifies a potential lack of novelty in the general ideas presented. While this is a valid observation, it does not provide specific, actionable feedback on how the authors should improve their draft. The suggestions are more about pointing out existing work rather than offering concrete steps for improvement. Therefore, the helpfulness is limited as it doesn't directly guide the authors towards better work."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the question about the granularity of quantization, identifying 'finer grouping', 'pertensor', and 'perchannel' as options. While it doesn't provide a specific action or solution, it clearly points to a specific area of methodological choice. Therefore, it is considered 3 as it identifies a concrete aspect of the method.", "grounding_specificity_rationale": "The comment explicitly mentions 'quantization' and the specific granularities 'finer grouping', 'pertensor', and 'perchannel'. This allows the authors to accurately identify the relevant part of the discussion. Therefore, it is considered fully grounded. While it doesn't specify a *solution*, it clearly pinpoints the area of confusion, making it somewhat specific.", "verifiability_rationale": "The comment is a question and does not contain a claim that requires verification. It's more of a request for justification or explanation. Therefore, it does not fit into the 'X' category for X and is not verifiable in the sense of supporting a claim.", "helpfulness_rationale": "The comment directly addresses a potential point of confusion for the authors regarding a method they might be considering (quantization granularity). By asking 'why not', it prompts for justification or explanation. While it doesn't offer a solution, it identifies a potential gap in the authors' understanding or the paper's explanation, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment suggests a *benefit* of exploring a different experimental setup (studying the impact of the ratio of unseen classes) but doesn't provide a concrete action for the author to take *now* to address their current work. It's a suggestion for future work, not a direct instruction for improvement.", "grounding_specificity_rationale": "The comment is general and doesn't point to any specific part of the paper or identify any specific issue within the paper. It's a broad suggestion about an experimental setup, not a targeted critique of a specific section or element.", "verifiability_rationale": "The review point is a suggestion, not a claim about the current work. It proposes a *potential* area for improvement (understanding the impact of the ratio of unseen classes) but doesn't make a judgment about the current work's quality or identify a specific problem that requires immediate attention. Therefore, it doesn't contain a claim that needs verification.", "helpfulness_rationale": "While the suggestion is relevant to the general area of research (understanding class imbalances), it lacks specific actionable steps for the author. It's a broad suggestion, which might be helpful for the author to explore but isn't a direct, immediate fix for their current work. Therefore, it's '3' as it points towards a relevant area, but not with concrete guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out two main issues: the lack of acknowledgment of the theory's inapplicability to the used model and the underestimation of GNNs' societal impact. While the reviewer doesn't explicitly state *what* the authors should do, they clearly indicate *where* the paper is lacking. This makes the actionable aspect somewhat implicit. For instance, the reviewer suggests the authors should acknowledge the limitations, and the authors could infer the need to discuss the societal impact of GNNs.", "grounding_specificity_rationale": "The reviewer mentions 'limitations' and 'societal impact' as areas for improvement. These are general concepts and do not specify a particular section, table, figure, or unique aspect of the paper. The reviewer could have pointed to a specific section where the limitations are discussed or provided a specific example of where the societal impact is unclear. However, the reviewer uses general terms, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer makes claims about the paper's limitations and the underestimation of GNNs' societal impact. They provide a reason for their claim ('I think the authors underestimate...') and suggest a general area for discussion ('potential negative societal impact of graph neural networks in general'). While the reasoning is present, it lacks specific examples or references, making the verifiability somewhat low. The reviewer doesn't provide concrete evidence to support their claims.", "helpfulness_rationale": "The reviewer identifies two distinct and significant shortcomings in the paper: the lack of discussion about the theory's applicability to the model and the underestimation of GNNs' societal impact. While the reviewer does not provide explicit instructions on how the authors should address these issues, they clearly highlight areas where the paper is incomplete or lacks context. This points towards concrete directions for improvement, making the review point helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3: 4", "verifiability_label": "3: UnderSpecific", "helpfulness_label": "4", "actionability_rationale": "The reviewer directly asks a question about a specific implementation detail ('For training we used an epsilongreedy ... What does this mean exactly? You have epsilongreedy exploration on top of the proposed strategy?'). This is a clear request for clarification, indicating an implicit action: the authors need to understand how epsilongreedy is implemented. The request is explicit about the location (before Appendix D.2) and the specific detail (epsilongreedy exploration).", "grounding_specificity_rationale": "The reviewer explicitly mentions the section of the paper ('before Appendix D.2') where this information is likely to be found. They also specify the exact implementation detail ('epsilongreedy ... What does this mean exactly?'). This indicates a high level of specificity in identifying the relevant part of the paper and the issue within it.", "verifiability_rationale": "The reviewer's question indicates a lack of clarity regarding the implementation of epsilongreedy. They are asking for a definition or explanation, suggesting the information is either missing or not wellexplained in the original paper. While the request itself is a form of verifiability check, the lack of a clear answer makes it somewhat underspecific as the authors need to go beyond the request to find the information.", "helpfulness_rationale": "The reviewer's question directly targets a practical implementation detail. They are asking for clarification on a specific aspect of the training process. This is a valid and likely to be helpful request for the authors, as understanding the implementation of epsilongreedy is crucial for replicating and building upon the work."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer states their opinion about the discussion section's clarity and importance. While they don't explicitly state what is missing, the phrasing suggests a lack of clarity. The suggestion to be more explicit about the 'vital part' implies a desire for more concrete guidance. However, the reviewer doesn't pinpoint a specific action or detail that needs to be addressed, making it less explicit than a suggestion about a specific figure or table.", "grounding_specificity_rationale": "The reviewer refers to 'the framework,' 'CLIP,' 'weakly supervised learning,' and 'discussion section,' providing some grounding. They also explain *why* they think the discussion is vital (distinguishing from related work), which adds to the specificity. However, they don't pinpoint a specific part within the discussion that is unclear or needs to be elaborated on.", "verifiability_rationale": "The reviewer makes a claim about the discussion section lacking clarity and its importance in distinguishing the work from related work. They provide a reason for this claim, suggesting a logical reasoning behind it. However, they don't provide specific examples or references to external works to support their claim.", "helpfulness_rationale": "The reviewer points out a lack of clarity in the discussion section, which directly addresses a potential weakness for the authors in understanding the paper's contribution and differentiating it from related work. Their suggestion to make the discussion clearer and more explicit about the vital part of the framework is a constructive and actionable suggestion for the authors. The reviewer's point directly helps the authors improve their understanding of the paper's contribution and its relation to existing work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that the findings might restrict implications, which is an action. They also imply a limitation by focusing on bitserial accelerators. The specificity of 'bitparallel fixedpoint numbers' makes the action quite clear.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'bitparallel fixedpoint numbers' and explains its relevance to the limitations of the methodology in the context of existing ML accelerators. This is a clear identification and explanation of the issue.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the methodology but doesn't provide any specific examples, references, or logical reasoning to support this claim.", "helpfulness_rationale": "The reviewer identifies a potential limitation, which is generally helpful as it provides a balanced perspective. However, the lack of specific details and supporting evidence makes the impact of the review point limited. It doesn't offer a constructive suggestion or a clear path forward."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issues with the paper's claims and the proposed method, making the action clear and direct. The reviewer also identifies specific areas (vit quantification, MHSA quantization, variance difference, precision loss), making the action specific. The reviewer suggests improvements by pointing out flaws in the paper's own arguments and the proposed method, which are actionable steps for the authors to consider.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific parts of the paper being discussed. For example, they refer to 'vit quantification' and mention 'Line 45', 'Fig1(b)', and 'Fig5(b)' for specific numerical comparisons. They also refer to 'MHSA quantization' and draw a parallel to 'transformer quantization' and cite examples from other domains. This demonstrates a strong grounding of the specific aspect being addressed.", "verifiability_rationale": "(a) The reviewer provides specific numerical examples (variance differences) to support their claim that the paper's argument about direct quantization causing distortion isn't convincing and the proposed method doesn't improve upon it. This provides logical reasoning and concrete evidence. (b) The reviewer points to the cited literature on NLP quantization, providing external references to support their claim that the variance difference isn't significant and the criticism about precision loss isn't unique to the ViT model. This provides external references and logical connections to existing work.", "helpfulness_rationale": "(a) The reviewer's point about the paper's argument and the proposed method is 3 as it highlights areas where the authors might be overlooking or misinterpreting existing work and the limitations of their approach. (b) The reviewer's point about the lack of novelty in the precision loss issue is also 3 as it directs the authors to consider existing solutions in other domains and avoid redundant work. While not directly suggesting a new method, it guides the authors towards a more informed approach."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the similarity of the proposed method to STNs and the lack of comparison. It also mentions existing works that use STNs locally, providing a clear action for the authors to take: acknowledge the similarity and include a comparison.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper being addressed. While it mentions 'this work' generally, it doesn't point to a specific section, table, or figure. Therefore, the grounding is weak.", "verifiability_rationale": "The comment contains a claim (the weakness in technical novelty and missing comparison) and provides some justification by mentioning existing works using STNs locally. This justification, while not exhaustive, supports the claim to a certain degree.", "helpfulness_rationale": "The comment clearly identifies a weakness and provides a general suggestion for improvement (acknowledging similarity and including comparison). While it lacks specific details on how to achieve this, it offers a clear direction for the authors to follow, making it helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "Both points are implicitly suggesting improvements. L384 points out a missing detail in notation, and L431 suggests a correction to a potential notational inconsistency. While the suggestions are clear, they require the authors to infer the intended meaning or action, making them 2.", "grounding_specificity_rationale": "Both points are fully grounded. L384 explicitly mentions the notation and the probabilistic statement, and L431 refers to the specific notations \u03bc_t and \u0303\u03b5_t without needing to infer their location.", "verifiability_rationale": "Both points contain claims that can be supported. L384's claim about the notation being ambiguous can be supported by pointing to the probabilistic statement. L431's claim about the notational inconsistency can be supported by explaining the potential difference between \u03bc_t and \u0303\u03b5_t.", "helpfulness_rationale": "Both points are 5. L384's suggestion to mention the probabilistic statement directly improves the clarity of the paper. L431's suggestion to correct the notational inconsistency is a significant improvement that avoids potential confusion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the incorrect figure number ('Fig.7' should be 'Fig.12') and provides a specific location within the supplementary material (line 821, page 31). This is an explicit action that the authors can directly address by correcting the figure reference. Furthermore, the reviewer suggests a concrete improvement by linking each theorem and corollary to its proof, which is a clear action item. The specificity of the figure number and the suggestion for linked proofs make this an actionable comment.", "grounding_specificity_rationale": "The reviewer provides a precise location within the supplementary material (line 821, page 31) where the error ('Fig.7') is found. This allows the authors to confidently identify the referenced section. Additionally, the reviewer suggests a specific improvement (linking each theorem and corollary to its proof) directly related to the content being discussed (theorems and corollaries). This level of detail in both identifying the issue and suggesting a solution makes the grounding highly specific.", "verifiability_rationale": "The reviewer makes a claim by pointing out a factual error ('Fig.7' should be 'Fig.12') and suggesting an improvement (linking proofs). This claim is verifiable through direct inspection of the supplementary material at the specified location (line 821, page 31). The suggestion to link proofs is also a verifiable action that the authors can take to improve the paper's organization and accessibility. The reviewer provides sufficient information for the authors to either correct the error or implement the suggested improvement.", "helpfulness_rationale": "The review point directly identifies a specific error ('Fig.7' should be 'Fig.12') and provides a clear, actionable suggestion to improve the paper's structure by linking theorem and corollary proofs. These are concrete and directly address potential issues the authors might be facing with the supplementary material. The reviewer's feedback is not just general; it points to a specific location and a specific way to enhance the paper's clarity and accessibility, making it 5 for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a potential limitation of the feature selection framework (Sec. 4.2) and suggests a specific improvement by considering representation learning. The suggestion is clear and directly points to a direction for the authors to take. While the suggestion is broad, it is actionable in the sense that it provides a concrete goal for the authors to work towards.", "grounding_specificity_rationale": "The reviewer mentions 'the proposed invariant learning module' and 'Section 4.2' in the review, but the criticism itself focuses on the general framework of feature selection and the suggestion to consider representation learning. While the module is mentioned, the criticism doesn't pinpoint a specific subsection, table, or figure within the paper. The reviewer is discussing the framework at a higher level. Therefore, the grounding is weak as the authors would need to infer the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer presents a criticism about the feature selection framework without providing any external references or detailed reasoning within the review point itself. The criticism is presented as a statement of opinion or a suggestion for improvement, lacking any justification or evidence. Therefore, the claim is not verifiable based on the information provided in the review point.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the proposed method (feature selection framework) and provides a specific suggestion for improvement (considering representation learning). This directly guides the authors towards a potential enhancement. The criticism is not just a critique but also a constructive suggestion, making it 5 for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X (X)", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a gap in information (missing details on reward design) but does not explicitly state how to address this gap or provide concrete steps for the authors to take. It points out a problem but lacks a direct solution or action.", "grounding_specificity_rationale": "The comment mentions 'how to design the rewards is not fully understandable' but does not explicitly identify a specific section, table, figure, or unique aspect of the paper where this information is lacking. The reference to 'rewards' is somewhat general.", "verifiability_rationale": "The comment does not make a claim that requires verification. It is a statement of a missing detail rather than a definitive assertion about the paper.", "helpfulness_rationale": "The comment identifies a weakness in the draft (missing details on reward design) but does not offer any suggestions or guidance on how to improve the draft based on this weakness. It points out a problem but does not provide a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out that the work is an 'incremental improvement' and has 'little novelty'. While this implies an actionable point \u2013 that the authors should consider more novel approaches \u2013 it doesn't explicitly state *how* to make this improvement or provide concrete steps. The reviewer's statement is clear about the nature of the contribution but lacks specific guidance on actionable changes.", "grounding_specificity_rationale": "The reviewer mentions the 'incremental improvement' and 'little novelty' but doesn't specify *which* part of the paper or method this improvement is related to. They don't point to a specific section, table, or figure. The weakness is implied but 1 in a specific location within the paper.", "verifiability_rationale": "The reviewer makes a judgment about the work being an 'incremental improvement' and having 'little novelty'. This constitutes a claim. However, they don't provide any evidence, reasoning, or external references to support this claim. The statement is presented as an opinion without backing.", "helpfulness_rationale": "The reviewer expresses a degree of dissatisfaction with the work, framing it as an incremental improvement with limited novelty. While they identify a potential area for improvement, the overall tone is somewhat negative and nitpicking. The feedback is presented as a critique rather than a constructive suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors should discuss the runtime of Prithvi WxC and its implications for computational cheapness as a selling point for MLbased emulators. This directly points to an action the authors should take.", "grounding_specificity_rationale": "The review point explicitly mentions 'Prithvi WxC' and its 'runtime' and 'large parameter count'. This clearly identifies the specific aspect of the paper being addressed, making it fully grounded. It also specifies what needs to be addressed (discussing the runtime).", "verifiability_rationale": "The review point makes a claim about the importance of discussing runtime for MLbased emulators, especially given the large parameter count of Prithvi WxC. It provides a logical connection between the parameter count and the need for runtime discussion, making the claim verifiable. While it doesn't provide specific examples or citations, the reasoning is clear and logical.", "helpfulness_rationale": "The review point directly addresses a potential weakness (high computational cost/runtime) and suggests a concrete improvement (discussing the runtime). It provides a clear reason *why* this is important in the context of MLbased emulators. The suggestions are actionable for the authors."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "1 (1 and Not Specific)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The review point states, \"The framing of the paper seems to oversell the method in a way that makes the contribution less clear.\" This statement identifies a potential issue (\"oversell the method\") and its consequence (\"contribution less clear\"). However, it doesn't specify *how* to fix it. It's a potential problem, not a clear action.", "grounding_specificity_rationale": "The comment refers to the \"framing of the paper\" and the \"method\" in general. It doesn't specify a particular section, table, figure, or a precise aspect of the method. The issue is perceived to be at a higher level.", "verifiability_rationale": "The review point is a statement of opinion or interpretation ('seems to oversell\"). It doesn't present a claim that can be verified with evidence from the paper. It's a subjective assessment, not a verifiable claim.", "helpfulness_rationale": "The review point identifies a potential issue with the paper's presentation. While it doesn't offer a specific solution, it points to a problem that could hinder understanding or impact the perceived contribution. Even without a concrete solution, identifying a problem is helpful feedback."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states two concrete actions: 'presenting such process in separate steps' and 'too many symbols and a notation table could be better'. These actions are directly actionable for the authors to improve their model description.", "grounding_specificity_rationale": "The reviewer refers to 'the model description' in general, which is a broad area. While the suggestions are relevant to this area, the review point does not specify a particular section, table, figure, or unique element within the model description where the issue lies. The suggestions are general to the overall description.", "verifiability_rationale": "The review point makes a claim by stating 'e.g., the generative process is in detail but presenting such process in separate steps should be better for understanding, too many symbols and a notation table could be better.' This is a suggestion for improvement. While the reviewer doesn't provide specific examples or references to support this claim, the suggestion itself is a verifiable action that the authors can take. The 'should be better' is a subjective opinion, but it still constitutes a claim that can be verified by attempting the suggested changes or providing evidence.", "helpfulness_rationale": "The review point provides two specific suggestions: improving the presentation of the generative process and suggesting a notation table. These suggestions are directly actionable and address specific aspects of clarity and organization within the model description. The reviewer is pointing out concrete areas where the authors can make improvements, making the feedback very practical and useful."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests 'further verify the effectiveness and universality to nonLLMbased models'. This is an implicit action. The authors would need to infer the action of testing the framework on models like HiTeA and InternVideo.", "grounding_specificity_rationale": "The reviewer explicitly states 'the FlippedQA framework is a general framework for various generative VideoQA models. However, the authors only apply this framework to LLMbased models. It would be better to further verify the effectiveness and universality to nonLLMbased models like HiTeA and InternVideo.' This clearly grounds the discussion in the authors' work and specifies the focus on LLMs and suggests specific nonLLM models.", "verifiability_rationale": "The reviewer makes a claim about the framework's generality but doesn't provide any evidence or references within the review point itself. While the reviewer provides a clear statement, there's no explicit justification or references provided within this review point.", "helpfulness_rationale": "The reviewer directly suggests an improvement for the authors. 'further verify the effectiveness and universality to nonLLMbased models'. This is a clear suggestion for the authors to improve their draft by expanding the evaluation of the FlippedQA framework."}
{"actionability_label": "1", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that 'the writing could be improved' and 'it took me quite a lot of effort to go back and forth to understand the main idea and the theoretical analysis of the paper.' While the reviewer identifies a problem, they do not provide specific actions or concrete suggestions for improvement. The phrases used are general and do not point to a particular aspect of the paper that needs to be changed. Therefore, the review lacks explicit and actionable feedback.", "grounding_specificity_rationale": "The reviewer mentions 'the main idea' and 'the theoretical analysis of the paper.' While they identify the areas where they struggled, they do not specify a particular section, table, figure, or unique aspect within these broad areas. The reviewer's comment is at a high level and lacks the precision needed to pinpoint the exact location of the issue. Therefore, the grounding of the comment is weak.", "verifiability_rationale": "The reviewer states that 'it took me quite a lot of effort to go back and forth to understand the main idea and the theoretical analysis of the paper.' This statement describes the reviewer's experience but does not provide any evidence or reasoning to support the claim that the writing is indeed difficult to understand. The reviewer expresses a problem but does not offer any logical justification or references to back up their assertion. Therefore, the claim is not wellsupported.", "helpfulness_rationale": "The review points out that 'the writing could be improved' and that it 'took me quite a lot of effort to go back and forth to understand the main idea and the theoretical analysis of the paper.' While the reviewer identifies a problem with the writing, they do not offer any specific suggestions or actions to address these issues. The comment is essentially a statement of a problem without providing any constructive or actionable feedback. Therefore, the review is not particularly helpful in guiding the authors towards improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the proposed method 'primarily builds upon a combination of existing methods...'. This is an explicit statement of what the method does. However, the reviewer does not specify the exact nature of this combination or how the existing methods are being integrated. The action is stated, but it is implicit and lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer names specific methods used in the proposed approach: 'ClopperPearson intervals' and 'Gaussian elimination'. This clearly indicates that the reviewer has identified the specific parts of the paper being addressed. While the reviewer does not explain *how* these methods are being used or combined, the identification of these methods is explicit and points to a specific area of the paper. Therefore, the grounding is strong regarding the *what* of the method.", "verifiability_rationale": "The reviewer states a claim: 'I am willing to improve my score, if the authors can well address these concerns.' This is a clear statement of intent based on the authors' response. The claim is verifiable because it is a statement that can be assessed for evidence. The authors' ability to address the concerns is the evidence, and the claim is directly stated.", "helpfulness_rationale": "The reviewer states a negative assessment of the proposed method: 'I am willing to improve my score, if the authors can well address these concerns.' While the reviewer expresses a willingness to improve their score, the initial statement about the lack of theoretical novelty is a direct critique of the paper's contribution. The reviewer's willingness to improve is a potential action, but the initial statement about the lack of theoretical novelty is a direct critique of the paper's content."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem (cumbersome phrasing) and provides a clear action (clarify the sentence). The suggestion to rewrite the sentence is also concrete, indicating exactly what needs to be done. The reviewer's intention is very clear and actionable.", "grounding_specificity_rationale": "The reviewer directly names the specific part of the paper (the sentence in lines 1217) and clearly identifies the issue (cumbersome phrasing) within that part. This demonstrates full grounding as the paper section is explicitly mentioned. The specificity is high as the problem and the proposed solution are both clearly defined within that section.", "verifiability_rationale": "The reviewer's suggestion to clarify the sentence is based on the general principle of clarity in writing, which is a widely accepted practice. While the reviewer doesn't provide a specific citation in this abstract point, the logical reasoning behind the suggestion is sound. The suggestion is to rewrite the sentence, which is a concrete action that can be implemented.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion (rewrite the sentence) and identifies a specific location in the paper (the abstract) where this issue occurs. This directly addresses a potential problem for the authors and provides a concrete step they can take. The suggestion is directly relevant to improving the draft."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "3 (Weakly Grounded and UnderSpecific)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer explicitly states that the proposed approach does not outperform or is even worse than Decouple Kang et al. for the overall performance. This is a clear indication of an explicit action. However, the reviewer does not specify *how* the proposed approach underperforms or *why* it is worse. The lack of concrete details makes it difficult to understand the specific issues and how to improve the proposed method. Therefore, while the information is present, the lack of specificity makes it less actionable.", "grounding_specificity_rationale": "The reviewer mentions 'Decouple Kang et al.' and 'hyperparameters' in the context of the baselines. While they mention a specific paper and a general concept, they do not explicitly identify the specific section, table, figure, or unique aspect of their own method or the baseline that is being compared. The mention of 'hyperparameters' is also general and doesn't pinpoint a specific instance. Therefore, the grounding is weak. Furthermore, while the reviewer points out a potential improvement for the baselines, they do not specify *what* needs to be done to achieve this improvement. The connection to the proposed method's limitations is implied but not explicitly stated. This makes the specificity underspecific.", "verifiability_rationale": "The reviewer states that '3) shows that the proposed approach does not outperform or is even worse than Decouple Kang et al. for the overall performance.' This is a clear claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. They simply state the observation without explaining *why* it is true or providing evidence. Therefore, the claim is 1.", "helpfulness_rationale": "The reviewer's comments highlight a key weakness in the proposed approach (lack of clear improvement over a strong baseline) and a potential area for improvement in the baselines (similar tradeoff with hyperparameters). While these points are valuable for guiding future research, they do not provide immediate actionable feedback on how to improve the *current* proposed method. Therefore, the helpfulness is somewhat limited."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'relying on 4 OCR QA datasets' and 'More scenarios like the LLaVA benchmark would be expected.' These are clear statements identifying limitations in the evaluation approach. While the reviewer doesn't directly recommend an action, the suggestion to 'include more scenarios like the LLaVA benchmark' implies a desire to address the identified limitation. The reviewer also points out that the authors 'admit in Fig 4(5), this evaluation may be unreliable,' which is an explicit acknowledgement of the limitation and a suggestion for improvement.", "grounding_specificity_rationale": "The reviewer mentions '4 OCR QA datasets' and 'LLaVA benchmark' in the context of 'more scenarios would be expected.' While the reviewer doesn't explicitly state 'Section 4.2' or 'Table 3,' the mention of specific datasets and benchmarks strongly implies they are referring to specific parts of the paper. The reviewer also specifies 'ablation studies' as a type of scenario that is lacking. This indicates a degree of specificity in identifying the areas for improvement.", "verifiability_rationale": "The reviewer states 'As the authors admit in Fig 4(5), this evaluation may be unreliable.' This is a claim about the potential limitations of the evaluation methodology. The reviewer directly quotes the authors' admission ('Fig 4(5)') to support this claim. This provides a clear and logical justification for the statement.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement: 'More scenarios like the LLaVA benchmark would be expected, especially in ablation studies.' This directly addresses a limitation identified in the evaluation methodology. The reviewer's suggestion is specific and directly related to the identified weakness. The reviewer also points out a potential unreliability in the evaluation, which is a valid concern for researchers."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that they have 'a lot of problems' with abstract visual reasoning tasks and explicitly asks for 'proof' that the current formulation is necessary. While the reviewer identifies a problem, the action of seeking proof is relatively clear. The reviewer *identifies* the area of difficulty and *states* the need for proof. However, the level of detail on how to apply this 'proof' is vague.", "grounding_specificity_rationale": "The reviewer refers to 'abstract visual reasoning tasks' and 'this formulation in the paper.' While the reviewer identifies the *type* of task and the *general* area of the paper, they do not explicitly point to a specific section, table, or figure. The grounding is to a broader concept rather than a precise element. The reviewer *mentions* the area but doesn't specify a unique aspect within the paper.", "verifiability_rationale": "The reviewer makes a claim by stating they have 'a lot of problems' with the tasks and 'have a lot of trouble solving them.' They also suggest seeking 'proof' and ask a question about simpler formulations. This constitutes a claim. The reviewer *identifies* an area where further investigation is needed but doesn't provide immediate evidence or references. The suggestion to seek proof and the question about simpler formulations indicate a lack of immediate verifiability.", "helpfulness_rationale": "The reviewer explicitly states their difficulty with abstract visual reasoning tasks and requests evidence to support the current formulation. This demonstrates a clear identification of a problem and a desire for improvement. While the reviewer doesn't immediately provide solutions or concrete steps, the feedback is focused on a specific area of weakness and offers a clear direction for future work. The reviewer's statement of having 'a lot of problems' and the request for 'proof' indicate a desire for actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states concrete actions: \"Weak supervision could be better evaluated\" and \"The generation of authors is also not realistic\". These are clear suggestions for improvement that authors can readily implement.", "grounding_specificity_rationale": "The review point mentions \"weak supervision\" and \"the generation of authors\". While it hints at the area, it doesn't explicitly point to a specific section, table, figure, or unique element in the paper. The reviewer is addressing issues related to the methodology described in the paper, but without pinpointing a specific element. It's implied, but not explicitly stated.", "verifiability_rationale": "The review point makes a claim: \"Weak supervision could be better evaluated\" and \"The generation of authors is also not realistic.\" However, it doesn't provide sufficient justification or evidence for these claims. The *why* is missing. We don't know *how* the evaluation is unrealistic or *why* the averaging method is considered unrealistic.", "helpfulness_rationale": "The review point identifies specific areas for improvement in the evaluation methodology and the author generation process. It points to concrete shortcomings. By highlighting the lack of realism in the evaluation and the simplistic author generation method, the reviewer provides actionable feedback that could guide further development. It doesn't simply point out a problem but suggests ways to make the evaluation and generation more robust."}
{"actionability_label": "3", "grounding_specificity_label": "1: 2", "verifiability_label": "1", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The review point identifies a potential weakness ('lack of essential visualization') but doesn't explicitly state what should be done. While it implies a need for improvement, it lacks specific actionable steps. The vagueness of 'essential visualization' and 'intermediate processes' makes it difficult to pinpoint exactly what needs to be added or improved.", "grounding_specificity_rationale": "The review point doesn't explicitly identify a specific part of the paper or methodology that lacks visualization. The phrase 'lack of essential visualization' is general and doesn't point to a particular section, table, or figure. Therefore, the grounding is weak.", "verifiability_rationale": "The review point states a problem ('lack of essential visualization') but doesn't provide any evidence or justification for why this is a problem or how it impacts the paper. It's a statement of a potential issue without a claim or suggestion for improvement.", "helpfulness_rationale": "The review point identifies a potential area for improvement but doesn't offer any concrete suggestions or actionable steps for the authors. It's a negative statement about the current state of the paper without providing a positive alternative or guidance on how to address the issue."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "X", "grounding_specificity_label": "X", "verifiability_label": "X", "helpfulness_label": "X", "actionability_rationale": "The reviewer is posing a question about the definition of 'discourse' used in the authors' work, which does not imply an action or request for information within the paper.", "grounding_specificity_rationale": "The reviewer is asking about the authors' definition of 'discourse,' which is a question about terminology and scope, not a direct reference to a specific part of the paper.", "verifiability_rationale": "The reviewer is posing a question, not making a claim that requires verification.", "helpfulness_rationale": "The reviewer is asking a question that could be helpful for clarification for the authors, but it does not directly provide actionable feedback on how to improve the draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a direction for improvement (higher output quality) but doesn't specify how to achieve it. The phrase 'there\u2019s still much room for improvement' is a general statement, not a concrete action the authors should take.", "grounding_specificity_rationale": "The review point refers to 'Recent GAN works' and 'amazing quality in synthesized results' in a general way. It doesn't pinpoint a specific section, table, figure, or unique aspect of the paper being criticized. The reference to 'output quality' is also broad.", "verifiability_rationale": "The review point contains the claim 'Output quality is reasonable, but still far from realistic' and provides supporting evidence by mentioning the advancements in GANs with 'Recent GAN works have shown amazing quality in synthesized results'.", "helpfulness_rationale": "The review point is helpful in identifying a key limitation (output quality) and providing context for the authors' work. It suggests a direction for improvement ('there\u2019s still much room for improvement') and offers a justification for rejection based on novelty, resolution, and hardware requirements."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue with the 'soft labels' implementation and its impact on the performance metrics (CRM and Crossentropy). While they identify the area of concern, they don't explicitly state what action the authors should take or how to implement a fix. The mention of 'subpar hyperparameters' is vague and doesn't provide a concrete step for the authors to adjust them. Therefore, while the reviewer identifies a problem, they don't offer specific, actionable steps for the authors to address it.", "grounding_specificity_rationale": "The reviewer mentions 'soft labels,' 'CRM,' 'Crossentropy,' 'iNaturalist19,' and 'beta value.' While they identify these terms, they don't explicitly pinpoint the exact location or type of error within the code or experimental setup. The mention of 'subpar hyperparameters' is also vague. The reviewer doesn't provide a specific section or table number where the issue is located. While they understand the concepts, they don't provide enough detail to fully ground the comment.", "verifiability_rationale": "The reviewer expresses a concern about the results and the potential impact of hyperparameters on the performance metrics. They state a doubt about the 'impressiveness' of the results and suggest investigating 'subpar hyperparameters.' However, they don't provide any evidence, justification, or reasoning to support their concern. The statement is presented as a question or doubt rather than a claim supported by logical reasoning or external references. Therefore, the claim is not verifiable based on the provided information.", "helpfulness_rationale": "The reviewer clearly states a concern about the results and suggests investigating the 'subpar hyperparameters.' This is a constructive critique, pointing out a potential issue that could indeed be helpful for the authors. They are not simply stating a fact; they are raising a question and suggesting an investigation, which can lead to improvements. While they don't offer a solution, they identify a problem that needs attention."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the concern about the dataset size and links it to the 'texting' aspect, indicating a clear action to investigate.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'VioT dataset' and the specific numbers of images and categories, and they also specify the concern regarding the impact on the 'texting' (testing) of the approach, making it 5.", "verifiability_rationale": "The reviewer states a claim about the dataset size but provides no supporting evidence or justification.", "helpfulness_rationale": "The reviewer identifies a potential issue with the dataset size but doesn't offer a direct solution or recommendation, making it 3 as it points to a problem area."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment is a suggestion for future research (an ablation study) rather than a direct instruction on how to improve the current draft. It proposes a potential experiment but doesn't specify how to implement it or what changes to make to the current work.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper or the author's work. The author has to infer that the suggestion relates to the model architecture (layers) and performance (evaluation). This inference is necessary, but the comment doesn't pinpoint a specific section or detail.", "verifiability_rationale": "The comment is a suggestion, not a claim or assertion about the current work. It doesn't make any judgments about the current draft or propose changes that can be verified with evidence from the paper itself.", "helpfulness_rationale": "The comment suggests an interesting experiment, which could be valuable for the author's research in the future. However, it doesn't directly provide actionable steps or insights on how to improve the current draft. It's a suggestion for future exploration, not a direct improvement strategy."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question ('how sensitive are the empirical results to hyperparameter choices') and expresses a concern ('This second point is especially crucial since wrong choices can conceivably wipe out whatever improvement is gained from this method'). However, it does not explicitly state what action the authors should take to address this issue. It lacks a direct instruction or suggestion for improvement. The authors are left to wonder what specific steps they should undertake to mitigate this sensitivity.", "grounding_specificity_rationale": "The review point refers to 'hyperparameter choices' generally, without specifying which particular hyperparameters are being discussed or which section of the paper this relates to. It does not provide a clear target for improvement by naming a specific part of the paper (e.g., 'Section 3.2', 'Table 4'). The mention of 'this second point' is vague and does not pinpoint a specific element within the paper.", "verifiability_rationale": "The review point does not make a claim that requires verification. It is a statement of concern and a request for clarification ('I will be willing to reconsider my rating if this particular issue is resolved'). While it identifies a potential problem, it does not offer a solution or propose a specific action that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The review point raises a valid concern about the robustness of the empirical results to hyperparameter choices. This is a relevant issue for the authors to consider. However, it does not provide concrete suggestions or guidance on how to address this concern. It lacks actionable steps or specific recommendations for the authors to take. The reviewer's willingness to reconsider the rating after addressing this issue suggests the feedback is perceived as needing more concrete improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the issue: 'This work utilizes existing attack methods on a surrogate model. It is similar to use the transferability of adversarial examples directly.' This directly points to a need for the authors to clarify the novelty of their approach. While it doesn't explicitly state 'imply a need for clarification,' the phrasing strongly suggests it. Therefore, it can be considered explicit.", "grounding_specificity_rationale": "The review point explicitly mentions 'existing attack methods,' 'surrogate model,' and 'transferability of adversarial examples.' This allows the authors to identify the specific aspects of their work being criticized. The mention of 'similar to' also specifies the nature of the similarity being questioned. Therefore, it can be considered 5.", "verifiability_rationale": "The review point makes a claim about the similarity of the proposed method to existing techniques. While it doesn't provide a citation or detailed explanation, the logical connection between transferability of adversarial examples and the use of surrogate models is generally understood in the field. Therefore, it can be considered verifiable based on common knowledge and logical reasoning.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper's novelty and contribution by highlighting the similarity to existing methods. It provides a clear direction for the authors to improve their work by emphasizing the need to clearly articulate their novel contributions. While it doesn't demand a specific solution, it points to a crucial area for clarification and improvement. Therefore, it can be considered 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a formatting issue (text size) and a specific technical error (missing gradient symbol) in Algorithm 1. While the text size issue is vague in terms of action, the algorithm issue is concrete. However, the actions are not fully detailed, making it 3.", "grounding_specificity_rationale": "The reviewer mentions \"table 1\" for the text size issue, which is weakly grounded as it doesn't pinpoint the exact section or table. They explicitly mention \"Algorithm 1\" and \"line 4\" for the gradient symbol issue, which is fully grounded. However, the specificity for the gradient symbol issue is limited to identifying the *location* of the problem, not the *nature* or *consequences*.", "verifiability_rationale": "The reviewer points out a problem in the algorithm but doesn't provide any justification or evidence for why the gradient symbol is missing or why this is a significant issue. It's a claim without supporting reasoning or references.", "helpfulness_rationale": "The reviewer identifies weaknesses in the paper's presentation and a technical detail in the algorithm. However, they don't offer specific, actionable, or constructive suggestions for improvement. The feedback is diagnostic but lacks prescriptive value."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue: 'It is unclear whether their proposed methods can be made practically useful for high dimensions.' This clearly identifies a problem and suggests a direction for improvement. The action is to investigate the practical limitations in high dimensions.", "grounding_specificity_rationale": "The reviewer mentions 'computational aspects' and 'high dimensions' as areas of concern. While they identify a general area, they do not pinpoint the exact section, table, figure, or unique element of the paper being addressed. The mention of 'LPs' is a general reference to linear programming, not a specific citation or reference within the paper itself.", "verifiability_rationale": "The reviewer points out a discrepancy between the theoretical requirements of the algorithm (solving several LPs in high dimensions) and the experimental setup (all performed on very small scale datasets). This highlights a lack of verifiable connection between the theoretical claims and the empirical evidence. The reviewer's point is a hypothesis based on the stated requirements, and the authors haven't provided any evidence to refute this point. The verifiable information is the stated requirement of solving LPs in high dimensions, but the supporting evidence (experiments on small datasets) is insufficient to verify this requirement's feasibility.", "helpfulness_rationale": "The reviewer's point is relevant to the authors and directly addresses a potential limitation of their work. They highlight a gap between the theoretical computational requirements and the practical applicability demonstrated in the experiments. This feedback is valuable for guiding future research and improving the practical utility of the proposed methods. While it doesn't offer a specific solution, it points to a crucial area for further investigation."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about a specific implementation detail (parameter sharing) and suggests a concrete experiment to investigate it. This directly points to a potential issue or area for improvement, making it actionable. The suggestion to compare against a deeper ResNet with parameter sharing provides a clear next step for the authors.", "grounding_specificity_rationale": "The reviewer directly references 'section 7.1' and specifically asks about 'parameter sharing in the ResNet'. This provides a precise location and a very specific aspect of the paper being addressed, indicating strong grounding. The suggestion of a baseline experiment further enhances the specificity by detailing what kind of comparison would be beneficial.", "verifiability_rationale": "The reviewer's suggestion to compare against a deeper ResNet with parameter sharing is a logical and verifiable suggestion. It provides a concrete baseline to test the impact of parameter sharing. The connection to ODE networks, while requiring some background knowledge, is a reasonable and verifiable extension of the concept of residual connections, suggesting a deeper understanding of the paper's contribution.", "helpfulness_rationale": "The review point is 5 as it directly addresses a specific implementation detail and suggests a relevant and actionable experiment. The connection to ODE networks provides valuable context and potential for further research. This feedback is not just about pointing out a problem but about suggesting a concrete next step and a way to understand the work better."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the crossencoder architecture is not 'ignoring crossentity comparison', directly pointing out an inaccuracy in the paper's description. This provides a clear action for the authors to correct their understanding or implementation.", "grounding_specificity_rationale": "The reviewer directly identifies the section of the paper where the incorrect statement about the crossencoder is made ('The crossencoder architecture is not \"ignoring crossentity comparison\"'). This allows the authors to precisely locate the relevant information.", "verifiability_rationale": "While the reviewer doesn't provide a citation to support the claim that crossencoders attend to all candidates at once, this principle is generally understood in the field. The reviewer's point, while not definitively proven here, is based on common knowledge about how crossencoders operate, making it 3.", "helpfulness_rationale": "This review point is 5 as it directly identifies a potential misunderstanding in the authors' interpretation of the crossencoder's behavior and also points out a weakness in the paper's motivation. This feedback is actionable and likely to improve the authors' work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly points out a specific detail in the code (trimming after the first 10) and provides a clear reason (computational cost of longer sequences) for why this might be an odd design choice. They also connect it to the model's nature (bagofwords), which suggests longer sequences are not expensive. This is a direct and actionable point.", "grounding_specificity_rationale": "The reviewer refers to 'L254,' which is a specific line number in the paper. This demonstrates strong grounding as they identify the specific part of the paper being addressed. They also clearly specify the issue (computational cost of trimming) and suggest an alternative (not trimming).", "verifiability_rationale": "The reviewer makes a claim about the odd design choice and provides a logical explanation based on the bagofwords nature of the model and the computational cost of longer sequences. While there are no direct citations, the reasoning is sound and based on understanding the model. This provides some support for the claim.", "helpfulness_rationale": "The reviewer provides a clear criticism of a specific implementation detail and suggests a change. This directly addresses a practical aspect of the model's usage and is actionable for the authors. It is a specific, wellarticulated point that is likely to be helpful."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a problem (antiquated model/method) and its impact. While it identifies an issue, the suggested action is implicit, lacking a clear direction on how to improve. The reviewer identifies the problem but doesn't explicitly state what needs to be done.", "grounding_specificity_rationale": "The reviewer refers to 'this work,' 'this framework,' 'the baseline algorithms/methods,' and 'this GNN model.' While they don't give a specific section number, the context strongly implies they are referring to the parts they've already described in the review point. The issue is also clearly stated.", "verifiability_rationale": "The reviewer makes a claim about the antiquated nature of the model/method and its impact. However, they do not provide any evidence or reasoning to support this claim. There are no citations or logical arguments presented to back up the assertion.", "helpfulness_rationale": "The reviewer criticizes the use of an outdated approach. While the criticism is valid, it lacks specific, actionable, and constructive suggestions for improvement. The reviewer identifies a problem but doesn't offer a clear path forward or propose concrete solutions."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out that while the paper claims the proposed method produces the explanation for Figure 1, the *specific mechanism* of how this is achieved is not explicitly detailed. The reviewer suggests that an *additional adhoc postanalysis* might be required to extract the shared motifs, implying the process isn't fully integrated or clear within the method description. While the method is intended to do this, the lack of a concrete, stepbystep explanation makes the action somewhat implicit rather than explicit.", "grounding_specificity_rationale": "The reviewer's comment asks for more specific information about *how* the proposed method identifies the NO2 group in Figure 1. They are asking the authors to identify the specific part of the paper being addressed (the explanation for the NO2 group) and how the method achieves this. The reviewer's suggestion of 'additional adhoc postanalysis' indicates that the process isn't fully integrated into the method and requires further steps beyond the core method, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer raises a valid point about the justification for the method's ability to identify the NO2 group in Figure 1. They are asking for evidence or reasoning to support the claim that the method is capable of this specific task. While the paper *claims* the method produces this explanation, it doesn't explicitly *prove* or *justify* why the method is effective in identifying this specific motif. The lack of explicit support makes the claim somewhat 2.", "helpfulness_rationale": "The reviewer provides a concrete suggestion for improvement by asking for a more detailed explanation of how the method identifies the NO2 group in Figure 1. This is a direct request for more information and clarification, which is a valuable piece of feedback for the authors. While the paper *claims* the method does this, the lack of explicit details makes the feedback 3, as it prompts the authors to seek further clarification."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of the experiment, focusing on the reliance on Proposition 3.2 and the large perturbation value. They also suggest two concrete ways to strengthen the experiment. The action is explicitly stated, and the concrete improvements are directly related to the identified limitations.", "grounding_specificity_rationale": "The reviewer clearly identifies the experiment being criticized and specifies the aspects of the experiment that are problematic (reliance on Proposition 3.2 and the large perturbation value). They also suggest specific ways to improve the experiment, indicating a clear understanding of what needs to be addressed. The grounding is explicit, and the specificity is evident in the detailed description of the issues.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the experiment and provides specific reasons for this claim, referencing Proposition 3.2 and the large perturbation value. While the verifiability of Proposition 3.2 itself isn't explicitly addressed, the reviewer's reference to it is a form of justification. The suggestions to strengthen the experiment are also verifiable by the authors themselves.", "helpfulness_rationale": "The reviewer provides a clear critique of the experiment, identifying specific limitations and offering concrete suggestions for improvement. The suggestions are directly actionable and directly address the identified issues, making the review 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The colon (':') in the equation is explicitly defined as an assignment operator. This means that the left side of the colon is being defined as equal to the expression on the right side. This is a clear and explicit instruction for the authors to understand the meaning of the notation.", "grounding_specificity_rationale": "The reviewer is asking for clarification on the meaning of a symbol within a specific equation. While the equation itself is mentioned, the reviewer is not explicitly pointing to a specific part of the paper (like a section or table). The grounding is more about the context of the equation. The request is quite specific about the symbol and the equation it belongs to.", "verifiability_rationale": "The review point does not contain a claim. It is a request for clarification on a specific aspect of a paper. Therefore, it does not fall under the 'Verifiability' aspect, which is concerned with claims and their support. The appropriate label for this type of review point is 'X' (X).", "helpfulness_rationale": "The review point is 5 as it directly addresses a potential point of confusion for the authors regarding the notation used in a specific equation. Understanding this notation is crucial for them to interpret the equation correctly and potentially identify any issues with it. The request is specific and actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the locations of the errors in the SuppMat (lines 502 and 507) and suggests specific actions: 'two lines in red that should be in green'. This is a concrete action with clear instructions.", "grounding_specificity_rationale": "The reviewer clearly identifies the section of the paper being addressed ('SuppMat') and provides specific details about the errors (two lines should be green, specific references to lines and sections/tables/algorithms). This is 5.", "verifiability_rationale": "The reviewer makes a claim about errors in the SuppMat and provides specific examples and references to support this claim (e.g., 'two lines in red that should be in green', 'L502: \u03f5 \u03b8 > z \u03b8 SuppMat'). This claim is verifiable based on the provided information.", "helpfulness_rationale": "The reviewer provides very specific and actionable feedback. They identify exact locations in the SuppMat and suggest concrete changes. This is 5 for the authors to understand and implement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review states \"a much more comprehensive and dataintensive analysis would improve this paper significantly.\" This comment identifies a desired outcome (more comprehensive analysis) but does not explicitly state what action the authors should take to achieve this. The authors would need to infer that they need to conduct more data collection and analysis. Therefore, this is an implicit action.", "grounding_specificity_rationale": "The review mentions \"this paper significantly\" as a need for improvement but does not specify which part of the paper or what specific issue within the paper is lacking data or analysis. The authors cannot confidently determine which aspect the comment addresses. Therefore, the grounding is weak.", "verifiability_rationale": "The review states \"a much more comprehensive and dataintensive analysis would improve this paper significantly.\" This is a suggestion or claim that the authors would need to evaluate and accept. However, the review does not provide any specific evidence, references, or logical reasoning to support this claim. The suggestion lacks justification. Therefore, the claim is 1.", "helpfulness_rationale": "The review points out a valid area for improvement (more comprehensive and dataintensive analysis) but does not specify *where* within the paper this improvement should be made or *how* the authors should go about achieving this. The suggestion is broad and lacks concrete guidance. Therefore, the review is 2 for the authors in directly addressing the paper's content."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states actions or suggestions, such as 'should be cited' and 'try to distinguish'. However, the specific *how* of these actions is not fully detailed. For example, while it suggests citing, it doesn't specify *which* citations or *how* they should be cited. This makes the action somewhat vague.", "grounding_specificity_rationale": "The comment mentions 'metalearning' and provides examples like 'the work on RL for architecture search and/or as optimizers for learning'. This provides some grounding by referencing specific areas of related work. However, the connection to the current paper's specific content or methodology is not explicitly stated as a specific section, table, or figure. The reviewer implies a connection to 'continual learning' but doesn't directly link it to a particular part of the paper.", "verifiability_rationale": "The comment contains a claim: 'the work on RL for architecture search and/or as optimizers for learning should be more heavily linked to this work'. The reviewer provides supporting reasoning: 'as it seems to directly follow as an application to continual learning'. They also suggest a direction: 'should be more heavily linked'. They even provide a potential *where* this connection could be made: 'as an application to continual learning'. This provides sufficient justification and context.", "helpfulness_rationale": "The review point provides clear suggestions for improvement. It suggests 'citing and distinguishing those approaches' and 'linking existing work to this work'. These are concrete actions that the authors can take to strengthen their paper. The reviewer also provides a rationale for why these connections are important ('as it seems to directly follow as an application to continual learning') and where these connections could be made ('as an application to continual learning'). This makes the review point actionable and relevant to the authors' goals."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment does not explicitly state what the reviewer intends to do with the feedback. While it raises a question about the diversity of feedback, it doesn't provide a concrete action for the author. The reviewer is asking about the process, not suggesting specific changes to the paper.", "grounding_specificity_rationale": "The comment does not specify which aspect of the paper the reviewer is referring to when they talk about 'autogenerated teacher feedback'. It's a general question about the diversity of feedback in general, not about a specific element of the paper. The reviewer is asking about the process, not a specific part of the work.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It's a question about the process of feedback, not a statement that needs to be supported by evidence. The reviewer is asking about the *process* of feedback, not making a judgment about the paper itself.", "helpfulness_rationale": "The comment does not directly provide actionable feedback or suggestions for the author. It's a question about the *review process* itself, not a critique of the paper's content or a suggestion for improvement. The reviewer is asking about the process, not about what the author should do with the feedback."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "None", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the desired outcome: 'The main text should make it more clear that there are additional experiments in the supplement (and preferably summarize their results)'. This is a clear and direct action for the authors to take. The reviewer wants the authors to understand the presence of supplementary experiments and to have a summary of their results, which are concrete actions they can perform.", "grounding_specificity_rationale": "The reviewer's comment implicitly refers to the 'supplement' as the location of the additional experiments. While the type of additional material (experiments) is specified, the specific experiment or the detailed location within the supplement is not mentioned. The reviewer also doesn't specify what aspects of the experiments' results need summarization. Therefore, while the *type* of additional information is grounded, the *specific* experiments and the *details* of the summary are not.", "verifiability_rationale": "X", "helpfulness_rationale": "The reviewer's comment is directly relevant to the authors and provides a clear direction for improvement. They want the authors to be aware of the supplementary experiments and to have a summary of their results. This information is directly helpful for the authors to understand the completeness of the work and potentially address any omissions. While the request for a summary is specific, the request itself is a direct and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point identifies a lack of support for a claim but doesn't explicitly state how the prompts should be improved. The action is implied rather than clearly articulated.", "grounding_specificity_rationale": "The reviewer refers to \"our proposed prompts\" generally and implies the improvement is in the context of Tables 6 and 7 without explicitly stating which prompts or the specific issue within those tables.", "verifiability_rationale": "The point is a statement of observation, not a claim requiring verification. It doesn't introduce a new idea or assertion that needs supporting evidence.", "helpfulness_rationale": "The review points out a discrepancy between a claim and experimental results but doesn't offer specific, actionable suggestions or propose an alternative. It's a critique of the claim rather than a helpful suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a potential improvement to the Cycle FC method by exploring different designs, specifically mentioning 'experiments or analysis with different sampling intervals and sample size'. This provides a clear direction for the authors to consider and act upon.", "grounding_specificity_rationale": "The reviewer mentions 'sampling intervals' and 'sample size' as potential areas for improvement. While they don't explicitly name the 'Cycle FC' method, the context strongly implies they are referring to a feature alignment process within a model. This provides a reasonably clear reference point for the authors to investigate.", "verifiability_rationale": "The reviewer suggests 'experiments or analysis with different sampling intervals and sample size' as a way to verify the current alignment method. This is a claim that can be tested through further investigation, although the verifiability depends on the authors' ability to conduct these experiments and analyze the results.", "helpfulness_rationale": "The reviewer suggests exploring 'different designs' and specifically mentions 'experiments or analysis with different sampling intervals and sample size'. This provides a clear direction for the authors to consider and explore, making the review suggestion actionable and useful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing standard deviations and directly connects this omission to the uncertainty about the 'best' method. The action is to acknowledge the absence of standard deviations, and the implication is that this lack of information hinders the ability to confidently determine the best configuration.", "grounding_specificity_rationale": "The reviewer identifies the *absence* of standard deviations. While they don't explicitly name a section or table, the identification of the problem is implicit. The grounding is in the *lack* of information rather than a precise reference to a specific part of the paper.", "verifiability_rationale": "The reviewer makes a claim that the lack of standard deviations makes it difficult to assess the significance of the results and thus the 'best' method. The reasoning is implicit, based on the assumption that standard deviations are crucial for determining statistical significance and, therefore, the best performing method. The claim is that the information is not verifiable without standard deviations.", "helpfulness_rationale": "The reviewer directly addresses a crucial aspect of result presentation (standard deviations) and its impact on the ability to draw conclusions about the 'best' method. This is a clear and actionable point for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer is implicitly asking for clarification on the feature extractor used, which is an action that needs to be taken. However, the action itself is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Line 201' and asks about the 'feature extractor', which directly refers to a specific part of the paper and the issue with that part (the lack of clarity on the feature extractor). This demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer is posing a question, which is not a claim or suggestion. Therefore, it is not verifiable in the sense of supporting a claim. However, the question itself is verifiable in the sense that the information should be available in the paper if it's a crucial detail.", "helpfulness_rationale": "The reviewer is asking a question, which is a request, not a critique or suggestion that could help improve the draft. Therefore, it is not helpful in the sense of providing actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a gap in the paper (missing details) but doesn't provide a concrete action for the author to take. The reviewer says 'add more details' but doesn't say 'add Section 3' or 'explain Algorithm 1 in more steps'.", "grounding_specificity_rationale": "The review point refers to 'computation/algorithm/implementation details' generally, without pointing to a specific section, figure, or table in the paper. It's vague.", "verifiability_rationale": "The review point is a suggestion, not a claim that something is wrong or needs improvement. It lacks any logical reasoning, common knowledge, or external references to support it.", "helpfulness_rationale": "The review point is relevant and identifies a valid issue (missing implementation details). However, it lacks specific guidance on how to address it, making it less impactful."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for an explanation of how the threshold p < 0.4 was chosen. While the reviewer's intent is to understand the *process* of choosing this threshold, the review point itself doesn't explicitly state the *action* of choosing this threshold. It's more of a question seeking clarification on a prior decision. Therefore, it's not fully actionable as it doesn't directly tell the author what to do with this information. However, it does point towards a potential area for improvement in the author's understanding of the algorithm's parameters.", "grounding_specificity_rationale": "The reviewer is asking about a threshold used in the paper. To ground this, they would ideally refer to the specific section of the paper where this threshold is used (e.g., 'In the experimental setup, we set p < 0.4 for...', 'In Section 3.2, the algorithm uses...'). The review point doesn't provide this context. Therefore, the reviewer cannot confidently determine which part of the paper they are addressing. This makes the grounding weak. The comment also doesn't specify what needs to be addressed in this part (the threshold itself), making it not specific in that sense either.", "verifiability_rationale": "The review point is a question seeking explanation, not a statement containing a claim that needs verification. Therefore, it doesn't contain a claim that requires justification or support. According to the guidelines, this falls under 'X'.", "helpfulness_rationale": "The review point is a question seeking explanation about a specific parameter (p < 0.4) used in the algorithm. While understanding why a threshold was chosen can be helpful for the author's understanding of the algorithm's behavior, it doesn't directly provide actionable feedback on how to improve the draft. The author would still need to go back to the paper and try to understand the reasoning behind this choice themselves. Therefore, it's not 5 in terms of directly improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'Lack of Analysis' and 'Lack of comparison'. These are clear statements of what should be done, indicating an explicit action. However, the reviewer does not specify *which* aspects of the analysis or comparison are lacking, making the action somewhat vague. Therefore, while an explicit action is taken, it is not fully concrete.", "grounding_specificity_rationale": "The reviewer mentions 'data augmentation methods' and provides examples like 'EDA' and 'LLMbased paraphrasing', indicating a reasonable level of grounding in the 'what'. However, the reviewer does not specify *which* aspects of these methods need analysis or *how* the comparison should be done, making the grounding underspecific regarding the 'how'.", "verifiability_rationale": "The reviewer states that there is a 'lack of analysis' and suggests comparing their approach to other methods. This constitutes a claim that needs to be verified. The suggestions provided are actionable and could be supported by literature, making the claim verifiable.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as 'analyzing the effectiveness of each data augmentation method' and 'comparing their approach to other paraphrasing methods'. These suggestions are actionable and directly address the identified weaknesses, making the review 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests a baseline experiment where all negative samples are assigned to a single 'distractor class'. While this sets up a potential experiment, it doesn't explicitly state how the author should implement this or what the expected outcome should be. The reviewer is prompting the author to consider this simple baseline, but lacks the explicit action of guiding the author on the implementation details.", "grounding_specificity_rationale": "The reviewer's comment is somewhat vague. While they imply a baseline experiment, they don't explicitly identify a specific part of the paper being addressed (e.g., a particular layer, metric, or analysis step). The reference to a 'distractor class' is general and doesn't pinpoint a specific element within the author's work. Therefore, the grounding is not as precise as it could be.", "verifiability_rationale": "This review point does not contain a claim that requires verification. It's a suggestion for an experiment and a question about its potential performance. Since there's no assertion to validate, the concept of verifiability doesn't directly apply to this specific review point.", "helpfulness_rationale": "This review point has the potential to be helpful by highlighting a potential weakness in the author's analysis \u2013 the lack of consideration for a simple baseline experiment. By suggesting this, the reviewer encourages the author to think critically about their approach and include a basic check. However, it doesn't provide a direct solution or expected outcome, making it less actionable than a fully constructive comment."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The review point states that the advantage of RLCD over RLAIF shrinks from 7B to 30B models. While this indicates a potential area for further investigation, it doesn't explicitly tell the authors *how* to explore this further. The suggestion to 'look at Tab. 2' is a starting point, but lacks specific actionable steps.", "grounding_specificity_rationale": "The review point explicitly mentions 'Tab. 2' as the location where the performance difference is observed. This clearly indicates that the reviewer has identified a specific part of the paper. The comment also specifies what it's referring to as 'the advantage of RLCD over RLAIF shrinking'.", "verifiability_rationale": "The review point makes a claim that the advantage of RLCD over RLAIF shrinks. This is a claim that can be supported by logical reasoning (the observed trend) and by referring to the data presented in 'Tab. 2'. However, it doesn't provide specific examples or citations to external works to back up this claim.", "helpfulness_rationale": "The review point raises a question about the scalability of RLCD based on the observed performance trend. While this is a valuable suggestion for the authors to consider, it doesn't directly improve the model or provide a concrete step for the authors to take. It's more of an observation and a question for further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of 'specific measurements or comparisons' to support the claim of computational gains. This is an implicit action as the reviewer identifies a missing element but doesn't name it directly. The action is vague as it doesn't specify what kind of measurements or comparisons are needed.", "grounding_specificity_rationale": "The reviewer mentions 'quantitative analysis,' 'measurements,' and 'comparisons' as examples of what is missing. This clearly identifies the specific part of the paper and the issue needing improvement, making it fully grounded. However, the reviewer doesn't specify the exact metrics or baselines for these measurements and comparisons, making it underspecific.", "verifiability_rationale": "The review point clearly states a claim: 'A quantitative analysis\u2014such as GPU hours, memory usage, or training time\u2014would provide stronger evidence of the efficiency improvements in DQ V2.' This claim is supported by logical reasoning (the need for evidence) and common knowledge (the importance of quantitative analysis in evaluating efficiency). The reviewer also provides specific examples of what this analysis could include.", "helpfulness_rationale": "The review point clearly identifies a weakness in the paper: the lack of quantitative analysis to support the claim of computational gains. The reviewer provides a specific suggestion for improvement: 'A quantitative analysis\u2014such as GPU hours, memory usage, or training time\u2014would provide stronger evidence of the efficiency improvements in DQ V2.' This is a clear and actionable suggestion that directly addresses the identified weakness."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The criticism explicitly states a factor (time) that impacts efficiency, making it an explicit action. It also provides concrete information about the time involved in COLMAP and finetuning, making it a concrete action. The reviewer suggests a direct step the authors should take \u2013 consider the time involved.", "grounding_specificity_rationale": "The criticism does not explicitly name a specific section, table, or unique aspect of the paper where the time factor is particularly relevant. While it mentions COLMAP and finetuning, it doesn't pinpoint the exact results or comparisons affected by this time factor. Therefore, it is not fully grounded. While it mentions specific components (COLMAP, finetuning), the *implication* is general, making it somewhat specific but not fully specific in its grounding.", "verifiability_rationale": "The criticism makes a judgment about the method's efficiency being less due to the time factor. This constitutes a claim. However, the criticism does not provide specific evidence or references within the review point to *verify* this claim. It's a logical deduction based on common knowledge in computational tasks, but not explicitly stated or supported within the point itself.", "helpfulness_rationale": "The review point clearly identifies a relevant factor often overlooked in efficiency comparisons. It suggests considering the time involved, which is a concrete action the authors can take to potentially improve their method. While the criticism doesn't specify *which* results are affected, it provides a clear direction for the authors to consider."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state what the authors should do. The first part, 'The results are only reported after a bunch of training has occurred,' is a statement of fact, not an actionable suggestion. The second part, 'I presume that early in training the model parameters are essentially garbage,' is a speculative hypothesis, not a concrete action. Therefore, the review point lacks explicit and direct instructions for the authors.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or concept. The first part, 'The results are only reported after a bunch of training has occurred,' is vague and does not pinpoint a specific section. The second part, 'I presume that early in training the model parameters are essentially garbage,' is slightly more specific, mentioning 'training' but not a particular section or table. Therefore, the grounding is weak, as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point does not contain a claim that is explicitly supported by evidence. The first part, 'The results are only reported after a bunch of training has occurred,' is a factual statement. The second part, 'I presume that early in training the model parameters are essentially garbage,' is a hypothesis, not a verifiable claim. Therefore, the review point does not present a claim that can be logically reasoned, referenced external works, or deduced from the paper.", "helpfulness_rationale": "The review point is not particularly helpful. The first part, 'The results are only reported after a bunch of training has occurred,' identifies a potential limitation in the reporting process but does not offer a solution. The second part, 'I presume that early in training the model parameters are essentially garbage,' is a speculative hypothesis, not a constructive suggestion. The overall feedback is limited and does not provide actionable improvements for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states that the contribution looks marginal, which is an example of an explicit action. However, the reviewer does not provide concrete suggestions on how to improve the contribution, making the action vague.", "grounding_specificity_rationale": "The reviewer makes a general statement about the contribution being marginal without specifying which part of the paper or method is affected. They do not point to a specific section, table, or figure, nor do they clearly explain what is wrong with the existing methods.", "verifiability_rationale": "The reviewer makes a claim that the contribution looks marginal. However, they do not provide any evidence or justification for this claim. There are no logical reasoning, common knowledge, or external references supporting this statement.", "helpfulness_rationale": "The reviewer states that the contribution looks marginal to them, which is a clear negative opinion. While they suggest adding another stream for lowresolution, this is a suggestion for a potential improvement rather than a helpful comment that guides the authors on how to address the identified weakness. The comment lacks actionable feedback."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential issue (unclear contribution) and points to a discrepancy (ablation study vs. motivation). While the reviewer explicitly states the performance gain is 'mostly' from PBSD, the specific unclear aspect of the contribution is not explicitly stated. The motivation is also implicitly stated as being 'mostly' supervised contrastive learning. The reviewer could be more explicit about the specific unclear aspect and the nature of the discrepancy between the stated motivation and the ablation study results.", "grounding_specificity_rationale": "The reviewer mentions 'the main contribution,' 'PBSD,' 'the DSCL part,' 'tail classes,' and 'ablation study.' While they don't explicitly name a section or table, they refer to key elements of the paper, making the grounding somewhat weak. The reviewer *does* specify the 'discriminative of the learned representation on tail classes' as a known contribution and asks for 'any other motivations for PBSD,' showing a degree of specificity. However, the focus is on a known aspect rather than a broader, unexplored area.", "verifiability_rationale": "The reviewer makes claims such as 'The main contribution is somehow a little bit unclear' and 'However this paper is mostly motivated by supervised contrastive learning, that is, the DSCL part.' These are explicit statements that could be verified. The reviewer also provides a partial justification by referencing the ablation study, stating 'From the ablation study, we can see the performance gain is mostly from PBSD.' However, they do not explicitly cite specific results from the ablation study or provide a detailed explanation of why PBSD's ablation led to the observed performance gain. The connection between the claims and the ablation study results is implied but not fully elaborated or supported by specific references.", "helpfulness_rationale": "The reviewer raises a relevant point about the clarity of the paper's contribution and the apparent mismatch between the stated motivation and the ablation study results. The reviewer's question about 'any other motivations for PBSD?' is a valuable point for clarification and further discussion. While the point is relevant to the authors, particularly those working on the PBSD component, it does not offer a specific solution or a clear next step for improvement. The point highlights a potential area for further investigation or clarification rather than a direct suggestion for action."}
{"actionability_label": "2 (2)", "grounding_specificity_label": "3 (Somewhat Grounded and Specific)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer states a fact (''2 gives a tester for the spread parameter...\") but doesn't explicitly say what the implication is or how it relates to an (\u03f5, \u03b4)identity tester. The reviewer also raises a specific concern about the (\u03c0, \u03d5) pairs, indicating a lack of clarity on the practical application of the mentioned tester.", "grounding_specificity_rationale": "The reviewer explicitly mentions a specific aspect of the tester (its behavior with certain (\u03c0, \u03d5) pairs) and asks a question about it. This shows a clear focus on a specific part of the paper and what is unclear about it.", "verifiability_rationale": "The reviewer states a fact (''2 gives a tester for the spread parameter...\") and then poses a question (''For e.g., how is it dealing with ( \u03c0 , \u03d5 ) pairs where \u03d5 = \u03d5 0 , but d K ( \u03c0 0 , \u03c0 ) is large?\"`). The reviewer does not provide any justification or explanation for why this is a relevant question or what the implications are. They are simply posing a question.", "helpfulness_rationale": "The reviewer points out a potential gap in the explanation of how a specific tester relates to a broader concept. They are asking a question that highlights a lack of clarity. While the reviewer is trying to understand something, the review itself doesn't directly offer a solution or improvement. It's a question seeking clarification."}
{"actionability_label": "2", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states a problem ('is unclear') but does not offer any specific steps or guidance on how to address it. It's a symptom, not a solution.", "grounding_specificity_rationale": "The review point mentions 'the proposed dataset' generally, without pinpointing a specific section, table, figure, or unique aspect of the dataset within the paper. The grounding is weak because it refers to the dataset as a whole without specifying where within the paper or what specific detail is missing.", "verifiability_rationale": "The review point states a problem ('is unclear') which can be considered a negative judgment or a suggestion for improvement, but it doesn't explicitly *claim* something is wrong without a suggestion. It's more of a statement of a deficiency. Furthermore, even if there's an implicit suggestion, the *reasoning* for why the distribution is unclear isn't provided. There's no reference to common knowledge or external sources about typical dataset distribution issues.", "helpfulness_rationale": "The review point identifies a genuine lack of clarity, which is a valid concern for anyone working with datasets. However, it stops short of providing any concrete solutions or guidance. It points out a problem but doesn't offer a path forward, making it less helpful than a review that suggests specific improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the method 'necessitates annotated labels' and then contrasts this with 'selfsupervised pretraining without annotations'. This clearly identifies a limitation of the proposed method and suggests a concrete alternative. The reviewer directly points out a requirement and proposes a solution, making it 5.", "grounding_specificity_rationale": "The reviewer mentions 'annotated labels' and 'supervised training', which are specific aspects of the method. While they don't explicitly say 'labels for semantic tokens', the context strongly implies it. The reviewer also mentions 'learning semantic tokens', which is a specific element being criticized. The connection between the method and the need for annotations is clear, making it fully grounded. The specifics of 'annotated labels' and 'supervised training' are also provided, making it fully specific.", "verifiability_rationale": "The reviewer makes a clear statement: 'A selfsupervised pretraining approach without annotations could be more appealing.' This is a claim that the method 'necessitates annotated labels for learning semantic tokens' and that this is limiting. While the reviewer doesn't provide explicit verification of this claim, the implication is clear and the alternative is welldefined. Therefore, it is 3 as the claim is implied but lacks explicit justification or references.", "helpfulness_rationale": "The reviewer directly points out a limitation of the method ('necessitates annotated labels') and suggests a potential improvement ('selfsupervised pretraining'). This is a clear and actionable feedback for the authors. The reviewer's point is easy to understand and directly addresses a specific aspect of the method. The suggestion is concrete and directly addresses the identified limitation, making it 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies the importance of demonstrating scalability by showing LFF can help solve more challenging DRL tasks. While the *what* (scalability) is clear, the *how* (which specific tasks or how to approach them) is not explicitly stated. The reviewer suggests 'more challenging DRL tasks' but doesn't provide specific examples or a methodology for selecting them. This makes the action implicit rather than explicit. The reviewer also doesn't specify how the author should *improve* their draft based on this information.", "grounding_specificity_rationale": "The review point explicitly mentions 'most continuous control experiments' and names specific examples of simple tasks ('cartpole' and 'mountain car') and complex tasks ('locomotion of ants or humanoids'). The grounding is strong as the specific parts of the paper (types of tasks) are identified. The specificity is high as the examples are clear and within the relevant domain.", "verifiability_rationale": "The review point makes a claim about the importance of demonstrating scalability in LFF research. It provides a logical reasoning by stating that 'most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car. To fully demonstrate the scalability of LFF, it\u2019s important to show LFF can also help to solve more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids.' The reasoning is clear and points to the need for experiments on more complex tasks. The suggestion of 'locomotion of ants or humanoids' provides a concrete example.", "helpfulness_rationale": "The review point is 5 as it identifies a valid limitation in the experimental evaluation of LFF. It directly points out that the current focus on simple tasks might hinder the demonstration of scalability. The reviewer suggests exploring 'more challenging DRL tasks with higher input dimensionality' and provides an example ('locomotion of ants or humanoids'). This provides a clear direction for the author to consider and is a valuable piece of feedback for improving the draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the issue with the baselines (MULT being outdated) and suggests considering more recent work. This is a clear and actionable point for the authors.", "grounding_specificity_rationale": "The comment explicitly mentions the year (2019) of the MULT paper, providing a clear grounding point in the literature. It also mentions 'deep learning based baselines that consider crosssensory interaction,' which is a specific concept within the field.", "verifiability_rationale": "The comment provides specific examples of relevant publications (MULT, MULT2020, MULT2022) and a year, making the claim verifiable. The reasoning is that these papers represent the current stateoftheart in the mentioned area.", "helpfulness_rationale": "The comment identifies a relevant limitation in the chosen baselines (MULT being from 2019) and suggests considering more recent work. This is a helpful point as it guides the authors to update their baseline comparisons. While it points to a general trend, it doesn't pinpoint a specific weakness in the *current* paper's methodology, making it 3 rather than 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a gap in the experimental section by stating 'Comparison against other models in the experiments are unclear.' It also provides a concrete suggestion for improvement by mentioning 'the value of the used ranks for all the models are omitted which make not possible a fair comparison.' The reviewer proposes comparing tensor completion results for all models but having the same number of model parameters, which is a direct and actionable suggestion. The core of the actionable part is the suggestion to provide rank information and parameter counts.", "grounding_specificity_rationale": "The reviewer directly points to the 'experiments' section of the paper (or the draft being reviewed) and states 'The value of the used ranks for all the models are omitted which make not possible a fair comparison.' This indicates a lack of specific information about the experimental setup within that section. While the reviewer doesn't explicitly state the ranks, their omission is the key point. The reviewer's suggestion to 'add the number of entries of all core tensors for each model (see my question about experiment settings below)' implies that the section *does* exist, but lacks the necessary details for a fair comparison.", "verifiability_rationale": "The reviewer makes a claim about the unfairness of the comparison against other models. They provide a method for verifying this claim by suggesting 'adding the number of entries of all core tensors for each model (see my question about experiment settings below)' and comparing the tensor completion results for all models but having the same number of model parameters. This method is logical and provides a clear path to verification. The claim is verifiable because it proposes a concrete way to gather information (ranks and parameter counts) to address the issue.", "helpfulness_rationale": "The reviewer's comment directly addresses a significant weakness in the experimental description: the lack of clarity and fairness in the comparison against other models. They provide a clear and actionable suggestion to include rank information and model parameter counts. This directly helps the authors understand the missing details and how to improve their experimental setup for a fairer comparison. The suggestion is concrete and directly addresses the identified problem, making it 5 for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential difference in the 'normalization module' between two versions and suggests standardizing the icons. While the *what* (normalization module) is somewhat specific, the *how* (the exact nature of the difference and why it's problematic) is vague. The suggestion to standardize icons is a potential action, but the reviewer doesn't explicitly state what needs to be done to achieve this standardization. Therefore, while the reviewer identifies a potential issue, the lack of detailed actionability makes it 3 but not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions 'the normalization module' and 'Fig. 4'. This indicates a specific part of the paper or concept being referenced. However, the reviewer does not explicitly state *what* is wrong with the normalization module or the icons in Fig. 4. The description is general, focusing on the *potential* difference and the *general* issue of overlapping icons. Therefore, the reviewer identifies a specific *thing*, but lacks detail about the *issue*, making it weakly grounded. The specific issue of overlapping icons in the 0/50 latency range further supports this, as it clearly points to a specific part of the figure that needs attention.", "verifiability_rationale": "The reviewer states 'the normalization module seems different' and 'Fig. 4 is a bit confusing'. These statements are claims that require justification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The confusion about the icons in Fig. 4 is also not substantiated with any evidence. Therefore, the claims are present, but lack sufficient verification, making it 1.", "helpfulness_rationale": "The reviewer suggests standardizing the icons and points out minor problems with the text. While these suggestions are potentially helpful, they are quite general. The reviewer doesn't specify *which* icons need standardization or *what* the current inconsistencies are. Similarly, the textual issues are mentioned but not detailed. The helpfulness is limited by the lack of specificity in the suggestions and the unelaborated textual issues. Therefore, the review provides some potential improvements, but they are not detailed enough to be fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "2: Full Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer correctly identifies an implicit action (the goal of pruning). However, the lack of detail in the theoretical part regarding how the algorithm removes subdivision splines makes it not fully actionable. The reviewer's question about the algorithm's details is a clear indication of this lack of explicitness.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'theoretical part' and asks about 'how the proposed algorithm in detail to remove the subdivision splines.' This demonstrates a clear attempt to pinpoint the specific section and process being discussed, indicating full grounding. The question also targets a specific aspect (removal of splines) within that section, enhancing specificity.", "verifiability_rationale": "The reviewer makes a claim that the author 'didn\u2019t provide how the proposed algorithm in detail to remove the subdivision splines.' While this claim is likely true based on the provided text, the provided text itself doesn't explicitly state *why* the details are missing or *what* examples or references would be needed. Therefore, it's not 5.", "helpfulness_rationale": "The reviewer's questions directly address the paper's claims and ask for clarification on a key aspect (the algorithm's details and computational cost). These questions are relevant to the reader's understanding and potential implementation, making the review 3 in identifying a gap in the paper's presentation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer raises a valid concern about the consistency of the 300WLP dataset usage across the proposed method and the baselines. While the reviewer doesn't explicitly state the action to take, the question implies that if the baselines don't use 300WLP, the proposed method might have an unfair advantage. The action is implicit, requiring the authors to investigate the experimental setup of the baselines. The action itself is vague, as the authors need to determine how to address the potential discrepancy, which isn't specified in the review point.", "grounding_specificity_rationale": "The reviewer mentions 'experimental methodology' generally, which is a broad area. While they also mention '300WLP', they don't explicitly point to a specific section, table, or unique aspect of the paper where this detail is discussed. The reviewer's comment is about the *type* of methodology, not a specific instance within it. Therefore, the grounding is weak as the authors can't confidently pinpoint the referenced part until they read the paper.", "verifiability_rationale": "The reviewer states a claim: 'Most baselines do not use 300WLP dataset in their training' and raises a question about its implications. This claim is not explicitly supported by any external references or logical reasoning within the review point itself. The verifiability depends on the authors' prior knowledge of the baselines' implementations, which isn't provided in the review point. Therefore, it's 1 based solely on the information given.", "helpfulness_rationale": "The reviewer's point is likely to be helpful. They identify a potential inconsistency in the experimental setup that could affect the fairness of the comparison. By highlighting this, they provide a basis for the authors to investigate and potentially address the issue. However, the review point itself doesn't provide a direct solution or specific steps to take, so its helpfulness is limited to prompting further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The comment identifies a potential issue (lack of novelty) but doesn't provide specific details on how to address it. It's a general observation, not a specific suggestion for improvement.", "grounding_specificity_rationale": "The comment mentions 'computation offloading' and 'gradient augmentation' generally. It doesn't explicitly identify the specific part of the paper being addressed, making it 1.", "verifiability_rationale": "The comment is a judgment about the potential lack of novelty of certain techniques but doesn't provide any logical reasoning, common knowledge, or external references to support this claim. It's a general observation, not a specific claim requiring evidence.", "helpfulness_rationale": "The comment identifies a potential weakness (lack of novelty) but, as determined for actionability and grounding specificity, it doesn't provide concrete steps for the authors to address it. It's a general observation, not a specific suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'no indepth analysis' and asks 'why?'. This is a clear and direct request for a specific action (providing analysis). While the request is clear, it lacks specific details on *how* to perform the analysis or *what* aspects of the training dynamics need explanation. Therefore, it is somewhat explicit but somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific issue: 'inverse scaling happens over compute.' They also clearly specify the area of concern: 'why?'. This indicates a strong grounding of the comment in the paper's content and a clear specification of the problem. The reviewer is pointing to a specific relationship between two key variables and asking for an explanation of a phenomenon.", "verifiability_rationale": "The reviewer presents a claim about the lack of indepth analysis and the request for an explanation. However, they do not provide any evidence or justification for this claim. There is no logical reasoning, common knowledge, or external references provided to support the assertion that the paper lacks a detailed analysis of the inverse scaling phenomenon. The comment is a statement of what *should* be present, not what *is* present, and no evidence is given to back up the claim.", "helpfulness_rationale": "The reviewer's comment directly points to a potential weakness in the paper \u2013 the lack of a detailed explanation for the observed inverse scaling phenomenon. By asking for more analysis and an explanation, they are providing a constructive suggestion for improvement. This comment is directly addressing a potential area for enhancement and encourages the authors to delve deeper into their experimental results and provide a more comprehensive understanding. While it's a request for more, it's a specific and actionable request aimed at improving the paper's clarity and completeness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a problem with the paper's assumption and suggests an alternative approach by questioning the assumption itself. This is a clear and actionable point, directly challenging a core premise of the paper.", "grounding_specificity_rationale": "The reviewer clearly identifies the IID assumption and explains *why* it's problematic in the context of the paper's argument. They also explain *how* this undermines the argument (the sqrt(m) argument and Theorem 6/7). This is a strong, specific criticism of a core assumption, making it 5.", "verifiability_rationale": "The reviewer provides a clear explanation of why the IID assumption is problematic in the context of the paper's argument. They explain the logical connection between the assumption and the convergence proof. This is wellsupported evidence, making the criticism 5.", "helpfulness_rationale": "The reviewer's comment is highly valuable. They directly challenge a key assumption and highlight a potential flaw in the paper's theoretical framework. This is extremely helpful for the authors to understand the limitations of their work and potentially improve their approach."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests improving the analyses of the method and experimental outcomes. While this is a clear direction for improvement, the reviewer does not specify *how* these analyses should be improved. They only state that the current analyses are 'not comprehensive enough'. This lack of specificity makes the action implicit rather than explicit. The reviewer also does not provide any concrete examples of what constitutes a 'comprehensive' analysis. Therefore, while the reviewer identifies a need for improvement, the lack of specific details makes it 3 but not fully actionable.", "grounding_specificity_rationale": "The reviewer refers to 'the analyses of the method itself and the experimental outcomes'. While the *subject* of the criticism is concrete, the *phrase used* is vague. The reviewer does not specify *which* section, table, or figure these analyses refer to. They could have been more specific, for example, by saying 'Section 4.2' or 'Table 3'. However, the reviewer *does* specify what they think needs improvement: 'not comprehensive enough'. This specificity is about the *outcome* of the analysis rather than the *reference* to a specific part of the paper. Therefore, the grounding is weak because the reference is vague, but the specificity is strong because the critique is about the quality of the analysis.", "verifiability_rationale": "The reviewer states that 'A majority of the experiments focus on the presentation of results. The analyses of the method itself and the experimental outcomes are not comprehensive enough.' This statement expresses an opinion or judgment about the comprehensiveness of the analyses. There is X that something is definitively true or false. The reviewer is suggesting an area for improvement, not making a claim that can be verified. Therefore, this point does not contain a claim that can be supported by evidence, logical reasoning, or external references.", "helpfulness_rationale": "The reviewer points out a potential weakness in the paper's evaluation, specifically the lack of comprehensive analysis of the method and experimental outcomes. This is a valuable piece of feedback for the authors. It directly addresses a potential area for improvement and provides a clear direction for the authors to enhance their work. The feedback is directly relevant to the paper's core contribution and its evaluation."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out a limitation of the paper's focus but doesn't explicitly state what the authors should do to address this. While it identifies a problem ('This paper mainly focuses...'), it lacks specific, actionable steps or suggestions for improvement. The reviewer states the issue but doesn't tell the authors how to make the paper more applicable.", "grounding_specificity_rationale": "The review mentions 'multitask models' and 'applicability' as areas for improvement. While it identifies a general area of concern, it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper that is lacking. The reviewer provides a highlevel suggestion without specifying what part of the paper needs adjustment or what specific issue within multitask modeling is causing the limited applicability.", "verifiability_rationale": "The review states a claim about the paper's focus ('This paper mainly focuses...'). However, it doesn't provide any evidence, reasoning, or references to support this claim. The reviewer is stating an opinion about the paper's focus without backing it up with logical arguments or external references. There are no factual statements that require verification.", "helpfulness_rationale": "The review identifies a potential area for improvement (a more applicationfocused approach) but fails to provide concrete suggestions or specific directions for the authors to take. It's a highlevel critique that lacks actionable guidance. The reviewer doesn't explain how the paper should be more applicationfocused or what specific changes are needed. They simply state the problem."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly names two missing papers and suggests a performance comparison. This directly tells the authors what to do.", "grounding_specificity_rationale": "The reviewer refers to 'the next section' initially, which is vague. However, they then proceed to discuss specific papers and a performance comparison, indicating they are addressing a specific area of the related work.", "verifiability_rationale": "The reviewer makes a claim about the performance of the suggested papers but provides no evidence or reasoning to support this claim within the review itself.", "helpfulness_rationale": "The reviewer identifies relevant papers, which is helpful. However, the lack of supporting evidence makes it difficult for the authors to fully benefit from this feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point does not explicitly state an action or provide concrete suggestions. It poses questions that require the authors to perform further analysis and potentially make changes. While the intent is helpful, the lack of direct actionability makes it less immediately useful for improving the draft at hand.", "grounding_specificity_rationale": "The review point does not explicitly identify any specific part of the paper being discussed. The questions are general and do not target any particular section, table, figure, or unique aspect of the work. Therefore, the grounding is weak as the authors cannot pinpoint the area being addressed.", "verifiability_rationale": "The review point does not contain a claim. It is a question posed to the authors, not a statement that requires verification. Therefore, it does not fit the criteria for verifiability.", "helpfulness_rationale": "The review point is relevant and prompts the authors to consider additional insights and performance evaluations. It acknowledges potential areas for improvement and encourages further exploration. While it doesn't provide immediate solutions, it is a valuable prompt for the authors to think critically about their work and potentially make enhancements."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a factual deficiency in the paper: the absence of information on hyperparameters and their derivation. While it points out what is missing, it doesn't explicitly instruct the reader on what specific hyperparameters are needed or how they should be derived. The reader still needs to search for this information within the paper itself. Therefore, the criticism is about identifying a missing element, but not directly guiding the reader on the action to take.", "grounding_specificity_rationale": "The review point is a general statement about the paper lacking information on hyperparameters. It does not pinpoint a specific section, table, figure, or unique element where this information should be found. The reviewer is aware that the information is missing but cannot confidently identify the exact location. Therefore, the criticism is 1 in a specific part of the paper.", "verifiability_rationale": "The review point itself is a statement of fact: 'The paper does not describe what hyperparameters are used by each defense nor how those hyperparameters are derived.' It does not present a claim that requires verification. There is no suggestion that the paper is lacking in some way that needs justification. Therefore, there is X to be verified.", "helpfulness_rationale": "The review point identifies a factual deficiency in the paper regarding the description of hyperparameters. While this points out a gap in the paper's content, it does not directly provide the author with a specific action or suggestion on how to address this deficiency. The reviewer informs the reader of what is missing, but doesn't guide them on how to find or rectify it. Therefore, the feedback is informative but lacks direct actionable guidance for the author."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review points to a 'main takeaway point' and a specific action ('query a cluster proportionally to the square root of its size'), but it doesn't explicitly state how to implement this action. The formula or algorithm isn't provided, making the action only implicitly suggested.", "grounding_specificity_rationale": "The review refers to 'theoretical results' and 'main takeaway point.' While it hints at the area of interest, it doesn't pinpoint a specific section, table, figure, or a unique element within the paper. The connection to the 'square root of its size' is also vague.", "verifiability_rationale": "The review makes a claim ('query a cluster proportionally to the square root of its size') but doesn't provide strong justification or evidence for its effectiveness or novelty. The lack of a formula makes the specific suggestion less verifiable. The critique of novelty is a statement of opinion.", "helpfulness_rationale": "The review points to a potential area for improvement ('query a cluster proportionally to the square root of its size'), but it lacks the necessary details and justification to be truly helpful. It doesn't explain *why* this is a good idea, *how* to implement it, or *why* it's better than alternatives. The critique of novelty is also a general statement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking *why* separators are introduced, implying a lack of explicit explanation for their purpose beyond basic I/O. While the action is implied (the reviewer wants to understand the benefit), the details are missing, making it 3 but not fully explicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 4' and 'separators,' indicating a clear identification of the part of the paper being addressed. However, the *specific* benefit beyond I/O is not detailed, making it somewhat specific but not fully grounded in detail.", "verifiability_rationale": "The reviewer makes a claim about the paper's lack of explanation for the additional benefits of separators beyond I/O. This claim is verifiable if the paper explicitly states the basic I/O function but lacks a detailed explanation of the *additional* benefits. Without the paper content, we assume this is the case, making it 3.", "helpfulness_rationale": "The reviewer's question is a valid form of feedback, pointing to a potential area for improvement. However, it lacks the explicit suggestions and concrete details that would make it 5. It's 3 because it identifies a valid concern, but it doesn't provide a direct solution."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a potential improvement: 'why is it that mean pooling works?' and suggests exploring 'other pooling strategies'. This indicates a clear action: to investigate different pooling methods. Furthermore, the reviewer provides concrete examples of alternative pooling strategies ('what about other pooling strategies?') which makes the action very specific and actionable. The reviewer is not just pointing out a problem but also suggesting a concrete solution.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'mean pooling' and also refers to 'pooling strategies' in general. This provides a clear grounding point within the paper. The reviewer specifies the type of pooling being questioned, which is a level of specificity beyond just mentioning 'pooling'.", "verifiability_rationale": "The reviewer makes a claim: 'mean pooling works'. While the reviewer doesn't provide a direct justification for this claim within the review point itself, the reviewer's suggestion to explore 'other pooling strategies' implies that the reviewer has observed or believes mean pooling might not be optimal. This provides a basis for verification: if mean pooling doesn't work, what are the alternatives? The reviewer doesn't explicitly cite external references for this claim, but the suggestion to explore alternatives provides a direction for investigation.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential limitation in the current implementation (the use of mean pooling) and offers a concrete suggestion for improvement (exploring other pooling strategies). This is a helpful feedback point for the authors as it guides them towards potential enhancements. The reviewer also asks for justification ('why is it that mean pooling works?'), which is a valuable feedback point that encourages the authors to explain their choices."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a specific question about the VQGAN's training details, which can be interpreted as an implicit request for clarification on how the model was trained. While the action is implied, the reviewer does not explicitly state what action the authors should take (e.g., 'Check if the VQGAN is pretrained'). The reviewer is prompting for information, which can be seen as a form of implicit action, but it lacks the explicit steps or instructions needed for full actionability. The reviewer is asking a question that, if answered, would provide the authors with information to understand the training process better.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'VQGAN' and asks a question specifically about its training. This directly refers to a component mentioned in the paper. The comment is about a specific part of the paper, and the reviewer is asking about details within that part (training details). Therefore, the grounding is explicit.", "verifiability_rationale": "The reviewer poses a question about the VQGAN's training. This is a claim that requires justification. The justification would involve stating whether the VQGAN is pretrained and what dataset it was trained on. While the reviewer doesn't provide the justification themselves, the *absence* of this information in the paper would be verifiable by checking the paper's content. The reviewer is implicitly pointing out a missing piece of information that would be verifiable.", "helpfulness_rationale": "The reviewer directly addresses a potential weakness in the paper by pointing out the missing training details of the VQGAN. They ask specific questions to clarify this information. This information is directly actionable for the authors. They can use this feedback to go back and check the paper for information about the VQGAN's training, which could help them understand the model better and potentially improve their own work by considering similar training approaches or addressing any limitations."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a potential alternative to the proposed method (vanilla Adam) and highlights a discrepancy in the number of runs (40 vs. 40 restarts). This constitutes an explicit comparison and provides concrete details on how the alternative differs. The reviewer identifies a potential weakness in the proposed method and offers a specific alternative.", "grounding_specificity_rationale": "The reviewer mentions 'the experimental strengths of this approach' and 'the proposed algorithm' generally. While they specify the number of networks (40) and the alternative method (vanilla Adam), the initial claim about the experimental strengths is 1 in a specific part of the paper or methodology. The grounding is present for the suggestion, but the connection to the initial claim is weak.", "verifiability_rationale": "The reviewer makes a claim about the experimental strengths of the approach and suggests an alternative. However, they do not provide any evidence, justification, or reasoning to support their claim. There is no logical reasoning, common knowledge, or external references provided to back up their assertion. The claim is presented without any supporting arguments.", "helpfulness_rationale": "The reviewer clearly identifies a potential weakness in the proposed method and offers a concrete alternative. While the alternative is valid, the reviewer does not explain *why* their alternative is superior or how it directly addresses the concerns raised about the original method. The feedback is presented as a suggestion without a clear 'so what?' factor. The authors are informed of a potential issue and given a different approach, but they are not guided on how to improve their original method based on this feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for a definition of Omega, which is an action. However, the action is vague as it doesn't specify how the definition should be presented or what aspects of Omega are important to understand. The reviewer also points out the broadness of OMD, which makes the action less concrete.", "grounding_specificity_rationale": "The reviewer asks for a definition of Omega, which implies they are referring to a specific concept in the paper. However, they do not explicitly identify the section, table, figure, or unique aspect where Omega is discussed. The grounding is implied but not precise.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity regarding Omega and OMD. While they provide some context (OMD being a family of algorithms and the regret guarantee), they do not provide specific examples or references to support their claim about the lack of clarity. The verifiability is somewhat lacking as the reviewer doesn't elaborate on *why* they find Omega and OMD unclear.", "helpfulness_rationale": "The reviewer's suggestions for improving the clarity of Omega and providing more details about OMD are specific and actionable. If the paper were revised to address these points, it would likely be helpful for readers trying to understand the concepts. The helpfulness is high because the suggestions are concrete and directly address potential areas of confusion."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests exploring videos with a longer duration, which implies using the LSTM over more time steps. However, the review point does not explicitly state how to implement this change or what specific modifications are needed. The suggestion is general and lacks concrete steps, making it difficult to directly apply the feedback.", "grounding_specificity_rationale": "The reviewer mentions 'short video sequences (e.g., 16 frames)' which provides a specific reference point within the paper. They also identify specific issues observed in these short videos, such as 'inconsistent motion, changing color, or object disappearing over time.' These observations are tied to the short video sequences, indicating a clear grounding in the experimental setup and results.", "verifiability_rationale": "The reviewer makes a claim suggesting that exploring videos with longer durations would be interesting. While the reviewer also states that the evaluation has limitations ('It would be interesting to videos with a longer duration (by running the LSTM over many time steps). In sum, this is a paper with an interesting idea and extensive experiments. While the results are still not perfect and seem to handle subtle motion, the quantitative and qualitative evaluation show clearly improved results over the previous stateoftheart.'), the reasoning for this claim is not explicitly provided. The claim is presented without a clear justification or evidence.", "helpfulness_rationale": "The reviewer's suggestion to explore longer videos is relevant to the identified limitations of the current evaluation. The reviewer provides examples of the problems observed in the short videos ('inconsistent motion, changing color, or object disappearing over time'), which provides some context for the suggestion. However, the suggestion itself is somewhat vague and lacks specific details on how to implement the change. While the reviewer indicates that the paper has strengths ('This is a paper with an interesting idea and extensive experiments. While the results are still not perfect and seem to handle subtle motion, the quantitative and qualitative evaluation show clearly improved results over the previous stateoftheart.'), the review point focuses on the *limitation* of the evaluation, making the helpfulness somewhat conditional on addressing that specific limitation."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a question and suggests an experiment. This is an explicit action. The action is also concrete as it asks about the outcome of an existing experiment.", "grounding_specificity_rationale": "The reviewer refers to \"numbers of bits in logits\" and \"PGD attack,\" which are specific concepts within the paper. While they don't explicitly name the section, table, or unique element, the terms are highly specific, indicating the reviewer understands the context and can identify the relevant parts. The comment specifies what needs to be addressed: the experiment and its expected outcome. Therefore, it can be considered 5 as it directly relates to a specific aspect of the paper.", "verifiability_rationale": "The reviewer does not explicitly state a claim. They pose a question and suggest an experiment. While their intuition about the relationship between bit precision and robustness could be considered a potential claim, the review itself does not contain a clear statement of a claim, a suggestion, or a judgment. Therefore, it is classified as having X.", "helpfulness_rationale": "The reviewer is suggesting an experiment and asking a question related to the paper's content. This could be helpful for the authors to understand the implications of their results and potentially strengthen their work. While it doesn't directly tell them what to change, it encourages them to think critically about their findings and consider the impact of bit precision on robustness. The suggestion to expand the experiment is also a helpful suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'The meta solvers seem to be centralized controllers' and provides a clear action for the authors: 'The authors should clarify the difference between the meta solvers and the centralized RL where agents share the weights.' This is a direct and actionable suggestion.", "grounding_specificity_rationale": "The reviewer refers to 'meta solvers' and contrasts them with 'centralized RL where agents share the weights.' While 'meta solvers' might not be a universally standard term within the specific subfield the paper belongs to, the comparison to a wellknown concept like 'centralized RL' provides a degree of grounding. The reviewer also mentions a specific citation, 'Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,' which further grounds the point by providing an example of related work. The reviewer also specifies what needs clarification: 'the difference between the meta solvers and the centralized RL where agents share the weights.'", "verifiability_rationale": "The reviewer is pointing out a potential ambiguity in the paper's description of 'meta solvers' and suggests that the authors should clarify the relationship to 'centralized RL where agents share the weights.' This statement itself is not definitively 'true' or 'false' in an empirical sense, but it highlights a potential point of confusion or lack of clarity that needs to be addressed. The reviewer is suggesting a logical next step for the authors, which implies a need for verification or clarification.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential point of confusion for the authors regarding the description of 'meta solvers' and their relation to 'centralized RL.' By suggesting that the authors should clarify this, the reviewer is providing a clear direction for improvement and highlighting a relevant area that could impact the authors' understanding and the overall quality of their work. This is a valuable piece of feedback that directly helps the authors refine their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly suggests providing examples to clarify M_T, which is a direct and actionable step.", "grounding_specificity_rationale": "The reviewer identifies a potential ambiguity in the definition of M_T on page 3, which grounds the issue, but the exact nature of the ambiguity remains unclear.", "verifiability_rationale": "The reviewer claims the notation for M_T is unclear, which could be verifiable if the original text is examined and the notation is indeed ambiguous or poorly explained.", "helpfulness_rationale": "The reviewer provides a clear and helpful suggestion to improve the clarity of M_T by providing examples, which directly addresses the potential lack of understanding."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment does not explicitly state what needs to be done. It uses vague language like 'modest' and 'further refinement' which do not provide clear actions for the author to take.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper being addressed. It refers to 'the observed performance enhancements' without specifying which ones or where they are located.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a statement of observation ('somewhat modest') and a suggestion ('further refinement').", "helpfulness_rationale": "The comment identifies a valid observation ('modest performance enhancements') and suggests a direction for improvement ('further refinement'). While it lacks specific action items, it provides a relevant and helpful feedback to the author."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the problem: 'the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method'. They also point to a specific comparison: 'since the performance is similar to IRM'. While the reviewer identifies a weakness, they don't provide a concrete action or suggestion on how to improve the experimental setup or analysis to address this unconvincing result. The reviewer identifies the *area* of concern and a *specific comparison*, but lacks a clear, actionable step to improve the experimental validation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the experimental results on the last two datasets' as the specific part of the paper being addressed. This is a clear and precise identification. Furthermore, the reviewer points to a specific comparison: 'the performance is similar to IRM'. This provides a concrete detail within the identified area. The reviewer's statement directly links the issue to a specific section and a specific performance metric (or comparison to IRM), making it highly specific and grounded.", "verifiability_rationale": "The reviewer states a claim: 'the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method' and 'the performance is similar to IRM'. However, the reviewer does not provide any justification or reasoning for these claims. There are no references to external works, logical arguments, or specific examples to support these observations. The reviewer simply states the observation without explaining why it is the case or how it should be addressed. The claim is presented without any supporting evidence or justification.", "helpfulness_rationale": "The reviewer identifies a problem with the experimental results: 'the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method'. However, the reviewer does not offer any specific solutions or actionable steps to address this issue. The reviewer also expresses a 'wonder if it is caused by the problems mentioned above' (referring to the similarity to IRM), indicating a lack of clarity on what needs to be improved. While the reviewer points out a problem, they do not provide any constructive feedback or guidance on how to resolve it. The reviewer's comment is primarily a statement of concern rather than a suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's question is framed as a statement of confusion rather than a direct instruction on what to do. While the question implies an implicit desire for clarification, it doesn't explicitly state an action or how to take that action. Therefore, it's not fully explicit. The action itself (asking for clarification) is somewhat concrete, but the lack of a specific method or expectation makes it less actionable than a suggestion to remove an entity or add a clarification.", "grounding_specificity_rationale": "The reviewer explicitly refers to the entities in Figure 2, even though they don't name the specific sections or tables. This indicates a degree of grounding. However, the reviewer doesn't specify *which* entities are being referred to or *why* both are necessary. The grounding is weak because the reviewer can't confidently identify the referenced part. The specificity is also weak because the question is about the *difference* rather than a specific detail within the entities.", "verifiability_rationale": "The reviewer is not making a claim that needs verification. They are simply asking a question about the paper's content. Therefore, it doesn't fit the definition of verifiable, which requires a claim to be evaluated. The *answer* to the question *could* be found in the paper, but the question itself isn't a claim that needs justification.", "helpfulness_rationale": "The reviewer is pointing out a lack of clarity in the paper's explanation of entity types and their differences. This is a constructive criticism aimed at improving the paper, which aligns with the goal of guiding authors (in this case, the reviewer is acting as an author seeking clarification). While the question itself isn't a direct solution, it highlights a specific area needing improvement. Therefore, it's 3 in identifying areas for clarification."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states \"I would like to see some experiments where the bounds are validated.\" This indicates an action: 'see experiments\". However, the phrase \"the bounds are validated\" is vague and doesn't specify what aspect of the paper or model these bounds refer to. Without this clarity, the reviewer's suggestion, while indicating a desire for improvement, lacks the specific action needed for the authors to act upon.", "grounding_specificity_rationale": "The reviewer refers to \"empirical validation\" generally, without specifying which part of the paper or model this validation is intended for. They don't mention a specific section, table, figure, or unique element of the paper. The request is quite broad and lacks the precision needed to pinpoint exactly where the authors should focus their efforts. Therefore, while the intent is clear (improving the paper through empirical validation), the grounding is weak.", "verifiability_rationale": "The review point contains a claim: \"I would like to see some experiments where the bounds are validated.\" This is a suggestion for improvement, not a critique of the paper itself. While the suggestion is positive, it lacks logical reasoning, common knowledge, or external references to support why this is a valuable improvement. The claim is presented as a desire for more experiments, but without specifying what those experiments should be or how they should be conducted.", "helpfulness_rationale": "The review point offers a constructive suggestion: \"I would like to see some experiments where the bounds are validated.\" This is a positive direction for improvement. However, the lack of specificity regarding the \"bounds\" makes it somewhat vague and less helpful than a very concrete improvement. The authors would benefit from more clarity on *which bounds* need validation and *how* this validation should be approached. Without this, the suggestion is somewhat broad and requires further elaboration from the reviewer. It's not a critique, but it lacks the detailed guidance needed for immediate action."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a belief about the meaning of 'chunks' and its relation to 'nonsequential information.' While the reviewer identifies a potential ambiguity, they don't explicitly state what *should* be done with 'chunks' to make them nonsequential. The suggestion to consider 'ordered units' is implicit.", "grounding_specificity_rationale": "The reviewer is pointing out a potential ambiguity in the paper's description of 'chunks.' They can identify the specific concept being questioned, but they don't specify what kind of nonsequential information is being referred to or how 'chunks' should be interpreted in this context.", "verifiability_rationale": "The reviewer is making a statement about their understanding of 'chunks' and its relation to 'nonsequential information.' This is a claim. The reviewer's statement is a definition, not a claim requiring external verification. It's a clarification of terminology.", "helpfulness_rationale": "The reviewer is seeking clarification, not criticism or suggestions for improvement. While their clarification is helpful, the *act* of seeking clarification isn't inherently 'helpful' in the sense of providing new information or guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point directly addresses a potential inconsistency in Theorem 1 by pointing out a scenario (a node with 0 neighbors) that seems to contradict the theorem's implication about the upper bound. The reviewer explicitly asks how this exception can be explained, which is a clear indication of an actionable issue. The action is to explain the exception, and the action is quite explicit.", "grounding_specificity_rationale": "The review point explicitly mentions 'Theorem 1' and the concept of a 'node with 0 neighbors'. This clearly grounds the comment in the specific part of the paper being discussed. The reviewer is directly referring to a specific element within the paper's content, making the grounding very precise.", "verifiability_rationale": "The review point requests an explanation for a potential exception to Theorem 1. This requires the authors to engage in logical reasoning and potentially consult external knowledge (if the theorem is standard). While the request itself is verifiable (it's a claim that needs justification), the explanation itself is not a verifiable fact within the review point. Therefore, it's partially verifiable.", "helpfulness_rationale": "The reviewer's question directly targets a core theoretical concept (Theorem 1) and its applicability to a specific scenario (nodes with 0 neighbors). This is a highly relevant and likely helpful question for the authors, as it seeks to clarify a key aspect of their work. The question directly addresses a potential weakness or area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point does not explicitly state what is wrong with the paper or how the authors should improve it. It only states that the paper has limited technical novelty and draws parallels to two other papers. There is no clear action or suggestion for the authors to take.", "grounding_specificity_rationale": "The review point does not specify which part of the paper is being addressed. While it mentions 'idea, coattention mechanism, and architecture,' it does not clearly identify the specific aspect of the paper that is similar to the mentioned papers. The reviewer is stating a general similarity without pinpointing the exact location or nature of the overlap.", "verifiability_rationale": "The review point contains a claim that the paper has 'limited technical novelty' and is similar to the two mentioned papers. However, it does not provide any specific evidence or references to support this claim. The reasoning is vague and lacks concrete examples or external references to back up the assertion of similarity.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper (lack of technical novelty) and suggests a comparison to related work. While this points to an area for improvement, it does not offer concrete suggestions or specific directions for the authors to take. It is a statement rather than a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests 'further analysis or solutions can be proposed' and 'why is GPTgenerated Rumor closer to Natural Rumor'. While the reviewer identifies a potential area for improvement, the action itself, suggesting further analysis, is explicit. The reviewer doesn't specify *how* to perform this analysis, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer states 'The paper points out the challenges of detecting rumors generated by GPT, but further analysis or solutions can be proposed' and 'why is GPTgenerated Rumor closer to Natural Rumor'. The reviewer does not explicitly identify a specific part of the paper being addressed, such as a particular section or table. The comment is more about a gap in the analysis rather than pinpointing a specific issue within the paper.", "verifiability_rationale": "The reviewer states 'The paper points out the challenges of detecting rumors generated by GPT, but further analysis or solutions can be proposed' and 'why is GPTgenerated Rumor closer to Natural Rumor'. This statement itself is a claim. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The claim is presented without justification.", "helpfulness_rationale": "The reviewer suggests 'further analysis or solutions can be proposed' and 'why is GPTgenerated Rumor closer to Natural Rumor'. While these suggestions are relevant, they are vague and lack concrete details on how to perform the analysis or what specific solutions should be proposed. The reviewer also states 'why is GPTgenerated Rumor about as difficult to detect as Natural Rumor?' which is a question that doesn't offer a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states an action: 'increase the font size'. This is a direct and concrete instruction for the authors to take a specific step to improve their draft.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 6' as the part of the paper being addressed. This is a literal mention and a clear identification of the specific element.", "verifiability_rationale": "The review point does not contain a claim. It is a suggestion for improvement rather than a statement that requires verification. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point directly identifies a weakness ('the font size is a little bit small') and provides a clear and actionable suggestion ('increase the font size'). This is a direct and helpful feedback for the authors to improve their draft."}
{"actionability_label": "1 and Not Specific", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer is questioning the fairness of comparing ChatGPT's accuracy to other models due to its higher abstention rate. They are not suggesting a specific action or flaw in ChatGPT's behavior, but rather questioning the validity of the comparison itself. Therefore, the comment does not identify a clear action or specific issue that needs addressing. The reviewer is essentially asking a question about a comparison, not providing a direct instruction or critique of a specific aspect of the model's output.", "grounding_specificity_rationale": "The reviewer's comment does not identify a specific part of the paper or model behavior being questioned. They are broadly criticizing the comparison of ChatGPT's accuracy to other models. Therefore, the comment lacks grounding specificity as it does not pinpoint a particular aspect of ChatGPT's performance or behavior.", "verifiability_rationale": "The reviewer's comment does not contain a claim that requires verification. They are raising a concern about the fairness of a comparison, but not presenting a specific assertion that needs to be supported by evidence. Therefore, the comment does not contain a verifiable claim.", "helpfulness_rationale": "The reviewer's comment is a critique of the comparison itself, not a specific suggestion for improvement of ChatGPT's output. They are questioning the validity of the comparison, which is a negative assessment of the utility of the comparison. Therefore, the comment is not helpful in providing actionable feedback to improve the model or the comparison process."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a design choice: 'a mono tonic relationship is imposed between the degree of a singletask predictor participation and the weight of the corresponding task loss'. They also suggest an alternative: 'Whether the mono tonic relationship can be replaced by other relationships?'. This clearly indicates an actionable point. The reviewer proposes a change and asks a question about its feasibility, providing a clear direction for the authors to consider. The action is 'to explore alternative relationships' and the method is to 'question the current monotonic relationship'. The reviewer provides a direct suggestion and a direction for improvement, making it 5.", "grounding_specificity_rationale": "The reviewer's comment is a general question about a design choice in the method. They do not explicitly point to a specific part of the paper (e.g., 'Section 3.2', 'Figure 4') or a particular element within that section. While the comment is about a specific aspect of the method (the relationship between predictor participation and task loss weights), the reviewer does not provide enough information for the authors to pinpoint exactly *where* this relationship is discussed or implemented in the paper. The comment is about the *concept* of the relationship rather than a specific instance of it within the text. Therefore, while the comment targets a specific aspect of the method, it lacks the specificity needed to ground the comment to a particular part of the paper.", "verifiability_rationale": "The reviewer does not present a claim that requires verification or justification. They are posing a question about an existing method and its design choice. There are no external references or logical arguments presented within the review point itself. The comment is a suggestion for the authors to consider an alternative to the current implementation. There is no assertion that something is wrong, needs to be supported, or requires further evidence. The comment is a suggestion, not a claim that needs verification.", "helpfulness_rationale": "The reviewer's comment is relevant and provides a clear direction for the authors to consider. They suggest exploring alternative relationships, which is a valuable piece of feedback. This comment is actionable and directly addresses a design choice in the method. While it doesn't provide a definitive answer or a specific alternative, it prompts the authors to think critically about the current implementation and consider alternatives. The reviewer's suggestion is a valuable point that could guide the authors' implementation and potentially lead to improvements in the method. The comment is not vague or unhelpful, but it doesn't provide a complete solution either."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a list of actionable suggestions for the authors to consider. They explicitly state what the authors should do, such as 'revisit the introduction,' 'focus on problems where the loss function does not decompose as the sum of sample losses,' and 'consider alternative distributed algorithms such as Hogwild'. These suggestions are concrete and point towards specific areas for improvement.", "grounding_specificity_rationale": "The reviewer's point is primarily directed at the introduction, where the goal of the paper is not clearly articulated. While the reviewer suggests specific areas for improvement (nondecomposable loss functions, Hogwild), the initial grounding of the comment is in the general area of the introduction. The reviewer's suggestions are somewhat general and could apply to various parts of the paper, although the core issue seems to revolve around the introduction. However, the reviewer does suggest a specific *type* of problem (nondecomposable loss), which provides some level of grounding. The comment is not entirely '1' because the core issue is about the introduction, and the reviewer suggests a specific area of focus within the paper.", "verifiability_rationale": "The reviewer provides suggestions and questions that are logically reasoned and suggest specific improvements. For example, they recommend 'revisiting the introduction' and suggest 'exploring alternative distributed algorithms like Hogwild' as potential solutions. While the reviewer doesn't explicitly provide external references in this specific point, the suggestions are based on common knowledge in the field of distributed algorithms and machine learning. The reasoning is clear and suggests concrete actions the authors should take.", "helpfulness_rationale": "The reviewer provides a list of suggestions and questions that are directly relevant to improving the draft. They suggest revisiting the introduction, exploring specific problem areas (nondecomposable loss functions, Hogwild), and questioning the relevance of samplingbased Bayesian methods. These suggestions are actionable and provide concrete directions for the authors to follow. The reviewer's comments are not just critical but also offer potential solutions, making them 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem (broken hyperlink) but does not specify how to fix it.", "grounding_specificity_rationale": "The comment explicitly mentions 'footnote 3 and 4', allowing the author to locate the issue precisely.", "verifiability_rationale": "The comment states a fact ('The hyperlink... do not seem to work') without making a claim that needs verification.", "helpfulness_rationale": "The comment identifies a weakness (broken hyperlink) but does not provide a suggestion or solution."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their suggestion to revise the modeling section and provides specific examples like 'better formalization' and 'external parameters'. While the reviewer doesn't detail *how* to achieve these, they clearly indicate a desire for improvement. This suggests a clear action the authors can take.", "grounding_specificity_rationale": "The reviewer refers to 'the modeling section' and mentions 'Label Embeddings'. While they identify the *area* of the paper, they don't pinpoint the exact line, paragraph, or element within the modeling section that needs revision. They also don't specify *how* the Label Embeddings are unclear or what aspect of them is problematic. This lack of precise identification makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer makes a clear claim: 'I suggest to revise a bit the discussion, especially in the modeling section...'. They then provide supporting evidence by stating 'which in its current form is not clear enough', 'For example, in section 2 it would be nice to see a better formalization', and 'If I understood correctly, the Label Embeddings are external parameters; instead, the figure is a bit misleading'. These statements provide logical reasoning and examples to support their claim.", "helpfulness_rationale": "The reviewer's comment directly identifies an area for improvement ('the modeling section') and provides a clear desire for change ('I suggest to revise a bit the discussion...'). While they don't specify the exact nature of the revision, the comment clearly indicates a need for the authors to address the clarity of the modeling section."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer states that the description of the neural network is 'hard to understand' and suggests starting the section with the clarification. While the reviewer identifies a problem, the suggestion to start with the clarification implies that the current version of the description is unclear. The reviewer does not explicitly state what is unclear, making the action implicit.", "grounding_specificity_rationale": "The reviewer refers to 'the section' and 'the final paragraph of the section' when identifying the relevant part of the paper. This indicates that the reviewer can accurately pinpoint the section and paragraph where the issue lies. However, the reviewer does not specify *what* is missing or unclear within that section or paragraph, making the specificity underspecific.", "verifiability_rationale": "The reviewer states that the description of the neural network is 'hard to understand' and suggests starting the section with the clarification. This statement is a claim that the description is unclear. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion to start with the clarification is a recommendation, not a claim requiring verification. Therefore, the claim is not wellsupported by evidence or justification.", "helpfulness_rationale": "The reviewer explicitly states that the description of the neural network is 'hard to understand' and suggests starting the section with the clarification. This directly addresses a potential point of confusion for the author and provides a clear direction for improvement. While the suggestion itself isn't a claim requiring verification, it is a concrete action the author can take."}
{"actionability_label": "3", "grounding_specificity_label": "X", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential limitation of the model's training (seems like the model is limited to CTC loss) and suggests an alternative training approach (train them towards attention based encdec training). While the suggestion is explicit about the *type* of training to explore, it lacks specific details on how to implement this change or what aspects of the model might need adjustment. The action of trying a different loss is implied but not concretely defined.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper or model architecture where the limitation might be occurring. It's a general observation about the model's training behavior. The suggestion to try a different loss is not tied to a specific section or table in the paper.", "verifiability_rationale": "This review point is a suggestion for improvement, not a claim that requires verification. There are no logical reasoning, common knowledge, or external references provided to support the suggestion.", "helpfulness_rationale": "While the comment suggests an alternative training approach, it lacks concrete details on how to implement this change. The suggestion is vague and doesn't provide specific guidance on what aspects of the model or training process need adjustment. Without more specific information, the reviewer is providing a potential direction for improvement but not a clear path for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the observation and asks a question, making it explicit. However, the action of investigating and potentially changing the division is not explicitly stated or concrete.", "grounding_specificity_rationale": "The authors can accurately pinpoint the section, table, figure, or unique aspect being addressed through the mention of 'Section 3' and the specific detail about 'tables divided into three types'.", "verifiability_rationale": "The reviewer expresses a wondering or a question about a specific detail, which can be considered a claim requiring justification. The request for clarification is a logical and understandable point, though not 5 with external references in this instance.", "helpfulness_rationale": "The review points to a valid area for clarification, but it's a very specific and localized concern. It doesn't address a major flaw or offer a broad suggestion. The impact on the authors' ability to improve their draft is limited."}
{"actionability_label": "2", "grounding_specificity_label": "1 and Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests considering other attack methods, which can be interpreted as an implicit action: 'Look at the limitations of the current attack methods and consider alternative approaches.' However, the reviewer does not explicitly state what the authors should do *now* or how to implement this suggestion. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer criticizes the paper's experimental setup regarding attack methods but does not specify *which* part of the paper or the draft this criticism directly addresses. The reviewer offers general suggestions without pinpointing a specific section, table, figure, or unique aspect of the paper. The grounding is implied but not explicitly stated.", "verifiability_rationale": "The reviewer claims that other attack methods are relevant for the paper's scope. This is a claim that needs to be supported. However, the reviewer does not provide immediate, detailed reasoning or external references within this review point to justify the relevance of these other attack methods. The claim is stated but not thoroughly verified within this review.", "helpfulness_rationale": "The reviewer provides suggestions for improvement by suggesting the use of other attack methods. This is helpful in that it points towards a potential area for strengthening the paper's evaluation. However, the suggestions are somewhat general and lack immediate actionable steps. The reviewer offers a direction for improvement but doesn't provide specific, detailed guidance on how to implement these suggestions within the current review context."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that mitigation methods affect image generation capabilities of diffusion models. This is an explicit action. However, the reviewer does not specify which aspects of image generation are affected or how this impact manifests. Therefore, while the action is explicitly stated, it is vague on how to execute it.", "grounding_specificity_rationale": "The reviewer mentions 'diffusion models' in general. While the reviewer identifies a specific area of the paper (image generation capabilities), they do not explicitly identify the specific part of the paper being addressed. The grounding is weak because the reviewer does not pinpoint the exact section, table, figure, or unique aspect of the paper being discussed.", "verifiability_rationale": "The reviewer makes a claim that 'mitigation methods affect the image generation capabilities of diffusion models, which can lead to lower image quality...'. This is a claim. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. The claim is stated without any backing, making it 1.", "helpfulness_rationale": "The reviewer points out a potential negative impact of mitigation methods on image generation quality. While this is likely to be helpful for the authors as it highlights a limitation of their approach, the lack of specific details makes the feedback less actionable and less helpful overall. The reviewer identifies a weakness but doesn't provide concrete suggestions or evidence."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a potential methodological flaw (leakage of information) that could affect the validity of comparisons. While the reviewer identifies a *potential* risk, they don't specify *how* this leakage occurs or what specific steps need to be taken to prevent it. This makes the action *vague*.", "grounding_specificity_rationale": "The reviewer is referring to 'such prior knowledge,' 'pretrained visual model,' and 'target dataset.' The reviewer mentions these elements but doesn't explicitly point to a specific section, table, figure, or unique aspect of the paper. This suggests *weak grounding*. The reviewer points out a *potential* issue related to these elements but doesn't detail *how* they leak information or what specific aspects of these elements are problematic. This suggests *underspecificity*.", "verifiability_rationale": "The reviewer presents a statement about a potential risk: 'There is a potential risk that the pretrained visual model and target dataset might leak additional information into the model, thereby skewing results and leading to issues of unfairness.' This is a claim that needs to be verified. However, the reviewer states the *potential* risk but doesn't provide any specific evidence, examples, or references to back this claim up. The language is speculative ('might leak,' 'could skew results').", "helpfulness_rationale": "The reviewer points out a potential methodological flaw (leakage of information) that could affect the validity of comparisons. While the reviewer highlights a concern that authors might need to consider, they do not offer any specific solutions or actionable steps for the authors to take to address this issue. The focus is on *identifying* the problem rather than providing a solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer expresses surprise at the dominance of function words and suggests they may not understand Japanese. While they point out a phenomenon, the explicit action to take based on this observation is not clearly stated. They could have suggested checking word counts or explaining the phenomenon, but they didn't. The action is implied but not explicit.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 1' and identifies the issue with 'function words' and 'content words' within that specific figure. This demonstrates strong grounding as they accurately pinpoint the section being discussed. The specificity comes from identifying the *types* of words involved and applying it to the content of the figure.", "verifiability_rationale": "The reviewer states a claim ('I am a bit surprised...') but does not provide any evidence or justification for this observation. They are expressing a reaction rather than logically deducing or citing external references. There is no logical reasoning, common knowledge, or external references provided to support the claim.", "helpfulness_rationale": "The review point primarily expresses surprise and a potential misunderstanding. While it highlights a potential issue with the writing, it does not offer any concrete suggestions or actionable advice to the authors. The reviewer is not providing a solution, only pointing out a symptom."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their suggestion: \"I think the minimal kmeans objective over multiple seeds is more reasonable.\" This is a clear and direct action. Once the action is identified (proposing a different baseline calculation), the reviewer also provides a reason (it's more reasonable) and references to support this claim. Therefore, the action is not only explicit but also concrete as the reviewer specifies the exact change. The references further enhance the concreteness by providing evidence for their claim.", "grounding_specificity_rationale": "The reviewer directly addresses the calculation of the baseline kmeans objective. They specify the exact term they believe should be used: \"the minimal kmeans objective over multiple seeds.\" This clearly identifies the specific aspect of the paper being addressed. The reviewer also provides reasons for this suggestion, indicating a clear understanding of why this might be better. Therefore, the grounding is fully grounded. The reviewer also specifies what they believe is better (the minimum objective) and why, making the grounding specific.", "verifiability_rationale": "The reviewer makes a declarative statement: \"I think the minimal kmeans objective over multiple seeds is more reasonable.\" This constitutes a claim. The reviewer provides a reason for this claim: \"It's more reasonable.\" Furthermore, the reviewer provides references to support their assertion: 1 Jin, Chi, et al. \"Local maxima in the likelihood of gaussian mixture models: Structural results and algorithmic consequences.\" Advances in neural information processing systems 29 (2016): 41164124. 2 Fr\u00e4nti, Pasi, and Sami Sieranoja. \"Kmeans properties on six clustering benchmark datasets.\" Applied Intelligence 48.12 (2018): 47434759. These references provide evidence to support the reviewer's claim, making it 5.", "helpfulness_rationale": "The reviewer's suggestion directly addresses a specific methodological choice in the paper (the calculation of the kmeans baseline). By proposing the use of the minimal objective instead of the average, they are providing a concrete and actionable improvement for the authors. This suggestion is likely to be helpful as it could lead to a different interpretation of the results and potentially different conclusions about the performance of the algorithms. The reviewer also provides a reason for their suggestion, indicating a clear understanding of why this might be better. The provided references further support the claim, making the suggestion more impactful. This is a specific and targeted improvement, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question about the relationship between temperature and uncertainty calibration, which implies a need for clarification on how to apply these concepts. The question 'Could the authors clarify this point?' directly points to an actionable suggestion. While the reviewer doesn't state the action explicitly, the question itself is a clear indication of a need for more information on how to apply the calibration techniques. The reviewer also asks a question about the regularization term H, which implies a need for clarification on its effect. The reviewer's questions are clear and directly address the application of the methods.", "grounding_specificity_rationale": "The reviewer refers to specific lines (155160 and 133136) and mentions the regularization term H. This indicates some level of grounding as the reviewer is referencing specific parts of the paper and a particular component. However, the grounding is weak because the reviewer doesn't explicitly state which part of the paper is being addressed. While the mention of H suggests a focus on the calibration process, the exact section or table where the confusion arises isn't pinpointed. The reviewer also doesn't specify what needs to be addressed regarding H, making the grounding less precise.", "verifiability_rationale": "The reviewer raises a point that seems contradictory to the stated motivation. They state that reducing entropy makes predictions more confident, which is against the paper's motivation to calibrate networks that are already overconfident. This suggests a lack of sufficient justification or clarity regarding the role of H and its connection to the paper's goals. The reviewer's confusion indicates that the explanation of H's effect is not fully convincing or clear enough to be considered 5. The reviewer's questions stem from a lack of clarity in the paper's explanation of the calibration process and the role of the regularization term.", "helpfulness_rationale": "The reviewer's questions and confusion directly stem from the paper's content. While the questions are valid, they stem from a lack of clarity and potentially contradictory information. The reviewer's confusion about the order of operations and the effect of H makes the review point 3 in highlighting areas of confusion, but it is not entirely clear and actionable. The reviewer's questions are valid and point to areas where the paper could be improved, but the lack of a clear resolution makes the review point somewhat ambiguous."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'Important reference missing' and names the specific paper 'Lista' with its URL. This is a clear and direct action that the authors can take to address the identified issue.", "grounding_specificity_rationale": "The authors can accurately pinpoint the specific paper being addressed by stating 'the idea of unrolling, first proposed in, 'Lista''. They also clearly identify what is missing  the importance of discussing the relationship and differences with this work for proper context.", "verifiability_rationale": "The review point contains a claim: 'The paper is closely related to, and important to discuss in the context of, the idea of unrolling, first proposed in, 'Lista''. This claim is supported by the reasoning: 'While there are important similarities and differences between the proposed work and Lista, it is important that the paper talks about them and places itself in appropriate context.' This provides a logical justification for the importance of the missing reference.", "helpfulness_rationale": "This review point is 5. It directly identifies a crucial missing piece of information (a citation) and explains why it is important for the authors to address. The implications are that the authors need to understand and contextualize the work of Lecun and his team, which is directly related to their proposed method. This provides a clear direction for their revision."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the 'FLOT cost matrix' in 'Algorithm 1' is not defined. This directly identifies an actionable gap in the paper's description of a specific component.", "grounding_specificity_rationale": "The comment explicitly mentions 'Algorithm 1' when stating that the 'FLOT cost matrix' is not defined. This allows the reader to locate the specific part of the paper being referred to, indicating strong grounding. The comment also clearly identifies the issue as the lack of a definition, providing specific information about what is missing.", "verifiability_rationale": "The comment contains a claim that the 'FLOT cost matrix' in 'Algorithm 1' is not defined. While the comment itself doesn't provide verification, the implication is that this missing definition could hinder understanding or implementation of the algorithm. This makes the claim 3, as the absence of a definition would be evident if the paper were read. The comment also implicitly suggests that this is a necessary detail for the algorithm's clarity and reproducibility.", "helpfulness_rationale": "The comment identifies a specific missing element ('FLOT cost matrix') in 'Algorithm 1' and points to its potential lack of definition. This is a clear indication of a potential issue that the authors should address to understand and implement the algorithm correctly. While it doesn't specify what the cost matrix should be or how to define it, it highlights a concrete area for improvement and clarification."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the term 'connectivity' is misleading and explains why. It clearly defines what it means for 'connectivity' to be misleading (structural connections between the brain and body) and what it does not (something else). This provides concrete information for the authors to adjust their understanding of the term.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper where the misleading use of 'connectivity' occurs. While it points out the *nature* of the misleading use, it doesn't pinpoint the exact section, table, figure, or unique aspect being discussed. Therefore, the grounding is weak.", "verifiability_rationale": "The review point is a judgment about the terminology 'connectivity' and its potential misinterpretation. It doesn't present a factual claim that requires verification or support from external references. It's a critique of how the concept is being used, not a claim that *something is* or *is not* the case.", "helpfulness_rationale": "The review point is relevant to the authors as it highlights a potential ambiguity in the use of the term 'connectivity'. It encourages the authors to consider the specific meaning they intend when using this term and to ensure it aligns with the structural connections between the brain and body. This feedback is valuable for improving the clarity and accuracy of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out 'missing details' in related work, experiment, and writing. While this is a valid point, it doesn't explicitly state how to add these details or provide specific examples. The reviewer implies an action but lacks the concrete steps needed for the author to act upon.", "grounding_specificity_rationale": "The reviewer mentions 'related work,' 'experiment,' and 'writing' as areas needing improvement. While these are specific parts of the paper, the reviewer doesn't pinpoint the exact sections, tables, or figures within these broad categories. The grounding is present but not fully precise.", "verifiability_rationale": "The reviewer states the paper is 'not polished and not ready to publish' and lacks 'details.' This is a judgment about the paper's quality. However, the reviewer doesn't provide any specific examples, references, or logical reasoning to support this claim. The statement is a statement of opinion without evidence.", "helpfulness_rationale": "The review is critical and points out general shortcomings. While it identifies problems, it lacks specific, actionable suggestions. The criticism itself is 3 in highlighting weaknesses, but without concrete guidance, it's not 5 for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer clearly identifies a potential ambiguity in the method used to compare trajectories of different lengths. They specify the method used (padding with the last state) and point out a potential flaw (lack of normalization). The reviewer also provides a clear alternative (normalization) and explains the implications of the current approach. This is a direct and explicit identification of a problem and a proposed solution, making it 5 for the authors.", "grounding_specificity_rationale": "The reviewer explicitly states the problem being addressed: the comparison of trajectories with different lengths. They also clearly explain how the authors are addressing this problem (padding with the last state). Furthermore, the reviewer goes beyond identifying the problem and explains the potential consequences of the lack of normalization, making the grounding very clear and specific. The reviewer also mentions the implication for the distance increasing with trajectory length, adding further specificity.", "verifiability_rationale": "The reviewer provides a clear explanation of why the identified method of comparing trajectories with different lengths is problematic. They explain that padding can lead to a distance that increases with the length of the trajectory, potentially favoring longer trajectories. This explanation is logical and wellreasoned, making the claim 5. The reviewer also suggests a solution (normalization), further strengthening the verifiability of their point.", "helpfulness_rationale": "The reviewer's point is highly specific and directly addresses a potential ambiguity in the methodology. They clearly explain the issue with comparing trajectories of different lengths and propose a solution. The reviewer also explains the implications of the current approach, making it a very helpful point for the authors to understand and interpret their results. This level of detail and clarity is likely to be very beneficial for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the evaluation for SI 6.5 is different from Mnih et al. 7 because 'no human starts are used.' Authors can directly identify the change in evaluation methodology from this statement.", "grounding_specificity_rationale": "The review point explicitly mentions 'SI 6.5' and 'Mnih et al. 7' when describing the change in the evaluation process. This clearly identifies the specific section and related work being referenced, demonstrating strong grounding specificity.", "verifiability_rationale": "The review point states that the evaluation for SI 6.5 is different from Mnih et al. 7 because 'no human starts are used.' While it doesn't provide a justification for this change, it clearly identifies the difference in the evaluation process, making it 3.", "helpfulness_rationale": "The review point directly points out a change in the evaluation methodology for SI 6.5 by stating that 'no human starts are used.' This is a clear and actionable piece of information that would likely be helpful for the authors to understand the implications of this change on their results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of a metric for efficiency, which implicitly suggests the authors should report one. This makes the review point 3, as the authors know what they should do (report a metric). However, the reviewer doesn't specify *how* they suggest the authors should report the metric, making it only 2.", "grounding_specificity_rationale": "The reviewer refers to 'efficiency' in general, without specifying which part of the paper or what specific aspect of efficiency they are referring to. They are not pointing to a specific section, table, or figure. Therefore, the grounding is weak. The reviewer is criticizing the absence of a metric, not specifying what metric is needed, making it not specific.", "verifiability_rationale": "The reviewer claims the paper 'does not report any metric that shows it is more efficient to train with this proposed method.' This is a claim that can be evaluated for verifiability. However, the reviewer does not provide any evidence or reasoning to support this claim. They are stating it as a fact without backing it up. Therefore, the claim is 1. The reviewer is making a judgment about the paper's content without providing justification.", "helpfulness_rationale": "The reviewer identifies a weakness in the paper: the lack of a metric to demonstrate improved efficiency. They also suggest a concrete improvement: the authors should report such a metric. This feedback is helpful because it points out a deficiency and provides a clear direction for improvement. While the reviewer doesn't specify *which* metric, the suggestion is actionable."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer states they need more details about the statespace, continuity, actions, and the space theta lies in, indicating an implicit need for information. However, the specifics of how to obtain this information are not provided, making it vague on how to apply the action.", "grounding_specificity_rationale": "The reviewer is asking for information about the statespace, continuity, actions, and theta space in relation to the paper. While the information is relevant to the paper, the specific section or part of the paper where this information is crucial is not explicitly mentioned, leading to weak grounding. The specificity of the request is also low as it is quite general.", "verifiability_rationale": "The review point does not contain a claim in the defined sense of stating an opinion or judgment. Instead, it requests clarification on assumptions. While the assumption (statespace is finite and continuous) is implied, the justification for this assumption is not provided within the review point itself.", "helpfulness_rationale": "The reviewer's request for clarification is generally helpful for the authors as it addresses a potential gap in their understanding and the clarity of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X (X)", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a weakness in the object detection task (lack of accurate locations and poses for IoUbased metrics) and suggests an alternative (LiDAR segmentation). While the reviewer identifies a problem and proposes a different approach, the specific *action* the authors should take to improve their object detection task is not explicitly stated. The reviewer suggests focusing on accurate locations and poses, but doesn't detail how to achieve this within the object detection framework itself.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'LiDARbased segmentation' as a better alternative to object detection for their LiDARbased model. They also name specific benchmarks, 'KITTI and Waymo,' which are relevant to the task and evaluation metrics. This demonstrates strong grounding as the authors can identify the specific part of the paper (the object detection task) being addressed and the specific issues (accurate locations and poses).", "verifiability_rationale": "The reviewer expresses an opinion about the strengths of different pretraining approaches (colorization vs. segmentation). This is a subjective opinion and does not contain a claim that can be verified with logical reasoning, common knowledge, or external references. There is no evidence presented to support or refute this statement.", "helpfulness_rationale": "The reviewer provides a clear rationale for their critique, highlighting the limitations of colorizationbased pretraining for object detection, particularly in the context of IoUbased metrics. They suggest focusing on accurate locations and poses, which is a helpful direction for the authors. While the suggestion is focused on the task rather than the pretraining itself, it still offers valuable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "Partially Grounded and Specific", "verifiability_label": "Verifiable (4)", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out a potential problem in Algorithm 1, specifically the use of the same symbol $p$ for two different purposes. This directly identifies a need for clarification and action to avoid confusion for the reader. The reviewer is suggesting a concrete action: to use different symbols for the phase mixing probability and the dummy variable. The impact is clear: it directly addresses a potential ambiguity in the algorithm's description, making it more actionable for the reader.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly linked to a specific section, table, or figure in the original paper being reviewed. The reference is to 'Algorithm 1' in their own review document. While the reviewer can accurately identify the section of their own algorithm description where the potential confusion arises, the grounding is in their own review text rather than the original paper's structure. The specificity is high as the reviewer clearly identifies the conflicting use of the variable $p$.", "verifiability_rationale": "The reviewer makes a claim about a potential *confusion* in Algorithm 1 due to the dual use of the symbol $p$. This claim is verifiable based on common knowledge about variable naming conventions and the potential for ambiguity. The reasoning is logical and based on general understanding of algorithmic notation. There are no external references needed to understand the issue.", "helpfulness_rationale": "The reviewer's comment is 5 for the authors who would likely be implementing or understanding Algorithm 1. By pointing out a potential area of confusion, the reviewer provides a concrete suggestion for improvement in the algorithm's description. This actionable feedback can directly help the authors avoid misinterpretations and correctly implement the algorithm."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests *what could have been* added (additional benchmarking tasks outside of AitW) but does not specify *how* to add them or what specific tasks would be beneficial. The action is implicit.", "grounding_specificity_rationale": "The comment refers to 'AitW' but does not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The grounding is implicit.", "verifiability_rationale": "The comment expresses a preference for including benchmarking tasks outside of AitW, which can be seen as a suggestion or judgment. However, it does not explicitly claim that *including* these tasks is a necessary or improving change, nor does it provide specific examples of what those tasks *should* be. The justification is implied but not explicitly stated.", "helpfulness_rationale": "The comment suggests a valuable direction for improvement (more diverse benchmarking tasks) and highlights a potential area for expansion. However, it doesn't provide concrete suggestions on *how* to implement this change or what specific tasks would be appropriate. This makes it 3 as it encourages the authors to consider this area, but not fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer implies an action (clarifying the citation) but doesn't specify how to do it. The citation label '15' doesn't exist within the paper, and there's another paper with the same name, PointNet. This suggests a lack of clarity in how the citation is being used. While the reviewer doesn't explicitly state that the authors are confused about the citation, their point highlights a potential ambiguity that could hinder understanding. The reviewer's suggestion to use the full paper title is a concrete action that would address the lack of clarity.", "grounding_specificity_rationale": "The reviewer doesn't explicitly state which part of the paper they are referring to when mentioning the citation confusion. They are inferring that the authors might be struggling with the citation. This makes the grounding weak. However, the reviewer *does* specify the exact citation label ('15') and the paper it refers to ('PointNet'), making the specificity high. The reviewer is pointing to a specific issue (the citation label) but not directly identifying the location within the paper where this confusion arises.", "verifiability_rationale": "The review point does not contain a claim about the paper's content. The reviewer is pointing out a potential issue with the referencing. Therefore, this is classified as 'X' (X).", "helpfulness_rationale": "The reviewer's suggestion to use the full paper title instead of the citation label is a helpful suggestion. It directly addresses a potential ambiguity in the referencing and could improve the clarity of the paper. While it doesn't directly address a flaw in the content, it is a helpful suggestion for improving the presentation and understanding of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer raises questions about the optimality of the policy gradient method and suggests a clarification. While the questions imply an action (suggestion that it might not be optimal), the action is not explicitly stated as a concrete step the reviewer should take. The reviewer is pointing out a potential area of confusion.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Eq. 6' and 'Eq. 5' and 'Line 132', clearly identifying the specific part of the paper being addressed. This demonstrates a high level of grounding specificity.", "verifiability_rationale": "The reviewer raises a valid point about the connection between the algorithm and the optimal solution. However, the claim itself is a question about the method's properties, which can be argued as implicitly suggesting a need for justification. The reviewer doesn't explicitly state *why* they think it might not be optimal or what evidence they have.", "helpfulness_rationale": "The reviewer's questions are directly relevant to understanding the method and its limitations. They provide actionable feedback by pointing out a potential area of confusion and suggesting clarification. The suggestion to clarify notation is also actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about a specific methodological choice (using a general Gaussian distribution instead of an isotropic one). While it doesn't explicitly state an action to be taken, it implies a desire for clarification on the implications of this choice. The reviewer is asking 'Is it possible to assume the general gaussian distribution rather than isotropic gaussian in the proposed algorithm? What is the difference?' This directly relates to understanding the method. The reviewer is seeking to understand the impact of this specific choice on the algorithm's performance. The reviewer is asking a question that directly relates to the method description, making it 3 in terms of seeking clarification.", "grounding_specificity_rationale": "The reviewer asks about the 'general gaussian distribution' and the 'isotropic gaussian distribution'. While the paper likely uses these terms or concepts, the reviewer doesn't explicitly point to a specific section, table, or figure where these distributions are discussed. They can infer the relevance based on the context of probability distributions and algorithms. Therefore, the grounding is weak. The reviewer is asking about specific concepts (Gaussian distributions) within the paper, making the grounding somewhat specific.", "verifiability_rationale": "The reviewer's question implies a need for justification or explanation regarding the difference between the two Gaussian distributions and their impact on the algorithm. If the paper doesn't provide this, the comment is 1. The reviewer is asking for a comparison and a possibility, which implies a need for justification or explanation. The paper *should* explain these distributions and their differences in the method section. If the paper doesn't, then the reviewer's request is 1. The reviewer is asking for a comparison and a possibility, which implies a need for justification or explanation.", "helpfulness_rationale": "The reviewer's question directly addresses a methodological choice (Gaussian distribution) within the paper. It's likely to be helpful for the authors in understanding and potentially improving their own work if they use a similar algorithm. However, it's a question, not a direct solution, so it's not 5. The reviewer is asking a question that directly addresses a methodological choice in the paper. It's likely to be helpful for the authors in understanding and potentially improving their own work if they use a similar algorithm. However, it's a question, not a direct solution, so it's not 5. The reviewer is asking a question that directly addresses a methodological choice in the paper. It's likely to be helpful for the authors in understanding and potentially improving their own work if they use a similar algorithm. However, it's a question, not a direct solution, so it's not 5."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "2 (3)", "verifiability_label": "3 (3)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer points out a potential issue with the partitioning strategy and suggests discussing its limitations. While the reviewer implies an action (discussing limitations), the action is not explicitly stated or detailed. The reviewer does not specify how the limitations should be discussed or what aspects of the limitations are relevant. Therefore, while the reviewer identifies a weakness, the specific action and its implementation are not clearly defined.", "grounding_specificity_rationale": "The reviewer refers to 'Line 192' and the concept of 'partitioning' in their comment. While they mention the specific location (Line 192), they do not explicitly identify the specific section, table, figure, or unique aspect of the paper being addressed in relation to the partitioning. The grounding is implied but not precisely stated. The reviewer mentions the *idea* of limitations but doesn't specify *what* part of the paper is being partitioned and what specific issue is being discussed.", "verifiability_rationale": "The reviewer states a concern about the 'risk' and 'strong assumptions' of freezing the partitioning in the first iteration. This constitutes a claim that requires justification. The reviewer suggests discussing the limitations, which could provide justification. However, the reviewer does not provide specific examples or references to external works to support their claim about the limitations. The verifiability is limited to the suggestion itself, which could be expanded with more details.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the partitioning strategy and suggests discussing its limitations. This provides the authors with a specific area for improvement and a potential concern to address. While the reviewer does not offer concrete solutions or detailed explanations of the limitations, the suggestion itself is a valuable piece of feedback that can guide the authors in refining their approach. The reviewer's comment is not entirely void of value, even if it lacks specific details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks 'why not average with type accuracy, for example?' This points to a missing justification or explanation for a specific action (using link prediction accuracy for early stopping). While the reviewer identifies the *action* (asking why), the *implementation* (link prediction accuracy) is already present in the paper. Therefore, it's 3, but the lack of explanation makes it not fully actionable yet.", "grounding_specificity_rationale": "The reviewer directly asks a question about a specific part of the paper's methodology: 'The decision to do early stopping only by link prediction accuracy should be explained...'. The reviewer is trying to pinpoint the specific aspect of the paper being addressed and asks for clarification. This indicates strong grounding as the reviewer is actively engaging with the paper to understand the reasoning behind the choice.", "verifiability_rationale": "The reviewer's comment is a question about a methodological choice, not a claim that can be verified. The paper does not explicitly state the reasoning behind choosing link prediction accuracy for early stopping, nor does it provide external references to support this decision. Therefore, the claim (if any implicit) is not wellsupported, making it 1 to the authors.", "helpfulness_rationale": "The reviewer's question directly addresses a methodological choice made in the paper (using link prediction accuracy for early stopping). By asking 'why not...', the reviewer is prompting the authors to provide justification for this decision. This is a relevant and actionable feedback for the authors, making the review point 5."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the paper 'prunes ...' but doesn't specify how the pruning was done. This is an implicit action (identifying the need for more detail) that is vague (no specific method provided). The reviewer suggests the comment is 'implied' but not 'explicit.'", "grounding_specificity_rationale": "The reviewer can identify the general area of the paper being discussed  lines 238239 and the concept of sensitivity. However, they cannot pinpoint the exact specific detail about the pruning method within that section. The specificity of the 'sensitivity' concept itself is low (they don't know how it's calculated), but the grounding aspect is about where the lack of detail is being pointed out.", "verifiability_rationale": "The reviewer states a problem: 'Authors don't explain the detail on how the ground truth of sensitivity is achieved...'. This is a claim. However, the reviewer doesn't provide any evidence or justification within the review point itself to support this claim. They are stating it as a problem without backing it up with a logical reasoning, common knowledge, or external references within this review point.", "helpfulness_rationale": "The reviewer points out a valid missing detail in the experimental methodology. However, they don't explicitly state why this lack of detail is a significant problem for the authors. While it's a valid point, it's a specific detail within a general area (sensitivity). The helpfulness is moderate as it points to a potential issue without explicitly connecting it to the authors' current work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the proposed approach 'still requires carefully choosing basis functions and meshes and assembling stiffness matrices (i.e., in the specific case of the present work, it is heavily relying on FEniCS)'. This clearly indicates an action that needs to be taken, namely, the selection and implementation of these components. The implication is that the approach is not entirely independent of these FEM aspects.", "grounding_specificity_rationale": "The reviewer mentions 'basis functions,' 'meshes,' 'stiffness matrix assembly,' and even specifies the software 'FEniCS' in their critique. This demonstrates a high level of specificity in identifying the components of the approach that still require FEM expertise. The reviewer can accurately pinpoint the specific parts of the method that are being criticized.", "verifiability_rationale": "The reviewer's statement that the approach 'still requires carefully choosing basis functions and meshes and assembling stiffness matrices (i.e., in the specific case of the present work, it is heavily relying on FEniCS)' is a claim that, while true, lacks specific justification or examples within this review point itself. The reviewer is stating a limitation but doesn't provide evidence *within this point* that operator learning *can* solve FEM's problems. The verifiability relies on external knowledge or future work, not on the information presented in this review point.", "helpfulness_rationale": "The reviewer's point that the approach 'still requires carefully choosing basis functions and meshes and assembling stiffness matrices (i.e., in the specific case of the present work, it is heavily relying on FEniCS)' is a valuable critique. It highlights a significant limitation: the approach is not entirely universal and still demands expertise in FEM components. This directly impacts the potential usefulness and accessibility of the proposed method for authors who might not be familiar with these specific FEM details. The reviewer is effectively pointing out a lack of 'new' universality."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paragraph is unclear and difficult to understand. They also point out that the explanation of dashed lines is vague and lacks detail on how to apply the action. The reviewer suggests improvements by clarifying the paragraph, explaining the Gittins strategy, and improving the figure's clarity. These are all concrete actions the authors should take.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'this paragraph' (L156166) and even attempts to label the potential issue with dashed lines ('Dashed lines indicate that the agent can plan ahead...'). This clearly identifies the specific part of the paper being addressed, making the grounding fully specific.", "verifiability_rationale": "The reviewer claims the paragraph is unclear and difficult to understand. While they don't provide external references, they offer a reason (their personal difficulty) which can be considered a form of implicit verification. They also point out the vagueness of the explanation for dashed lines, indicating a lack of clarity. The mention of the Gittins strategy, though not directly in the paper, suggests a potential gap that needs addressing, adding a layer of verifiability by highlighting a missing detail. The reviewer's statement about the figure being 'hard to understand' also points to a lack of verifiability in that aspect.", "helpfulness_rationale": "The reviewer raises several concrete points for improvement. They identify a significant issue (lack of understanding) and suggest specific actions the authors should take (clarify the paragraph, explain the Gittins strategy, improve figure clarity, clarify dashed lines). While the explanation of dashed lines is vague, the other suggestions are clear and actionable. The reviewer's overall sentiment is one of concern about the paragraph's clarity and a desire for improvement, making the review 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states a fact about the limitations of the approach. It doesn't directly tell the author what to change or how to improve. While the reviewer mentions 'I am not sure how large these inputs needs to be', this is a statement of uncertainty, not an explicit action or suggestion for improvement. The lack of explicit guidance makes it difficult for the author to take the next step. Therefore, the review point is not actionable.", "grounding_specificity_rationale": "The review point explicitly refers to the 'bounds' of the approach, grounding the discussion in the technical aspects. However, the reviewer then states 'I am not sure how large these inputs needs to be'. This introduces an element of uncertainty related to the practical application of the bounds, which is not explicitly detailed in the paper. While the technical aspect is grounded, the practical implication is not fully specified, making the grounding partially specific.", "verifiability_rationale": "The review point presents the statement 'I am not sure how large these inputs needs to be'. This is a statement of uncertainty or a question about the implications of the previous statement. It does not provide any external references or logical reasoning to justify why the author is unsure about the input size. The reviewer is stating their own uncertainty without providing supporting evidence. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The review point highlights a limitation of the approach, specifically that it might limit applications due to the 'o(1) terms' and the uncertainty about the 'input size'. However, the review itself does not provide any concrete steps or suggestions for the author to address this limitation. While the reviewer points out a potential issue, they do not offer a direct solution or actionable steps for the author to take. The lack of direct guidance reduces the helpfulness of the review. Therefore, the review point is not 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point asks a question and suggests an area for exploration. It does not explicitly tell the authors what to change or how to improve their draft. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer mentions 'DVP' and 'video' but does not specify which part of their work or method these refer to. The grounding is implied but not explicitly pointed out.", "verifiability_rationale": "The review point is a question, not a statement that makes a claim or judgment about the paper. It does not present a verifiable statement that requires justification.", "helpfulness_rationale": "The review point raises a question about an existing method without providing any direct feedback or suggestions for improvement related to the authors' work. It's more of a comment on external work than a direct critique or suggestion for the authors' paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their confusion about whether the paper targets singletoken or multitoken cloze queries. This indicates a lack of clarity in the paper regarding the scope of the work. While the confusion is resolved in the conclusion, the initial lack of clarity means the reviewer did not immediately know what action they should take to understand the paper better or potentially improve it. The reviewer's statement implies a need for a direct explanation of the task type early in the paper.", "grounding_specificity_rationale": "The reviewer's confusion about the type of cloze queries is not tied to a specific section, table, or figure within the paper. They are expressing a general lack of clarity regarding a core concept (single vs. multitoken). The reviewer could have inferred the answer by reading the introduction or the problem statement, but they did not. Therefore, while the issue is not '1' in the sense of missing a section reference, the lack of a clear explanation of the task type makes it difficult to pinpoint where the confusion arises.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are pointing out a lack of clarity in the paper itself. There are no references to external works or logical reasoning needed to address their confusion. The statement is more of a request for clarification than a claim that needs to be supported.", "helpfulness_rationale": "The reviewer's statement, while pointing out a valid issue, is not immediately helpful because the information is not clearly presented early in the paper. The reviewer *expected* a clear statement about the type of cloze queries, but it was only resolved in the conclusion. This delay in clarity makes the feedback less actionable at the time the reviewer is trying to understand the paper. The feedback is valid, but its immediate helpfulness is limited by the lack of clarity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of connection between Section 2 and the methodology, but the *how* is not specified. This makes the comment 3, as the authors know *what* is wrong (a disconnect), but not *how* to fix it.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"Section 2\" and \"methodology section,\" providing full grounding. They also specify the *nature* of the issues (lack of connection, simplistic analysis) and even reference a specific work 1, making the grounding highly specific.", "verifiability_rationale": "The reviewer makes claims about the issues in the paper. However, they do not provide any evidence, reasoning, or references to support these claims. The claims are presented as opinions without justification.", "helpfulness_rationale": "The reviewer identifies two areas for improvement, showing that the review has value. However, the lack of specific, actionable suggestions makes the review less helpful than it could be. The feedback is informative but lacks concrete guidance on how to implement the changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question and suggests a direction for further discussion. While it doesn't explicitly state what to do, it points to a specific area of the loss function and its relation to specularities, making it 3. The reviewer is suggesting a *type* of situation to explore, rather than a direct, stepbystep improvement.", "grounding_specificity_rationale": "The review point asks a question about the behavior of the loss function in specific situations (specular areas). While it doesn't explicitly name a section or subsection, it implies a connection to the loss function and its properties. This can be considered weak grounding as the reviewer is hinting at a specific aspect of the method being discussed. The lack of a direct section reference makes it not fully grounded.", "verifiability_rationale": "The review point contains a suggestion for further discussion, which can be interpreted as a claim. However, it doesn't provide any justification or examples to support this claim. The suggestion is vague and doesn't offer a logical reasoning or external references to back it up. Therefore, it is 1.", "helpfulness_rationale": "The review point suggests a direction for further discussion, specifically about the behavior of the loss function in specular areas. This is a valuable piece of feedback as it guides the authors towards exploring a specific aspect of their method. While it doesn't provide a concrete solution, it points towards a relevant area for further investigation and potential future work, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states what is missing ('how to determine n_t') and what is unclear ('what does 'appropriate number' mean'). This is explicit and actionable for the authors to improve their draft.", "grounding_specificity_rationale": "The reviewer points to a specific location in the paper (Algorithm 2) where the missing definition should be. This is strong grounding. They also point to a specific line (225) where the ambiguity exists.", "verifiability_rationale": "The reviewer points out the absence of a definition for n_t in Algorithm 2 and the lack of clarity in the term 'appropriate number', indicating a lack of verifiability.", "helpfulness_rationale": "The reviewer clearly states the impact this has on the authors: they need to define n_t and understand the meaning of 'appropriate number'. This is directly beneficial for their work."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "1 (1)", "verifiability_label": "X (X)", "helpfulness_label": "3 (3)", "actionability_rationale": "The comment asks a question but doesn't provide a specific action or suggestion on how to address the reproducibility issue.", "grounding_specificity_rationale": "The comment is a general question about code availability and doesn't specify which part of the paper the reproducibility issue is related to.", "verifiability_rationale": "The comment is a question, not a statement making a claim that needs verification.", "helpfulness_rationale": "The comment raises a valid concern about reproducibility, which is helpful context. However, it doesn't offer specific advice or suggestions on how to improve the situation, making it 3 but not 5."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a discrepancy between the claim and the experiments but doesn't explicitly state what the author should do to address this. The action is implied \u2013 the author should consider the limitations of the experimental support for the claim. Therefore, while the reviewer identifies a problem, the specific action to take is not clearly laid out. This falls under the threshold for being '4' where the action is inferred, but it's not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions \"the mixing time is even better\" as a claim. This claim is not explicitly tied to a specific section, table, figure, or unique aspect of the paper. The reference is general. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim (\"the claims that 'in practice the mixing time is even better' are not nearly sufficiently supported by the experiments\") but does not provide any evidence or reasoning to support this claim. There are no logical arguments, references, or examples given to back up their assertion about the insufficient support. This makes the claim 1.", "helpfulness_rationale": "The reviewer highlights a limitation in the current discussion of mixing time and points out that the claims might be overreaching based on the experiments. This encourages the authors to be more cautious and critical in their interpretation of their results. While it doesn't provide a specific solution, it identifies a potential area for improvement and forces the authors to reevaluate their claims."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a change to the representation of the feature A, indicating an actionable step. However, it doesn't explicitly state the action to be taken (e.g., 'Change A to a vector'), making it only 3.", "grounding_specificity_rationale": "The review point is a general suggestion and does not specify which part of the paper or element it refers to. Therefore, it is 1.", "verifiability_rationale": "The review point is a question, not a claim that requires verification. Therefore, it has no verifiability.", "helpfulness_rationale": "The review point is a relevant suggestion that points towards a concrete change (representing A as a vector). While it lacks specific implementation details, it offers a clear direction for the authors to explore and is therefore 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their belief that the proposed method is related to selftraining in semisupervised learning, making the action clear and actionable. They identify a potential weakness and suggest a direction for the authors to explore.", "grounding_specificity_rationale": "The reviewer mentions 'selftraining methods in semisupervised learning' as a point of comparison, which grounds the comment to a specific area of related work. However, they do not specify a particular section, table, figure, or unique aspect within that field, making the grounding weak.", "verifiability_rationale": "The reviewer makes a claim that the method is 'not very novel' and 'related to a common way to incorporate unlabeled data'. However, they do not provide any specific evidence, examples, or logical reasoning to support this claim, making it 1.", "helpfulness_rationale": "The reviewer's comment is a direct criticism of the novelty of the proposed method. While it prompts the authors to consider related work, it does not offer specific suggestions for improvement or alternative approaches, making it not particularly helpful in terms of actionable feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the issue: 'A feature comparison with prior work is shallow' and suggests a concrete improvement: 'missing two relevant papers'. The reviewer is directly pointing out a weakness and providing a clear direction for the authors to improve their feature comparison.", "grounding_specificity_rationale": "The comment explicitly mentions 'a feature comparison with prior work' and then specifically identifies the missing elements as 'two relevant papers'. This clearly points to the specific aspect of the paper being addressed, making it fully grounded. It also specifies what needs to be addressed in this part, making it highly specific.", "verifiability_rationale": "The comment contains a claim: 'A feature comparison with prior work is shallow, missing two relevant papers.' While it doesn't provide external references or logical reasoning to *verify* why the comparison is shallow or why those specific papers are missing, it clearly states the claim and identifies the missing papers, making it 3 as it points to specific issues.", "helpfulness_rationale": "The comment is highly specific about the weakness in the related work section (shallow feature comparison) and suggests concrete improvements by adding 'two relevant papers'. This directly addresses a likely area of confusion for the authors and provides a clear next step for them to take, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the use of the word 'equivalent' at specific line numbers. This directly points to a potential area for clarification or verification, making it an explicit action. The specific line numbers provide a clear target for further investigation, making it concrete.", "grounding_specificity_rationale": "The comment explicitly mentions the specific line numbers (8, 56, 70, 93) where the word 'equivalent' is used. This directly identifies the part of the paper being addressed, making it fully grounded. The comment also specifies the word 'equivalent' itself, clearly indicating what needs to be examined, making it fully specific.", "verifiability_rationale": "The comment contains a claim that the use of 'equivalent' at the specified lines needs more caution. However, it does not provide any specific justification, examples, or references to support this claim. Therefore, it is not independently verifiable based on the information given. It implies a need for further investigation or clarification, but lacks concrete evidence within the review point itself.", "helpfulness_rationale": "The comment identifies a potential issue with the use of the word 'equivalent' and suggests being more cautious. While this points towards a need for further action and provides a direction for improvement, it does not offer a specific solution or detailed guidance. Therefore, it is helpful but lacks the depth of a fully comprehensive suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their lack of understanding of the multiview clustering approach and asks specific questions about the dominance of the paraphrase similarity view. They also suggest a concrete action: a more detailed analysis of the different views and clustering techniques. This makes the point both explicit and concrete.", "grounding_specificity_rationale": "The reviewer mentions 'multiview clustering approach' and then focuses on the 'paraphrase similarity view' and its dominance. While they don't have a specific section number, they are clearly referring to the methodology section discussing different views and clustering techniques. This can be considered weak grounding as they could be more precise. However, the reviewer clearly specifies the issue (dominance of paraphrase similarity) and the area (clustering techniques), making it somewhat specific.", "verifiability_rationale": "The reviewer makes a claim about the dominance of the paraphrase similarity view and its impact on understanding the usefulness of other views. However, they do not provide specific examples or references to external work to support this claim. The suggestion for further analysis is a potential avenue for verification but is not a direct verification of the claim itself. Therefore, the claim is 1.", "helpfulness_rationale": "The reviewer raises a valid concern about the multiview clustering approach and its interpretation. They highlight a potential gap in understanding and suggest a concrete action: further analysis. This point provides a clear insight and constructive feedback for improvement, making it 5 to the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly names the metrics 'BertScore' and 'BLEURT' and suggests a concrete action: 'maintain consistency'. This action is directly actionable and clearly defined.", "grounding_specificity_rationale": "The comment refers to 'BertScore and BLEURT' generally, without specifying a particular section, table, or figure. While the unique aspect of the metrics is implied, the grounding is not explicit. The specificity of the comment regarding the *problem* of the inconsistency is also limited.", "verifiability_rationale": "The comment itself does not contain a claim that requires verification. It's a suggestion for improvement. However, the *implied* suggestion to 'maintain consistency' could be interpreted as a judgment or recommendation, making it 2. There is no external reference or logical reasoning provided within the review point itself to support the value of this suggestion.", "helpfulness_rationale": "The comment points out a minor, arguably unnecessary, inconsistency in referencing. While it suggests a change, it lacks a clear explanation of *why* this inconsistency is a problem or *how* maintaining consistency would benefit the paper. The impact is likely very small and not welljustified."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point does not explicitly state an action or provide a solution. It poses a question for further investigation: 'I\u2019d be interested to know if other multilingual pretraining setups also struggle with Greek.' This is a question, not a directive for improvement, making it not explicitly actionable.", "grounding_specificity_rationale": "The reviewer mentions 'Greek' as a potential cause. While this grounds the possibility, the explanation is limited to identifying the language without specifying *why* it might be problematic or how it differs from other languages. The grounding is present, but it's not fully specific.", "verifiability_rationale": "The reviewer makes a claim: 'I\u2019d be interested to know if other multilingual pretraining setups also struggle with Greek.' This is a claim that can be verified by checking other models. The reviewer also provides a suggestion: 'This is a plausible and verifiable hypothesis. It's based on common knowledge about multilingual models and the challenges of handling different languages.' The suggestion is a plausible alternative explanation that can be tested.", "helpfulness_rationale": "The review point is helpful in prompting the authors to consider an alternative explanation for the observed issue. It encourages them to investigate whether the problem lies specifically with the Greek language or a more general issue with multilingual pretraining. This is a constructive suggestion for improving their draft by exploring different possibilities."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The action is explicitly stated as 'manually observed' (Explicit). However, the reviewer does not specify what was observed or how the observation was conducted, making it vague on how to apply this feedback (Concrete). Therefore, while the action is identified, its implementation is unclear.", "grounding_specificity_rationale": "The comment explicitly mentions 'line 293295' (Weak Grounding). However, it does not specify what aspect of the examples in that section is unclear or difficult to understand (Specificity). Therefore, while the section is identified, the specific issue within that section is not pinpointed.", "verifiability_rationale": "The comment contains a claim that 'It would be difficult for readers to understand and evaluate' (Claim). While the reviewer offers a suggestion ('manually observed') as a potential explanation, this suggestion lacks specific examples or references, making the claim somewhat undersupported (Verifiability).", "helpfulness_rationale": "The review points out a potential issue with the clarity of writing in a specific section (Clarity). While this is a valid concern, the suggestion provided ('manually observed') is vague and lacks concrete details, making it less immediately helpful for the authors to improve their draft (Constructiveness)."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment suggests using realworld datasets instead of synthetic datasets. This is a clear action that the authors can directly implement. The suggestion is explicit and does not require further interpretation. The authors know exactly what change they should make.", "grounding_specificity_rationale": "The comment does not specify which part of the paper it is addressing. It is a general suggestion about the type of datasets to use. The authors cannot confidently determine which aspect of the paper this comment refers to. While the comment identifies a potential issue (synthetic datasets vs. realworld datasets), it does not pinpoint a specific problem within the paper itself.", "verifiability_rationale": "The comment contains a claim that 'it is better to conduct experiments on real world datasets instead of the synthetic datasets(at least for the outofdistribution setting.)'. This is a statement of opinion or judgment about the experimental setup. While the suggestion is for improvement, the claim itself is not supported by any specific evidence or reasoning within the review point. The reviewer is making a judgment about what would be a better experimental approach, but lacks justification for this claim.", "helpfulness_rationale": "The comment suggests using realworld datasets to address the limitations of synthetic datasets in the context of realistic scenarios in disentangled representation learning. This is a relevant and potentially helpful suggestion for improving the paper's aims. However, the comment lacks specifics on *why* synthetic datasets are problematic in this context and *how* realworld datasets would solve those problems. The suggestion is a good direction but lacks the detailed guidance needed for immediate implementation."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a potential area for improvement (vague explanation) but does not explicitly state how the author should address it. It's a pointer rather than a direct instruction.", "grounding_specificity_rationale": "The comment explicitly mentions \"the last paragraph of Section 3 (lines 207210) on the single image case,\" clearly identifying the specific part of the paper being addressed.", "verifiability_rationale": "The comment is a question and a suggestion for improvement, not a claim that requires verification. It doesn't make a definitive statement that can be judged as true or false.", "helpfulness_rationale": "The comment points to a potential issue (vague explanation) but does not provide specific, actionable steps for the author to take. It's a pointer rather than a direct instruction or suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of considering only one truck and one drone and poses a clear question about extending this to multiple vehicles. The action of identifying this limitation and suggesting an extension is direct and actionable for the authors.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'ONE truck' and 'ONE drone,' accurately identifying the specific part of the paper being addressed. The suggestion to extend to 'multiple trucks and drones' further specifies the area for improvement. The grounding is strong as the parts are clearly identified.", "verifiability_rationale": "The reviewer makes a statement about the current scope (considering one truck and one drone) and poses a question about the feasibility of extension. While the verifiability of the current scope depends on the paper's content, the suggestion itself is a logical and verifiable next step in the field of multivehicle systems. The reviewer is not making a judgment about the quality of the singlevehicle approach but rather suggesting a natural progression.", "helpfulness_rationale": "The reviewer clearly identifies a limitation in the scope of the work and provides a constructive suggestion for improvement. The question about extending to multiple trucks and drones is a valuable point that would help the authors consider more complex scenarios and potentially guide future research directions. The feedback is directly relevant and actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points to a specific issue (confusion about the number of biases) and explicitly mentions a hyperparameter (`num_baselines`) in the code related to the feedforward models in section 3.4. This directly identifies a concrete action the authors should take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'section 3.4' and 'the num_baselines parameter', which directly identifies the specific part of the paper and the relevant code. This allows the authors to precisely pinpoint the issue.", "verifiability_rationale": "The reviewer makes a claim about the missing hyperparameter and provides specific evidence (section 3.4 and the num_baselines parameter) to support it. This claim is verifiable through the code and the described section.", "helpfulness_rationale": "The reviewer clearly identifies a missing hyperparameter and explains its relevance to the desired shape and the confusion about C biases. This directly points to a necessary change the authors need to make."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "6", "helpfulness_label": "4", "actionability_rationale": "The review point asks for clarification on the relationship between the number of MC samples, performance, network structure, and empirical evidence. While it doesn't explicitly state what the author should do, it clearly indicates a lack of understanding in this area. The reviewer is implicitly suggesting the author look for empirical studies, but doesn't directly tell them where to find them or what to expect. Therefore, it's implicitly actionable but lacks explicit guidance.", "grounding_specificity_rationale": "The reviewer explicitly asks 'How does the number of MC samples affect performance, empirically?' and 'How does the network structure affect this?'. This directly points to a specific aspect of the method's behavior and asks for empirical evidence. The reviewer is not leaving the definition of 'network structure' ambiguous. They are asking about its *impact* on the MC sampling performance in an *empirical* way. The grounding is clear and specific to this question.", "verifiability_rationale": "The reviewer is not making a claim that needs verification. They are asking for information or a clarification. There are no logical statements, opinions, or suggestions being made. The request is framed as a question seeking understanding, not as a statement that requires justification. Therefore, there is X to verify, and the verifiability score is X (X).", "helpfulness_rationale": "The review point asks a question about a specific aspect of the method's behavior (the relationship between MC samples, performance, network structure, and empirical evidence). While this is a valid question that could be helpful for the author, it doesn't directly provide a solution or actionable steps. The reviewer is asking for information, not telling the author what to do. Therefore, it is 3 in identifying a gap in knowledge, but it doesn't offer a direct path to improvement. It's not 5 because it doesn't provide a definitive answer or a clear direction for the author's work."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desired action: 'show the smoothed GT shapes'. This action is directly tied to the identified areas in Figure 3 and Figure 5. The suggestion is not vague; it clearly states what should be added and where. The reviewer provides a direct instruction on how to potentially improve the understanding of the reconstruction quality.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 3' and 'Figure 5', providing a clear and accurate grounding of the suggested change. The suggestion is also specific, mentioning 'smoothed GT shapes' which implies a particular type of ground truth shape. The reviewer does not need to infer the location or the specific type of shape, making the grounding precise.", "verifiability_rationale": "The reviewer suggests a potential improvement to the readers' understanding of the reconstruction quality. While the suggestion itself isn't a claim that *must* be true, it's a valid suggestion that *could* be helpful. The reviewer implies that showing these shapes would allow readers to better assess the quality. This is supported by logical reasoning (improving understanding) and the existence of the figures where these shapes could be placed. The suggestion is not entirely unassailable, but it is a plausible and relevant suggestion.", "helpfulness_rationale": "The reviewer's comment directly points to a concrete and actionable improvement for the authors. Suggesting to show specific elements in figures is a clear and direct way to help the authors understand their results better. This is a valuable suggestion that directly addresses the potential lack of clarity in the figures."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point does not explicitly state an action or suggestion that the authors should take. While it identifies a potential issue (lack of direct comparisons), it does not provide a concrete action to address it. The reviewer points out a *potential issue* (lack of direct comparison) but doesn't recommend a specific action to address it.", "grounding_specificity_rationale": "The review point mentions 'language or vision tasks used to evaluate the proposed approach' but does not explicitly identify the specific part of the paper or the unique element being addressed. It is general about the comparison being missing. The grounding is weak because it identifies a problem but doesn't pinpoint the exact section or task where the comparison is lacking.", "verifiability_rationale": "The review point contains a claim that *there is a comparison of training loss in Section 3.4 and a comparison of the rank of possible solutions of the two approaches in Section 3.5 but without a direct comparison of test accuracy it is unclear if this approach is indeed an improvement over the baseline that it directly modifies*. The claim is supported by the mention of existing comparisons (training loss and rank of solutions) as evidence against the absence of a test accuracy comparison. The reasoning is that the absence of this comparison makes it difficult to assess improvement.", "helpfulness_rationale": "The review point is 3 because it identifies a valid concern (lack of direct comparison of test accuracy) and provides context by mentioning the existing comparisons of training loss and the rank of possible solutions. While it doesn't offer a direct solution, it raises a point that warrants further investigation and discussion. The reviewer provides reasons for their concern, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly identifies a problem ('inconsistent notation') in Section 2. However, it does not specify *which* notations are inconsistent or *where* in Section 2 this occurs. Therefore, while it points to an issue, it doesn't provide enough detail for the author to take immediate action.", "grounding_specificity_rationale": "The comment explicitly mentions 'Section 2', which is a specific part of the paper. It also identifies the issue as 'inconsistent notation', which is a specific type of problem. Therefore, the reviewer is grounded and specific about the area of concern.", "verifiability_rationale": "The comment points out a potential issue ('inconsistent notation') in Section 2. While it doesn't provide a definitive statement about the inconsistency, it sets the stage for the authors to investigate and verify the claim. It lacks external references or specific examples, making it 3 but not fully so.", "helpfulness_rationale": "The comment identifies a potential area for improvement ('inconsistent notation') in Section 2. This is helpful in that it highlights a specific point that needs attention. However, it lacks concrete suggestions or guidance on how to address the inconsistency, making it 3 but not very helpful overall."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests investigating the hyperparameter tuning process and the distance to the next best model. While this is a valid point, the reviewer does not explicitly state how to implement this investigation. They suggest checking the hyperparameter range but do not provide specific steps or criteria for determining if the chosen hyperparameters are at the end of the search range. Therefore, while the reviewer identifies a potential issue, the lack of concrete instructions makes the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'hyperparameter tuning' and specifically asks about the 'distance to the next best model'. While the context of hyperparameter tuning implies a specific section or area of the paper, the reviewer does not explicitly name a specific section, table, or figure. The reviewer also mentions the 'distance to the next best model' but does not define what this distance represents or how it is calculated. Therefore, the grounding is weak because the exact location and the specific metric are not clearly identified.", "verifiability_rationale": "The reviewer states that the SCNN getting 'lucky' on domain pricing is suspicious given the hyperparameter tuning. This can be considered a claim or a suggestion for further investigation. The reviewer proposes checking the hyperparameter range and the distance to the next best model as potential indicators of suspiciousness. However, the reviewer does not provide specific references or logical reasoning to support this claim. The suggestion itself provides a path for verification, but the claim itself requires further investigation. Therefore, the claim is present, and the suggestion provides a path to verification, but the verification itself isn't done.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the potential for randomness in model performance and suggests investigating the hyperparameter tuning process. The comment is relevant to the model selection and hyperparameter tuning aspects of the paper. However, the comment does not provide a definitive solution or a clear path to resolving the issue. It encourages the authors to look into the hyperparameter tuning process and the distance to the next best model, which can be a helpful suggestion for improvement. While it doesn't directly address the 'lucky' outcome, it prompts the authors to consider potential issues in their model selection process. Therefore, the comment is helpful in identifying a potential area of concern and guiding further investigation, but it doesn't offer a complete solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a general issue ('some aspects of the experimental setup were unclear or poorly motivated') but does not explicitly state what is unclear or how to improve it. The phrase 'see details below' indicates the information is not immediately available in the review point itself, making the action implicit and vague.", "grounding_specificity_rationale": "The review point mentions 'corpora and datasets' but does not specify which particular part of the paper or experiment these refer to. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part. The issue itself ('unclear or poorly motivated') is also not specifically detailed, making the specificity low.", "verifiability_rationale": "The review point states a problem ('some aspects of the experimental setup were unclear or poorly motivated') without providing any evidence or justification for why this is the case. There is X being made, only a statement of observation.", "helpfulness_rationale": "The review point identifies a valid concern about the experimental setup, which is a relevant aspect for authors to consider. By pointing out this issue, the reviewer is guiding the authors to pay closer attention to these aspects and potentially improve their methodology. While the specific details are deferred to 'details below', the general feedback is still valuable."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks a question about the size of the hourglass modules, which implies they are missing information. While the reviewer doesn't explicitly state what is missing, the question itself points to an actionable next step for the authors: go back to their paper and find the size of the modules. The reviewer is asking 'how big' each module is, suggesting they don't know the number of parameters or layers.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'hourglass modules' and the paper having '4 hourglass modules'. This is a clear and specific reference to the paper's structure. The reviewer is asking about the size of these modules, which is a specific aspect of the model. The grounding is strong because the reviewer is pointing to a specific part of the paper and asking about a specific detail within that part.", "verifiability_rationale": "The reviewer is pointing out a factual omission in the paper. They are not making a claim that requires evidence. They are stating a fact about what information is missing. The paper describes the model as having 4 hourglass modules but does not state the size of each. The reviewer is highlighting a gap in the information provided, not a claim that needs verification.", "helpfulness_rationale": "The reviewer is asking about the size of the hourglass modules to compare the model's size to competing approaches. While this is a relevant piece of information, the paper does not provide this information. The reviewer is highlighting a missing detail in the paper, not providing a concrete suggestion for improvement within the authors' own work. The feedback is about understanding the context of the work, not directly guiding the authors on how to improve their own model."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that the metric learning theory is 'basically comes from the generalization theory of neural networks' and that the paper's analysis 'does not give better results' compared to previous theoretical results. While the reviewer identifies a potential issue, the action taken is to state this observation rather than provide a concrete step or suggestion on how to improve the paper based on this finding. The reviewer points out a potential problem but doesn't offer a specific action to address it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the metric learning theory in this paper basically comes from the generalization theory of neural networks Bartlett et al. (2017)'. This directly identifies the specific part of the paper being addressed, making the grounding strong. The reviewer also specifies what is being criticized: 'the metric perspective analysis proposed in this paper does not give better results' and 'the part of metric learning does not seem to work', providing a clear and specific description of the issue.", "verifiability_rationale": "The reviewer makes a claim by stating 'Compared with the previous theoretical results, the metric perspective analysis proposed in this paper does not give better results' and 'From the existing content of this paper, the part of metric learning does not seem to work.' However, the reviewer does not provide any evidence or logical reasoning to support these claims within the review point itself. The statements are presented as observations without further justification or references to external sources.", "helpfulness_rationale": "The reviewer's comment is a critique of the paper's theoretical contribution regarding metric learning. While the criticism is specific and points to a potential issue, it does not offer any actionable suggestions or improvements. The reviewer identifies a problem but doesn't provide any guidance on how the authors should address it. The comment is diagnostic but not prescriptive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states actions the authors should take: 'move visual results from supplementary to the main paper' and 'condense the architecture figures'. These actions are clear and direct, indicating a strong intent to improve the paper's presentation. The reviewer is suggesting concrete modifications to the paper's structure and content.", "grounding_specificity_rationale": "The reviewer specifically points out the lack of visual results for the 'crowd density estimation' experiment, which forms the main experiment of the paper. This provides strong grounding as the reviewer is identifying a specific area where improvement is needed and highlighting the absence of visual support for this key aspect. The reviewer is not just saying 'the paper needs more visuals,' but rather specifying *where* these visuals are lacking.", "verifiability_rationale": "The reviewer suggests 'condensing the architecture figures'. However, the reviewer does not provide any justification or reasoning for why these figures should be condensed. There is X that these figures are redundant, unnecessary, or need to be removed. The suggestion is presented as a potential improvement without supporting evidence. Therefore, the claim is not wellsupported by any evidence, making it 1.", "helpfulness_rationale": "The review point suggests adding visual results to the main paper, which is a valid and potentially beneficial suggestion for the authors, especially for the crowd density estimation experiment. By highlighting this, the reviewer is pointing towards a concrete way to improve the presentation and potentially the understanding of the results. While the suggestion to condense the architecture figures is not verifiable, the overall intent of improving the paper's presentation is helpful. The reviewer is offering a potential improvement, even if the specific claim about condensation lacks justification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests using a different dataset (WebQuestions) instead of the current one (WebQuestionsSP). While this doesn't explicitly state an action to be taken by the authors, it implies a desire for improvement in terms of ease of use and comparability. However, it doesn't provide concrete steps on how to implement this change or what specific issues might arise from the switch. Therefore, while it points towards an actionable direction, the lack of explicit action makes it somewhat vague.", "grounding_specificity_rationale": "The review point suggests using a different dataset (WebQuestions) instead of the current one (WebQuestionsSP). It doesn't explicitly identify the specific part of the paper being addressed (the dataset choice). It also doesn't detail what is wrong with the current dataset or what needs to be improved in the new one. The grounding is weak because the reviewer doesn't pinpoint a specific section, table, or figure related to the dataset choice. The suggestion is general and doesn't target a specific aspect of the paper.", "verifiability_rationale": "The review point suggests using a different dataset (WebQuestions) instead of the current one (WebQuestionsSP). It doesn't contain a claim that requires verification. The suggestion is a preference or an alternative option, not a statement that needs to be supported by evidence or reasoning. Therefore, it doesn't fit into the categories of claim verification.", "helpfulness_rationale": "The review point suggests using a different dataset (WebQuestions) instead of the current one (WebQuestionsSP). This is a valid and potentially helpful suggestion for improving the accessibility and comparability of the work. By suggesting a more popular and potentially easiertouse dataset, the reviewer is offering a concrete alternative that could benefit the authors and the broader research community. While it doesn't provide a specific reason for the current dataset choice, it does propose a valuable improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "Not Applicable", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states that the desirability of sparsity is not obvious and that the benefits need to be demonstrated. While the reviewer identifies an area that requires clarification, the action of *identifying the lack of clarity* is explicit. However, the *specific action* of how to demonstrate the benefits is vague. Therefore, it's not fully actionable because the concrete step is missing.", "grounding_specificity_rationale": "The reviewer's comment is about the general concept of sparsity and its desirability, without explicitly pointing to a specific section, table, or figure in the paper. While the topic is specific, the reviewer doesn't clearly identify the *unique element* within that section that is causing confusion. The grounding is weak because the reviewer is making a general comment about a concept rather than a specific issue within a part of the paper.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are questioning an assumption about the desirability of sparsity. Therefore, this aspect does not fit the criteria for verifiability, as there is no explicit statement that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer's comment is critical of the motivation for introducing sparsity, stating that it is not obvious and that the benefits need to be demonstrated. This directly impacts the value of the review point for the author. The reviewer is essentially saying that the *why* behind the introduction of sparsity is not clear, which is a significant hindrance to understanding and potentially implementing it. This comment is highly detrimental to the author's ability to build upon the work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a *lack* of analysis on *other datasets*. While this is a valid point, the reviewer doesn't explicitly tell the authors *what* to do or *how* to do it. They suggest 'verifying the effectiveness of the framework on ImageNet1k or even ImageNet100' and 'presenting these results in the main paper'. The 'how' is missing, making it not fully actionable. However, it's not completely 1 as it identifies a clear area for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'other datasets (e.g., ImageNet derivatives)' and 'the framework'. This provides some grounding as they identify a specific area and the subject of analysis. However, they don't pinpoint a *specific* section, table, or unique aspect of the paper. The mention of 'e.g., ImageNet derivatives' is a general suggestion rather than a precise reference. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim: 'While the paper shows improvements on CIFAR derivatives, it lacks analysis or results on other datasets (e.g., ImageNet derivatives). Verifying the effectiveness of the framework on ImageNet1k or even ImageNet100 is important.' This claim is supported by logical reasoning ('While the paper shows improvements...') and the suggestion to 'verify...'. The reviewer also implies the importance of this analysis. Therefore, the claim is verifiable.", "helpfulness_rationale": "The reviewer clearly identifies a gap in the evaluation ('lacks analysis or results on other datasets') and suggests a direction for improvement ('verify the effectiveness...'). The suggestion to 'present these results in the main paper' is a constructive and actionable recommendation. While the 'how' isn't fully specified, the feedback is clear and points towards a concrete next step. The reviewer also implies the importance of this analysis, making the feedback relevant."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a discrepancy between the initial framing of BigFive and MBTI as models for extension and their later use as datasets in the experiments. This suggests a lack of explicitness in the action the authors should take. While the authors might implicitly understand the use of these datasets, the reviewer's point highlights a need for clearer instructions on how to utilize them. The action is present (using the datasets), but the explicitness and concreteness of the action are questionable.", "grounding_specificity_rationale": "The reviewer argues that the authors don't explicitly state why BigFive and MBTI are being used as datasets *unless* they provide a justification. The initial sections imply their importance, but the authors need to clearly identify the specific part of the paper they are addressing. The grounding is present (the datasets are mentioned), but the explicit identification of the referenced part is weak.", "verifiability_rationale": "The reviewer's comment doesn't explicitly contain a claim that requires verification. However, the underlying issue is that the *reasoning* for using BigFive and MBTI as datasets could be clearer. If the authors are suggesting a novel approach or extending existing models, this could be considered a claim that needs justification. The lack of explicit justification makes the comment somewhat 2.", "helpfulness_rationale": "The reviewer finds the comment not helpful because the authors haven't adequately explained the use of BigFive and MBTI, making it difficult to understand their role and potentially replicate the experiments. The lack of clarity and explicitness makes it challenging for the authors to apply the feedback. The comment doesn't directly identify a weakness or suggest an improvement, but it points out a lack of clarity, which hinders understanding and application."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential nuance in the paper's interpretation of the dataset analysis. They suggest that the conclusion about the relationship between readability and question difficulty might be too general and could depend on the specific features used for answer detection, such as POS/dependency parse features. This is an explicit statement of a potential issue and a concrete suggestion for the authors to consider. Therefore, the review point is 4 as it directly identifies a potential area for improvement in the analysis.", "grounding_specificity_rationale": "The reviewer's comment is not directly pointing to a specific part of the paper, such as a table or figure. Instead, they are making a general comment about the interpretation of the dataset analysis. However, they do specify that the potential issue might relate to 'featurebased methods' like POS/dependency parse features. This makes the comment somewhat specific in its suggestion, even if it doesn't pinpoint a specific section. Therefore, the grounding specificity is somewhat specific.", "verifiability_rationale": "The reviewer makes a claim that the paper's conclusion about the relationship between readability and question difficulty is too broad and might not hold for specific featurebased methods. This claim can be verified by considering common practices in dataset analysis, where the choice of features significantly impacts the results. The reviewer provides a basis for verification by suggesting specific types of features. Therefore, the review point is 4 as it provides a basis for evaluating the claim against the paper's methodology.", "helpfulness_rationale": "The reviewer's comment is constructive and points towards a potential improvement in the paper's analysis by considering featurespecific impacts. This suggests a clear direction for the authors to enhance their work. Therefore, the review point is 5 as it provides a concrete suggestion for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a specific imbalance in the space allocation between explaining 'basic memory networks' and the 'forward model', suggesting an action to adjust the length of these sections. They also mention that the 'related work' section lacks detail, implying a need for more specific examples or citations. While the general sentiment about improving writing quality is somewhat vague, the specific issues identified are concrete and actionable.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly pointing to a specific section, table, or figure in the paper. They are discussing the content of the 'basic memory networks' and 'forward model' sections and the 'related work' section in general terms. While they identify areas for improvement, they do not specify which exact part of the paper needs adjustment or what specific details are missing.", "verifiability_rationale": "The reviewer makes claims about the space allocation between 'basic memory networks' and the 'forward model' and points out a lack of detail in the 'related work' section. These claims are supported by common knowledge about the importance of clear structure and thorough literature review, and the reviewer suggests specific actions like adjusting the length and adding more detail or citations. The reasoning behind these claims is based on established principles, making the verifiability high.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as adjusting the length of sections explaining 'basic memory networks' and the 'forward model' and adding more detail or citations to the 'related work' section. These suggestions are concrete and directly address identified weaknesses, making the review point 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the change to P'o and its consequence on the reachability of the first state. They also state that this change is due to either Ass.1 or Ass.2. However, the reviewer does not provide concrete steps or suggestions for the author to address this potential issue. The reviewer identifies a problem and a possible cause, but lacks a clear action for the author.", "grounding_specificity_rationale": "The reviewer refers to 'Ass.1' and 'Ass.2' without explicitly naming them, which makes the grounding somewhat weak regarding the assumptions. However, the reviewer refers to 'the first column of Qo' and 'the first state', which are specific parts of the paper, providing full grounding regarding the location of the change. The reviewer also refers to 'the first state is not reachable anymore but from a terminating state', which is a specific observation. However, the reviewer does not specify which assumption is responsible for the change, making the grounding somewhat weak overall.", "verifiability_rationale": "The reviewer presents a potential issue ('I assume that either Ass.1... or Ass.2...') and a possible consequence ('this could lead to an infinite loop'). This constitutes a claim. However, the reviewer does not provide any external references or logical reasoning to support their assumption about which assumption is responsible. The reviewer's conclusion about the potential for an infinite loop is a logical deduction, but the basis for that deduction (which assumption is responsible) is an assumption, not a verifiable fact.", "helpfulness_rationale": "The reviewer points out a potential flaw in the theoretical construction (P'o) and suggests that this could lead to an infinite loop. While this highlights a potential issue, the reviewer does not offer concrete solutions or specific steps for the author to take to address this problem. The reviewer is essentially stating a concern and a possible cause, but lacks actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The suggestion is a general recommendation for the authors to explore alternative metrics (accuracy, specific properties) if their initial focus (FLOPs/inference time) doesn't yield improvements. It doesn't explicitly state what specific action the authors should take (e.g., 'Check the classification accuracy'), making it somewhat implicit.", "grounding_specificity_rationale": "The suggestion mentions 'accuracy or specific properties' without specifying which one or how to measure them. This lack of specificity makes it difficult for the authors to ground the comment in their work, resulting in weak grounding specificity.", "verifiability_rationale": "The suggestion is a recommendation based on the authors' own observation of no improvement in FLOPs or inference time. It doesn't present a claim that needs to be verified or supported by evidence. Therefore, it has X and is not verifiable.", "helpfulness_rationale": "The suggestion provides a practical alternative for the authors to explore if their initial focus doesn't yield positive results. It guides them towards investigating accuracy and specific properties, which can be valuable for improving their draft. While it's a suggestion rather than a direct solution, it is still helpful in directing their attention to potentially fruitful areas of improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point directly asks a question about a specific assumption regarding entity embeddings, making it 5. The reviewer wants to know if the assumption that d_e are good replacements for entity embeddings has been tested. This is a clear and direct request for information about a specific methodological choice.", "grounding_specificity_rationale": "The review point explicitly mentions 'd_e' and 'entity embeddings', clearly identifying the specific components being discussed. It also asks a direct question about whether an assumption has been tested, indicating strong grounding in the relevant concepts.", "verifiability_rationale": "The review point is a question about whether something has been tested. While it implies that the work relies on this assumption, it doesn't provide any evidence *within this point* to support or refute the testing. Therefore, it's not directly verifiable *within this review point*. However, it does point to a potential area where further investigation is needed.", "helpfulness_rationale": "The review point is clear, direct, and relevant to a key assumption about entity embeddings. It highlights a potential gap in the validation of a methodological choice, which could impact the reliability of the results. While it doesn't offer a solution, it effectively points out a potential issue that needs further attention, making it helpful in guiding further investigation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state an action or suggest a change to the paper. It is a critique of the scoring function itself, indicating a lack of clarity in how the components of the function were derived and the thresholds were set. Therefore, it lacks explicit and concrete actionable feedback.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or methodology that is unclear. It is a general statement about the scoring function's components and thresholds. Therefore, the grounding is weak as the authors cannot pinpoint the exact area needing clarification.", "verifiability_rationale": "The review point makes a factual statement about the lack of clarity in the derivation of the scoring function's components and thresholds. However, it does not provide any evidence or justification for why these were chosen in the first place. The claim that the authors arrived at different components and thresholds is presented without supporting reasoning or references. Therefore, the claim is 1 as it lacks sufficient evidence or justification.", "helpfulness_rationale": "The review point expresses a lack of clarity regarding the scoring function. While this might be helpful in identifying areas for improvement, the lack of explanation about how the components and thresholds were determined makes the feedback less helpful. The authors are left wondering why certain aspects were weighted more heavily or why specific thresholds were chosen. This lack of clarity reduces the overall helpfulness of the review point."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, not a statement that directly instructs or suggests an action. While it points to a potential area for improvement in the authors' description, the reviewer doesn't explicitly state what the authors should do to address this.", "grounding_specificity_rationale": "The reviewer explicitly states 'one simulation' which grounds the reference to a specific part of the paper. They also ask 'How many different kinds of physical interaction...', which clearly identifies the issue as the type of interaction. This provides a clear target for the authors to clarify.", "verifiability_rationale": "The review point is a question, not a claim that requires verification. Therefore, it doesn't fall under the 'Verifiability' aspect, which focuses on the presence and support of claims.", "helpfulness_rationale": "The review point directly addresses a potential area of confusion for the authors by asking about the types of physical interactions in their simulation. This is a valid point of clarification that could help the authors improve their writing by making their simulation description clearer."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the issues with the datasets and the modeling choices related to them. It suggests adding categorical features and specifically mentions onehot encoding for a dataset. The suggestions are clear and actionable.", "grounding_specificity_rationale": "The comment identifies specific aspects of the paper being addressed (datasets, categorical features, onehot encoding). While it doesn't explicitly name a section or table, the context implies it's referring to the datasets and the modeling choices related to them. The comment specifies what is missing (categorical features, lack of onehot encoding) and why it might be a problem (challenging, potentially negative performance).", "verifiability_rationale": "The comment contains a claim (the chosen selection of datasets is not adequate) and provides reasons for this claim (omission of categorical features, no onehot encoding). While it doesn't provide external references, the reasons are logical and based on common knowledge in machine learning.", "helpfulness_rationale": "The comment provides specific and actionable feedback on the identified weaknesses. It suggests adding categorical features and specifically mentions onehot encoding for a dataset. While the reviewer doesn't explicitly state that the datasets are 'not wide range' or the comparison is 'not thorough', these are implied consequences of the identified issues. The suggestions are likely to be helpful for the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the choice of datasets as a weakness and suggests alternative datasets. While the reviewer doesn't provide explicit steps for improvement, the suggestion of alternative datasets implies a clear action for the authors to take.", "grounding_specificity_rationale": "The reviewer directly mentions the specific datasets used by the authors ('FlatCam Face' and 'Headpose detection') and even suggests alternative, more common IoT datasets. This demonstrates a clear grounding of the criticism in the authors' choices.", "verifiability_rationale": "The reviewer claims the choice of datasets is a 'weird choice' and that this makes the benchmarking results 'hard to sense and evaluate'. While the reviewer doesn't provide direct evidence of the datasets' unpopularity, the suggestion of alternative datasets implies an understanding of their relevance. The claim about the results being 'hard to sense' is inferential but still grounded in the authors' choices.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the authors' experimental setup (the choice of datasets) and offers concrete suggestions for improvement (using alternative datasets). This directly addresses the authors' work and provides actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not contain an explicit or implicit action or suggestion. It poses a question about the content of the figures, not how to improve them.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper (e.g., 'Section 3.2', 'Figure 2b') that has been swapped. While it refers to 'Figs 1 and 2', this is a general reference and not a precise identification of a section or subfigure. The comment is also not identifying a specific issue within these figures that requires grounding.", "verifiability_rationale": "The review point does not contain a claim. It is a question posed to the authors, not a statement that requires verification.", "helpfulness_rationale": "The review point identifies a potential issue (swapped subfigures) that could affect the interpretation of the results. While it provides a question for the authors to consider, it does not directly suggest a concrete action or improvement. It is a question for clarification rather than a directive for change."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests 'increasing the risk of false positives should be a substantial part of the discussion.' This is a direct suggestion for the authors to address a potential drawback. While it doesn't explicitly state how to discuss it, it clearly points to a relevant area for improvement. The reviewer identifies a *discussion* area as the action.", "grounding_specificity_rationale": "The reviewer refers to 'dropout probe' and 'dropout probe improves sensitivity' as the specific part of the paper being addressed. This demonstrates a clear grounding of the concern. While the exact location of the 'dropout probe' discussion isn't explicitly named (e.g., 'Section 3.2'), the focus on the *method* grounds it. The concern about false positives is also tied to the *concept* of dropout, further grounding the specificity.", "verifiability_rationale": "The reviewer makes the claim 'all other things being equal, one should worry that this also increases the risk of false positives.' This is a judgment or suggestion about the implications of the dropout probe. While the reviewer doesn't provide specific evidence or citations to back up this claim about false positives, it is a reasonable concern based on general knowledge of dropout in machine learning. The claim is somewhat supported by logical reasoning about potential overfitting or noise sensitivity leading to false positives.", "helpfulness_rationale": "The reviewer suggests that 'all other things being equal, one should worry that this also increases the risk of false positives. I would think this should be a substantial part of the discussion.' This is a valuable suggestion that directly addresses a potential limitation of the proposed method. By highlighting this concern, the reviewer provides a concrete direction for the authors to improve their work. The reviewer identifies a *discussion* area and a *potential improvement* as the helpful actions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the regret bound for the minibatch method is *claimed* to be in the appendix and then clearly indicates that they *did not find* it there. This is an explicit statement of an action the authors should take (check the appendix) and is concrete in stating where they expect the information to be.", "grounding_specificity_rationale": "The reviewer provides a specific location (appendix) where they expected to find the regret bound. This is a literal mention of a section, making the grounding very strong.", "verifiability_rationale": "The reviewer provides a clear statement of their inability to find the regret bound in the appendix. This claim is directly supported by their search, making it 5.", "helpfulness_rationale": "The reviewer's inability to find the regret bound is likely to be a valuable piece of feedback for the authors, guiding them to the correct location. This specific feedback is likely to be helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the 'paper is not sound' and 'does not discuss and compare these methods'. This is a direct identification of a weakness and a clear suggestion for improvement. The reviewer names specific exploration methods (countbased, RND, ICM), making the suggestion concrete. The action is to discuss and compare these methods, which is actionable.", "grounding_specificity_rationale": "The reviewer names specific exploration methods (countbased, RND, ICM) when stating the paper 'does not discuss and compare these methods'. This grounds the criticism to a specific part of the paper. However, the reviewer does not specify *where* in the paper these discussions should occur or what specific aspects of these methods are lacking. The specificity of the grounding is limited to the types of methods, not the sections or details.", "verifiability_rationale": "The reviewer makes a claim that 'the paper is not sound' and 'does not discuss and compare these methods'. This is a claim that needs verification. However, the review point itself does not provide any evidence or justification for why the paper is unsound or why it lacks these discussions. The reviewer is stating their assessment, not providing a reason for it.", "helpfulness_rationale": "The reviewer clearly identifies a weakness ('the paper is not sound') and provides a concrete suggestion for improvement ('discuss and compare these methods'). This directly addresses a potential area for enhancement in the paper. The suggestion is specific and actionable, as it points to particular exploration methods and the desired outcome (discussion and comparison)."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and points to potential limitations, but it doesn't explicitly * tell the authors what to do next. While it implies that the model might be doing something unintended (inference getting slowed down and unidirectional prediction), it doesn't provide a clear path for the authors to address this. The point is somewhat vague and lacks specific guidance on how to resolve the identified issues.", "grounding_specificity_rationale": "The reviewer points to general issues like 'inference getting slowed down' and 'label prediction' without specifying a particular aspect of the paper or method. While the point touches on concepts, it doesn't clearly identify a specific section, table, figure, or unique element of the paper being addressed. The questions raised are also quite general and don't pinpoint a specific implementation detail. Therefore, the grounding is weak.", "verifiability_rationale": "The point makes claims about the implications of the model and raises questions about implementation details (coefficient of p(L, E | X)). However, it lacks specific references or explanations to support these claims. The reasoning is presented without clear citations or logical connections to existing knowledge, making it difficult to verify the claims fully. It is 3 in that it points to potential issues, but lacks the necessary supporting evidence to be fully convincing.", "helpfulness_rationale": "The review point raises valid concerns about the model's behavior and implementation details. It points out potential limitations and suggests areas for improvement. However, it doesn't offer concrete, actionable suggestions for the authors to implement or address the identified issues. The writing is also criticized, but the point doesn't directly link the writing issues to specific areas of the paper that need improvement. Therefore, while the point identifies problems, it doesn't provide sufficient guidance to be 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that \"the proposed compression performs worse than PQ\" when a 'small code length is allowed.\" This is an explicit statement about the performance of the proposed method relative to PQ under a specific condition. While it doesn't detail how it performs worse, it clearly identifies a weakness and a context for it. Therefore, it is 3 as it points towards a direction for improvement.", "grounding_specificity_rationale": "The review point refers to \"the proposed compression\" and \"PQ\". While it mentions the comparison is made \"when a small code length is allowed\", it doesn't specify the exact section, table, or unique aspect of the paper where these methods are discussed. The reviewer needs to infer which specific compression method and PQ implementation are being referred to. Therefore, the grounding is weak.", "verifiability_rationale": "The review point makes a claim: \"the proposed compression performs worse than PQ\". This is a judgment that requires some level of verification. The justification provided is \"when a small code length is allowed\", which offers a context for the comparison. However, it doesn't provide a detailed explanation, examples, or external references to support this claim. Therefore, the claim is 3.", "helpfulness_rationale": "The review point identifies a weakness (\"performs worse\") and links it to a specific condition ('small code length\"). This provides a clear direction for the author to focus their improvements. While it doesn't offer a detailed explanation of why it's worse, it highlights a specific area of concern. Therefore, it is 3 as it points towards a concrete area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out issues with subjective statements and the need for proofs, which are implicit actions. However, the reviewer does not explicitly state how to improve the subjective statements or what kind of proofs are needed. The reviewer also mentions multiscale methods and skip connections but does not specify how to fuse multiscale features or how to verify the implicit use of skip connections. The suggestions are broad and lack concrete steps.", "grounding_specificity_rationale": "The reviewer mentions 'subjective statements,' 'proofs and references,' 'multiscale methods,' and 'skip connections.' While they touch upon these concepts, they do not explicitly identify a specific part of the paper or table where these issues are present. The references are general, and the mention of 'skip connections' is broad, lacking a specific element of the paper being addressed.", "verifiability_rationale": "The reviewer makes claims about the laborintensive nature of finding the right architecture and the sensitivity of performance to architectural choice. They also state that multiscale design is daunting and that skip connections implicitly use multiscale information, requiring justification. However, the paper does not provide explicit reasoning or references to support these claims. The reviewer asks for a 'detailed explanation' to verify these statements, indicating a lack of inherent verifiability within the review point itself.", "helpfulness_rationale": "The review identifies potential issues with the paper, such as subjective statements and the need for more information. However, the suggestions provided are vague and do not offer concrete, actionable steps for the authors to improve their draft. The reviewer asks for 'proofs' and 'verification' without specifying what these proofs or verifications should entail. The call for a 'detailed explanation' is a request for more information rather than a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a desire for *more detailed analysis* regarding *language/nationality*. This is a clear action the reviewer is proposing.", "grounding_specificity_rationale": "The reviewer mentions *language/nationality* and even specifies the type of analysis *comparing biases*. This indicates they are targeting a specific aspect of the work.", "verifiability_rationale": "The reviewer is *suggesting* an analysis. While this is a claim, there's no concrete evidence or references provided to *verify* this suggestion. It's more of an idea for future work or potential avenues for exploration.", "helpfulness_rationale": "The reviewer's comment is about *future analysis*. While this could be valuable, it's not a direct critique of the current draft or an immediate, actionable improvement. It's more of a suggestion for further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point directly asks a question, 'Besides norm, is there any other property of features can be used?'. This implies the reviewer is suggesting exploring alternative approaches, which is an explicit action. However, the question is quite general and doesn't specify which alternative properties are being considered or how they might be useful, making it vague in its specific recommendations.", "grounding_specificity_rationale": "The reviewer asks 'Besides norm, is there any other property of features can be used?'. This question is about a general characteristic of features (beyond statistical norms). While it doesn't explicitly name a specific section or table, it's asking about a property of the features themselves. This could be considered weakly grounded as the authors can infer they need to consider different types of feature properties. However, the question is broad and doesn't specify what needs to be addressed, making it underspecific.", "verifiability_rationale": "The review point is a question, not a statement containing a claim. Therefore, it fits the 'X' category for claim extraction, meaning there is X to verify.", "helpfulness_rationale": "The review point is a question prompting the authors to consider alternative feature properties. While it encourages them to think differently about their features, it doesn't directly provide a solution or a specific direction to explore. It's a helpful prompt, but not a direct fix, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests improvements but doesn't explicitly state what needs to be done or how to implement them. It implies a need to 'broaden the scope' and 'include more diverse tasks' but lacks specific details.", "grounding_specificity_rationale": "The reviewer mentions 'tasks beyond link predict' and 'PE is important' but doesn't specify which tasks or provide concrete examples. The comment is vague and doesn't clearly identify a specific part of the paper being addressed.", "verifiability_rationale": "The review point contains a claim ('PE is important') and implies a lack of current diversity ('It is expected to see a variety of tasks beyond link predict where PE is important'). While the expectation is generally accepted, the claim isn't fully supported by specific references or logical reasoning within the review point itself.", "helpfulness_rationale": "The review point is relevant and points to a valuable direction for improvement in the paper. It encourages authors to consider a broader range of tasks and applications for Personalized Equations. However, it doesn't provide specific instructions on how to achieve this improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point asks for more information but does not explicitly state what needs to be done or how to achieve the desired outcome. It's a desire, not a directive. Therefore, it's not actionable.", "grounding_specificity_rationale": "The authors cannot confidently determine which part the comment addresses. Further, the comment does not specify what needs to be addressed in this part. The reviewer mentions other works but doesn't explicitly link them to a specific aspect of their own work.", "verifiability_rationale": "The claim about other works is supported by the mention of 'semantic face editing' and 'continuous control', but lacks specific details or references to external works within their own paper.", "helpfulness_rationale": "The review point is a question seeking information, not a critique or suggestion for improvement. It's more about understanding existing work than guiding the author to improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests moving important content to the main body and details to the appendix. These are implicit actions. While the reviewer doesn't explicitly state 'move this specific section to the main body,' the general suggestion implies an action. However, the action is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The review point does not explicitly refer to any specific part of the paper (e.g., 'the discussion section,' 'the methodology details'). It is a general comment about the overall structure and content. Therefore, it is 1.", "verifiability_rationale": "The review point expresses an opinion about the excessive use of footnotes and suggests structural improvements. Opinions are generally not considered verifiable. The suggestions are general and do not provide specific examples or justifications, making them not verifiable as claims.", "helpfulness_rationale": "The review point identifies potential issues with the paper's structure and suggests improvements. The suggestions are relevant and directly address the paper's presentation. However, the reviewer does not provide specific examples of 'important content' or 'detailed settings' that should be moved. The suggestions are general and lack concrete steps for the authors to take. The opinion about footnotes being 'too extensively used' is not supported by any evidence or reasoning."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the impact of the GS module on the effective receptive field, rather than providing a direct action or suggestion. While the question is relevant, it doesn't tell the authors what to do or how to implement a change.", "grounding_specificity_rationale": "The review point mentions the 'GS module' and 'effective receptive field' but does not explicitly identify a specific section, table, or figure in the paper. The reference to '2' suggests external context but doesn't ground the discussion within the submitted work.", "verifiability_rationale": "The review point is a question, not a declarative statement that requires verification or justification.", "helpfulness_rationale": "The review point asks a relevant question about a potential improvement (change in receptive field) and suggests consulting external work. This encourages the authors to consider the impact of the GS module and potentially explore further."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies potential weaknesses related to time complexity by pointing out the use of an itemoriented autoencoder, an elementwise function, and a large number of hidden units. However, the reviewer does not explicitly state what specific actions the authors should take to address these weaknesses or how to implement those actions. The criticism is more about the *characteristics* of the components rather than direct instructions.", "grounding_specificity_rationale": "The reviewer mentions 'the itemoriented autoencoder,' 'the elementwise function,' and 'the number of hidden units.' While they name these components, they do not explicitly identify the *specific* section, table, figure, or unique aspect within these components where the time complexity issue arises. The reviewer implies the problem based on the properties of these components. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim about the time complexity being high due to the mentioned components. They provide reasoning by stating that the autoencoder processes many users, the elementwise function is expensive, and the high dimensionality of hidden units contributes to the complexity. While they don't provide external references, the reasoning is logical and based on the properties of the components. Therefore, the claim is 3.", "helpfulness_rationale": "The reviewer points out potential inefficiencies in the proposed method, specifically the high time complexity. This directly addresses the authors' work and suggests areas for improvement. While the reviewer doesn't explicitly state concrete actions, the identification of a problem that affects the authors' method is generally helpful. Therefore, the review point is 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'improve the clarity of the figures.' It also identifies the specific components of the autoencoders that are potentially unclear: 'pretrained solution encoders & solution decoders.' This directly addresses the 'Explicit vs. Implicit' and 'Concrete vs. Vague' criteria. While the reviewer doesn't provide a specific method for improvement, the action is clear and directly points to an area needing attention.", "grounding_specificity_rationale": "The reviewer mentions 'multiple types of autoencoders' as a potential source of confusion. This implies they are referring to a specific part of the paper, likely the section describing the autoencoders. While they don't explicitly name a section number, the context strongly suggests they are referring to the description of the autoencoders. Furthermore, they clearly specify the components ('pretrained solution encoders & solution decoders') that are potentially unclear, making the issue specific.", "verifiability_rationale": "The reviewer's comment contains a claim in the form of a suggestion: 'improve the clarity of the figures.' While the suggestion itself isn't directly supported by evidence within the review point, the implication that the figures are unclear is a form of justification. The reviewer is pointing out a problem (lack of clarity) and offering a solution (improving clarity), which can be seen as a logical reasoning to identify an issue.", "helpfulness_rationale": "The review point directly addresses a specific area of the paper (the figures) and suggests a relevant improvement (increased clarity). The reviewer is providing constructive feedback and offering a direction for action. While the suggestion doesn't provide a specific *howto* improvement, it clearly identifies a problem and offers a constructive suggestion, making it helpful for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the absence of comparisons with NeRFbased methods and questions the relevance of the occlusion experiment. While the reviewer doesn't explicitly state what needs to be done, they identify specific areas for improvement. The lack of specific instructions makes the actionable part somewhat implicit.", "grounding_specificity_rationale": "The reviewer mentions 'NeRFbased methods' generally and refers to the 'occlusion experiment' without specifying details. This lack of specific references makes the grounding somewhat weak. While the topic of comparison and the experiment is mentioned, the specific elements being addressed are not clearly identified.", "verifiability_rationale": "The reviewer makes claims about the importance of comparisons with NeRFbased methods and the irrelevance of the occlusion experiment. However, they do not provide any evidence or justification to support these claims. The reasoning is present but lacks concrete examples or references.", "helpfulness_rationale": "The reviewer's comments are relevant and point out missing elements that would be beneficial for the authors. However, the feedback is relatively brief and lacks specific details on *why* these comparisons are important or *how* the lack of focus on occlusion affects the paper's contribution. The suggestions are present but lack depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment does not explicitly state an action or suggestion. It asks a question about implementation details, which is an implicit request for information. Therefore, it lacks a clear direction for the authors to apply the feedback.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper when asking for implementation details. It is a general request about the experiments. Therefore, it is 1 in a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The comment does not contain a claim. It is a question asking for information about the experiments. There is no assertion or suggestion being made, so verifiability is not applicable.", "helpfulness_rationale": "The comment asks for information about the computation required to implement the experiments, including time, hardware, and experimental setup. While this information is generally helpful for reproducibility and understanding the practical effort involved, it does not directly address a theoretical or methodological weakness in the paper itself. It is a request for implementation details rather than a critique or suggestion for improvement. Therefore, it is not 5 for improving the core aspects of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the model's behavior with imperfect multimodal data and doesn't explicitly state what needs to be done. While it implies exploring the model's robustness and investigating inference mechanisms, it lacks a clear, direct instruction for the authors. Therefore, it is not 5. It leans towards '2' as it points to a relevant area of investigation, but lacks a clear, direct instruction for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions 'multimodal data', 'imperfect', 'missing', 'higherorder interactions', 'polynomial tensors', and 'additional modalities'. It clearly identifies the specific aspects of the model and data being discussed. This indicates strong grounding. Therefore, it is '5'.", "verifiability_rationale": "The review point makes a claim about the model's behavior with imperfect data and asks a question about the impact on polynomial tensors. However, it does not provide any evidence, examples, or references to support this claim. The reasoning is speculative, and there are no external references provided. Therefore, it is '1'.", "helpfulness_rationale": "The review point raises a valid concern about the model's behavior with imperfect data, which is a relevant issue for authors to consider. However, it does not offer any concrete solutions or guidance on how to address this issue. It primarily asks a question for clarification rather than providing actionable feedback. Therefore, it is '3' as it points to a relevant area of investigation but doesn't offer direct solutions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors do not verify the stability of OGEAug on OOD benchmarks, which is an explicit action. Furthermore, the reviewer names the specific benchmark (DrugOOD) and the method to validate it (SPE), making the action concrete.", "grounding_specificity_rationale": "The reviewer explicitly identifies the area of concern as the 'stability of the OGEAug' and then specifies the 'OOD benchmarks such as DrugOOD' as the relevant area. This strong identification of the specific part of the paper being addressed makes the grounding fully grounded. The reviewer also specifies what needs to be addressed in this part, which is the lack of verification and the suggestion to use DrugOOD and validate SPE.", "verifiability_rationale": "The review point makes a claim: 'Authors don\u2019t verify the stability of the OGEAug on OOD benchmarks'. The reviewer then provides a suggestion to use DrugOOD and validate SPE as a way to address this claim. This provides a clear basis for verification. While the reviewer doesn't provide detailed justification for why DrugOOD and SPE are the best choices, they offer a concrete next step to validate the claim. The reasoning is logical, suggesting a specific method for verification.", "helpfulness_rationale": "The review point is 5 as it identifies a potential gap in the authors' evaluation (lack of OOD benchmark verification). It provides a clear and actionable suggestion (using DrugOOD and validating SPE) to address this gap. This directly empowers the authors to improve their evaluation methodology and potentially strengthen their findings. The suggestion is specific and points towards a concrete way to improve the assessment of OGEAug's stability."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a change (training on multiple seeds) and identifies a problem (difficulty assessing significance). The suggestion is concrete, stating 'multiple seed experiments' and implying 'more robust evaluation'.", "grounding_specificity_rationale": "The review point refers to 'Single Seed Experiments' and 'multiple seed experiments'. The reviewer can identify the specific type of experiment being addressed. While they don't name a specific section, the phrase is clear. The reviewer also mentions the impact on 'performance differences and the true impact of the proposed cycle consistency loss on convergence', adding some detail to the identified part.", "verifiability_rationale": "The review point contains a claim: 'Multiple seed experiments would provide a more robust evaluation.' However, it does not provide any specific justification or references to support this claim. The reasoning is stated as a suggestion rather than a verified assertion.", "helpfulness_rationale": "The review point directly identifies a limitation of the experimental setup (single seed experiments making it difficult to assess significance) and provides a clear suggestion for improvement (multiple seed experiments). This directly addresses a potential weakness for the authors and empowers them to make changes to their evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a question about the motivation behind using the VMF distribution and the truncated normal distribution. The action is clear: 'Why use the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector? The motivation behind this is unclear to me.' This directly addresses the 'why' aspect of the methodological choice, making it explicit. The reviewer also identifies an implicit action by asking for clarification, which the authors can use to understand the rationale. The concreteness is high as the reviewer is asking for a specific justification related to the angle and magnitude.", "grounding_specificity_rationale": "The reviewer is asking a question about the motivation for using specific statistical distributions. This question does not directly identify a specific part of the paper being addressed. The information is about the *why* of a methodological choice, not about a specific element within the paper. Therefore, the grounding is weak. The reviewer can make an educated guess that the motivation relates to the angle and magnitude, but this is not a precise identification of a section, table, figure, or unique aspect.", "verifiability_rationale": "The reviewer states a question about the motivation behind using specific distributions. This constitutes a claim (asking for justification). However, the review point itself does not provide any evidence or justification for *why* these distributions were chosen. The reasoning is missing within the review point itself. The reviewer is asking for a *justification*, but the review point only states the *what* (using VMF and truncated normal) without explaining the *why*.", "helpfulness_rationale": "The reviewer is asking for clarification on a methodological choice. This is a common and valuable piece of feedback for authors. The reviewer is likely to benefit from understanding the rationale behind using the VMF distribution and the truncated normal distribution for characterizing the angle and magnitude of the target vector. This information can help them understand the underlying assumptions and potentially improve their own work if they encounter similar situations. The request for clarification is likely to be helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review points out a *what* (a multiGPU setup is needed) but not a *how* or *why* (why is this necessary, how can this be addressed). This suggests it's likely *not actionable* in the sense of providing a direct fix. While the reviewer identifies a problem, they don't offer a concrete solution or suggestion for improvement. The lack of a proposed action makes it difficult for the authors to act upon the feedback.", "grounding_specificity_rationale": "The review mentions \"optimizations in the proposed method\" but doesn't specify *which* optimizations or *where* in the paper they are discussed. This suggests weak grounding. The authors cannot confidently determine which part the comment addresses. However, the comment does specify what needs to be addressed in this part (multiGPU setup for optimizations).", "verifiability_rationale": "The reviewer states \"An entire multiGPU setup is required for the optimizations in the proposed method\". This is a claim that needs to be supported. However, the review point does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a fact without justification.", "helpfulness_rationale": "The review identifies a valid concern (accessibility due to multiGPU requirements) but fails to provide any actionable feedback or suggestions. It's a *detriment* to the authors, highlighting a limitation without offering a path forward. The reviewer points out a problem but doesn't offer a solution or a way to mitigate it. The lack of helpful feedback makes it difficult for the authors to improve their work based on this review."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'Compare this system, which also captures semantics.' This is a direct instruction for the authors to address a gap in their current system. While the reviewer also mentions 'Ref2' as a potential baseline, this is presented as a suggestion rather than a direct action to be taken. The reviewer is indicating a need for comparison, but doesn't provide specific steps on how to perform it.", "grounding_specificity_rationale": "The reviewer refers to 'this system' and 'Ref2'. While 'Ref2' is a specific paper, 'this system' is vague and doesn't pinpoint a specific part of the current system being discussed. The grounding is weak because the reviewer is referencing existing entities rather than a specific aspect of their own work.", "verifiability_rationale": "The reviewer makes a claim: 'Even, Ref2 can be a strong baseline to compare the performance of the current system.' This claim is supported by the statement that Ref2 is a 'strong baseline'. The reviewer provides a justification for why Ref2 is a relevant comparison point.", "helpfulness_rationale": "The reviewer's primary goal is to provide suggestions for improvement ('suggestions to improve:'). The review point itself is more about pointing out a gap ('As the current system captures the semantics through RNN based models. So, it would be better to compare this system...') and offering a potential solution ('Even, Ref2 can be a strong baseline to compare the performance of the current system. Suggestions to improve:'). While the suggestions are relevant, the review point itself doesn't directly address a specific problem or propose a concrete solution in a detailed manner."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly states a missing detail ('how the quantitative results are obtained') and identifies a specific area within that detail ('how to implement the inferred action'). This fits the definition of explicit and concrete.", "grounding_specificity_rationale": "The comment doesn't explicitly state the dataset used or the specific splits for training, validating, and testing. It implies the existence of such data but doesn't provide the necessary specifics. This fits the definition of weak grounding.", "verifiability_rationale": "The comment points out a missing element (data details) that would be necessary for verification. It's not inherently verifiable *as is*, but rather points to a missing piece of information that would enable verification. This fits the definition of 2.", "helpfulness_rationale": "The lack of this information is a significant obstacle for the authors. It prevents them from understanding the experimental setup and potentially reproducing or building upon the work. This is a high level of unhelpfulness."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states 'It is unclear why the model does not fully succeed in identifying the true sources in the triangle dataset' and suggests potential reasons like 'one of the assumptions not satisfied' or 'learning difficulties'. This is an explicit statement pointing towards further investigation and potential improvements.", "grounding_specificity_rationale": "The reviewer mentions the 'triangle dataset' and the 'model's failure' but does not specify which particular aspect of the model's behavior or methodology is unclear or which specific assumption is violated. The suggestions are general and lack specificity.", "verifiability_rationale": "The reviewer provides potential reasons for the model's failure but does not offer any concrete evidence, examples, or references to support these claims. The suggestions are speculative and lack verifiability.", "helpfulness_rationale": "The reviewer identifies a problem ('unclear why the model does not fully succeed') but does not provide specific details or concrete suggestions on how to address it. The potential reasons are vague and lack supporting evidence, making it difficult for the author to implement concrete changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states their desire for the system to generalize to more views, which is an explicit action. However, they do not specify how this generalization should be implemented, making the action vague and lacking detail on how to apply it.", "grounding_specificity_rationale": "The reviewer criticizes the approach in general, not pointing to a specific part of their paper or the system. While their statement implies a problem with the approach, it doesn't directly reference a specific element, making the grounding weak. The comment is specific in its criticism of the approach's limitations, but it doesn't pinpoint a concrete part of their work being affected.", "verifiability_rationale": "The reviewer's statement about the approach being limited to two views is a claim. However, they do not provide any evidence or reasoning to support this claim, making it 1. They express a feeling or intuition but lack logical support or references.", "helpfulness_rationale": "The reviewer provides criticism of the approach and suggests a potential improvement (generalizing to more views). While the criticism is somewhat clear, the suggestion is vague and lacks specific details on how this generalization should be achieved. Therefore, the helpfulness is somewhat limited as the authors might not receive concrete guidance on how to implement the suggested change."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The question asks for the reason behind a specific design choice in a decoderdecoder model. This is an explicit request for an action (explaining why). The action is also concrete as it directly identifies the mechanism (temporal information flow).", "grounding_specificity_rationale": "The reviewer is asking about a general mechanism (temporal information flow) in a decoder. While the *concept* of decoding is implicit, the *specific implementation detail* of how the decoder uses past information is not explicitly stated. The grounding is weak because the reviewer is inferring this from the standard architecture rather than being explicitly told how the history is incorporated. The specificity is limited to the general idea of using past information, not a specific implementation detail like a particular attention mechanism or state.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It's a question about the model's architecture. Therefore, it doesn't fit into the 'Claim Extraction' step for verifiability. The 'X' category is appropriate here.", "helpfulness_rationale": "The review point raises a valid concern about a potential issue in the model's architecture (why only use information up to time step t). This can be helpful for authors to identify potential problems or misunderstandings. However, it doesn't directly provide a solution or a clear action to take. The helpfulness is moderate as it points out a potential problem that needs further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a weakness: 'The discussion on arbitrary hyperparameter \u03b3 is missing...'. This is an explicit statement of a need for action. However, the review does not provide any concrete steps or guidance on how to address this weakness. The reviewer asks 'how to set it in practice' and 'how to analyze on the sensitivity of this hyperparameter', but does not offer a solution or a method. Therefore, while the point identifies a problem, it lacks the explicit action or suggestion needed for high actionability.", "grounding_specificity_rationale": "The review point explicitly mentions 'hyperparameter \u03b3'. This is a specific reference to a particular aspect of the paper. The reviewer also asks about 'sensitivity analysis', which further grounds the point to a specific area of concern. While the reviewer doesn't provide the exact location (e.g., 'Section 3.2'), the mention of '\u03b3' is a clear indication of the specific part being addressed. Therefore, the grounding is present, but could be more precise.", "verifiability_rationale": "The review point contains a claim: 'The discussion on arbitrary hyperparameter \u03b3 is missing...'. This claim is verifiable because the reviewer points to a specific area (hyperparameter discussion) and indicates a lack of information. While the reviewer doesn't provide external references or logical reasoning to *why* this discussion is missing, the identification of the missing discussion itself is a verifiable statement. The reviewer implies a problem, and the act of pointing out the missing discussion is a form of justification.", "helpfulness_rationale": "The review point identifies a weakness ('missing discussion of hyperparameter \u03b3') and asks for improvements ('how to set it in practice' and 'how to analyze on the sensitivity of this hyperparameter'). This points to a clear area for improvement. However, the review point does not provide *specific solutions* or *practical guidance* on how to address this weakness. It asks questions but doesn't offer concrete steps or methodologies. Therefore, while the point highlights a need, it lacks the specific guidance required for high helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential confounding factor (head location) in an ablation study and suggests a controlled baseline. While the suggestion is clear, the reviewer doesn't explicitly state the implications of this confounding factor or how the suggested baseline would be implemented. The action is present, but the details are somewhat implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'head location' as a potential confounding factor and suggests a 'controlled baseline' to address it. The reviewer accurately identifies the specific part of the paper (ablation study) and the issue (head location). This demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer identifies a potential issue (different head locations) and suggests a method to address it (controlled baseline). While the reviewer doesn't provide specific examples of literature to support this suggestion, the logic behind the proposed solution is sound and verifiable through standard experimental design principles. The claim is present, and the reasoning is generally logical, making it '4'.", "helpfulness_rationale": "The reviewer raises a valid point about a potential confounding factor in an ablation study. The suggestion for a controlled baseline is a practical and actionable improvement that could enhance the validity of the ablation study. This directly addresses a potential weakness in the experimental design and provides a clear direction for the authors to consider. Therefore, the review point is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that a section on synonym identification is missing. This directly points to an actionable step for the authors to look for this information in the 'similarity measurement' section. While the action is clear, the specifics of what is missing are not detailed, making it somewhat vague.", "grounding_specificity_rationale": "The comment explicitly mentions 'synonym identification' and its location within the 'similarity measurement' section. This allows the authors to accurately identify the missing part and understand its context, making it fully grounded. The comment also specifies that this section relates to a 'multiplechoice task', adding further specificity about the type of information missing.", "verifiability_rationale": "The comment is a statement of fact: 'A section on synonym identification is missing under similarity measurement that would describe how the multiplechoice task is approached.' It does not contain a claim that requires verification or support. Therefore, it is not verifiable.", "helpfulness_rationale": "The comment identifies a specific gap in the paper's content (the missing section on synonym identification within the similarity measurement for a multiplechoice task). This points the authors directly to where they should look for more information. While it doesn't instruct them on how to perform synonym identification, it directs them to a relevant part of the paper where this information should be, making it 3 in locating the necessary details."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests providing an overview, which is an explicit action. However, it lacks concrete details on what aspects of the workflow and model should be included, making it only 3.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper (e.g., a section, table, or figure) related to the workflow or model. Therefore, it is 1.", "verifiability_rationale": "The review point is a suggestion, not a declarative statement making a claim. Therefore, it has X to be verified.", "helpfulness_rationale": "The review point is relevant and points towards improving the understanding of the workflow and model. However, it lacks specific details, making it only 3 for the authors to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the *problem* (expected quantities are scalars, shown as vectors) and suggests a *specific change* (redefine the figure). This fits the definition of explicit. It also provides clear guidance on what needs to be done, making it concrete. The reviewer directly tells the authors what to do and how to do it.", "grounding_specificity_rationale": "The comment explicitly mentions 'figure3' and suggests a change related to the *type* of representation (expected quantities are scalars). While it doesn't pinpoint a specific element within the figure (e.g., a particular axis or data point), it clearly identifies the *category* of figure being addressed. This can be considered 'fully grounded' as the specific figure is mentioned. However, the *specificity* is limited as it doesn't detail what is wrong with the vector representation itself.", "verifiability_rationale": "The comment contains a claim (i.e., a judgment about the expected representation of scalars in figures) and provides a justification based on general understanding of vector/scalar representation in figures. While it doesn't explicitly cite external references within this review point, the reasoning is logical and based on common practices. Therefore, it can be considered '3' as the claim is supported by logical reasoning, although it lacks specific examples or references within this point.", "helpfulness_rationale": "The comment provides a clear suggestion for improvement, directly pointing out a potential source of confusion for the authors. It is actionable and provides a specific direction for the authors to follow. While it could be expanded with more context, it is a helpful starting point."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the problem with 'ablations' and 'experiment setup', indicating a clear action: identifying and addressing issues with these elements. While the action is stated, the specifics of what needs improvement are not detailed, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'ablations' and 'experiment setup' generally, without pinpointing a specific section, table, or unique aspect of the paper. While 'ablations' is somewhat specific within the context of machine learning, 'experiment setup' is a broader concept. Therefore, the grounding is weak. The comment specifies the *area* of concern but not the *specific* part of the paper.", "verifiability_rationale": "The reviewer makes a claim: 'so many questions arise'. This indicates a lack of clarity or understanding regarding the ablations and experiment setup. However, the reviewer does not provide any evidence, reasoning, or external references to support this claim. The verifiability is low as the claim is presented without justification.", "helpfulness_rationale": "The reviewer's comment identifies a potential issue (unclear ablations and experiment setup) but does not offer any suggestions or insights on how to address it. The helpfulness is low because the comment points out a problem without providing any actionable guidance or resolution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a weakness: 'Unfortunately, no empirical evidence is provided to test the hypothesis.' It also suggests a concrete next step: 'It would have been interesting for the authors to look deeper into this.' This clearly indicates an action the authors should take. While the action isn't a complete solution, it's a specific direction. The comment also points out a potential issue with the word similarity datasets: '...the word similarity data sets contain frequent word pairs.' This suggests a specific area where the data might be problematic. The reviewer is not just criticizing; they are offering a specific investigation.", "grounding_specificity_rationale": "The comment explicitly mentions 'the proposed models' and the specific hypothesis about lowfrequency words and sememes. It also refers to 'the word similarity data sets.' This clearly identifies the specific parts of the paper being addressed. The reviewer is not just saying 'the paper is unclear'; they are pinpointing a specific aspect of the methodology and the data used. The language is precise and identifies the relevant sections.", "verifiability_rationale": "The comment contains claims: 'no empirical evidence is provided' and 'the word similarity data sets contain frequent word pairs.' These claims are supported by logical reasoning. The reviewer is stating facts that can be verified. While the reviewer doesn't explicitly cite specific examples of frequent pairs, the claim itself is clear and verifiable. The reasoning is logical and points to a potential flaw in the experimental setup or data.", "helpfulness_rationale": "The comment is specific about the lack of empirical evidence and suggests a concrete investigation into the word similarity datasets. This provides the authors with a clear direction for their next steps. While it doesn't guarantee finding the solution, it offers a valuable starting point for further analysis. The reviewer is not just pointing out a problem; they are also suggesting a way to potentially address it, making the comment quite helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues with Figure 5 ('it is difficult to understand') and provides a concrete suggestion ('there are a lot of lines on top of each other'). This indicates a clear and actionable point. For the metrics, the reviewer points out that 'the main metrics reported are performance compared to remaining weights' and suggests adding 'flops or model size'. This is also an explicit and concrete action. The reviewer is not just pointing out a problem but also suggesting a specific solution.", "grounding_specificity_rationale": "For Figure 5, the reviewer refers to 'figure 5' which is a fully grounded reference. The issue is also specific ('difficult to understand'). For the metrics, the reviewer refers to 'the main metrics reported' which is a weakly grounded reference as they don't name the specific metrics. However, they are very specific about the *type* of metrics they suggest ('flops or model size').", "verifiability_rationale": "For Figure 5, the reviewer states 'it is difficult to understand' and 'a lot of lines on top of each other' which are observations. While they imply this is a problem, the claim itself is not explicitly stated. For the metrics, the reviewer states 'the main metrics reported are performance compared to remaining weights' which is a claim. They also suggest 'flops or model size' as improvements, which provides justification for the claim.", "helpfulness_rationale": "The reviewer provides clear and actionable feedback on both the clarity of Figure 5 and the missing metrics. They explicitly state the issues and suggest concrete improvements. This makes the feedback very helpful for the authors."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Partially Grounded and UnderSpecific", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point states, 'Some details of the proposed method are missing, as noted in the questions section below.' This points to a problem but doesn't explicitly state what is missing or how to address it. The action is implicit (inferring missing details) but vague. The suggestion is to go to the 'questions section', which is not concrete.", "grounding_specificity_rationale": "The review point refers to 'the proposed method' generally and then mentions 'as noted in the questions section below.' The grounding is implicit, as the reviewer can infer the missing details relate to the proposed method. However, the specificity is low because the 'questions section' is not a precise location within the paper. The reviewer needs to go there to find more information.", "verifiability_rationale": "The review point states a fact: 'Some details of the proposed method are missing...'. This is a statement of observation, not a claim requiring evidence. There is no suggestion or request to add, remove, or clarify anything, so there is X to verify.", "helpfulness_rationale": "The review point points out the absence of details in the proposed method. While this information is likely relevant to the authors, it doesn't directly suggest improvements or provide specific guidance on what is missing or how to address it. It highlights a gap but doesn't propose a solution or explain its impact."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem ('Figure 4 is confusing') and clearly identifies the action ('it's not clear what the columns mean').", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 4' and specifically identifies the 'columns' as the unclear element.", "verifiability_rationale": "The reviewer states a problem ('Figure 4 is confusing') and what is unclear ('the columns'). While the issue is clear, the suggestion for improvement isn't explicitly stated, making it partially verifiable.", "helpfulness_rationale": "The reviewer identifies a specific area for improvement (clarity of Figure 4) but doesn't offer a solution. This is helpful but not fully comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to ask a question, which implies a desire to receive information and take action to understand the situation. The request for 'explanations' is a clear action to be taken upon receiving the information. The language is direct and requests a specific type of information.", "grounding_specificity_rationale": "The reviewer mentions 'ablation experiments' and names specific methods 'fCLSWGAN 4 and fVAEGAND2 5'. This clearly identifies the specific part of the paper or methodology being referenced. The reviewer also states the issue as 'why the results are so low' and compares them to 'some simple early methods', further specifying the nature of the problem being questioned.", "verifiability_rationale": "The reviewer expresses a concern about the results of the ablation experiments and compares them to the performance of other methods. This implies a belief that there might be an issue with the ablation study or the baseline methods. While the reviewer doesn't explicitly state that their ablation study is flawed, the question itself requires verification and explanation to address the concern about the low performance.", "helpfulness_rationale": "The reviewer directly asks a question seeking to understand a discrepancy in results. This is a clear and actionable request for information that is likely to be helpful for the authors in understanding and potentially addressing the performance issue. The request for 'explanations' is a direct action the authors would take to gain insight."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of ablation analysis as a problem and suggests that including ablation studies in the main paper would make it easier to pinpoint the source of performance gain. This is an explicit and concrete action that directly addresses the stated issue.", "grounding_specificity_rationale": "The reviewer points to the lack of ablation analysis in the main paper. While the reviewer implies the importance of this, the lack of specific grounding makes it difficult for the authors to know *where* to look in the main paper for this information.", "verifiability_rationale": "This review point does not contain a claim or assertion that requires verification. It is a statement of fact.", "helpfulness_rationale": "The review point identifies a valid weakness (the lack of ablation analysis) and suggests a concrete and relevant improvement (mentioning ablation analysis). This is a constructive and helpful suggestion for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1: 2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state what is wrong with the CNN experiments or how the authors should improve them. It is a subjective statement of opinion rather than a directive action. Therefore, it lacks actionability.", "grounding_specificity_rationale": "The reviewer refers to 'the CNN experiments' generally, without specifying which experiments are being discussed or providing any context. This makes the grounding weak as the authors cannot confidently identify the referenced part.", "verifiability_rationale": "The review point makes a claim ('The CNN experiments are not fully convincing') but does not provide any evidence or reasoning to support this claim. It lacks logical reasoning, common knowledge, or external references to back up the statement.", "helpfulness_rationale": "The review point is a subjective statement of opinion ('The CNN experiments are not fully convincing') without providing any specific, actionable feedback or suggestions for improvement. It does not empower the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing with SoTA approaches, which is a valid piece of advice. However, it doesn't explicitly state how to go about comparing or what specific comparisons would be beneficial. It's a suggestion but lacks the concrete steps needed for action.", "grounding_specificity_rationale": "The review point is very general and doesn't mention any specific section, table, figure, or element of the paper. It's a broad statement about the need to compare with SoTA approaches, lacking any grounding of where this comparison should be made or what aspects are important.", "verifiability_rationale": "The review point is a suggestion or recommendation, not a claim that needs verification. It doesn't make a judgment about the current work or propose a method.", "helpfulness_rationale": "The review point suggests comparing with SoTA approaches, which is generally helpful. However, it's a very general suggestion and lacks specific details needed for the authors to act on it effectively, such as which models to compare with or how this comparison will lead to improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an alternative method (using the adaptive method directly) but doesn't explicitly tell the authors what to do. While it points to a potential improvement (using adaptive directly), the authors would need to investigate further to understand the value of freezing. The suggestion is implicit, making it not fully actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'MLS selection' and the 'freezing' aspect, clearly identifying the specific part of the paper being addressed.", "verifiability_rationale": "The review point makes a suggestion ('If adaptive is good, why not just use adaptive method...') but doesn't provide a specific justification or evidence for why freezing is used in MLS selection or why the alternative is better. It's a suggestion based on intuition or a perceived inconsistency, lacking strong supporting reasoning.", "helpfulness_rationale": "The review point raises a valid point about the lack of clarity in MLS selection and the potential redundancy of using freezing with an already effective adaptive method. However, it doesn't provide explicit instructions on how to improve the draft. The authors would need to follow up with research and potentially implement the suggested change, making it potentially helpful but not definitively so."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks whether the proposed knowledgeCLIP model solves a specific issue. This is a direct and clear action. The suggestion to perform a robustness analysis by changing negations or entities is also a concrete action that the authors can take. The explicit nature of the actions makes them directly identifiable.", "grounding_specificity_rationale": "The review point refers to 'the proposed knowledgeCLIP model' and 'the specific issue'. While it doesn't point to a unique section or table, it does identify the model and the area of concern. This can be considered 'weak grounding'. The suggestion to perform a robustness analysis by changing negations or entities is specific to the type of analysis, but not a specific part of the paper. Therefore, it is 'specific' in the sense that it targets a particular kind of evaluation, but doesn't pinpoint a specific element within the model or paper. Thus, it is '3'.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is more of a suggestion for further investigation and analysis. Therefore, it does not fit into the verifiability categories.", "helpfulness_rationale": "The review point suggests an interesting analysis and points towards potential weaknesses in the proposed model's robustness. While it doesn't directly identify a flaw or provide a concrete improvement suggestion, it offers a direction for further investigation, which can be helpful for the authors in understanding the limitations of their model. Therefore, it is '3'."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they want a 'discussion' on the computational cost and complexity. This is a clear request for information, which is an explicit action. They are asking for details on why the additional cost didn't lead to significant delays, which is a specific action to understand a potential issue.", "grounding_specificity_rationale": "The reviewer refers to 'computational cost' and 'computational complexity', which are specific aspects of the method. They are also asking for a 'discussion' which implies they want the paper to address these points. The references to 'scalability' further indicate a focus on specific implementation details and potential limitations. The reviewer is not just stating a problem but also pointing towards where the information should be located.", "verifiability_rationale": "The reviewer is making a suggestion for improvement ('I believe the paper deserves a more comprehensive discussion...') rather than stating a claim that needs verification. There is no logical reasoning, common knowledge, or external references provided to support this suggestion. It's a direct request for more information.", "helpfulness_rationale": "The reviewer has identified a clear gap in the paper (lack of discussion on computational cost and complexity) and has provided a specific suggestion ('I believe the paper deserves a more comprehensive discussion...'). This is a valuable contribution that directly addresses a need identified by the reviewer and provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the issue: 'For clarity, consider explaining a bit more how novel values in the test set are handled.' This clearly identifies an action the authors should take. While the action itself isn't fully detailed, the request for explanation is a clear direction. Therefore, it is considered explicit. However, the lack of specific details makes it somewhat vague in terms of concrete implementation.", "grounding_specificity_rationale": "The review point explicitly mentions 'novel values' within the 'test set'. This directly identifies the specific part of the paper being referred to. While it doesn't provide a specific example, the terms used are quite specific. The reviewer is pointing to a particular aspect of the data. Therefore, the grounding is strong. However, the lack of specificity in the *handling* of these values makes it somewhat specific in terms of the action to be taken.", "verifiability_rationale": "The review point itself does not contain a definitive claim or assertion. It's a request for clarification rather than a statement of what should be done. However, the request implies a lack of clarity in the current implementation, which could be considered a form of judgment about the paper's state. The request itself is a form of implicit justification, suggesting the authors should provide more detail. Therefore, it leans towards 3 due to the implicit expectation of an explanation.", "helpfulness_rationale": "The review point directly addresses a potential ambiguity in the implementation by asking for clarification on how 'novel values' in the 'test set' are handled. This is a specific and actionable request that would likely be helpful for the authors to understand and implement their experiments correctly. The request directly targets a potential point of confusion or missing information. Therefore, it is 5 as it directly addresses a specific implementation detail."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that 'Similar methods have already been proposed...'. This is an explicit action as the reviewer directly points out the existence of similar methods. However, the comment lacks specific details on how these methods are similar or what aspects of multitask learning are missing, making it somewhat vague in terms of concrete action.", "grounding_specificity_rationale": "The comment explicitly mentions 'multitask learning' and states that 'has not been discussed in this paper'. This directly identifies the specific part of the paper being addressed (multitask learning). The comment is also specific in pointing out a *lack of discussion*. However, it doesn't provide specific examples or details about *which aspects* of multitask learning are missing, making it somewhat specific in terms of grounding but not fully specific in terms of content.", "verifiability_rationale": "The comment contains a claim ('Similar methods... have not been discussed...') and provides some justification by stating that this is a 'weakness' in the paper. However, it lacks specific examples or references to support this claim. The reasoning is logical but lacks concrete evidence or citations.", "helpfulness_rationale": "The comment identifies a weakness in the paper (lack of discussion of similar methods in multitask learning). While it doesn't directly tell the authors how to improve their draft, it points out a specific area that needs attention. This makes it 3 in highlighting a deficiency."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a weakness: 'Missing indepth analysis on experimental results.' This directly points to a need for the authors to elaborate on their findings. While the reviewer doesn't specify *how* to perform this analysis, they clearly identify a missing element in their current approach. The example they provide ('why the improvements of models are limited on offense detection dataset and are significant on coarse stereotype set?') further clarifies the nature of the missing analysis. This points to a clear action for the authors to take.", "grounding_specificity_rationale": "The reviewer mentions 'experimental results' generally. While they provide an example of the *nature* of the results (limited improvement on one dataset, significant on another), they don't explicitly point to a specific section, table, figure, or unique aspect of the paper where this discrepancy needs addressing. The suggestion is general: 'indepth analysis.' Therefore, while the *area* of analysis is specified, the *exact* part of the paper being affected is not. This makes the grounding somewhat specific, as the *nature* of the issue is clear, but the precise location is not.", "verifiability_rationale": "The reviewer makes a claim: 'Missing indepth analysis on experimental results.' This claim is supported by the reasoning that 'understanding the underlying reasons for these discrepancies is crucial for improving the model's robustness and generalizability.' While the reviewer doesn't provide specific external references in this point, the suggestion of 'indepth analysis' implies the need for logical reasoning and potentially external knowledge to understand the results. Therefore, the claim is supported by logical reasoning and the suggested analysis, making it 3.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper: the lack of indepth analysis of experimental results. They provide a specific example to illustrate this weakness ('why the improvements of models are limited on offense detection dataset and are significant on coarse stereotype set?'). This highlights a significant gap in the evaluation. While the reviewer don't suggest a specific *howto* for the analysis, they clearly point out a crucial area for improvement. This makes the review point 5 for guiding the authors to enhance their experimental evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point mentions the extensive hyperparameter search and the multiple hyperparameters used. While it implicitly suggests that the baseline might not have been tuned sufficiently, it doesn't explicitly state what specific actions the authors should take. The reviewer points towards a potential area for improvement in the baseline tuning process, but the exact steps are not detailed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'temperature, penalty, and threshold' as hyperparameters involved in the extensive hyperparameter search. This clearly identifies the specific part of the paper being addressed, making the grounding very specific.", "verifiability_rationale": "The reviewer recommends 'making sure that the baseline is fully tuned with the similar resource given to the proposed method'. This recommendation is based on the general principle of thorough experimentation. While it's a reasonable suggestion, it lacks specific justification or references to external literature to support this claim.", "helpfulness_rationale": "The review point identifies a potential weakness in the baseline tuning process and suggests a concrete improvement (tuning the baseline similarly). While the suggestion is somewhat general in its implementation details, it clearly points to an area for improvement in the experimental methodology. It doesn't criticize the results but highlights a potential flaw in the setup."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review points out the absence of standard deviations, which is a direct and explicit indication of a missing element. While it doesn't explicitly state how to calculate or use them, the reviewer implies the need to understand the significance of the results, which is a clear action the authors could take. The reviewer also mentions the difficulty in judging significance, which is a direct consequence of the missing information, making the action clear.", "grounding_specificity_rationale": "The review refers to 'the experimental results' as the specific part of the paper being addressed. This is a literal mention, indicating full grounding. It then explicitly states the missing element: 'standard deviations'. This is a clear and specific identification of what is missing within the referenced part. The reviewer also mentions the consequence of this missing information: 'it is hard to judge the significance of the results', further emphasizing the specific nature of the issue.", "verifiability_rationale": "The review makes a claim: 'the experimental results do not contain standard deviations and therefore it is hard to judge the significance of the results'. This is a statement of opinion and a consequence of a factual observation. The reviewer explains why standard deviations are important for judging significance, providing a logical reasoning. While it doesn't provide a specific citation, the reasoning about the importance of standard deviations for statistical significance is generally wellknown and widely accepted. This makes the claim somewhat supported by logical reasoning.", "helpfulness_rationale": "The review provides a clear and specific piece of feedback to the authors. It identifies a crucial missing element (standard deviations) in the experimental results and explains why its absence makes it difficult to judge the significance of the findings. This directly impacts the authors' ability to interpret their results and understand the reliability of their conclusions. The feedback is actionable, as the authors can now focus on obtaining or calculating these missing values. The reviewer's statement is a direct and helpful suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly names the missing theoretical components (existence and smoothness of SDE solutions, discretization guarantees). This is both explicit and concrete. Therefore, it's 5.", "grounding_specificity_rationale": "The reviewer mentions \"theoretical work\" but doesn't point to a specific section or table. This is weak grounding. However, they clearly specifies the *nature* of the missing information (theoretical aspects of sampling and particlebased optimization). This is specificity. Therefore, it's somewhat grounded and specific.", "verifiability_rationale": "The reviewer makes a claim about the weakness of the analysis due to the missing theoretical details. This claim is verifiable because the absence of these details *could* impact the analysis. However, the reviewer doesn't provide specific examples of *how* these missing details affect the analysis. Therefore, it's 3.", "helpfulness_rationale": "The reviewer identifies a weakness in the paper's theoretical foundation. By highlighting these missing details, the reviewer is suggesting the authors should address them to strengthen their work. This is helpful because it guides the authors to investigate these theoretical aspects. The reviewer doesn't suggest *how* to address the weakness, but they identify the *area* for improvement. Therefore, it's 3."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem: 'Quality of generated images by proposed method is limited.' They also suggest an action: 'improve realism'. While the action itself is somewhat vague, the identification of the problem is clear and actionable.", "grounding_specificity_rationale": "The reviewer mentions 'paper and supplemental material' in relation to the limited realism. This indicates they are referring to the visual presentation of results, but they do not explicitly identify the specific section, table, figure, or unique aspect within the paper that is affected. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a claim: 'Quality of generated images by proposed method is limited' and 'realism of generated results showed in paper and supplemental material is limited.' While they provide some context: 'While good continuous control is achieved,' this context does not serve as sufficient evidence or justification to fully verify the claim about limited realism. The claim is somewhat supported but lacks key elements like specific examples or references to external work. Therefore, it is 3.", "helpfulness_rationale": "The reviewer offers a suggestion: 'improve the realism' to address the issue. This is a helpful comment as it directly points out an area for improvement in the authors' work. However, the suggestion is quite general and does not provide specific guidance on how to achieve this improvement. It lacks a strong critique of the method's image generation capabilities in detail."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer is correcting a statement made by the authors, suggesting a potential misunderstanding or error in their description. While the reviewer provides a specific detail about the backpropagation process, the initial statement by the authors could be interpreted in multiple ways, making the action implicit. The reviewer is suggesting a concrete change to the authors' understanding, but the exact nature of the authors' original statement is unclear, making it difficult to fully assess the concreteness of the action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Lines 559560' in the review point, providing a clear reference to a specific location in the paper. They also refer to 'Cycle Consistency loss' and 'backpropagation process', which are specific concepts within the paper. This indicates a strong grounding of the comment in the text and the specific area being discussed.", "verifiability_rationale": "The reviewer states that the authors' description of the Cycle Consistency loss is inaccurate and provides a specific detail about the two separate backpropagation processes. This constitutes a claim that needs verification. The reviewer provides a specific detail about the implementation, which could serve as evidence to verify or invalidate the authors' claim. Therefore, the claim is 3 as it offers a specific detail that could be checked.", "helpfulness_rationale": "The reviewer is directly correcting a potential misunderstanding or error in the authors' description of the Cycle Consistency loss. This is a clear and actionable feedback that is likely to be helpful for the authors in understanding the correct implementation details. The reviewer is providing a specific correction, which is directly actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the issue: \"calling 'hyperspectral' is confusing.\" This indicates an implicit action: the reviewer is pointing out a potential problem with the use of the term. However, the action is not concrete; the reviewer doesn't specify what needs to be done to resolve the confusion. The lack of a suggested improvement makes it difficult to act upon.", "grounding_specificity_rationale": "The reviewer mentions \"hyperspectral\" generally, which is a specific term. They do not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. While they point to a specific concept, they don't tie it directly to a concrete element within the paper. Therefore, the grounding is weak.", "verifiability_rationale": "The review point is a statement of observation: \"calling 'hyperspectral' is confusing.\" It does not contain a claim or suggestion for improvement. Therefore, it does not meet the criteria for verifiability, which requires a claim to be verified.", "helpfulness_rationale": "The review point identifies a valid issue: the potential confusion surrounding the term 'hyperspectral'. However, it does not provide any actionable feedback or suggestions for improvement. The reviewer simply states the problem without offering a solution or direction for the authors to address it. This makes the review point less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: Partially Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a gap in the experimental validation (ablation study) and raises questions about the implementation and statistical significance. While it points towards a missing piece of information, it doesn't explicitly state what the authors *should* do with this information. Therefore, it's partially actionable.", "grounding_specificity_rationale": "The review point mentions the 'ablation study' and 'w/o perception module' but doesn't specify *exactly* which table or section in Table 10 contains the relevant information. It also doesn't detail *how* the implementation detail is missing. Therefore, it's partially grounded and underspecific.", "verifiability_rationale": "The review point claims the ablation is inconclusive and the results are questionable, suggesting a lack of statistical significance. It *implies* the similar performance is evidence of this. While it points to a potential issue, it doesn't provide direct, verifiable evidence or references to support these claims. Therefore, it's partially verifiable.", "helpfulness_rationale": "The review point directly highlights several shortcomings of the experimental setup and results reporting. It points out the missing ablation details, the lack of statistical significance, and the similar performance between ablations. These are all actionable items for the authors to address. Therefore, it's 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that 'previous works on Lasso screening are not cited or compared' in the context of the paper's claim about Transfer Lasso's best accuracy. This is a clear and direct criticism, identifying a missing element. The action is to identify the missing citations and comparisons. The information is also concrete, as the reviewer specifies *where* the missing information is.", "grounding_specificity_rationale": "The review point explicitly mentions 'Transfer Lasso' and 'previous works on Lasso screening.' This is a literal mention of the section or topic being discussed, providing clear grounding. The specificity is high as the reviewer directly identifies the missing elements.", "verifiability_rationale": "The review point contains a claim: 'previous works on Lasso screening are not cited or compared.' The reasoning provided is that 'Transfer Lasso showed the best accuracy in feature screening.' This provides a basis for verification by indicating the specific area of Lasso screening that is missing and why it's relevant. While it doesn't provide specific examples of missing citations, it does offer a logical connection.", "helpfulness_rationale": "The review point directly points out a factual omission in the paper. It tells the authors *what is missing* (citations and comparisons) and *where it is missing* (previous works on Lasso screening). This is immediately actionable and helpful for the authors to improve their understanding and potentially reevaluate their claims about Transfer Lasso."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the notation for results is unclear and points to the '3%p' improvement for CIFAR10. This is a clear indication of an actionable issue. The reviewer directly identifies the problem and suggests that the authors clarify the notation. The action is explicit: 'clarify the notation'. The implications are also clear: the authors need to understand what 'p' stands for to fully grasp the improvement.", "grounding_specificity_rationale": "The reviewer directly references the '3%p' improvement for CIFAR10. They mention the specific result and the percentage. This demonstrates strong grounding specificity. The authors can easily identify the specific part of the paper being addressed \u2013 the results section for CIFAR10. The issue is also clearly specified: the missing definition of 'p'. The reviewer provides a precise reference point.", "verifiability_rationale": "The reviewer's comment is a statement of observation: 'The notation for results is not clear. The paper claims the improvement for CIFAR10 is 3%p but it is not clear what %p stands for.' This comment does not contain a claim that can be verified. There are no external references, logical reasoning, or examples provided to support the reviewer's observation. The reviewer is simply stating that the information is unclear.", "helpfulness_rationale": "The reviewer's comment directly points out a clear issue in the paper: the lack of clarity in the percentage improvement notation. They are asking the authors to clarify this notation, which is a helpful and actionable suggestion. The reviewer is not making a judgment about the validity of the improvement, but rather highlighting a lack of clarity in the presentation. This is a helpful comment as it directly addresses a presentation issue that could hinder understanding."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests adding a clarification to the title. While the suggestion is clear, it lacks specific details on *what* needs to be clarified. The reviewer implies the title is ambiguous, but doesn't pinpoint the specific aspect of ambiguity. Therefore, the action is implied but not explicitly stated, making it 3.", "grounding_specificity_rationale": "The reviewer refers to the 'title' as a whole, which is a general term. They don't specify which part of the paper or the title they are referring to. The suggestion is broad and doesn't identify a specific section, table, figure, or unique element. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The reviewer provides a justification for their suggestion: 'because \u201creading comprehension\u201d and \u201creadability\u201d usually mean that.' This is a logical reasoning based on common usage in the field. The reviewer explains *why* the distinction is important. Therefore, the claim is verifiable based on common knowledge and logical reasoning.", "helpfulness_rationale": "The reviewer's suggestion to clarify the title is relevant and addresses a potential ambiguity. They provide a reason ('because \u201creading comprehension\u201d and \u201creadability\u201d usually mean that') which offers a basis for improvement. While the suggestion is general, it points to a specific area for improvement (the title's clarity). The authors can infer the need for a more specific description of what the title should convey. Therefore, the review point offers some helpful direction, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states they want an explanation for why TSS was chosen over a human metric. This constitutes an explicit action. However, the explanation provided is vague and does not offer concrete details on how this clarification will be applied.", "grounding_specificity_rationale": "The reviewer mentions 'style control' and 'TSS' as specific areas and metrics. This indicates a strong attempt to identify the specific part of the paper being addressed, thus achieving full grounding.", "verifiability_rationale": "The reviewer criticizes the use of TSS without providing a clear justification for this choice over a human metric. The claim that this criticism is ' helpful' is undermined by the lack of supporting evidence or reasoning for why TSS was selected. The verifiability of this point is therefore low as the reasoning is vague, insufficient, or difficult to follow.", "helpfulness_rationale": "The reviewer's point is 5 in identifying a potential weakness in the evaluation process. They are suggesting a concrete improvement by requesting a justification for the metric choice. However, the lack of a clear justification makes the criticism itself seem arbitrary and less verifiable, thus reducing the overall helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides explicit suggestions for improvement, such as 'Please include confidence intervals' and 'Consider evaluating on more diverse datasets'. These are direct actions the authors can take to address the identified issues. While the suggestions are general, they are still explicit and point to concrete steps. Therefore, the review point is 3 as it clearly identifies areas for improvement.", "grounding_specificity_rationale": "The review point identifies issues related to the statistical significance of performance gains and the evaluation methodology. However, it does not explicitly pinpoint a specific section, table, figure, or unique aspect of the paper that lacks confidence intervals or where the evaluation was performed. The suggestions are general and apply broadly to the results and the datasets used. Therefore, the grounding specificity is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point makes a claim that 'the lack of confidence intervals for their results, so it is unclear whether performance gains are statistically significant' and 'they also only evaluate on two datasets, though these seem to be standard datasets in the RNP community'. The claim about confidence intervals is verifiable through statistical principles. The claim about the evaluation on two datasets is also verifiable by examining the paper's experimental setup. However, the claim about 'standard datasets' is less verifiable as it requires external knowledge of the RNP community to confirm if these are indeed standard and if their use raises concerns about generalizability. Therefore, the verifiability is 3 as the claims are generally supported but lack specific examples or references to external sources for the 'standard datasets' claim.", "helpfulness_rationale": "The review point provides clear and actionable feedback to the authors. It directly points out specific weaknesses (lack of statistical significance, limited dataset diversity) and suggests concrete improvements (including confidence intervals, evaluating on more diverse datasets). While the suggestions are general, they are still helpful in guiding the authors towards addressing the identified issues. Therefore, the review point is 3 as it provides clear and actionable feedback that empowers the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their wish to see 'training losses', which is a direct action. However, the specifics of what kind of losses or how they should be calculated are not provided, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'a deep localization network' and 'differentiable Sinkhorn'. While they don't explicitly name a section or table, the mention of these terms strongly implies a specific part of the paper. The request for 'training losses' is somewhat vague, lacking specific details about the loss function or calculation method.", "verifiability_rationale": "The reviewer is asking for 'training losses' rather than making a claim that needs verification. Therefore, it doesn't fit the verifiability framework.", "helpfulness_rationale": "The reviewer explicitly states their wish to see 'training losses'. This is a clear desire for actionable feedback related to the implementation of a specific technique."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "Not Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer states 'The paper overclaims the strength of the proposed BC loss in theoretical analysis' which is an implicit statement. However, the reviewer also suggests 'You should clarify how these different perspectives relate to each other and provide a unified explanation of the BC loss's theoretical benefits.' This explicit suggestion makes the point actionable for the authors.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific section or element of the paper as being missing. However, the reviewer implies that the connection between 'geometric interpretability, theorem 1, the high/low entropy representations, and the hardnegative mining ability' is missing or unclear. This can be considered '3' as the specific issue is implied, and the suggestion for clarification is specific.", "verifiability_rationale": "The reviewer is criticizing the *presentation* and *clarity* of the theoretical analysis, not the verifiability of specific claims within it. The reviewer is stating that the different aspects are the same thing, which is a claim that could be verifiable. However, the criticism is about the *lack of clarity* in how this is presented. Therefore, it's 'Not Verifiable' as the criticism is about the *presentation* rather than a lack of supporting evidence for a claim.", "helpfulness_rationale": "The reviewer provides a clear diagnosis: 'The paper overclaims the strength of the proposed BC loss in theoretical analysis. The geometric interpretability, theorem 1, the high/low entropy representations, and the hardnegative mining ability, are actually the same thing (i.e., applying stronger constrains for samples with higher popularity) from different viewpoints.' This diagnosis is insightful and actionable. The reviewer also suggests 'You should clarify how these different perspectives relate to each other and provide a unified explanation of the BC loss's theoretical benefits.' This makes the point 5 for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that RegMixup sees 2x samples per iteration and consequently runs 1.5 times slower. It also points out that this could lead to an unfair comparison with other methods. The action is directly stated, and the implications for the authors' implementation are clear.", "grounding_specificity_rationale": "The review point explicitly mentions 'RegMixup' and its behavior of seeing '2x samples per iteration'. This is a literal mention of the method and a specific detail about its implementation. It also clearly identifies the issue of 'slow running speed'.", "verifiability_rationale": "The review point contains a claim: 'RegMixup seeing 2x samples may lead to unfair comparison.' This claim is based on the authors' stated training time, making it 3 as it relies on the reader accepting the authors' assertion. However, it doesn't provide independent evidence or references to support this claim about the authors' training time.", "helpfulness_rationale": "The review point directly points out a potential issue (unfair comparison) based on a specific technical detail. While it doesn't offer a concrete solution, it provides a clear observation that could help the authors improve their draft by considering the sample size or comparing against methods with similar resources. The suggestion is helpful in guiding the authors' investigation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the potential issue with using focal loss for regression (inaccurate gradients) and suggests the authors might be taking a naive unified approach. This provides a clear direction for improvement and helps the authors consider the implications of their method choice. The reviewer also points out the difference between classification and regression, which is a key aspect of actionability.", "grounding_specificity_rationale": "The reviewer clearly identifies the 'focal loss' and its application to 'regression tasks' (specifically IoU regression). While they don't give an exact section number, the context strongly implies they are referring to the method description where focal loss is introduced. This can be considered 'fully grounded' as the reviewer pinpoints the specific aspect of the paper. The reviewer also specifies what is being criticized: 'accurate problem' (implying accurate IoU calculation) and the potential flaw in using focal loss for regression. This is 'specific' as the reviewer focuses on the technical implications for the IoU calculation.", "verifiability_rationale": "The reviewer's claim about the potential issue with focal loss for regression and the authors' naive unified approach is a hypothesis based on their understanding of the method and its typical use. They don't provide direct evidence or citations to support their claim. Therefore, the claim is 'not verifiable' at this point. The reviewer is making an inference, not stating a fact that can be immediately confirmed.", "helpfulness_rationale": "The reviewer is trying to point out a potential misunderstanding or misapplication of focal loss. While it's a valid point, it doesn't directly 'improve' the paper. It highlights a potential area for clarification or further investigation for the authors. It's not actively hindering the authors' work, but it's also not directly helping them. Therefore, it's '3' in that it encourages the authors to think critically about their method choices."}
{"actionability_label": "3", "grounding_specificity_label": "X", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question about the method's scaling behavior, which implies a desire for information rather than a direct instruction on how to improve the draft. While it points towards an area for improvement, it doesn't explicitly state what needs to be done or how to implement it.", "grounding_specificity_rationale": "The review point is a general question about the method's scaling as corpus size or hidden dimension increases. It does not explicitly refer to a specific part of the paper or method being discussed.", "verifiability_rationale": "The review point is a question, not a statement that requires verification or justification. It does not present a claim that needs to be supported by evidence.", "helpfulness_rationale": "The review point is a question that encourages the authors to investigate the scaling of their method. While it can be helpful in guiding the authors' exploration, it doesn't directly instruct them on how to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the desire for 'More datasets' and provides specific examples of datasets (XNLI, XTREME). This is an explicit action. Furthermore, the reviewer clearly states the intention of using these datasets to 'show the proposed technique can generalize to tasks with different levels of reasoning requirements', making the action concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'datasets' and provides specific examples of 'traditional multilingual tasks' (XNLI, XTREME). This clearly identifies the specific part of the paper being addressed. The comment also states the intention of using these datasets to 'show the proposed technique can generalize to tasks with different levels of reasoning requirements', which specifies what needs to be addressed in this part. This is 5.", "verifiability_rationale": "The review point contains a claim: 'More datasets on traditional multilingual tasks like XNLI, XTREME, to show the proposed technique can generalize to tasks with different levels of reasoning requirements.' However, the review point does not provide any logical reasoning, external references, or examples to support this claim. It simply states a desire for more data. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point suggests adding more datasets and tasks to evaluate the technique. While this is a valuable suggestion for future work, it does not directly critique or identify specific weaknesses in the proposed technique itself. It is a suggestion for evaluation data, not a constructive critique of the method. Therefore, it is 3 in guiding future experiments but does not directly improve the technique at hand."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a lack of implementation details as a concern. While it doesn't explicitly state what is missing, it implies that the authors need more information on how the proposed methods are implemented. This makes it 3 as the authors know they are missing something, but the exact nature of the missing information is not fully specified.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 4.1' as the location of the missing implementation details. This is a clear and precise identification of the specific part of the paper being addressed, indicating full grounding. It also specifies what is missing \u2013 implementation details of the proposed methods. This is 5.", "verifiability_rationale": "The review point makes a claim about the 'lack of implementation details of the proposed methods'. This is a clear statement that requires verification. While it doesn't provide specific examples or references, it identifies a specific area (implementation details) within a specific section (implied by the context of 'proposed methods') that needs to be addressed. This makes it 3 as the claim is clear and points to a specific area, but lacks explicit supporting evidence.", "helpfulness_rationale": "The review point directly addresses a practical concern for the authors \u2013 the lack of implementation details. By pointing out this specific area, the reviewer provides a clear direction for where the authors should look to improve their draft. This directly helps them understand what needs revision and why (the missing details). The suggestion to include this in Section 4.1 is also helpful in guiding the authors. This review point is 5 as it directly addresses a practical issue and provides a clear direction for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the inconsistent use of 'P' for both probability and cumulative distribution function (CDF). This is an explicit statement of a problem that the authors can directly address by adopting different notations. The suggestion to use different symbols is also concrete.", "grounding_specificity_rationale": "The reviewer mentions the issue in the context of the mathematical expressions in the Appendix (Eq. (3), (4), and L44). While they don't explicitly say 'Section Appendix', the context strongly implies it. The reviewer also specifies that 'P' is used for both probability and CDF, which is a clear indication of the issue within a specific part of the paper. This can be achieved through literal mention of the section or unique element, making it fully grounded. The specificity is high as the reviewer clearly identifies the dual use of 'P' within a specific mathematical context.", "verifiability_rationale": "The reviewer's point is a suggestion for improvement, not a claim that can be directly verified within this review point itself. While it's a valid suggestion, the lack of evidence to support or refute it within this text makes it 1.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion (using different symbols) to address the identified problem. This directly empowers the authors to improve their draft by clarifying the notation. The suggestion is specific and directly addresses the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a difference between artificial and natural spurious correlations but does not explicitly state what needs to be done to address this difference or how to analyze natural spurious correlations. The statement is more about clarifying a potential area of confusion within the community rather than providing a direct action.", "grounding_specificity_rationale": "The reviewer mentions 'natural spurious correlations' but does not explicitly identify a specific part of the paper where this distinction is relevant. The reference is more conceptual than pinpointed to a particular section, table, or figure.", "verifiability_rationale": "The reviewer makes a claim about the current state of research regarding the use of artificial patterns versus natural spurious correlations. While the claim is based on the reviewer's understanding, it lacks specific justification or references to external works to support the assertion that duplicating artificial patterns is different from natural spurious features.", "helpfulness_rationale": "The reviewer's comment is informative and highlights a potential gap in understanding within the community. However, it does not directly provide actionable steps or suggestions for the authors on how to address this gap or improve their work based on this observation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the method discussed by the paper is 'limited in navigation problems' and suggests 'combining RL and planning' as a potential improvement. This indicates a clear action: to explore this combination and its potential benefits.", "grounding_specificity_rationale": "The reviewer mentions 'navigation problems' and 'PRMRL' as areas where the method is limited and has been discussed before. While the connection to the paper's specific content isn't explicitly stated as a direct section or unique element, the mention of 'navigation problems' provides some grounding. The suggestion to 'apply such algorithms in more general tasks' further grounds the comment in a specific area of interest.", "verifiability_rationale": "The reviewer makes claims such as 'the paper is limited in navigation problems' and 'Combining RL and planning has already been discussed in PRMRL'. However, the paper does not explicitly mention PRMRL or discuss the combination of RL and planning in the context of the paper's method. The claims are based on the reviewer's general knowledge of the field but lack specific references or justification within the context of the paper being reviewed.", "helpfulness_rationale": "The reviewer points out a limitation of the paper's method and suggests exploring the combination of RL and planning. While this is a relevant and potentially helpful suggestion, the review lacks specific details on how this combination would be implemented or what specific improvements it would bring to the paper's approach. The suggestion is interesting but lacks concrete details to be fully helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a potential issue ('are all feature spaces wellsuited for 1NN?') and suggests a solution ('If a feature space is not close to a spherical Gaussian, it may perform poorly. If feature dimensions are individually standardized, it would avoid this issue.'). This indicates a clear action to be taken.", "grounding_specificity_rationale": "The comment directly references a specific line in the paper ('line 213') and then elaborates on the issue and potential solution within the context of this line, indicating strong grounding and specificity.", "verifiability_rationale": "The comment poses a question ('are all feature spaces wellsuited for 1NN?') which is a claim. While it offers a potential solution ('If feature dimensions are individually standardized, it would avoid this issue'), this is more of a suggestion than a direct verification of the claim. The reviewer doesn't provide specific examples or references to back up the claim that 'all feature spaces' are unsuitable for 1NN.", "helpfulness_rationale": "The review points out a relevant issue for authors using 1NN and provides a practical suggestion ('If feature dimensions are individually standardized, it would avoid this issue'). However, it doesn't cover all possible scenarios or provide a comprehensive analysis of feature space suitability for 1NN, making it 3 but not fully comprehensive."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the lack of a definition and suggests a 'clear, formal definition'. This is an explicit action that the authors should take.", "grounding_specificity_rationale": "The reviewer identifies the specific issue: 'the contrastive gap' and its lack of a 'clear, formal definition'. This clearly points to the specific part of the paper that needs clarification.", "verifiability_rationale": "The reviewer claims that the lack of a definition is a problem, which can be verified by the general understanding in academic writing that clear definitions are important and a lack thereof can be considered a weakness. While not explicitly citing literature, the implication is clear.", "helpfulness_rationale": "The reviewer provides a clear suggestion for improvement: 'a clear, formal definition'. This directly addresses the identified weakness and offers a concrete solution, making the feedback actionable."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their point: 'Ideally other baselines would also be included, such as the other works discussed in related work 29, 5, 6.' This is a clear and direct statement of what they believe is missing or could be improved. The reviewer also states their action: 'After the Authors' Response My weakness points after been addressed in the authors' response. Consequently I raised my score.' This indicates a direct action taken by the authors in response to the reviewer's point. The reviewer further elaborates on their action: 'All unclear parts have been answered The authors' explained why the chosen baseline makes the most sense.' This provides concrete steps the authors have taken to address the reviewer's concerns. The reviewer's question: 'Questions  Do you think there is a way to test beforehand whether I(X_1...' is a request for clarification, not a claim requiring evidence.", "grounding_specificity_rationale": "The reviewer explicitly mentions specific related works: '29, 5, 6'. This clearly identifies the area of the paper being discussed. The reviewer also suggests actions related to these specific works: 'After the Authors' Response My weakness points after been addressed in the authors' response. Consequently I raised my score.' This indicates a clear intention to address the specific concerns raised by the reviewer. The reviewer further elaborates on actions related to specific parts: 'All unclear parts have been answered The authors' explained why the chosen baseline makes the most sense.' This shows a direct action to address the specific point about the baseline. The reviewer's question: 'Questions  Do you think there is a way to test beforehand whether I(X_1...' is a request for clarification, not a claim requiring evidence.", "verifiability_rationale": "The reviewer makes a claim: 'Ideally other baselines would also be included, such as the other works discussed in related work 29, 5, 6.' This is a statement of opinion or judgment about the paper. The reviewer also provides reasoning for this claim: 'After the Authors' Response My weakness points after been addressed in the authors' response. Consequently I raised my score.' This indicates an attempt to justify their point. The reviewer further elaborates on reasoning: 'All unclear parts have been answered The authors' explained why the chosen baseline makes the most sense.' This provides further justification for their point. The reviewer's question: 'Questions  Do you think there is a way to test beforehand whether I(X_1...' is a request for clarification, not a claim requiring evidence.", "helpfulness_rationale": "The reviewer's point is 5. They explicitly state what they believe is missing: 'Ideally other baselines would also be included, such as the other works discussed in related work 29, 5, 6.' They also provide a clear action: 'After the Authors' Response My weakness points after been addressed in the authors' response. Consequently I raised my score.' This indicates a direct action the authors should take. The reviewer further elaborates on actions: 'All unclear parts have been answered The authors' explained why the chosen baseline makes the most sense.' This provides concrete steps the authors should take. While the reviewer also asks a question, this is a request for clarification, not a critique of the paper's content. The reviewer's attempt to raise their score demonstrates a positive attitude and a desire for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states the inconsistency between L_task and L_class. While it doesn't directly tell the authors what to do, it points to a clear discrepancy that needs addressing. The action is somewhat implicit  the authors should understand that the naming conventions are different in these two places.", "grounding_specificity_rationale": "The review point mentions 'L_task' in the text and 'L_class' in Figure 1. It identifies the *locations* of the inconsistency. However, it doesn't explicitly state which loss function is intended to be the 'task loss' or the 'class loss'. The grounding is somewhat weak because the authors need to infer the intended meaning from the context.", "verifiability_rationale": "The review point makes a factual statement about the inconsistency in naming conventions. It is clear that 'L_task' in the text and 'L_class' in Figure 1 refer to different loss functions. This claim is supported by the information presented in the text and figure, making it 5.", "helpfulness_rationale": "The review point identifies a clear discrepancy in naming conventions used in a paper. This is likely to be helpful for the authors to ensure consistency in their terminology. While it doesn't explicitly tell them what to do, it points to a potential source of confusion and a place where they should doublecheck their work."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks 'What are other limitations of the method?' which is a direct action suggesting the authors should consider limitations. However, it lacks specific guidance on *how* to identify or address these limitations. The question is broad and doesn't provide concrete steps or examples, making it less actionable than a point that says 'You should check the literature on efficiency'.", "grounding_specificity_rationale": "The review point explicitly mentions 'the graph case' and its limitation 'the network was pretty shallow'. This provides a clear and specific reference point for the authors. They can easily identify the section or aspect being addressed. The question is also quite specific, asking 'is this the case here?', directly linking it to their current work. Therefore, the grounding is strong.", "verifiability_rationale": "The review point itself does not contain a claim that needs verification. It's a question prompting the authors to consider limitations. Therefore, it doesn't fit the 'Verifiability' evaluation criteria as it doesn't present a statement that requires logical reasoning, common knowledge, or external references to be supported.", "helpfulness_rationale": "The review point is relevant and prompts the authors to think critically about their method's limitations. However, it lacks specific guidance or suggestions on how to address these limitations. It's a good starting point for discussion but doesn't provide concrete steps or insights beyond the general idea of considering limitations. Therefore, while it's not *unhelpful*, it doesn't offer significant improvement potential either."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the tasks used for evaluation: 'This work only uses answer generation and summarization to evaluate the proposed method.' They also state the issue: 'While these are indeed conditional generation tasks, they are close to \"open domain\" generation rather than \"close domain\" generation such as machine translation.' The reviewer suggests a specific improvement: 'I think this work would be more convincing if it is also evaluated in machine translation which exhibits much lower uncertainties per word.' While the reviewer identifies the tasks and the domain issue, the suggestion of machine translation, while relevant, is more of a suggestion for improvement rather than a direct actionable point within the current review. The reviewer does not explicitly state an action or how to implement the suggested change within the current review.", "grounding_specificity_rationale": "The reviewer explicitly states the tasks used for evaluation: 'This work only uses answer generation and summarization to evaluate the proposed method.' They also explicitly states the issue: 'While these are indeed conditional generation tasks, they are close to \"open domain\" generation rather than \"close domain\" generation such as machine translation.' The reviewer clearly identifies the specific tasks being criticized. The reviewer also suggests a specific improvement: 'I think this work would be more convincing if it is also evaluated in machine translation which exhibits much lower uncertainties per word.' This suggests a clear understanding of the specific tasks and their limitations. The reviewer does not mention any ambiguity or missing parts related to the tasks.", "verifiability_rationale": "The reviewer states the tasks used for evaluation: 'This work only uses answer generation and summarization to evaluate the proposed method.' They also state the issue: 'While these are indeed conditional generation tasks, they are close to \"open domain\" generation rather than \"close domain\" generation such as machine translation.' The reviewer suggests a specific improvement: 'I think this work would be more convincing if it is also evaluated in machine translation which exhibits much lower uncertainties per word.' The reviewer's critique is based on the * nature of these tasks and their relation to the concept of 'close domain' generation. While the reviewer doesn't explicitly claim the current evaluation is definitively '1', the lack of a clear connection to 'close domain' principles and the suggestion of a more suitable method can be interpreted as a lack of strong, direct evidence for the current evaluation's validity within the context of 'close domain' tasks. The reviewer does not provide any external references to support their claim about the 'open domain' nature of these tasks.", "helpfulness_rationale": "The reviewer explicitly states the tasks used for evaluation: 'This work only uses answer generation and summarization to evaluate the proposed method.' They also explicitly states the issue: 'While these are indeed conditional generation tasks, they are close to \"open domain\" generation rather than \"close domain\" generation such as machine translation.' The reviewer suggests a specific improvement: 'I think this work would be more convincing if it is also evaluated in machine translation which exhibits much lower uncertainties per word.' The reviewer clearly identifies the limitations of the current evaluation methodology and provides a concrete suggestion for improvement. This provides a clear direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer is explicitly asking for specific details (dropping rate and number of masks) regarding the dropout mechanism described in the paper. While the request is explicit, the reviewer hasn't found the specific values, making it 3 but not fully concrete.", "grounding_specificity_rationale": "The reviewer is asking about a specific mechanism (dropout) described in the paper, making it grounded. They are also asking for specific values (dropping rate and number of masks), which adds to the specificity.", "verifiability_rationale": "The reviewer is pointing out a lack of information in the paper regarding the dropout mechanism. While the request is about identifying a weakness, the lack of specific details makes it 1.", "helpfulness_rationale": "The reviewer's question directly addresses a missing implementation detail (dropout mechanism) in the paper. This is a valid concern for the authors, as explicitly stating these details can significantly improve clarity and reduce the authors' workload. Therefore, the review point is 5 in identifying this missing information."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment states a problem ('This paper does not provide the type of GPUs, and inference time when testing.') but does not provide explicit instructions on how to address it. It lacks concrete steps for the author to take.", "grounding_specificity_rationale": "The comment refers to 'this paper' in a general sense, indicating a lack of specific section or detail. It doesn't pinpoint a specific table, figure, or unique aspect.", "verifiability_rationale": "The comment states a factual observation about the paper's content ('This paper does not provide the type of GPUs, and inference time when testing.') but does not explicitly frame it as a weakness or suggestion for improvement. While the missing information is generally considered important, the comment itself is a verifiable statement.", "helpfulness_rationale": "The comment identifies a factual omission ('This paper does not provide the type of GPUs, and inference time when testing.') which is a relevant piece of information for evaluating or reproducing the work. While it doesn't suggest a solution, it points out a significant gap, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question seeking clarification on the attention mechanism, which is a direct action the authors should take to understand the method better. While not a direct instruction on *how* to implement it, the request for clarification is an explicit action.", "grounding_specificity_rationale": "The reviewer is directly asking a question about a specific aspect of the method (the attention mechanism and its scope) and points to a specific part of the description (equation 2 and N_l^(s)) as evidence for their question. They are asking 'Can each node attend to its own lowerlevel representation? From equation 2, it seems to be that only neighbouring nodes are attended to, based on the description of N_l^(s).'", "verifiability_rationale": "The reviewer is making a claim based on their interpretation of equation 2 and asking for verification of this claim. They are stating a potential discrepancy between the description of N_l^(s) and the implication of equation 2.", "helpfulness_rationale": "The reviewer's question is directly aimed at clarifying a key aspect of the method, which will likely be very helpful for the authors when implementing and understanding the paper. They are seeking to resolve a potential misunderstanding about the attention mechanism's scope."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point presents two suggestions: including results on a specific dataset and evaluating performance on another. While these suggest actions, they lack explicit instructions or concrete steps on how to implement them. The phrasing is more about desiring improvements rather than directly instructing on what to do.", "grounding_specificity_rationale": "The review point explicitly mentions 'crowdpose dataset' and 'Table 4', clearly identifying the specific dataset and table being referenced. It also mentions 'MS COCO dataset' and 'easy (non occluded) settings', specifying the dataset and a particular subset for evaluation.", "verifiability_rationale": "The review point does not contain a claim that can be verified. It presents suggestions for future work or analysis rather than stating a verifiable fact about the paper.", "helpfulness_rationale": "The suggestions in the review point are relevant to researchers working with the mentioned datasets and interested in performance evaluation. However, they are more about pointing towards future actions rather than providing immediate actionable steps to improve the current draft. The suggestions are somewhat generic and lack specific details on how to implement them within the current work."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review states: \"The claim of making use of \u201cannotation guideline\u201d may be an overstatement  this paper only considered label name, label description and fewshot examples, however, annotation guideline in IE domain are very complicated and was curated by linguists. E.g., For TACRED slot filling (https://tac.nist.gov/2015/KBP/ColdStart/guidelines/TAC_KBP_2015_Slot_Descriptions_V1.0.pdf), section 3.6 per:city_of_birth, they use \u201cGPEs below the city level (e.g. 5 boroughs of New York City) are not valid fillers.\u201c as an example rule to guide annotators. The prompts proposed by this paper might not fully capture the depth of true guideline understanding.\" While the reviewer identifies a potential overstatement, they do not explicitly state what is missing or how to carry out this action. The suggestion about complex guidelines and the TACRED example is a statement of opinion, not a direct instruction for improvement.", "grounding_specificity_rationale": "The review focuses on the \"annotation guideline\" aspect, implicitly referring to the IE domain and the complexity of guidelines. However, it doesn't explicitly mention a specific section, table, or figure in the paper it is reviewing. The reviewer's point is about the general aspect of annotation guidelines, not a specific element within the submitted work.", "verifiability_rationale": "The review contains the claim: \"The claim of making use of \u201cannotation guideline\u201d may be an overstatement\". The reviewer then provides a *reason* for this claim: \"this paper only considered label name, label description and fewshot examples, however, annotation guideline in IE domain are very complicated and was curated by linguists. E.g., For TACRED slot filling (https://tac.nist.gov/2015/KBP/ColdStart/guidelines/TAC_KBP_2015_Slot_Descriptions_V1.0.pdf), section 3.6 per:city_of_birth, they use \u201cGPEs below the city level (e.g. 5 boroughs of New York City) are not valid fillers.\u201c as an example rule to guide annotators. The prompts proposed by this paper might not fully capture the depth of true guideline understanding.\" This reasoning, along with the external reference to TACRED guidelines, provides sufficient justification for the claim.", "helpfulness_rationale": "The review points out a potential overstatement of the paper's use of annotation guidelines. While it doesn't offer a direct solution, it raises a valid concern about the scope of the paper's evaluation of annotation guidelines. The reviewer provides an example from another domain (TACRED) to illustrate the complexity of annotation guidelines, which could encourage the authors to consider a broader range of guidelines in their work. This feedback is relevant to the topic of annotation guidelines and highlights a potential limitation in the paper's approach."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The comment states that the authors did not show the possible weaknesses of the proposed model. While this identifies a weakness, it does not specify how to demonstrate these weaknesses. The action is implicit (showing weaknesses), but the implementation is vague.", "grounding_specificity_rationale": "The comment is 1 because it does not specify which part of the paper or model it is referring to. It makes a general statement about the lack of demonstrated weaknesses without pointing to a specific location or aspect.", "verifiability_rationale": "The comment makes a claim ('the authors did not show the possible weaknesses of the proposed model') but does not provide any justification or suggestions on how to show these weaknesses. It lacks supporting reasoning or examples.", "helpfulness_rationale": "The comment identifies a valid concern (lack of demonstrated weaknesses) but fails to provide any actionable steps or guidance on how to address it. It points out a problem but doesn't offer a solution."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of detail in the related work section. While they suggest 'more work on GLN' and 'reflect the advantages or difference of the proposed method, such as the difference from BGLN', this is a suggestion for improvement rather than a concrete action the authors can take immediately. The reviewer identifies a problem, but the proposed solution is broad and lacks specific implementation details.", "grounding_specificity_rationale": "The reviewer specifically mentions 'the introduction of related work' as the area needing improvement. This clearly identifies the specific part of the paper where the issue lies. However, the reviewer does not specify *which* papers are missing or *how* the related work should be discussed. The grounding is explicit about the *section* but lacks detail about the *content*.", "verifiability_rationale": "The reviewer states that 'the introduction of related work is not sufficient'. This is a claim that something is lacking. While the reviewer suggests adding more GLN work and comparing to BGLN, this is presented as a suggestion for improvement rather than a verifiable justification for the insufficiency of the current related work. The reviewer identifies a deficiency but doesn't provide concrete evidence or examples to support their claim.", "helpfulness_rationale": "The reviewer's comment highlights a clear weakness in the paper: the insufficient related work section. This directly points to a lack of context and proper contextualization. While the reviewer doesn't offer a specific solution within the scope of this review, they clearly identify an area where the paper falls short, which is directly beneficial for the authors to understand the paper's place in the field."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a difference in hyperparameter settings for dropout in two different approaches (Moon's and Variational dropout) and asks a question. While the reviewer doesn't explicitly state what needs to be done, they identify a potential area for improvement in Moon's approach by suggesting a more granular dropout strategy. This implies an action, but it's not as concrete as suggesting a specific change. The reviewer also asks a question, which doesn't constitute an action at all.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Moon's approach' and 'Variational dropout', providing clear grounding. They also specify 'inputoutput dropout' and 'recurrent dropout', further grounding the discussion within the technical details of these methods. The reviewer is also asking a question about the reasoning behind these differences, adding further specificity to the feedback.", "verifiability_rationale": "The reviewer makes a claim about the difference in hyperparameter settings and asks a question about the reasoning behind it. While the reviewer doesn't provide external references or logical reasoning within the review point itself, the question itself is a valid point for the authors to consider and potentially investigate. The claim about the difference is verifiable, but the reasoning behind it is not.", "helpfulness_rationale": "The reviewer points out a potential area for improvement in Moon's approach by suggesting a more granular dropout strategy. They also ask a question about the reasoning behind the different dropout settings. This provides actionable feedback and constructive suggestions, prompting the authors to consider their design choices. While it doesn't tell them *exactly* what to do, it guides them towards a more detailed analysis of their model."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment states \"ProtPainter just provides an empirical conformation estimation.\" This is a statement of what ProtPainter *does*, not necessarily what it *should* do or how to improve it. While it implies a need for further optimization and validation, it doesn't explicitly tell the author *how* to achieve these. The action is implied but not stated directly, making it less actionable.", "grounding_specificity_rationale": "The comment mentions \"ProtPainter\" and \"binder design\" generally. It doesn't pinpoint a specific section, table, figure, or unique aspect within the binder design or ProtPainter. While it identifies the *what* and *area*, it lacks specificity about *where* or *what specific aspect*.", "verifiability_rationale": "The review point states \"ProtPainter just provides an empirical conformation estimation.\" This is a statement of ProtPainter's behavior, not a claim that needs verification. There is no explicit claim about why this is a problem, how it hinders the binder design, or what needs to be validated. The statement is a description rather than a claim requiring evidence.", "helpfulness_rationale": "The comment identifies a limitation of ProtPainter (empirical conformation estimation) and suggests further optimization and validation. This points to a meaningful weakness and encourages the author to explore and improve the tool. While it doesn't provide explicit steps on how to do this, it motivates the author to think critically about the tool's functionality and its impact on the binder design. Therefore, it is 3 as it highlights an area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'More evaluation would have been welcome.' This indicates a clear action the authors should take, making the review actionable. However, the reviewer does not specify *what* kind of additional evaluation is needed, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'CIFAR10 in the full label and lower label scenarios.' This clearly identifies the specific part of the paper or context being addressed, indicating strong grounding. However, the reviewer does not specify *what* aspects of CIFAR10 or the label scenarios need more evaluation, making the grounding somewhat underspecific.", "verifiability_rationale": "The reviewer makes a recommendation: 'more evaluation would have been welcome.' This is a claim that needs to be supported. However, the reviewer does not provide any reasoning or justification for why more evaluation is needed, making the claim 2. The reviewer simply states a desire for more, without explaining the limitations of the current evaluation or the benefits of additional evaluation.", "helpfulness_rationale": "The reviewer provides a clear recommendation ('more evaluation would have been welcome') and identifies a specific area for improvement ('CIFAR10 in the full label and lower label scenarios'). This suggests the review is intended to be helpful, even though the specifics of the additional evaluation are missing. The authors can infer the need for more evaluation and potentially focus on the mentioned datasets. The impact is likely to be helpful, but the lack of specific details might limit its immediate effectiveness."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer's questions directly address how the algorithm should be used and what happens with more iterations. The missing citation for Laplacian eigenmaps is also a clear gap. These points provide specific suggestions for improvement, making the comment actionable.", "grounding_specificity_rationale": "The reviewer's questions about the algorithm's behavior with more iterations (T > 2) are general and could apply to any algorithm. The reference to 'Fig.' is ambiguous and does not clearly identify a specific part of the paper being addressed. Therefore, the grounding is weak. While the questions are specific about the algorithm's behavior, the lack of a clear target makes the grounding weak overall.", "verifiability_rationale": "The reviewer's questions about the algorithm's behavior with more iterations are logical and based on common knowledge about iterative algorithms. The missing citation for Laplacian eigenmaps is a factual omission that should be verifiable. Therefore, the claim is 3. The questions about iterations are verifiable. The missing citation is also verifiable if added. However, the lack of a clear connection to the placement of the comment makes it less verifiable in that specific context.", "helpfulness_rationale": "The reviewer's questions highlight important areas for improvement, such as clarifying the algorithm's behavior and adding a missing citation. The placement of the comment itself is a helpful suggestion to improve the clarity of the paper. While the missing citation is a significant omission, the reviewer's questions are directly related to improving the understanding and completeness of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states a problem ('I don't understand why...') but does not explicitly suggest a solution or action. While the reviewer offers a suggestion ('...the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed CBN approach'), this suggestion is not framed as a concrete action to be taken by the authors. The criticism is more about the *organization* of the paper rather than a direct, actionable improvement request.", "grounding_specificity_rationale": "The reviewer criticizes the inclusion of the ResNet architecture description but does not specify which part of the paper is unclear or problematic. The criticism is general and does not point to a specific section, table, figure, or unique aspect of the paper. The reviewer's statement is an implication of the relevance of the ResNet description, but not a direct identification of the issue.", "verifiability_rationale": "The reviewer's comment is a question (' I don't understand why Section 2.1 is included.') and does not present a claim that requires verification or justification. The comment is a statement of confusion or a request for clarification, not a statement that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The reviewer identifies a valid point about the paper's organization and suggests a solution ('...the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed CBN approach'). This suggests the reviewer has a genuine concern and proposes a potential improvement. However, the criticism is vague and lacks specific examples or actionable suggestions. The lack of clarity in *why* the ResNet description is included makes the reviewer's point less impactful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The reviewer identifies a problem ('it is unclear how the resulting matrix is expected to be sparse') but doesn't provide a direct action or solution for the author. It points to a missing piece of information.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'equation (1)' and 'the resulting matrix', clearly identifying the specific part of the paper being discussed.", "verifiability_rationale": "The review point is a question ('it is unclear how the resulting matrix is expected to be sparse') and does not present a claim that needs verification.", "helpfulness_rationale": "The review point identifies a potential area of confusion for the author, suggesting they might not fully understand how the matrix multiplication leads to a sparse matrix. While it doesn't offer a direct solution, it points to a specific area that needs clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the relationship between NGD and NGF ('NGD is a discretization of NGF') and concludes that initialization should play a role in the context of IVPs ('Thus, initialization should play a role such as pretraining.'). This constitutes an explicit action. However, the reviewer does not provide specific details on *how* initialization should be pretrained, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'NGD,' 'NGF,' 'initial value problem (IVP),' and 'initialization.' While these terms are mentioned, the reviewer does not explicitly identify a specific section or element in the paper they are referring to. The connection is implied but not explicitly made. The reviewer also suggests 'pretraining' as a potential action for initialization, which is a general concept and lacks specific grounding within the paper's content.", "verifiability_rationale": "The reviewer makes a claim about the relationship between NGD, NGF, discretization, IVP, and initialization. They provide a reference to support their claim about the limitations of the empirical Fisher approximation, which supports the 'claim extraction' aspect. They also define an IVP, which supports the 'specificity' aspect. However, the connection to 'pretraining' is more conceptual and lacks direct verifiable evidence within the review point itself.", "helpfulness_rationale": "The reviewer points out a potential area for clarification in the original paper regarding the role of initialization in the context of NGD, NGF, and IVPs. They suggest that initialization should be considered similar to pretraining and provide a reference to support this. While the suggestion is relevant and potentially helpful, the lack of specific details about the pretraining aspect and the somewhat vague connection to IVPs make the overall contribution less impactful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point has two parts. The first part, 'It is not clear how named entities were extracted from the datasets,' is implicit. The reviewer identifies a deficiency but doesn't explicitly state what needs to be done. The second part, 'Suggest adding a section, paragraph, or subsection,' is explicit. The reviewer directly states the desired action. However, the reviewer doesn't provide specific details on how the named entity extraction should be clarified, making the actionable part vague. The suggestion for proofreading is concrete, but the grounding is missing, as the reviewer doesn't specify where the improvement is needed.", "grounding_specificity_rationale": "The review point mentions 'named entities were extracted from the datasets,' which is a specific part of the paper. However, the reviewer doesn't specify what exactly needs to be extracted or how the extraction should be performed. Therefore, the grounding is weakly grounded. The suggestion to 'add a section, paragraph, or subsection' is specific about the action. However, the reviewer doesn't specify *where* in the paper this addition should occur, making the grounding weak.", "verifiability_rationale": "The review point states 'It is not clear how named entities were extracted from the datasets' without providing any justification or evidence for this claim. This is a statement of observation, not a claim requiring verification. However, the suggestion 'Suggest adding a section, paragraph, or subsection' is a claim that could be better supported by explaining the potential benefits of such an addition or providing examples.", "helpfulness_rationale": "The review point raises a valid concern about the clarity of named entity extraction, which could hinder the readability and usability of the dataset. However, the reviewer doesn't offer a specific solution or suggestion for improvement, making the feedback somewhat general and potentially unhelpful. The suggestion to 'add a section, paragraph, or subsection' is 5 and directly addresses a likely need for authors to improve readability. However, the reviewer doesn't specify *where* this addition should occur, making the actionable suggestion less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem (L and E should be defined) and suggests a concrete action (define L and E). This directly addresses a lack of clarity and provides a clear path for improvement.", "grounding_specificity_rationale": "The reviewer explicitly points to lines 296 and 302, indicating a clear understanding of where the inconsistency lies. They also specify the nature of the issue (inconsistent italicization of L and E), making it 5.", "verifiability_rationale": "The reviewer makes a claim about a verifiable fact: the inconsistent italicization of L and E in the specified lines. This claim can be verified by checking the paper directly.", "helpfulness_rationale": "The reviewer's point, if addressed, would significantly improve the clarity and correctness of the paper, making it a highly valuable piece of feedback for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies specific line numbers (2, 56, 158, 265) and points out grammatical errors or areas for improvement. The suggested corrections are also directly actionable. The reviewer provides clear, concrete steps for the authors to take.", "grounding_specificity_rationale": "The review point explicitly refers to specific line numbers within the paper. The identified issues are also specific and welldefined grammatical errors or suggestions. The reviewer doesn't refer to sections, tables, or figures, but the line number is a very specific reference point within the paper. The suggested corrections are also specific to the identified issues.", "verifiability_rationale": "The review point contains claims about grammatical errors and suggests specific corrections. These claims are directly supported by the identified issues and the suggested fixes. The reasoning is clear and precise. The references to multiway arrays and ConAC are also specific and welldefined.", "helpfulness_rationale": "The review point is highly specific, pointing to exact line numbers and identifying clear grammatical errors. The suggestions are actionable and directly address the identified issues. This is extremely helpful for the authors as it directly guides them to make the necessary corrections. The reviewer provides clear and constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'Mistakes in Eqs.' which indicates a perceived flaw or error in the equations. This directly points to a problem that needs addressing. The reviewer is not just asking a question but identifying a potential issue. Therefore, the action is explicit.", "grounding_specificity_rationale": "The comment directly references 'W4 \u2013 Mistakes in Eqs.' This is a very specific reference to a particular section and equation in the paper. The reviewer is not making a general comment but is pinpointing a specific area for potential error. Therefore, the grounding is fully grounded.", "verifiability_rationale": "The comment contains the claim 'Mistakes in Eqs.' and points to two possible interpretations of the potentially incorrect operation ('inversion of matrix determination' or 'number the division of the number of samples'). This provides some basis for verification by highlighting potential areas of confusion. However, it doesn't offer specific examples or citations to definitively prove the mistake or clarify the operation. Therefore, the verifiability is 3.", "helpfulness_rationale": "The comment identifies a potential error in a specific equation (W4) and asks a focused question to clarify its meaning. While it doesn't provide a definitive answer, it clearly points to a concrete issue that needs to be investigated. By highlighting this specific equation, the reviewer helps the authors prioritize their efforts and understand a potential problem in their methodology or calculations. Therefore, the review is 3 in guiding the authors to a specific area of concern."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer implies a suggestion to compare performance in different logic types, but the suggestion itself is not explicitly stated as an action to be taken on the paper. The action is implied rather than directly pointed out.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the proposed method' and 'the paper', indicating a clear grounding of the suggestion within the context of the work being reviewed. The suggestion also specifies a comparison between sequential and combinational design, adding to its specificity.", "verifiability_rationale": "The reviewer's point is more of a suggestion for an experiment or further investigation rather than a direct claim that can be immediately verified. While the suggestion implies a potential benefit, it doesn't present a verifiable statement about the paper itself.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors to consider. The suggestion to compare performance in different logic types is directly aimed at improving the method and provides a concrete direction for experimentation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer is directly asking for the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This is a clear and explicit request for a specific calculation or report. The reviewer is prompting for a direct answer to their question, indicating a high level of actionability as they are asking for a concrete piece of information.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'LDA+LSTM' baseline and the 'topic switch percent' metric. This demonstrates a clear and precise identification of the specific part of the paper and the issue being addressed. The terms are welldefined within the context of the paper, indicating high grounding specificity.", "verifiability_rationale": "The reviewer is not presenting a claim that requires verification. They are simply asking for the value of a specific metric for a specific baseline. There is no external reference or logical reasoning provided within this review point to support the request. Therefore, the verifiability is low as the information is not provided in this review point.", "helpfulness_rationale": "The reviewer is asking for a specific piece of information (performance of the LDA+LSTM baseline in terms of the topic switch percent metric). This is a direct and actionable request. While the information might not be explicitly stated in this review point, the request itself is clear and relevant to understanding the model's performance, making it 5 for the authors to consider. The reviewer is essentially asking for a calculation or report, which is a concrete action the authors can take."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states that the claim about the synergies between DQD and PPO is 'insufficiently backedup'. This indicates a lack of explicit action or suggestion on the part of the reviewer. While the reviewer points out missing information (TD3GA and the importance of DQDTD3 comparison), they don't directly suggest how to improve the paper based on this observation. Therefore, it can be considered 2 as the reviewer identifies a deficiency but doesn't provide concrete steps to address it.", "grounding_specificity_rationale": "The reviewer states that the 'main paper does not even mention the TD3GA algorithm'. This clearly indicates that the reviewer cannot confidently determine which part of the paper the comment addresses. The lack of mention of TD3GA suggests that the paper does not explicitly identify this algorithm. While the reviewer mentions the importance of the DQDTD3 comparison, the absence of a mention of TD3GA indicates weak grounding. Therefore, it can be considered 2.", "verifiability_rationale": "The reviewer makes a claim about the 'synergies between DQD and PPO looks insufficiently backedup'. This is a claim that requires verification. However, the reviewer does not provide any specific evidence or references to support this claim. The lack of justification makes the claim 1. Therefore, it can be considered 1.", "helpfulness_rationale": "The reviewer's comment directly points out a lack of information and justification regarding the synergies between DQD and PPO. This lack of information and justification makes the comment not helpful for the authors in improving their draft. Therefore, it can be considered not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states an action: 'I suspect the latter, but some slight rephrasing would be great.' This indicates a desire to clarify the meaning of 'confident'. However, the action is vague as it doesn't specify *what* needs rephrasing or *where* the confusion lies within the concept of 'ceterus paribus convexity'.", "grounding_specificity_rationale": "The comment implicitly refers to the section or part of the paper where 'ceterus paribus convexity' is discussed, as stated in the review point: 'We have found it easier to be confident about applying ceterus paribus convexity;'. While the reviewer doesn't explicitly name the section, the context implies a specific area in the paper. However, the comment doesn't specify *what* is unclear within that section.", "verifiability_rationale": "The comment contains a claim: 'the word \"confident\" threw me off a little here, as I was not sure if this is about model confidence or human interpretability.' This is a statement of opinion or judgment about the clarity of the term. However, the comment does not provide any logical reasoning, common knowledge, or external references to support this claim. It's a statement of confusion without further justification.", "helpfulness_rationale": "The review point asks for clarification on a specific term ('confident') within a particular context ('ceterus paribus convexity'). This is a valuable piece of feedback as it points to a potential area where the authors' explanation could be improved. While it doesn't directly suggest a concrete change, it identifies a weakness in the presentation of the concept."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment states 'novelty is limited' and 'tighter CIs with finetuning are expected'. While it identifies a potential issue, it doesn't explicitly state an action or provide concrete steps for the authors to take to address the limited novelty or the expected behavior of CIs. The explanation is a hypothesis, not a direct action.", "grounding_specificity_rationale": "The comment makes general statements about the 'novelty' of the work and the 'expected behavior' of confidence intervals. It does not explicitly refer to a specific section, table, figure, or unique aspect of the paper. The implications are broad and not tied to a concrete element.", "verifiability_rationale": "The comment states 'tighter CIs with finetuning are expected' as a reason for limited novelty. This is more of an interpretation and a potential explanation rather than a definitive claim that requires immediate verification. The novelty is presented as a finding, not a claim to be proven.", "helpfulness_rationale": "The review points out a potential issue with the authors' work (limited novelty) and offers a plausible explanation (expected CI behavior). While it doesn't provide concrete solutions, it raises a valid concern that could prompt the authors to reflect on their work and potentially address these points in future iterations. It's not entirely useless, as it points to a significant aspect of their research."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point is a question about the objective of adversarial prediction accuracy, not a direct instruction or action item for the author to improve their work. It asks 'In which real scenarios is the objective given by the adverserial prediction accuracy they propose, in contrast to classical prediction accuracy?' This is a query for information about the evaluation metric, not a directive on how to fix the paper.", "grounding_specificity_rationale": "The review point is about the objective of a different evaluation metric (adversarial accuracy) compared to classical accuracy. It does not identify a specific part of the paper or detail that needs addressing. It's a question about the *purpose* of a metric, not a critique of a specific section in the paper.", "verifiability_rationale": "The review point itself is not a claim that requires verification. It's a question asking 'In which real scenarios is the objective given by the adverserial prediction accuracy they propose, in contrast to classical prediction accuracy?'. There is no assertion being made that needs to be supported by evidence.", "helpfulness_rationale": "The review point is a question about the objective of a different evaluation metric. While it might be interesting for the author to consider, it doesn't directly provide actionable feedback or suggestions on how to improve their draft. It's a metaquestion about evaluation, not a direct improvement guide."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies several areas where the evaluation could be improved, but it doesn't explicitly state what actions the authors should take. While the reviewer mentions 'more transparency regarding the experiment setup,' 'exploring the effects of varying the number of InContext Examples,' and 'evaluating solely on one dataset,' these are suggestions rather than explicit instructions. The reviewer infers what is missing rather than stating it directly. Therefore, while the reviewer points out potential improvements, the actions are not explicitly stated, making it 3 but not fully actionable.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. The reviewer is criticizing the evaluation section as a whole, pointing out general limitations like 'lack of comprehensiveness' and 'reliance on one dataset.' There is no mention of a specific section, table, figure, or unique aspect of the paper that the reviewer is referring to. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point contains claims, such as 'the evaluation in the paper is not sufficiently comprehensive' and 'the evaluation relies solely on one dataset, which may limit the generalizability of the results.' However, these claims are not wellsupported. The reviewer states what is missing but does not provide evidence or references to back up their claims about the evaluation being 'not sufficiently comprehensive' or 'relying solely on one dataset.' The reasoning and common knowledge provided are vague. Therefore, the claims are not wellverified, making the verifiability low.", "helpfulness_rationale": "The review point identifies several areas where the authors could improve their evaluation section, such as increasing comprehensiveness, improving transparency, exploring the effects of varying the number of InContext Examples, and evaluating on multiple datasets. These suggestions are concrete and actionable, providing the authors with specific directions for improvement. While the review doesn't offer specific solutions for each point, it clearly highlights what needs to be done. Therefore, the review point is helpful as it points out areas for improvement, even if it doesn't provide detailed guidance on how to achieve those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests improvements but lacks explicit instructions on how to implement them. The action is implied, making it implicit and therefore 1.", "grounding_specificity_rationale": "The review point explicitly mentions specific related work examples (1, 2, 3), indicating full grounding. However, it doesn't specify how these works should be addressed, making it only weakly specific.", "verifiability_rationale": "The review point expresses a desire for more attention to related work rather than making a claim that requires verification.", "helpfulness_rationale": "The review point identifies a valid area for improvement (related work) and provides a list of specific works. This makes it 3 as it highlights a weakness. However, the lack of concrete guidance on how to address this limits its full helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential weakness (limited novelty due to the Blackwell winner concept) and suggests focusing on algorithmic aspects. However, it does not provide explicit instructions on how to address these issues. The authors are left to interpret what 'should have' been focused on and how to demonstrate the novelty. The action is implied but not explicitly stated in a concrete manner.", "grounding_specificity_rationale": "The comment is general and does not pinpoint a specific section, table, figure, or unique element of the paper. While it mentions 'algorithmic aspects' and 'novelty of the paper,' it doesn't clearly identify which part of the paper is lacking these elements. The grounding is implied but not explicit.", "verifiability_rationale": "The comment contains claims, such as 'the paper should have focused on the algorithmic aspects' and 'the novelty of the paper seems limited.' However, it lacks specific evidence or references to support these claims within the review point itself. The reasoning is present but not backed by external references or concrete examples within the review.", "helpfulness_rationale": "The comment identifies potential weaknesses in the paper's focus and novelty. While it highlights areas for improvement, it does not offer concrete suggestions or actionable steps for the authors to take. The authors are left to determine how to address the identified issues themselves, which limits the helpfulness of the comment."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper could be improved by making comparisons more systematic and by comparing the best performance of each method. This directly identifies an action the authors should take. The reviewer also implies that the current comparisons are lacking by suggesting a specific improvement. Therefore, the action is clearly defined and actionable.", "grounding_specificity_rationale": "The reviewer mentions 'the most closely related work of Zemel et al. (2013)' and refers to 'the present paper'. While they don't specify a particular section or detail, they clearly identify the area of comparison. The reviewer also suggests a *type* of comparison ('systematically compare the best performance of each method'), which specifies the nature of the improvement being suggested. However, the *specific aspect* of the current paper that needs to be compared to Zemel et al. (2013) is not explicitly pointed out. The grounding is present but not fully specific.", "verifiability_rationale": "The reviewer makes a claim that the paper explains differences and provides comparisons in simulations with respect to Zemel et al. (2013). This is a clear statement of what they believe. The reviewer then suggests a *method* for improvement ('systematically compare the best performance'). This suggests a perceived lack of rigor in the current comparisons and implies that the current comparisons are not as strong as they could be. While not a direct criticism of a flaw, it points to a potential area for improvement, making the claim 3.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement: 'systematically compare the best performance of each method'. This is a specific and constructive comment that directly addresses a potential weakness in the paper's comparison methodology. The reviewer is not just pointing out a problem but also offering a concrete way to solve it. This makes the review point 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the connection to the 'properties of universal kernels' and refers to 'chapter 4 of Steinwart and Christmann'. This clearly indicates an intended action: to investigate this connection.", "grounding_specificity_rationale": "The reviewer mentions 'properties of universal kernels' and specifically points to 'chapter 4 of Steinwart and Christmann'. This provides a clear indication of the section being referenced, indicating strong grounding. However, the reviewer does not specify *which* property or *how* this relates to the paper being reviewed, making the specificity somewhat underspecific.", "verifiability_rationale": "The reviewer makes a suggestion: 'See in particular chapter 4 of Steinwart and Christmann...'. This constitutes a claim. However, the reviewer does not provide any justification or evidence *within the review point itself* to support this claim. The evidence for this suggestion would need to be found externally, in Steinwart and Christmann.", "helpfulness_rationale": "The reviewer suggests investigating a connection to a specific theoretical concept (universal kernels) in a relevant textbook chapter. This directly addresses a potential weakness in the authors' understanding of the theoretical foundations. While the exact nature of this weakness isn't specified, the suggestion is actionable and could be very helpful if the connection is indeed relevant to the authors' work."}
