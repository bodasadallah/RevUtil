{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point points out a potential issue (noise in the dataset). This is an observation, not a direct action. While it *suggests* an action: \"Check the dataset for noise.\", the review itself isn't explicit or concrete. Therefore, it's not actionable as it stands.", "grounding_specificity_rationale": "The reviewer mentions \"artificially created dataset,\" \"noise,\" \"misinformation,\" and \"outofcontext images.\" This is pointing to *specific* potential problems within the dataset. They are not just saying \"the dataset is noisy\" but are pinning down the *nature* of the potential noise. This can be considered highly specific.", "verifiability_rationale": "The reviewer states these are \"potential\" issues. They don't provide concrete evidence or references to support this claim. It's a *hypothesis* about the dataset's quality. Therefore, it's not verifiable as a fact.", "helpfulness_rationale": "The reviewer is expressing a concern about the dataset's quality. While it points to a potential problem, it doesn't offer *solutions* or *directions* for improvement. It's a *statement* of a problem, not a helpful suggestion. Therefore, it's not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their understanding of HIERENC's input calculation and provides a concrete explanation of the potential noise issue. While the reviewer doesn't state that the current implementation is *explicitly* stated as an action, the suggestion to average all entity instantiations implies a clear action to be taken (i.e., to consider all entities). The vagueness lies in the reviewer's suggestion of 'this would most likely introduce a lot of noise' without providing a specific action or how to mitigate it. The reviewer identifies the action (average all entities) but doesn't detail how to apply it or what the expected outcome should be.", "grounding_specificity_rationale": "The reviewer mentions 'HIERENC' which is a specific component of the model. However, the reviewer doesn't explicitly state which part of the paper or model architecture they are referring to in detail. The connection between 'HIERENC' and the specific averaging operation isn't explicitly stated, making the grounding somewhat weak. The specificity is high in the reviewer's understanding of HIERENC's input, but the grounding is weak because the mechanism isn't clearly linked to a specific part of the paper or model.", "verifiability_rationale": "The reviewer makes a claim about a potential issue with HIERENC's input calculation. The verifiability comes from the logical reasoning that averaging all entity instantiations could introduce noise because only one instantiation is correct. This is a plausible claim that can be verified by understanding the typical processing of entity mentions in such models. The reasoning is clear and based on common sense in NLP.", "helpfulness_rationale": "The reviewer provides a clear and specific criticism of a potential implementation detail related to HIERENC. They identify a specific area of concern (input calculation) and explain why it might be problematic. This is a direct and actionable feedback that can help the authors improve their understanding and potentially refine their method. The suggestion to average all entities is a concrete action the authors could take (or not take) to address the potential noise."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "Not Verifiable", "helpfulness_label": "Not Helpful", "actionability_rationale": "The reviewer explicitly states the system's behavior: 'You mention that you only select 10 answers from all correct answers.' This is an explicit statement of an action taken by the system. However, the reviewer does not specify *how* this selection is done or what criteria are used. Therefore, while the action is explicitly stated, the lack of detail makes it partially actionable but not fully actionable.", "grounding_specificity_rationale": "The reviewer's question is general: 'You mention that you only select 10 answers from all correct answers, why do you do this?' The reviewer does not specify which 'correct answers' they are referring to or why only 10 are selected. The comment does not identify a specific part of the paper or the selection process. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer's question is about a *process* (selecting answers) rather than a direct claim about the content of the answers or the system's behavior. The question itself does not present a claim that can be verified logically, commonly, or with external references. Therefore, it is not verifiable.", "helpfulness_rationale": "The reviewer is asking a question about the system's methodology. While the *answer* to the question might provide valuable information for authors to understand the system's limitations, the review point itself does not directly address the authors' work or provide actionable feedback on how to improve their draft. Therefore, it is not directly helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer requests clarification on a specific aspect of the paper (Table 4 and ATIS numbers), which implies an implicit action of clarifying. However, the action is not explicitly stated within the review point itself. The reviewer is asking 'what splits are used for obtaining the ATIS numbers?', indicating a need for more detail on the methodology. While the information is requested, the explicitness of the request could be improved.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Table 4' and 'ATIS numbers' within the review point. This clearly grounds the comment in a specific part of the paper. The request is also very specific, asking about the 'splits' used for obtaining the ATIS numbers, indicating a high level of specificity regarding the information needed.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It is a question seeking clarification on a specific detail of the paper. Therefore, the concept of verifiability does not apply to this review point.", "helpfulness_rationale": "The reviewer's request for clarification on the calculation of ATIS numbers in Table 4 is directly related to understanding a specific aspect of the authors' work. While the request itself doesn't contain a claim, it points to a potential area of confusion and asks for a crucial piece of information. This type of feedback, which seeks to improve understanding, is helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "6: X", "helpfulness_label": "3", "actionability_rationale": "The review point implies a desire for the authors to improve their phrasing, which can be considered an action. However, the action is not explicitly stated or very specific. The reviewer suggests reconsidering their wording, which implies a concrete action but lacks details on how to do it.", "grounding_specificity_rationale": "The review point is a general statement about the results and presentation. It does not specify which part of the paper or analysis is being referred to. Therefore, it is 1 in a specific section, table, figure, or unique aspect of the paper. It is also not specific in detailing what is wrong or missing in that part.", "verifiability_rationale": "The review point expresses a concern about the phrasing ('on par or better') and suggests it might be biased. This is a subjective opinion and does not contain a claim that requires verification. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The review point identifies a potential issue with the authors' communication and suggests they reconsider their phrasing. This provides a clear direction for improvement and is therefore helpful, although it doesn't offer a definitive solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer states 'Lack of novelty' which is an explicit action or suggestion. However, the reviewer does not specify what is lacking in novelty or how the authors should address it. The action is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer mentions 'Adversarial attacks by perturbing text has been done on many NLP models and imagetext models.' This is an explicit statement, but it does not specify which part of the paper or model is lacking novelty. The grounding is weak as the authors cannot confidently determine which part the comment addresses. However, the comment does specify what needs to be addressed in this part (lack of novelty in the approach).", "verifiability_rationale": "The reviewer makes a claim 'Lack of novelty' and provides a justification 'Adversarial attacks by perturbing text has been done on many NLP models and imagetext models.' This claim is verifiable as it is supported by the existence of similar attacks. However, the reasoning is general and could be more specific with examples.", "helpfulness_rationale": "The reviewer clearly identifies a problem with the novelty of the work. However, they do not offer any concrete suggestions or actionable steps for the authors to improve their draft. The feedback is present but lacks specific guidance on how to address the lack of novelty."}
{"actionability_label": "4", "grounding_specificity_label": "Mostly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the proposed method (matching the head of noun phrases) and then identifies a limitation: 'It\u2019s not clear how to handle the situation when the head word is not a pronoun.' This directly points to an actionable suggestion. However, the reviewer does not provide a concrete solution for how to handle the nonpronoun case. They suggest 'matching the head of noun phrases' as a method, which is a concrete action, but the specific issue of nonpronoun heads makes it only vague in terms of a complete action.", "grounding_specificity_rationale": "The reviewer *mentions* a specific method (matching the head of noun phrases) and then *clearly specifies* the problem: 'how to handle the situation when the head word is not a pronoun.' While they don't explicitly state which section of the paper describes this method, the context implies they are referring to the method they just described. Therefore, the grounding is considered 'weakly grounded' because they could be more explicit about where this method is described. However, the specificity of the problem is high as they pinpoint the exact condition causing the lack of clarity.", "verifiability_rationale": "The reviewer makes a claim that the method is 'not clear' and 'not specific.' They then provide a *partial* solution by suggesting 'matching the head of noun phrases' and specifically addressing the 'not a pronoun' case. While the solution is not fully comprehensive, it provides some justification for their claim by offering a potential resolution to the identified issue. Therefore, it is '3'.", "helpfulness_rationale": "The reviewer provides a potential solution to a specific problem related to the proposed method. While the solution is not fully detailed, it offers a concrete direction for improvement. The reviewer's suggestion to 'match the head of noun phrases' and address the 'not a pronoun' case directly tackles the identified limitation. Therefore, the comment is '3' as it points towards a actionable improvement, even if the action itself isn't entirely clear."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for a discussion on the convergence of the joint learning process and its relation to obtaining stable points in probabilistic metric space. This directly implies an action: to explain or discuss this mechanism. The reviewer identifies a gap in the current explanation, indicating they understand a specific part of the method and its importance. This suggests the comment is explicit about the action needed and identifies the specific aspect of the method being addressed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the convergence of the proposed joint learning process' and then specifies 'for RNN and CopyRNN'. This clearly identifies the specific part of the paper being addressed. Furthermore, they explain *why* this is important: 'so that readers can understand, how the stable points in probabilistic metric space are obtained?'. This provides a clear and specific reason for the discussion, indicating strong grounding in the relevant section and its purpose.", "verifiability_rationale": "The reviewer does not present a claim that something is wrong with the paper or that a certain statement requires justification. Instead, they are pointing out a missing discussion or lack of explanation regarding the convergence process. While the lack of this information can be considered verifiable, the comment itself does not contain a claim that needs to be supported. Therefore, it does not have a claim and is classified as 'X'.", "helpfulness_rationale": "The reviewer directly addresses a potential practical issue: the difficulty of reproducing results due to a lack of explanation about the convergence process and its connection to stable points. This is a clear and actionable request for improvement. It directly addresses a potential user concern about the usability and reproducibility of the work. Therefore, it is 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a concern about societal biases in knowledge bases and suggests using reasoning chains as a method to address this. While the suggestion to use reasoning chains is present, the exact steps or tools the authors should use are not specified. The concern about societal biases is also broad.", "grounding_specificity_rationale": "The reviewer mentions 'societal biases' and 'knowledge bases' in a general way. They don't pinpoint a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer states a concern ('It is not described if the knowledge bases that are inserted in are free from societal biases, or the issue is not affected by such restriction') and suggests a method to address it ('reasoning chains'). This is a suggestion, which can be considered a claim. However, the reviewer doesn't provide specific examples or references to external literature to support the claim that this method effectively addresses societal biases. The reasoning is also somewhat general.", "helpfulness_rationale": "The reviewer raises a valid concern about societal biases in knowledge bases and suggests a method for addressing it. However, they don't provide specific, actionable steps for the authors to take. The concern is broad and doesn't offer concrete guidance on how to improve the draft."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that 'authors should describe more about the traits of the experts' which is a clear action. However, the reviewer does not specify *what* these traits are or *how* they should be described, making the action somewhat vague. The request to 'justify why annotation must be carried out by the experts' adds a concrete element to the action, but the specifics of the justification are missing.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'linguistic experts' and 'domain experts' by name, which grounds the comment to specific sections of the paper. However, the reviewer does not specify *which* parts of the paper these experts are annotating or what specific aspects of the annotation are being focused on. The grounding is present, but the specificity within the grounded section is lacking.", "verifiability_rationale": "The reviewer makes a claim: 'annotations must be carried out by experts'. This claim is not supported by any logical reasoning, common knowledge, or external references within the review point. The justification for why experts are needed is stated but not explained or backed up.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors: 'describe more about the traits of the experts' and 'justify why annotation must be carried out by the experts'. This directly addresses a potential area of confusion for the authors and provides a concrete direction for improvement. While the specifics of the traits and the justification are not detailed, the reviewer has identified a meaningful issue and offered a solution, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The action is explicitly stated (suggestion), but the specifics are missing, making it 3. While the reviewer suggests 'seeing some examples', the *act* of seeing is implied, but the *how* of seeing it (e.g., a specific type of text, a demonstration) is not explicitly stated. The suggestion is about *action*, but the specifics of that action are vague.", "grounding_specificity_rationale": "The reviewer doesn't explicitly point to a specific part of their own paper. They are offering a suggestion for *improving* their paper (including their system). Therefore, there's no specific part of *their* paper being addressed. The grounding is weak. Even if we consider the 'their system' aspect, the suggestion is quite general. It doesn't pinpoint a specific module, function, or use case within the system. It's a broad suggestion.", "verifiability_rationale": "The reviewer point contains a claim or recommendation: 'It will be nice to see some examples of the system on actual texts (vs. other components & models)'. This is a clear statement of what the reviewer *wants*. While it's a suggestion for improvement, it's not a claim that can be verified based on the information provided in the review point itself. It's a desired feature, not a statement that can be proven true or false with evidence *against* the system.", "helpfulness_rationale": "The review point is not directly helpful for the reviewer to improve their specific draft. The suggestion is about enhancing the system's capabilities, which is relevant to the users of the system, not necessarily to the reviewer's specific situation. It doesn't directly address problems or weaknesses in the reviewer's own paper or their current approach."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer is explicitly asking for clarification on how the Challenge Set is used. This is an explicit request for information, and the action is to understand the usage of the Challenge Set. The reviewer is also asking for the data split, which is a concrete detail. Therefore, the reviewer is seeking explicit and concrete information about the Challenge Set's usage and data split.", "grounding_specificity_rationale": "The reviewer mentions 'linguistic experts' but does not explicitly state which part of their paper the Challenge Set is used for. While the reviewer is asking a question about the Challenge Set, they are not pinpointing a specific section, table, figure, or unique aspect of their own work related to it. The grounding is weak because the specific location isn't mentioned.", "verifiability_rationale": "The reviewer is stating a claim about the Challenge Set's usage and data split. However, they are not providing any evidence or references to support this claim within the review point itself. The claim is presented as a question/request for information, not a statement supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer is asking for clarification on a key component of the evaluation process (the Challenge Set) and the data used for it. This is directly relevant to understanding and potentially improving the draft. The reviewer is seeking actionable feedback on how the Challenge Set is used, which is likely to be helpful for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a problem with performance on nouns and provides a clear action for the authors to investigate the PPDBClus dataset. The reviewer identifies a specific area of weakness and suggests a direction for improvement, making the feedback actionable.", "grounding_specificity_rationale": "The review point directly mentions 'PPDBClus' and 'nouns' as the area of concern, indicating strong grounding and specificity. The reviewer clearly identifies the specific dataset and part of speech where the performance issue arises.", "verifiability_rationale": "The review point identifies a contradiction with a claim but does not provide specific evidence or references within this review to support the claim. The evidence for the contradiction would need to be found elsewhere in the paper, making the claim 1 within this review point itself.", "helpfulness_rationale": "The review point provides a clear and specific action for the authors to take, which is to investigate the performance gap on PPDBClus for noun phrases. This is a valuable direction for improvement, even though the evidence for the claim is missing within this review point."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer requests an example of a spurious structure, which is an explicit action. However, the action is vague because the nature of these spurious structures is not clearly defined or connected to the abstract discussion in section 5.2. The reviewer understands the *request* but not the *how* or *why* within the context of the abstract discussion.", "grounding_specificity_rationale": "The reviewer explicitly mentions section 5.2 as the relevant part of the paper, indicating strong explicit grounding. However, the specificity of the request is limited. While the section is named, the reviewer doesn't know what specific aspect of section 5.2 relates to the spurious structures or how the abstract discussion connects to these potential examples. The reviewer can *identify* the section but not *precisely* pinpoint the referenced part and how it relates to the request.", "verifiability_rationale": "The reviewer is making a request for examples rather than making a claim that needs verification. There is no statement of a claim, judgment, or suggestion. The request is a question or desire for information, not a statement that requires logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer explicitly states they 'don't get the insights.' This indicates a lack of helpfulness. While the reviewer is interested in the information (requesting examples), the abstract nature of the discussion in section 5.2 makes it difficult for them to gain the desired insights. The helpfulness is limited because the feedback is not directly translating into a concrete understanding or improvement for the author."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue ('the probabilistic connection is not drawn very well') and provides a clear suggestion ('cement this connection more formally or adjust the language'). This indicates a direct identification of a problem and a proposed solution, making it actionable.", "grounding_specificity_rationale": "The reviewer specifically mentions 'probabilistic connection,' which strongly implies a particular aspect of the paper. While they don't provide a section number, the term itself is highly specific. Furthermore, the reviewer elaborates on the nature of the problem ('not formal enough'), providing detail about what needs to be addressed within that specific part.", "verifiability_rationale": "The reviewer makes a claim ('I don't think the probabilistic connection is drawn very well') and suggests an improvement ('cement this connection more formally'). While the reviewer doesn't provide external references to support their claim, the suggestion itself points towards a verifiable standard of 'formal enough'. The claim is not definitively proven, but the suggestion implies a verifiable goal.", "helpfulness_rationale": "The reviewer clearly identifies a weakness ('the probabilistic connection is not drawn very well') and provides a concrete suggestion ('cement this connection more formally or adjust the language'). This actionable feedback is directly relevant to the authors and points them towards a specific area of improvement. While the reviewer doesn't prove the connection is unimportant, the suggestion is a clear direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'It would be good to show some empirical evidence...'. This is an explicit action suggesting the authors should conduct additional experiments. However, the action is vague as it doesn't specify *which* experiments, *which* datasets, or *how* the evidence should be presented. The lack of specificity makes it less concrete.", "grounding_specificity_rationale": "The review point mentions 'the third contribution of the paper' as the area needing empirical support. This indicates a degree of grounding as the authors can infer the specific part of the paper being addressed. However, the request 'show some empirical evidence' is general and lacks specific details about what kind of evidence is needed, how to obtain it, or which aspects of the contribution should be validated. The lack of specificity in the request means it is not fully grounded.", "verifiability_rationale": "The review point is a suggestion for new experiments rather than a claim that something is incorrect or needs verification. It doesn't state that the current work lacks evidence or makes a judgment about its quality. Therefore, it doesn't fall under the 'claim extraction' criteria for verifiability. It's a suggestion for future work, not a critique of existing evidence.", "helpfulness_rationale": "The review point directly addresses the weakness identified in the third contribution by suggesting empirical evidence. This is a relevant and actionable suggestion. However, the lack of specificity in the suggestion makes it less impactful. While it points in the right direction, it doesn't provide concrete guidance on how to achieve the suggested improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks 'what kind of style shifts happen in such a time?' which implicitly suggests the authors need to investigate and potentially address these shifts. However, the reviewer does not explicitly state an action or provide details on how to do this. The action is implied but not clearly defined, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'style shifts' generally but does not specify which aspects of the paper are affected or how they relate to the 4year period. The grounding is weak because the authors cannot confidently determine which part of the paper the comment addresses.", "verifiability_rationale": "The reviewer poses a question ('is 4 years sufficient?') and asks for information ('what kind of style shifts happen?'). This implies a claim that the current period might be insufficient for studying style shifts. However, the reviewer does not provide any evidence, references, or logical reasoning to support this claim. The verifiability is low because the claim is presented without sufficient backing.", "helpfulness_rationale": "The reviewer raises a valid concern about the sufficiency of the dataset and asks for information relevant to style shifts. This could be helpful for the authors to consider when analyzing their data. However, the review is more of a question and request for information rather than a direct solution or actionable suggestion. The helpfulness is moderate because it points towards a direction for further investigation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a potential issue ('several places may cause confusion') but does not specify the exact parts of the paper that are problematic or how to address them. It's a general statement about a potential area for improvement, not a directive with concrete actions. Therefore, it lacks explicit and concrete actionable steps.", "grounding_specificity_rationale": "The review point mentions 'several places may cause confusion' but does not identify a specific section, table, figure, or unique element of the paper as being problematic. The grounding is weak because the authors cannot confidently determine which part the comment addresses. The specificity is also lacking as the nature of the confusion is not detailed.", "verifiability_rationale": "The review point states a potential issue ('several places may cause confusion') but does not contain a claim that requires verification or support. It's a diagnostic statement about a potential area for improvement, not a prescriptive suggestion backed by evidence. Therefore, it doesn't present a claim that needs to be justified.", "helpfulness_rationale": "The review point identifies a potential area for improvement ('several places may cause confusion') but does not provide any specific guidance on how to identify or address those issues. It's a general concern rather than a constructive suggestion that empowers the authors to make changes. Therefore, it doesn't offer actionable feedback that would help the authors improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the results are 'not obvious a priori' and require 'a fair degree of technical competency'. This directly informs the authors to consider the limitations of relying solely on standard techniques and the need for deeper understanding. While it doesn't specify *how* to improve, it points to a clear action they should take.", "grounding_specificity_rationale": "The comment refers to the 'results' in general, without pinpointing a specific section, table, or figure. While it implies the results section, the authors cannot confidently determine which part is being addressed. However, the comment clearly specifies the issue: 'relying on standard techniques' and suggests an improvement: 'considering deeper understanding'. This makes the grounding somewhat specific as it identifies an area for improvement, but lacks the detail of a specific part of the paper.", "verifiability_rationale": "The comment contains a claim: 'the results ... are not obvious a priori' and 'require a fair degree of technical competency'. However, it does not provide any evidence or references to support this claim. The reasoning is general and lacks specific examples or external references, making it 1.", "helpfulness_rationale": "The comment raises a valid concern about the limitations of standard techniques and the need for technical expertise. It provides a direction for improvement by suggesting 'considering deeper understanding'. However, it lacks specific details on *what* aspects of the results are unclear or *how* the authors should consider deeper understanding. The feedback is general and could be more actionable for the authors to implement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that 'the difference between the two proposed systems is only a few percentage points,' which is an explicit action pointing to a specific quantitative difference. However, it doesn't specify *which* percentage points or *how* this difference was measured, making the action somewhat vague on how to apply it directly. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions 'the text disambiguation model' and 'the endtoend system,' identifying the specific parts of the paper being discussed. It also mentions 'percentage points' as the difference, which is a specific element. Therefore, the comment is 5.", "verifiability_rationale": "The comment contains a claim that 'the lower data usage might question the superiority of the direct model.' The comment provides some implicit support by mentioning 'a few percentage points,' which could be interpreted as evidence. However, it lacks specific examples, references, or a clear logical reasoning to fully verify the claim. Therefore, the comment is 3.", "helpfulness_rationale": "The comment provides an insightful observation about a potential limitation based on the difference in training data. It suggests that the authors should consider the impact of training data size on model performance. While it highlights a concern, it doesn't offer a specific, actionable step beyond acknowledging the difference. Therefore, the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the lack of motivation for GaRare and the need for a more detailed algorithmic presentation. This makes the action explicit. However, the reviewer does not specify *what* the motivation should be or *how* the algorithmic presentation should be detailed, making the action vague.", "grounding_specificity_rationale": "The reviewer refers to 'GaRare' and 'GaLore' and 'projected gradients' and 'updated parameters'. While they don't explicitly state the section where these are discussed, the terms strongly suggest they are referring to the motivation and algorithmic sections, respectively. This makes the grounding somewhat weak, as the authors can infer the specific parts but don't have a precise reference.", "verifiability_rationale": "The reviewer makes a claim that 'GaRare lacks evidence or justification for GaRare's advantages over GaLore based on theoretical analysis' and 'a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients'. However, the reviewer does not provide any evidence or justification to support these claims within the review point itself. The reasoning is presented as a suggestion for improvement rather than a statement supported by facts or references.", "helpfulness_rationale": "The review point identifies specific areas where the authors could improve their understanding or the paper's presentation. The lack of motivation for GaRare and the ambiguity in the algorithmic description are likely to be valuable feedback for the authors, helping them understand the limitations of their work and improve their method. While the feedback is not explicitly offering solutions, it points to concrete areas for improvement, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the missing links and highlights the similarity in structure and inference capabilities of the mentioned works. While it doesn't explicitly say *where* to find them, the action of looking for similar work on Continuous Conditional Random Fields is clear. The reviewer suggests adding these works to the related work section, which is a direct action the authors should take.", "grounding_specificity_rationale": "The comment identifies a specific area of related work (Continuous Conditional Random Fields and Conditional Neural Fields) and highlights a key feature (similar structure and ability to perform exact inference). While it doesn't pinpoint a specific section or table, it clearly specifies what is being compared and what aspect of similarity is being pointed out. The reviewer implies that these works should be discussed in the related work section.", "verifiability_rationale": "The comment makes a claim about the missing link and the similarity of the mentioned works to the authors' work. However, the evidence for this claim is not directly provided within the review point itself. The reviewer suggests that the authors should look for these specific types of papers and compare their structure and inference capabilities. The verifiability of this claim would require the authors to independently verify the existence and similarity of these works.", "helpfulness_rationale": "The comment identifies a gap in the related work section and suggests a specific area to explore. It points out that the authors have not discussed similar approaches based on Continuous Conditional Random Fields and Conditional Neural Fields. This is a valuable piece of feedback as it highlights a potential area for improvement in the authors' work's positioning and contribution. The reviewer provides a clear direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states a similarity between their method and a specific related work. This directly points to an actionable suggestion for the authors to investigate and clarify their method in relation to this work. However, the reviewer does not specify *how* the method is similar, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions a specific related work, which allows the authors to identify the relevant part of the paper being discussed. However, the reviewer's statement about the similarity is general ('the method part is very similar'), lacking specific details about which aspects of the method are similar. Therefore, the grounding is present, but the specificity of the identified issue is lacking.", "verifiability_rationale": "The reviewer is asking for clarification, which is a request for information, not a claim that needs verification. They are not stating that something is wrong or needs to be improved based on external evidence. Therefore, the verifiability is low as there is X being made that requires justification.", "helpfulness_rationale": "The reviewer's comment is a request for clarification regarding a potential similarity with prior work. While this is helpful in guiding the authors to investigate their method, it doesn't directly point out a specific weakness or propose a concrete improvement. It's more of a question than a critique."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer raises concerns about the fairness of the comparison and the potential of the proposed technique. While these are valid points, they do not directly instruct the authors on what to do or how to improve their draft. The reviewer is pointing out potential issues rather than providing explicit actions.", "grounding_specificity_rationale": "The reviewer mentions 'comparison with other methods' and 'could the proposed technique promote existing Class incremental semantic segmentation methods'. However, these are general areas of concern and potential future directions, not specific parts of the paper or concrete issues. The reviewer is broad in their questioning.", "verifiability_rationale": "The reviewer does not make any claims that require verification. They are posing questions about the fairness of the comparison and the potential of the technique, but these are not statements that need to be supported by evidence within the review point itself.", "helpfulness_rationale": "The reviewer's points are valuable and raise important considerations for the authors. However, they do not provide concrete, actionable advice or suggestions. The reviewer is highlighting potential limitations and future research directions rather than offering direct improvements to the authors' work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem (tersely written section) but does not specify a concrete action or suggestion to improve it. It mentions 'slower development' which is vague and doesn't provide a clear path for the authors to follow.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 4', indicating that the authors can identify the specific part of the paper being addressed. This fulfills the criteria for full grounding.", "verifiability_rationale": "The review point makes a claim about Section 4 being 'very tersely written'. This claim is supported by the reviewer's observation, even if it lacks specific examples. The logical reasoning is present in stating the observation as a fact.", "helpfulness_rationale": "The review point identifies a valid issue (tersely written section) but does not provide a specific, actionable suggestion to address it. While it points out the problem, it lacks the necessary guidance for the authors to improve their draft effectively. Therefore, it is not 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point clearly identifies a gap in the paper's description of the dataset and provides concrete suggestions for improvement. The reviewer explicitly states the importance of video length distribution for reasoning ability and robustness, and then suggests concrete actions: creating a table and explaining the balancing process. These actions are direct and actionable, allowing the authors to directly implement them.", "grounding_specificity_rationale": "The reviewer refers to the 'distribution of videos of different lengths within the benchmark' and the importance of this distribution for 'reasoning ability and robustness'. While the reviewer doesn't explicitly name the section or table where this information should be, the topic is generally understood in the context of dataset description. The reviewer also implies that the authors should 'ensure a balanced representation', which is a specific action. Therefore, the grounding is strong, although not as explicit as 'fully grounded'.", "verifiability_rationale": "The reviewer states a fact about the importance of video length distribution for assessing reasoning ability and robustness. They then provide suggestions for how the authors can address this. While the reviewer doesn't present a claim that needs verification in the sense of requiring external evidence, the implication is that the paper *should* have this information. The suggestions are also somewhat specific, guiding the authors on what to do. Therefore, it's partially verifiable.", "helpfulness_rationale": "The review point directly addresses a potential weakness the authors might be facing: a lack of information about video length distribution in the dataset description. The reviewer provides clear, actionable suggestions: creating a table to show the distribution and explaining how they ensured a balanced representation across the 11 categories. These suggestions are directly applicable and constructive, empowering the authors to improve their understanding and potentially their model's performance. The reviewer's request is very specific and directly addresses a potential gap in the authors' knowledge."}
{"actionability_label": "1", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review points out a *problem* (dataset not available) but doesn't offer any *actions* or *solutions*. It's a statement of fact, not a directive. The reviewer states, 'The promised dataset has not yet been made publicly available,' which identifies the issue but doesn't provide a concrete step to address it. The phrase 'a cautious approach should be taken' is vague and doesn't offer specific actions.", "grounding_specificity_rationale": "The review explicitly mentions 'the promised dataset' as the specific part of the paper being addressed. The reviewer states, 'The promised dataset has not yet been made publicly available,' clearly identifying the section being discussed. The information is presented directly without needing to infer its location within the paper.", "verifiability_rationale": "The review states a fact: 'The promised dataset has not yet been made publicly available.' There is X being made, just a statement of observation. According to the definitions provided, a 'Normal Statement' is one that describes facts without suggesting changes. Since there is X, there is no evidence to verify.", "helpfulness_rationale": "The review identifies a crucial missing component (the dataset) that is essential for the contribution. It highlights a potential bottleneck in the authors' ability to proceed. However, it does not offer any actionable advice or suggestions on how to address this issue. The reviewer states the problem but doesn't provide any steps to solve it, making it less helpful in terms of guiding improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly state how to address the identified limitations. The reviewer points out the similarity to existing attentional modules and ResNeSt but does not provide concrete, actionable steps for the authors to follow. The focus is on identifying the problem rather than offering a solution.", "grounding_specificity_rationale": "The reviewer mentions specific prior works 1, 2, 3 and ResNeSt 4 by name, indicating some level of grounding. However, the reviewer does not explicitly state which specific part of these papers is being referenced (e.g., a section, table, or unique aspect). The grounding is implied but not precise.", "verifiability_rationale": "The claim of limited novelty and similarity to existing structures lacks sufficient evidence or justification within the review point. There is no logical reasoning, common knowledge, or external references provided to support these claims. The reviewer states the similarity without explaining why or providing examples.", "helpfulness_rationale": "The review point primarily criticizes the novelty and structural similarity to existing works without offering any constructive feedback or suggestions for improvement. The authors are left with the problem of limited novelty but no guidance on how to address it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states 'the required implicit call to the Witness oracle is confusing.' While it doesn't explicitly state an action, the reviewer implies a potential action: clarifying the call to the Witness oracle. However, the action is vague, as the reviewer doesn't specify *how* the call should be made or why it is confusing. The lack of explicit action makes it difficult for the author to take a concrete step.", "grounding_specificity_rationale": "The review point mentions 'Witness oracle' and its 'required implicit call.' This suggests the reviewer has identified a specific part of the paper or draft that is potentially problematic. However, the reviewer doesn't explicitly state which section, table, figure, or unique aspect of the paper this refers to. While the mention of 'Witness oracle' implies a degree of grounding, the lack of a clear reference point makes the grounding weak. Furthermore, the reviewer doesn't specify what is confusing about the call, making the specificity low.", "verifiability_rationale": "The review point states 'the required implicit call to the Witness oracle is confusing.' This statement can be considered a claim, as the reviewer is expressing an opinion about a potential issue. However, the claim is not supported by any evidence or reasoning. The reviewer doesn't provide any logical arguments, common knowledge, or external references to back up their claim that the call is confusing. Therefore, the claim is 1.", "helpfulness_rationale": "The review point states 'the required implicit call to the Witness oracle is confusing.' While the reviewer has identified a potential issue, they do not provide any suggestions or explanations to address the confusion. The comment is purely negative and doesn't offer any actionable feedback to the authors. Without clarifying the call or explaining why it is confusing, the authors are left without guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a limitation of the proposed method (headpose control) and asks a question, implying an action is needed to address this issue. While not explicitly stating 'Do this!', the implication is that the authors should consider how to handle headpose. The reviewer also mentions a previous work that *could* handle headpose, suggesting they are aware of a potential solution, but the paper doesn't address why their method can't do so. This indicates a lack of clarity or justification for the proposed method's limitations, making it 3 but not entirely clear what needs to be done.", "grounding_specificity_rationale": "The reviewer explicitly states 'The proposed method cannot handle the headpose' and then provides a specific example of a previous work (Gafni et al. ICCV 2021) that *could* handle both facial expression and headpose. They also ask a question ('Why is it not possible...') to further specify the issue. This clearly identifies the problem and provides context, making the grounding very specific.", "verifiability_rationale": "The reviewer makes a claim about the proposed method's limitations ('The proposed method cannot handle the headpose') and provides a reason for this claim ('a previous work (e.g., Gafni et al. ICCV 2021) is already able to control both facial expression and headpose'). They also explain *why* they think the proposed method might not be able to handle it ('Why is it not possible to condition the headpose parameters in the NeRF beyond the facial expression similar to Gafni et al. ICCV 2021?'). This claim is supported by logical reasoning and the mention of external work, making it 5.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the proposed method (lack of headpose control) and provides a suggestion for improvement (conditioning headpose in NeRF like Gafni et al. ICCV 2021). They also ask a question to guide the authors towards this improvement. This directly points out a gap and offers a constructive suggestion, making the review 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the optimization algorithm is 'directly from some previous works'. This is a clear identification of an action or suggestion that the authors should consider. While the reviewer doesn't specify *how* it's derived, the fact that it's 'from previous works' implies a potential lack of novelty or a reliance on existing solutions. Therefore, the action is explicit.", "grounding_specificity_rationale": "The reviewer mentions 'optimization algorithm' generally, indicating a weak grounding. They don't specify *which* part of the paper or provide details about the algorithm's origin. The reviewer could have been more specific, for example, by saying 'the optimization algorithm is directly from the section on gradientbased methods' or 'the optimization algorithm is directly from work X'. Without this specificity, the reviewer can only infer that there might be an issue with the optimization approach. Therefore, the grounding is 3 but not fully grounded.", "verifiability_rationale": "The reviewer makes a claim that the optimization algorithm is 'directly from some previous works'. However, they do not provide any evidence, citations, or logical reasoning to support this claim. The reviewer simply states it as a fact without backing it up. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer's point is about the potential reduction in contribution due to the optimization algorithm being derived from previous work. While the reviewer identifies a potential issue, they don't provide specific suggestions or solutions to address this concern. The feedback is primarily a question about the novelty and contribution. Therefore, the feedback is 3 in raising a concern, but it lacks actionable suggestions to improve the draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the performance issue with the 'pipeline style method' and identifies the specific models and datasets ('XVNLI' and 'MaRVL') where the improvement was not achieved. While the exact *how* to improve is not specified, the reviewer clearly points to a weakness and suggests focusing on performance enhancement. The reviewer implies that the identified method is not effective for these specific tasks, which provides a clear direction for the authors to investigate and potentially improve their approach.", "grounding_specificity_rationale": "The comment mentions 'pipeline style method,' 'two models,' 'XVNLI,' and 'MaRVL.' While the 'pipeline style method' is a general term, the specific mention of the models and datasets grounds the comment to a particular experimental context. The reviewer clearly identifies the specific components and datasets where the performance is lacking, making the grounding quite specific within the relevant domain.", "verifiability_rationale": "The comment contains a claim: 'This pipeline style method including two models does not give better average results for both XVNLI and MaRVL.' While this claim is stated, the reviewer does not provide any specific evidence, examples, or references to support this assertion. The lack of justification makes it difficult to verify the claim's validity, although the statement itself is clear and points to a specific issue.", "helpfulness_rationale": "The comment identifies a performance issue with a specific experimental setup ('pipeline style method' and 'two models') on specific datasets ('XVNLI' and 'MaRVL'). This points to a clear weakness that the authors could potentially address. However, the comment lacks specific suggestions or guidance on *how* to improve the performance. The reviewer identifies a problem, which is helpful, but the lack of concrete recommendations makes it less impactful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests a general improvement but lacks specific details on how to implement the \"more sophisticated methodology.\" It's not entirely absent, but it lacks the concrete steps needed for immediate action.", "grounding_specificity_rationale": "The reviewer identifies the *methodology* as the problematic part, which is a specific aspect. However, they don't pinpoint a specific line or section within that methodology.", "verifiability_rationale": "The reviewer makes a claim: \"The observation that language models reproduce the biases of the corpora on which they're trained has been made at each step of the evolution of these models...\" and offers a potential *solution*: \"The observation that language models reproduce the biases of the corpora on which they're trained has been made at each step of the evolution of these models, from word2vec to BERT to ChatGPT, and so it's unclear why this observation needs to once again be made using the authors \"coarse\" methodology.\" This is a claim that requires justification. The reviewer attempts to justify it by pointing out the historical context.", "helpfulness_rationale": "The reviewer identifies a valid concern: the use of a \"coarse\" methodology might limit the insights gained from the experiment. They suggest a potential improvement. While the suggestion is general, it raises a legitimate point about the limitations of the current approach."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point states \"When discussing related work it is crucial to mention related work on modular networks for VQA such as A\". This explicitly points out a missing element in the introduction. While it doesn't tell the authors *how* to fix it, it clearly identifies a specific action they should take.", "grounding_specificity_rationale": "The review point directly refers to \"the introduction right now\", which is a specific section of the paper. This clearly identifies the part of the paper being addressed.", "verifiability_rationale": "The review point states \"When discussing related work it is crucial to mention related work on modular networks for VQA such as A\". This is a statement of importance and a recommendation, not a claim that something is wrong or needs fixing. It's more of a suggestion for improvement.", "helpfulness_rationale": "The review point clearly identifies a missing piece of information (citing related work) and suggests where it should be added. This directly addresses a potential gap in the introduction and helps the authors improve their work. While it doesn't provide the exact wording to add the citation, it points to a concrete improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a discrepancy between the authors' focus on SSC and the absence of comparison with other methods like TSC and greedy subspace clustering. It implies a direct action: 'improve your introduction by discussing TSC and greedy subspace clustering' or 'add a section comparing your method to these existing approaches'. This directness makes it actionable.", "grounding_specificity_rationale": "The review point names specific methods, 'thresholded subspace clustering (TSC)' and 'greedy subspace clustering by Park', which directly grounds the criticism in concrete examples. It also mentions the properties of these methods, such as 'computational efficiency' and 'similar guarantees', further specifying the context of the criticism.", "verifiability_rationale": "The review point makes a claim: 'The authors mainly seem to focus on SSC, and do not contrast their method with several other subsequent methods...'. It then provides supporting information: 'which are all computationally efficient as well as come with similar guarantees'. This logical reasoning and specific examples make the claim verifiable.", "helpfulness_rationale": "The review point identifies a specific area for improvement in the authors' work \u2013 the lack of comparison with related methods. It provides a clear suggestion: 'contrast your method with these existing approaches'. While it doesn't critique the authors' work directly, it guides them on how to enhance their contribution by placing it within the existing literature. This actionable and constructive feedback makes the review point 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the paper's description of semantic segmentation as a 'lowlevel cue' is inaccurate and suggests removing this statement. The action is clearly identified, and the direction to remove the statement is also provided, making it concrete. While the reviewer doesn't specify *how* the paper incorrectly describes semantic segmentation, the intention to correct it is clear and actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'semantic segmentation' and describes the paper's inaccurate description as being 'specified for each pixel'. This allows the reviewer to precisely identify the part of the paper being addressed. The specificity of the criticism, 'statements about semantic segmentation being a lowlevel cue', is also clear.", "verifiability_rationale": "The review point contains a claim: 'the statements about semantic segmentation being a lowlevel cue should be removed from the paper.' While the reviewer identifies a potential issue, they do not provide external references or logical reasoning within the review point itself to *verify* the inaccuracy of the paper's description. The claim is stated, but the supporting evidence is missing from this specific review point.", "helpfulness_rationale": "The review point clearly identifies a potential issue in the paper ('statements about semantic segmentation being a lowlevel cue') and provides a direct action for improvement ('remove this statement'). This actionable feedback is directly aimed at improving the clarity and accuracy of the paper's description of semantic segmentation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the relationship between Theorem 1 and 2 and degree bias is not intuitive enough and asks for an explanation. This directly points to a lack of clarity and a need for the authors to take action by providing a more detailed explanation of the mechanism.", "grounding_specificity_rationale": "The reviewer refers to 'Theorem 1 and 2' as the specific part of the paper being addressed, indicating a clear grounding of the issue. They also ask a specific question about the relationship with degree bias, further emphasizing the specificity of the concern.", "verifiability_rationale": "The reviewer makes a claim about the intuitiveness of the explanation regarding degree bias. While the paper *could* potentially provide a clearer explanation, the reviewer's statement about the intuitiveness is a valid observation about the current presentation. The claim requires justification, but the underlying point about clarity is valid.", "helpfulness_rationale": "The reviewer requests an explanation for a specific point of confusion regarding a technical aspect of the paper. This directly addresses a potential weakness and empowers the authors to improve their understanding, making the review 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the areas where more details are needed, such as the 'definition of the resistance distance' and 'more explanations on Alg. 1 with brief sentences defining A_t, Y_t,...'. These are direct actions the authors should take to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'many graph notions' and then focuses on specific areas for improvement, such as the 'definition of the resistance distance' and 'Algorithm 1 with brief sentences defining A_t, Y_t,...'. This indicates a clear identification of the specific part of the paper that needs attention.", "verifiability_rationale": "The reviewer states 'the writing is generally good though more details could sometimes be provided'. This is a claim that is somewhat supported by the reviewer's statement about the writing quality, suggesting that the authors' current version might be lacking in certain aspects.", "helpfulness_rationale": "The review point provides clear and actionable feedback on specific areas where the authors should improve their draft. The suggestions are direct and specific, guiding the authors on what needs to be clarified or expanded upon."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The statement explicitly states that the main idea of variable splitting is not new and the algorithm is also not new. This provides a clear action for the authors to consider existing literature on variable splitting and algorithms. However, it doesn't specify *how* these are not new, making it somewhat vague on how to apply this information.", "grounding_specificity_rationale": "The reviewer mentions 'variable splitting' and 'algorithm' as examples of limited originality. While this provides some grounding, it doesn't explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The grounding is weak because the reviewer can't precisely identify the referenced part.", "verifiability_rationale": "The statement about limited originality and the algorithm not being new is presented as an assertion, not based on any specific evidence or references within the review point. There is X being made, so it's not verifiable in the sense of supporting a claim with evidence.", "helpfulness_rationale": "The statement directly points out a potential weakness (lack of originality) and suggests areas for improvement (considering the existing literature on variable splitting and algorithms). This is helpful for the authors as it guides them to think about the novelty of their work and its relation to existing research."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the limitation: 'evaluation on transformations of training images cannot fully prove the point.' This clearly identifies a weakness in the methodology. While it doesn't specify *how* to improve it, it directly points to an area needing attention. Therefore, it is actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'transformations of training images' as the context of the criticism. This clearly identifies the specific aspect of the paper being addressed. While it doesn't specify *which* transformations, it does specify the *type* of transformations being questioned. Therefore, it is grounded and somewhat specific.", "verifiability_rationale": "The comment contains a claim: 'evaluation on transformations of training images cannot fully prove the point.' This is a statement of opinion or judgment about the methodology. The suggestion to 'are there any quantitative results on testing images?' is a request for further investigation and evidence. It doesn't provide immediate verifiable facts but points towards a way to verify the claim. Therefore, it is 3.", "helpfulness_rationale": "The comment requests 'quantitative results on testing images' to address a limitation in the methodology. This is a constructive suggestion that directly addresses the identified weakness. It empowers the authors to further validate their claims and strengthen their work. While it doesn't provide immediate actionable steps, it clearly outlines a direction for further research and verification. Therefore, it is 5."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly names a specific paper and suggests a concrete action: 'discuss and compare against'. This is an explicit and concrete action that the authors can directly implement to improve their work.", "grounding_specificity_rationale": "The review point explicitly mentions the paper by Ghoshdastidar and Dukkipati and the year (AAAI 2015). This allows the authors to identify the specific paper being referenced. While it doesn't specify a particular section or detail within the paper, it clearly identifies the area of related work. Therefore, it has full grounding but might be considered somewhat underspecific as it doesn't pinpoint a specific issue within the referenced work.", "verifiability_rationale": "The review point presents a suggestion for improvement ('discuss and compare against') which can be considered a claim that needs justification. This claim is supported by logical reasoning (it's a standard practice) and doesn't require external references to be considered verifiable. It's a clear and reasonable suggestion.", "helpfulness_rationale": "The review point identifies a potential gap in the related work by suggesting the inclusion of a relevant paper. It provides a clear action ('discuss and compare against') that would directly benefit the authors by providing context and potentially highlighting differences or improvements. While it's a general suggestion, it's still a valuable point for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the computational cost of optimal transport and then asks specific questions about how to assess its scalability on normal machines and how to derive the exact optimal transport from the Sinkhorn algorithm's output. These are all direct and identifiable actions the authors should take to understand and potentially improve their method.", "grounding_specificity_rationale": "The reviewer provides specific details about the concern: 'scalability on normal machines' and 'how do you compute exactly optimal transport, because the Sinkhorn method gives you a doubly stochastic matrix (how do you go from it to optimal transport?)'. This demonstrates strong grounding as the reviewer clearly identifies the specific aspects of the method they are questioning.", "verifiability_rationale": "The reviewer poses a claim about the computational cost of optimal transport and then asks specific questions that require investigation and clarification. This claim is supported by the reviewer's questions about practical aspects like scalability and the algorithmic details of Sinkhorn. The reasoning is logical and points to specific areas for the authors to look.", "helpfulness_rationale": "The review point is 5 because it directly addresses a potential bottleneck in the authors' workflow (computational cost). By highlighting the lack of clarity on scalability and the Sinkhorn connection, the reviewer provides specific areas for the authors to investigate and potentially improve their implementation. This is a constructive critique that can lead to actionable steps for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment states 'The paper was extremely hard to follow' and 'I read it multiple times and still had trouble following the exact experimental procedures and evaluations that the authors conducted.' This comment identifies a problem the reviewer experienced but does not provide specific instructions on how to improve the paper. The reviewer states they had trouble following, but doesn't say what they found difficult or suggest how to address it. Therefore, it lacks explicit and concrete instructions for the authors to follow.", "grounding_specificity_rationale": "The reviewer mentions 'the exact experimental procedures and evaluations that the authors conducted.' This indicates that the reviewer can identify the specific area within the paper they are referring to \u2013 the experimental section. They even specify the type of information ('procedures and evaluations'), showing they have some understanding of the paper's structure and content. However, they don't pinpoint the exact subsection, table, or figure. This falls under the category of '3' as the reviewer can identify the *type* of information causing issues, but not the precise location.", "verifiability_rationale": "The comment states 'The paper was extremely hard to follow' and 'I read it multiple times and still had trouble following the exact experimental procedures and evaluations that the authors conducted.' There is no explicit claim being made or challenged in this review point. It is a statement of the reviewer's experience. Verifiability requires a claim to be supported by evidence (logical reasoning, common knowledge, or external references). This review point does not present a claim that needs verification.", "helpfulness_rationale": "The reviewer states they had trouble following the experimental procedures and evaluations. While this points to a potential weakness in the paper's presentation, the review point itself does not offer any specific suggestions or actionable steps for the authors to improve their writing or presentation of the experimental details. It's a statement of a problem, but without any proposed solutions or remedies, it is not helpful in the sense of providing direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the specific model has bounded parameters (acceleration and scaling) and distinguishes it from the potentially infinite subdivisions mentioned earlier. The reviewer directly addresses a potential ambiguity in the model description by clarifying the scope of the model. The action is clearly defined: 'certain parameters are bounded on one side (acceleration and scaling parameters)' and how to implement it is concrete: 'This clarifies the scope of the model and distinguishes it from scenarios with potentially infinite subdivisions for \u03b3^1 and \u03b3^m.'", "grounding_specificity_rationale": "The reviewer explicitly identifies the 'certain parameters' that are bounded, which are 'acceleration and scaling parameters'. This directly points to the relevant parts of the model. The grounding is strong because the reviewer names the specific parameters being discussed. The specificity is also high as the reviewer clarifies that these parameters are 'bounded on one side'. This provides a clear understanding of the constraint being imposed.", "verifiability_rationale": "The reviewer's point implicitly suggests a need for clarification regarding the bounded nature of the parameters. While not a strong explicit 'claim' in the sense of recommending a change, it points to a potential area where the model's description could be improved. The reviewer is indicating that the lack of clarity on these bounds might lead to confusion. The reasoning is implied but not explicitly stated, and the external references are not provided.", "helpfulness_rationale": "The review point directly addresses a potential ambiguity in the model description by clarifying the bounded nature of key parameters and contrasting it with the potentially infinite subdivisions. This directly helps the authors understand the scope and constraints of the model. The feedback is clear and actionable, guiding the authors on the nature of the parameters. The impact on the authors' ability to implement the model is significant."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their opinion about the required condition for the learning rate and provides a specific example (scaling with the number of samples). This makes the action quite direct and allows the authors to identify a potential issue. While the reviewer doesn't provide a concrete solution, they clearly identify a discrepancy that needs attention.", "grounding_specificity_rationale": "The reviewer mentions 'the required condition on the learning rate (scaling with the number of samples)' and 'practical experience'. While they touch upon 'practical experience', they don't pinpoint a specific section, table, figure, or unique element of the paper where this condition is discussed or its impracticality is demonstrated. The reference to 'practical experience' is general and doesn't directly ground the comment to a specific part of the paper.", "verifiability_rationale": "The reviewer presents a claim about the impracticality of the required learning rate condition. However, they do not provide external references or logical reasoning to support this claim. They are stating an opinion based on their own experience, which lacks the necessary evidence to verify the claim. The reviewer doesn't offer any examples or evidence to back up their assertion.", "helpfulness_rationale": "The reviewer's comment identifies a potential issue with the authors' understanding of learning rate scaling. While they highlight the discrepancy between the required condition and practical experience, they do not offer a concrete alternative or solution. The comment is more of a critique pointing out a potential flaw in the authors' assumptions rather than a helpful suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the difficulty of sampling from the DPP when eigenfunctions are inaccessible and draws a clear parallel to the challenges of sampling from leverage scores. The reviewer also implies that the authors should be able to infer the difficulty of DPP sampling in this scenario, making it an explicit action that is somewhat concrete.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific technical challenge of sampling from the DPP with inaccessible eigenfunctions and connects it directly to the problem of sampling from leverage scores. The reviewer does not need to infer which part of the paper is being addressed, making the grounding explicit and accurate.", "verifiability_rationale": "The reviewer makes a claim about the difficulty of sampling from the DPP in the specified scenario and draws a logical inference by comparing it to the known challenges of sampling from leverage scores. While the connection is inferential, the reviewer provides a clear reasoning for why this is a problem and how it relates to another known issue, making it 3.", "helpfulness_rationale": "The reviewer's point is 5 because it directly challenges a potentially misleading claim about the relative ease of DPP sampling compared to leverage score sampling. By highlighting the lack of clarity in this specific sampling scenario, the reviewer forces the authors to reconsider their assumptions and potentially revisit the underlying methodology. The question is insightful and prompts a deeper analysis of the problem."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out a missing element (evaluation details) but doesn't actively propose a solution or provide a clear next step.", "grounding_specificity_rationale": "The reviewer correctly identifies a missing element (evaluation details) but doesn't pinpoint where in the abstract this information should be.", "verifiability_rationale": "The statement about the abstract being \"good\" is a subjective opinion. While the lack of detail is factual, the connection to verifiability isn't explicitly stated or justified.", "helpfulness_rationale": "The reviewer points out a weakness (lack of evaluation details) but doesn't offer any improvement or actionable suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their lack of conviction and provides specific examples of POMDP problems with nonconvex value functions they believe should be included. While not a direct 'do this' instruction, it's a clear call for action regarding the experimental section. The reviewer implicitly suggests that the current experiments are insufficient to support the claims made about solving POMDP problems with nonconvex value functions.", "grounding_specificity_rationale": "The reviewer explicitly mentions the type of POMDP problems with nonconvex value functions they believe should be included in the experiments. They name specific examples like 'surveillance in museums with thresholded rewards' and 'privacy preserving data collection'. This demonstrates a clear attempt to ground the suggestions in specific problem types. However, the reviewer does not specify how these experiments should be designed or what metrics should be used, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer makes a claim that the experimental results are not convincing and provides examples of the types of experiments they believe are missing. However, the reviewer does not explicitly state that the existing experiments are unconvincing *because* they lack specific details or justification. They are pointing out a lack of specific experiments, which is a different issue. Therefore, the claim is not fully supported by explicit, sufficient, and robust evidence.", "helpfulness_rationale": "The reviewer's point is clear and directly addresses a potential weakness in the paper's experimental validation. They provide specific examples of the type of experiments that would be relevant and suggest the lack of these experiments makes the experimental section less useful. This provides a clear direction for improvement and highlights a concrete area where the paper could be strengthened."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies several potential issues with the authors' workload and contribution assessment, and points out missing key baselines and citations. While these are valid points, the reviewer does not explicitly state how the authors should address these issues. The reviewer suggests a combination of GraphRAG methods, but doesn't provide specific steps for the authors to implement this. The reviewer also mentions missing citations but doesn't specify which ones are needed or how to find them. The reviewer's suggestions are general and lack concrete, actionable steps for the authors.", "grounding_specificity_rationale": "The reviewer provides general suggestions about missing baselines and the need for RAG algorithms, but does not explicitly identify a specific part of the paper being addressed. The reviewer mentions 'many key baselines were not cited' and 'some essential RAG algorithms should have been introduced' without pinpointing which specific sections, tables, or unique elements of the paper are affected. The reviewer's suggestions are broad and do not provide a clear target for the authors to focus their improvements.", "verifiability_rationale": "The reviewer makes claims about the workload and contribution being ' immense' and 'incremental', respectively. The reviewer also states that the work is 'essentially a combination of GraphRAG and GraphCare' and suggests 'commonly used missing citations'. While the reviewer provides some reasoning for these claims (e.g., 'My understanding is that it is essentially a combination of GraphRAG and GraphCare'), they do not provide specific references or logical reasoning to support these statements. The reviewer's claims are based on their interpretation of the paper's content and the provided references, but lack external validation or concrete examples.", "helpfulness_rationale": "The reviewer points out several potential issues with the authors' workload and contribution assessment, and highlights missing key baselines and citations. While these are valid points, the reviewer's suggestions are general and lack specific, actionable steps for the authors. The reviewer suggests a combination of GraphRAG methods but doesn't provide specific implementation details or new baselines to add. The reviewer also suggests commonly used RAG algorithms but doesn't specify which ones are missing or how to find them. The reviewer's comments are informative but lack the concrete, actionable guidance needed to fully improve the draft. The suggestions are more about identifying weaknesses than providing clear, stepbystep improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the desired outcome: 'show a graph showing the plot of T vs number of images, and Expectation(T) over the imagenet test set.' This is a clear and direct request for a specific visualization. The reviewer also mentions the purpose of the graph: 'It is important to understand whether the performance improvement stems solely from the network design...'. This indicates a clear action to be taken and a specific goal to achieve. The reviewer's suggestion to 'algorithms skipping layers or channels' further clarifies the intended analysis and provides a concrete direction for the graph.", "grounding_specificity_rationale": "The reviewer provides a very specific request: 'show a graph showing the plot of T vs number of images, and Expectation(T) over the imagenet test set.' This clearly identifies the *what* of the request. The reviewer also explicitly states the *why*: 'It is important to understand whether the performance improvement stems solely from the network design...'. This demonstrates a clear understanding of the context and the intended use of the graph. Furthermore, the reviewer anticipates a followup question: 'Note, algorithms skipping layers or channels do not enjoy this luxury.' This indicates a clear understanding of the specific aspect being addressed and the potential implications.", "verifiability_rationale": "The reviewer makes a claim: 'The authors need to show a graph showing the plot of T vs number of images, and Expectation(T) over the imagenet test set.' This claim is verifiable because the reviewer provides a clear and specific request for a visualization. The reviewer also states the *purpose* of this graph: 'It is important to understand whether the performance improvement stems solely from the network design...'. This provides a logical reasoning for why this graph is relevant. While the reviewer doesn't provide external references, the request itself is a verifiable claim based on the stated goal and the suggested comparison with algorithms skipping layers/channels.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'show a graph showing the plot of T vs number of images, and Expectation(T) over the imagenet test set.' This directly addresses a potential concern about the source of performance improvements. The reviewer is specific about the type of graph and the data source (Imagenet test set). The reviewer also anticipates a followup question about algorithms skipping layers or channels, suggesting they are aware of a potential confounding factor. This demonstrates a proactive and helpful approach to understanding the results. While the reviewer doesn't provide specific implementation details, the request itself is a helpful suggestion for improving the authors' analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point states a fact ('When trained and evaluated with the same timestep, Figure 5 shows similar performance...') and offers a potential explanation ('This makes the effectiveness of the proposed methods questionable...'). While the fact is explicit, the explanation is vague and doesn't provide a concrete action for the authors. The reviewer implies an action ('Maybe under some scenarios...') but doesn't explicitly state what the authors should do with this information.", "grounding_specificity_rationale": "The review point explicitly mentions 'Figure 5' and identifies a specific issue: 'similar performance between the baseline model and the timeaware model when trained and evaluated with the same timestep.' This clearly points to a specific part of the paper and the details being discussed.", "verifiability_rationale": "The review point contains a claim: 'This makes the effectiveness of the proposed methods questionable when the goal is just to achieve good performance.' However, this claim is not wellsupported by evidence or reasoning within the review point. The reviewer offers a potential explanation ('Maybe under some scenarios...') but doesn't provide specific examples, references, or logical reasoning to back up their claim about the questionability of effectiveness.", "helpfulness_rationale": "The review point identifies a potential limitation of the proposed method by pointing out the similar performance with the baseline model under specific conditions. While this raises a valid concern, the reviewer doesn't offer a concrete, actionable suggestion or a strong justification for why this is a problem within the scope of the given review point. They suggest exploring different timesteps but don't provide a clear next step for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the problem of lack of clarity on how disentanglement is guaranteed and points to the 'Broader Impacts and Limitations' section. This indicates an explicit action being identified: 'how the disentanglement is guaranteed'. However, the point stops at identifying the location of this information and doesn't provide concrete details on the mechanisms or how the bias types are avoided. Therefore, while an explicit action is identified, it lacks concrete details, making it 3 but not fully actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'Broader Impacts and Limitations' which is a specific section of the paper. This indicates that the authors can identify the section where the issue is discussed. However, the point does not specify *which* subsection or detail within that section is unclear or how the disentanglement is *realized*. The grounding is present, but it is not fully specific. Therefore, it is 3.", "verifiability_rationale": "The review point itself is a statement of a lack of information. It does not contain a claim that needs to be verified using logical reasoning, common knowledge, or external references. Therefore, it falls under the 'X' category of X.", "helpfulness_rationale": "The review point identifies a genuine gap in the explanation regarding a key limitation (disentanglement). It directs the authors to a specific section where the limitation is discussed but doesn't provide any solutions or further clarification within that section. While it highlights an important area for improvement, it doesn't actively guide the authors on how to address the issue. Therefore, it is 3 in identifying a problem but not fully helpful in providing solutions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests using a 'standard regularization trick' for comparison. This action is directly stated and provides a clear direction for the author. While the exact implementation details of the 'standard regularization trick' might not be provided, the action itself is explicit.", "grounding_specificity_rationale": "The reviewer mentions 'stronglyconvex concave case' when suggesting the use of the regularization trick. While the term 'stronglyconvex concave case' is specific, the reviewer does not explicitly point to a particular section, table, or figure in the paper. Therefore, the grounding is weak as the reviewer needs to infer the relevant context.", "verifiability_rationale": "The reviewer suggests using a 'standard regularization trick' for comparison. The term 'standard' implies a widely accepted and wellestablished method. This provides a clear and logical basis for the suggestion, making it verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for comparing the proposed method with existing work in a 'stronglyconvex concave case' by recommending the use of a 'standard regularization trick'. This is directly relevant to improving the paper and addresses a common need in research, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a valuable discussion and presents solutions as a potential outcome. While it doesn't provide immediate actionable steps, it points towards a direction for improvement and encourages the authors to think about their work from a broader perspective. It's not entirely useless.", "grounding_specificity_rationale": "The review point is very general. It doesn't mention any specific section, table, figure, or unique element of the paper. The suggestion is broad and applies to the entire paper.", "verifiability_rationale": "The review point is a suggestion, not a claim. It doesn't state something is *incorrect* or *missing*. It proposes a direction for future work.", "helpfulness_rationale": "The suggestion to discuss different input types and present solutions is valuable and could guide the authors. However, it lacks specific actionable steps, making it less immediately helpful than a review that directly points out a problem and offers a solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests an alternative approach to question transformation but does not explicitly state the action the authors should take or how to implement it. The action is implicit, requiring the authors to consider the limitations of the current method and explore alternative strategies. The lack of specific steps makes the action somewhat vague.", "grounding_specificity_rationale": "The reviewer's comment does not identify a specific part of the paper or method being criticized. The suggestion is general and applies to 'QA' or 'question answering' in general, without pinpointing a specific section, table, figure, or unique aspect of the paper. Therefore, the comment is 1 at all.", "verifiability_rationale": "The reviewer states a concern about the method's limitations regarding nonWhtype questions. While this is a valid concern, the reviewer does not provide specific examples or references to justify this claim. The suggestion to consider alternatives is a recommendation but lacks a clear logical reasoning or external references to support it. Therefore, the claim is somewhat underspecified.", "helpfulness_rationale": "The reviewer provides a suggestion for improvement by recommending considering alternative approaches to question transformation. This is a helpful suggestion as it directly addresses a potential limitation of the current method. However, the suggestion is general and lacks specific implementation details, making it somewhat vague and potentially less actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a problem (drop in accuracy) caused by a change (ICLHAR). While it suggests a discussion, it doesn't explicitly recommend a specific action to address this issue. The action is implicit: 'You changed X, it caused Y, maybe try Z.' The action isn't directly stated.", "grounding_specificity_rationale": "The authors can identify the specific part of the paper being addressed: the impact of ICLHAR on accuracy scores. They can also specify what is being discussed: the change in accuracy and the potential reasons for it. The mention of TRIP and accuracy scores provides specific elements of the paper.", "verifiability_rationale": "The review point makes a claim about the impact of ICLHAR on accuracy scores, stating that it has negatively affected performance. While it provides the numerical values (dropping from 70.4 to 55.6), it doesn't explicitly reference external works or provide a detailed logical reasoning to support this claim within the review point itself.", "helpfulness_rationale": "The review point directly points out a problem (drop in accuracy) caused by a change (ICLHAR) and suggests a discussion about it. This is a clear call for improvement and directly addresses a potential weakness for the authors. It provides a clear direction for the authors to investigate and potentially address the issue."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point states that the rockpaperscissors example is inspired by previous work but does not provide explicit or concrete actions for the authors to take. The authors are not told what to do with this information or how to implement it.", "grounding_specificity_rationale": "The review point mentions 'an example that appeared in many previous work' but does not specify which rockpaperscissors example the authors are referring to. The reviewer does not identify a specific section, table, figure, or unique aspect of the paper being addressed.", "verifiability_rationale": "The review point is a statement of observation ('the rockpaperscissors example is clearly inspired by an example that appeared in many previous work') and does not contain a claim that requires verification or justification.", "helpfulness_rationale": "The review point criticizes the potential redundancy of the rockpaperscissors example but does not offer any concrete suggestions or actions for the authors to improve their draft. It is a critique, not a helpful suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the flaw in the evaluation methodology: 'Comparing the performance of the model only pretrained on synthetic data is unfair'. It also suggests an alternative approach: 'demonstrating that the proposed three projection errors are important is more preferred. In other words, providing the performance of the models pretrained on synthetic data but finetuned on realworld datasets with different losses is necessary'. While the reviewer doesn't explicitly state the action to take, they clearly identify the problem and propose a solution. However, the reviewer doesn't specify *how* to implement the alternative evaluation, making the action somewhat implicit.", "grounding_specificity_rationale": "The review point explicitly mentions 'pretrained on synthetic data' and 'finetuned on realworld datasets' as the key aspects of the alternative evaluation. The reviewer clearly identifies the specific parts of the paper being addressed. The grounding is strong as the reviewer pinpoints the exact sections or components being discussed. The comment specifies what needs to be addressed in this part \u2013 the performance evaluation across different losses.", "verifiability_rationale": "The review point makes a claim: 'Comparing the performance of the model only pretrained on synthetic data is unfair'. The reviewer then provides a suggestion: 'demonstrating that the proposed three projection errors are important is more preferred. In other words, providing the performance of the models pretrained on synthetic data but finetuned on realworld datasets with different losses is necessary'. While the reviewer doesn't provide explicit justification for *why* this alternative is important, they clearly state the steps involved in the suggested evaluation. The claim is 3 as it proposes a specific alternative methodology. However, the reviewer doesn't provide concrete examples or references to support the claim about the importance of the projection errors.", "helpfulness_rationale": "The review point is helpful because it identifies a potential flaw in the evaluation methodology of the paper. By pointing out that the model was only pretrained on synthetic data, the reviewer highlights a potential bias or limitation in the results. The suggestion to evaluate the model by pretraining on synthetic data and finetuning on realworld datasets with different losses is a concrete and actionable step that the authors can take to address this issue. While the review point doesn't provide a complete solution, it offers a clear direction for improving the evaluation, making it moderately helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of relying solely on AUC for evaluating clinical scoring systems and suggests focusing on calibration and the distinction between classification and scoring. This is a clear and direct identification of a weakness in the paper's approach. The reviewer also suggests including calibration curves, which is a concrete action. The reviewer also suggests discussing the difference between traditional methods and their method, which is also a concrete action.", "grounding_specificity_rationale": "The reviewer mentions 'calibration curves' and 'the difference between classification and scoring'. While they don't explicitly name a specific section, table, or figure, the general concept of calibration is implied. The reviewer also hints at the clinical relevance, which is a general comment. Therefore, the grounding is not literal but also not completely underspecified.", "verifiability_rationale": "The reviewer states that 'calibration curves are important' and 'the difference between classification and scoring can also be discussed'. This is a claim that can be verified by examining the paper's content or by referencing literature on clinical scoring systems. The reviewer provides a clear statement of importance. While they don't provide specific examples of where these curves or the difference are discussed, the claim is clear and verifiable.", "helpfulness_rationale": "The reviewer argues that the paper should 'prove the feasibility of the generated scoring system' and that 'the difference between the traditional method and our method can also be discussed in this paper'. These are clear suggestions for improvement that directly address the clinical utility of the proposed method. The reviewer provides concrete directions for what the paper should include. These suggestions are directly beneficial for the authors and address a practical concern. The reviewer's argument is wellarticulated and directly addresses a potential weakness in the paper's contribution."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a discrepancy or lack of clear insight regarding the sparsity patterns. While they don't explicitly state what needs to be done, the question implies a desire for further investigation or clarification. The lack of specific details makes the action somewhat implicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 4.3: presentation bits > representation bits' as the context. This provides a clear and specific reference point within the paper. They then ask a question about whether this observation holds for GNNs in general, directly relating the mentioned section to the broader topic. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The review point is a question, not a claim that requires verification. There is no statement that needs to be supported by evidence or reasoning. Therefore, it does not fit the criteria for verifiability.", "helpfulness_rationale": "The reviewer asks for clarification and poses a question aimed at improving understanding. This directly addresses a potential weakness or lack of clarity for the authors. The request for context is also helpful in guiding the authors. While it doesn't directly *how* to improve, it points towards a direction of improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for a comparison with other methods (CaCE, raw gradients) and suggests discussing the transformation of highdimensional data to lowdimensional latent spaces. This indicates a clear and direct action to be taken by the authors to improve their draft by providing more context and justification for their choice of method.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Shapely value explanations' and 'other methods like CaCE or even raw gradients' as points of comparison. They also mention 'transforming the highdimensional data to lowdimensional latent space,' which is a specific aspect of the method. This demonstrates a clear grounding of the review comment in specific details of the paper and its methodology.", "verifiability_rationale": "The reviewer states, 'I think the authors need to back up their argument for using Shapely value explanations over other methods by comparing experimentally with other methods such as CaCE or even raw gradients.' This statement highlights a lack of clear reasoning or supporting evidence for the choice of Shapely values, making the claims 1.", "helpfulness_rationale": "The reviewer states, 'Because of these concerns, I am keeping my original rating.' This suggests that while the reviewer identifies valid concerns and points that would be helpful for the authors, the information provided in the review point itself is not inherently helpful without further elaboration or experimental backing. The reviewer's statement implies a need for more information to fully assess the helpfulness of the point."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point suggests comparing the perspective taken in Section 6 to prior efforts. This is an explicit action, as it clearly states what needs to be done. However, it doesn't specify exactly where in Section 6 this comparison should be made, making it somewhat vague in terms of concrete implementation.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 6', which allows the authors to identify the specific part of the paper being addressed. Therefore, it is grounded. However, it does not specify what needs to be addressed within Section 6 or what the specific difference in perspective is, making it underspecific.", "verifiability_rationale": "The review point suggests comparing the perspective taken in Section 6 to prior efforts. This statement itself is a claim, as it implies a difference or a need for adjustment. However, the review point does not provide any specific examples, references, or logical reasoning to support this claim, making it 1.", "helpfulness_rationale": "The review point suggests comparing the perspective taken in Section 6 to prior efforts. This is a clear and actionable suggestion that can help authors improve their related work section by contextualizing their contributions and highlighting differences. It is helpful because it directly points to an area for improvement and provides a direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the action of changing the number of scenarios, making it an explicit instruction. While it doesn't specify *how* to examine the performance, the action itself is clear and concrete.", "grounding_specificity_rationale": "The review point refers to 'scenarios' in general, which is not a specific part of the paper. While the context implies the experimental scenarios, the term itself is broad and doesn't pinpoint a unique section, table, or figure. The specificity of the point is limited to the general concept of 'scenarios'.", "verifiability_rationale": "The review point makes an assumption ('I would assume') about the relationship between the number of scenarios and performance. This assumption is not explicitly stated as a claim that requires immediate verification. The point does not provide any evidence, reasoning, or references to support this assumption.", "helpfulness_rationale": "The review point suggests an investigation into the impact of varying the number of scenarios. While this is a valid direction for research, it doesn't provide specific, actionable feedback on what aspects of the current draft need improvement or how to implement the suggested experiment. It lacks concrete suggestions for addressing potential weaknesses."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review states what the authors *did* conduct but does not provide explicit instructions or concrete steps for the authors to take next. They describe the experiments but don't say, \"Based on these experiments, you should...\"", "grounding_specificity_rationale": "The reviewer mentions \"the authors\" conducting comprehensive experiments... and then lists specific experiments (e.g., \"including an architectural mismatch...\"), but it does not explicitly pinpoint a specific section, table, or unique aspect of the paper being addressed. While it mentions \"the authors,\" it doesn't pinpoint a specific section, table, or unique aspect of the paper being addressed. While it mentions \"the authors,\" it doesn't pinpoint a specific section, table, or unique aspect of the paper being addressed. While it mentions \"the authors,\" it doesn't pinpoint a specific section, table, or unique aspect of the paper being addressed.", "verifiability_rationale": "The review is a factual statement about the authors' actions and does not contain any claims or suggestions that require verification.", "helpfulness_rationale": "The review describes the authors' experiments but does not offer feedback on the paper being reviewed or suggest specific improvements based on these experiments."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly states 'Appendix A.2 does not illustrate the state space representation of the environment clearly.' This indicates an implicit action or suggestion that the authors should improve the clarity of Appendix A.2. However, the suggestion lacks concrete details on *how* to achieve this improvement. The authors are not given specific actionable steps or criteria for what constitutes 'clear' illustration.", "grounding_specificity_rationale": "The comment explicitly mentions 'Appendix A.2' and 'state space representation of the environment,' providing a clear and specific reference point within the paper. This demonstrates strong grounding as the authors can easily identify the section and the specific aspect being addressed. However, the comment does not specify *what* is unclear within the illustration.", "verifiability_rationale": "The comment is a judgment about the clarity of the illustration in Appendix A.2. There is X that can be logically verified or supported by external references in this specific instance. It's a statement of a problem without providing evidence or a solution.", "helpfulness_rationale": "The comment identifies a potential weakness in the paper (the lack of clarity in Appendix A.2) but does not provide any specific guidance or suggestions on how to address this weakness. It is a diagnosis without a cure."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The comment explicitly states a limitation of the approach, indicating an action (identifying a problem scale issue). However, it doesn't provide concrete steps on how to address this limitation for large problems.", "grounding_specificity_rationale": "The comment does not specify which part of the paper or approach is being discussed. It refers to the 'authors' approach' generally, lacking specific references to sections, tables, figures, or unique aspects.", "verifiability_rationale": "The comment contains a claim ('The authors approach is only applicable for problems that are small or medium scale') and provides a reason ('Truly large problems will overwhelm current LPsolvers') as supporting evidence. However, it lacks specific examples or citations to back up this claim.", "helpfulness_rationale": "The comment informs the authors about a limitation of their approach. While this is valuable information, it doesn't directly suggest concrete improvements or actionable steps for the authors to take to address this limitation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the impact of the bounded noise assumption ('somewhat restrictive') and mentions the direction of improvement ('efforts to extend these noise conditions'). While it doesn't provide the specific steps for extension, it identifies a clear area for the authors to focus on. The lack of explicit 'how' makes it 3.", "grounding_specificity_rationale": "The review point explicitly mentions 'bounded noise assumption' and then names specific papers and conferences related to extending these conditions. This demonstrates strong grounding as the specific concept and relevant research are identified. The references are literal mentions of specific works, providing clear grounding.", "verifiability_rationale": "The review point contains a claim ('the bounded noise assumption, while common, is somewhat restrictive') and provides references to support the idea of extending these conditions. The presence of specific references makes this claim verifiable.", "helpfulness_rationale": "The review point identifies a potential area for improvement (the bounded noise assumption) and provides relevant references. While the specific *how* to improve isn't detailed in the review, pointing towards existing research is helpful for the authors. The impact is focused on a specific theoretical aspect, which might be of interest to some authors but not all. However, it's a relevant and potentially valuable piece of feedback."}
{"actionability_label": "2", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The review point states that the 'overall motivation of using characteristic function regularization is not clear.' This is a statement of a problem, not a direct instruction on what to do. While it implies the authors should try to understand the motivation, it doesn't explicitly tell them how to do so or what specific aspect is unclear. It's vague and doesn't pinpoint a concrete action.", "grounding_specificity_rationale": "The review point is a general statement about the motivation of a method used in the paper. It doesn't specify which part of the paper or method is unclear. It's a broad critique without pinpointing a specific element.", "verifiability_rationale": "The review point is a statement of a lack of clarity, which is a judgment or opinion. It doesn't present a claim that requires verification or support. There's no suggestion of where the unclear motivation might be or what evidence is needed.", "helpfulness_rationale": "The review point identifies a weakness in the authors' own paper \u2013 the lack of clarity regarding the motivation of a specific method. This could be helpful for the authors to understand where their explanation falls short and how to improve it. However, it doesn't provide specific guidance on how to address this lack of clarity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the combination of techniques, which is an 'Explicit' action. However, the reviewer does not provide concrete guidance on how this combination is a problem or what specific improvements are needed. The suggestion is highlevel and lacks actionable steps.", "grounding_specificity_rationale": "The reviewer mentions specific techniques (Lykouris et al., 2018; Zhou et al., 2021; contextual linear bandits) and their combination, indicating 'Full Grounding'. However, the reviewer's claim about the combination being 'not surprising' and 'incremental' is a general statement and lacks specific details about *why* it's not surprising or incremental in the context of these specific techniques.", "verifiability_rationale": "The reviewer makes a claim about the contribution's novelty ('The fact that these results can be combined together is not surprising, and thus the contribution could be considered incremental.') without providing any external references or logical reasoning to support this claim. The reasoning provided is subjective and does not meet the criteria for verifiability.", "helpfulness_rationale": "The review point is primarily an opinion about the novelty and potential incremental contribution of the work. It does not offer specific, actionable feedback on how the authors should improve their draft based on this observation. Therefore, it is not particularly helpful in terms of providing constructive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly points out a specific issue: 'The aggregation operation after \"Integration\" needs further clarification.' This indicates a direct and actionable suggestion for the authors to improve their multiscale modeling description. While the reviewer doesn't provide the specific details of the aggregation, they identify the location of the problem and suggest a concrete action (providing more details).", "grounding_specificity_rationale": "The reviewer mentions 'Integration' within the context of multiscale modeling, which demonstrates an attempt to ground the feedback in a specific part of the paper. However, the reviewer does not explicitly state which subsection or section of the paper contains the 'Integration' process. They also do not specify the exact nature of the aggregation operation beyond 'aggregation'. While the reviewer identifies a specific area and a specific operation, the lack of precise grounding makes it somewhat specific.", "verifiability_rationale": "The reviewer states 'The aggregation operation after \"Integration\" needs further clarification.' This is a claim that requires verification. However, the reviewer does not provide any evidence or reasoning to support this claim. They do not explain why the aggregation is unclear, what aspects are missing, or provide any references to back up their assertion. Therefore, the claim is not wellsupported.", "helpfulness_rationale": "The reviewer identifies a potential area for improvement in the paper's description of multiscale modeling, specifically the aggregation operation after 'Integration'. By pointing out the need for further clarification, the reviewer provides a clear direction for the authors to improve their work. While the review itself does not provide the specific details for clarification, it highlights a actionable area for the authors to focus on."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a gap in explored techniques (actionable) and highlights a similarity to prior work (actionable). However, they do not provide specific steps on how to achieve compositional generation through logical combination of concepts learned through data subsets (actionable).", "grounding_specificity_rationale": "The reviewer mentions 'energy models' and 'VAEs' (grounded), and refers to a 'prior VAE paper' (weakly grounded). The reviewer also specifies the type of generative models being discussed (specific), but the similarity to a 'prior VAE paper' is weakly grounded. The level of specificity is partially specific regarding the model types but less specific regarding the exact nature of the similarity to the prior work.", "verifiability_rationale": "The reviewer makes a claim: 'the use of energy models for image generation is much more unexplored compared to GANs and VAEs' (claim). However, the reviewer does not provide any evidence or justification for this claim (1).", "helpfulness_rationale": "The reviewer provides a general observation about the relative unexploredness of energy models and points to a similarity with prior work. While this offers a direction for the authors to focus their research, it lacks concrete suggestions for improvement (helpful)."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'The method is evaluated only on the tasks from Meta World...'. This is a direct and clear statement of a limitation in the evaluation scope. The reviewer also states 'Hence, it is difficult to judge whether the results will generalize to other domains.' This is a direct action the authors should take. The reviewer further elaborates with 'I strongly recommend running experiments on a different benchmark such as Atari...'. This is a concrete suggestion for improvement. The reviewer's point is clear, direct, and actionable.", "grounding_specificity_rationale": "The reviewer mentions 'Meta World, a robotic manipulation domain' as the context of the evaluation. While this provides some grounding, it does not pinpoint a specific section, table, figure, or unique aspect of the paper being addressed. The reviewer could have specified which tasks within Meta World or mentioned a particular characteristic of the method. The grounding is present but not as precise as it could be.", "verifiability_rationale": "The reviewer makes a claim: 'The method is evaluated only on the tasks from Meta World...'. This is a statement that requires verification. The reviewer provides supporting information: 'Hence, it is difficult to judge whether the results will generalize to other domains.' This is a logical reasoning supporting the claim. The reviewer also suggests an alternative: 'I strongly recommend running experiments on a different benchmark such as Atari...'. This provides an example of a different domain. The claim is supported by logical reasoning and an example.", "helpfulness_rationale": "The reviewer provides a clear and actionable comment. They identify a specific limitation ('evaluation only on Meta World') and suggest a concrete improvement ('run experiments on Atari'). This comment directly addresses a relevant aspect of the paper (generalizability) and provides a clear path for the authors to address this limitation. The reviewer's intent is to help the authors improve their draft by highlighting a potential area for further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states an action: 'check the feedback/suggestions' which tells the authors where to find the analysis. However, it doesn't specify *how* to perform this action or what exactly needs to be done with the feedback/suggestions. The action is implied but not fully concrete.", "grounding_specificity_rationale": "The review point refers to 'what the model does' generally, without pinpointing a specific section, table, figure, or unique element of the paper. The reviewer can infer that the analysis relates to the model's performance but cannot precisely identify the referenced part.", "verifiability_rationale": "The review point contains a claim: 'a bit of analysis on what the model does is missing'. This is a clear statement that something is lacking. The suggestion to 'check the feedback/suggestions' provides a practical way to verify this claim, making it 3.", "helpfulness_rationale": "The review point is helpful because it identifies a specific area for improvement ('analysis of the model') and provides a clear direction for the authors to take ('check the feedback/suggestions'). This directly empowers the authors to address the identified weakness."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for clarification on a crucial aspect of the methodology: which EHR notes are used as input and how far removed the outcomes are from the last note date. This is a clear and direct request for information that would make the methodology more actionable. The reviewer is asking for specific details about the input data and its temporal relationship with the outcome, making it actionable.", "grounding_specificity_rationale": "While the reviewer doesn't explicitly state that the paper doesn't mention the EHR notes or their temporal relationship, the request implies a lack of clarity in these aspects. The reviewer is asking for specific details, suggesting that if these were clearly stated, the information would be readily available. Therefore, the grounding is weak because the information is not explicitly defined within the paper at the time of the review. The reviewer is pointing to a potential ambiguity, not a complete absence of information.", "verifiability_rationale": "The reviewer requests specific details about the EHR notes used as input and the temporal distance of the outcomes. This request directly points to the need for external references or verifiable information to support the methodology. The reviewer is asking for evidence or examples that would make the claims more verifiable. The information is likely to be found in the cited works (the EHR notes and outcome documentation), making the request for verifiable information highly relevant and achievable.", "helpfulness_rationale": "The reviewer's request is clear and directly addresses a potential ambiguity in the methodology. They are asking for crucial details that would allow for better understanding and potentially replication of the work. The request is actionable and provides a clear direction for the authors to improve their understanding of the data used. Therefore, the review point is 5 in guiding the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the convergence rates of the proposed algorithm DMLCBO and the previous works SUSTAIN and MRBO, and clearly identifies the discrepancy in the convergence rates. The reviewer also explicitly states the need for discussion regarding the theoretical differences. This indicates a clear and actionable point for the authors to address.", "grounding_specificity_rationale": "The reviewer mentions specific algorithms (SUSTAIN and MRBO) and their properties (convergence rate) when describing the proposed algorithm DMLCBO. This demonstrates a strong grounding of the relevant prior work and a clear focus on the specific aspects of the algorithms being compared. The reviewer also explicitly mentions the double momentum technique, further grounding the discussion.", "verifiability_rationale": "The reviewer makes a claim about the convergence rate of DMLCBO compared to previous works and suggests a discussion of the theoretical differences. This claim is supported by the provided convergence rates. However, the reviewer does not delve into the specific theoretical underpinnings of DMLCBO or the previous works to explain *why* the convergence rate is different. While the information is present, a deeper explanation and comparison of the theoretical techniques are missing, making it 3 but lacking in depth.", "helpfulness_rationale": "The reviewer points out a relevant aspect of the algorithm's performance (convergence rate) and encourages the authors to discuss the theoretical differences. This is a relevant point for the authors to consider and address. However, the point is somewhat general and does not provide a specific suggestion for improvement or a concrete question to ask. It encourages discussion but doesn't directly guide the authors towards a solution, making it 3 but lacking in specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the modulator is 'heuristically designed' and that there might be a scalability issue requiring 'tedious hyperparameter tuning'. While it identifies a potential problem, it does not explicitly state what action the author should take or how to implement it. The reviewer points out a concern but doesn't provide concrete steps for improvement. The vagueness in terms like 'scalability' and 'hyperparameter tuning' makes it difficult to pinpoint a specific, actionable change.", "grounding_specificity_rationale": "The review mentions 'modulator' and 'hyperparameter tuning' but does not explicitly identify a specific section, table, figure, or unique aspect of the paper it is referring to. The terms are general and do not point to a precise location or detail within the paper. The reviewer can infer that the issue relates to the modulator and hyperparameters, but lacks the specificity to know exactly what part needs attention.", "verifiability_rationale": "The review states that the modulator is 'heuristically designed' and that there might be a scalability issue requiring 'tedious hyperparameter tuning'. These statements can be considered claims. However, the review does not provide any evidence, references, or logical reasoning to support these claims. It presents a concern without justifying or backing it up with external sources or clear explanations.", "helpfulness_rationale": "The review points out a potential issue with the modulator's design and suggests that it might require 'tedious hyperparameter tuning'. While this identifies a problem, it does not offer any specific solutions or guidance on how to address it. The reviewer highlights a concern but does not provide actionable feedback or constructive suggestions for improvement. The lack of concrete steps makes the review less helpful to the author."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a need for experiments but doesn't specify how to conduct them or what the results should be. It's explicit about the *problem* (lack of experiments) but lacks detail on the *solution*.", "grounding_specificity_rationale": "The comment is broadly about the applicability of imitation learning and the lack of experiments on labeled data. It doesn't specify which part of the paper or methodology is affected.", "verifiability_rationale": "The comment makes a claim about the absence of experiments. While this is a verifiable statement in principle, the lack of specifics about the *nature* of the difficulties or the *impact* of data size makes it only partially verifiable.", "helpfulness_rationale": "The comment points out a potential gap in the research and encourages the author to investigate the applicability of imitation learning. While it doesn't provide a direct solution, it highlights a relevant area for further inquiry, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a limitation: 'it does not thoroughly explore the implications of their proposed method for other NLP tasks.' However, it does not specify which aspect of the method or NLP tasks are affected, nor does it suggest any concrete actions or improvements the authors should take to address this limitation.", "grounding_specificity_rationale": "The comment refers to 'their proposed method' generally, without pinpointing a specific section, table, figure, or unique element of the paper. It identifies a limitation regarding 'other NLP tasks' without specifying which part of the method or which aspect of NLP is lacking. While it implies a general area of concern, it lacks precise identification. This can be seen as a form of weak grounding as the authors would need to infer the specific part being addressed. The specificity is also low as it doesn't detail what is missing or wrong in the referenced part.", "verifiability_rationale": "The comment states a fact about the paper: 'it does not thoroughly explore the implications of their proposed method for other NLP tasks.' This is a statement of observation, not a claim that requires verification. There is no suggestion or recommendation for improvement, and no logical reasoning or external references are provided to support this observation.", "helpfulness_rationale": "The comment identifies a valid limitation of the paper: the limited exploration of the proposed method's implications for other NLP tasks. However, it does not offer any concrete suggestions or guidance to the authors on how to address this limitation. The helpfulness is limited as the comment points out a potential area for future work but doesn't directly instruct the authors on how to improve their current draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: \"The use of the terminology \"certificate\" in some contexts (for instance at line 267) might be misinterpreted, due to its strong meaning in complexity theory.\" This is a clear and actionable suggestion for the authors to clarify the usage or provide context for the term \"certificate\".", "grounding_specificity_rationale": "The reviewer explicitly mentions \"certificate\" as the specific part of the paper being addressed and clearly identifies the issue: \"might be misinterpreted, due to its strong meaning in complexity theory.\" This demonstrates strong grounding as the reviewer accurately pinpoints the specific term and the nature of the potential confusion.", "verifiability_rationale": "The reviewer makes a claim: \"The use of the terminology \"certificate\" in some contexts (for instance at line 267) might be misinterpreted, due to its strong meaning in complexity theory.\" This claim is wellsupported by the reviewer's understanding of the term \"certificate\" in complexity theory, which is a logical and verifiable point.", "helpfulness_rationale": "The review point is 5 as it clearly identifies a potential source of confusion for the authors (the overloaded term \"certificate\" and its meaning in complexity theory). The suggestion to clarify the usage or provide context is actionable and directly addresses a likely point of ambiguity."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests 'More experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to further strengthen the paper.' While it identifies the type of experiments to conduct, it lacks specific details on how to implement these experiments. The reviewer doesn't specify which datasets, training parameters, or evaluation metrics to use for these new experiments. The action is implied but not explicitly stated in a concrete manner.", "grounding_specificity_rationale": "The review point mentions 'deeper networks' and 'other network structures' generally. It does not explicitly identify a specific part of the paper being addressed. The reviewer is making a suggestion about the *type* of network to use, but not pointing to a specific section, table, or figure in the paper. While the *concept* of network architectures is relevant, the suggestion is about a *category* of architectures, not a specific element within the paper.", "verifiability_rationale": "The review point states a need for 'more experiments' but does not make any claims or judgments about the current experiments or the paper. It is a suggestion for future work rather than a critique or assertion requiring verification. There is X being made that needs to be supported by evidence.", "helpfulness_rationale": "The review point suggests trying 'deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet)'. While this is a relevant suggestion for improving the paper, it is a general direction rather than a specific fix for the current state of the paper. It doesn't pinpoint any specific weaknesses or issues in the current draft. The suggestion is practical but lacks the specificity needed to directly improve the current work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a limitation in the evaluation scope (two old, small models). This is an explicit limitation. However, it doesn't specify how this limitation should be addressed. It points out a missing part in the evaluation. Therefore, it's partially actionable.", "grounding_specificity_rationale": "The comment identifies a specific aspect of the evaluation (the choice of models). However, it doesn't specify which models or why these specific models were chosen. It doesn't pinpoint a unique element of the paper being addressed. Therefore, it's weakly grounded.", "verifiability_rationale": "The comment states a fact ('two relatively old and small models were evaluated'). However, it doesn't provide any justification or reasoning for this choice. There are no external references or logical arguments presented. Therefore, it's 1.", "helpfulness_rationale": "The comment highlights a limitation in the evaluation's scope. While it's a valid point for improving future evaluations, it doesn't directly provide actionable feedback on how to improve the specific draft being criticized. It's more of a call for a more diverse set of models rather than a direct suggestion for improvement. Therefore, it's 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the connection between Knowledge Distillation (KD) and Label Smoothing (LS) and provides specific conditions (uniformly distributed teacher network and temperature of 1) under which they might be equivalent. This makes the suggestion both explicit and concrete, providing a clear action for the authors to consider.", "grounding_specificity_rationale": "The reviewer clearly identifies the concepts of Knowledge Distillation (KD) and Label Smoothing (LS) and specifies the conditions under which KD can be viewed as a special form of LS. The mention of 'teacher network,' 'uniformly distributed,' and 'temperature is set at 1' demonstrates a high level of grounding specificity.", "verifiability_rationale": "The reviewer presents a claim about the relationship between KD and LS under specific conditions. However, they do not provide any justification, reasoning, or references to support this claim. The connection is stated without any supporting evidence, making it 1.", "helpfulness_rationale": "The reviewer identifies a potential area for further investigation or clarification regarding the relationship between KD and LS. While the suggestion is present, it lacks immediate actionability and supporting evidence. The reviewer's belief, though potentially valuable, is not presented in a way that would immediately benefit the authors. The helpfulness is moderate as it raises a valid point but doesn't offer concrete steps for improvement at this time."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need for 'more recent works' and 'large scale datasets including ImageNet'. This indicates a clear and direct suggestion for improvement, making the comment actionable. The reviewer provides concrete examples of what constitutes 'more recent' and 'large scale', further enhancing the actionability.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'competing dynamicpruning methods' and 'large scale datasets including ImageNet'. This directly identifies the specific area of the paper being addressed, making the grounding very strong. The reviewer provides a clear focus for the feedback.", "verifiability_rationale": "The reviewer states a claim: 'Competing dynamicpruning methods are kind of outofdate'. This is a statement of opinion. The reviewer then provides reasoning for this claim by suggesting 'more recent works' and 'results on large scale datasets including ImageNet' as solutions. This logical reasoning supports the claim, making it verifiable.", "helpfulness_rationale": "The reviewer provides a clear and actionable critique by pointing out the lack of recent work and the need for results on largescale datasets. This directly helps the authors understand the limitations of the existing literature and what additional experiments or comparisons would be beneficial. The suggestions are specific and provide a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "6: 1", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a question that implies a lack of clarity or justification for the random CIFAR image backgrounds. While they don't explicitly state what should be done, the question itself is a form of implicit criticism, suggesting the authors should consider alternative backgrounds. However, the action is vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions the use of CIFAR images as backgrounds, which grounds the criticism. However, the criticism focuses on the *motivation* and *interestingness* of this choice, rather than pinpointing a specific flaw within that section or table.", "verifiability_rationale": "The review point is a question, not a statement making a claim. There is no evidence of a claim, judgment, or suggestion being made.", "helpfulness_rationale": "The reviewer's question directly targets a potential weakness in the experimental setup and encourages the authors to think critically about their choices. It doesn't provide a solution, but it prompts a discussion about the design."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the problem ('The motivation is not clear at all'), but it does not specify what aspect of the motivation is unclear or how the authors should address this issue. The action is implied but not concretely stated.", "grounding_specificity_rationale": "The authors cannot confidently determine which part of the paper the comment addresses. The comment is a general statement about the motivation, not a specific section or element within the paper. The grounding is weak because the authors can only infer the target area.", "verifiability_rationale": "The comment does not contain a claim. It is a statement of observation about the clarity of the motivation. Therefore, verifiability is not applicable, and the label is X (X).", "helpfulness_rationale": "The comment identifies a significant weakness in the paper (lack of clarity in the motivation) and suggests improvement (revision of the introduction). While it doesn't provide specific, actionable steps, it points to a crucial area that needs attention. It is helpful in highlighting a problem that needs solving."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the need to 'align relabeled reward data with human annotator judgments' and that this alignment is 'insufficiently validated.' This directly points to an action the authors should take: validate the alignment. While the *method* of validation isn't specified, the action is clearly stated. This aligns with the definition of being explicit and pointing to an action, albeit a somewhat vague one.", "grounding_specificity_rationale": "The review point explicitly mentions 'relabelled reward data' and 'human annotator judgments,' which are specific parts of the paper. It even names the *purpose* of the relabeling (to align with human judgment). This is fully grounded. While it doesn't specify *how* the alignment should be validated, it clearly specifies what needs to be validated.", "verifiability_rationale": "The review point itself is a statement of a problem, not a claim requiring verification. It doesn't present any assertions that need supporting evidence or logical reasoning. Therefore, it doesn't fit the definition of verifiability.", "helpfulness_rationale": "The review point clearly identifies a weakness in the alignment process and suggests a solution (validation). While it doesn't provide specific details on *how* to validate, it points to a concrete next step for the authors: investigate the alignment. This makes it 5 in highlighting a crucial issue and guiding the authors towards a potential next step. The vagueness in the 'how' doesn't negate the helpfulness of pointing out a concrete problem."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a limitation in the method's applicability due to the limited number of molecules used for training. While it points out a potential issue, it doesn't explicitly state what the author should do to address it or how to implement a solution. The reviewer suggests the method might need to be trained for each molecule individually, but this is presented as a concern rather than a concrete action the author should take. The lack of a specific action or method makes it less actionable than a review that directly suggests an improvement or a specific step to follow.", "grounding_specificity_rationale": "The reviewer mentions 'limited number of molecules' and 'indistribution testing'. While the reviewer doesn't explicitly name the specific part of the paper being addressed, the context implies it's related to the experimental setup and the type of testing performed. The reviewer also expresses an opinion about the method's value based on this limitation. However, the reviewer does specify the issue with 'indistribution testing', which clearly indicates a lack of generalization to unseen data. The reviewer identifies the *nature* of the testing and the potential problem with it.", "verifiability_rationale": "The reviewer states an opinion about the method's value based on the limited experimental setup and the need to train for each molecule individually. This statement is a claim, an opinion, and a suggestion. While the reviewer's reasoning is logical (that training for each molecule individually would be computationally expensive and impractical), the review itself doesn't provide any external references or specific data to support this claim. The claim is based on the reviewer's understanding of the limitations, but without direct evidence within the review, it's not 5.", "helpfulness_rationale": "The reviewer raises a valid concern about the method's potential impracticality due to the need for individual training for each molecule. This concern directly relates to the authors' ability to use and scale the method. While the reviewer doesn't offer a solution, they highlight a significant limitation that could hinder the method's adoption and perceived value. The reviewer's point is directly relevant to the authors' workflow and the feasibility of implementing the method."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the issue (' Symbols are complicated') and suggests a potential improvement ('takes a lot of time to understand'). This is an explicit and concrete actionability. The authors can directly infer that they need to simplify the symbols or provide more guidance on how to interpret them.", "grounding_specificity_rationale": "The review point generally refers to 'symbols' without specifying which particular symbols are causing the issue. This makes the grounding weakly grounded. While the topic is about symbols, the specific elements within the symbols that are problematic are not identified.", "verifiability_rationale": "The review point makes a claim ('Symbols are complicated and take a lot of time to understand') without providing any evidence, justification, or references. There is no logical reasoning, common knowledge, or external references to support this claim. Therefore, it is 1.", "helpfulness_rationale": "The review point identifies a potential issue (complicated symbols) that could hinder understanding and potentially the reproducibility of results. While it doesn't directly tell the authors how to fix it, it highlights a problem area that the authors are likely to encounter. This makes it helpful in pointing out a potential area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about the role of periodicity, which can be interpreted as an implicit request for clarification or a suggestion for an experiment. While not entirely explicit, the action is clear and directly related to the content of the paper.", "grounding_specificity_rationale": "The reviewer clearly identifies 'periodicity' and 'compositionality' as the relevant concepts. They also suggest a specific experiment ('adding periodicity to the spectral kernel') to test their hypothesis. This strong grounding and specificity make the comment highly specific.", "verifiability_rationale": "The reviewer presents a claim about the potential sufficiency of periodicity and suggests an experiment to test it. This claim is verifiable as the authors can design and conduct the suggested experiment to compare the models' performance. The suggestion for a specific experiment provides a basis for verification.", "helpfulness_rationale": "The reviewer's point is 5 as it directly addresses a potential limitation of the models being evaluated and suggests a concrete experiment to investigate this limitation. It provides a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1: Not Helpful", "actionability_rationale": "The comment is implicit, suggesting a problem with the writing quality but not specifying what needs to be done. It lacks explicit instructions on how to improve the paper.", "grounding_specificity_rationale": "The comment does not identify a specific part of the paper being addressed. It is a general statement about the writing quality, making it 1 in a specific section, table, or figure.", "verifiability_rationale": "The comment contains a claim ('the paper is not very wellwritten') but does not provide any supporting evidence, reasoning, or references to back it up.", "helpfulness_rationale": "The comment is a general criticism of the writing quality without offering specific suggestions or actionable steps for improvement, making it unhelpful for the authors."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the introduction to orthogonality in Part 2 is lacking in detail. This is an explicit action that the authors should take to improve their draft. However, the comment does not specify *how* the introduction should be made more detailed. The action is concrete in identifying the area for improvement but is vague on the implementation steps.", "grounding_specificity_rationale": "The comment explicitly mentions 'Part 2' where orthogonality is discussed. This allows the authors to identify the specific section being referred to, demonstrating strong grounding. However, the comment does not specify *which* part of 'Part 2' or *what specific aspect* of the orthogonality introduction needs more detail. The grounding is specific to the section but lacks detail about the exact location or issue.", "verifiability_rationale": "The comment presents a suggestion for improvement ('could be more detailed') but does not provide any justification or evidence to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the introduction to orthogonality is lacking in detail. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The comment identifies a potential area for improvement in the authors' draft ('orthogonality in Part 2') and suggests making the introduction more detailed. This directly points to a actionable step the authors can take. While the suggestion is general, it provides a clear direction for the authors to consider. The comment is not vague or dismissive, making it helpful in guiding the authors towards a more detailed explanation."}
{"actionability_label": "1", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point discusses existing analyses and findings but does not provide explicit instructions or concrete steps for improvement based on this information. It's an observation rather than a directive.", "grounding_specificity_rationale": "The review point does not specify which part of the paper it is referring to or what specific issues it is addressing within that part. It's a general observation about prior work.", "verifiability_rationale": "The review point contains claims about existing analyses and provides references to prior work (RobustBench, A, B), making it partially verifiable.", "helpfulness_rationale": "The review point provides context and situates the current work within the existing literature on robustness and distribution shifts, making it 3 by offering a broader perspective."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the study about different subdomain sizes is not an 'ablation' study because it doesn't involve removing a component of the method. Instead, it explores the impact of varying subdomain sizes. This is an explicit statement of an action that the authors should take to clarify their work.", "grounding_specificity_rationale": "The reviewer directly addresses the 'subdomain size study' and criticizes its labeling as an 'ablation' study. The authors, upon reading this comment, would immediately understand that this is specifically about the subdomain size experiment. The grounding is explicit and directly points to the relevant part of the paper.", "verifiability_rationale": "The reviewer makes a claim about the authors' characterization of their study. The authors can easily verify the details of their subdomain size experiments and compare them to the typical definition of an ablation study. The evidence for verifiability is strong and direct.", "helpfulness_rationale": "The reviewer points out a potential misunderstanding or mischaracterization of the authors' work. While it doesn't directly suggest specific improvements, it prompts the authors to reconsider their terminology and potentially clarify their experimental setup. This is a moderately helpful comment as it highlights a potential communication issue."}
{"actionability_label": "High", "grounding_specificity_label": "Medium", "verifiability_label": "N/A", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states: 'It would be stronger if the base DA methods were similarly evaluated with/without the architectural competitors such as AutoDial and AdaBN that are direct competitors to TN.' This is a clear and direct suggestion for an action to be taken. The reviewer provides a specific action: 'evaluate the base DA methods with and without AutoDial and AdaBN.' This makes the action concrete and directly addresses the comparison of architectural methods.", "grounding_specificity_rationale": "The reviewer suggests 'evaluating several base DA methods with and without the architectural competitors such as AutoDial and AdaBN.' While the *action* of evaluating is clear, the reviewer does not specify *which* base DA methods should be compared. The mention of AutoDial and AdaBN is literal, indicating a degree of grounding. However, the lack of specificity in identifying the base methods makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer's statement is a prescription for improvement, not a claim requiring verification. The statement is: 'It would be stronger if the base DA methods were similarly evaluated with/without the architectural competitors such as AutoDial and AdaBN that are direct competitors to TN.' This is a suggestion or recommendation, not a statement of fact or opinion that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer states: 'It would be stronger if the base DA methods were similarly evaluated with/without the architectural competitors such as AutoDial and AdaBN that are direct competitors to TN.' This suggests a specific evaluation that, if implemented, would provide valuable feedback to the authors, empowering them to significantly improve their draft. The reviewer's suggestion is directly aimed at helping the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the evaluation is weak, which implies an action (improving the evaluation). However, the specifics of *which* aspects are weak and *how* to improve them are not detailed, making the action vague. The lack of explicitness makes it less actionable than '4' or '1'.", "grounding_specificity_rationale": "The review point is a general statement about the evaluation being weak and the baselines being inadequate. It does not specify which part of the paper or methodology is being evaluated, nor does it pinpoint the exact issues with the baselines. Therefore, it lacks the grounding required for '3' or 'Weakly Grounded and UnderSpecific'. It also doesn't fully identify the referenced part as 'Fully Grounded'.", "verifiability_rationale": "The review point makes a claim ('the evaluation is weak; the baselines used in the paper are not even designed for fair classification') but does not provide any evidence or reasoning to support this claim. There are no logical arguments, common knowledge references, or external citations. Therefore, it does not meet the criteria for '3' or '4'. It also doesn't fit the 'X' category as it does make a statement, albeit without support.", "helpfulness_rationale": "The review point criticizes the evaluation as being weak and the baselines as inadequate. While this critique might be helpful in identifying areas for improvement, the lack of specific details about the weaknesses and the proposed improvements makes it difficult to determine its overall helpfulness. It's a negative comment about the evaluation's quality without concrete suggestions, making it less helpful than '4' or '4'."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the action they believe would improve the paper: 'spelling out the setting'. This action is directly related to the first three paragraphs of section 2. The reviewer provides a clear and actionable suggestion, making it explicit. The specificity of the action, focusing on the setting within those specific paragraphs, makes it concrete. The reviewer's intention is for the authors to understand the context and scope of their work more clearly, which is a direct and actionable improvement.", "grounding_specificity_rationale": "The reviewer identifies the specific part of the paper they believe needs clarification: 'the first three paragraphs of section 2'. This is a clear and precise identification, indicating strong grounding. The reviewer also specifies the * aspect being addressed: 'the setting'. This specificity goes beyond simply mentioning a section or table, indicating a clear understanding of what needs to be improved.", "verifiability_rationale": "The reviewer makes a claim: 'it seems like the authors want to receive credit for doing something in greater generality than what they actually present, and this muddles the exposition'. This claim is supported by logical reasoning. The reviewer is inferring that the lack of clarity in the setting is causing confusion and preventing the authors from demonstrating their work's generality. While the reviewer doesn't provide external references, the logical connection between the unclear setting and the difficulty in demonstrating generality is evident.", "helpfulness_rationale": "The reviewer provides a clear action (spelling out the setting) and a justification for why it would be helpful (it muddles the exposition). This suggests a wellreasoned and actionable piece of feedback. The reviewer is directly addressing a potential issue that could hinder the authors' ability to demonstrate the generality of their work. The suggestion is specific and directly related to the identified problem."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a weakness in the choice of baselines (R3D, C3D) and suggests exploring more modern 3D CNNs (X3D, SlowFast). While the reviewer identifies a potential area for improvement, the suggestions are not explicitly tied to specific parts of the paper or the proposed method. The reviewer implies an action (exploring new architectures) but doesn't provide concrete steps on how to implement this suggestion or how it would improve the method. The reviewer's point is implicit, requiring the authors to infer the next steps.", "grounding_specificity_rationale": "The reviewer criticizes the choice of baselines and suggests exploring alternative 3D CNNs. While the reviewer implicitly refers to the experiments by mentioning 'the experiments are not quite convincing,' they do not explicitly identify a specific section, table, or figure in the paper that is problematic. The reviewer's comment is general about the experiments as a whole and the limitations of the chosen baselines.", "verifiability_rationale": "The reviewer states a claim about the limitations of the chosen baselines (R3D, C3D) and suggests exploring more advanced 3D CNNs (X3D, SlowFast). The reviewer does not provide any external references or specific examples to support their claim about the advantages of the proposed method over these newer architectures. The claim is presented without sufficient justification or evidence.", "helpfulness_rationale": "The reviewer raises a valid concern about the choice of baselines and suggests exploring alternative 3D CNNs. However, the review point itself does not directly provide actionable feedback on how to improve the proposed method or the experimental setup. The reviewer's comment is more of a question or suggestion for further investigation rather than a direct improvement for the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer is implicitly suggesting that the authors should clarify the attention module's integration with ResNet20. However, the reviewer does not explicitly state the steps or actions the authors should take to achieve this clarification. The reviewer's questions are general and do not provide concrete instructions on how to proceed.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify the specific part of the paper where the attention module integration is unclear. The reviewer is making a general statement about the lack of clarity in this area. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer points out a potential problem (lack of clarity) but does not provide any justification or evidence for why this is a significant issue. The reviewer's statement is a claim that requires verification, but the verification is missing. The reviewer does not reference external knowledge or logical reasoning to support their claim.", "helpfulness_rationale": "The reviewer's comment identifies a potential issue in the methodology (lack of clarity in attention module integration). However, the feedback is very general and lacks specific details on how this lack of clarity affects the results or how the authors should address it. The reviewer does not provide actionable steps or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point partially addresses actionability. The statement 'The proposed method looks stronger at high bitrate but close to the baselines at low bitrate' identifies a performance difference but lacks specific actionable steps. However, the suggestion 'Besides, a related work about implementing content adaptive algorithm in learned video compression is suggested for discussion or comparison' is explicit and actionable, directly pointing to a relevant piece of work.", "grounding_specificity_rationale": "The review point is 1. The statement 'The proposed method looks stronger at high bitrate but close to the baselines at low bitrate' refers to general performance without explicitly pinpointing a specific section, table, figure, or unique aspect of the paper. The suggestion to discuss a related work is also 1 as it doesn't specify how this work relates to the submitted paper.", "verifiability_rationale": "The review point is not verifiable. The statement 'The proposed method looks stronger at high bitrate but close to the baselines at low bitrate' is an observation, not a claim requiring evidence. The suggestion to discuss a related work is also not verifiable as it doesn't propose a claim that needs to be supported.", "helpfulness_rationale": "The review point is 3. The observation about performance at different bitrates is a valid point for discussion. The suggestion to discuss a related work is 5 as it directly points to a relevant area for comparison and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review suggests a *distinction* between two concepts. While it points to a potential area for clarification, it doesn't directly instruct the authors on *what to do*. Therefore, it's not fully actionable. The suggestion to 'distinguish' is implicit, and the authors are left to figure out the specifics.", "grounding_specificity_rationale": "The review *mentions* the 'allornothing or cutoff phenomenon' and 'machine learning and NeurIPS community' and 'statistical bounds'. These are specific terms, indicating some grounding. However, it doesn't pinpoint a unique element within a section or table, making it only somewhat grounded.", "verifiability_rationale": "The review contains a claim (that distinguishing the terms is important or beneficial). However, it lacks concrete evidence or justification to be 5. It suggests a potential area for improvement but doesn't explain *why* this distinction is crucial or how it impacts the work.", "helpfulness_rationale": "The review is not entirely useless, as it highlights a potential conceptual gap. However, it doesn't provide specific guidance on how to address it. It's more of a suggestion than a direct critique or actionable advice. The authors are left to interpret the value of this suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation regarding the Gaussian assumption and suggests a comparison to existing rates. This is a direct and clear identification of a problem and a proposed solution, making it 5. The reviewer clearly states what needs to be addressed (Gaussian assumption) and how to potentially improve the algorithm (comparing rates).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Gaussian' and 'noise are Gaussian' when identifying the specific part of the paper being addressed. This is a literal mention of a specific aspect of the theoretical analysis, making it fully grounded. The reviewer also clearly specifies what is being criticized (the Gaussian assumption) and what should be done (compare rates), making it specific.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the theoretical results. This claim is verifiable because the reviewer suggests a concrete next step (comparing rates) to address the identified issue. The suggestion to compare rates provides a basis for verification and further investigation.", "helpfulness_rationale": "The reviewer provides a constructive critique by pointing out a specific limitation in the theoretical analysis and suggesting a concrete improvement. This is 5 as it directly addresses a potential weakness and offers a clear direction for future work. The suggestions are actionable and specific, making it a valuable feedback point."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a comparison with a previous work, which is a direct and actionable suggestion for the authors. The comparison is a clear indication of what needs to be done.", "grounding_specificity_rationale": "The reviewer specifically mentions 'Schiratti et al. (2015)' and 'simulated data' as the basis for the comparison. This provides a clear and precise reference point, indicating strong grounding. The paper and data source are explicitly named.", "verifiability_rationale": "The reviewer does not make a claim or assertion. They are simply suggesting a comparison. There is no logical reasoning, common knowledge, or external references provided within this review point itself.", "helpfulness_rationale": "The reviewer's suggestion to compare the proposed extension with the original approach is directly relevant to understanding the contribution and potential benefits of the new method. This provides valuable context and is likely to be helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review explicitly states the problem of limited baselines and provides a concrete suggestion to add more relevant works. This is both explicit and concrete.", "grounding_specificity_rationale": "The reviewer focuses on the experimental section and the baselines, indicating weak grounding. However, the suggestion to include specific works 1, 2, 3 adds specificity.", "verifiability_rationale": "The reviewer makes a judgment about the experimental limitations. The suggestion to include specific works 1, 2, 3 provides a basis for verifying the claim by referencing external literature.", "helpfulness_rationale": "The review identifies a clear weakness in the experimental section and offers a specific and actionable suggestion. This is highly beneficial for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'ignores some other NAS' and provides specific examples ('supernet/oneshot approaches, etc...'). This indicates a clear and direct suggestion for improvement, making it explicit. The reviewer also implies a need to compare against specific types of NAS, which provides a clear direction for action.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific section, table, or figure in the paper where the lack of comparison is noted. While the reviewer implies a need for more comparisons within the NAS category, they do not specify which part of the paper this deficiency is located. The reviewer mentions 'some other NAS' generally, without pinpointing a unique element of the paper being addressed.", "verifiability_rationale": "The reviewer makes a factual statement about the BRPNAS analysis: 'it only compares against 3 basic alternatives and ignores some other NAS (e.g. supernet/oneshot approaches, etc...).' This claim is verifiable based on the information *absent* from the paper, as the reviewer is stating an observation about the lack of specific comparisons.", "helpfulness_rationale": "The reviewer provides a specific suggestion for improvement by recommending comparisons against 'specific types of NAS' (supernet/oneshot). This suggests a clear direction for the authors to take action on, making the comment helpful in guiding them towards a more comprehensive analysis. While it doesn't directly tell them *how* to implement the comparison, it provides a concrete goal for further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a lack of detail regarding the filtering process and asks what needs to be done to assess the dataset quality. While the reviewer doesn't explicitly state an action, they clearly indicate a need for more information, which can be directly applied by the authors to understand and improve the dataset. The action is somewhat implicit but directly addresses a gap in the information.", "grounding_specificity_rationale": "The reviewer mentions 'filtering process' and 'translation and filtering methodology' as specific aspects of the dataset creation. However, they don't explicitly identify a specific section, table, or unique element of the paper where this information is supposed to be found. The grounding is present but could be stronger by pointing to a specific location. The specificity is good as the reviewer is asking about a specific aspect of the dataset creation.", "verifiability_rationale": "The reviewer states a need for more information and asks a question about how to assess dataset quality. There isn't a direct claim or opinion stated. The reviewer is implicitly suggesting that the lack of this information is a problem, which can be considered a logical deduction. The verifiability is good because the implication can be drawn, but it's not a direct statement of a belief.", "helpfulness_rationale": "The reviewer clearly identifies a gap in the information provided about the dataset. This directly informs how the authors should proceed with using or developing the dataset. The reviewer's point is 5 and directly relevant to their work with the dataset. The authors know exactly what they need to do next."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly mentions the 'lack of attacks with different strength' and the 'lack of how different thresholds influence the detection performance'. These are explicit actions or suggestions that the authors can directly implement. However, the reviewer does not specify *how* to address these issues, leaving the authors with a general direction but no concrete steps. The lack of specificity makes it less actionable than '4'.", "grounding_specificity_rationale": "The reviewer refers to 'the experiment results' as the area of concern. While they hint at the *content* of the criticism ('attacks with different strength', 'different thresholds'), they do not pinpoint a specific section, table, figure, or unique aspect within the 'experiment results' section. The reference is broad, making it 'Weakly Grounded'.", "verifiability_rationale": "The reviewer states the 'lack of attacks with different strength' and the 'lack of how different thresholds influence the detection performance'. These are claims that need to be addressed. However, the reviewer does not provide any specific examples, references, or logical reasoning to support these claims. The lack of evidence makes it '1'.", "helpfulness_rationale": "The reviewer suggests enriching the experiment results by addressing the 'lack of attacks with different strength' and the 'lack of how different thresholds influence the detection performance'. While this is a valid suggestion for improving the paper, it is quite general. The authors would need to conduct further research and experimentation to fully address these points. The lack of specific guidance makes it only '2'."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment does not explicitly state what the authors should do or how they should apply the information. While it implies the need to understand the impact of different experimental choices, it doesn't provide a clear action. The comment is implicit in nature.", "grounding_specificity_rationale": "The comment mentions 'L170' which suggests an attempt at grounding the issue to a specific location in the paper. However, it does not explicitly identify the section, table, figure, or unique aspect of the paper being addressed. The reference is vague and could be interpreted in multiple ways, indicating weak grounding.", "verifiability_rationale": "The comment does not contain a claim or assertion that needs to be verified. It is a request for information or clarification rather than a statement that requires evidence or justification. Therefore, it is not verifiable as it does not fit the definitions of a claim requiring support.", "helpfulness_rationale": "The comment is likely to be 3 as it points the authors towards an area where they might need more information to understand the impact of their experimental choices. However, it does not directly instruct them on what to do or how to interpret the results. The helpfulness is limited to providing a direction for further investigation rather than a direct solution."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a potential improvement: 'is there existing work that offers a way around (an approximation, for instance) to compute the contribution?' and offers a solution: 'If not, maybe a line or two should be added that there exists no solution for this, and it is an open (hard) problem.' This directly tells the authors what to do and how to address a potential gap. The suggestion is concrete, proposing a search for existing work or stating the absence of a solution.", "grounding_specificity_rationale": "The reviewer refers to 'FFNs' (Fuzzy Functions) and specifically mentions the issue with a 'linear decomposition cannot be obtained'. This clearly identifies a specific part of the paper being addressed. The reviewer also specifies the potential improvement area: 'compute the contribution'. The combination of mentioning FFNs and the specific problem strongly implies a particular section or subsection, thus providing good grounding. The potential improvement area is also clearly defined.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It presents a suggestion ('is there existing work...') and a potential solution ('If not, maybe a line or two should be added...'). There are no statements that require logical reasoning, common knowledge, or external references to be considered valid. The reviewer is offering suggestions and a potential improvement, not making a definitive statement that needs to be proven.", "helpfulness_rationale": "The review point is 5 because it directly addresses a potential weakness in the paper (the omission of a decomposition method for FFNs) and offers a concrete suggestion for improvement: exploring existing work or stating the absence of a solution. This provides the authors with actionable feedback and a clear direction for enhancing their work. The suggestion is practical and directly relevant to the identified issue."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The questions are clear and address a potential issue (the impact of the number of images on performance) and a method (BYOL). However, they don't specify how to carry out the action of determining the impact or explaining BYOL. The questions are openended and lack concrete steps.", "grounding_specificity_rationale": "The review points to 'the cluster structure is defined by the identity' and 'BYOL in the abstract.' This is vague and doesn't pinpoint a specific section, table, figure, or unique element. The questions about the impact of images and the explanation of BYOL are general and don't specify which aspects are relevant.", "verifiability_rationale": "The review contains claims about the potential impact of the number of images and the need to explain BYOL. However, it doesn't provide specific evidence or references to support these claims. The request to explain BYOL is a valid point but doesn't offer any specific examples or citations.", "helpfulness_rationale": "The questions raise a valid concern about the experimental setup and the clarity of the method description. While they don't offer immediate solutions, they point to areas where the author's draft could be improved. The request to explain BYOL is a direct call for more information, which is helpful. The question about the number of images is a valid experimental inquiry."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks 'why does the method work?' regarding the L_pixel component. This is an explicit request for an explanation of the underlying reasoning or mechanism. While the request doesn't specify *how* to implement this explanation, it clearly identifies the action (providing justification) as the desired outcome. Therefore, it is 3 as it points to a specific area needing clarification.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'L_pixel' as the component in question. This is a clear identification of a specific part of the paper. While the reviewer doesn't specify *what* is wrong with L_pixel, they are focusing on this particular component as the area needing further explanation. Therefore, the grounding is fully grounded as the specific component is named. However, the specificity is underspecified as the reviewer doesn't pinpoint a specific issue *within* L_pixel that needs addressing.", "verifiability_rationale": "The reviewer is not making a claim that something is wrong or needs to be changed. Instead, they are asking for an explanation of *why* something works. Therefore, this point does not fall under the verifiability framework, which focuses on claims and supporting evidence. However, for the sake of completeness, if we were to interpret the request as a potential implicit claim (e.g., 'L_pixel is not working well'), the request itself is not verifiable as it is a question, not a statement. But the reviewer's suggestion to provide 'stronger arguments or intuitions' implies they expect a logical and intuitive explanation, which aligns with the concept of verifiability if we infer the claim is 'L_pixel's effectiveness needs better justification'.", "helpfulness_rationale": "The reviewer directly addresses a potential weakness in the paper (the lack of clarity on why the method works, specifically regarding L_pixel) and offers a concrete suggestion for improvement (providing stronger arguments or intuitions). This is a clear and actionable feedback aimed at enhancing the paper. Therefore, the review point is 5 as it directly targets a perceived limitation and offers a specific remedy."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the concern about the sufficiency of 44k dialogues and provides a concrete suggestion to increase the training data to 100k dialogues. This indicates a clear understanding of a potential limitation and a direct proposal for improvement, fitting the definition of high actionability.", "grounding_specificity_rationale": "The reviewer explicitly identifies the issue as being related to the 'amount of training data' and its impact on 'capturing user traits and personalities'. This clear identification of the specific part of the paper being addressed supports full grounding specificity. The reviewer also provides a concrete suggestion to increase the dataset size, further reinforcing the grounding aspect.", "verifiability_rationale": "The reviewer states a belief about the limitations of the 44k dialogue dataset. While they express uncertainty, the core of the point is a claim about the insufficient data. There is no external reference or logical reasoning provided to support this claim. Therefore, it is not 5. It contains a claim but lacks sufficient justification, making it 2.", "helpfulness_rationale": "The reviewer clearly states the problem (potential limitations of 44k dialogues) and proposes a solution (increasing the dataset size). While the concern is valid, the reviewer doesn't explicitly explain *why* 44k is insufficient or *demonstrate* the benefits of 100k. The reasoning is implied but not explicitly stated. Therefore, it is 3 as it points to a potential issue, but lacks a detailed explanation of the problem and the benefits of the suggested solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The binary classification is too highlevel. It doesn't provide specific guidance on *how* to improve. The lack of detail hinders actionability. For example, knowing it's 'incorrect' is less helpful than knowing 'the technique error is in the specific calculation and needs to be refined using a specific technique refinement method.'", "grounding_specificity_rationale": "The binary classification is 1 in the specific error. The review points to the lack of specificity in identifying the *type* of error (technique error). The metric doesn't tell you *where* in the process the error occurred or what specific aspect of the technique is flawed. It's a general assessment, not pinpointing the location of the error within the TAL process.", "verifiability_rationale": "The binary classification lacks sufficient justification. While it states that the classification is correct, it doesn't provide any reasoning or examples to support this claim. The lack of specific evidence makes it difficult to verify the classification. For instance, if the classification is 'incorrect,' the reasoning should explain *why* it's incorrect and provide evidence or references to support this assertion.", "helpfulness_rationale": "The binary classification is not very helpful for guiding improvements. It tells you the model is wrong, but not *how* it's wrong, making it difficult to act upon. The lack of specific feedback limits the ability to refine the model effectively. A more detailed classification would provide actionable insights for model improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states actions or suggestions, such as 'Additionally, there has been a large amount of work on LLM evaluation 2' and 'it would still be good to see how SynTextBench metric compares to the other metrics proposed in the paper.' These statements indicate a desire for the authors to consider this information. However, the comment lacks specific guidance on *how* to approach this comparison or what specific aspects of SynTextBench to focus on. The action is stated, but the implementation details are missing.", "grounding_specificity_rationale": "The comment explicitly refers to 'SynTextBench metric' and 'other metrics proposed in the paper,' indicating a clear identification of the specific aspect of the SynTextBench metric being discussed. Furthermore, it specifically mentions 'LLM evaluation' and requests a 'comparison of SynTextBench with other metrics (eg: say MMLU / Big Bench for language generation).' This provides clear guidance on the type of comparison being suggested, making it highly grounded and specific.", "verifiability_rationale": "The comment contains a claim: 'it would still be good to see how SynTextBench metric compares to the other metrics proposed in the paper.' However, this claim is presented as a suggestion or request for the authors to consider a comparison, rather than a statement that is logically derived or supported by external references. There is no explicit logical reasoning or external evidence provided to justify this suggestion.", "helpfulness_rationale": "The comment provides a suggestion for the authors to consider a comparison of SynTextBench with other metrics. While it doesn't directly tell the authors what to do, it guides them towards a specific area of analysis and provides a concrete example (MMLU/Big Bench) to consider. This provides a direction for the authors to follow, making it 3."}
{"actionability_label": "Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer is asking a question about the *action* of considering only ECG segments with one label assigned. They are seeking the *reason* behind this specific methodological choice. This is an explicit question about the action taken in the paper.", "grounding_specificity_rationale": "The reviewer is asking a question about the paper's methodology. They are trying to *identify* the reason for filtering ECG segments with multiple labels. While the paper *could* potentially provide this information, the reviewer's question suggests it's not explicitly stated or easily inferred. The grounding is weak because the authors don't directly address the *why* of their methodological choice in the paper itself.", "verifiability_rationale": "The reviewer is making a statement about their expectation regarding the difficulty of reports with all reports vs. singlelabel reports. This statement is presented as a claim (an opinion or judgment). However, the paper does not provide any data or justification to support or refute this claim. The reviewer is speculating about the impact of the filtering method, but there is no evidence within the paper to validate this expectation.", "helpfulness_rationale": "The review point is a question seeking clarification on a methodological choice. While it highlights a potential issue with the analysis, it doesn't directly *improve* the draft. It's more of a diagnostic question than a constructive suggestion. It doesn't point to a specific weakness or offer an alternative approach. The reviewer is asking *why* something was done, not *what* was wrong with it."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a weakness ('Limited Discussion of Scalability Bounds') but does not explicitly suggest a specific action or improvement. While it points to areas for improvement ('memory requirements' and 'computational complexity'), it lacks concrete details on how to address them. This makes the action implicit and vague.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being discussed ('FedDES', 'scalability', 'memory requirements', 'computational complexity'). It is a general critique of the discussion on scalability bounds. Therefore, the grounding is weak.", "verifiability_rationale": "The review point itself is not a claim. It is a critique of the paper's discussion. While the reviewer's claim about the paper's limitations is what needs to be verified, the review point itself does not provide evidence or reasoning to support this claim about the paper's content. It is a statement of opinion rather than a factual assertion requiring verification.", "helpfulness_rationale": "The review point identifies a genuine gap in the discussion regarding the scalability of FedDES. It alerts the authors to a potential area for improvement. While it does not provide specific suggestions for improvement, it points to a weakness that needs addressing. Therefore, it is helpful in highlighting an area for further work."}
{"actionability_label": "4", "grounding_specificity_label": "3: 5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that 'NodeSort differentially sorts nodes depending on the base node' and then asks 'Does this mean that the base node affects the ordering, affects the key nodes for attention, and further affects the model performance?'. The reviewer is directly asking about the implications of the stated fact. The reviewer is also asking for clarification on how the base node influences these aspects. The reviewer is not just stating a fact but is asking a question that requires further explanation and understanding of the model's behavior. The reviewer is also implicitly asking for a connection between the differential sorting and the model's performance.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'NodeSort,' 'nodes,' and 'base node' in their review point. This clearly identifies the specific parts of the paper being discussed. The reviewer is also asking about the 'ordering,' 'key nodes for attention,' and 'model performance,' which are specific aspects of the model's behavior. The reviewer is not just stating a general observation but is asking about specific details related to the mentioned concepts.", "verifiability_rationale": "The reviewer is asking a question about the implementation details of 'NodeSort' and its impact on 'ordering,' 'key nodes for attention,' and 'model performance.' This implies a lack of clarity or sufficient explanation in the original text. The reviewer is not making a claim that requires verification but is instead asking for clarification. The absence of explicit details about how the base node affects these aspects makes the reviewer's question verifiable.", "helpfulness_rationale": "The reviewer is asking a question about a specific implementation detail ('NodeSort') and its potential impact on the model's behavior. This is a relevant question for understanding and potentially improving the model. While the question itself doesn't directly provide a solution, it highlights an area that requires further investigation. The reviewer is encouraging the authors to look deeper into the model's inner workings and its performance implications. The question is directly related to the model's implementation and its consequences."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a question about the diagram, specifically why the arrow points in a certain direction. While this prompts an answer, it doesn't directly tell the authors *what* to do with the information. The reviewer is prompting clarification, which is an action, but it's not explicit.", "grounding_specificity_rationale": "The reviewer explicitly points to the arrow in Figure 2 and asks about its connection to the latent space and n^(i). This demonstrates strong grounding specificity as the reviewer can accurately pinpoint the referenced part of the paper and clearly identify the issue being asked about.", "verifiability_rationale": "The reviewer is asking a question about the purpose of an element in a diagram. This can be considered a claim (they are making a statement about the diagram's intended function). The verifiability depends on whether the paper adequately explains the diagram. While the paper should explain the diagram, the reviewer's question implies a lack of clarity, making it 3.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific detail in a diagram. While it doesn't directly point out a flaw, it's highly likely the lack of clarity hinders understanding and potentially the implementation of the method. Therefore, it's 3 in identifying a potential point of confusion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that 'AR' stands for 'domain adaptation tasks and algorithms'. This provides a clear action for the authors to take when interpreting 'AR' in Table 5. The reviewer also provides a concrete definition of 'AR', making it clear what is being referenced.", "grounding_specificity_rationale": "The reviewer explicitly identifies the abbreviation 'AR' as the part of the paper being addressed in Table 5. The reviewer also clearly specifies what 'AR' stands for in this context ('domain adaptation tasks and algorithms').", "verifiability_rationale": "The reviewer does not make a claim. However, the information provided about the meaning of 'AR' could be considered verifiable if the authors independently looked up the term. The reviewer's point is about the lack of this information, not the verifiability of the information itself.", "helpfulness_rationale": "The reviewer provides a clear definition of the abbreviation 'AR', which directly addresses the issue raised by the lack of definition. This directly helps the authors understand Table 5 better."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about a technical difference between two methods (advantage vs. qvalue) but does not explicitly state an action or suggestion for the author. While it implies that the author should understand the difference, it doesn't provide a concrete step to take or improve their work.", "grounding_specificity_rationale": "The review point refers to 'advantage' and 'q value' without specifying which part of the paper or method it is addressing. It does not clearly identify what is wrong with using advantage instead of qvalue or why one might be preferred. The grounding is weak as the specific section or element is not mentioned.", "verifiability_rationale": "The review point does not contain a claim in the sense of criticizing or suggesting an improvement. It is a question about a technical detail. Therefore, it does not have verifiability in the context of improving the paper.", "helpfulness_rationale": "The review point is a question about a technical detail and does not directly identify a weakness in the author's work or suggest a concrete improvement. While understanding the difference might be helpful for the author's methodological choices, it doesn't directly empower them to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states that VINS uses different sample weights while most compared baselines use a weight of 1. This is an explicit statement of a difference in implementation. However, the review point does not provide specific guidance on how to address this difference or what aspects of the weights are different. Therefore, while the action is identified, it is not concrete enough to be fully actionable.", "grounding_specificity_rationale": "The review point refers to the performance comparison in Table 1 but does not explicitly identify which specific part of the paper or experiment this comparison relates to. While the comparison is implied to be between the methods in Table 1, the specific section, table, or figure being discussed is not mentioned. Therefore, the grounding is weak as the authors need to infer the target of the comparison.", "verifiability_rationale": "The review point makes a claim that the performance comparison in Table 1 is unfair due to different sample weights. However, it does not provide any evidence, logical reasoning, or external references to support this claim. The statement is presented as a fact without justification.", "helpfulness_rationale": "The review point identifies a potential issue with the experimental setup (unfair comparison in Table 1) but does not offer any suggestions or actions for the authors. It points out a problem without providing a solution or direction for improvement. Therefore, it is not helpful in guiding the authors to address the identified issue."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a statement of a potential problem (high time complexity) without providing any specific instructions or guidance on how to address it. It identifies a * issue but lacks a *howto.", "grounding_specificity_rationale": "The review point includes a specific citation (1 PRMRL...). This allows the authors to identify the paper. However, the statement itself is general about the reply buffer.", "verifiability_rationale": "The review point is a statement of a potential issue without any supporting evidence, logical reasoning, or references. It's an observation, not a claim requiring verification.", "helpfulness_rationale": "The review point identifies a problem but offers no solutions or actionable steps. It's a negative observation without any constructive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests an action: 'involving some other baselines'. This action is further elaborated with specific methods: 'optimizing the discretization schedule' and 'modifying the original SGM formulation'. These are concrete steps the authors can take to improve their experimental results.", "grounding_specificity_rationale": "The review point provides explicit actions for the authors to take: 'involving some other baselines', 'optimizing the discretization schedule', and 'modifying the original SGM formulation'. Furthermore, it names specific techniques within these actions, such as 'optimizing the discretization schedule' and 'modifying the original SGM formulation', and even provides a list of relevant papers 16, 15, 23, 36, 31, 37, 20, 10, 25, 35, 45 as examples of such baselines. This strong emphasis on specific actions and examples makes it highly grounded.", "verifiability_rationale": "The review point itself does not make a claim that this approach is better. It is a suggestion for improvement, not a statement of what the authors should do. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The review point directly addresses a common challenge faced by authors: the effective presentation of experimental results. It provides concrete suggestions on how authors can improve their performance analysis by including additional baselines and exploring different aspects of their SGM implementation. This directly empowers the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their suggestion to compare the proposed framework with a method defending against multiple attacks. This constitutes an explicit action that is directly actionable for the authors, guiding them on what kind of comparison to include. The action is also somewhat concrete as it specifies the *type* of attack defense the comparison should focus on. However, it lacks specific details about which method to compare with.", "grounding_specificity_rationale": "The reviewer mentions 'a method that is designed to defend against multiple attacks.' While they identify a category of methods, they don't specify a particular method or detail what aspects of the proposed framework or the future method should be compared. This makes the grounding somewhat weak as the authors can only infer the relevance of the comparison.", "verifiability_rationale": "The reviewer's suggestion is about future research and doesn't present a specific claim that requires verification within the current paper. It's a suggestion for improvement rather than a critique of an existing aspect. Therefore, it doesn't have verifiability in the sense of pointing out a flaw that needs justification.", "helpfulness_rationale": "The reviewer's suggestion to compare with a method defending against multiple attacks is a valuable point that would enhance the paper's positioning and impact. It directly addresses a potential weakness in the current comparison. However, the lack of specific grounding makes the helpfulness somewhat limited as the authors don't know exactly what to look for in this new comparison."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer is explicitly asking for a definition of a specific term (\tau_i^l) which is crucial for understanding the 'timewarp function'. This is a direct request for information about a specific aspect of the method. The request is clear and directly addresses the missing information. Therefore, it is actionable.", "grounding_specificity_rationale": "The reviewer is asking for a definition of a specific term (\tau_i^l) which is part of the 'timewarp function'. The reviewer is indicating that this term is important for understanding the function. The request directly targets the definition of this specific term, implying the reviewer has identified the relevant part of the paper and is asking for a specific detail within it. Therefore, the grounding is fully specific as the reviewer is asking for the definition of a specific element within a specific section of the paper.", "verifiability_rationale": "The request is not a claim. It is a request for information about a specific term. Therefore, it does not fall under the category of verifiability.", "helpfulness_rationale": "The reviewer is asking for a definition of a specific term (\tau_i^l) that is crucial for understanding the 'timewarp function'. This is a direct and actionable request for information about a specific technical detail. The information will help the authors clarify their work and potentially improve it by understanding this crucial parameter. The request is specific and directly relevant to the technical aspects of the paper. Therefore, it is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a problem (low efficiency) with pairwise matching but does not explicitly state what action or improvement should be taken. While it points out the issue, it lacks concrete steps on how to address it.", "grounding_specificity_rationale": "The review point refers to 'pairwise matching' generally and does not specify which part of the paper it is addressing. It lacks precision in identifying the exact area of concern.", "verifiability_rationale": "The review point makes a claim about the low efficiency of pairwise matching but does not provide any evidence, justification, or references to support this claim. It states the problem without backing it up.", "helpfulness_rationale": "The review point identifies a practical limitation (low efficiency) and suggests the need for improvement. While it points in a direction, it doesn't offer specific, actionable advice on how to achieve this improvement, making it 3 but lacking detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a weakness (' allocation of Figure 1 is too naive') and suggests an improvement ('Overall, you could have edited the space of main paper more wisely'). However, the suggested improvement is vague and doesn't explicitly state what needs to be done to reallocate the space. The action is implied rather than explicitly stated and detailed.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1' as the part of the paper being addressed. While it doesn't specify a unique element within Figure 1, the mention of a specific figure indicates a degree of grounding. The reviewer is general about the issue with Figure 1, but the reference to the figure itself grounds the comment to a specific part of the paper.", "verifiability_rationale": "The comment contains a claim: ' allocation of Figure 1 is too naive' and 'you could have edited the space of main paper more wisely'. The claim ' allocation of Figure 1 is too naive' is supported by the suggestion to 'edits the main paper space more wisely', implying that the current allocation is indeed a problem. While it lacks specific examples or external references, the suggestion acts as implicit justification.", "helpfulness_rationale": "The comment identifies a potential weakness (' allocation of Figure 1 is too naive') and suggests a direction for improvement ('edits the main paper space more wisely'). However, the suggestion is vague and doesn't provide specific steps on how to reallocate the space. The reviewer offers a general direction but lacks the concrete details needed for the author to act upon. The comment is helpful in pointing towards a potential area for improvement but lacks the necessary specificity for actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the action needed: rewrite the first sentence of the abstract.", "grounding_specificity_rationale": "The comment directly and accurately identifies the specific part of the paper: 'the first sentence of the abstract.'", "verifiability_rationale": "The comment makes a judgment about the quality of the writing in the abstract but does not present a claim that requires verification or support.", "helpfulness_rationale": "The comment identifies a weakness and suggests an action, making it 3 as it prompts the author to address the issue. However, it lacks specific guidance on *how* or *why*."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states 'Adding a method on the top of other methods to improve transferability'. This directly identifies an action the authors should take. However, the comment does not provide details on *how* to implement this action, making it only partially actionable.", "grounding_specificity_rationale": "The comment does not specify which part of the paper is being addressed when suggesting the addition of a method. It refers to 'adding a method' generally without pointing to a specific section, table, figure, or unique element. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The comment makes a judgment about the 'goodness' of adding a method and its 'significance' as a contribution. However, it does not provide any evidence or reasoning to support this judgment. The claim is made without sufficient justification or references.", "helpfulness_rationale": "The comment suggests adding a method to improve transferability, which is a relevant point. However, it lacks specific details about *which* method, *where* to add it, or *how* it would be implemented. This lack of specificity makes the suggestion vague and difficult for the authors to act upon, thus reducing its helpfulness."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states that it is not clear what the challenges are when analyzing Adam under (L0,L1)smoothness. They are pointing to a missing explanation or action for the authors.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific section or table. Instead, they imply that the relevant part is the (L0,L1)smoothness analysis and highlight the lack of explanation regarding the challenges. The comment is vague about what needs to be addressed in this part.", "verifiability_rationale": "The reviewer makes a claim: 'one can directly apply standard analysis on the (L0,L1)smoothness condition.' They then provide a reason why this might be incorrect, referencing the work of Zhang et al. This claim is supported by logical reasoning and references.", "helpfulness_rationale": "The reviewer's point, if addressed, would be 5 for the authors trying to understand the challenges of analyzing Adam under (L0,L1)smoothness and the differences with Zhang et al.'s work."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the two types of methods (based on pedestrian detector and endtoend) and mentions a potential gap in combining detection and reID. This is an explicit statement of what is known about the field. While it doesn't directly tell the authors what to do, it sets the context for a discussion.", "grounding_specificity_rationale": "The review point explicitly mentions 'person reID methods' and 'pedestrian detector' as the basis for twostep methods. It also mentions 'endtoend method' and 'combines detection and reID'. This strong grounding as it accurately identifies the specific parts of the paper (or field) being discussed. It specifies the nature of the two approaches.", "verifiability_rationale": "The review point makes a statement about the current state of person reID methods and points out a potential gap in combining detection and reID. This can be considered a claim that there are methods building on pedestrian detectors and endtoend methods. This claim is verifiable based on common knowledge in the field of person reidentification. While it doesn't provide specific citations, the claim is generally supported by established knowledge.", "helpfulness_rationale": "The review point provides context about the current landscape of person reID methods and suggests a potential area for improvement. While it is helpful in guiding research directions, it doesn't directly provide actionable steps for improving a specific draft. It's a general observation rather than a direct critique or suggestion of concrete changes."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of 'adding a first sentence' and clearly indicates where this addition should occur in the paper. There's no ambiguity about the action or how to implement it.", "grounding_specificity_rationale": "The review point directly references 'Section 3.2', providing a precise location in the paper where the suggested change should be made. This is a fully grounded comment.", "verifiability_rationale": "The review point is a suggestion, not a claim that something is wrong or needs fixing. Therefore, it doesn't require verification.", "helpfulness_rationale": "The review point identifies a potential weakness (lack of introduction) and offers a clear, concrete solution (adding a first sentence). This is a 5 and constructive comment for the author."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment 'Line 44: What is meant by the initial rationale selector is perfect?' identifies a potential issue but lacks a specific action or suggestion. While it points to a problem with the rationale selector, it doesn't tell the author what to do. It's a question rather than a directive, making it less actionable than a comment that says 'Check section 3.2 and remove the circular logic'.", "grounding_specificity_rationale": "The comment 'Line 44: What is meant by the initial rationale selector is perfect?' identifies the 'initial rationale selector' as a specific part of the paper. However, it does not specify what is meant by 'perfect' or what issues might be present. The grounding is explicit (it names the selector), but the specificity is lacking as it doesn't detail the problem.", "verifiability_rationale": "The comment 'Line 44: What is meant by the initial rationale selector is perfect?' is not a claim that requires verification. It's a question posed about a component of the paper. Therefore, it doesn't fit into the verifiability categories which focus on statements that need to be supported by evidence or reasoning.", "helpfulness_rationale": "The comment 'Line 44: What is meant by the initial rationale selector is perfect?' raises a valid concern about the rationale selector. However, it doesn't provide specific guidance or suggestions on how to address the issue. It's a question that highlights a potential area for improvement but doesn't offer concrete steps, making it 3 but lacking in actionable detail."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a potential missing detail (experiments with ontologies) and asks for clarification on a specific aspect (Line 211). This implies an action the authors should take (investigate or clarify), making it actionable.", "grounding_specificity_rationale": "The review point directly references 'Line 211', which is a specific section in the paper. It also asks for specific information ('how many questions' and 'accuracy of this system'), indicating a clear understanding of where the information should be found and what it should include.", "verifiability_rationale": "The review point is based on the assumption that information about the number of questions and the accuracy of the zeroshot intent classifier exists at 'Line 211'. However, the paper does not currently provide this information, making the claim 1 at this point.", "helpfulness_rationale": "The review point is helpful in that it directly points to a specific location (Line 211) and asks for specific, actionable information ('how many questions' and 'accuracy of this system'). This guides the authors to the relevant details and highlights a missing piece of information."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states \"Missing some citations\", which is an explicit action. However, it doesn't specify the exact missing citation or section, making it vague on the concrete action to be taken.", "grounding_specificity_rationale": "The review point identifies the area where citations are missing (recent MARL work, selfplay, population play). This provides grounding. However, it doesn't specify a particular section, table, figure, or unique element within that area where the missing citation is needed, making it underspecific about the exact location of the missing information.", "verifiability_rationale": "The review point contains a claim about missing citations and identifies the area where these are needed. However, it doesn't provide specific examples of missing citations or direct references to external works at this point, making the claim somewhat 1 at this stage.", "helpfulness_rationale": "The review point directly addresses a common issue for researchers \u2013 the need for proper context and referencing. It prompts the authors to look for recent work in the areas of selfplay and population play, making it a valuable and actionable suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification on the 'abstention process' and 'prediction probability threshold'. While the request is explicit in asking for a definition, it lacks the concrete details of how the abstention process works and how it differs from a decision threshold. The specifics are missing, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer is asking about the 'abstention process' and 'prediction probability threshold' in general, without specifying which part of the paper or model these terms refer to. The grounding is weak as the authors cannot confidently determine which aspect the comment addresses.", "verifiability_rationale": "The review point is a request for clarification on a process and threshold, not a statement of opinion, judgment, or suggestion. Therefore, it does not contain a claim and is classified as 'X' (X).", "helpfulness_rationale": "The reviewer is asking for clarification on a crucial aspect of their work (the abstention process). Understanding this process is likely to improve their model's performance. While it's a request for information, it's information that is likely to be helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a weakness: \"lack of meaningful baselines\" and proposes a specific action to address this: \"comparing with a chainofthought prompting approach\". This directly points to an actionable recommendation.", "grounding_specificity_rationale": "The review point mentions \"various model criticism techniques\" in Section 2. However, it doesn't specify *which* technique or *where* in Section 2 this lack of baselines is a problem. The suggestion to compare with \"chainofthought prompting\" is a general improvement suggestion, not a specific reference to a part of the paper. Therefore, the grounding is weak. The reviewer's comment is weakly grounded. They identify a problem but don't clearly link it to a specific part of the paper or technique. The suggestion is general and doesn't target a specific part of the paper or technique.", "verifiability_rationale": "The review point states a claim: \"the authors limit their comparisons to simple naive baselines.\" This claim is not explicitly supported by evidence *within this review point*. They are making an assertion about the authors' choices. However, the suggested comparison with \"chainofthought prompting\" is a verifiable suggestion as chainofthought is a known technique. Therefore, the claim is partially verifiable. The reviewer's comment is partially verifiable. The claim about \"meaningful baselines\" is stated but not explicitly supported by evidence or justification within this review point. However, the suggested comparison is verifiable.", "helpfulness_rationale": "The review point clearly identifies a weakness in the experimental setup (lack of strong baselines) and provides a concrete suggestion to address it. The suggestion is specific and actionable. This is a valuable piece of feedback for the authors. The reviewer directly points out a limitation in the authors' work and offers a clear, specific improvement. This is a valuable piece of feedback for the authors. The reviewer directly points out a limitation in the authors' work and offers a clear, specific improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point implicitly raises a potential issue regarding the generalization of the model trained on the entire dataset to a setting without labels. While it doesn't explicitly state an action, the question implies a desire to understand the model's behavior in a coldstart scenario, which is a relevant concern for authors. However, the reviewer doesn't provide concrete steps on how to address this issue, making it partially actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'the entire dataset' and 'generalize to setting where you don\u2019t have the associated labels.' This clearly identifies the specific aspect of the paper being addressed and the issue being raised. The grounding is strong as the parts of the paper are explicitly mentioned.", "verifiability_rationale": "The review point poses a question rather than making a declarative claim. While it raises a valid concern about the generalization of a model trained on the entire dataset, it doesn't provide any evidence or references to support its assertion. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point raises a pertinent question about a potential limitation of the model (generalization to a coldstart scenario) and suggests a potential area for improvement (pretraining on the entire dataset). This points to a specific area where the authors could benefit from further investigation or clarification. While it doesn't provide a definitive answer, it highlights a relevant concern and encourages the authors to consider the implications of their training data. Therefore, it is helpful in guiding the authors towards a more thorough evaluation of their model."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "N/A", "helpfulness_label": "3", "actionability_rationale": "The review point states a fact about hardware and software dependence but does not provide explicit or implicit instructions on how the authors should act upon this observation. It lacks concrete steps or guidance on what changes are needed.", "grounding_specificity_rationale": "The review point is a general statement about a potential issue and does not specify which part of the paper or any unique element is being addressed. It lacks grounding to a specific section, table, figure, or unique aspect.", "verifiability_rationale": "The review point is a statement of fact, not a claim that requires verification. Therefore, it does not fall under the scope of verifiability. It also does not fall under the category of 'X' as it provides information.", "helpfulness_rationale": "The review point identifies a potential limitation of the work (potential hardware/software dependence) and suggests considering this as a positive step. While it doesn't directly instruct the authors on how to improve their draft, it provides context and a potential avenue for future work, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer is questioning the significance of the ablation study's results, not suggesting a specific action to improve the model. The comment is a question rather than a directive. Therefore, the actionability is low as the authors are not guided on what to do.", "grounding_specificity_rationale": "The reviewer's comment is a general question about the overall significance of the ablation study results, not specifically pointing to a particular section, table, or figure. The grounding is weak because the authors cannot confidently determine the referenced part. The comment specifies what needs to be addressed (significance of the ablation) but doesn't identify the part being addressed. This fits the '4' category.", "verifiability_rationale": "The reviewer is raising a question about the interpretation of the results, not making a claim that requires verification. There is no explicit claim being made, so the verifiability score is based on the 'X' category, which is labeled as 'X'.", "helpfulness_rationale": "The reviewer's comment is a question about the significance of the ablation study, not a suggestion for improvement. It does not offer actionable feedback or guidance to the authors. Therefore, it is not helpful in guiding the authors to improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out the absence of experimental details in the Appendix and criticizes the lack of explanations there. While the reviewer doesn't explicitly state 'Add PCA details to the main text,' the general sentiment implies a need for more information in the main body. The action is present but implicit.", "grounding_specificity_rationale": "The reviewer specifically mentions 'experimental details' and then narrows it down to 'PCA experiments in Figures 3, 7, and 8.' This precise identification of the location and type of missing information demonstrates strong grounding. The reviewer can confidently pinpoint the referenced part of the paper.", "verifiability_rationale": "The reviewer states 'The Appendix has too much' and 'the Appendix also includes almost no explanations or interpretations.' These statements are claims that the Appendix is problematic. However, the reviewer does not provide any logical reasoning, examples, or external references to support these claims. The claims are presented without sufficient backing.", "helpfulness_rationale": "The reviewer's point about the Appendix being too much and lacking explanations is relevant to the authors' experience. However, the suggestion to 'improve the Appendix' is quite general and lacks specific details on how to achieve this. The reviewer identifies a potential issue but doesn't offer a concrete, actionable improvement strategy."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'No new evaluation metrics are proposed. Only existing evaluation metrics are proposed.' This is a clear and direct statement of what the reviewer is suggesting, making it 5. The action is to focus on existing metrics, and the method is clear.", "grounding_specificity_rationale": "The comment refers to 'evaluation metrics' in general. While it mentions 'new' and 'existing,' it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper it is addressing. The grounding is somewhat general. The authors would need to infer the focus is on the evaluation section. However, the comment clearly identifies the area of improvement: 'not proposing new evaluation metrics.'", "verifiability_rationale": "The comment contains a claim: 'No new evaluation metrics are proposed. Only existing evaluation metrics are proposed.' This is a statement of intent or a suggestion. However, the comment does not provide any justification or examples to support this claim within the review point itself. The verifiability relies on external knowledge or examination of the paper's evaluation section, which is not within the scope of this single review point. The claim is presented without any supporting evidence.", "helpfulness_rationale": "The comment offers a constructive suggestion to focus on existing evaluation metrics and avoid proposing new ones. This is a helpful point for the authors, prompting them to consider the scope of their evaluation. While it doesn't directly critique a specific section of the paper being reviewed, it provides a valuable perspective on their evaluation process, guiding them towards a more focused approach."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly points out the *problem* (abuse of notation) and the *suggestion* (use different notation). While the suggestion isn't fully concrete in specifying the correct notation, the reviewer clearly identifies the conflicting uses of 'K'. This indicates a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'notation K' generally, mentioning its use in 'a known kernel function' and 'the number of layers.' While they identify the *concept* of the abuse, they don't pinpoint a specific instance or section where this occurs. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a clear claim: 'the notation K is abused too...'. They also provide a justification for this claim by stating that 'it could lead to confusion for readers'. This justification, while not a rigorous citation, provides a logical reasoning for the issue, making it 3.", "helpfulness_rationale": "The reviewer clearly identifies a weakness ('the notation K is abused too') and provides a direct suggestion for improvement ('use different notation'). This actionable feedback is helpful for the authors to understand a potential source of confusion and improve their clarity."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out that the connection between human cognition and the CPR model is unclear and that the authors' statement about the influence of cognitively basic mechanisms and CPR structure on selforganization is also unclear. While the reviewer doesn't explicitly state what action should be taken, they imply a need for clarification and more context. The action is implicit, making it 2.", "grounding_specificity_rationale": "The reviewer attempts to ground the comment by mentioning 'cognitively basic adaptation mechanisms' and 'structure of the CPR itself.' However, they do not explicitly point to a specific section, table, or figure in the paper. The grounding is implied, making it weakly grounded. While the reviewer does identify specific parts of the paper they are referring to, the degree of clarity and the request for more citations indicates it is not specific.", "verifiability_rationale": "The reviewer makes a clear claim that the authors' statement about the influence of cognitively basic mechanisms and CPR structure is unclear and that behavioral economists would likely ignore these factors. However, the reviewer does not provide any specific evidence or reasoning to support this claim. The statement is presented as a question for the authors, not a statement that can be independently verified.", "helpfulness_rationale": "The reviewer's comment is primarily a request for clarification and more context regarding the connection to human cognition and the influence of bargaining mechanisms. While the feedback is relevant, it does not directly identify a specific flaw or missing element in the authors' work. The reviewer is suggesting a potential area for improvement in how the authors frame their work and relate it to existing literature, but they do not provide concrete suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the sentence '... our pioneering contributions herald a new era in robotic adaptability ...' is exaggerated and that the word choice is 'bit flamboyant'. This directly points to a specific issue within a defined part of the paper (the conclusion). The reviewer provides a clear action, identifying the sentence and its problematic nature. The action is also concrete, as the reviewer specifies *which* sentence and *what* is wrong with it.", "grounding_specificity_rationale": "The reviewer not only points out that the wording is exaggerated but also specifically identifies the sentence in the conclusion where this occurs. They state, '... the conclusion: \"... our pioneering contributions herald a new era in robotic adaptability ...\"'. This demonstrates a strong grounding as the reviewer accurately pinpoints the section being addressed. Furthermore, they specify that the *word choice* in this sentence is the issue, making the specificity high.", "verifiability_rationale": "The reviewer makes a claim about the writing style in the conclusion being 'overly exaggerated' and 'word choice is a bit flamboyant'. While they don't provide external references to support this claim, they offer a logical assessment based on their own reading. The claim is somewhat justified as the reviewer provides a reason for their judgment (word choice being flamboyant) and points to a specific area (the conclusion). However, without concrete examples or citations, the verifiability is not fully established.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement. They identify a specific sentence in the conclusion that suffers from 'overly exaggerated' wording and 'bit flamboyant' word choice. This is 5 because the reviewer not only points out the issue but also specifies *where* it is located in the paper. The suggestion is also 3 because the reviewer offers a logical assessment of the word choice, even if it lacks external references. This level of detail and specificity makes the feedback very helpful for the authors to understand and improve their writing."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point requests an ablation study, which can be seen as an explicit action. However, the specifics of the ablation are not provided, making it vague on how to execute it. The reviewer suggests comparing the proposed method with TubeR in terms of learnable parameters and GFLOPs, but the exact components or layers to ablate are not specified. This lack of detail makes the action vague and leaves the authors without clear guidance on how to apply it.", "grounding_specificity_rationale": "The review point requests an ablation study to compare the proposed method with TubeR. While the paper and the comparison are specific parts of the paper, the reviewer does not explicitly identify the unique elements of the paper being addressed. The request is general and doesn't pinpoint a specific section, table, figure, or unique aspect beyond the comparison itself. Therefore, the grounding is weak as the authors need to infer the target part from the request.", "verifiability_rationale": "The review point requests an ablation study to compare the proposed method with TubeR. While the reviewer identifies a weakness (the lack of ablation experiments) and suggests a comparison, there is no explicit claim or suggestion that is supported by logical reasoning, common knowledge, or external references. The request itself is the content being evaluated for verifiability.", "helpfulness_rationale": "The review point identifies a potential weakness in the authors' draft \u2013 the absence of ablation experiments for comparing the proposed method with TubeR in terms of learnable parameters and GFLOPs. This is a relevant suggestion as ablation studies are a standard practice for understanding the contribution of different components of a method and for comparing its efficiency with other approaches. However, the review point lacks specificity. It does not provide concrete guidance on *which* aspects of the method to ablate, *how* to perform the ablation, or *why* these comparisons are crucial for the authors' work. Without this additional information, the reviewer's suggestion, while potentially helpful, remains vague and lacks actionable steps."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states what is missing: 'How are historical observations combined with inputs known over all time given differences in sequence lengths (L vs L+M)? The text mentions separate embedding and addition with positional encoding, but clarifications on how the embeddings are combined and fed into the CSCM are needed.' The reviewer clearly identifies the missing action: explaining the combination and feeding mechanism. They also state that this action is needed to understand the method. Therefore, the reviewer has identified a clear and actionable gap in the paper.", "grounding_specificity_rationale": "The reviewer states: 'How are historical observations combined with inputs known over all time given differences in sequence lengths (L vs L+M)? The text mentions separate embedding and addition with positional encoding, but clarifications on how the embeddings are combined and fed into the CSCM are needed.' The reviewer identifies the specific part of the paper being addressed: 'how embeddings are combined and fed into the CSCM'. However, the paper does not explicitly state this. The reviewer has to infer this missing information from the description of separate embeddings and addition. Therefore, the grounding is weak because the exact location is not explicitly mentioned.", "verifiability_rationale": "The reviewer states: 'How are historical observations combined with inputs known over all time given differences in sequence lengths (L vs L+M)? The text mentions separate embedding and addition with positional encoding, but clarifications on how the embeddings are combined and fed into the CSCM are needed.' The reviewer identifies a claim in the paper: 'The paper should explain how the embeddings are combined and fed into the CSCM'. The paper provides the individual steps (separate embedding and addition) but lacks the explicit connection between them and the final input to the CSCM. This information could be provided through logical reasoning, examples, or references. Therefore, the claim is verifiable but could benefit from more explicit support.", "helpfulness_rationale": "The reviewer states: 'How are historical observations combined with inputs known over all time given differences in sequence lengths (L vs L+M)? The text mentions separate embedding and addition with positional encoding, but clarifications on how the embeddings are combined and fed into the CSCM are needed.' This is a very specific and important technical detail for understanding the method. The reviewer clearly explains what is missing and why it is crucial for understanding how the method works. The paper's lack of clarity in this area hinders the reader's ability to fully grasp the proposed approach. Therefore, this is 5 feedback."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about a potential issue (oversmoothing) with a specific technique (similarityaware positive sample selection). It *doesn't* explicitly state what the reviewer *wants* to do. The concern is presented as a problem, not a direct instruction for the authors to fix it.", "grounding_specificity_rationale": "The reviewer mentions 'similarityaware positive sample selection\" and \"GNNbased encoder oversmoothing\" as potential issues. They also suggest 'same dataset\" and \"perturbation noise\" as potential problems. While the *terms* are specific, the *reviewer's* understanding of *how* these factors relate to oversmoothing or generalization is not detailed. The connection between these concepts is implied but not explicitly stated in terms of *which* part of the model or process is being affected.", "verifiability_rationale": "The reviewer raises concerns about the *mechanism* of positive sample selection and its impact on *generalization performance*. They don't provide any specific examples, citations, or logical reasoning to support these claims. The statement is presented as a hypothesis or concern.", "helpfulness_rationale": "The reviewer's comment is focused on potential limitations and concerns regarding the proposed method and its generalization. While it identifies a potential issue, it doesn't offer any suggestions or insights on how to address it. The feedback is primarily negative, focusing on potential problems rather than offering constructive improvement."}
{"actionability_label": "3", "grounding_specificity_label": "X", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a direct question about the expressiveness of fast SMP compared to SMP. While it doesn't explicitly state an action to be taken, the question itself is a clear instruction that the authors should consider this specific aspect of their model. The phrasing 'I wish to have seen more discussion on the power of different architectures' further implies an actionable suggestion for the authors to explore this topic more thoroughly. Therefore, while the point isn't a direct instruction on how to answer the question, it is a clear prompt for the authors to engage with a specific technical detail.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or model. It is a general question about the expressiveness of different architectures. Therefore, it lacks grounding in a particular aspect of the work.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. It is a question and a desire for more discussion, not a statement that needs to be proven or justified. Therefore, it doesn't present any information that would need to be supported by evidence or references.", "helpfulness_rationale": "The review point directly asks a question about a specific technical aspect (the expressiveness of fast SMP compared to SMP) and encourages more discussion on the power of different architectures. This directly points to a valuable area for improvement in the authors' understanding and potentially their model. While it doesn't provide a direct solution, it identifies a specific area for further exploration and analysis, which is a helpful piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a lack of clarity regarding 'the types of situations/social norms' in the main paper. While it points out a problem, it doesn't explicitly state what action the authors should take to address it. The reviewer is implicitly suggesting that this lack of clarity is a weakness, but doesn't provide a concrete step for improvement.", "grounding_specificity_rationale": "The review point refers to 'the main paper' generally, without specifying a particular section, table, figure, or unique element. The reviewer is making a general observation about the clarity of information within the paper, but doesn't pinpoint the exact location of the issue.", "verifiability_rationale": "The review point makes a claim: 'The types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper.' This is a statement of a problem or deficiency. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. The claim is presented as a fact without justification.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper by highlighting the lack of clarity regarding 'the types of situations/social norms'. This observation could be helpful for the authors to identify areas for improvement and further discussion. However, the review point itself does not offer a concrete solution or actionable steps for the authors to take to address this weakness."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"I expect more baselines\" and \"more domains\", which are direct requests for action. However, the reviewer does not specify *how* these baselines or domains should be different or what specific improvements are anticipated. The lack of detail makes it less concrete. The reviewer also states \"As I mentioned, the choices of the weighting and the way of learning density functions are not strongly motivated.\" This implies a desire for more specific and welljustified choices, but the current choices are not clearly defined or explained in the context of this review point. Therefore, while the reviewer points to specific areas for improvement, the lack of concrete details makes the action somewhat vague and less actionable.", "grounding_specificity_rationale": "The reviewer refers to \"more baselines\" and \"more domains,\" which could be interpreted as implicitly referring to specific aspects of the paper being reviewed that could benefit from additional analysis or comparison. However, the reviewer does not explicitly identify a specific section, table, figure, or unique element of the paper being addressed. The reviewer is making a general request for more data or analysis across different domains, rather than pinpointing a specific part of the paper that needs improvement. Therefore, the grounding is weak as the reviewer cannot confidently determine which part of the paper they are addressing.", "verifiability_rationale": "The reviewer states a claim: \"the choices of the weighting and the way of learning density functions are not strongly motivated.\" This is a statement of a perceived weakness or lack of justification. However, the reviewer does not provide specific examples or references to support this claim. The reasoning behind the current choices is not explicitly stated or justified in this review point. Therefore, the claim is present, but the supporting evidence is lacking, making it only partially verifiable.", "helpfulness_rationale": "The reviewer states \"I expect more baselines to be compared and more domains to be tested. As I mentioned, the choices of the weighting and the way of learning density functions are not strongly motivated. In this case, I have to ask for stronger empirical results: baselines with other design choices and more domains.\" This clearly states a desire for more and different improvements. The reviewer explicitly mentions the lack of motivation for the current choices and requests stronger empirical results, indicating a clear need and a desire for improvement. The reviewer's statement directly implies the value of the feedback and the need for action. Therefore, the feedback is clearly helpful."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a concern about the significance of the results, which implies a desire for improvement, but it does not explicitly state what needs to be changed or how to achieve it. The criticism is broad and lacks specific action. Therefore, it is 2 as it points towards improvement but lacks specific steps.", "grounding_specificity_rationale": "The review point is a general statement about the overall significance of the results and does not specify which part of the paper or element is affected. It lacks any reference to a specific section, table, figure, or unique aspect of the paper. Therefore, it is 1 as it does not identify a specific area of concern.", "verifiability_rationale": "The review point is a critique of the research direction and its significance, not a claim that can be verified with evidence or logical reasoning. It does not contain a statement that requires justification or support. Therefore, it contains X and is not verifiable.", "helpfulness_rationale": "The review point is critical and does not offer any specific feedback or suggestions on the content of the paper. It focuses on the overall significance of the results rather than providing actionable improvements to the paper itself. Therefore, it is not helpful as it does not provide concrete feedback on the paper's content."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states the paper is 'limited' and 'straightforward,' which are somewhat vague and don't provide explicit actions or suggestions. While they mention 'transposition of DeCorr's insights' and 'different datasets and backbones,' these are specific elements, but the overall assessment of 'novelty' lacks a clear direction. The lack of a concrete, actionable suggestion for improvement makes it less actionable.", "grounding_specificity_rationale": "The reviewer's comment is a general statement about the paper's limited novelty and lack of unique insights in recommender systems. They do not explicitly point to a specific section, table, figure, or unique element of the paper as being the core issue. The comment is broad and doesn't provide a clear reference point.", "verifiability_rationale": "The reviewer claims the paper is 'limited' and has 'no enough insights about what are unique challenges of overcorrelation in recommender systems.' This is a claim that needs to be supported. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to back up these claims. The statement is presented as an assertion without evidence.", "helpfulness_rationale": "The reviewer's comment is primarily critical, stating that the paper is 'limited' and lacks 'insights.' While they identify a potential area for improvement ('unique challenges of overcorrelation in recommender systems'), they do not offer any concrete suggestions or actionable steps for the authors to take. The feedback is primarily a critique without constructive alternatives, making it less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states a limitation: 'the results of the paper could be restrictive.' This clearly indicates an actionable suggestion for improvement. While it doesn't provide a stepbystep guide, it points towards a concrete action: 'Consider including Matern kernels in your analysis.'", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the spectrum of a kernel' and specifically 'Matern kernels'. This demonstrates a clear identification of a specific aspect of the paper, making it weakly grounded. Furthermore, the reviewer explains why Matern kernels are relevant by stating, 'However, another popular class of kernels such as Matern kernels are not included, since their spectrum only decay polynomially.' This adds specificity to the point, making it somewhat specific.", "verifiability_rationale": "The reviewer presents a point with implicit verification. They state that 'the spectrum of a kernel' and then provide context by saying 'the popular Gaussian kernels are in this class' and 'Matern kernels are not included, since their spectrum only decay polynomially.' While they don't explicitly state that Gaussian kernels are subgaussian, this is a generally known property. The connection between the spectrum and the restrictiveness of the results is implied but not explicitly verified with a citation.", "helpfulness_rationale": "The review point is 5 as it directly suggests a concrete improvement to the authors' work. The reviewer proposes 'Consider including Matern kernels in your analysis' and explains why this is relevant: 'This is OK, as the popular Gaussian kernels are in this class. However, another popular class of kernels such as Matern kernels are not included, since their spectrum only decay polynomially.' This provides a clear direction for the authors to explore and potentially strengthen their results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks 'How would we choose which ELM to pick (male/female)?', which is a direct request for information and a clear action to be taken. The reviewer also asks a followup question, indicating a desire for clarification. Both questions are concrete and point to specific aspects of the ELM selection process.", "grounding_specificity_rationale": "The reviewer asks 'How would we choose which ELM to pick (male/female)?', which implies a need to identify the specific ELMs involved. While the terms 'male' and 'female' are specific, the *concept* of choosing between gendered ELMs might not be explicitly stated in the paper's section. However, the reviewer also asks a specific question about the gender detection model's impact, adding a layer of specificity. The reviewer does not explicitly state which ELMs are being considered, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer states 'Accuracy should be calculated after using a gender detection model in the pipeline (at least in the cases where vocal traits match speaker identity)'. This is a statement of a potential issue or a desired order of operations. However, the reviewer does not provide any evidence, reasoning, or references to support this claim. The statement is presented as a suggestion for improvement without justification.", "helpfulness_rationale": "The reviewer provides a clear question about how to choose between male and female ELMs and raises a concern about the order of accuracy calculation in a pipeline. These are directly relevant questions that could help the authors improve their draft. The reviewer's questions are actionable and point to specific areas that require clarification or further consideration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review points out a lack of technical substance and simply adds a new loss to 31. While the action is stated as 'add a new loss', the specific *how* to do this is not provided, making the action vague. The reviewer suggests adding a new loss, which is a direct action, but the details of implementation are missing, making it 3 but ultimately vague.", "grounding_specificity_rationale": "The review mentions '31' but does not explicitly identify the specific part of the paper or the unique aspect where the new loss should be added. The reviewer implies that '31' refers to their work, but this connection is not clearly established, making the grounding weak. The reviewer mentions 'add a new loss to 31' without specifying what this loss is or what it should achieve, making the specificity low.", "verifiability_rationale": "The review states 'The paper is incremental and does not have much technical substance.' This is a claim about the paper's quality and lack of novelty. However, the reviewer does not provide any specific evidence or reasoning to support this claim within the review itself. The statement is a subjective assessment without clear justification or references.", "helpfulness_rationale": "The review is critical, stating that the paper is 'incremental and does not have much technical substance'. While this identifies a potential area for improvement (adding a new loss), it lacks specific details on how to do this or what the expected outcome would. The suggestion is vague and lacks actionable steps. The overall tone is critical, indicating that the feedback is not very helpful for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a concern but does not suggest a specific action or improvement for the authors.", "grounding_specificity_rationale": "The reviewer's concern is about the 'realworld diffusion process' generally, without specifying a particular section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer makes a claim about the need for empirical evidence but does not provide any logical reasoning, examples, or references to support this claim.", "helpfulness_rationale": "While the topic is relevant, the suggestion is too general and lacks justification, making it less helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests a *plot* to visualize weight changes, which is an explicit action. However, the specifics of the plot (e.g., axes, data source) are not explicitly stated, making it somewhat vague on how to implement it. The reviewer implicitly suggests plotting relative weight changes, which could be made more actionable by specifying the calculation method.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'weights of the model' and 'different weights', which clearly grounds the comment to a specific part of the paper. They also suggest a *plot* as a visualization tool, further specifying the area of analysis.", "verifiability_rationale": "The reviewer suggests a *plot* to visualize weight changes. While a plot is a valid visualization tool, the *specific details* of how to calculate the weight changes and how to represent them in the plot are not provided. The reviewer is making a suggestion for analysis rather than claiming something is verifiable.", "helpfulness_rationale": "The reviewer's suggestion to create a *plot* of weight changes is highly specific and directly addresses a potential need for the authors to understand how different layers are affected by unlearning. This provides a clear direction for further investigation and analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the novelty of the paper appears to be limited and points to the ENCODE work as prior art. They also directly critique the decomposition method. This provides clear and direct feedback on specific aspects of the paper.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'methodology aspect' and then further specifies 'ENCODE part' and provides a citation '10'. This demonstrates a strong grounding as the reviewer can accurately pinpoint the section being addressed.", "verifiability_rationale": "The reviewer makes a claim about the limited novelty and provides implicit support by referencing the ENCODE work and critiquing the decomposition. While not providing a direct citation to a specific flaw in the ENCODE methodology, the connection is logical and verifiable.", "helpfulness_rationale": "The reviewer provides clear feedback on the novelty of the paper and specifically criticizes the decomposition method. This feedback is directly actionable for the authors and provides a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a specific weakness: 'presentation is at times too equationdriven and notation is hard to follow.' They also suggest a concrete action: 'An illustrative figure of the key concepts in section 3 would have been helpful.' This clearly indicates an explicit action that the authors can take to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'chapter 3' when suggesting an improvement: 'An illustrative figure of the key concepts in section 3 would have been helpful.' This precise identification of the section demonstrates strong grounding. The suggestion to add an 'illustrative figure' for 'key concepts' is also a specific type of improvement, further enhancing the grounding.", "verifiability_rationale": "The review point does not contain a claim that requires verification. The reviewer states a problem ('presentation is at times too equationdriven...') and offers a suggestion ('An illustrative figure...'). While the suggestion itself could be considered verifiable, the review point itself does not present a claim that needs explicit justification or support.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the presentation ('presentation is at times too equationdriven...') and provides a direct suggestion for improvement ('An illustrative figure...'). This actionable feedback is directly aimed at addressing the identified issue, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out that the subscripts in Figure 3 need improvement for readability and aesthetic appeal. While the reviewer doesn't explicitly state the current subscripts are *bad*, the suggestion implies a desire for better presentation, which can be considered an implicit action. However, the action isn't fully concrete as the reviewer doesn't specify *how* the subscripts should be improved.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'figure3' and specifically mentions 'subscripts' as the area needing improvement. This direct identification of the specific part of the paper and the issue within it demonstrates strong grounding. The reviewer also states the desired outcome as 'better readability and aesthetic appeal', which clearly specifies the nature of the improvement.", "verifiability_rationale": "The reviewer makes a claim that the visual presentation, specifically the subscripts, 'could be enhanced for better readability and aesthetic appeal'. This is a claim that requires some level of justification. While the reviewer doesn't provide specific examples or references, the suggestion implies a logical reasoning that the current presentation is hindering readability. However, without concrete evidence, the verifiability is not fully established.", "helpfulness_rationale": "The reviewer suggests improving the 'aesthetic appeal' of the 'subscripts in figure3'. This is a clear and actionable suggestion directly related to a specific part of the paper. While the suggestion is broad, it points to a concrete area for improvement that could positively impact the paper's presentation, making it helpful."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "Medium", "helpfulness_label": "Low", "actionability_rationale": "The reviewer points to a specific sentence in the paper that states the difference between Batch Normalization and Online Normalization regarding gradient bias. The action is explicit: 'Batch Normalization has the problem of gradient bias because it uses minibatch to estimate the real gradient distribution. In contrast, Online Normalization can be implemented locally within individual neurons without the dependency on batch size. It sounds like that Online Normalization and Batch Normalization are two different ways to estimate the real gradient distribution. I am confused why Online Normalization is unbiased and Batch Normalization is biased.' The reviewer is asking for clarification on this statement. The action is directly identified and the reviewer is asking for an explanation. Therefore, the action is explicit.", "grounding_specificity_rationale": "The reviewer directly references a specific sentence in the paper that explains the difference in bias between Batch Normalization and Online Normalization. The grounding is explicit: 'Batch Normalization has the problem of gradient bias because it uses minibatch to estimate the real gradient distribution. In contrast, Online Normalization can be implemented locally within individual neurons without the dependency on batch size.' The authors can easily identify the section being addressed. The grounding is literal and precise. Therefore, the grounding is fully grounded.", "verifiability_rationale": "The paper makes a claim: 'Online Normalization is unbiased and Batch Normalization is biased.' The paper provides a supporting reasoning: 'Batch Normalization uses minibatch, causing gradient bias. Online Normalization operates locally, avoiding this dependency.' The reasoning is present, but it doesn't fully explain *why* local operation makes it unbiased. The claim is supported by reasoning, but the reasoning is incomplete. Therefore, the claim is 4.", "helpfulness_rationale": "The reviewer explicitly states they will 'stay with my original score' after reading the paper's explanation. This indicates that the reviewer did not find the review point helpful in resolving their confusion. The information provided in the paper, while present, did not lead to a clear understanding of the underlying mechanisms. The reviewer's time was not efficiently used. While the review points out a valid point of confusion, it doesn't offer significant improvement guidance beyond what the paper already contains."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the problem: \"equations are crammed together, captions are too close to the figures.\" This constitutes an explicit action or suggestion. However, it does not provide concrete steps on how to fix this issue. The reviewer identifies the *what* but not the *how*. Therefore, it is 3 but lacks specific guidance on implementation.", "grounding_specificity_rationale": "The comment explicitly mentions the specific parts of the paper being addressed: \"equations,\" \"captions,\" and \"figures.\" This clearly identifies the specific section, table, figure, or unique aspect being addressed. This can be achieved through literal mentions of sections, tables, figures, etc. Therefore, the grounding is fully precise.", "verifiability_rationale": "The comment contains a claim: \"This by itself is grounds for rejection since it effectively violates the 9page paper limit.\" This claim is supported by logical reasoning: reducing whitespace impacts readability and can lead to exceeding the page limit. Therefore, the claim is thoroughly supported by explicit, sufficient, and robust evidence.", "helpfulness_rationale": "The comment identifies a valid issue (formatting violations potentially impacting the 9page limit). However, it does not offer specific suggestions or guidance on how to address this problem. The reviewer points out the *problem* but doesn't provide *how to solve it*. Therefore, it is not 5 as it lacks actionable improvement suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the 'lack' of technical details and formulations, indicating an awareness of a missing component. They also specify the potential novelty lies in the 'scheme or procedure', providing a direction for where the issue might be. This points to a clear area for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'technical details' and 'formulations' generally, without pinpointing a specific section, table, or unique aspect of the paper. While they identify a potential area of weakness, they don't provide enough detail to precisely locate the issue.", "verifiability_rationale": "The reviewer presents a claim about the 'limited technical details and formulations' and suggests the 'main novelty reflected in the scheme or procedure'. However, they do not provide specific evidence or logical reasoning to support this claim within the review point itself. It remains a hypothesis rather than a verifiable statement.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the technical aspects of the paper and suggests that the novelty might be in the 'scheme or procedure'. While this points to an area for improvement, it does not directly instruct the authors on what specific technical details are missing or how the novelty is implemented. The feedback is about a potential problem rather than a direct solution."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the paper claims better results in Table 3 and then points out that adding the constrained method leads to lower validity and diversity. This directly identifies a discrepancy and suggests a specific area for improvement. The reviewer proposes the action: \"investigate why the constrained method leads to lower validity and diversity despite better overall results.\"", "grounding_specificity_rationale": "The reviewer refers to \"Table.3\" which is specific to the Molecule generation experiment. They also mention \"validity\" and \"diversity\" which are specific metrics within that experiment. While the reviewer doesn't explicitly name the sections or tables, the reference to a specific table and metrics within it grounds the comment. The authors can infer the exact section in the paper.", "verifiability_rationale": "The reviewer states a fact: \"the paper claims better results in the Molecule generation experiment (Table.3)\". They then present evidence suggesting otherwise: \"it looks adding the proposed constrained method actually yields lower validity and diversity\". This statement is verifiable based on the data presented in Table 3. The reviewer is making a claim based on the presented data.", "helpfulness_rationale": "The reviewer clearly identifies a potential issue (lower validity and diversity despite better overall results) and suggests an area for investigation (the constrained method). This is a constructive critique that directly points the authors towards a specific problem and a potential solution pathway."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a desire for more description, indicating an action the authors should take. However, the action is vague, as it doesn't specify *what kind* of description is needed.", "grounding_specificity_rationale": "The comment does not explicitly refer to a specific part of the paper or environment (Starcraft). It is a general desire for more explanation, making it 1 in a specific section, table, figure, or unique aspect.", "verifiability_rationale": "The comment contains a claim (a judgment about the level of description), but it is not supported by any evidence or reasoning. It lacks specific examples or references.", "helpfulness_rationale": "The comment identifies a potential area for improvement (more description) but lacks specificity. The authors don't know *what* more description is needed, making the feedback less actionable and helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the lack of discussion regarding the prompt dataset creation and its source. This is an explicit statement about what should be included. Furthermore, the point clearly identifies the specific area of the paper being referred to (prompt dataset creation and its source), making the action concrete. The authors know exactly what needs to be addressed.", "grounding_specificity_rationale": "The review point explicitly mentions 'prompt dataset creation' and 'its source'. This allows the authors to directly identify the specific part of the paper being addressed, achieving 'Full Grounding'. The comment also clearly specifies what is missing \u2013 a discussion of this aspect, which provides 'Specificity'.", "verifiability_rationale": "The review point does not contain a claim in the sense of a definitive statement or suggestion. It's more of a statement of fact: 'a lack of discussion'. Therefore, it fits the 'X' category. There is no logical reasoning, common knowledge, or external references provided to support this statement.", "helpfulness_rationale": "The review point identifies a clear area for improvement by pointing out the absence of a discussion on prompt dataset creation and its source. This provides the authors with a specific direction to look for information. While the point doesn't offer a specific solution, it guides the authors to improve their paper by addressing this deficiency. The implication is that the authors should now seek out information about prompt dataset creation and its source to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point states 'Very difficult to follow the motivation of this paper.' This suggests an implicit action or an action that needs to be inferred. While the motivation is identified as the area of concern, the specific steps or changes needed to improve the motivation are not explicitly stated. The reviewer implies a need for clearer writing or structuring, but the 'how' is missing.", "grounding_specificity_rationale": "The review point 'Very difficult to follow the motivation of this paper' does not identify a specific part of the paper being addressed. There is no mention of a particular section, table, figure, or unique element of the paper. The reviewer is broadly criticizing the overall clarity of the motivation without pinpointing the exact location of the problem.", "verifiability_rationale": "The review point 'Very difficult to follow the motivation of this paper' does not contain a claim that requires verification. It is a statement of opinion or judgment about the paper's clarity. There is no suggestion, recommendation, or judgment that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The review point identifies a problem ('difficult to follow the motivation') but does not offer any specific suggestions or improvements. While the feedback highlights an area for improvement, it lacks the actionable steps needed to actually address that issue. The reviewer knows there's a problem, but doesn't provide concrete guidance on how to fix it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of 'ablate the crossentropy loss weighting' and asks the authors to 'see if this might help'. This is a clear and direct suggestion for improvement, making it actionable. The reviewer also mentions 'an ablation on the weighting method of the crossentropy loss', further specifying the action.", "grounding_specificity_rationale": "The reviewer mentions 'an ablation on the weighting method of the crossentropy loss' which is a general suggestion. However, they also provide a specific example, 'the authors note for example that in Atlantis their method underperforms because \"the game has repetitive background sounds\". This is a scenario I'd expect the weighting might have helped remedy.' The inclusion of the 'Atlantis' example provides some grounding by identifying a specific context where the weighting might be relevant.", "verifiability_rationale": "The reviewer makes a claim that 'The authors note for example that in Atlantis their method underperforms because \"the game has repetitive background sounds\". This is a scenario I'd expect the weighting might have helped remedy.' This is a claim that can be supported by the previous observation about Atlantis. The reviewer provides a specific example ('Atlantis and repetitive sounds') to illustrate their expectation, which provides some basis for verification.", "helpfulness_rationale": "The review point is clear and directly addresses a potential weakness ('underperforms in Atlantis') by suggesting a specific improvement ('ablate the crossentropy loss weighting'). The reviewer's expectation that this might help is a constructive suggestion that directly addresses the identified issue. The suggestion is actionable and provides a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a weakness ('lack of novelty') and provides some context ('new dataset', 'synthetic benchmark'), but it does not explicitly state an action or suggest a concrete modification the authors should make to address this weakness. The reviewer offers general ideas but lacks specific guidance on how to improve the work.", "grounding_specificity_rationale": "The reviewer mentions 'column operations', 'TexttoSQL', 'semantic parsers', 'dataset', and 'train/test split'. While these are specific areas within the paper, the review does not pinpoint a specific section, table, figure, or unique element within the paper that needs improvement. The suggestions are very general and lack specificity about the exact part of the paper being criticized.", "verifiability_rationale": "The review point makes a claim ('A critical weakness of the paper is the lack of novelty') and provides some reasoning ('The paper addresses a particular problem of column operations... They design a new dataset...'). However, the reasoning is highlevel and lacks specific evidence or references to support the claim. The suggestions are also general and do not provide concrete examples or references to verify the claim's validity.", "helpfulness_rationale": "The review point identifies a valid concern ('lack of novelty') and offers some context ('new dataset', 'synthetic benchmark'). However, it lacks specific suggestions on how to address this weakness. The suggestions are very general and do not provide actionable steps for the authors. Therefore, while the review points out a problem, it does not offer concrete guidance on how to improve the work, making it unhelpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a problem ('experiments are only done on one game environment') but does not specify how to address it. It lacks concrete actions or suggestions for improvement.", "grounding_specificity_rationale": "The comment is too general and does not specify which game environment or aspect of the experimental setup is limited. It lacks a clear reference to a specific part of the paper.", "verifiability_rationale": "The comment points out a valid limitation ('experiments are only done on one game environment') but does not provide any specific evidence, reasoning, or references to support potential solutions or improvements.", "helpfulness_rationale": "The comment identifies a weakness ('experiments are only done on one game environment') but does not offer specific, actionable, or wellsupported suggestions for improvement. It is a clear indication of a problem but lacks constructive guidance."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "Low", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states the need to explain the importance of relaxed assumptions and suggests a concrete method (using examples) to achieve this. This directly addresses a perceived weakness and offers a clear action.", "grounding_specificity_rationale": "The reviewer directly mentions specific assumptions ('bounded variance' and 'bounded gradients') and suggests a concrete way to illustrate them ('solid examples'). This clearly identifies the part of the paper being addressed and specifies the type of explanation needed.", "verifiability_rationale": "The reviewer suggests using 'solid examples,' which is a general concept and lacks specific examples or references in the review point itself. While the intention is helpful, the lack of concrete examples makes it difficult to verify the claim within this specific review point.", "helpfulness_rationale": "The reviewer directly addresses a perceived weakness in the paper (lack of explanation for relaxed assumptions) and offers a clear and actionable suggestion (using examples). This is a constructive comment aimed at improving the paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a specific problem ('slow and low accuracy') and provides concrete data ('SHE needs 1 day and 2.5 days to test an ImageNet picture by AlexNet and ResNet18, respectively' and accuracy is around 70%) which directly links the issue to the authors' implementation. This makes the action very explicit and concrete.", "grounding_specificity_rationale": "The reviewer refers to the authors' claim about implementing ImageNet. While they don't explicitly state the section or table, they clearly identify the *general* area of the authors' implementation, providing weak grounding. They also specify *what* is wrong (slowness and low accuracy), adding to the specificity of the issue.", "verifiability_rationale": "The reviewer makes a claim about the authors' implementation ('they are very slow and accurate') and provides specific numerical data ('SHE needs 1 day and 2.5 days to test an ImageNet picture by AlexNet and ResNet18, respectively' and accuracy is around 70%) which serves as evidence. While the reviewer doesn't explicitly cite external references to support the general statement about ImageNet, the numerical data makes the claim 3.", "helpfulness_rationale": "The review clearly identifies a problem ('slow and low accuracy') and provides supporting evidence ('SHE needs 1 day and 2.5 days to test an ImageNet picture by AlexNet and ResNet18, respectively' and accuracy is around 70%) which is directly relevant to the authors' implementation. This makes the review 5 for the authors to understand and address the issue."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "1", "actionability_rationale": "The reviewer suggests exploring the use of labeled data in consistency training for graph anomaly detection and provides references to relevant work. However, the reviewer does not explicitly state a concrete action or modification that the authors should apply to their current draft. The suggestion is more of a question and a potential avenue for future research rather than a direct instruction for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions two specific papers (a Graph Contrastive Learning Automated and b Graph Contrastive Learning with Adaptive Augmentation) and the task of graph anomaly detection. This demonstrates a clear identification of the relevant section, papers, and the specific issue being addressed.", "verifiability_rationale": "The reviewer poses a question about the potential benefits of using labeled data in consistency training and suggests exploring existing work in graph contrastive learning. While the reviewer doesn't provide a definitive answer or proof, the suggestions and references offer a basis for further investigation and could be considered partially verifiable if the authors decide to explore these avenues. The reasoning is present, but the claim itself is more exploratory than a direct criticism or solution.", "helpfulness_rationale": "The reviewer's point is more about suggesting a potential research direction (exploring labeled consistency training for graph anomaly detection) and providing relevant references. While this is valuable for the field and the researcher developing the method, it does not directly provide actionable feedback or suggestions for improving the specific draft being reviewed. The suggestion is about future work, not immediate actionable improvements for the authors' current work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides a clear and actionable suggestion: 'report the classification accuracy of the proposed classifier on ImageNet data' and 'some theoretical justifications, if possible, would be great for the issue.' This indicates a direct understanding of what needs to be done to address the concern about the new classifier's performance.", "grounding_specificity_rationale": "The reviewer mentions 'ImageNet data' and 'classification accuracy' as areas for improvement. While the metric is specific, the reviewer does not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The reference to 'ImageNet data' is general, not pinpointing a specific part of the dataset.", "verifiability_rationale": "The reviewer does not make a claim. They are posing a question and suggesting further investigation. Therefore, there is X to verify.", "helpfulness_rationale": "The reviewer raises a valid concern about the potential tradeoff between improved outofdistribution detection and classification accuracy. By suggesting the authors report the classification accuracy on ImageNet, the reviewer provides a concrete and actionable step that directly helps the authors understand the impact of their proposed classifier. The suggestion to seek theoretical justifications further enhances the helpfulness of the comment."}
{"actionability_label": "3", "grounding_specificity_label": "2: Weakly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue with a specific recognition model (based on lists) when applied to a common recognition scenario (old vs. new judgments). They highlight a potential discrepancy: traditional recognition lists might not account for *all* items in memory, especially in the \"new vs. old\" context. While the reviewer doesn't explicitly state what action the authors should take, they imply that this discrepancy could lead to difficulties in implementing and testing the model. This suggests a lack of explicitness in the potential issue and how it relates to the proposed method. The reviewer is implicitly suggesting that the authors need to be careful about applying this method in this specific recognition scenario.", "grounding_specificity_rationale": "The reviewer is grounding the discussion in a specific type of recognition task (new vs. old). They are implying that the standard listbased approach might not be directly applicable or effective in this context. While they don't explicitly name a section or table, the context strongly suggests they are referring to the \"recognition\" or \"method\" section. However, the reviewer doesn't specify *which* part of that section or table they are referring to, nor does they clearly explain *how* the lists are constructed in this new vs. old context. This makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer makes a statement about the potential limitations of applying a listbased recognition model to new vs. old recognition. They provide a *reason* for their claim: \"it's hard to see how such an exhaustive list could be effectively implemented and concrete predictions tested with simulations.\" This is a logical argument based on the complexity of memory and the practical challenges of implementing exhaustive lists. The reviewer provides a clear claim and supports it with a logical reasoning. They don't mention external references in this specific point.", "helpfulness_rationale": "The reviewer raises a specific concern about the applicability of a recognition model in a common scenario. They highlight a potential issue with the listbased approach in the new vs. old recognition context. This is a clear and actionable feedback for the authors. They are not just pointing out a problem, but they are linking it to a specific type of recognition and suggesting potential difficulties in implementation and testing. This makes the feedback helpful for the authors in understanding potential limitations of the method."}
{"actionability_label": "High", "grounding_specificity_label": "Medium", "verifiability_label": "N/A", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states their desire for clarification on 'alternate formulations for Confidence Diversity (CD)' and 'Predictive Uncertainty' (PU). They also express confusion about the justification for not using entropy as a measure of spreading of teacher predictions. The reviewer doesn't just state they are confused; they pinpoint specific areas of confusion related to these concepts. The request for 'detailed explanation' further indicates a desire for concrete actionable feedback.", "grounding_specificity_rationale": "While the reviewer doesn't explicitly state a *specific* section or table they are referring to when they say 'line 113 did not clarify it for me,' their confusion about the relationship between CD, PU, and entropy suggests they are looking for a more detailed explanation of these concepts as they are presented in the paper. The request for 'alternate formulations' implies a desire to understand how CD is defined and implemented. However, the reviewer doesn't provide a clear mapping or specific location within the paper where this clarification is lacking.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are asking for clarification and a detailed explanation of existing concepts, not making a statement that needs to be supported by evidence or reasoning. Therefore, it does not fit into the 'claim extraction' and 'verifiability verification' process.", "helpfulness_rationale": "The reviewer explicitly states they want clarification and a detailed explanation. This directly addresses a potential weakness in the paper for the authors. The request for 'alternate formulations' and 'detailed explanation' suggests a desire for actionable feedback that would help them improve their understanding and potentially their own work. The reviewer's confusion about entropy further indicates a need for constructive feedback."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: 'The nature of the contribution with respect to ECE_sweep is not clearly described in the text.' While the reviewer doesn't provide a specific action, the statement itself is an actionable suggestion for the authors to clarify the relationship between their method and ECE_sweep, particularly regarding the binning process. The reviewer identifies a lack of explicitness in the description of the contribution.", "grounding_specificity_rationale": "The reviewer points out a lack of clarity in the paper's description of the contribution. They do not explicitly identify a specific section, table, or figure where the issue arises. The reviewer's comment is a general statement about the overall framing of the contribution, rather than a precise reference to a particular part of the paper. The authors would need to infer the issue from the reviewer's description.", "verifiability_rationale": "The reviewer makes a claim: 'this is not something fundamentally different.' They argue that the contribution is merely a hyperparameter tuning process. While the reviewer provides a logical explanation for this claim ('it's just a way to choose the number of bins using data'), they do not provide specific examples or references to external works to support this assertion. The claim is supported by reasoning, but lacks concrete evidence or references.", "helpfulness_rationale": "The reviewer's comment is clear and identifies a specific area of confusion for the authors. They state that the paper does not clearly describe the contribution with respect to ECE_sweep and the binning process. This is a direct and actionable feedback that would likely help the authors improve their understanding and the clarity of their paper. The reviewer's confusion highlights a lack of explicitness in the paper's description."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that 'none of them is used as a baseline' and suggests including RL methods as baselines. This is a clear and actionable suggestion for the authors to improve their draft by including a relevant comparison method.", "grounding_specificity_rationale": "The review point mentions 'RL methods' generally, which is a category of methods. While it's relevant to the paper's focus on NMT, it doesn't specify a particular section, table, figure, or unique aspect of the paper that would require the authors to go back and find where RL methods are discussed. The grounding is at the level of the method category rather than a specific element of the paper.", "verifiability_rationale": "The review point makes a claim that 'none of them is used as a baseline' regarding RL methods. While this is a claim, the review point itself doesn't provide any logical reasoning, common knowledge, or external references to support this statement. The justification for why RL methods aren't used as baselines isn't explained or referenced within the review point itself.", "helpfulness_rationale": "The review point identifies a potential gap in the related work by pointing out the absence of RL methods as baselines in NMT model training. This is a specific and actionable suggestion that could help the authors position their work more effectively within the field and provide a more comprehensive comparison to existing methods."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer identifies the ambiguity surrounding the term 'Efficient Proxy' but does not provide a specific action or suggestion on how to resolve it. While the reviewer points out the difference between a 'particular proxy' and 'efficient proxies in general,' they do not explicitly state what the authors should do to clarify this ambiguity. The reviewer's comment is more of a clarification request than a directive action.", "grounding_specificity_rationale": "The reviewer attempts to ground the comment by mentioning both 'a particular efficient proxy' and 'efficient proxies in general,' indicating an effort to specify the ambiguity. While not a direct section reference, the use of these terms suggests an attempt to ground the comment within the discussion.", "verifiability_rationale": "The reviewer states a fact: 'it is unclear if the authors mean a particular efficient proxy or efficient proxies in general.' This is a statement of uncertainty, not a claim that requires verification or justification. The reviewer is simply pointing out a lack of clarity without proposing a solution or making a judgment.", "helpfulness_rationale": "The reviewer's comment identifies a potential issue with clarity regarding the term 'Efficient Proxy.' However, the reviewer does not offer any specific actions or suggestions to address this ambiguity. The comment is diagnostic in nature, revealing a lack of clarity but not providing any guidance on how to improve it."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the steps taken: 'stack the methods of Mirzasoleiman et al., 2020 and Grouplearning setting' and then 'use one classical method DBSCAN to cluster'. This provides clear and direct information about the methodology. The authors can easily identify the actions to be taken based on this information.", "grounding_specificity_rationale": "The reviewer does not explicitly identify where in the paper these methods are being applied. They only state that the methods are 'stacked' and then 'used' for clustering. This implies a general methodology but lacks specific referencing of sections, tables, or unique aspects. The authors cannot confidently determine which part of the paper the reviewer is referring to.", "verifiability_rationale": "The reviewer presents a statement about the methodology: 'They stack the methods of Mirzasoleiman et al., 2020 and Grouplearning setting, and then use one classical method DBSCAN to cluster.' This statement is a normal statement ('X') as it describes a sequence of actions without making a claim, judgment, or suggestion. There is X that requires verification.", "helpfulness_rationale": "The reviewer points out a potential inefficiency in the methodology. If the 'stacking' of methods is already being performed, applying a classical clustering method like DBSCAN might not be a significant contribution. This raises a valid concern for the authors regarding the novelty and impact of their approach. While it doesn't directly ask a question, it does highlight a potential area for simplification or a more novel contribution in the stacking process."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests 'it would be helpful to see resilience of the metric to the choice of random projection'. While this implies an action (investigating resilience), the reviewer does not specify how to do this or what specific analyses to perform. The action is implicit rather than explicit.", "grounding_specificity_rationale": "The reviewer's statement, 'What sort of variability is there in the results with the chosen random projection matrix?', does not explicitly identify a specific part of the paper or methodology being addressed. The comment is general and lacks grounding in a particular section, table, figure, or unique aspect of the paper. The reviewer is asking about a general property rather than a specific issue.", "verifiability_rationale": "The reviewer makes a claim ('it would be helpful to see...') but does not provide any justification or evidence for why this is helpful or how the authors should go about assessing the variability. There is no logical reasoning or references provided to support the claim.", "helpfulness_rationale": "The reviewer's suggestion is relevant to the paper's content, as it raises a valid concern about the robustness of the method. However, the suggestion is presented as a general request without concrete steps or guidance on how the authors can address it. The reviewer does not offer specific advice or propose a solution."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The statement is explicit about the purpose of the FGT evaluation (ablation study) and how it should be used (to evaluate method performance against comparative methods). The actions are explicit (evaluate in ablation study) and concrete (against comparative methods).", "grounding_specificity_rationale": "The reviewer refers to the 'evaluation of FGT' and its 'purpose in the ablation study'. While the *content* of the review point is about the *purpose* of the FGT evaluation, the reviewer doesn't explicitly point to a specific section, table, figure, or unique aspect of the paper being addressed. The grounding is implicit through the mention of 'FGT evaluation' and 'ablation study'.", "verifiability_rationale": "The review point is a statement of fact: 'the evaluation of FGT is only leveraged to evaluate the method performance in the ablation study, which should be used to evaluate the performance of the proposed method and the comparative methods.' There are no opinions, suggestions, or judgments expressed. It's a factual statement about the intended use of the FGT evaluation.", "helpfulness_rationale": "The reviewer is pointing out a potential issue with the experimental setup (the ablation study's focus) and suggesting an alternative (evaluating against baselines). While they identify a potential limitation, they don't explicitly recommend a concrete improvement to the experimental design or the paper being reviewed. The feedback is about the experimental setup, not a direct suggestion for improvement within the paper itself."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the concern: 'It\u2019s unclear how this paper contributes novelly to the understanding of this behavior with its extremely simplified settings, especially since most of the findings have been reported in previous works (Sec 5).' While the reviewer identifies a problem, they do not propose a specific action or solution. The action is implicit  the reviewer is indicating a lack of novelty. Therefore, it's 4 as the action is clear, but lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer specifically mentions 'NNbased clustering algorithms' as a point of comparison, providing a concrete reference point. Furthermore, they highlight the 'simplified settings' and the 'reporting of findings in previous works,' detailing the specific aspects that need clarification. This demonstrates a clear and specific identification of the issue.", "verifiability_rationale": "The review point does not contain a claim that needs verification. It's a critique of the paper's contribution rather than a statement that requires evidence or justification.", "helpfulness_rationale": "The reviewer provides a clear critique of the paper's contribution, which is directly relevant to the authors. While they don't propose specific improvements, identifying a significant gap in novelty is a valuable piece of feedback that empowers the authors to focus on the unique aspects of their work compared to existing research. This feedback is helpful in guiding future work and understanding the limitations of the current approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two explicit suggestions: 'It may be good to briefly mention the negligible computational cost of CHR (which is in the appendix)' and 'A rough example of some runtimes in the experiments may also be useful for readers looking to apply the method'. These are direct and actionable suggestions aimed at improving the paper.", "grounding_specificity_rationale": "The reviewer explicitly states where the suggestions should be made ('main paper') and what specific information should be included ('negligible computational cost' and 'rough example of runtimes'). This clearly identifies the intended location and content, making it fully grounded. The reviewer also specifies the *what* of the suggestion ('negligible computational cost' and 'rough example of runtimes'), making it specific.", "verifiability_rationale": "The reviewer suggests explicitly mentioning the 'negligible computational cost' and providing 'rough examples of runtimes'. While the reviewer doesn't provide external references or logical reasoning to *verify* these claims, the suggestions themselves are based on observable elements (computational cost, runtime). Therefore, it can be considered '4' as the suggestions are based on the content of the paper (albeit potentially needing a quick check of the appendix for the 'negligible computational cost' claim).", "helpfulness_rationale": "The reviewer's suggestions directly address a practical concern (computational cost) and aim to improve the reader's understanding and potential adoption of the method. By mentioning the computational cost in the main paper, the reviewer helps motivate the method by providing a practical benefit. Including runtime examples further enhances this by giving concrete evidence of the method's efficiency. These suggestions are clear and directly address the stated goals, making them 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the action of 'compare with existing code completion commercial applications' and suggests focusing on 'RepoEval' and ' Copilot'. This indicates a clear and direct action for the authors to take.", "grounding_specificity_rationale": "The review point mentions 'RepoEval' and ' Copilot', which are specific elements of the paper or project. It also explicitly states the intention to 'compare' and 'test on a smaller subset of RepoEval'. This demonstrates a clear identification of the specific part of the paper being addressed and provides details on what is being compared.", "verifiability_rationale": "The review point identifies a potential improvement area ('missing baselines') and suggests a comparison with ' Copilot'. While the suggestion is relevant, the review point lacks explicit justification for why this comparison is necessary or what specific aspects of the comparison should be considered. There is no external reference provided to support this suggestion.", "helpfulness_rationale": "The review point directly suggests a concrete action for the authors: 'compare with existing code completion commercial applications' and highlights the importance of this comparison by stating 'It can be tested on a smaller subset of RepoEval, and it is essential to compare with these stateoftheart code completion systems.' This provides a clear direction for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a consequence of the subset choice ('raises questions about generalizability') but does not explicitly propose a specific action or solution. While the reviewer implies a desire for more information, the comment lacks concrete steps on how to address the concern.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Massive Text Embedding Benchmark (MTEB)' and refers to a 'subset' of it. The issues raised ('generalizability' and the need to understand 'criteria' and consider 'other tasks or datasets') are specific to this selection. The reviewer clearly identifies the target and the nature of the problem.", "verifiability_rationale": "The reviewer makes a claim about the limitations of using a subset of MTEB for generalizability. They also suggest further investigation, providing a logical basis for their concern. However, they do not provide specific examples or citations to back up their claim about generalizability.", "helpfulness_rationale": "The reviewer points out a potential issue with the evaluation methodology (using a subset of MTEB) and suggests further investigation. While relevant, this is more of a critique of the benchmark selection rather than a direct, actionable suggestion for improving the paper itself. The authors might not directly benefit from this review point in terms of concrete changes to their work."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a lack of clarity in the experimental setup (shifted MNIST) and suggests a valuable experiment. While the reviewer's statement itself isn't a direct instruction on what to do, the implication is that the current setup is problematic and needs clarification or improvement. The reviewer suggests showing performance on a different distribution, which implies a need for action to implement this experiment. Therefore, while not explicitly stating a concrete action, the reviewer sets the stage for the authors to take action to clarify the current setup or perform the suggested experiment.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'shiftedMNIST' and points out the difference between 'shift=0' and 'shift~ N ( 0 , \u03c3 2 )'. This clearly identifies the specific part of the paper they are referring to. They are also highlighting a specific issue within this part \u2013 the lack of clarity in the experimental setup. The reviewer's comment is focused on a specific detail within the experimental description, indicating a clear grounding in the relevant section. They are also pointing out a specific area for improvement within that section.", "verifiability_rationale": "The reviewer states a claim: 'It would be useful to show the performance the model and baselines on test samples from the observational (in) distribution.' However, they do not provide any justification or evidence for this claim. They simply state what they think would be a useful experiment. The claim is stated, but the reasoning or support for why this is useful is missing. Therefore, it is not 5.", "helpfulness_rationale": "The reviewer points out a lack of clarity in a specific experimental setup and suggests a valuable experiment. This is a constructive comment that highlights a potential area for improvement in the paper. While the reviewer doesn't provide a direct solution, they identify a problem and suggest a direction for future work. This is a valuable comment that guides the authors towards a specific area of refinement and experimentation. Therefore, it is 3 in identifying an area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'Description of experimental details would significantly benefit from increased clarity' and implicitly suggests the authors should make the descriptions clearer. This directly tells the authors what the issue is and what they should improve.", "grounding_specificity_rationale": "The comment refers to 'experimental details' generally, without specifying a particular section, table, figure, or unique aspect of the paper. While it implies the need for clarity, it doesn't pinpoint the exact location or provide a clear reason *why* the clarity is needed beyond a general desire for better judgment of the results. The phrase 'increased clarity' is vague.", "verifiability_rationale": "The comment suggests 'improving clarity' rather than making a definitive statement about the current state of the experimental details being flawed or lacking. It doesn't present a claim that requires verification using logical reasoning, common knowledge, or external references. It's more of a suggestion for improvement than a claim that needs to be supported.", "helpfulness_rationale": "The comment clearly identifies a weakness ('lacking detail') and provides a clear direction for improvement ('increase clarity'). It's concise and directly addresses the issue, making it a helpful suggestion for the authors to focus on improving the clarity of the experimental description."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly suggests the action of including a definition for 'treewidth' and its role in the proofs. This is a clear and explicit action that the authors can readily implement. The suggestion is not implicit and requires no further inference from the reviewer. The reviewer clearly states the importance of 'treewidth' in the proofs, making the action concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'treewidth' and its role in the proofs. This directly identifies the specific part of the paper being addressed, making the grounding fully grounded. The reviewer does not need to infer the importance of 'treewidth' from the context. The reference to proofs further clarifies the specific aspect being addressed.", "verifiability_rationale": "The reviewer states that 'treewidth is central to all the proofs in the paper.' This provides a basis for verification. While the exact proofs are not provided, the statement about the importance of treewidth in the proofs is a logical and plausible claim within the context of parameterized complexity and graph algorithms. The reviewer provides a clear justification for the importance of the term, making the claim 3.", "helpfulness_rationale": "This review point directly identifies a crucial missing element ('treewidth') and its importance for understanding the paper's proofs. This is 5 and directly addresses a core aspect of the work. By suggesting the inclusion of a definition, the reviewer provides a clear direction for the authors to improve their understanding and potentially build upon this work. The feedback is directly linked to the core methodology, making it highly valuable."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the paper is not selfcontained and requires the supplementary material for understanding. While the need for selfcontainment is implied, the specific action or information needed to make the paper selfcontained is not explicitly stated. The reviewer suggests making the paper understandable given the NIPS format, but doesn't detail what changes are needed within the main paper itself.", "grounding_specificity_rationale": "The reviewer points out that the paper is not selfcontained and that the supplementary material is necessary to understand large parts of the main paper. This implies that the reviewer can infer that the main paper is not entirely understandable on its own. However, the reviewer does not explicitly identify which specific parts of the paper are unclear or require the supplementary material. The grounding is implied but not explicitly stated.", "verifiability_rationale": "The reviewer does not present a claim that requires verification. They are stating a problem (the paper not being selfcontained) rather than making a statement that needs to be supported by evidence or reasoning.", "helpfulness_rationale": "The reviewer explicitly states their desire for the paper to be understandable without relying on supplementary material and code release. This directly addresses a practical issue for the authors and would significantly improve their ability to understand and potentially reproduce the work. The request for selfcontainment and code release directly points to a need for clearer and more readily accessible information."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point implicitly suggests an action by asking 'How important is the added complexity?' and 'Will one IN do?'. While it doesn't explicitly state 'do this,' the questions directly point to areas where the authors should focus their attention. The reviewer is prompting the authors to consider the necessity and redundancy of the design. However, the questions are general and openended, lacking specific guidance on how to determine the importance or redundancy.", "grounding_specificity_rationale": "The review point explicitly refers to 'multiple INs at different speeds in the dynamics predictor' and asks questions about 'this specific design choice' and 'this part of the paper'. This demonstrates strong grounding as the reviewer clearly identifies the specific technical detail being questioned. The questions are also specific, asking about the importance and redundancy of this particular design.", "verifiability_rationale": "The review point is more of a question than a definitive claim that requires external verification. While it implicitly suggests that further investigation (like ablation studies) is needed, it doesn't make a statement that needs to be supported by logical reasoning, common knowledge, or external references to be considered helpful. The reviewer is prompting the authors to explore this design choice further, but doesn't provide a clear direction or justification for what they should do next.", "helpfulness_rationale": "The review point raises a valid concern about a design choice (multiple INs at different speeds) without providing immediate guidance on how to address it. While it encourages the authors to investigate this further (implying the need for ablation studies), it doesn't offer concrete suggestions or a clear path forward. The reviewer is pointing out a potential issue but doesn't provide a direct solution or actionable steps for the authors to take based on this observation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential issue with the experimental setup and the interpretation of results by highlighting the discrepancy between the authors' proposed payoff and the opponent's actual objective function (classical SE and AE). This information can help the authors identify a flaw in their experimental design and potentially refine their payoff comparison. While it doesn't explicitly state the action to take, it points to a specific area of the methodology that needs to be revisited. It's 3 because it encourages the authors to consider the opponent's actual optimization objective when evaluating their payoff.", "grounding_specificity_rationale": "The comment identifies the opponent's objective function (SE and AE) but doesn't explicitly point to a specific section, table, or figure in the paper. It's generally applicable to the experimental setup. While it's not literally naming a section, it's also not vague enough to be considered 1. It clearly specifies what needs to be addressed in this part (the opponent's objective function).", "verifiability_rationale": "The comment presents a hypothesis about the opponent's objective function but doesn't provide any specific evidence, examples, or citations to support this claim within the review point itself. It relies on the reviewer's understanding of game theory and the common practices in that field. Therefore, it's 1 because it lacks concrete evidence or justification within the review point itself.", "helpfulness_rationale": "The comment raises a valid concern about the experimental setup and the fairness of comparing the authors' payoff against an opponent who isn't optimizing for that specific payoff. It encourages the authors to reevaluate their payoff comparison and the opponent's objective function. This can lead to a more thorough and accurate analysis of their results. While it doesn't provide a definitive answer, it prompts the authors to consider a crucial aspect of their experimental design and analysis, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a missing justification for the choice of the REINFORCE algorithm and suggests an alternative (PPO). They also imply the connection to attention models. This constitutes an explicit action and provides a clear direction for improvement, making it 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'REINFORCE algorithm' and 'PPO' as alternatives. While the connection to 'attention model paper' could be more direct, the specific algorithms are clearly identified, indicating a good level of grounding. The reviewer also implies the relevance to attention models through the suggestion of PPO, which is often used in sequence modeling, a key aspect of attention mechanisms.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are suggesting an alternative algorithm and explaining its potential benefits. This is a suggestion, not a claim that needs to be supported by evidence or references, making it not verifiable.", "helpfulness_rationale": "The reviewer directly addresses a potential gap in the paper by asking for justification of the algorithm choice and suggesting an alternative. This provides a clear direction for the authors to improve their work. The suggestion of PPO is a reasonable alternative, and the connection to attention models, while not explicitly stated, is likely relevant to the reviewer's field. This review point is 5 in guiding the authors towards a more robust methodology."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer states they are 'confused' about the statement in Theorem 5.1. While they acknowledge the existence of a statement, the meaning and implications of that statement, and consequently the advice it offers, are not immediately clear. They are aware there's a comparison being made, but the specific action or advice derived from this comparison is ambiguous. Therefore, the review is partially actionable as the information is present, but the actionable step is unclear.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Theorem 5.1' and 'variance regularized problem' in their comment. This demonstrates a clear understanding of the specific section and comparison being referenced within the paper. They are not just stating a general observation but specifically pointing to elements within the text. Therefore, the grounding is fully specific.", "verifiability_rationale": "The reviewer's comment is a statement of confusion and interpretation of a statement in a theorem, not a claim requiring verification. They are expressing their uncertainty about the implications of the theorem's statement regarding the conservativeness of MMD DRO. There is no assertion of a fact that needs to be supported by evidence. Therefore, there is X, and the label is 'X'.", "helpfulness_rationale": "The reviewer's confusion about the theorem and its implications for MMD DRO's conservativeness leads to a lack of actionable advice for the authors. They are unsure what the statement means in practical terms and how it affects their work. This lack of clarity makes the review unhelpful for guiding improvements. Therefore, the helpfulness score is '1'."}
{"actionability_label": "3", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks a question about the invariance of morphologic segmentation across domains, which is a direct action to seek clarification and understanding. The request is also concrete, as it specifically asks about the paper's assumption regarding this aspect.", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "The reviewer's point is highly relevant to the authors as it directly addresses a potential limitation or area of confusion in the paper's methodology. By asking a specific question, the reviewer is encouraging the authors to clarify a key aspect of their work, which can significantly improve their understanding and potentially lead to improvements in their approach. While the review point itself doesn't contain a claim, its helpfulness stems from its direct relevance to the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking for clarification on a specific implementation detail of the object detection attention mechanism. While they are asking for explicit information, the request itself is actionable as it points to a potential issue or area for improvement in the method. The authors can look for where the attention is applied (image vs. feature map) and check for any rescaling operations.", "grounding_specificity_rationale": "The reviewer is asking about the input to the object detection attention mechanism. They are implicitly asking about the spatial correspondence between the image and the feature map. While they don't explicitly name a section, their question clearly targets a specific part of the method. However, they are not specifying *which* feature map or *if* any rescaling is involved, making the grounding somewhat underspecific.", "verifiability_rationale": "The review point is a request for clarification, not a claim or assertion. There is no logical reasoning, evidence, or references provided. The reviewer is asking for more information to understand a potential implementation detail, not making a judgment about the paper.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific implementation detail of the object detection attention mechanism. This is a direct and actionable request that would help the authors understand and potentially improve their draft. The request is clear and directly addresses a potential implementation issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the missing element ('missing discussion about Set Transformer... and other related works that also uses summary tokens') but does not provide concrete steps on how to address this. It identifies the gap but lacks a direct action.", "grounding_specificity_rationale": "The comment explicitly mentions 'Set Transformer' and 'other related works that also uses summary tokens', providing a clear and specific reference point within the paper. The authors can easily identify the sections or concepts being referred to.", "verifiability_rationale": "The comment contains a claim ('Missing discussion about Set Transformer...') and provides logical reasoning by implying that this omission is a weakness. While it doesn't provide specific examples of what is missing, it clearly states the absence of a discussion.", "helpfulness_rationale": "The comment identifies a specific area of related work that is missing and suggests the authors look for similar discussions. This provides valuable context and direction for the authors, making the feedback helpful in improving their understanding of the field."}
{"actionability_label": "1", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer is not proposing a specific action or improvement based on the identified issue. They are asking a question about a potential gap in the theoretical support. While the question implies a desire for clarification, it doesn't directly instruct the authors on how to address the NTK convergence issue.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Fourier features accelerate NTK convergence in the highfrequency range' as a point of concern. They are also asking if they overlooked something, which implies they are trying to ground the issue in the paper's analysis. The specificity is high as they are pinpointing a very specific technical detail.", "verifiability_rationale": "The reviewer poses a question, which can be considered a claim that requires justification. They are asking for clarification on whether the NTK convergence issue is analyzed, and if not, why not. However, the paper itself doesn't explicitly state whether this analysis is present or absent, so the justification is missing.", "helpfulness_rationale": "The reviewer is pointing out a potential gap in the theoretical support and asking a question to seek clarification. This is a valid point that could help the authors improve their paper by addressing the missing analysis. While it's not a direct instruction, it's a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states they cannot find details on a specific training aspect, which is a clear indication of a potential area for improvement. While they don't propose an action, identifying a missing piece of information is a form of actionable feedback, though it lacks concrete steps for the authors to take immediately.", "grounding_specificity_rationale": "The reviewer refers to 'the training process' or 'how the network is trained' without explicitly pointing to a specific section, table, or figure. This indicates weak grounding as the authors cannot confidently determine the referenced part. However, the reviewer does specify the * aspect* they are interested in (fitting the residual), making the specificity somewhat clear.", "verifiability_rationale": "The reviewer states that they 'can't find details' regarding a specific training method. This is a claim that requires verification. However, the review point lacks any supporting evidence or reasoning to back up this claim. The justification for verifiability is missing, making it 1.", "helpfulness_rationale": "The reviewer points out a lack of detail in the training process, which is likely to be helpful for them in understanding and potentially improving their own network. While the feedback is specific to a training aspect, it doesn't offer a direct solution or citation, requiring the authors to take further action to find the information. Therefore, it is 3 as it highlights a potential problem."}
{"actionability_label": "1", "grounding_specificity_label": "4: Mostly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The comment asks a question about the experiment setup, which is the opposite of providing an action. It's a request for information, not a directive to improve the authors' work.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3.3' and asks about 'data augmentation methods' and 'learning rate', clearly pinpointing the relevant part of the paper and the specific issues.", "verifiability_rationale": "The comment is a question, not a claim that needs verification. It's a request for information.", "helpfulness_rationale": "The comment asks for information about the experiment setup, which is helpful for understanding the paper's context, but it doesn't directly guide the authors on how to improve their own work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer asks a question about whether a statistical significance test was done. This is an implicit request for information. While the reviewer implies an expectation, they don't explicitly state an action the authors should take or how to implement it.", "grounding_specificity_rationale": "The reviewer is asking a general question about a common practice in research (statistical significance testing) rather than specifically pointing to a particular section, table, or figure in the paper. Therefore, the grounding is weak. However, the topic of statistical significance is a specific area of research, making the specificity somewhat present.", "verifiability_rationale": "The reviewer is asking a question, not making a claim. Questions, by their nature, do not provide verifiable information in the same way a statement of critique or suggestion would. The answer to the question would be verifiable, but the review itself doesn't contain verifiable content.", "helpfulness_rationale": "The reviewer's question is relevant to the authors' work, as it pertains to the rigor of their comparison with baselines. However, it is a general question about a standard practice and does not directly critique the authors' methods or suggest a specific improvement. It lacks the directness and specificity of a helpful critique."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the paper's focus on learning HMMs with nonparametric emission distributions and clearly identifies the missing link regarding the impact of these distributions on inference. They also ask for clarification on specific inference tasks (filtering, smoothing, marginal likelihood). This provides clear directions for improvement.", "grounding_specificity_rationale": "The reviewer accurately identifies the paper's focus on nonparametric emission distributions and the impact on inference. They also ask for clarification on specific inference tasks, indicating a clear understanding of the relevant concepts. The request for clarification implies a strong grounding in the paper's content.", "verifiability_rationale": "The reviewer poses a question seeking information about the computational aspects of NPSPECHMMs, implying that this information is not readily available or wellknown. While the request for clarification suggests an awareness of potential lack of verifiability, the specific question and the focus on NPSPECHMMs indicate a degree of verifiability through further explanation or context within the paper.", "helpfulness_rationale": "The reviewer has identified a clear area for improvement in the paper (the impact of emission distributions on inference) and has provided specific suggestions for addressing it. They are not just pointing out a problem but also suggesting a path forward. This makes the review 5 for the authors."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "4", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a lack of analysis *why* the poor performance occurred, which is an explicit suggestion for improvement. However, the reviewer does not specify *what* kind of analysis would be beneficial, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'the scope prompting method' and 'GPT3.5turbo', which are specific aspects of the experimental setup and the model used. While they don't explicitly point to a specific section, the terms are specific enough to identify the area of concern. The reviewer also clearly specifies what needs to be analyzed (the underlying reasons for poor performance).", "verifiability_rationale": "The reviewer makes a statement about the analysis being insufficient and provides an example. This statement itself does not contain a claim that requires verification in the sense of logical reasoning or external references. It's more of a constructive suggestion for improvement.", "helpfulness_rationale": "The reviewer points out a genuine weakness in the analysis and suggests a concrete direction for improvement (further analysis of results). This feedback is likely to be beneficial for the authors, as it highlights a gap in their analytical process and encourages them to engage more deeply with their experimental results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action of 'remove the unnecessary explanation' and provides a clear reason ('the main result is about polytopes, not lowrank factorization'). This makes the action very direct and actionable.", "grounding_specificity_rationale": "The reviewer refers to 'the lowrank factorization' mentioned in the introduction, which can be identified as a specific part of the paper. They also explain why this explanation is unnecessary based on the paper's focus on polytopes, providing a clear reason for the grounding.", "verifiability_rationale": "The reviewer makes a claim ('the motivation in the introduction with the lowrank factorization is unnecessary') and provides a clear reasoning ('given a direct action') and a supporting statement ('the main result is about polytopes'). This reasoning directly supports the claim, making it 5.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion ('remove the unnecessary explanation') based on a wellsupported observation ('the main result is about polytopes, not lowrank factorization'). This feedback is directly helpful for improving the clarity and focus of the paper."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "Not Verifiable", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about a specific implementation detail ('Which method?'). While it points to a potential area for improvement (the lack of specificity in the method description), it doesn't directly instruct the author on what the method is. The reviewer is implicitly asking the author to identify the specific alternating direction method used.", "grounding_specificity_rationale": "The reviewer provides a brief description of the method's purpose ('an alternating direction method is used to solve the minmin problem'). This description, while not a direct section name, strongly suggests a specific section or paragraph where this implementation is discussed. It's likely the reviewer is referring to a particular part of the paper based on the context of the method and the problem it addresses. However, they don't explicitly name the section, table, or figure.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking a question ('Which method?'). There's no assertion of what the method is or why it's relevant. It's a request for information, not a statement of fact or a claim needing justification.", "helpfulness_rationale": "The reviewer is asking for information that could be valuable for the author. By mentioning the alternating direction method and the minmin problem, they are implicitly suggesting that the author's description of the method might be lacking in specificity. This question encourages the author to provide more details, which could improve the clarity and reproducibility of their work. While it doesn't directly tell the author what the method is, it prompts them to be more precise."}
{"actionability_label": "3. 3", "grounding_specificity_label": "1. 1", "verifiability_label": "X", "helpfulness_label": "5. 5", "actionability_rationale": "The reviewer points out a potential lack of novelty in using linear models to interpret DNN predictions. While this points to a limitation of a specific technique, it doesn't explicitly suggest a concrete action or improvement for the author. The statement is clear about the limitation but lacks specific guidance on how to address it.", "grounding_specificity_rationale": "The reviewer's point about the limited novelty is 1 in a specific part of the paper. They are making a general statement about the approach without referencing a particular section, table, figure, or unique aspect of the paper. The mention of 'linear model' is a general term and doesn't pinpoint a specific section or element being discussed in the paper.", "verifiability_rationale": "The reviewer's point about the limited novelty is not a claim that requires verification. They are stating an observation about the approach without making a specific assertion that needs to be supported by evidence or references. The statement is a general observation, not a claim.", "helpfulness_rationale": "The reviewer's point about the limited novelty is 5. It informs the author about a potential lack of contribution from their method and can guide them to explore more innovative approaches or focus their efforts on areas where their method might still be valuable. This information is directly relevant to the author's work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the desired improvements: 'more comprehensive and general' experiments. It also specifies the limitations of the current setup: 'model size is limited' and 'baselines are restrictive'. This provides clear and direct instructions on how the authors should adjust their work. The actions are not only explicit but also concrete, detailing the specific aspects that need improvement.", "grounding_specificity_rationale": "While the review point addresses specific tasks (language modeling and image classification), it does not pinpoint a specific part of the experimental setup or results within those tasks. It refers to the tasks generally, stating that the 'model size is limited' and 'baselines are restrictive' without specifying which experiment or baseline is lacking specifics. Therefore, the grounding is weak as the authors cannot confidently determine the exact area needing improvement. However, the point does specify the *nature* of the limitations (model size, baselines), adding a degree of specificity.", "verifiability_rationale": "The review point contains a claim: 'the experiments should be more comprehensive and general'. This claim is supported by stating the current limitations: 'the model size is limited' and 'the baselines are restrictive'. While the point doesn't provide specific examples of what constitutes a 'more comprehensive' or 'more general' baseline, it offers a logical reasoning for the suggestion, implying the need for more diverse models and comparisons. The verifiability is somewhat lacking as it doesn't point to specific external references or detailed justifications for the suggested improvements.", "helpfulness_rationale": "The review point is 5 as it clearly identifies a need for improvement in the experimental setup. It provides specific areas for enhancement, such as 'more comprehensive' and 'more general' experiments, and names the specific limitations: 'model size is limited' and 'restrictive baselines'. This actionable feedback empowers the authors to focus their efforts on expanding their experimental scope and comparisons. The suggestions are directly linked to potential weaknesses, making it a valuable piece of feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly suggests adding an optimization based metalearning approach to Table1, which is a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'Table1' as the location for the potential addition, indicating some grounding. However, they do not specify how the optimization based metalearning approach would be integrated or what modifications would be needed, making the grounding not fully specific.", "verifiability_rationale": "The reviewer makes a claim about the possibility of adding a metalearning approach to Table1 but does not provide any evidence, reasoning, or references to support this claim, making it 1.", "helpfulness_rationale": "While the reviewer points to a specific location (Table1) for potential improvement, they do not provide any details about why this would be beneficial or how the integration would work, making the feedback less concrete and helpful."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of an ablation study and suggests investigating the prompt choice, making the action somewhat explicit but not fully explicit about the specific prompt.", "grounding_specificity_rationale": "The review point discusses a general issue (lack of ablation study) rather than a specific part of the paper, making it fully grounded in the idea of an ablation study but underspecific about the prompt.", "verifiability_rationale": "The review point identifies a problem (lack of ablation study) and suggests a potential solution (investigating prompt choice), making it 3. However, it lacks supporting evidence or justification for the suggested approach.", "helpfulness_rationale": "The review point directly addresses a clear weakness (lack of specific ablation study) and offers a constructive suggestion for improvement by pointing towards investigating the prompt choice, making it 5."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a potential issue with the use of 'causal mechanisms' but does not explicitly state what needs to be changed or how to apply the suggested improvement. The reviewer is implicitly suggesting that the authors should be careful to distinguish between causality and temporal relationships. While the comment points out a potential problem, it lacks concrete steps or explicit instructions on how to correct the terminology. Therefore, it is implicit and vague.", "grounding_specificity_rationale": "The comment is 1 as it does not specifically point to a particular part of the paper or methodology. It is a general critique about the potential misuse of terminology. The comment is also somewhat vague as it does not specify *why* the distinction between causality and temporal relationships is important in the context of 'causal mechanisms'.", "verifiability_rationale": "The comment does not contain a claim in the sense of a statement that requires verification or justification. It is a suggestion for improvement in writing style. While it points out a potential issue, it does not present a claim that needs to be supported by evidence or logical reasoning.", "helpfulness_rationale": "The comment is helpful in that it points out a potential area for improvement in the authors' writing and encourages them to be more precise in their terminology. It highlights a common pitfall in scientific writing and suggests a way to avoid it. While it doesn't provide a specific solution, it prompts the authors to reflect on their language and consider the distinction between causality and temporal relationships. This feedback can empower the authors to improve the clarity and rigor of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's statement is explicit. They are directly stating a result of replacing procedure steps with a random mechanism. The implication is that the procedure steps might not be as effective as claimed, or that the algorithm's performance relies heavily on chance.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"XAIFOOLER\" and \"procedure steps.\" This is a clear identification of the specific part of the paper being addressed. They are not making a general statement about the algorithm.", "verifiability_rationale": "While the reviewer states a claim: \"replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance\" and infers \"I'm unsure that 'better than random' is a strong demonstration of capability.\" they do not provide any direct evidence or references within the given review point to support this claim.", "helpfulness_rationale": "The reviewer is pointing out a potential flaw in the methodology or implementation of the XAIFOOLER algorithm. They are suggesting that a simple random mechanism could perform better than the proposed procedure steps, at least in some cases. This is a valid concern that could impact the perceived effectiveness of the algorithm. While the reviewer doesn't offer a direct solution, they highlight a specific area that needs investigation, which can be helpful for the authors to understand a potential limitation of their algorithm."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states they would like a discussion of a specific paper and a specific concept from that paper. This is a clear and direct action. The reviewer is not leaving ambiguity about what needs to be done. The action is also concrete as the reviewer specifies the exact paper and the concept within it.", "grounding_specificity_rationale": "The reviewer explicitly mentions a specific paper ('On the Complexity of Learning with Kernels') and a specific area of research within that paper ('kernel learning using lowrank approximation'). This provides strong grounding as the authors can directly identify the referenced part. The reviewer also specifies what is missing \u2013 a discussion of this specific theoretical result. The comment details what needs to be addressed in this part.", "verifiability_rationale": "The reviewer is not making a claim that something is wrong with the paper. They are suggesting a discussion of related work. Therefore, there is X to verify. The comment is a suggestion, not a statement that requires evidence.", "helpfulness_rationale": "The reviewer's suggestion to discuss related work is 5. It directly addresses a potential weakness in the paper (lack of connection to existing theoretical results) and provides a clear direction for the authors to improve their work. It is a constructive suggestion that empowers the authors to better understand and contextualize their research."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point primarily focuses on the limitations and assumptions of the proposed method (PCA for reducing interaction count) rather than directly addressing an actionable issue the author might be facing. While the reviewer raises valid concerns about the incremental novelty and the need for justification of PCA assumptions, the point doesn't explicitly state what the author should do next. The reviewer asks questions and requests clarification, which can be helpful, but doesn't provide a clear, direct action for the author to take.", "grounding_specificity_rationale": "The review point does not explicitly mention any specific part of the paper (e.g., 'Section 3.2', 'Figure 4') or detail what is unclear about it. The reviewer is more focused on the general limitations of the method and the assumptions involved. Therefore, the grounding is weak as the reviewer doesn't pinpoint a specific area within the paper that needs clarification.", "verifiability_rationale": "The review point raises concerns about the assumptions of PCA but doesn't provide any external references or specific examples to support these claims. The reviewer suggests looking at a specific paper (1) related to deep neural network explanations, indicating a lack of immediate verification or connection to existing literature. The point is more of a question and a request for information rather than a statement that can be directly verified.", "helpfulness_rationale": "The review point raises valid concerns about the novelty and significance of the work and points to potential areas for improvement (verifying PCA assumptions, providing more robust explanations). However, it doesn't offer concrete, actionable steps for the author to take based on these concerns. The reviewer is asking questions and requesting clarification, which can be helpful for the author's understanding, but it doesn't directly guide the author on how to improve their work or address the identified limitations."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states an action: 'Compare the performance of the current models with relation extraction/generation models in fewshot settings.' However, the specifics of this comparison are not detailed, making it less concrete.", "grounding_specificity_rationale": "The reviewer mentions 'relation extraction/generation models' generally, which is a category of models rather than a specific section, table, or unique element of the paper. This indicates weak grounding.", "verifiability_rationale": "The reviewer claims the models are 'not stateoftheart' and suggests a comparison, but provides no evidence or justification for this claim. The reasoning behind this suggestion is also not explained.", "helpfulness_rationale": "While the reviewer raises a valid point about comparing with stateoftheart models and relation extraction/generation models, the lack of specificity and the absence of supporting evidence make the suggestion vague and potentially unhelpful for the authors. The authors would not know exactly how to carry out this comparison or how it would benefit their model."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'no results were shown' and asks 'what was observed.' This is an implicit action, as they are inferring the need for results. The action of 'speaking about what was observed' is also vague, as the reviewer doesn't specify what they were looking for or what the results might have been. The lack of a concrete next step makes this 1.", "grounding_specificity_rationale": "The reviewer mentions 'the discussion of using sequential MCB vs a single MCT layers for the decision head,' which clearly identifies a specific part of the paper. However, the comment does not specify what was observed or why it was important. The reviewer is pointing out a missing result or a lack of clarity regarding that specific aspect, but they are not detailing the specifics of the observation within that context. While they identify the part, they don't fully ground the criticism within that specific part. Therefore, it is weakly grounded but specific.", "verifiability_rationale": "The reviewer states 'no results were shown' and 'what was observed.' This is a statement of observation, not a claim that needs verification. They are noting the absence of results and the lack of discussion about them. There is no external evidence being referenced to support this observation. Therefore, it is not a verifiable claim.", "helpfulness_rationale": "The reviewer is asking for more information about the comparison between sequential MCB and a single MCT. While this is a valuable request for clarification and more data, it is not a direct action the authors can take based on this review. The reviewer is not stating a problem that needs solving, but rather asking for more context and results. Therefore, it is 3 in providing direction, but not a direct call to action. It's helpful in the sense that it points to a potential area for improvement, but it's not a clearly stated problem that needs immediate resolution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states they are unsure *why* 20 distribution sets were chosen, indicating a lack of clear reasoning. The action of understanding this choice is vague as the *how* is missing.", "grounding_specificity_rationale": "The reviewer *mentions* the number 20 but doesn't specify *which* choice it refers to or connect it to a specific part of the paper. The grounding is weak because the referenced part is unclear.", "verifiability_rationale": "The reviewer makes a claim about the unclear choice of 20 distribution sets but provides no evidence or reasoning to support this claim. The verifiability is low because there's no justification for the statement.", "helpfulness_rationale": "The request for clarification is helpful in understanding the current setup, but it doesn't directly provide actionable feedback on how to improve the draft. The helpfulness is moderate because it addresses a potential source of confusion but doesn't directly guide improvements."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem with the perplexity experiments, identifying the use of obsolete language models (ngram HMM, RNN) as the issue. They then clearly state their suggestion to use transformerbased models. This constitutes an explicit action that is directly related to the identified problem.", "grounding_specificity_rationale": "The reviewer mentions 'perplexity experiments' generally but does not specify which part of the paper or section this refers to. They do not provide any literal mentions of specific sections, tables, figures, or unique elements of the paper. Therefore, the grounding is weak as the authors cannot precisely identify the referenced part.", "verifiability_rationale": "The reviewer claims that transformerbased models are better for perplexity evaluation. However, within the review point itself, there is no justification provided for this claim. The reviewer is stating an opinion about what is better, but not providing any logical reasoning, examples, or references to support this assertion within the review point.", "helpfulness_rationale": "The reviewer provides a clear and relevant suggestion directly related to the methodology of the perplexity experiments. They identify a potential weakness (use of obsolete models) and offer a relevant alternative (transformer models). This is a 5 and constructive suggestion that directly benefits the authors by improving the alignment of their work with current NLP trends."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the difficulty in estimating mu, which is a concrete piece of information for the authors. They know what the problem is.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'mu, but as it is the proportion of missing observations,' which grounds the comment. However, the comment does not specify how to estimate it.", "verifiability_rationale": "The reviewer states a fact ('it is not wholly clear how it can be estimated at all') but does not provide any supporting evidence or references.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the methodology (difficulty in estimating mu) but does not offer any suggestions or solutions, making it 3 but not fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'It would be possible to get highprobability bounds?'. However, it lacks concrete details on how to achieve this. The reviewer suggests using ensemble methods, which implies a specific technique, but the comment doesn't elaborate on the steps or considerations involved in implementing this. Therefore, while the action is stated, the lack of detail makes it somewhat vague and incomplete in terms of how to apply it.", "grounding_specificity_rationale": "The comment does not explicitly refer to any specific part of the paper. It is a general suggestion about the nature of the bounds. Therefore, it cannot be grounded to a specific section, table, figure, or unique aspect of the paper. The comment is highly unspecific.", "verifiability_rationale": "The comment identifies a weakness in the current work (only bounds in expectation are provided) and suggests a way to address it (using ensemble methods). This constitutes a claim that is verifiable by attempting to implement the suggested method and observing the resulting bounds. The suggestion is based on existing experimental practices, providing a basis for verification. Therefore, the claim is verifiable based on the reviewer's suggestion and understanding of the field.", "helpfulness_rationale": "The comment identifies a limitation in the current work (only bounds in expectation) and offers a concrete suggestion for improvement (using ensemble methods to obtain highprobability bounds). It also suggests ways to better understand the robustness of the results (measuring error bars or standard deviation). These suggestions directly address the need for the author to improve their draft by providing actionable steps. The reviewer is not just pointing out a problem but also offering a path towards a better solution. Therefore, the review provides clear guidance on how to improve the author's work."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'there is no diversity' and suggests the model *should* enforce diversity. This is a clear indication of an actionable issue. While the reviewer doesn't specify the *how*, the *what* (lack of explicit diversity) is clear and actionable. The reviewer knows what they want (explicit diversity enforcement) and knows what is currently present (lack of explicit diversity).", "grounding_specificity_rationale": "The reviewer mentions the title contains 'diversity' and the paper 'motivates' diversity extensively. This strongly links the criticism to the *entire paper* dealing with diversity. While the reviewer doesn't pinpoint a specific section or table, the context is clear. The reviewer is referring to the paper's content and motivation related to diversity, making the grounding quite explicit, although not as precise as 'fully grounded'.", "verifiability_rationale": "The reviewer states 'there is no diversity' and 'I was all excited to see how the authors managed to get the diversity term into their model'. These are statements of fact, not opinions or suggestions that require verification. The reviewer is reporting their expectation and the actual outcome, but there's X being made that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer clearly identifies a significant issue (lack of explicit diversity enforcement) that they anticipated seeing. This is likely to be a valuable piece of feedback for the authors, as it directly relates to their stated motivation. While the lack of specificity on the *how* might make it '3,' the core issue is welldefined and actionable enough to be considered '4.' The reviewer's excitement highlights the relevance of the comment to the authors' work."}
{"actionability_label": "1", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point states 'some experiments are missing\" and provides examples. While it identifies a gap, it doesn't explicitly tell the authors what to do with this information. The authors still need to determine which experiments to add, how to add them, and why these specific types of experiments are important for their work.", "grounding_specificity_rationale": "The review point mentions 'some experiments\" generally and then provides examples of the types of experiments that are missing. While it grounds the type of experiment, it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper where these experiments are supposed to be added. Furthermore, it doesn't explain why these specific types of experiments are missing or beneficial.", "verifiability_rationale": "The review point states 'some experiments are missing\" and provides examples. This is a statement of fact about the current draft, not a claim that requires verification. It describes a gap or a potential area for improvement, but it doesn't make a definitive statement that needs to be proven.", "helpfulness_rationale": "The review point identifies a valid weakness in the draft (missing experiments) and even suggests potential improvements (contrastive and adversarial learning). However, it doesn't provide concrete guidance on how to address this weakness. The authors still need to figure out which missing experiments to add, how to implement them, and why these specific types of experiments are crucial for their research. It's a pointer to potential improvements, but lacks a detailed roadmap."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a gap between the lower and upper bounds, suggesting an improvement using the independence number. While it points towards a potential action, it doesn't explicitly state the action or how to implement it. The suggestion is implicit.", "grounding_specificity_rationale": "The review point mentions 'graphs' and 'results' generally, without specifying a particular part of the paper or methodology. The suggestion of using the 'independence number' is a general idea, not a specific improvement to a defined section. Therefore, it's 1 in a specific aspect of the work.", "verifiability_rationale": "The review point states a discrepancy between the bounds and suggests an 'independent improvement.' While it implies a potential justification, it doesn't provide specific evidence, references, or logical reasoning to support why the independence number might be better. The claim is present but lacks strong backing.", "helpfulness_rationale": "The review point identifies a significant issue (the gap between bounds) and offers a concrete suggestion (using the independence number) to potentially address it. This feedback is directly aimed at improving the understanding of the bounds and offers a clear direction for improvement. The 'other remarks' further suggest a constructive idea. Therefore, the review point is 5 in guiding potential improvements."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a discrepancy in the experimental results, which is a clear indication of a need for investigation. While the reviewer doesn't explicitly state an action or a concrete suggestion, the observation itself is a form of actionable insight. The reviewer identifies a potential problem and asks a question about it, which can guide the authors to explore further. However, the reviewer doesn't provide a specific step the authors should take to address this issue.", "grounding_specificity_rationale": "The reviewer points out a discrepancy in the experimental results, which is a general observation about the complete loss function performing worse than those with missing terms for CUB and SOP datasets. The reviewer does not explicitly identify a specific part of the paper or methodology being addressed. The comment is about the overall performance of different loss functions on specific datasets. Therefore, the grounding is weak as the reviewer doesn't pinpoint a specific section, table, or figure.", "verifiability_rationale": "The reviewer's point is based on the experimental results presented in Table 2. The reviewer makes a claim about the performance of different loss functions on specific datasets. This claim is verifiable as it is based on the data presented in the table. The reviewer states a fact about the observed results, which can be supported by the data in Table 2. The reviewer provides a logical reasoning by stating that the results are unexpected and contradict the expected behavior of the loss functions.", "helpfulness_rationale": "The reviewer's point is a valuable observation about the experimental results. It highlights a potential issue with the complete loss function and its performance on specific datasets. This observation can guide the authors to investigate further and potentially identify the cause of the poor performance. The reviewer's question about why this happens is a direct request for explanation and clarification, which is a helpful feedback point for the authors. The reviewer provides a clear and actionable question that the authors can use to guide their investigation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the type of experiment (occlusion) and the purpose (simulating irregularity and inspecting inference capacity). They also provide specific details about the occlusion (half of the image, random) and the rationale behind the request. This indicates a clear and direct action the authors should take.", "grounding_specificity_rationale": "The reviewer explicitly mentions the type of data (neural/behavioral data, keypoint detection) and the specific aspect of the data that needs addressing (frames with failed detection). They also provide a clear description of the issue and the reason for the request. This demonstrates strong grounding of the specific problem they are addressing.", "verifiability_rationale": "The reviewer makes a clear claim that the authors should include specific experiments. They also provide a logical rationale for this recommendation, explaining the benefits of these experiments in simulating irregularity and inspecting inference capacity. This justification makes the claim verifiable.", "helpfulness_rationale": "The reviewer directly asks for specific experiments and their purpose, which is a clear and direct request. The suggested experiments are relevant to the stated goals and are likely to be helpful for the authors. The reviewer's suggestion is constructive and addresses a specific need."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "3", "helpfulness_label": "High", "actionability_rationale": "The reviewer explicitly states the comment asks for clarification on a specific part of the abstract: \"what does this mean? The abstract should be more highlevel. Such technicalities are not necessary.\" This directly points to a need for the authors to understand a particular aspect of their work. The reviewer also identifies the unclear part: \"with a lowrank feature subspace, a small number of attacked samples, and other mild assumptions.\" This makes the request concrete and actionable.", "grounding_specificity_rationale": "The reviewer identifies the specific area of the abstract that needs clarification: \"with a lowrank feature subspace, a small number of attacked samples, and other mild assumptions.\" While they don't provide the exact section number, they clearly point to a specific phrase within the abstract. This can be considered 'Full Grounding' as they can accurately pinpoint the referenced part. The reviewer also specifies the *nature* of the unclear information, which adds to the specificity.", "verifiability_rationale": "The reviewer identifies a weakness in the abstract: the unclear technical terms and assumptions. This constitutes a claim that needs to be addressed. While the reviewer doesn't provide a direct external reference, their suggestion to make the abstract 'more highlevel' implies a lack of explanation for these technical terms and assumptions, making it 3. The logical reasoning here is that a more highlevel abstract would be easier to understand without needing to delve into the technical details.", "helpfulness_rationale": "The reviewer provides a clear and specific request for clarification on a particular part of the abstract. They identify the exact unclear section and suggest a concrete improvement: making the abstract more highlevel. This is a direct and actionable feedback that empowers the authors to improve their work. The suggestion to avoid 'technicalities' is also very helpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The suggestion is not explicit or concrete. It lacks specific details on which modalities, methods, or experiments are needed.", "grounding_specificity_rationale": "The point doesn't pinpoint any specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The point is a suggestion, not a declarative statement requiring justification.", "helpfulness_rationale": "The suggestion is relevant and points towards improvement, but it lacks specific details, making it less impactful than a more concrete comment."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the paper defines a fewshot situation but doesn't explain how the proposed method effectively utilizes it. They also state that the method doesn't guarantee generalization. This is an explicit action pointing out a clear gap in the paper's explanation.", "grounding_specificity_rationale": "The reviewer mentions 'how to leverage a few instances to learn a generalizable model' and 'how to guarantee the trained model can be generalized well to new tasks with 0/few training steps', which are general concepts related to the paper's topic. However, the paper doesn't explicitly state which part of the paper addresses these points, making the grounding weak. The reviewer also points out the lack of explanation regarding the use of fewshot learning and the guarantee of generalization, which is specific to the identified gaps. However, the paper doesn't explicitly mention these as gaps, making the grounding somewhat ambiguous.", "verifiability_rationale": "The reviewer makes a claim: 'the proposed method does not consider how to effectively use \u201cfewshot\u201d and how to guarantee the trained model can be generalized well to new tasks with 0/few training steps.' This claim is not supported by any evidence or justification within the review point itself. The reviewer states the lack of these aspects without providing reasons or examples.", "helpfulness_rationale": "The reviewer provides a clear and actionable criticism. They highlight specific areas where the paper falls short (lack of explanation of fewshot usage and generalization) and suggest improvements (addressing these points). This is a helpful critique as it directly points to concrete weaknesses and provides direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states the GP usage is 'kind of straightforward and naive' and mentions 'dynamical modeling' and 'Gaussian Process Dynamical Model' without explicitly stating what is meant by 'naive' or how the GP is currently being used. While it implies a lack of sophistication, it doesn't provide concrete steps for improvement. The reviewer suggests considering more advanced models, but doesn't specify which aspects of the current GP usage need improvement or how to achieve this. The comment identifies a potential area for improvement but lacks specific guidance on how to implement it.", "grounding_specificity_rationale": "The comment does not explicitly identify which part of the paper or the author's work it is referring to. It makes a general statement about the GP usage being 'straightforward and naive' without specifying which aspect of the GP implementation or the context in which it is used. The reviewer mentions 'dynamical modeling' and 'Gaussian Process Dynamical Model' but doesn't connect these to a specific element of the author's work. The comment lacks a clear link to a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The comment presents a statement about the GP usage being 'naive' and mentions 'dynamical modeling' and 'Gaussian Process Dynamical Model'. However, it does not explicitly state a claim that requires verification. While it points out a potential improvement area, it doesn't provide any logical reasoning, common knowledge, or external references to support the claim that the GP usage is naive or that specific models like GPDMs are relevant. The comment is more of an observation and a suggestion for improvement rather than a claim that needs to be verified.", "helpfulness_rationale": "The comment suggests that the GP usage is 'naive' and recommends considering 'dynamical modeling' and 'Gaussian Process Dynamical Model'. While this points to a potential area for improvement and suggests a more sophisticated approach, it lacks specific details on how to implement these changes or what benefits they would bring. The reviewer doesn't provide concrete steps or examples of how the author should incorporate these advanced models. The comment is more of a constructive suggestion but lacks the specific guidance needed to be immediately helpful to the author."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the problem ('the differential privacy application is a bit too 'halfbaked'') and suggests an improvement ('I would encourage the authors to think through it more clearly'). While the action is somewhat implicit (they aren't *telling* the authors what to do), it's a clear direction for improvement. Therefore, it's *3*.", "grounding_specificity_rationale": "The reviewer refers to '2)5)' which likely points to specific earlier points in the paper. Assuming the authors can identify the relevant section, the grounding is considered *fully grounded*. The specific issue ('the differential privacy application is a bit too 'halfbaked''') is clear and specific within that section.", "verifiability_rationale": "The reviewer does not make a claim about what *should* be in the paper. They are offering feedback and encouragement. Since there's no explicit claim being made and verified, the verifiability is low.", "helpfulness_rationale": "The reviewer identifies a problem ('the differential privacy application is a bit too 'halfbaked''') but doesn't explicitly *say* what needs to be changed or *why* it's a problem. They offer encouragement, which is positive, but lacks concrete guidance. It's a direction, but not a fully formed suggestion with justification."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "Not Verifiable", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a concern about the generality of 'robotic manipulation' and suggests 'bimanual manipulation' as a more specific scope. This indicates a clear action: the authors should consider whether their work falls under bimanual manipulation and adjust accordingly. While the suggestion is clear, it might lack specific details on how to implement this change or what aspects of the work are bimanual.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'bimanual manipulation' as the specific type of robotic manipulation. This clearly grounds the suggestion in a specific aspect of the paper. The suggestion is also very specific, indicating a high level of grounding specificity.", "verifiability_rationale": "The comment does not contain a claim that needs verification. It's a suggestion for improvement. Therefore, it doesn't fit into the verifiability categories.", "helpfulness_rationale": "The reviewer directly points out a potential issue (lack of specificity in the methodology) and offers a concrete solution (suggestion to use 'bimanual manipulation'). This is a clear and actionable piece of feedback that can help the authors improve their work. While it doesn't provide a specific 'howto' for the change, it identifies a meaningful area for improvement and offers a direction."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests providing METEOR results. While the action of 'providing' is explicit, the aspect of how to provide these results is not specified. The reviewer does not detail whether they should be included in the paper, supplementary material, or a specific table. Therefore, while the action is stated, the lack of detail makes it less actionable.", "grounding_specificity_rationale": "The reviewer suggests providing METEOR results. However, the review point does not specify *where* these results should be provided. There is no mention of a specific section, table, figure, or unique aspect of the paper that necessitates the inclusion of METEOR results. The reference 15 is vague and does not pinpoint a specific location or aspect.", "verifiability_rationale": "The reviewer makes a suggestion: 'You should provide the METEOR results, which is also reported in recent works 15.' This is a claim that METEOR results should be provided. However, the review point does not offer any justification or reasoning for *why* this is a necessary or beneficial suggestion. There is no logical explanation or reference to external works that supports the suggestion itself.", "helpfulness_rationale": "The review point suggests providing METEOR results. While this is a relevant suggestion as METEOR is a standard evaluation metric, the lack of actionability and verifiability makes the comment less helpful. The reviewer does not specify *how* the authors should provide these results, nor does the review point offer any justification for why the authors should follow this suggestion. Therefore, the authors are aware they need METEOR results, but the comment does not guide them on how to obtain or use them effectively."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "3 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "2 (2)", "actionability_rationale": "The reviewer points out a *lack* of discussion on the implications of AutoML findings for future architecture design. While they identify a weakness, they don't provide specific actions or suggestions for the authors to take. The reviewer asks 'what might be the biggest takeaways,' which is a question prompting further information, not a concrete action.", "grounding_specificity_rationale": "The reviewer mentions 'AutoML approaches' and 'design of new network architectures' as areas where the authors could benefit. However, they do not explicitly identify a specific part of the paper being addressed. While they mention these areas, they are general and not tied to a specific section, table, or figure. The reviewer also asks for 'specific takeaways,' indicating a lack of concrete information about what the authors should expect or do.", "verifiability_rationale": "The reviewer makes a statement about the authors not spending much time commenting on the implications of AutoML. This statement can be considered a claim. However, the reviewer does not provide any evidence or justification to support this claim. They state it as a fact without backing it up with logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer identifies a valid area for improvement in the paper \u2013 the lack of discussion on how AutoML findings can inform future architecture design. They provide a clear *desire* for more information. However, the lack of *actionability* and *grounding specificity* means the reviewer's suggestion isn't actionable for the authors. They know *what* to discuss but not *how* to do it. The request for 'specific takeaways' is a good starting point but lacks concrete direction."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'can be more concise' and 'including empirical results'. These are direct actions. However, the reviewer does not specify *which* parts of the introduction to make more concise or *which* empirical results are needed. The action is stated, but the specifics are missing, making it not fully actionable.", "grounding_specificity_rationale": "The reviewer refers to the 'main part' and 'introduction part' generally. While they *mention* the introduction, they don't pinpoint a specific section, table, figure, or unique element within it. The grounding is weak because the referenced part is not accurately identified.", "verifiability_rationale": "The reviewer makes a claim: 'The main part can be more concise (especially for the introduction part)and including empirical results.' This is a statement of opinion or suggestion. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The claim is presented without sufficient evidence, making it 1.", "helpfulness_rationale": "The reviewer provides feedback on the need for conciseness in the introduction and the inclusion of empirical results. While relevant, the feedback lacks specific actionable steps for the authors. The reviewer doesn't tell the authors *how* to make the introduction more concise or *what* kind of empirical results to include. The feedback is general and lacks concrete guidance, making it 3 but not very impactful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of using 'two typical games' and suggests 'more complex problems, especially when the game has bigger depth'. This is a clear and actionable suggestion for the authors to improve their draft.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'ReBeL's performance' and 'more complex problem' (including 'bigger depth'). This is a clear and specific reference to parts of the paper, indicating a strong grounding of the comment.", "verifiability_rationale": "The reviewer makes a claim that the experiments were limited to 'two typical games'. They then provide a justification by stating that 'the ReBeL's performance on more complex problem. Especially when the game has bigger depth which will cause huge inputs of the value and policy function.' This justification, while not a direct citation, provides a logical reasoning for the potential limitations.", "helpfulness_rationale": "The reviewer's comment is highly valuable as it points out a significant limitation in the experimental scope and offers a clear direction for improvement. By suggesting testing on 'more complex problems, especially when the game has bigger depth', the reviewer provides actionable feedback that can help the authors enhance the generalizability and robustness of their findings."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states their opinion about the triviality of improvements and the limited novelty, suggesting a specific type of change (adding topic entities). While the suggestion isn't fully detailed, it points towards a concrete area for improvement, making it 3.", "grounding_specificity_rationale": "The reviewer mentions 'improvements on different datasets' and 'adding topic entities,' indicating they are referring to specific parts of the paper. However, they do not specify which datasets or provide details about the topic entities, making the grounding weak.", "verifiability_rationale": "The reviewer makes claims about the triviality of improvements and the limited novelty but provides no evidence or reasoning to support these claims. The suggestion to add topic entities is offered without any justification.", "helpfulness_rationale": "The reviewer's comment is primarily critical, lacking concrete evidence to support their claims about the triviality of improvements and the limited novelty. While they offer a suggestion, it is not backed by any reasoning, making the review less helpful overall."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer states 'lacks discussion,' which is an explicit action (i.e., the paper doesn't have this discussion). However, they don't specify *what* should be discussed in this section, only the *topic* of the discussion (theoretical guarantee of the hierarchical strategy). Therefore, while the action is explicit, the lack of specificity makes it 3.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'theoretical guarantee,' 'approximation ratio,' 'hierarchical strategy,' and 'global optimal.' These terms clearly pinpoint the specific aspect of the paper being addressed. This indicates strong grounding as the authors can easily identify the referenced part of the paper and the specific issue.", "verifiability_rationale": "The reviewer makes a clear claim: 'The paper lacks discussion on the theoretical guarantee...'. This is a verifiable claim as the authors can then attempt to find or discuss this analysis. The claim is specific about the type of analysis and the missing element.", "helpfulness_rationale": "The reviewer points out a specific missing piece of analysis that could be relevant for readers interested in the theoretical underpinnings of the method. This is a valuable piece of feedback for the authors to understand the limitations of their approach and potentially improve it. While it doesn't directly tell them *how* to include the discussion, it highlights a relevant gap."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the 'lack of quantitative measure' as a problem. While it doesn't provide explicit steps to fix it, it clearly identifies a deficiency. The suggestion to use 'quantitative measures' is an implicit action. However, the action of 'identifying the need for quantitative measures' is not detailed, making it somewhat vague on how to implement it. Therefore, it's not fully actionable but points towards a clear issue.", "grounding_specificity_rationale": "The review point mentions 'evaluation of generated VCEs' and 'quantitative measure' as key aspects. While it pinpoints the *purpose* of the evaluation, it doesn't specify a *unique* part of the VCE evaluation process or a *specific* aspect of VCEs that needs improvement. The focus is broad, and the type of quantitative measure is not defined. Therefore, the grounding is not precise enough.", "verifiability_rationale": "The review point makes a claim: 'reliance solely on visual inspection is insufficient for evaluating VCEs.' It provides some justification by stating the 'limitations of visual inspection' (lack of objectivity, subjectivity). While it doesn't explicitly cite external references, the logic is generally verifiable within the field of HCI/Eye Tracking. The claim is supported by logical reasoning and the common understanding of evaluation methods. Therefore, it's 5.", "helpfulness_rationale": "The review point clearly identifies a problem (lack of quantitative measures) and suggests a potential solution (quantitative measures). It's directly relevant to the evaluation of VCEs and points out the limitations of the current method. While it doesn't provide specific details on *what* quantitative measures to use, it highlights a significant gap in the evaluation process. Therefore, it's 5 in highlighting the need for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer states 'Only marginal improvements,' which is an explicit action, but it is vague as it doesn't specify *where* these improvements are or *how* they are achieved. The action is implicit in the sense that the reviewer is pointing out a lack of significant improvement, but the specifics are missing.", "grounding_specificity_rationale": "The reviewer's comment is 1 in a specific part of the paper. They are making a general statement about the overall performance of the method compared to baselines. There is no mention of a specific section, table, or figure. The specificity is also weak as they don't pinpoint what is 'marginal' or 'within the error bar range'.", "verifiability_rationale": "The reviewer makes a claim ('Only marginal improvements...'), but they do not provide any evidence or justification for this statement. They state the observation without explaining why these improvements are marginal or why the error bars are high. There are no logical reasoning, common knowledge, or external references provided to support this claim.", "helpfulness_rationale": "The reviewer's comment is not particularly helpful to the authors. They point out a limitation in the method's performance without offering any suggestions or guidance on how to address this limitation. The comment is more of a negative observation than a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out 'significant artifacts' in the generated videos and notes that 'action recognition performance is much below the current stateoftheart on the UCF dataset'. While the reviewer identifies a problem and suggests areas for improvement, the exact nature of the artifacts and the specific ways to improve the performance are not explicitly stated. The reviewer implies that the issue lies with 'generated videos' and 'action recognition', suggesting an action, but the precise steps are vague.", "grounding_specificity_rationale": "The reviewer mentions 'generated videos' and then narrows it down to 'generated videos, specifically the beach videos'. While they attempt to ground the issue, the term 'beach videos' is still somewhat vague and doesn't pinpoint a specific section, table, or figure within the paper. The reviewer also mentions 'action recognition performance' which is a general area, not a specific part of the paper. The grounding is present but not fully precise.", "verifiability_rationale": "The reviewer makes clear claims: 'The generated videos have significant artifacts' and 'The action recognition performance is much below the current stateoftheart on the UCF dataset'. These are statements that require justification. The reviewer provides some evidence by mentioning the visual quality of 'beach videos' and the performance gap on the UCF dataset. They also refer to 'deeper architectures' and 'optic flow' used in stateoftheart models, providing examples of external references. This comment is verifiable as it contains claims supported by logical reasoning and examples.", "helpfulness_rationale": "The reviewer identifies specific weaknesses in the generated videos and the action recognition performance. They suggest improvements like 'improving the quality of beach videos' and exploring 'deeper architectures' and 'optic flow'. While these suggestions are relevant and potentially helpful, they are somewhat general and lack specific details on how to achieve these improvements. The reviewer's feedback is focused on areas needing enhancement, making it potentially helpful but not fully constructive due to the lack of concrete steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states 'It is still unclear how to make the new proposed evaluation set more diverse and representative than the previous method'. This indicates an implicit action or suggestion that the authors should be able to infer from the comment. However, the reviewer does not explicitly state the steps or criteria for achieving this, making the action vague.", "grounding_specificity_rationale": "The reviewer mentions 'more diverse and representative' and 'select representative images' in the context of the proposed evaluation set. However, they do not explicitly identify the specific part of the paper or method this comment is referring to. The reference is general, making the grounding weak. While the reviewer specifies the desired properties (diversity, representativeness), the specific section or table within the paper being addressed is not clearly identified.", "verifiability_rationale": "The reviewer states 'It is still unclear how to make the new proposed evaluation set more diverse and representative than the previous method and how to select those representative images'. This statement is a claim about the lack of clarity regarding a specific aspect of the proposed evaluation method. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a fact of uncertainty without further explanation.", "helpfulness_rationale": "The reviewer clearly identifies a lack of clarity regarding the proposed evaluation method and its selection process. This is a direct and actionable point for the authors. The reviewer points to a specific area (the proposed evaluation set and the selection of representative images) and highlights a deficiency (lack of clarity). This provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'include a background section to introduce the basic RL framework'. It also provides a clear goal: 'to clarify the RL context being considered'. However, it lacks concrete details on *where* in the paper this background section should be placed or what specific aspects of the RL framework should be covered. The action is stated, but the implementation details are missing.", "grounding_specificity_rationale": "The comment explicitly mentions the need for a 'background section' and specifies its purpose: 'to introduce the basic RL framework' and 'to clarify the RL context being considered'. However, it does not identify a specific part of the paper where this section should be placed (e.g., 'introduce a section on MDPs' or 'provide background on policy learning'). The grounding is present in identifying the need for RL background, but the specific section is not pinpointed.", "verifiability_rationale": "The comment contains a claim: 'Without this, it is difficult to follow the subsequent sections'. The comment also provides supporting evidence: 'Additionally, a brief overview of the original DPO algorithm should be provided so that modifications proposed in the methods section are clearly distinguishable'. The claim is supported by stating the difficulty in following subsequent sections due to the lack of background and the need to understand DPO modifications.", "helpfulness_rationale": "The review point directly addresses a potential barrier to understanding the subsequent sections by highlighting the missing background on RL and DPO. It provides a clear suggestion for improvement: 'include a background section to introduce the basic RL framework' and 'provide background on the original DPO algorithm'. This is a concrete and actionable suggestion that could significantly improve the reader's comprehension of the paper."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential limitation but does not explicitly state an action or suggestion for the authors to take. It raises a concern about scalability, which is a potential action, but the point itself doesn't tell them *how* to address it or *what* to do. Therefore, it is 1.", "grounding_specificity_rationale": "The review point refers to 'new languages' in general, without specifying a particular section, table, figure, or unique aspect of the paper or method. It lacks precision in identifying the issue. Therefore, it is 1.", "verifiability_rationale": "The review point states a potential limitation but does not provide any evidence, justification, or reasoning to support the claim. It simply states that the method might have this limitation. Therefore, it is 1.", "helpfulness_rationale": "The review point raises a concern about the method's scalability to new languages. While it points out a potential issue, it doesn't offer any solutions or suggestions. It's more of a cautionary note than a constructive critique. Therefore, it is 3 as it highlights a potential problem that the authors might need to consider."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification on the relevance of a specific paper to their work. While the action is implied (the reviewer wants to understand the connection), the action itself is not explicitly stated or actionable. The reviewer needs to figure out how the DoshiVelez and Kim paper relates to their concept of 'interpretable'.", "grounding_specificity_rationale": "The reviewer explicitly mentions the DoshiVelez and Kim paper (\"DoshiVelez, F., & Kim, B. (2017).\") and the concept of \"interpretable machine learning\" in relation to their work. This clearly grounds the discussion in a specific section of the literature and a specific area of interpretability. The reviewer is also asking about the relevance, which specifies the aspect of the paper they are interested in.", "verifiability_rationale": "The reviewer is making a judgment that they need clarification on the relevance of the DoshiVelez and Kim paper to their concept of 'interpretable'. This constitutes a claim. The verifiability of this claim would depend on the authors' ability to consult the DoshiVelez and Kim paper and determine its direct relevance to their specific notion of interpretability. While the answer is likely to be found in that paper, the reviewer would need to perform this verification themselves.", "helpfulness_rationale": "The reviewer is asking for clarification, which is generally helpful for understanding the connections between different papers on interpretability. However, the question is quite broad and doesn't pinpoint a specific issue or weakness in the author's work. Therefore, while it provides some context, it is not the most direct or actionable form of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the similarity between the proposed method and the approach in 10 and poses a question about why the method in 10 cannot be equipped with scoring causal predictions and interventional data. This is a clear and direct statement of a point for discussion and a request for clarification.", "grounding_specificity_rationale": "The reviewer explicitly mentions '10' and the specific concepts 'scoring causal predictions' and 'interventional data' in relation to the method in 10. This indicates a clear and specific reference to elements within the cited work.", "verifiability_rationale": "The reviewer does not make a claim about the reviewed paper. They are asking a question about the capabilities of a related method. Therefore, it does not fit into the 'claim extraction' category, and there is no verifiability in the traditional sense of supporting a statement with evidence.", "helpfulness_rationale": "The reviewer's comment is likely to be helpful for the authors. By asking a question about the potential extensions or limitations of a related method, they are prompting a discussion that could be relevant to the development or understanding of the reviewed paper."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point does not specify any actionable steps for the authors. It identifies a limitation in the experimental setup but does not provide guidance on how to address it or what changes should be made to the draft.", "grounding_specificity_rationale": "The reviewer refers to 'the Atari game' and 'a single baseline' without specifying the exact game or baseline within Section 7.2. This makes the grounding weak as the authors cannot confidently determine which part of the paper is being addressed.", "verifiability_rationale": "The claim that the Atari game result is 'limited to a single game and a single baseline' and is 'very hard to interpret' is stated without providing any supporting evidence or justification. There are no logical reasoning, common knowledge, or external references to back up this claim.", "helpfulness_rationale": "The review point identifies a limitation in the experimental results but does not offer any suggestions or guidance on how to improve the draft or address the identified weakness. It is generally not helpful for constructive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the need for 'experiments on distributed deployment' and a 'larger model'. These are direct and concrete actions that the authors can take to improve their work. The reviewer is not inferring these actions but rather pointing them out as necessary steps.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or methodology. It broadly mentions 'distributed deployment' and 'a larger model' without specifying which section, table, figure, or unique element of the paper these relate to. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point contains a claim: 'The evaluation needs experiments on distributed deployment and a larger model.' However, this claim is not supported by any logical reasoning, common knowledge, or external references within the review point itself. It is a suggestion for future work, not a verifiable statement about the paper.", "helpfulness_rationale": "The review point suggests the need for 'experiments on distributed deployment' and a 'larger model'. While relevant, this is a suggestion for future research directions rather than direct feedback on specific weaknesses or areas for improvement in the current draft. It lacks the specificity and actionable steps needed to directly improve the authors' current work."}
{"actionability_label": "5", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly asks a question about the impact of larger word embedding and LSTM parameters. This is a direct and concrete request for information, making it 5 for the authors. The reviewer is inferring a potential issue with the original paper's parameter choices, but the request itself is clear and focused on a specific experiment.", "grounding_specificity_rationale": "The reviewer mentions the word embedding and LSTM size as key parameters in the original paper, providing some grounding by identifying the relevant components. However, they do not specify the exact values used in the original work. This makes the grounding somewhat weak as it relies on the reader's interpretation of 'much smaller'. The specificity is also low because the exact parameter values are not provided.", "verifiability_rationale": "The reviewer makes a claim about the original paper potentially using suboptimal parameter settings. This is a subjective opinion or judgment about the original work. While the reviewer provides a potential explanation for their belief, they do not provide any external references or logical reasoning to support this claim. The claim is not verifiable based on the information provided in the review point alone.", "helpfulness_rationale": "The reviewer's point is 5 as it directly addresses a potential weakness in the original paper's evaluation \u2013 the choice of smaller parameters. By suggesting an experiment with larger parameters, the reviewer provides a concrete and actionable direction for the authors to investigate and potentially improve their model's performance. The request is clear and directly relevant to the authors' work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer states their belief about the authors' motivation for regularization and the different regularization techniques used. While the reviewer doesn't explicitly ask the authors to *do* something, they suggest trying to reproduce previous model features, which is a clear next step for the authors to take. The reviewer's point is explicit about the inconsistency in the regularization approach.", "grounding_specificity_rationale": "The reviewer refers to the 'authors note' and the 'form of regularization' applied to the 'GLMs'. While not a direct reference to a specific section, the concepts are related to the paper's content. The reviewer also specifies the *type* of regularization applied to the LN models and the *believed type* of regularization used in the original Pillow et al. work for GLMs. This specificity helps the authors understand the issue more clearly.", "verifiability_rationale": "The reviewer makes a claim about the authors' motivation for regularization and the different regularization techniques used. They also provide information about what they believe the original Pillow et al. work used for GLMs. This claim is somewhat supported by the reviewer's understanding of the Pillow et al. methodology, although it's not definitively proven. The reviewer's point is based on logical reasoning and common knowledge about previous work.", "helpfulness_rationale": "The reviewer's point is 5. They identify a potential inconsistency in the authors' approach and suggest a way to improve the experimental design by aligning with previous work. This encourages the authors to investigate the original Pillow et al. methodology and potentially reproduce some of their features for a fairer comparison. The reviewer's feedback is constructive and directly addresses a potential weakness in the authors' methodology."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a missing element (inference time study) and suggests a reason for its absence (direct nature of the method) and a potential solution (comparing to other methods). While it could be more direct about the steps to take, it does provide a clear direction for improvement.", "grounding_specificity_rationale": "The review point discusses inference time and compares it to other methods generally. It does not specify a particular section, table, figure, or unique aspect of the paper or method that needs improvement.", "verifiability_rationale": "The review point contains a suggestion to compare inference speeds. However, it lacks a clear justification for why this comparison is important or provides specific examples of previous methods for comparison.", "helpfulness_rationale": "The review point highlights a valid limitation (missing inference time analysis) and suggests a relevant area for future work. While actionable, it doesn't directly critique the method or suggest a concrete fix, making its overall impact somewhat limited."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer states that the claim 'evolutional dropout addresses the internal covariate shift' is 'very limited' and suggests it *only increases the variance of lowvariance units*. While the reviewer identifies a potential nuance or limitation, the *action* isn't explicitly stated in the review itself. The reviewer *wants* the authors to discuss this more explicitly, but doesn't *do* it within the review text. Therefore, the actionable aspect is borderline.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'evolutional dropout', 'internal covariate shift', and then *specifically* discusses the limitations of evolutional dropout regarding variance and the role of batch normalization. This demonstrates a clear understanding of the relevant concepts and a specific focus on the claimed connection. The reviewer provides concrete examples of how the claim might be interpreted or limited.", "verifiability_rationale": "The reviewer provides *reasons* for their claim. They state that evolutional dropout *only increases the variance of lowvariance units* and that batch normalization *standardizes and centers the activation*. These are logical statements that, while not direct empirical evidence, are wellestablished concepts in the field. The reviewer's point is *verifiable* based on this understanding. The minor point about batch normalization's description is also verifiable as a factual observation.", "helpfulness_rationale": "The reviewer's comment is critical and points out a potential misunderstanding or oversimplification in the original text. By highlighting the limitations of evolutional dropout and suggesting a more nuanced discussion, they are providing valuable feedback that *should* be helpful for the authors to improve their understanding and the clarity of their work. The reviewer's suggestions for improvement are also actionable."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their preference not to show tentative attention maps in the qualitative figures. This is a clear and direct action that the authors can easily understand and implement.", "grounding_specificity_rationale": "The reviewer does not explicitly state which part of the paper they are referring to when mentioning 'qualitative figures'. While they are implying a preference for a specific type of visualization within those figures, the exact location or nature of the issue is not clearly defined.", "verifiability_rationale": "The reviewer's point is not a claim or suggestion but rather a statement of preference or an idea for improvement. There is no assertion of what is wrong or what should be done differently.", "helpfulness_rationale": "The reviewer suggests providing an alternative visualization for the attention maps. This is a constructive suggestion aimed at improving the analysis and presentation of the data. While it doesn't directly solve a specific problem, it offers a valuable improvement to the authors' toolkit."}
{"actionability_label": "2", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment suggests adding more description, which is an implicit action. It lacks specifics on *how* to add the description.", "grounding_specificity_rationale": "The comment refers to the 'contribution of this paper' broadly, without specifying a section, table, figure, or unique element. It doesn't explain *what* aspect of the contribution needs more description.", "verifiability_rationale": "The comment is a suggestion, not a claim requiring evidence. It doesn't state something is wrong or needs improvement in a way that demands verification.", "helpfulness_rationale": "The comment identifies a valid weakness (lack of detail about the contribution) and suggests an improvement (adding more description). However, the suggestion is vague and lacks specific guidance on *where* and *how* to add the description."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding 'missing supervised baselines' which is a direct and explicit action. However, it lacks specifics on *how* to identify these missing baselines or *how* to compare them. While the intent is clear, the implementation details are vague.", "grounding_specificity_rationale": "The review point mentions 'supervised baselines' generally, without specifying which part of the paper or section this refers to. It doesn't identify a specific element like a table, figure, or unique aspect of the paper. Therefore, the grounding is weak. While it mentions the *type* of baseline (supervised), it doesn't specify *which* supervised baselines are missing or relevant.", "verifiability_rationale": "The review point makes a claim by suggesting the addition of 'missing supervised baselines' and provides a justification for this suggestion. It states that it's 'reasonable to assume that full annotation is available for a dataset at this scale in practice' and that 'even if it isn\u2019t, it\u2019s an informative baseline to comparing to a fully supervised pretrained network'. This justification is logical and provides a basis for verifiability.", "helpfulness_rationale": "The review point clearly identifies a missing element (supervised baselines) and suggests a concrete action (adding them). It also provides a rationale for why this is a valuable addition, linking it to the scale of the datasets used in the experiments and the practical value of comparing against a fully supervised pretrained network. This makes the feedback actionable and relevant."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point states a fact ('Performance differences between methods are minimal') and offers a potential explanation ('less than 1 percentage point'). While it points to a *difference*, it doesn't explicitly *recommend* an action or provide a concrete next step for the authors. It's more of an observation.", "grounding_specificity_rationale": "The review point refers to 'Performance differences between methods' and 'benchmarks selected.' It doesn't explicitly identify a specific part of the paper being addressed. The comment is about the overall results and benchmarks, not a specific element *within* the results.", "verifiability_rationale": "The review point makes a statement ('Performance differences between methods are minimal') which constitutes a claim. However, the reviewer offers a potential explanation ('less than 1 percentage point') but doesn't provide *evidence* or *references* to support this observation about the minimal differences. The suggestion to 'reconsider the benchmarks' is a potential reason but lacks concrete justification within this review point itself.", "helpfulness_rationale": "The review point points out a potential issue (minimal differences) and offers a general suggestion ('reconsider the benchmarks'). It doesn't provide specific, actionable steps for the authors. While the suggestion is relevant, it's highlevel and doesn't directly address specific weaknesses or improvements for the authors' draft."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides several actionable suggestions. They explicitly state the method reduces to actionconditional masking on deterministic systems, which is a clear action. They also suggest evaluating on domains with nondeterministic dynamics, which is a direct action to take. While the reviewer doesn't explicitly state how to implement the evaluation on stochastic domains, the suggestion itself is a clear action. The reviewer also points out the missing BEAR baseline, which is a concrete action to address.", "grounding_specificity_rationale": "The reviewer's comments are not explicitly tied to a specific part of the paper. They are generally commenting on the method's applicability and the experimental setup. While they mention 'Hopper' and 'deterministic dynamics', they don't explicitly identify the section or table where these are discussed. They also don't specify *why* the method reduces to masking or *how* the evaluation on stochastic domains should be conducted.", "verifiability_rationale": "The reviewer makes several claims, such as 'Why does the method help on Hopper...', 'Can it be evaluated on some other domains...', and 'Why is BEAR missing from baselines...'. These are declarative statements that indicate claims. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. They simply state the questions or suggestions without explaining why they are valid or how they should be addressed.", "helpfulness_rationale": "The reviewer's comments are relevant and provide valuable insights for the authors. They point out a potential limitation of the method in the context of deterministic systems, suggesting an area for improvement. They also propose a relevant experiment using domains with nondeterministic dynamics, which is a constructive suggestion. Furthermore, they highlight the absence of the BEAR baseline, which is a practical issue for reproducibility and comparison. The reviewer's suggestions are directly actionable and likely to be helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests a concrete action: \"cotraining and weight averaging can improve results\". This indicates that the authors can directly identify the modification they should apply to their draft by seeking justification for these techniques. The mention of specific techniques like cotraining and weight averaging further supports the explicit nature of the action.", "grounding_specificity_rationale": "The review point mentions \"cotraining and weight averaging\", which are specific techniques used in machine learning. While it doesn't explicitly state the section, table, or figure where these techniques are discussed, it clearly identifies the area of the paper that needs further explanation. This indicates that the authors can infer the specific part of the paper being addressed, making it weakly grounded. However, the review also specifies what is wrong (lack of justification) and how it might improve results, making it specific.", "verifiability_rationale": "The review point contains the claim \"cotraining and weight averaging can improve results\". This is a statement of opinion or judgment. However, the review does not provide any logical reasoning, common knowledge, or external references to support this claim. It simply states the potential benefit without explaining *why* these methods are expected to improve results. Therefore, the claim is not wellverified.", "helpfulness_rationale": "The review point is relevant to the authors as it highlights a practical improvement they can make \u2013 seeking justification for the use of cotraining and weight averaging. However, the review itself does not provide any explanation or reasoning for *why* these methods are expected to improve results. This lack of explanation makes the review less helpful in guiding the authors to find the justification themselves. While it points to a useful direction, the absence of supporting evidence reduces its overall helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential limitation of the current approach (classical learning theorybased bounds) and suggests considering BayesianPAC bounds as a potential improvement. However, it does not explicitly state how the authors should go about implementing this change or what specific steps they should take. The suggestion is presented as a possibility rather than a direct action.", "grounding_specificity_rationale": "The comment refers to 'classical learning theorybased bounds' and 'BayesianPAC based bounds' generally, without specifying a particular section, table, figure, or unique aspect of the paper where these bounds are being discussed or applied. The reviewer is commenting on the *field* of bounds rather than a specific element within the paper.", "verifiability_rationale": "The comment presents a statement about the limitations of classical learning theorybased bounds and suggests considering BayesianPAC bounds as a potential improvement. This can be considered a claim that something is a limitation and that an alternative should be considered. While the claim itself is logically sound and suggests a direction for improvement, the review point does not provide specific examples or references to back up this claim within the text itself.", "helpfulness_rationale": "The comment identifies a potential limitation of the current approach and suggests a possible improvement (considering BayesianPAC bounds). While it doesn't provide concrete steps on how to implement this change, it does offer a direction for the authors to consider. The suggestion is logically connected to the identified limitation and provides a potential next step. Therefore, it offers some helpful direction, but lacks the specificity of a direct solution."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point asks for *more details* about the proposed method. While this implies a desire for information, the specific action to be taken is not explicitly stated. The reviewer needs to *find* these details, rather than being directly told *where* to look.", "grounding_specificity_rationale": "The reviewer can infer that the \"proposed method\" is likely a specific section or subsection in the paper. They are pointing out that the *section* where these details are supposed to be isn't explicitly labeled or clearly identified. However, the reviewer *does* specify *what* kind of details are missing \u2013 details about the implicit distribution and how uncertainty is handled.", "verifiability_rationale": "The review point clearly states a *need* for more details. This is a direct statement of a requirement, which can be considered a claim. However, the reasoning is logical (more details are usually helpful), but the *claim* itself (the need for more details) isn't supported by evidence *within this review point*. It's a statement of expectation or a desire for more information.", "helpfulness_rationale": "The review point directly asks for *more information*. While this is generally helpful for the authors by providing more context and potentially leading to improvements, it doesn't *immediately* provide them with actionable steps or concrete guidance. The reviewer is essentially saying, \"I want to understand this better.\" This is a desire for clarification, not a directive to improve the draft based on the information given."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation of the proposed method regarding its ability to detect hallucinations in openended responses. While they identify the issue, they do not provide explicit or concrete actions the authors should take to address this limitation. The reviewer suggests the method 'might struggle,' which is a general statement without specific guidance on how to improve the method. The lack of specific actions makes the feedback less actionable for the authors.", "grounding_specificity_rationale": "The reviewer criticizes the proposed method's hallucination detection for openended responses in general, without specifying which part of the method or process is problematic. They provide an example ('the prompt \"introduce a sports celebrity to me\"') to illustrate the issue, but this example doesn't pinpoint a specific section or component of the method that needs improvement. The criticism is broad and lacks a clear link to a specific part of the paper or method. The explanation is also somewhat underspecific, as it doesn't detail *how* the method struggles with this variability.", "verifiability_rationale": "The reviewer states a claim: \"The proposed method might struggle to detect hallucinations in openended responses.\" They provide a reason for this claim by giving an example of a prompt that could lead to this issue. While the reviewer provides some justification and an example, it could be more robust with explicit references to the method's mechanics or limitations. The claim is not entirely unsupported but lacks strong evidence or citations to back it up. Therefore, it is 3 but could be improved with more concrete support.", "helpfulness_rationale": "The reviewer's comment is critical of the proposed method's ability to detect hallucinations in openended responses. While they identify a potential weakness, they do not offer specific, actionable suggestions for the authors to improve the method based on this criticism. The feedback is more of a critique than a direct suggestion for improvement, making it 3 but not entirely helpful as it doesn't directly guide the authors on what changes to make."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The comment implies an action (verify the conclusion about the label noise and model size on MNIST and CNN) and provides a clear goal. However, the action itself is vague and lacks detail on how to apply it.", "grounding_specificity_rationale": "The comment doesn't explicitly mention a specific section, table, figure, or unique element of the paper. The suggestion to verify on MNIST and CNN is general and lacks specific details within the suggestion itself.", "verifiability_rationale": "The comment contains a suggestion, which can be interpreted as a claim that the current findings lack clarity and that the suggested experiment will address this. However, it lacks specific justification or references for how to perform the verification.", "helpfulness_rationale": "The comment provides a clear and actionable suggestion for the authors to gain confidence in their findings. The suggestion is specific (MNIST and CNN) and directly addresses the stated lack of clarity regarding realworld applicability."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "3 (5)", "verifiability_label": "5 (5)", "helpfulness_label": "4 (4)", "actionability_rationale": "The review point implicitly suggests that the authors should be aware of the requirement for the likelihood function to be Gaussian for the Kalman Filter/Smoothing and CVI to be valid. While the action of ensuring a Gaussian likelihood is implied, the *howto* is not explicitly stated in the review point itself. The reviewer is pointing out a potential gap in the authors' understanding or the paper's clarity regarding this requirement.", "grounding_specificity_rationale": "The review point explicitly mentions the likelihood function p(y | Hf_bar(tn)) and its role in the Kalman filter/Smoothing and CVI. The reviewer clearly identifies the specific part of the model that needs to be Gaussian. The grounding is strong as the section, table, or figure (if any) is directly referenced, and the issue is clearly specified as the need for a Gaussian likelihood for these methods to work.", "verifiability_rationale": "The review point states a factual claim: 'It should be mentioned that p ( y \u2223 H f \u00af ( t n ) ) has to be chosen Gaussian, as otherwise Kalman Filtering and Smoothing and CVI is not possible.' This claim is verifiable because it is based on a wellestablished property of Kalman filters \u2013 the assumption of Gaussian noise. The reasoning is clear: Kalman filters rely on Gaussian distributions for their optimal estimation.", "helpfulness_rationale": "The review point is helpful because it points out a potential issue (the likelihood not being Gaussian) that could affect the validity of the Kalman filter/Smoothing and CVI. By stating this requirement later in the ELBOs, the reviewer is highlighting a potential gap in the authors' understanding or the paper's clarity regarding this fundamental assumption. This information can help the authors ensure the appropriateness of their likelihood function choice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point points out a *potential* issue (large training loss with suboptimal weight decay) and suggests a *consequence* (suboptimal cosine similarities). It also notes a *limitation* in the reported results (plots ending before this issue manifests). While it identifies a *possible* problem, it doesn't explicitly *recommend* an action beyond investigating the training loss. Therefore, it's not fully actionable.", "grounding_specificity_rationale": "The reviewer point mentions \"weight decay is applied to all layers\" and refers to \"cosine similarities for such large weight decay strengths.\" The connection between these elements and specific parts of the paper isn't explicitly stated. The reviewer *does* specify the type of weight decay (\"large\") and the scope (\"all layers\"), and the consequence ('suboptimal cosine similarities\"). However, the *context* of the cosine similarities (e.g., which layers or model states) isn't fully clear.", "verifiability_rationale": "The review point presents a *hypothesis* about a potential issue with weight decay and its effect on cosine similarities. This is a claim that requires verification. The reviewer *doesn't* provide any evidence or reasoning to support this claim. They state the *potential* issue but don't explain *why* it's likely to happen or cite any relevant literature.", "helpfulness_rationale": "The review point raises a potential concern and points to a limitation in the reported results. While it doesn't directly *fix* the issue, it highlights a potential area for further investigation. It's not a complete critique, but it does offer a specific observation. The lack of verifiability weakens its impact."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of qualitative experiments and suggests concrete actions like using toy datasets to demonstrate separability. They also propose a new test metric and visualization, indicating a clear intention to make the claims actionable. The reviewer identifies a deficiency and provides a direct path for improvement.", "grounding_specificity_rationale": "The reviewer mentions 'qualitative experiments' and 'toy datasets' as ways to address the lack of evidence. While not directly stating 'this is about the evaluation of the conditional independence model', the context strongly implies it. The reviewer also suggests a 'new test metric' and 'visualization', which are specific actions aimed at demonstrating the validity of the model. The reviewer is grounding the need for more experiments in the specific area of the conditional independence model.", "verifiability_rationale": "The reviewer makes a claim about the need for illustrative experiments and suggests a new metric and visualization as ways to verify this claim. While the *claim* itself is not explicitly stated as a claim, the reviewer's suggestion of *how* to verify it provides a basis for potential verification. The reviewer is offering methods to demonstrate the validity of the conditional independence model, which could be seen as a form of justification or verification, even if not fully explicit or supported by external references at this point.", "helpfulness_rationale": "The reviewer directly points out a weakness in the paper (lack of qualitative experiments) and offers concrete suggestions for improvement, such as using toy experiments and proposing a new metric. These suggestions are directly aimed at addressing the identified weakness and making the claims more actionable for the authors. The reviewer is providing a clear path for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests *specific analyses* to perform (impact of cost, reward incentives, collective return) and *specific scenarios* to explore (different alpha values, roles of winners/cooperators). However, the reviewer does not explicitly state what the authors should do with this information. The action is implied rather than explicitly stated and performed.", "grounding_specificity_rationale": "The reviewer's comment is general and does not explicitly refer to a specific part of the paper, the table, figure, or unique aspect being addressed. The authors would have to infer the relevance of the suggested analysis. Therefore, the grounding is weak.", "verifiability_rationale": "The review point is a question, not a declarative statement. It does not contain a claim or judgment about the paper. Therefore, there is X to verify.", "helpfulness_rationale": "The reviewer points out a potential area for further research and analysis. While the review point does not provide explicit instructions on how to conduct the analysis, it suggests a relevant and potentially valuable direction for exploration. This can be helpful for the authors to understand the impact of incentivization mechanisms."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states that the approach description is 'partially difficult to follow' and suggests it should be 'revised'. While the suggestion to revise is clear, the comment does not specify *how* the description should be revised or what specific improvements are needed. The action is implied but not explicitly stated in a concrete manner.", "grounding_specificity_rationale": "The comment explicitly refers to 'approach description (\u00a7 3)', clearly identifying the specific part of the paper being addressed. The use of the section number indicates a strong understanding of where the issue lies.", "verifiability_rationale": "The comment contains a claim that 'approach description (\u00a7 3) is partially difficult to follow'. However, this claim is based on the reviewer's subjective assessment of the approach description's clarity and does not provide any external evidence or logical reasoning to support this claim. There is no reference to external works or common knowledge to back up the statement.", "helpfulness_rationale": "The comment directly points out a weakness in the submitted paper ('approach description (\u00a7 3) is partially difficult to follow') and offers a concrete suggestion for improvement ('should be revised' and 'use the additional page of the cameraready version'). This actionable feedback directly addresses an issue with the submitted work and provides a clear path for improvement, making it 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point states a desire for more evidence or analysis, which is a suggestion for future research rather than a direct instruction on how to improve the current draft. The authors are being asked to consider a broader implication of the dataset, not a specific action to take on the paper.", "grounding_specificity_rationale": "The review point is about the importance and usecases of the dataset, a general concept, and doesn't specify a particular part of the paper being addressed. The authors are being asked to consider a broader implication of the dataset, not a specific aspect of the paper.", "verifiability_rationale": "The review point is a suggestion for more research and analysis, not a claim that needs to be supported by evidence. It's a request for more information, not a statement that can be verified.", "helpfulness_rationale": "The review point suggests further research and analysis, which is valuable for the authors' understanding but doesn't directly improve the current draft. It's a call for more investigation rather than a direct improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer's point is somewhat implicit. While they raise a valid concern about regularization effects, the suggestion to 'properly ablate studies' is a general direction rather than a specific, actionable step. The reviewer doesn't explicitly state what needs to be ablated or how to perform it. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the case where the student distills knowledge to the teacher' and 'finetuning on GLUE without validation earlystopping.' This clearly identifies the specific part of the paper being addressed. They also point out a potential issue ('high variances') related to the method and training procedure, further grounding the criticism. The grounding is quite explicit.", "verifiability_rationale": "The reviewer makes a claim that 'the improvements could potentially be due to regularization effects rather than distillation as claimed.' This is a verifiable claim. They suggest 'proper ablation studies' as a way to verify this, indicating a logical reasoning. However, they do not provide specific references or examples to support this claim about regularization effects in this context. The claim is plausible but lacks concrete evidence at this point.", "helpfulness_rationale": "The reviewer raises a valid concern about the potential confounding factor of regularization effects on the observed improvements. They suggest 'proper ablation studies' as a way to address this. While the reviewer doesn't provide specific solutions or detailed steps, the suggestion to investigate further is a helpful direction for the authors. It prompts them to consider alternative explanations for their results and to design experiments to isolate the effect of distillation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the desired improvements: 'addition of performance on word similarity and sentence translation tasks' and 'addition of morphologically rich languages like Finnish, Hebrew, etc and lowresource languages'. These are both direct actions the authors should take. Furthermore, the reviewer provides specific examples (word similarity and sentence translation tasks, and languages like Finnish and Hebrew) which makes the action concrete. The reviewer is not leaving any ambiguity about what needs to be done.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific section, table, or figure in the paper. It is implied that the authors should consider adding these evaluations and experiments. While the intention is clear, the reviewer does not provide a precise reference to where in the paper these additions should be made. However, the reviewer does specify the *type* of tasks and languages, which adds some level of specificity to the *nature* of the addition.", "verifiability_rationale": "The review point contains claims. For the first part, 'addition of performance on word similarity and sentence translation tasks' is a suggestion for improvement, which can be considered a claim that requires justification (though not explicitly stated as such in the provided text). This claim is supported by the logical connection between evaluating on these tasks and increased credibility. For the second part, 'addition of morphologically rich languages like Finnish, Hebrew, etc and lowresource languages *would be good to have*' is also a claim, suggesting a beneficial addition to the experiments. This claim is supported by the logical argument that testing on diverse languages would improve the framework's robustness and effectiveness.", "helpfulness_rationale": "The review point provides clear suggestions for improvement. The first part, 'addition of performance on word similarity and sentence translation tasks', directly addresses a potential weakness in the framework's evaluation. The second part, 'addition of morphologically rich languages like Finnish, Hebrew, etc and lowresource languages', suggests a valuable experiment to broaden the evaluation. These suggestions are actionable and directly relevant to improving the framework's robustness and effectiveness. The reviewer is not just pointing out a problem but also suggesting concrete ways to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their confusion about how node importance is used in a 1shot scenario and why the paper doesn't include a 1shot experiment. While the reviewer identifies an area needing clarification, the request is not explicit about a specific action to be taken. The reviewer is asking 'how' and 'why', which are implicit actions.", "grounding_specificity_rationale": "The reviewer's questions are about the methodology and implementation details of the paper, specifically how node importance is used in a 1shot setting and why the paper doesn't include a 1shot experiment. The paper does not explicitly detail the process of using node importance in a 1shot setting, making the grounding somewhat weak. The reviewer is asking about a specific aspect of the method that is not clearly identified in the paper.", "verifiability_rationale": "The reviewer's question about how node importance is used in a 1shot scenario is a question that requires inference and deduction from the paper's description. The paper does not explicitly state the reasoning behind this design choice, making the verifiability low. The reviewer is asking 'how' and 'why', which are implicit actions and lack supporting evidence in the paper.", "helpfulness_rationale": "The reviewer's questions are directly relevant to understanding the paper's methodology, specifically how something works and why it was designed that way. While the questions are broad, they are still valuable and directly address a potential weakness in the paper's explanation. The reviewer is asking for clarification on a key aspect of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'There should be more discussions' which is a clear and direct action for the authors. It further specifies the *how* by asking for discussions on 'why LLMs struggle' and 'how to address these problems', making the action concrete.", "grounding_specificity_rationale": "The review point mentions 'finegrained hard constraints', which is a specific technical detail within the paper. This provides a clear reference point for the authors. Furthermore, the reviewer specifies the *type* of discussion by asking about the 'why' and 'how to address', adding to the specificity of the grounding.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a request for more information and discussion, not a statement that needs to be supported by evidence or reasoning. Therefore, it does not fit into the 'X' category for X, nor does it have any verifiable elements.", "helpfulness_rationale": "The review point identifies a valid area for improvement in the authors' work \u2013 the discussion of LLM limitations and potential solutions. It provides a clear direction for the authors to seek more information and elaboration. While it doesn't offer a solution, it is a helpful request that guides the authors towards a more comprehensive discussion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a limitation: \"little insights are given about why do we need to do selfsupervised learning on this kind of data.\" This directly points to a missing action or suggestion, making it explicit. However, the point does not specify *how* or *what* these insights should be, making it vague. Therefore, it is explicitly stated but lacks concrete details, making it 3 but vague.", "grounding_specificity_rationale": "The review point clearly identifies the specific part of the paper being addressed: 'selfsupervised learning on 360 video data which have spatial audio.\" This allows the authors to pinpoint the relevant section, making the grounding fully grounded. However, while the grounding is present, the point does not specify *what* insights are missing or *why* these insights are needed in this specific context. The statement \"little insights are given\" is general and does not detail the specifics of the missing information. Therefore, while grounded, the specificity of the identified issue is limited, making it weakly grounded and somewhat specific.", "verifiability_rationale": "The review point contains a claim: \"little insights are given about why do we need to do selfsupervised learning on this kind of data.\" This is a statement of a limitation or gap in the paper's explanation. However, the point does not provide any evidence, reasoning, or external references to support this claim. It simply states the absence of insights without explaining *why* they are missing or *why* they should be present. Therefore, the claim is not verifiable based on the information provided in this review point.", "helpfulness_rationale": "The review point identifies a valid limitation in the paper: the lack of explanation for applying selfsupervised learning to 360 video data with spatial audio. By highlighting this gap, the review point provides a clear direction for improvement and can motivate the authors to seek clarification or further information. While it doesn't explicitly state *what* the missing insights are, it points to a concrete area where the authors' understanding is lacking. This can be a helpful starting point for the authors to improve their understanding and potentially contribute to the field. Therefore, the point is helpful in identifying a missing piece of information."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests a change to the experimental process: \"Results should be averaged over multiple runs to determine statistical significance.\" This is a direct and actionable suggestion for the authors. The authors can immediately understand that this involves repeating their experiment multiple times and then calculating the average of the results to assess statistical significance. This provides a clear direction for improvement.", "grounding_specificity_rationale": "The review point suggests a change to the experimental process but doesn't specify which part of the paper or analysis this relates to. It's a general suggestion about improving the robustness of the results. The authors would need to infer where this suggestion applies, likely within the \"Experiments\" or \"Results\" section. Therefore, it's not fully grounded to a specific element.", "verifiability_rationale": "The review point itself does not contain a claim or assertion. It's a suggestion for improvement. Therefore, it falls under the \"X\" category.", "helpfulness_rationale": "The suggestion to average results over multiple runs is a relevant and practical piece of advice for improving the reliability and robustness of experimental findings. It directly addresses a common concern in research and provides a clear direction for the authors to take. While it's a valuable suggestion, it lacks specific details about *how* many runs to perform or *how* the averaging should be done. Therefore, it's likely to be 3."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a problem ('the observation and conclusions are hidden') but doesn't explicitly state how the author should address it. While it implies the issue is in the experimental section, the specific action of 'uncover hidden observations' is not directly recommended. The reviewer suggests highlighting these observations, which is a consequence rather than a direct action.", "grounding_specificity_rationale": "The comment explicitly mentions 'the experimental section' as the location of the hidden observations. This directly identifies the specific part of the paper being referred to.", "verifiability_rationale": "The comment presents a suggestion ('It would be great if the paper can highlight those observations and conclusions...') rather than a claim that requires verification. While the suggestion is valuable, it doesn't contain a statement that needs to be supported by evidence or logical reasoning.", "helpfulness_rationale": "The comment points to a valid area for improvement (hidden observations) and suggests a positive outcome (highlighting them). While it doesn't provide specific steps on how to implement this suggestion, it does indicate a direction for the author's revision and provides a reason for the suggestion (improving understanding of tradeoffs)."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their intention to compare the performance of their KDE method with Zhang et al.'s approach on datasets with decision spaces beyond binary classification. This is a clear and direct action to address a potential limitation of their method. The reviewer also implies that this comparison is needed based on the observation that other approaches do not seem to have the same issue. This makes the action quite explicit.", "grounding_specificity_rationale": "The reviewer mentions 'datasets that the decision space is beyond binary' which is a general concept. While they are pointing to a specific type of dataset, they do not explicitly identify the specific section, table, figure, or unique aspect of the paper where such datasets are discussed or located. They also do not provide any specific examples of how to identify these datasets. Therefore, while the concept is mentioned, the grounding is not fully explicit.", "verifiability_rationale": "The reviewer makes a claim about the potential performance issues of their KDE method in nonbinary decision spaces and suggests a comparison with another approach. This constitutes a claim that requires verification. The reviewer provides a logical reasoning by stating that Zhang et al.'s approach does not seem to have this problem, implying a need for empirical evidence. This reasoning is clear and provides a basis for verification.", "helpfulness_rationale": "The reviewer's question directly addresses a potential weakness of their KDE method, specifically its performance in nonbinary decision spaces. This is a clear and actionable question that directly targets an area for improvement. The suggestion to compare with another approach is a direct and helpful step for the authors to understand the limitations of their method."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises concerns about the impact of the SR model's capacity on FID and the presence of unexpected artifacts due to pipelining. However, it does not explicitly state what actions the authors should take to address these issues. The reviewer points out potential problems but lacks concrete guidance on how to investigate or resolve them. The lack of explicit and actionable suggestions makes the review point less actionable.", "grounding_specificity_rationale": "The reviewer identifies potential issues related to the SR model's capacity, FID, and unexpected artifacts arising from pipelining. However, the review point does not specify which part of the authors' paper is being referred to. It lacks a clear connection to specific sections, tables, figures, or unique elements of the authors' work. The reviewer's comments are general and do not pinpoint the exact location or nature of the problems, making the review point poorly grounded.", "verifiability_rationale": "The reviewer states the existence of 'unexpected artifacts' and suggests that 'missing details about the SR model's capacity' might be a contributing factor. However, the review point does not provide any evidence or reasoning to support these claims. The reviewer simply observes potential problems without investigating or explaining them. The lack of supporting evidence makes the claims 1.", "helpfulness_rationale": "The review point raises concerns about the impact of the SR model's capacity on FID and the presence of unexpected artifacts due to pipelining. However, it does not offer any concrete suggestions or guidance on how the authors can address these issues. The reviewer points out potential problems but does not provide any actionable steps or evidence to support the claims. The lack of helpful information makes the review point not particularly helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the *lack* of necessary experiments, which can be seen as an implicit action: the authors should conduct these experiments. However, the specific *type* of experiments (comparison, ablation, hyperparameter) are mentioned, making the action less vague than a comment like 'The paper needs more experiments'. Therefore, it's not fully explicit, making it **3**.", "grounding_specificity_rationale": "The comment is a general statement about the *lack* of necessary experiments. It doesn't specify a particular section, table, figure, or unique aspect of the paper where these experiments are missing. The reviewer is broadly pointing out a deficiency, not pinpointing a specific location. Therefore, it's **1**.", "verifiability_rationale": "The comment states a claim: 'The paper lacks additional necessary experiments...'. However, it doesn't provide any justification or evidence for this claim. There's no logical reasoning, common knowledge, or external references provided to support the statement. The reviewer simply states the lack of experiments without explaining *why* or *where* this lack is evident. Therefore, it's **1**.", "helpfulness_rationale": "The comment identifies a clear weakness in the paper: the absence of specific experimental details. By pointing out the *need* for additional experiments, it provides the authors with a direction for improvement. While it doesn't specify *what* experiments to add, it's a constructive suggestion that directly addresses a potential area for enhancement. Therefore, it's **3**."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review points out a lack of specific instructions on what to do. It criticizes the comparison but doesn't explicitly state how to fix it. The suggestion to 'consider' the impact of prior knowledge and the added complexity is a general direction rather than a specific, actionable step.", "grounding_specificity_rationale": "The review point refers to 'the experimental results,' 'the proposed method,' and 'SOTA' generally. While it doesn't point to a specific section or table, it clearly identifies the different methods being compared and the context of the comparison.", "verifiability_rationale": "The review point contains a claim: 'such comparison is a bit unfair' and 'such extra complexity and cost need to be considered.' These are statements that require justification. However, the review doesn't provide specific examples or references to support these claims. The reasoning is presented as a general observation rather than a logically sound argument backed by evidence.", "helpfulness_rationale": "The review point raises a valid concern about the experimental design and the implications of the prior information. It points out a potential flaw in how the methods were compared. However, it doesn't offer any concrete suggestions or alternative experimental designs for the authors to consider. It criticizes the *how* but doesn't provide a clear *what to do next*."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding a new element (collaborative games) to the experiments. While it implies an action, it doesn't explicitly state what needs to be done or how. The suggestion is broad and lacks specific details on implementation.", "grounding_specificity_rationale": "The review point is a general suggestion about exploring collaborative settings. It doesn't identify a specific part of the paper, the existing experiments, or any particular issue within them that needs addressing. The reviewer is proposing a new direction for research rather than pointing to a specific flaw.", "verifiability_rationale": "The review point presents a suggestion about future research directions (exploring collaborative settings) rather than a claim that can be directly supported or refuted based on the current paper. There are no immediate, verifiable evidence or logical reasoning provided to support this specific suggestion within the context of the current work.", "helpfulness_rationale": "The review point offers a potential area for future research and broadens the scope of the experiments. While it doesn't directly address current limitations, it introduces a new dimension to the evaluation of methods by considering collaborative settings. This could be valuable for researchers interested in multiagent systems, but it's a suggestion for future work rather than immediate actionable feedback for improving the current draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the problem: 'experimental settings for Figure 1 to Figure 9 are totally missing'. This directly identifies a lack of information that the authors would need to address to improve their draft. The action is clear and concrete: the authors need to provide the experimental details for each figure.", "grounding_specificity_rationale": "The comment identifies the specific parts of the paper (Figure 1 to Figure 9) where the experimental settings are missing. However, it doesn't explicitly name a specific section, table, or unique aspect within the experimental section where these details should be located. The authors would need to infer the location based on the context of each figure.", "verifiability_rationale": "The comment states a problem ('experimental settings are totally missing') but does not offer any justification, explanation, or references to support this claim. It doesn't present a suggestion or request for clarification. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The comment clearly identifies a significant weakness in the paper: the lack of experimental details for the figures. This directly impacts the reader's ability to understand and evaluate the results presented in those figures. While it doesn't suggest specific improvements, it highlights a crucial missing piece of information that the authors would need to address to improve their draft. It provides a clear indication of what is missing and why it is important."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question about how the proposed method avoids impeding the learning of new task knowledge. This constitutes an explicit action, as the authors are directly identifying a potential issue and asking for a solution. However, the question itself is quite general and lacks specific details on the mechanisms involved, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to 'parameter isolation methods' and 'sparsity exhibited by activation channels in deep networks.' While these are related concepts, the review does not explicitly identify a specific part of the paper or a unique aspect being addressed. The reference remains at a general level, making it not fully grounded.", "verifiability_rationale": "The reviewer poses a question about a potential issue with their method. While this can be interpreted as a claim that the current methods hinder new task learning, the question itself does not provide any evidence or reasoning to support this claim. The request for clarification implies a desire for justification, but the justification is missing in the review point.", "helpfulness_rationale": "The reviewer's point is primarily a question about a potential issue with their method. While it highlights a potential area for improvement, it does not directly offer a solution or actionable advice to the authors. It's more of a diagnostic question than a direct suggestion for improvement, making it 3 but not fully constructive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the regularization term is 'adhoc' and lacks 'theoretical support'. They also suggest alternatives like the median. This indicates a clear understanding of the issue and a direct suggestion for improvement. The reviewer identifies the problem and proposes a solution, making it 5.", "grounding_specificity_rationale": "The reviewer directly refers to the 'regularization term', 'mean', and 'standard derivation' in the regularization. They are specifically pointing out these elements as being potentially problematic. This demonstrates a clear identification of the specific part of the paper being addressed, indicating full grounding and specificity.", "verifiability_rationale": "The reviewer doesn't present a claim that can be directly verified. Instead, they are suggesting alternatives and asking questions. While they don't provide explicit evidence that the current approach is incorrect, they offer concrete directions for the authors to consider. This makes it 2 as the underlying intent is to improve the paper based on the suggested changes.", "helpfulness_rationale": "The reviewer provides specific suggestions for alternative regularization terms and asks relevant questions. These suggestions are directly aimed at improving the authors' draft. The questions prompt further investigation and consideration of different statistical measures. This level of detail and direction makes the review 5."}
{"actionability_label": "3.5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the action of 'comparisons with existing fairness algorithms' and the reason for it, which is to 'enhance the paper' and 'position the ManyFairHPO framework within the existing FairML research landscape'. This indicates a clear intention to provide feedback. However, the comment lacks specific details on *which* algorithms to compare against, *how* to perform the comparisons, or *what specific aspects* of the algorithms are relevant. The action is implied rather than explicitly stated, and the details are missing, making it somewhat vague.", "grounding_specificity_rationale": "The comment refers to 'existing fairness algorithms' generally, without specifying a particular section, table, figure, or unique element of the paper where these algorithms are discussed. While the intent is clear \u2013 to compare against existing work \u2013 the comment does not pinpoint the specific part of the paper being addressed. The grounding is weak because the comment doesn't directly refer to a specific aspect of the paper. The specificity is also limited as the comment doesn't detail what needs to be addressed in this part (e.g., specific algorithms, metrics, evaluation criteria).", "verifiability_rationale": "The comment contains a claim, which is the statement 'Integrating benchmark comparisons against stateoftheart fairness algorithms would significantly enhance the paper.' This claim is 3 in that the *what* (comparisons) is clear. However, the *how* and *why* are not welldefined. The *how* is vague, as it doesn't specify which algorithms to compare against or how the comparisons should be conducted. The *why* is also somewhat vague, as the term 'significantly enhance' is subjective and lacks specific justification. There are no external references provided to support this claim.", "helpfulness_rationale": "The review point directly addresses a significant weakness identified by the authors, which is the lack of benchmark comparisons with existing fairness algorithms. The reviewer clearly states the need for such comparisons to improve the paper and position the framework. The comment is specific about the *what* (comparisons) and the *why* (enhancing the paper and positioning). It provides a clear direction for improvement and highlights a concrete way to address a gap in the current work. While the *how* could be more detailed, the suggestion is actionable and directly relevant to the identified issue."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the potential issue: \"Supervised pretraining based on the prediction of homolumo gap may lead to negative transfer.\" This is a clear and direct statement of a problem. It also provides a specific example: \"For example, on QM9 in downstream experiments, TransformerM performs poorly on most tasks other than homo, lumo, and gap.\" This identifies a concrete scenario where the potential issue manifests. The reviewer suggests a potential flaw in the pretraining strategy that could affect the model's general applicability.", "grounding_specificity_rationale": "The review point mentions \"TransformerM\" and \"QM9 dataset.\" While it doesn't explicitly state the section, table, or unique aspect of the paper being addressed, it refers to specific models and datasets commonly used in the field. This could be considered weak grounding as the authors might need to infer the context within the paper. However, the review clearly specifies the potential issue (negative transfer) and the specific tasks (most tasks other than homo, lumo, and gap) where this problem is observed, making it somewhat specific.", "verifiability_rationale": "The review point contains a claim: \"Supervised pretraining based on the prediction of homolumo gap may lead to negative transfer.\" This is a statement of a potential consequence. While the reviewer suggests this is a problem based on the TransformerM results on QM9, they don't provide direct evidence within their review point to support this claim. The connection is implied, and the reviewer points to a potential issue that the authors might need to investigate further by looking at the TransformerM paper and QM9 results. The claim is not explicitly stated as a fact with a logical reasoning, but it's presented as a possibility.", "helpfulness_rationale": "The review point raises a valid concern about the potential negative transfer effect of pretraining on homolumo gap prediction. This is relevant to the authors of a \"generalpurpose neural network model\" as it questions the robustness and generalizability of their approach. While the review points out a potential issue and suggests an area for further investigation (looking at TransformerM and QM9), it doesn't offer a concrete solution or specific steps to address the problem. The feedback is focused on identifying a potential flaw rather than providing a clear path to improvement."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly suggests an alternative name (' something less strong') for the term 'distributional generalization' and clearly states the implication of the current name, suggesting a vanishing difference between train and test outputs, which might not be accurate based on the limited test functions. The actions are concrete: suggest a new name and point out the potential overstatement.", "grounding_specificity_rationale": "The reviewer's comment is general and does not specify which part of the paper or phenomenon they are referring to. They are commenting on the *name* of a concept in general, not a specific section or table. The grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The reviewer makes a claim about the strength of the 'distributional generalization' concept based on the limited empirical evidence presented. They argue that the current description might be an 'ideal' and not representative of realworld scenarios. The verification is 3 as the reviewer provides a logical reasoning (limited test functions) and a general argument, but lacks specific examples or citations to support the claim that it 'might not be the case'.", "helpfulness_rationale": "The reviewer provides a suggestion for an alternative name and questions the strength of the current name based on the limited empirical evidence. This directly points the authors towards a potential improvement and highlights a potential limitation of their current framing. The feedback is actionable and constructive."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review points out that the theoretical contribution is 'not particularly strong' and highlights issues like a 'weak, unpractical bound' and a lack of 'particular mathematical novelty'. While this identifies a weakness, it doesn't explicitly state what action the authors should take to address these issues. The reviewer describes the current state and characteristics of the contribution but doesn't provide a direct, actionable step for improvement.", "grounding_specificity_rationale": "The review refers to the 'theoretical contribution' and mentions issues like 'weak, unpractical bound' and 'lack of particular mathematical novelty'. However, it does not specify which part of the paper or a particular section is being criticized. The reference is general to the contribution as a whole, lacking a precise identification of a specific element within the paper.", "verifiability_rationale": "The review contains a claim that the 'theoretical contribution is not particularly strong' and provides supporting evidence by stating it is 'given existing results', has a 'weak, unpractical bound', and lacks 'particular mathematical novelty'. This claim is supported by specific reasons and observations about the contribution.", "helpfulness_rationale": "The review identifies specific weaknesses in the theoretical contribution, such as its 'not particularly strong' nature, the 'weak, unpractical bound', and the 'lack of particular mathematical novelty'. While it doesn't offer concrete solutions, it points out areas where the authors might need to refine their work, making it a valuable piece of feedback for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a grammatical error ('is sufficient' should be 'is sufficient for') and attempts to identify what this phrase is intended to be sufficient for, specifically referencing lines 240 and 428. The reviewer's attempt to link it to 'optimistic' hopedfor rewards, while speculative, indicates an effort to understand the context and potential implications of the statement. The reviewer identifies the core action of clarifying the meaning of 'is sufficient' and points to specific locations in the paper.", "grounding_specificity_rationale": "The reviewer explicitly points to lines 240 and 428 as the context for the statement 'is sufficient'. This demonstrates a clear understanding of where the issue might be and attempts to ground the comment in a specific part of the paper. The reviewer also offers a potential interpretation of what might be meant by 'is sufficient', adding a layer of specificity to the criticism.", "verifiability_rationale": "The reviewer's comment is primarily a suggestion for clarification and interpretation of the phrase 'is sufficient'. While the reviewer identifies a potential area for improvement in the writing style, the comment itself doesn't present a clear claim that requires verifiable evidence. The reviewer's suggestion is more of an interpretation than a direct criticism of a factual statement.", "helpfulness_rationale": "The reviewer's comment is generally helpful as it points out a potential writing issue ('is sufficient' should be 'is sufficient for') and attempts to help the authors understand the context of lines 240 and 428. However, the speculative nature of the suggestion about 'optimistic' hopedfor rewards makes it less concrete and potentially less helpful if the authors don't actually use that concept in those lines. The reviewer is offering a possible interpretation to aid understanding, which is generally beneficial but lacks definitive verifiability."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer clearly identifies the paper's method of VAD implementation as simply discarding TF bins with magnitude below a threshold. This is a direct and actionable criticism. The reviewer explains that this approach is more akin to noise suppression and does not align with the typical understanding of VAD, which should operate on time and identify the presence of speech based on energy variations across time. The reviewer provides a clear explanation of the discrepancy and its implications for the paper's proposed method. This allows the authors to directly address the flaw in their approach.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific aspect of the paper being criticized: the proposed VAD method and its implementation of discarding TF bins below a threshold. They also specify what is wrong with this approach \u2013 that it doesn't perform a true VAD and is more like noise suppression. The reviewer's statement 'This comment explicitly mentions which part of the paper it addresses' is accurate. The comment pinpoints the VAD method as the area of concern and clearly states the issue. This makes the grounding very specific.", "verifiability_rationale": "The reviewer provides a clear and verifiable explanation of why the paper's method is not a true VAD. They state that a true VAD should operate on time and identify speech based on energy variations, not by simply discarding frequency bins. The reviewer's explanation is based on the established understanding of VAD and provides a logical reasoning for the flaw. The comment includes explicit reasoning and precise explanations, fitting the criteria for '5'.", "helpfulness_rationale": "The review directly challenges a key claim of the paper: that the proposed method is a novel VAD technique. The reviewer explains that the method is simply discarding TF bins, which is not a true VAD and is more akin to noise suppression. This critique is highly specific and actionable. The authors can directly address this issue and propose a more appropriate VAD method. The reviewer's explanation is clear and directly impacts the validity of the paper's core contribution. This makes the review 5 for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the paper is 'not particularly easy to follow' and 'lacks a clear intuition.' While this points to a general issue, it doesn't explicitly state what needs to be improved or how the authors should proceed. The reviewer identifies a problem but doesn't offer a direct solution or a clear path towards improvement. Therefore, it can be considered implicit and vague.", "grounding_specificity_rationale": "The reviewer refers to the 'paper,' 'intuition,' and 'pieces fit together,' which suggests they are identifying a problem within a specific part of the paper. They can identify the general area where the lack of clarity is. However, they don't specify *exactly* which section, table, or figure is causing the issue. The description of the problem is also vague, stating 'lacks a clear intuition' rather than pinpointing a specific element. Therefore, the grounding is present but not very specific.", "verifiability_rationale": "The reviewer makes statements like 'Overall, the paper is not particularly easy to follow' and 'the presentation lacks a clear intuition.' These are statements of judgment or opinion. While they identify a problem, they don't provide any specific examples, references, or logical reasoning to support their claim. The reviewer doesn't explain *why* the paper is difficult to follow. Therefore, the claim is not wellsupported by evidence or justification.", "helpfulness_rationale": "The reviewer points out a significant issue for the authors \u2013 the difficulty in following the paper. This is a practical concern. However, the feedback lacks specific suggestions or actionable steps for the authors to improve the clarity. While the problem is relevant, the lack of concrete guidance makes the feedback less helpful in terms of providing direction for improvement. Therefore, it can be considered 3 as it identifies a problem that matters to the authors, but it lacks the depth and specificity needed for full impact."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the potential benefit of simultaneous training on the teacher network's performance and requests KID/FID metrics. While the *what* is clear, the *why* of the unfair comparison isn't explicitly stated, making the action somewhat vague. The request for metrics is a concrete action the authors can take.", "grounding_specificity_rationale": "The comment mentions 'simultaneous training' and 'teacher network' specifically. It identifies the networks being trained but doesn't explicitly state which part of the paper this refers to. The request for KID/FID adds a layer of specificity by pointing to a concrete evaluation metric. Therefore, the grounding is weakly specific as it identifies the networks but not the exact section or unique aspect being addressed.", "verifiability_rationale": "The comment states that 'simultaneous training may improve the performance of the teacher network.' This is a claim. The request for KID/FID metrics provides evidence supporting the relevance of this claim to the authors' work. The reviewer is suggesting that investigating this claim through metrics is a valuable step. The claim is somewhat justified by the request for metrics, but the reviewer doesn't explicitly explain *why* the comparison might be unfair or what specific aspects are causing the unfairness.", "helpfulness_rationale": "The review points out a potential issue (unfair comparison) and requests specific metrics (KID/FID). While the request is valuable, the reviewer doesn't explain *why* they believe the comparison is unfair. The impact on the author's work is indirect but potentially significant if the comparison is indeed unfair. The reviewer provides a suggestion for improvement but doesn't fully explain the problem."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the current method and proposes a modification by adding a 'scaling variable'. While the reviewer doesn't provide explicit steps on how to implement this, the suggestion is a direct and actionable change to the existing formula. The reviewer clearly identifies the area of the paper being discussed (line 157) and the specific mathematical operation. Therefore, the reviewer is pointing out a potential improvement to the existing method, making it actionable.", "grounding_specificity_rationale": "The reviewer directly references 'line 157' in the paper, indicating a clear understanding of the specific section being discussed. They also use technical terms like 'refined region vector', 'u_i', 'attention weight', and 'global pooling', showing a precise identification of the relevant part of the paper and the issue. The reviewer's suggestion is directly related to the identified area. Therefore, the reviewer is not just mentioning the paper but specifically pointing to a mathematical operation and suggesting a change to it.", "verifiability_rationale": "The reviewer's point is about the *mechanism* of the method. They are questioning the *effect* of the scaling factor. While the reviewer doesn't provide a definitive answer, they offer a plausible explanation (lack of flexibility) and a suggestion for improvement. The reviewer uses logical reasoning to explain why the scaling factor might be limited (attention weight in 0, 1). The suggestion of a 'scaling variable' directly addresses this limitation. Therefore, the reviewer is providing a justification for their point, making it 3.", "helpfulness_rationale": "The reviewer's point is about suggesting a modification to improve the method. While the suggestion is valid, it's a *suggestion* and not a direct fix. The reviewer proposes adding a new hyperparameter and potentially retraining or finetuning. The suggestion is valuable and points in a useful direction for improvement. Therefore, the reviewer's comment is helpful in guiding future development of the method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'Failures on the ALFRED benchmark often occurred due to goal misspecification'. This clearly identifies an actionable issue that authors could work on to improve their draft. However, the point does not specify *how* to address this misspecification or what aspects of the goal are problematic. The action is identified, but the implementation details are missing.", "grounding_specificity_rationale": "The review point mentions 'ALFRED benchmark' and 'goal misspecification'. While it identifies the *type* of misspecification, it does not explicitly identify a specific part of the paper or methodology that is affected by this misspecification. The grounding is at the level of the problem (goal misspecification) rather than a specific element within the paper. The connection to the ALFRED benchmark is implied through the context of failures *due* to this misspecification, but not explicitly stated as grounding a specific aspect of the ALFRED framework.", "verifiability_rationale": "The review point makes a claim: 'Failures on the ALFRED benchmark often occurred due to goal misspecification'. This is a claim that needs to be supported. However, the review point lacks specific examples, references, or logical reasoning to explain *why* this correlation exists. It describes the observation but doesn't provide evidence or justification for the claim.", "helpfulness_rationale": "The review point identifies a clear weakness in the draft (goal misspecification) that could lead to improvements. However, it lacks specific guidance on how to address this weakness. The point points to a problem but doesn't offer concrete steps or insights on how to resolve it. The helpfulness is limited by the lack of actionable steps beyond identifying the issue."}
{"actionability_label": "5 (5)", "grounding_specificity_label": "Partially Grounded and Specific (3)", "verifiability_label": "1 (1)", "helpfulness_label": "2 (2)", "actionability_rationale": "The reviewer explicitly states 'I think the improvement of this method over SOTA methods such as IGEV is small.' This is a clear statement of a weakness. They also suggest 'And I have another concern. Currently, SOTA schemes are basically iterative frameworks similar to IGEV. Is it difficult for SamplingGaussian to significantly improve such frameworks?' This suggests a concrete action the authors could take \u2013 analyzing disparity distributions. The reviewer is directly pointing out a problem and offering a potential solution.", "grounding_specificity_rationale": "The reviewer refers to 'iterative optimization schemes similar to IGEV.' While they don't specify a particular section or table, they clearly identify a category of methods. This indicates **Weak Grounding**. However, the reviewer *does* specify the *type* of iterative framework they are concerned about and suggest a *specific analysis* (disparity distributions), which adds some level of specificity.", "verifiability_rationale": "The reviewer makes claims such as 'I think the improvement of this method over SOTA methods such as IGEV is small' and 'Is it difficult for SamplingGaussian to significantly improve such frameworks?'. Neither of these claims are supported by any evidence or logical reasoning within the review point. There are no citations or examples provided to back up these assertions.", "helpfulness_rationale": "The reviewer raises a valid concern about the incremental improvement over SOTA methods and suggests a specific analysis. However, they do not provide any evidence or logical reasoning to support their claim that the improvement is 'small.' The suggestion to analyze disparity distributions is valuable, but the lack of backing for the initial claim makes the overall feedback less impactful. The reviewer also raises a question about the potential limitations of SamplingGaussian, which is a relevant concern."}
{"actionability_label": "3", "grounding_specificity_label": "2: 4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action: 'Investigating how specific models (e.g., GPT4o vs. InternVL2) behave differently when ReGuide is applied'. It also provides a concrete metric for comparison: 'presenting differences in false positive rates (FPR)'. This makes the action clear and the method for implementation specific. The reviewer is not just stating a general idea but providing a clear path for the authors to follow.", "grounding_specificity_rationale": "The comment explicitly mentions 'specific models (e.g., GPT4o vs. InternVL2)' which clearly identifies the part of the paper being addressed. It also specifies the metric for comparison: 'false positive rates (FPR)'. This demonstrates strong grounding as the authors know exactly which aspect of the model behavior to investigate and what metric to use. The 'e.g.,' suggests the reviewer has already considered multiple models, indicating a thorough grounding.", "verifiability_rationale": "The comment contains a claim: 'ModelSpecific Insights: The paper focuses on generic findings across models, but a deeper investigation into how specific models (e.g., GPT4o vs. InternVL2) behave differently when ReGuide is applied could add nuance to the conclusions.' This claim is supported by providing a method for verification: 'presenting differences in false positive rates (FPR)'. The reasoning is logical, and the suggestion is based on existing work (the authors' current experiments and evaluation metric). Therefore, the claim is verifiable through logical reasoning and the availability of relevant data (FPR).", "helpfulness_rationale": "The review point provides very specific and actionable suggestions for the authors. It tells them *what to investigate* (specific models) and *how to compare* (using FPR). This is a highly constructive suggestion that directly builds upon the authors' existing work and aims to provide more nuanced and detailed conclusions. The suggestions are directly tied to the authors' current experimental setup and evaluation metrics, making them highly verifiable and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point implicitly suggests that the authors are unsure about the nature of Fourier modes when treated as numbers. While it doesn't explicitly state 'You should clarify...', the suggestion is clear and actionable. The reviewer points to a specific area of potential confusion and offers a concrete direction for the authors to seek clarification.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Fourier modes' and suggests clarifying whether they are treated as real or complex numbers. This clearly identifies the specific part of the paper and the nature of the clarification needed, making it 4.", "verifiability_rationale": "This review point does not contain a claim that requires verification. It is a suggestion for improvement. While the suggestion is logically sound and based on common practices, it does not fall under the category of a verifiable claim as defined in the guidelines.", "helpfulness_rationale": "This review point is 5 as it directly addresses a potential point of confusion for the reader. By clarifying whether Fourier modes are treated as real or complex numbers, the reviewer provides a clear direction for the authors to seek additional information or context. This type of clarification is valuable for improving the accessibility and understanding of the paper."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking for clarification on the contribution of the task formulation versus pretrained language models. While the reviewer explicitly states the question, the suggestion to include results without pretraining implies an action (to add this experiment), making it partially actionable. However, the action is not very specific about which pretrained models are being referred to, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to the 'results' section and 'pretrained language models' in general, without specifying a particular table, figure, or unique aspect within the paper. While the comment identifies a specific area (results and models), it doesn't pinpoint an exact element within the paper, making it weakly grounded.", "verifiability_rationale": "The reviewer makes a claim that the contribution of the task formulation is unclear. However, this claim is based on the paper's own results and analysis, not on any external evidence or reasoning provided within the review point itself. Therefore, it is not verifiable within this context.", "helpfulness_rationale": "The reviewer suggests an experiment to clarify the contribution of the task formulation by including results without pretrained language models. This is a clear and actionable suggestion that directly addresses a potential ambiguity in the paper. Therefore, it is helpful for the authors to implement this suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states that the axes of Figure 1 are unclear and directly points the authors to the relevant part of the paper. The action is clear: understand the axes. The implementation is also clear: look at Figure 1 and its labels. This is a direct and actionable suggestion.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 1' and directly identifies the issue as 'unclear what the axes are'. The authors can precisely pinpoint the referenced part of the paper. This is 5.", "verifiability_rationale": "The comment does not contain a claim in the sense of a definitive statement of fact. It's a request for clarification. While it implies a need for better explanation of the figure, it doesn't provide any external references or logical reasoning to support the claim that the axes are unclear. Therefore, it is 1 as it stands. However, if the authors *do* understand the axes, the comment implicitly suggests that the explanation of Figure 1 needs improvement, which could be considered a form of implicit claim needing justification. For this framework, it's closer to a request for information than a definitive claim needing verification. Let's consider it as a request for clarification, which is the primary element.", "helpfulness_rationale": "The comment clearly identifies a potential issue (unclear axes) and directly suggests an improvement (understanding the axes). It is a clear and actionable feedback for the authors. The authors can directly address this by examining Figure 1 and its labels. This feedback is directly helpful in improving the clarity and understanding of the paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that 'Direct runtime comparisons with existing methods are missing' and provides a reason for this absence ('The proposed approach is based on implicit differentiation which usually requires additional computational costs.'). This clearly identifies an actionable item for the authors: to include these comparisons.", "grounding_specificity_rationale": "The review point refers to 'direct runtime comparisons' but does not explicitly point to a specific section, table, figure, or unique aspect of the paper where these comparisons should be made. The reference is more general.", "verifiability_rationale": "The review point makes a claim about the absence of direct runtime comparisons and provides a justification for this absence by stating that the method is based on implicit differentiation, which usually requires additional computational costs. This provides some support for the claim.", "helpfulness_rationale": "The review point directly identifies a missing element in the evaluation (direct runtime comparisons) and provides a reason for its absence. This is a clear and actionable piece of feedback for the authors, highlighting a specific area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states, 'I cannot see any technical contribution.' This is an explicit statement about what the authors should do. However, the reviewer does not specify *where* this lack of contribution is or what needs to be done to address it. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer states, 'the proposed framework is a simple combination of metalearning and federated learning.' This provides a specific aspect of the paper being discussed. However, the reviewer then immediately follows this with, 'I cannot see any technical contribution.' This suggests a lack of clarity in the specific issue being raised. The grounding is somewhat clear but the specificity is lacking.", "verifiability_rationale": "The reviewer makes a claim: 'I cannot see any technical contribution.' This is a subjective statement about the paper's novelty. The reviewer does not provide any evidence, reasoning, or external references to support this claim. The claim is presented as an opinion without any backing.", "helpfulness_rationale": "The reviewer's comment is a negative assessment of the paper's technical contribution. It does not offer any specific suggestions or identify concrete weaknesses that the authors can address. The comment is critical and does not provide any helpful information for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests 'discuss case studies and error studies' which is an explicit instruction on what to do. However, it lacks detail on how to conduct this discussion or what specific aspects of effectiveness to focus on. The phrase 'less convincing to figure it out' is vague and doesn't provide a concrete action.", "grounding_specificity_rationale": "The review point explicitly mentions 'Elementlevel Graph Pretraining', 'complex structure', and 'core elements', clearly identifying the specific components being discussed. It also explains the difference between these approaches, providing a clear context for the suggestion to use case studies and error studies. The suggestion itself is specific to evaluating the effectiveness of these components.", "verifiability_rationale": "The review point contains a claim: 'It could be convincing to discuss case studies and error studies to highlight the effectiveness of each proposed component.' This claim is supported by the reviewer's explanation of the different pretraining strategies (Elementlevel focusing on core elements vs. strategies capturing complex structure). The connection between these strategies and the suggested evaluation methods is logical and provides a basis for understanding why case studies and error studies might be helpful.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion: 'discuss case studies and error studies' to address the need to demonstrate the effectiveness of different components. The suggestion is specific to the context of the paper by connecting the proposed components (Elementlevel Graph Pretraining) to the evaluation methods (case studies and error studies). This directly helps the authors understand and validate the proposed components."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is suggesting an *action* \u2013 to consider explicitness (E) and size (S) as extra evaluation \u2013 but does not explicitly state what the implications or consequences of this action would be, nor does it provide concrete steps on how to implement it. The suggestion is presented as a point for consideration rather than a direct action. Therefore, the action is implicit.", "grounding_specificity_rationale": "The reviewer mentions 'DCI framework' and 'ES' in the review point, which can be considered a specific part of the paper being addressed. However, the reviewer does not explicitly state what the issue is with DCI or ES, nor does they clearly explain how explicitness and size relate to this issue. The grounding is present (mentioning DCI and ES), but the specificity of the problem and the connection to explicitness and size is not welldefined.", "verifiability_rationale": "The reviewer states that 'DCI and ES may be entangled with each other' and 'the motivation for considering explicitness(E) and size(S) as extra evaluation'. While the reviewer presents a claim, they do not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a potential issue without justification.", "helpfulness_rationale": "The reviewer raises a valid point about the potential entanglement of DCI and ES and asks for clarification on the motivation for considering explicitness and size. However, the way the point is phrased is somewhat vague and does not clearly articulate the specific problem or the proposed solution. The reviewer is asking for information rather than providing a clear and actionable suggestion. Therefore, the helpfulness is limited."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'Another issue of the paper is that the disentangling is done manually.' This is an explicit statement of a problem. Furthermore, the reviewer specifies the potential issue by pointing to the 'semantic segmentation network is the first module' as a reason for this manual disentanglement. This specificity makes the criticism actionable, as it identifies a concrete aspect of the methodology that could be improved.", "grounding_specificity_rationale": "The reviewer identifies the specific part of the paper being addressed by stating 'the disentangling is done manually.' This demonstrates grounding as the reviewer can accurately pinpoint the section being discussed. The reviewer further specifies the issue by mentioning 'the semantic segmentation network is the first module,' providing a specific reason for their belief in manual disentanglement. This specificity indicates that the reviewer has a clear understanding of the relevant part of the paper and the potential problem within it.", "verifiability_rationale": "The reviewer poses a question 'Why is that? Why not something else?' This indicates a point of inquiry rather than a declarative statement with supporting evidence. While the reviewer suggests an alternative approach ('it would be interesting if the paper did not have this type of manual disentangling'), this is a suggestion for further exploration rather than a verifiable claim with logical reasoning, common knowledge, or external references. Therefore, the claim is not fully supported by verifiable information.", "helpfulness_rationale": "The reviewer raises a valid concern about the manual disentanglement process and suggests an alternative approach. This points to a potential area for improvement in the paper. However, the reviewer does not provide a direct solution or a clear justification for why the current approach is problematic. The feedback is more of a suggestion for further investigation rather than a comprehensive critique with actionable recommendations."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of a strong connection between the theoretical analysis (PACBayesian bounds) and the proposed method (selfattention mechanism). They also explicitly state that the proposed method is similar to selfattention from transformers. While the reviewer identifies a concrete gap (unclear enhancement for distant nodes), the criticism is primarily focused on the *lack* of connection rather than a direct, actionable improvement on a specific detail within the proposed method itself.", "grounding_specificity_rationale": "The reviewer mentions the PACBayesian bounds and the proposed selfattention method, indicating a general understanding of these components. However, they do not explicitly state *where* in the paper the connection between these two should be made. They imply a disconnect but don't pinpoint the specific section, table, or unique aspect where the link is missing. This suggests weak grounding as the reviewer can infer the connection but cannot precisely identify the referenced part.", "verifiability_rationale": "The reviewer's claim that the proposed method 'simply adopts the idea of the selfattention mechanism from the transformer and apply it to the graph' is verifiable as a factual statement. However, the reviewer's claim that 'I fail to see the strong connection between the theoretical analysis and the proposed method' and 'I am not clear how the proposed method enhances the generalization for the distant nodes' are not 5. While the selfattention part is verifiable, the lack of clarity on the specific benefit for distant nodes is an 1 claim.", "helpfulness_rationale": "The reviewer provides a clear criticism regarding the lack of connection between the theoretical analysis and the proposed method, and the unclear enhancement of generalization for distant nodes. This criticism is directly actionable and points to a significant weakness in the paper. While the reviewer doesn't propose a specific solution, they identify a clear area for improvement, making the review helpful."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that 'some of the pieces are simply using existing methods, such as equation (12)'. This indicates an implicit action, as the reviewer knows something is missing but doesn't explicitly state what needs to be done. The vagueness of the statement, 'can only be understood after checking the original paper', further supports the idea that the action isn't clearly defined. The reviewer understands the issue but doesn't provide specific instructions on how to address it.", "grounding_specificity_rationale": "The reviewer mentions 'some of the pieces' and 'equation (12)'. While they identify a potential issue related to equation (12), they do not explicitly state which section, table, or figure is affected. The reviewer's statement, 'can only be understood after checking the original paper', suggests that the grounding of the issue within the current paper is weak. The reviewer identifies a problem but doesn't pinpoint the exact location or content that needs improvement.", "verifiability_rationale": "The reviewer states, 'Some of the pieces are simply using existing methods, such as equation (12)'. This is a factual statement about the content of the paper. There is X, judgment, or suggestion for change. The reviewer is describing a fact without providing any logical reasoning, common knowledge, or external references to support it.", "helpfulness_rationale": "The reviewer's statement, 'Some of the pieces are simply using existing methods, such as equation (12)', is a factual observation. While this points out a potential area for improvement, it does not provide any specific actions or suggestions for the authors to take. The reviewer is stating a fact, not a directive for improvement. Without concrete suggestions or a clear call to action, the information is not particularly helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a problem with the stability definition and suggests a solution by adding a lower bound. The reviewer clearly identifies the left side of the inequality as potentially being arbitrarily small, making the action concrete.", "grounding_specificity_rationale": "The reviewer refers to 'the stability definition' generally, which is weak grounding. While they explain *why* the left side can be small, they don't specify the exact definition or the location within it, making the grounding somewhat specific but not fully specific.", "verifiability_rationale": "The reviewer makes a claim that the stability definition needs better justification. They provide a clear reasoning for why the left side can be arbitrarily small, which supports their claim, making it 3.", "helpfulness_rationale": "The review points out a potential issue with a mathematical definition and suggests a general improvement (adding a lower bound). While the suggestion is relevant, it lacks specific details about where or what the bound should be, making it 3 but not 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the need for comparison to contrastive decoding and mentions potential notational issues. This points to specific areas for improvement. However, the reviewer does not specify *how* the comparison should be done or *what* the notational issues are, making the action less concrete.", "grounding_specificity_rationale": "The reviewer mentions 'existing methods, such as contrastive decoding' and 'notations issues.' While they point to a *category* of methods, they don't pinpoint a specific section or subsection in the paper where this comparison should occur. Furthermore, they don't specify the nature of the 'notations issues,' making it difficult to ground the comment precisely.", "verifiability_rationale": "The reviewer makes a claim that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and that there might be notational issues. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The justification is purely based on the reviewer's perception of the work needing such a comparison and addressing potential notational issues.", "helpfulness_rationale": "The reviewer provides suggestions for improvement, specifically suggesting a comparison to contrastive decoding and addressing potential notational issues. While these suggestions are relevant to the paper's development, the reviewer does not provide specific details on *how* to perform the comparison or *what* the notational issues are. This vagueness makes it difficult for the authors to take concrete action based on this review."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a limitation of the algorithm: its dependence on the full training dataset. While this is a valid concern, the reviewer does not explicitly state how the authors should address this issue. The suggestion is presented as a question ('Overall: ...'), indicating a lack of immediate, actionable advice. Therefore, while the problem is valid, the lack of a concrete step to take makes it 3.", "grounding_specificity_rationale": "The reviewer mentions the algorithm's dependence on the full training dataset. While they don't pinpoint a specific section or table, the context implies a general reliance on the dataset. This constitutes weak grounding. Furthermore, the reviewer does not specify how the algorithm should operate without the full dataset, making the specificity underdeveloped. The mention is weak, and the specification is absent.", "verifiability_rationale": "The reviewer states a problem: 'The effectiveness and problem of the algorithm are that it requires access to the entire training dataset.' This statement functions as a claim. However, the reviewer does not provide any logical reasoning, external references, or examples to support this claim. The claim is stated without sufficient evidence or justification, making it 1.", "helpfulness_rationale": "The reviewer raises two distinct points: the algorithm's dependence on the full training dataset and the perceived lack of technical contribution. The first point, regarding the dataset dependence, is a valid concern and offers a practical limitation for the authors. The second point, about the lack of technical contribution, is a subjective assessment but still provides valuable feedback on the algorithm's novelty. While the second point is more subjective, it still offers a constructive critique. Therefore, the overall review is 3 as it points out a practical limitation and encourages the authors to focus on the algorithmic contribution."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the proposed method is not wellpositioned in literature. They also point out a specific mathematical formulation (expectation of scores conditioned on inputs) that is known and used in other works. While the reviewer identifies a gap, the suggestion to explore existing literature is a highlevel recommendation rather than a detailed, actionable step. The action is implied but not fully specified.", "grounding_specificity_rationale": "The reviewer mentions 'literature' generally and points out a specific mathematical formulation. While they identify a general area (literature) and a specific concept within it, they don't pinpoint an exact section, table, figure, or unique aspect of their own method that is affected. The grounding is present but not very precise.", "verifiability_rationale": "The reviewer makes a claim about the proposed method's positioning in literature and provides supporting information by stating that the key idea has been used in other works, citing specific examples. This claim is supported by logical reasoning and examples.", "helpfulness_rationale": "The reviewer identifies a clear weakness in the proposed method (lack of proper literature positioning) and suggests a valuable direction for improvement (thorough literature review). This is a direct and actionable suggestion for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the reason for choosing PCC over KL divergence as 'the assumption that PCC is a more relaxed constraint compared with KL divergence because of its invariance to scale and shift'. This is an explicit statement of the claim being made. However, the reviewer does not provide concrete evidence or justification for this assumption. The suggestion to provide a gradient comparison between KL and PCC is a concrete action that could address the lack of justification, making the criticism more actionable.", "grounding_specificity_rationale": "The reviewer's statement 'One of the key components is the matching metric, namely, the Pearson correlation coefficient (PCC). However, the assumption that PCC is a more relaxed constraint compared with KL divergence because of its invariance to scale and shift is not convincing enough.' does not explicitly identify a specific part of the paper or constraint that this assumption is being made about. The grounding is weak because the connection to a specific part of the paper isn't clearly established.", "verifiability_rationale": "The reviewer's claim that the assumption about PCC being a 'relaxed constraint' due to 'scale invariance' is 'not convincing enough' is verifiable. The reviewer is stating that the provided reasoning lacks sufficient support. The suggestion to provide a gradient comparison between KL and PCC adds verifiability by offering a concrete way to evaluate the claim.", "helpfulness_rationale": "The reviewer's overall point is that the justification for using PCC is weak. While the reviewer identifies a potential flaw in the reasoning, the criticism itself is somewhat vague and doesn't offer a direct solution or alternative. The lack of a concrete suggestion makes the criticism less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential flaw in the paper's handling of a previously open debate and asks clarifying questions. While the reviewer doesn't directly instruct the authors on how to fix the issue, they are asking for explanations and experiments, which are implicit actions that encourage improvement. The reviewer's questions are specific and target the core of the debate and the methodology used to address it.", "grounding_specificity_rationale": "The reviewer refers to 'a previously careful to leave open (L29)' and mentions 'experiments' but does not explicitly name the section or table where the debate is discussed. The mention of 'experiments' is also general. Therefore, the grounding is weak. The reviewer specifies the *type* of issue (distribution shifts) and the *area of investigation* (removal of information), but lacks specific examples or details about which experiments are being referred to, making the specificity underspecific.", "verifiability_rationale": "The reviewer is questioning the paper's reasoning and asking for justifications regarding the handling of the debate. The reviewer's statement that the paper 'carelessly resolves a debate' implies a lack of sufficient evidence or logical reasoning. The reviewer's questions about distribution shifts and the disentanglement of changes are crucial for verifying the paper's claims and require external references or logical arguments to support them.", "helpfulness_rationale": "The reviewer's questions and concerns about the paper's handling of the debate are valuable feedback that encourages the authors to refine their approach and provide more robust evidence. While the reviewer doesn't directly tell the authors what to do, they are prompting them to clarify their methodology and address a potential flaw, which is a helpful point for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the difference in training parameters (AdamW with cosine LR vs. Adam with fixed LR) and provides a clear description of each setting. This directly identifies an action the authors should take. The action is also concrete, specifying the optimizer and learning rate schedule to consider.", "grounding_specificity_rationale": "The reviewer explicitly identifies the training parameters of the baseline methods as the area of comparison. They clearly point out that the authors are using different optimizers and learning rate schedules. While they don't suggest a specific fix, they clearly pinpoint the relevant part of the baseline methods. The grounding is explicit and the specificity is in identifying the training parameters as the point of comparison.", "verifiability_rationale": "The reviewer makes a claim about the unfairness of the comparison due to the different training parameters. They provide a justification for this claim by stating the difference in optimizers and learning rate schedules. However, they do not provide a direct solution or further evidence to support their claim. The claim is based on logical reasoning and the identification of the differing parameters.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential weakness in the comparison of the methods \u2013 the use of different training parameters. It is clear, actionable, and directly encourages the authors to consider reproducing the baselines with the same settings. This directly helps the authors improve their draft by ensuring fairer comparisons."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states multiple concrete actions the authors should take to improve the plots. They identify that the plots are 'terrible,' 'too small,' have 'hard to distinguish' colors (specifically mentioning pink vs. red), have 'poorly labeled' axes (asking 'what error?'), and labels that are 'visually too similar' (sdropout(tr) vs edropout(tr)). These are all direct and actionable suggestions that the authors can easily implement.", "grounding_specificity_rationale": "The reviewer refers to 'the plots' and 'the experimental results,' which is a general reference. However, they also specify the issues with the colors (pink vs. red) and the similarity of labels (sdropout(tr) vs edropout(tr)), indicating a degree of specificity in the areas they are addressing. While not pinpointing a specific figure, the detailed descriptions of the issues suggest they understand the context of the plots.", "verifiability_rationale": "The reviewer's claims about the plots being 'terrible,' 'too small,' having 'hard to distinguish' colors, having 'poorly labeled' axes, and having 'visually too similar' labels are based on direct observations. They are not relying on external references to support these claims, but rather stating their own assessment of the visual presentation. The reviewer's statement that these are the 'main presentation of the experimental results' and that they are a 'substandard' presentation implies they have some basis for this opinion, even without external evidence.", "helpfulness_rationale": "The reviewer explicitly states that the issues with the plots are the 'main presentation of the experimental results' and that they are a 'substandard' presentation. This directly links the feedback to a negative assessment of the paper's quality. The reviewer also provides concrete suggestions for improvement, such as making the plots larger, using colors that are easy to distinguish, and improving the labeling. These suggestions are directly actionable for the authors, making the feedback 5 in improving the paper."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "3 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "1 (1)", "actionability_rationale": "The review point states \"Table 1 does *not* show standard deviations.\" This is a factual statement identifying a deficiency. While it points to a problem, it doesn't explicitly tell the authors *what to do* or *how to fix it*. The action of adding standard deviations is not explicitly suggested.", "grounding_specificity_rationale": "The review point mentions \"Table 1.\" This explicitly refers to a specific part of the paper. However, the comment itself is about a *deficiency* in that table (lack of standard deviations) rather than a specific action or detail within it. The grounding is present, but the specificity of the suggestion is limited.", "verifiability_rationale": "The review point states \"Overall, this would be a far stronger submission, if the experiments were more extensive.\" This is a subjective statement expressing an opinion about the potential of the submission. There is no explicit claim being made that requires verification within the scope of the current submission. The suggestion about \"more extensive experiments\" is a forwardlooking comment, not a claim about the current work.", "helpfulness_rationale": "The review point identifies a missing element (standard deviations in Table 1) but doesn't provide a concrete, actionable suggestion for the authors to improve their current draft. While it points to an area for improvement, it doesn't directly guide them on how to address it. The suggestion about \"more extensive experiments\" is a general comment about future work, not a specific improvement for the current submission."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides general suggestions for improvement, such as 'improve the structure' and 'focus more on the IEM in Fig 3'. While these point towards specific areas, the reviewer does not explicitly state what actions the authors should take to achieve these improvements. For example, they don't say 'reorganize the introduction' or 'emphasize the IEM section'. The suggestions are broad and lack specific, actionable steps.", "grounding_specificity_rationale": "The reviewer mentions 'several sections' needing more reading, 'the IEM in Fig 3', 'improve the visualization of the Fig 7', and 'Fig'. This demonstrates that the reviewer can identify the specific parts of the paper being referred to. However, the reviewer does not specify *how* these sections or figures need to be improved. For instance, they don't suggest adding a table, removing a section, or clarifying a specific calculation within Fig 3. The suggestions are present but lack the specificity needed to guide concrete changes.", "verifiability_rationale": "The review point does not contain any claims or assertions that require verification. The reviewer is simply stating observations and suggestions for improvement. There is no statement that needs to be supported by evidence or reasoning. The language used is descriptive rather than declarative.", "helpfulness_rationale": "The reviewer's comments are valuable in identifying areas where the paper could be improved. However, the suggestions are general and do not provide specific instructions for the authors. For example, instead of saying 'improve the structure', the reviewer could have suggested 'reorganize the introduction'. The current suggestions are helpful in pinpointing issues but lack the specificity needed to directly translate into actionable improvements for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly suggests exploring 'other architecture' and 'classification tasks', indicating a desire for improvement by broadening the experimental scope. However, it lacks specific details on which architectures or tasks to consider, making the action somewhat vague.", "grounding_specificity_rationale": "The comment identifies a gap in the current experiments by pointing out the limitation of focusing solely on 'neural networks' and 'image classification tasks'. This demonstrates a degree of grounding as the comment refers to specific aspects of the paper's methodology. However, it doesn't pinpoint a specific section, table, figure, or unique element within the paper, making the grounding weak. The comment refers to general categories rather than specific instances.", "verifiability_rationale": "The comment is primarily a suggestion for future work, recommending 'conducting experiments' on 'other architecture and classification tasks'. It doesn't present a claim that requires verification or provide specific examples or references to support the suggestion. Therefore, it doesn't meet the criteria for verifiability.", "helpfulness_rationale": "The comment suggests exploring 'other architecture and classification tasks' as a valuable direction for research. While it points to a significant area for improvement, it lacks specific details on how to achieve this, what specific architectures or tasks to consider, or how to go about conducting these experiments. This makes the suggestion broad and potentially less actionable than a more specific critique or suggestion."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states their point about the locality bias of transformer models but does not explicitly explain how they arrived at this conclusion or what they mean by 'no locality bias' in this context. The reasoning is missing, making it difficult to understand the basis of their claim. Therefore, it is 2.", "grounding_specificity_rationale": "The reviewer mentions 'transformer free of localitybias' and 'neighborhood agents' and 'distant nodes' but does not explicitly refer to specific sections, tables, figures, or unique elements of the paper. The grounding is implicit, as the reviewer implies the relevance of these concepts without clearly pointing to their location or specific aspect within the paper.", "verifiability_rationale": "The reviewer claims to be asking for justification for why transformer\u2019s nolocality won\u2019t make a concern here. However, the review point itself does not provide any justification. The reviewer states their opinion but does not explain *how* they believe transformer models without locality bias are not the best option, or how this relates to the paper's specific problem. There is no logical reasoning, common knowledge, or external references provided within the review point itself to support their claim. Therefore, it is 1 based on the given text.", "helpfulness_rationale": "The review point is not helpful because it lacks justification. The reviewer states their opinion about the locality bias of transformer models but does not provide any supporting evidence or reasoning to back up their claim. Without any justification, the authors cannot effectively address the reviewer's concern or improve their draft based on this feedback. Therefore, it is 2."}
{"actionability_label": "3. 3", "grounding_specificity_label": "", "verifiability_label": "", "helpfulness_label": "", "actionability_rationale": "The review points out a potential issue with the mitigation strategies, specifically their impact on overall performance and utility. However, it doesn't explicitly instruct the authors on how to identify or resolve this issue. The authors would need to interpret the statement and infer the need for further investigation into the performance tradeoffs.", "grounding_specificity_rationale": "", "verifiability_rationale": "", "helpfulness_rationale": ""}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer identifies a missing justification for using 6fold crossvalidation, which can be considered an implicit action. While the reviewer clearly states the reason for crossvalidation is 'not understood', the action of pointing out this missing justification is explicit. However, the reviewer doesn't provide concrete steps or suggestions on *how* to address this lack of understanding, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify a specific part of the paper being addressed regarding the use of 6fold crossvalidation. The comment is more about the *reason* for its use, which is a general concern rather than a specific element of the paper. Therefore, the grounding is weak. The comment also doesn't specify *why* other papers didn't use it, further lacking specificity.", "verifiability_rationale": "The reviewer's statement that 'other papers that this work compares to did not use the cross validation in their papers' is a claim that requires justification. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as a fact without any backing.", "helpfulness_rationale": "The reviewer's primary concern is the lack of justification for using 6fold crossvalidation. While they identify a potential issue, they do not provide a clear explanation of why it's necessary or how it improves the work. The feedback is primarily a question rather than a constructive suggestion, making it less helpful in improving the draft."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for clarification on the 'NonAmbiguous Query Generation procedure' and requests the 'impact of these heuristic components'. This indicates a clear action the authors should take: clarify the procedure and analyze the impact of the heuristics. The reviewer is directly prompting the authors to take specific steps to improve their work.", "grounding_specificity_rationale": "The review point explicitly mentions 'NonAmbiguous Query Generation' and 'heuristic components'. While it doesn't provide the exact section number or a detailed description of the 'heuristic components', it clearly refers to a specific part of the paper and asks about the impact of a specific aspect within that part. This indicates some level of grounding, as the reviewer identifies a specific area, but it is not fully grounded as the exact location and details of the heuristic components are not specified.", "verifiability_rationale": "The review point states 'It would be helpful if the author could clarify the impact of these heuristic components.' This is a request for information and analysis, not a statement of opinion, judgment, or suggestion that requires verification. The reviewer is asking the authors to provide further details, which is a request, not a claim that can be supported or unsupported.", "helpfulness_rationale": "The review point is 5 because it directly points to a specific area needing clarification ('NonAmbiguous Query Generation procedure') and asks for the 'impact of these heuristic components'. This is a very actionable and constructive suggestion. It encourages the authors to be more explicit about their methods and to analyze the consequences of their design choices. While it doesn't provide a solution, it provides a clear direction for improvement, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their doubt and asks a direct question about the relationship between 'knowledge of CAD model correspondences' and 'ray marching'. This constitutes an explicit action, and the request for clarification implies a concrete need for more information. However, the *how* of this relationship isn't immediately clear, making it 3 but potentially lacking in detail.", "grounding_specificity_rationale": "The reviewer mentions specific components of the method ('knowledge of CAD model correspondences' and 'ray marching'), which provides some level of grounding. However, they do not explicitly state which section, table, or unique aspect of the paper this refers to. The reviewer's question about the 'relationship' further indicates a lack of precise grounding. While the *what* is specified, the *where* is less clear, making it 3.", "verifiability_rationale": "The reviewer presents a claim: 'I doubt the proposed method can be trained without using any camera information...'. This is a clear statement of opinion. However, the reviewer does not provide any evidence or reasoning to support this claim. The question about the 'source' of the ray further highlights the lack of justification. Therefore, the claim is not wellsupported, making it 1.", "helpfulness_rationale": "The reviewer's point is clear and directly addresses a potential ambiguity in the method description. They are questioning the necessity of camera information, which could help the authors understand the method's implementation. While the *what* is clear, the *how* and the specific role of camera information are not, making it 3 as it points out a potential area of confusion."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem: 'It seems that ODA, one of the methods of solving the MOIP problem, has learned the policy to imitate the problemsolving method...'. They also suggest a solution: '...but it did not clearly suggest how the presented method improved the performance and computation speed of the solution rather than just using ODA.' This direct identification of the issue and the desired improvement indicates a clear and actionable point.", "grounding_specificity_rationale": "The reviewer mentions 'ODA' and 'problemsolving method' as specific parts of the paper being addressed. While they don't explicitly state which section or table this refers to, the context implies a specific method within the paper being compared to ODA. This indicates a strong grounding, as the reviewer is referring to specific elements of the work.", "verifiability_rationale": "The reviewer makes a claim: 'it did not clearly suggest how the presented method improved the performance and computation speed of the solution rather than just using ODA.' However, the review point itself does not provide any evidence or reasoning to *verify* this claim. The lack of supporting arguments within this specific review point makes it 1.", "helpfulness_rationale": "The reviewer clearly identifies a potential weakness in the paper: the lack of clarity in how the presented method improves upon ODA. They directly point out a gap in the explanation. This constructive critique, identifying a specific area needing improvement, is 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the action \"conducing experiments,\" making it somewhat explicit. However, the suggestion lacks specific details on *which* datasets or *how* the experiments should be conducted beyond \"more datasets.\"", "grounding_specificity_rationale": "The reviewer mentions \"more datasets,\" which is a specific element. However, they don't explicitly link it to a specific section, table, figure, or unique aspect of the paper. The suggestion is general.", "verifiability_rationale": "The reviewer makes claims about the need for more experiments and different experimental settings. However, they don't provide any specific examples, references, or logical reasoning to back these claims up. They are simply stating suggestions.", "helpfulness_rationale": "The reviewer's comment is valid and constructive, suggesting a direction for future work. However, it doesn't directly pinpoint a weakness in the current draft that the authors need to address immediately. It's more of an *encouragement* for further experimentation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that it was not clear how the generic argument task and the random argument task proved what the authors claimed. While the reviewer identifies a problem, they do not explicitly state what is unclear or how to address it. The criticism is general and does not point to a specific action the authors should take. The reviewer's statement is a critique of the process rather than a direct instruction on how to improve the tasks.", "grounding_specificity_rationale": "The reviewer states that it was not clear how the generic argument task and the random argument task proved what the authors claimed. While the reviewer implicitly refers to a specific part of the paper (the experimental setup and tasks), they do not explicitly identify which section, table, figure, or unique aspect of the paper they are referring to. The reference is vague and does not pinpoint the specific part being addressed.", "verifiability_rationale": "The reviewer states that it was not clear how the generic argument task and the random argument task proved what the authors claimed. The reviewer makes a claim (that the tasks proved the claims) but does not provide any evidence, references, or logical reasoning to support this claim. The statement is presented as a critique rather than a statement requiring verification.", "helpfulness_rationale": "The reviewer provides a detailed critique of the dataset transformation and the experimental setup, stating that they 'felt very cumbersome and not very clear.' While the reviewer identifies a problem, they do not offer any specific suggestions or actions for the authors to take. The feedback is primarily critical and lacks constructive recommendations for improvement. The reviewer's comment is a general assessment of the process rather than a specific, actionable suggestion."}
{"actionability_label": "2", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point suggests an interesting possibility but does not provide explicit or concrete actions for the authors to take. It raises a question about the model's applicability to tabular data, which is a valid point but lacks actionable steps.", "grounding_specificity_rationale": "The review point discusses 'multimodal data' in general and mentions 'tabular data' as an example. It does not explicitly identify a specific section, table, figure, or unique element within the paper being addressed. The grounding is implied but not precise.", "verifiability_rationale": "The review point does not contain a claim or assertion. It is a question about the model's applicability to tabular data. Since there is X, there is no evidence to assess for verifiability.", "helpfulness_rationale": "The review point raises an interesting question but does not provide specific, actionable feedback or suggestions for the authors to improve their draft. It does not identify a weakness or propose a concrete improvement strategy."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer states 'For the languageagnostic characters of entity representations, the paper has weak analysis on the alignment of entity representations' which is an explicit statement. However, the reviewer does not specify *how* the analysis is weak or what specific aspects of the alignment are lacking. The action to take is to 'add more analysis about the multilingual alignment of entity representations' which is an explicit suggestion. However, the reviewer does not specify *what kind* of analysis, *how much* more, or *what specific aspects* of alignment they want examined. Therefore, the action is explicitly stated but the implementation details are vague.", "grounding_specificity_rationale": "The reviewer mentions 'entity representations' and 'alignment' which are specific concepts within the paper. However, the reviewer does not explicitly identify a *specific section* or *unique element* of the paper being addressed. The reviewer refers to 'the paper' generally. Therefore, the reviewer identifies the *type* of issue but not the *specific location* within the paper.", "verifiability_rationale": "The reviewer states 'the paper has weak analysis on the alignment of entity representations' which is a claim. However, the reviewer does not provide any *evidence* to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the analysis is weak. Therefore, the claim is made without sufficient justification.", "helpfulness_rationale": "The reviewer provides *specific suggestions* for improvement, such as 'add more analysis about the multilingual alignment of entity representations' and mentions 'visualizations or case studies for different types of languages such as language family'. This indicates a desire to help the authors improve their draft. However, the *details* of these suggestions are *vague*. The reviewer does not specify *which aspects* of alignment to analyze, *what kind* of visualizations, or *which specific languages* to focus on. While the suggestions are present, the lack of concrete details makes it harder for the authors to directly implement them. Therefore, the review point offers helpful directions but lacks concrete implementation details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the issues with the references list, such as duplicates and missing information. It directly points out what needs to be addressed, making it clear and actionable. The specific issues mentioned, like missing publication venues and years, provide concrete details for the authors to follow.", "grounding_specificity_rationale": "The comment identifies problems with the references section but does not specify the exact location of the duplicates or the missing information within that section. While it implies the need to check the references, it doesn't pinpoint the relevant part, making the grounding somewhat weak. The comment specifies *what* is wrong (duplicates, missing venues, years) but not *where* in the paper or section this information is lacking.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a statement of a problem or area for improvement. Therefore, it does not fall under the verifiability criteria.", "helpfulness_rationale": "The review point identifies a concrete issue with the references list, which is a fundamental aspect of academic writing. By highlighting the presence of duplicates and missing publication information, it provides a clear direction for the authors to improve their draft. While it doesn't claim to prove the existence of these issues, it effectively points them out and suggests a direction for the authors to take action. This makes it a 3 comment as it directly addresses a practical concern."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the theoretical analysis in Theorem 1 is unclear and that the meaning of the error bound is not understood. They also suggest that the authors should analyze and compare the theoretical results to other comparable methods. This is an explicit action that can be directly implemented by the authors. The reviewer clearly identifies the area of concern (Theorem 1) and the specific issue (unclear analysis and lack of understanding of the error bound). The suggested action (analyzing and comparing) is also clearly stated.", "grounding_specificity_rationale": "The reviewer refers to 'the theoretical analysis in Theorem 1' and specifically mentions 'the error bound'. This clearly identifies the specific part of the paper being addressed. The reviewer uses literal mention of a section and a specific element within that section to identify the issue. This demonstrates strong grounding as the section and element are explicitly named.", "verifiability_rationale": "The reviewer makes a claim that 'the theoretical analysis in Theorem 1 is unclear and weak' and suggests that the authors should 'analyze and compare the theoretical results to other comparable methods'. This claim is verifiable because the reviewer provides a specific method for verification: comparing the results to other methods. The reviewer's suggestion is a logical step to address the identified weakness and provides a basis for further investigation. The claim is supported by a proposed action and comparison strategy.", "helpfulness_rationale": "The reviewer's comment directly identifies a weakness in the theoretical analysis (unclear error bound) and provides a clear suggestion for improvement (analyzing and comparing with other methods). This actionable feedback is directly relevant to the authors and will help them understand and strengthen their work. The reviewer's intent is to empower the authors to address the identified issue and improve their theoretical framework."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X (X)", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance difference between explicit and implicit methods, which can be interpreted as an implicit action or an action that needs to be inferred. While it doesn't directly demand an action like 'fix the implicit method,' it prompts the authors to understand the underlying reasons for the observed performance difference. The action is somewhat vague as it doesn't specify how to investigate or analyze the methods.", "grounding_specificity_rationale": "The review point mentions 'locomotion tasks' and cites two specific papers (1 and 2). This indicates a degree of grounding as the authors can identify the context and potentially the relevant literature. However, it doesn't explicitly state which specific part of the locomotion task is being addressed or provide details about the methods being compared within that task. The grounding is weak because the authors need to infer the specific aspect being discussed.", "verifiability_rationale": "The review point doesn't contain a claim or opinion. It's a question about observed performance differences. Therefore, it doesn't have verifiable content in the sense of supporting a claim with evidence or references.", "helpfulness_rationale": "The review point raises a valid concern about the performance difference between explicit and implicit methods in locomotion tasks. However, it doesn't provide a direct explanation, analysis, or actionable steps for the authors to take beyond asking for clarification or further investigation. The missing pseudocode is a minor issue compared to the core question about method performance."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the paper's claims and experiments, but doesn't explicitly state what action the authors should take. They are exploring a potential inconsistency rather than directly instructing on a change.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'images corrupted using Gaussian noise' as the specific part of the paper being questioned. This clearly identifies the section or aspect they are referring to.", "verifiability_rationale": "The reviewer makes a claim: 'The paper mentions that their model can work well for a variety of image noise, but they show results only on images corrupted using Gaussian noise.' This claim is not explicitly supported by a logical reasoning, common knowledge, or external references within the review point itself.", "helpfulness_rationale": "The reviewer's question directly targets a potential inconsistency in the paper's claims and experiments. While it doesn't immediately provide a solution, it highlights a point that needs clarification and could be helpful for the authors to address."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "X (X)", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a need for the authors to visualize the performance decline of PU learning methods with increasing dimensionality. However, it does not specify the type of visualization, the data to be used, or the specific aspects of the performance decline to be visualized. The action is identified (visualization), but the concrete steps to achieve it are not provided.", "grounding_specificity_rationale": "The review point mentions 'PU learning methods' generally but does not explicitly refer to a specific section, table, figure, or unique aspect of the paper being addressed. The grounding is weak because the reviewer does not clearly identify the specific part of the paper being discussed.", "verifiability_rationale": "The review point suggests visualizing a phenomenon but does not make any claims or judgments about what is or is not the case. It is a suggestion for an action rather than a statement supported by evidence or reasoning.", "helpfulness_rationale": "The review point directly addresses the stated research motivation by suggesting a concrete next step for the authors (visualizing the performance decline). This provides a clear direction for the authors to explore and potentially improve their work, even though the specifics of the visualization are not provided."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the *what* (mathematical characterization) and the *why* (to remove ambiguity) of improving the definition of approximation error. The suggestion is clear and directly addresses the lack of a precise definition.", "grounding_specificity_rationale": "The reviewer's comment is general and does not specify *where* the ambiguity in the definition of approximation error lies. They do not point to a specific section, table, or unique aspect of the paper. The comment is about the definition itself, not a specific instance within the paper.", "verifiability_rationale": "The reviewer makes a claim about the current definition of approximation error being ambiguous. However, the reasoning or justification for this claim is not explicitly provided within this review point. There are no references to external works or logical reasoning to support the assertion of ambiguity.", "helpfulness_rationale": "The reviewer's comment is relevant and directly addresses a potential weakness in the paper (the definition of approximation error). They suggest a concrete improvement (mathematical characterization) that would likely be helpful for the authors to understand and implement the concept more clearly. The suggestion is constructive and directly addresses a potential issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states two actions: 'The reassignment probability should be increased to allow for more dynamic behavior' and 'The evolution model should be expanded to include changes in other edges.' These are direct and actionable suggestions for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed model' and 'edges with the (on average) 1 node changing cluster.' This clearly identifies the specific part of the paper being addressed, making the grounding explicit. They also specify *what* needs to be changed (edges).", "verifiability_rationale": "The reviewer's criticism is based on the definition of the reassignment probability (1/n) and the logical consequence of this definition on the model's dynamics. While they don't provide external references, the reasoning is clear and logical.", "helpfulness_rationale": "The reviewer provides two clear criticisms and two specific suggestions for improvement. The suggestions are directly linked to the identified weaknesses, making the feedback actionable and constructive for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the missing details about the train/test split and provides an implicit expectation for specific numbers and a description of the splitting method. The request is clear and points to a concrete action (providing the requested information).", "grounding_specificity_rationale": "The reviewer does not explicitly mention a specific section, table, or figure of the paper when stating the missing details about the train/test split. While the request is about a fundamental experimental setup, the reviewer does not identify the *specific* part of the paper where this information should be found. The reviewer only implies that this information is needed for the experimental section as a whole.", "verifiability_rationale": "The reviewer makes a factual observation about the missing details in the paper. The statement itself is verifiable as a factual claim. However, the reviewer does not provide any justification or examples to support why these details are important or how they should be addressed. The request is a statement of fact rather than a critique or a solution.", "helpfulness_rationale": "The reviewer's point is valid and directly relevant to the experimental setup. By highlighting the missing details, the reviewer helps the authors identify a gap in their documentation. However, the point itself does not provide a solution or critique; it simply points out a missing piece of information."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need to *reduce human labor* by exploring different *textual formats* for policy learning. They suggest *reducing human labor* and *exploring different textual formats* as actions to take. This is a clear and direct suggestion for improvement.", "grounding_specificity_rationale": "The reviewer *specifically* mentions the need to understand *text descriptions* and the *optimal textual format* for policy learning. While they don't explicitly name a section or table, the context strongly implies a specific area within the paper where these descriptions and formats are discussed. The reviewer also * specifies *what needs to be improved* (the textual format). This indicates good grounding within the relevant part of the paper and a clear specification of the issue.", "verifiability_rationale": "The reviewer's point is a suggestion for future work (*exploring different textual formats*) rather than a claim that can be verified with logical reasoning, common knowledge, or external references. The reviewer implies the need for experimentation but doesn't provide specific evidence or references to support this suggestion. Therefore, it lacks sufficient justification to be considered verifiable.", "helpfulness_rationale": "The reviewer directly points out a practical issue (the need for human labor due to the lack of knowledge about optimal textual formats) and offers a constructive solution (exploring different textual formats). This provides clear directions for improvement and directly addresses a problem the reviewer identifies. The suggestions are actionable and directly address the identified problem."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review points out a lack of new theoretical results. This is a clear statement of a weakness. The reviewer suggests this is a *new* application of a known loss function. The statement itself is explicit about the missing theoretical results, and the type of missing result (lack of proofs) is also concrete. The reviewer directly identifies the weakness, making it actionable.", "grounding_specificity_rationale": "The review mentions \"this work\" and \"this setting.\" While \"this work\" is not explicitly grounded, \"this setting\" is implied by the context of the loss function and the specific application described in the paper. The reviewer then clearly specifies the issue: \"this work does not prove any new theoretical results.\" This clearly identifies the specific area and the specific weakness within that area. Therefore, the grounding is fully specific, even if the initial reference to \"this work\" is weakly grounded. The issue itself is also clearly stated.", "verifiability_rationale": "The review states \"this work does not prove any new theoretical results.\" This is a claim that needs verification. The reviewer makes the claim but does not provide any specific examples, citations, or logical reasoning to support this claim. They simply state it as a fact. Therefore, the claim is not supported by any evidence, making it 1.", "helpfulness_rationale": "The review points out a clear weakness: the absence of new theoretical contributions. It directly tells the authors *what's missing*. This information is valuable for authors when considering future work or related research. The reviewer's statement is clear and directly identifies a significant aspect of the work. This feedback is actionable and directly informs the authors about a limitation or area for improvement. Therefore, it is 5 for guiding authors in understanding the scope and limitations of the research."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a hypothesis about the difficulty of different image parts. This constitutes an explicit action. However, the reviewer does not provide concrete steps or modifications based on this hypothesis; they simply ask for evidence. Therefore, while the action is stated, the subsequent steps are not explicitly defined, making it 2.", "grounding_specificity_rationale": "The reviewer proposes a specific hypothesis about which image parts are trivial or impossible and attributes this to factors like training data consistency, object pose, and ambiguous labels. This directly identifies the specific parts of the paper (image parts) and explains the issues within them. The reviewer also specifies the potential mechanisms (consistency/training data vs. ambiguity). This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer proposes a hypothesis but does not make a claim that requires immediate verification within the review itself. The request for evidence is about validating the *hypothesis*, not a statement that needs proof *within the paper itself*. Therefore, the verifiability of the review point itself is less central. However, the request *itself* could be considered 3 if the authors *do* provide evidence in their paper.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential weakness in the authors' analysis by proposing a specific hypothesis and asking for evidence. This is a clear and actionable feedback that directly helps the authors improve their understanding and potentially their analysis. The request for evidence is a concrete step they can take to further their investigation."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "2", "verifiability_label": "X (X)", "helpfulness_label": "2", "actionability_rationale": "The review point is a statement of observation, not a suggestion for improvement. It does not identify an explicit action or provide concrete details on how to apply it.", "grounding_specificity_rationale": "The comment refers to the 'bAbI' task generally, with a specific mention of the 'Task 1 of bAbI'. While the paper is mentioned, the core criticism is about the scope of the evaluation within the bAbI framework. The grounding is weak because the authors cannot confidently determine the exact part of the paper/method being addressed beyond the general 'bAbI' task. The specificity is also low as it doesn't pinpoint a specific section or table within the bAbI description.", "verifiability_rationale": "The review point is an opinion about the limitations of the evaluation on the 'bAbI' task. It does not contain a claim that requires logical reasoning, common knowledge, or external references to be verified.", "helpfulness_rationale": "The review point identifies a potential limitation in the evaluation methodology by focusing solely on 'Task 1 of bAbI'. While it doesn't directly suggest improvements, it highlights a gap in the evaluation's scope, which could be considered helpful for the authors to consider when planning future work or expanding their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests improvements to Sec. 3.2, which implies an action. However, the suggested improvement is vague and does not explicitly state how to achieve it. The phrase 'give more illustrations and examples' is a suggestion but lacks specific details on what kind of illustrations or examples would be beneficial.", "grounding_specificity_rationale": "The review point explicitly refers to 'Sec. 3.2' and states that it is 'hard to follow'. This clearly identifies the specific part of the paper being addressed and provides a direct comment on its clarity.", "verifiability_rationale": "The review point contains a claim that 'Sec. 3.2 is hard to follow'. The suggestion to 'give more illustrations and examples' is a common practice to improve clarity and can be considered a form of justification for the claim. While not explicitly backed by a citation within this review point, the suggestion is a generally accepted practice to enhance understanding.", "helpfulness_rationale": "The review point directly addresses a potential weakness the authors might be facing (difficulty in following Sec. 3.2) and offers a relevant suggestion (more illustrations and examples). While the suggestion is somewhat vague, it is still a concrete direction for improvement and is likely to be helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue (time complexity) related to hypervolume calculation in LaMOO. While they identify the problem and the component involved, they don't offer a specific solution or propose an alternative action. The action is somewhat explicit but lacks detailed guidance.", "grounding_specificity_rationale": "The reviewer directly addresses the computational cost of hypervolume calculation in LaMOO. They mention 'Time Complexity,' 'hypervolume calculation,' and 'promising region selection,' which are all specific aspects of the algorithm. The grounding is explicit as they are directly linking the issue to a specific component of the algorithm.", "verifiability_rationale": "The reviewer makes a claim about the potential impracticality of LaMOO for manyobjective problems due to the timeconsuming nature of hypervolume calculation. The reasoning is logical \u2013 calculating hypervolume for many regions in highdimensional space is computationally expensive. While the evidence is generally known about the complexity of hypervolume calculation, the reviewer doesn't provide specific citations or detailed analysis to fully verify this claim. Therefore, it's 3.", "helpfulness_rationale": "The reviewer raises a valid concern about the practical limitations of LaMOO for manyobjective problems. This is a relevant concern for potential users of the algorithm. The impact is on the usability and perceived value of the work. The reviewer's point is directly relevant to the audience of the paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue: 'the dataset used in the experiments are all very small.' This is a direct and clear identification of a problem, making it actionable for the authors to consider alternative dataset sizes. The action is also concrete as the authors can directly assess the impact of small datasets on their results.", "grounding_specificity_rationale": "The reviewer mentions 'the dataset used in the experiments are all very small.' While this identifies the *type* of dataset as small, it doesn't specifically pinpoint a particular section, table, figure, or unique aspect of the paper where this dataset size is a problem. The grounding is present but not fully precise.", "verifiability_rationale": "The reviewer suggests 'It would be more convincing to see some result on medium or even large dataset such as ImageNet.' This is a suggestion for improvement, implying a potential problem with the current results based on the small dataset. However, the reviewer does not provide any specific evidence, reasoning, or external references to support this claim. The suggestion is presented as a constructive idea rather than a clearly verifiable issue.", "helpfulness_rationale": "The reviewer points out a valid concern regarding the use of small datasets in the experiments. While the point is relatively minor and doesn't demand a complex solution, it is a relevant observation that could influence the interpretation and generalizability of the results. The suggestion, though not fully substantiated, is still a constructive comment aimed at improving the robustness of the findings."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer provides suggestions for improvement, such as being 'honest and direct,' and asks a question, 'What does 'brittle convergence properties' mean?'. While the initial statement about limitations is somewhat general, the reviewer does explicitly state actions they would like to see taken, which is a key aspect of actionability. The request for clarification can also be seen as an actionable step the authors should undertake to understand the concept better.", "grounding_specificity_rationale": "The reviewer mentions 'state, reactiveness, and learning during an episode' as areas for improvement. This provides some grounding as it refers to specific aspects of the method. However, the initial statement about limitations is quite general and doesn't pinpoint a specific part of the paper. The reviewer also asks for clarification on 'brittle convergence properties,' which, while specific, doesn't explicitly state which part of the paper this relates to, making the grounding somewhat weak.", "verifiability_rationale": "The reviewer doesn't explicitly state a claim that requires verification. They are pointing out areas where the authors' work could be improved. While the reviewer's suggestions could be considered claims that need to be supported, the paper itself doesn't explicitly state these as claims requiring verification. The reviewer is more focused on identifying areas for improvement than making a definitive statement that needs validation.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as being 'honest and direct' and asking for clarification on 'brittle convergence properties.' These suggestions are generally helpful and actionable for the authors. The reviewer's directness and the request for clarification are positive aspects that contribute to the helpfulness of the feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point directly asks for information on a specific methodological aspect: the synthesis of the focal stack. This is an explicit action the authors should take to clarify their methodology. The point also implicitly asks for the forward model, which can be inferred but is not explicitly stated. The point also implicitly asks how depth discontinuities are handled, which requires the authors to provide more detail on their implementation. While the point doesn't explicitly state an action, it clearly points to a missing or unclear action the authors should take.", "grounding_specificity_rationale": "The review point explicitly states what is missing: the synthesis of the focal stack, the forward model, and the handling of depth discontinuities. This directly grounds the feedback in the authors' work. The point is specific about the location of the missing information. The reviewer is not making a general comment about the paper but is pinpointing specific areas of uncertainty.", "verifiability_rationale": "The review point explicitly states the weaknesses or areas for improvement: the lack of clarity on the focal stack synthesis, the absence of a defined forward model, and the lack of explanation for handling depth discontinuities. The point provides clear examples of what is missing. The reviewer is not making a general claim but is providing specific details about the authors' work. The point is logically structured and provides concrete examples of the issues.", "helpfulness_rationale": "The review point is 5 because it directly addresses key methodological aspects of the authors' work. By asking about the synthesis of the focal stack, the forward model, and the handling of depth discontinuities, the reviewer is pinpointing specific areas where the authors' description is lacking. This provides the authors with concrete feedback on where their explanation needs to be more detailed. The point is specific and actionable, guiding the authors to clarify their methodology. It doesn't just point out a problem but asks for the specific steps taken and how they were implemented."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'It would be good if such a comparison *could be included*.' This indicates a clear and direct action: suggesting a comparison. Furthermore, the reviewer provides a concrete *how* by saying 'transfer adversarial prompts'. The action is not inferred but directly stated and is very specific.", "grounding_specificity_rationale": "The reviewer refers to 'GCG' and 'other LLMs' when suggesting a comparison. This demonstrates strong grounding as the reviewer accurately identifies the specific area of GCG and its application to other LLMs. The reviewer does not merely imply the relevance but explicitly names the components of the work being addressed.", "verifiability_rationale": "The reviewer suggests 'such a comparison *could be included*'. This implies a desire for inclusion, which can be interpreted as a suggestion for improvement. While not a direct recommendation to *do X Y and Z*, the reviewer provides a direction for action by suggesting 'transfer adversarial prompts'. This provides some level of justification, even if it's not a citation.", "helpfulness_rationale": "The reviewer offers a specific and direct suggestion for improvement: comparing GCG's transferability across LLMs. This is a valuable and actionable piece of feedback. The reviewer's suggestion is clear, specific, and directly addresses a potential area for further research or validation. It provides a clear direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly asks for a 'more detailed explanation' regarding the difference between 'similarity' and 'exit times in nature'. This is a clear call for action, as the authors can directly use this request to seek further clarification or resources. The request itself is explicit about the need for more information on these two concepts.", "grounding_specificity_rationale": "The reviewer mentions 'similarity' and 'exit times in nature' as key concepts they don't understand. While they identify the concepts being discussed, they do not explicitly state which section, table, figure, or unique aspect of the paper these terms refer to. The reviewer could have pointed to a specific section or table where these concepts are introduced, making the grounding more explicit.", "verifiability_rationale": "The reviewer is not presenting a claim that requires verification. They are asking for clarification on a specific aspect of the paper. While the request itself could be considered implicitly verifying the authors' lack of understanding, the core of the review is not about providing new information or justifying a claim.", "helpfulness_rationale": "The reviewer explicitly states they 'can't understand what is the difference between similarity and exit times in nature' and hopes for a 'more detailed explanation'. This indicates a clear need for improvement in the authors' understanding of a key aspect of their work, making the review 5 in addressing this gap."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the capabilities of a unified framework, which is an implicit suggestion for further investigation rather than a direct instruction on how to improve the draft. There is no explicit action required from the authors.", "grounding_specificity_rationale": "The reviewer is asking about the limitations of a unified framework in general, not about a specific part of their paper or the framework's implementation. The reference to the framework is vague.", "verifiability_rationale": "The reviewer is implicitly making a judgment about the limitations of the unified framework, which can be considered a claim. However, the claim is not strongly supported by specific evidence from the framework's authors or the review point itself.", "helpfulness_rationale": "The review point raises a relevant question about the limitations of a unified framework, which could help the authors decide if it's suitable for their work. However, it doesn't directly provide actionable steps for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests an alternative dataset (Kialo) and criticizes the authors' dataset creation process as 'optional'. While this points to a potential improvement, the reviewer does not propose a concrete action based on this critique within the context of their own work. They are offering a suggestion, not a direct action to be taken.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Kialo dataset' and 'short claims and their counters' as a more 'clean' and 'specific' alternative. They highlight the 'lack of automatic processes' in the authors' dataset, implying a preference for manual, specific data. This indicates strong grounding specificity as the reviewer clearly identifies the specific part of the paper (dataset) and the issue (lack of specificity) being addressed.", "verifiability_rationale": "The reviewer states a fact ('I found that...') and offers an alternative approach ('it is even cleaner than the dataset the authors created since no automatic processes exist to construct it. Still, what has been created in this paper can be extra data to learn from'). They are not making any claims that require logical reasoning, common knowledge, or external references to be verified. The statement is factual but lacks verifiability in the sense of providing new insights or solutions based on evidence.", "helpfulness_rationale": "The reviewer offers a suggestion ('I found that...') and an alternative approach ('it is even cleaner than the dataset the authors created since no automatic processes exist to construct it. Still, what has been created in this paper can be extra data to learn from'). While this offers a potential benefit, it doesn't directly address a specific problem identified by the authors or provide a concrete action to be taken based on this observation. The helpfulness is limited as it's an evaluative comment rather than a direct critique or solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a limitation regarding the number of tasks and suggests an action to address it by seeing 'several tasks'. The action of increasing the number of tasks is clear and direct. The request for 'sequential results' also provides a concrete action for the authors. The language is explicit about the desired improvement.", "grounding_specificity_rationale": "The reviewer implies a need for more tasks but does not specify the current number of tasks, making the grounding weak. While the suggestion to see 'sequential results' is somewhat specific, the term 'sequential' is not clearly defined in the context of the existing experiments, leading to some lack of specificity in what needs to be analyzed.", "verifiability_rationale": "The comment contains a claim about the limitations of the current experiments and suggests an improvement by seeing 'several tasks'. The suggestion is somewhat vague as it doesn't specify the nature of these tasks or how they should be structured. There is no explicit external reference provided to support this suggestion.", "helpfulness_rationale": "The review point is clear and identifies a potential weakness in the experimental design. However, the suggestion to 'see several tasks' is highlevel and lacks specific details. It doesn't provide concrete examples of what tasks to add or how the sequential results should be analyzed, making it potentially less helpful for the authors without further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point is a question, not a statement that tells the author what to do. Therefore, it is 1.", "grounding_specificity_rationale": "The review point refers to 'parameter S' generally, without specifying which part of the paper or model this parameter belongs to. Therefore, the grounding is not specific.", "verifiability_rationale": "The review point is a question, not a claim that needs verification. Therefore, it is not verifiable.", "helpfulness_rationale": "The review points out a valid problem, but it does not provide any actionable advice or suggestions on how to solve it. Therefore, it is 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the multinode seed cascades are 'artificially created by merging singlenode seed cascades'. This is a direct and clear statement of a methodological limitation. The reviewer identifies the action of 'creating multinode seed cascades' and provides a concrete detail of how this action is implemented ('merging singlenode seed cascades'). This makes the actionable nature of the comment clear.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'experimental setup' as the area of concern. They also specify the exact technique used to create the multinode cascades by referencing '2' and stating that it involves 'merging singlenode seed cascades'. This explicit identification of the section and the method of creation demonstrates full grounding. The reviewer clearly identifies the specific part of the paper and the method used, making the grounding highly specific.", "verifiability_rationale": "The reviewer makes a claim about the 'experimental setup being only semireal'. This is a clear statement of a limitation. The reviewer provides a justification for this claim by stating that 'multinode seed cascades are artificially created by merging singlenode seed cascades'. While the reviewer doesn't provide specific examples of *how* this makes it 'not fully realistic', the statement itself is verifiable based on the information provided. The reviewer logically connects the creation method to the claim of semirealism.", "helpfulness_rationale": "The reviewer points out a potential weakness in the experimental methodology by highlighting the semireal nature of the multinode seed cascades. This is a valuable piece of feedback for the authors as it raises questions about the generalizability of their findings. While the reviewer doesn't offer a solution, they clearly identify a limitation that the authors should be aware of. The feedback is specific enough to guide the authors to consider the realism of their experimental setup and potentially explore more realistic methods in future work. However, it doesn't provide a concrete stepbystep guide on how to fix the issue, making it 3 rather than 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out limitations, but doesn't directly instruct the authors on what to do. They could say \"Add datasets on socioeconomic status\" or \"Evaluate on a model like CLIP,\" but they don't. The statement is vague about how to address the limitations.", "grounding_specificity_rationale": "The reviewer *mentions* specific types of biases and datasets are missing but doesn't pinpoint *exactly* which sections or tables of the paper they relate to. They also don't explicitly state what needs to be *improved* in these areas. While the reviewer mentions \"bias benchmarks,\" \"datasets,\" and \"generative models,\" these are broad categories. They don't specify *which* sections or tables within those categories. The reviewer mentions \"other important biases and datasets are not measured\" and \"missing are assessments on stateoftheart generative models like GPT\". While they identify *types* of missing information, they don't specify *which* parts of the paper these relate to. The reviewer also doesn't specify *what* aspects of these areas need improvement.", "verifiability_rationale": "The reviewer clearly states a *problem* (\"Limited datasets and models\") and suggests a *solution* (\"Expand bias benchmarks\"). This constitutes a claim. However, the reviewer doesn't provide *evidence* to support their claim. They state the problem and suggest a solution but don't explain *why* the current benchmarks are insufficient or *how* evaluating on GPT would be beneficial beyond stating it's missing. The reviewer doesn't provide logical reasoning, common knowledge, or external references to support their claim.", "helpfulness_rationale": "The reviewer identifies a valid concern \u2013 the limited scope of bias evaluation and the absence of generative model assessments. This is helpful in pointing out a gap in the current evaluation practices. However, because the *specificity* of the improvement isn't detailed, the reviewer doesn't offer concrete next steps for the authors. They don't suggest *what* datasets to add or *how* to evaluate on GPT. This lack of concrete action makes the review point less helpful than it could be. It highlights a problem but doesn't provide a clear roadmap for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that Figure 3 is 'challenging to understand' and that the 'workflow and captions are unclear, and the representation of communication modes on the left side is confusing'. While the reviewer identifies a problem, they do not explicitly state what action the authors should take to improve the figure. They point out the issues but don't provide specific instructions on how to fix them.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Figure 3,' 'workflow,' 'captions,' and 'representation of communication modes' as the specific parts of the paper they are addressing. They clearly identify what is unclear about these specific elements. This indicates strong grounding as the authors can identify the relevant section and understand what needs to be improved.", "verifiability_rationale": "The comment does not contain a claim or suggestion. It is a statement of a problem: 'Figure 3 is challenging to understand' and 'the workflow and captions are unclear, and the representation of communication modes on the left side is confusing'. Therefore, there is X to be verified.", "helpfulness_rationale": "The reviewer points out that Figure 3 is 'challenging to understand' and that the 'workflow and captions are unclear, and the representation of communication modes on the left side is confusing'. While they identify a weakness, they do not offer any specific suggestions or actions for the authors to take to address these issues. The comment is a statement of a problem, not a suggestion of a solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of clarity regarding a specific term ('learned MASK embedding') and a stage ('SSL pretraining stage'). While the reviewer directly asks for clarification, they don't explicitly state an action the authors should take based on this information. The reviewer is informing the authors of a potential area of confusion, but the authors are not being asked to perform a specific action with this information.", "grounding_specificity_rationale": "The reviewer explicitly names the term 'learned MASK embedding' and the stage 'SSL pretraining stage'. This directly identifies the specific part of the paper where the issue lies, making the grounding very clear.", "verifiability_rationale": "The reviewer is stating a state of uncertainty or lack of understanding, which does not constitute a claim as defined in the verifiability framework. Therefore, it falls under 'X'.", "helpfulness_rationale": "The reviewer identifies a potential area of confusion for the authors. While this information is relevant and could be helpful for the authors to understand the method better, it doesn't directly instruct the authors on how to improve their draft. The helpfulness is indirect, as it points to a need for clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out that the results are 'partially derivative,' which is an explicit statement about the nature of the findings. However, the reviewer does not provide specific actionable steps or suggestions for the authors to improve their draft based on this observation. While the reviewer identifies a potential issue, they do not offer a concrete action for the authors to take.", "grounding_specificity_rationale": "The reviewer refers to 'results' and 'literature' generally, without specifying a particular section, table, figure, or unique aspect of the paper being addressed. While they mention 'hypernetworks' and 'standard networks,' this is within the broader context of 'results' and 'literature' rather than a precise reference to a specific part of the paper or work.", "verifiability_rationale": "The reviewer makes a claim: 'the reported results seem to be partially derivative.' This is a statement that requires verification. The reviewer then provides a justification for this claim by stating: 'extension to hypernetworks of results already presented in the literature for standard networks.' This justification provides a logical reasoning and specific examples, making the claim verifiable.", "helpfulness_rationale": "The reviewer's comment identifies a potential issue with the results ('partially derivative') and provides a reason for this assessment ('extension to hypernetworks of results already presented in the literature for standard networks'). While the comment doesn't offer a direct solution, it highlights a potential problem that the authors should be aware of, making it 3 in guiding their critical evaluation and consideration of alternative approaches."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action: 'improve it'. While it doesn't specify *how* to improve the figure's readability, the action itself is clear and concrete. The reviewer is indicating a need for better clarity and understandability of Figure 3.", "grounding_specificity_rationale": "The comment explicitly mentions 'Figure 3', providing a clear and specific reference to the part of the paper. The comment also clearly specifies what is wrong with this part ('very hard to read anything on the figure'). This fulfills both criteria for grounding specificity.", "verifiability_rationale": "The comment contains a claim suggesting improvement ('improve it'). While it doesn't provide specific examples or references to back up this claim, the goal itself is clear and verifiable. Authors can infer potential actions like increasing size, using better color schemes, or adding annotations.", "helpfulness_rationale": "The comment directly identifies a weakness ('Figure 3 is very hard to read anything on the figure') and suggests a direct and beneficial improvement ('improve it'). This is a clear and actionable piece of feedback that empowers the authors to address the issue."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment implies the GAT is trained with the whole model but doesn't explicitly state it or ask a direct question about it. It also suggests the need for a native review and rewriting for clarity, but doesn't provide concrete steps for either. Therefore, it's implicit and vague.", "grounding_specificity_rationale": "The comment refers to 'The GAT' and 'the whole model' without specifying which section or part of the paper this refers to. It also mentions 'improving the clarity' generally, without specifying what aspect is unclear. Therefore, the author cannot confidently determine which part the comment addresses, and the comment does not specify what needs to be addressed in this part.", "verifiability_rationale": "The comment contains claims ('Needs to be reviewed by a English native speaker' and 'some sentences need to be rewriting for improving the clarity') but doesn't provide any logical reasoning, common knowledge, or external references to support these claims. The justification is missing.", "helpfulness_rationale": "The comment points out potential issues with the GAT training and the clarity of the paper. However, it doesn't provide specific, actionable steps for the author to take. While it raises concerns, it lacks the direct guidance needed for maximum impact on the author's work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states two actions to be taken: replacing the expression `n^2/(2*s^2)` with a parameter `lambda` and using a learning rate of approximately 0.1. These are direct instructions for the authors to modify their draft.", "grounding_specificity_rationale": "The review point explicitly refers to 'lines 119121' for the first suggestion and 'line 164' for the second. This indicates a clear and precise identification of the location in the paper where changes should be made. The reviewer also specifies the exact mathematical expression and learning rate value to be used, making the grounding very specific.", "verifiability_rationale": "The review point makes a claim about the learning rate being 'unlike the Adam default value, it is unclear what the justification behind this value is.' This claim is not supported by any evidence or references within the review point itself. The reviewer states the issue but doesn't provide any logical reasoning, common knowledge, or external references to back up their claim about the lack of justification.", "helpfulness_rationale": "The review point provides clear and actionable feedback to the authors. It suggests a specific change to a mathematical expression and recommends a particular learning rate. These suggestions are concrete and directly address potential issues in the methodology. While the justification for the learning rate is not provided, the suggestion itself is a valuable piece of feedback for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the need for error analysis and provides a clear explanation of its purpose in identifying potential issues and guiding improvements. The instructions are direct and specify what should be done.", "grounding_specificity_rationale": "The reviewer mentions 'model performance' without specifying which model or aspect of the model's performance is being analyzed. The analysis target is not clearly defined, making it difficult to pinpoint the exact section or table to focus on. While the reviewer implies the analysis should be done on the model's performance, the specific context or data is not provided.", "verifiability_rationale": "The reviewer makes a claim about the importance of error analysis but does not provide any supporting evidence or justification for this claim. There are no logical reasoning, common knowledge, or external references provided to back up the statement that error analysis plays a crucial role in evaluating model performance and identifying potential issues.", "helpfulness_rationale": "The reviewer suggests conducting error analysis and providing explanations for model performance under different scenarios. While this is a valuable suggestion, the review lacks specific details about what kind of error analysis should be performed or how the explanations should be structured. The suggestion is general and could apply to various models and scenarios, making it less immediately actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests analyzing the domain gap and adding discussions about the gap between datasets. While this is a relevant suggestion, it lacks specific actions or concrete steps. The reviewer doesn't explicitly state what needs to be done to analyze the domain gap or what aspects of the gap should be discussed. The suggestion to finetune on synthetic data is a potential solution but lacks specifics on the data or the finetuning process. Therefore, the review point is implicit and lacks concrete actions, making it 2.", "grounding_specificity_rationale": "The review point is quite general and does not specify a particular part of the paper or dataset that needs improvement. The focus is on the 'domain gap' in general, without pinpointing a specific section, table, figure, or unique element. The reviewer doesn't mention any specific section or table where the discussion about the domain gap should be added. The focus is on the concept of the domain gap rather than a specific instance within the paper. Therefore, the review point is 1 at all.", "verifiability_rationale": "The review point contains a claim: 'It would be nice to add some discussions about the gap between datasets.' This is a suggestion for improvement, which can be considered a claim that the current draft lacks this discussion. However, the reviewer does not provide any evidence or reasoning to support this claim. They are proposing a change but not explaining why it's important or how it would be implemented. The reviewer doesn't offer any logical reasoning, common knowledge, or external references to back up their suggestion. Therefore, the claim is not supported by any evidence or justification, making it 1.", "helpfulness_rationale": "The review point suggests analyzing the domain gap and adding discussions about the gap between datasets. While this is a relevant suggestion, it lacks specific details and actionable steps. The reviewer doesn't specify how they would analyze the domain gap or what aspects of the gap they believe are problematic. The suggestion to finetune on synthetic data is a potential solution but lacks specifics on the data or the finetuning process. The review point is general and lacks specific details on how the suggested discussion would be implemented. While the suggestion is relevant, the lack of specifics makes it less helpful than a more detailed comment. Therefore, the review point is 3 but lacks the details needed for full impact."}
{"actionability_label": "None", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "None", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "5", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests two concrete actions: carrying out a significance test on the human evaluation results and comparing the proposed method with recent LLMs. These actions are directly derived from the comments and provide clear directions for improvement. The reviewer is not leaving any ambiguity regarding what needs to be done.", "grounding_specificity_rationale": "The review point suggests improvements to the experiment section but does not explicitly identify which specific part of the paper or results it refers to. While the suggestions are relevant to the experiment section, the exact location or data points are not mentioned. Therefore, the grounding is weak. It could be improved by specifying which section or table the human evaluation results are in or by naming a specific recent LLM.", "verifiability_rationale": "The review point makes two claims: that carrying out a significance test on the human evaluation results is beneficial and that comparing the proposed method with recent LLMs is also beneficial. These claims are supported by general knowledge and common practices in the field. While the reviewer does not provide specific examples or references, the suggestions are grounded in established methodologies and comparisons are relevant to current research trends. Therefore, the claims are verifiable.", "helpfulness_rationale": "The review point provides two clear and actionable suggestions directly related to improving the experiment section. The suggestions are specific enough to guide the authors on what needs to be done, such as conducting a significance test and comparing with LLMs. These suggestions are relevant and helpful for improving the experimental rigor and relevance of the work. The reviewer is not vague or ambiguous about the improvements to be made."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the existing research and suggests a comparison, making the action clear. However, the reviewer does not specify how to apply this action, leaving the authors needing to infer the connection.", "grounding_specificity_rationale": "The comment explicitly mentions which part of the paper it addresses (joint error in UDA) and it is obvious to the authors. However, the comment does not specify what needs to be addressed in this part (e.g., where in the paper the connection should be made or what specific aspects of the previous work are relevant).", "verifiability_rationale": "The claim exists ('the authors claim... but this problem... has already been studied...'). The claim is partially verifiable because the reviewer names a specific paper, providing evidence.", "helpfulness_rationale": "The comment thoroughly identifies a weakness in the paper's related work section (the unsupported claim about joint error in UDA) and offers a specific and actionable suggestion (discuss and compare to a specific paper). This directly addresses a potential gap in the authors' understanding of the existing literature."}
{"actionability_label": "Nonactionable", "grounding_specificity_label": "1", "verifiability_label": "Verifiable", "helpfulness_label": "Not 5", "actionability_rationale": "The review point does not directly instruct the authors on how to improve their draft. Instead, it critiques the methodology of the comparison, specifically mentioning the difference in dataset sizes between the proposed method and the SOTA methods. While this highlights a potential issue, it doesn't provide actionable steps for the authors to take to address this unfair comparison or improve their own work based on this feedback.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper it is referring to. It is a general critique of the comparison methodology. Therefore, it lacks grounding specificity.", "verifiability_rationale": "The review point contains a claim: \"The comparison with the SOTA methods may be unfair.\" It also provides a justification for this claim by stating the performance of the paper is based on a \"newly collected 209M dataset\" while \"existing methods use smaller datasets.\" This justification, while not a direct citation, provides a logical reasoning based on the understanding that dataset size can impact performance.", "helpfulness_rationale": "While the review point raises a valid concern about the fairness of the comparison, it doesn't directly provide actionable advice or insights on how the authors should improve their draft based on this critique. It's more of a headsup about a potential issue in the evaluation process rather than a direct guide for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests using pretrained language models as a base encoder and comparing the transfer parts. This is a clear action that provides a specific next step for the authors. The reviewer explicitly states the method (using BERT/XLNet as a base encoder) and the comparison (transfer parts). This provides a concrete action for the authors to take.", "grounding_specificity_rationale": "The reviewer mentions 'pretrained language models' in general. While the reviewer names specific models like BERT and XLNet later, the initial mention is broad. The reviewer does not explicitly identify the specific part of the paper where these models are being used or how they are being integrated. The grounding is weak because the authors need to infer the specific application of these models. The specificity is also limited as the reviewer doesn't detail the aspects of the models being compared.", "verifiability_rationale": "The reviewer states that 'powerful pretrained language models, e.g., BERT, XLNet, can overcome the domainshift problem to some extent.' This is a claim that needs to be supported. However, the reviewer does not provide any specific examples, references, or logical reasoning to back up this statement. The claim is made without sufficient justification or evidence.", "helpfulness_rationale": "The reviewer suggests using pretrained language models as a base encoder and comparing the transfer parts. This is a relevant suggestion for the domain adaptation problem, especially if the current method uses simpler ngram features. The reviewer provides a clear alternative or improvement path for the authors. This suggestion is directly addressing a potential limitation and offers a concrete direction for improvement."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "Partially Verifiable", "helpfulness_label": "3", "actionability_rationale": "The reviewer states the problem: \"It remains unclear whether the main performance gain originates from a particular module or if the improvement is merely due to having more parameters.\" and \"The current version of the ablation study does not provide definitive answers to these questions.\" This indicates an implicit request for clarification and further investigation. While the reviewer identifies the type of analysis needed (ablation study), they don't specify which modules to ablate or how to interpret the results. This makes the action somewhat vague.", "grounding_specificity_rationale": "The reviewer states the problem: \"It remains unclear whether the main performance gain originates from a particular module or if the improvement is merely due to having more parameters.\" They are pointing to a lack of clarity regarding the *source* of the improvement. However, they do not explicitly identify *which* module or parameter is the source of the confusion. They are pointing to a potential issue without pinpointing its exact location. This is weak grounding. The reviewer also does not specify *what* information is needed to clarify the source of the improvement. This makes the grounding not specific.", "verifiability_rationale": "The reviewer states a question: \"It remains unclear whether the main performance gain originates from a particular module or if the improvement is merely due to having more parameters.\" They are asking a question that requires further investigation and analysis. They *mention* the ablation study as a way to address this, which can be seen as a claim that an ablation study is needed. However, they do not provide details on *how* to conduct the ablation study or *what* results would confirm their suspicion. The evidence is lacking to fully verify the claim. The claim itself is present (the need for an ablation study), but the supporting evidence is incomplete.", "helpfulness_rationale": "The reviewer asks a question: \"It remains unclear whether the main performance gain originates from a particular module or if the improvement is merely due to having more parameters.\" and \"The current version of the ablation study does not provide definitive answers to these questions.\" This is a request for clarification. While the reviewer doesn't provide a direct solution, the information gained from answering the question could be valuable for the authors in understanding and improving their method. It could lead to better resource allocation for further development. The potential benefit is clear, even though the request itself is not a direct solution."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue: \"this requires more explanation\" and asks a direct question: \"why exactly are the two quantities different\". This indicates a clear action the authors should take to understand the paper better. The reviewer also asks a followup question: \"why does this capture the difference in learning settings?\", further emphasizing the need for clarification. The reviewer is directly pointing out a lack of understanding and asking a specific question about it.", "grounding_specificity_rationale": "The reviewer refers to \"quantities\" without explicitly naming the specific part of the paper they are referring to. They are pointing to a concept that is central to their understanding. However, when they ask their questions, they do specify what is unclear: \"why exactly are the two quantities different\" and \"why does this capture the difference in learning settings?\". This suggests that while the initial reference is weakly grounded, the subsequent questions add a layer of specificity to the area of confusion.", "verifiability_rationale": "The review point does not contain a claim or assertion that requires verification. The reviewer is stating a need for more explanation and asking questions. The statement \"this requires more explanation\" is a request, not a definitive assertion that needs to be proven. Therefore, it does not fall under the 'Claim Extraction' step. Since there is X, there is no subsequent step of 'Verifiability Verification'.", "helpfulness_rationale": "The reviewer states \"I still lean toward acceptance.\" This indicates that they believe the feedback is potentially valuable and could lead to an improvement in the paper. However, the reviewer does not offer a solution or a detailed explanation for why the two quantities are different or how this relates to the difference in learning settings. The review is primarily a request for clarification. While the reviewer acknowledges the potential value of the feedback, the lack of a concrete improvement limits its immediate helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point is a question prompting the authors to discuss the sensitivity of fixed tuning parameters. While it encourages the authors to analyze this aspect, it doesn't explicitly state an action or provide a concrete instruction on how to do so. The reviewer is asking a question rather than giving a direct instruction.", "grounding_specificity_rationale": "The reviewer specifically asks about 'fixed tuning parameters' and their 'sensitivity'. This clearly identifies the specific part of the paper being addressed. They also ask for both 'strengths' and 'weaknesses' regarding this sensitivity, which further specifies the issue. The language is precise and directly targets a specific aspect of the model.", "verifiability_rationale": "The reviewer poses a question about the sensitivity of parameters. This can be considered a claim that requires justification. While the reviewer doesn't provide specific examples or references, the question itself points to a verifiable aspect of the model. The sensitivity of parameters can be investigated through experimentation and analysis of the model's behavior with different parameter values.", "helpfulness_rationale": "The reviewer is directly asking the authors to discuss a specific aspect of their model (the sensitivity of fixed tuning parameters) and to identify both its strengths and weaknesses. This is a relevant question that could help the authors understand their model better and potentially identify areas for improvement. While it's a request for analysis rather than a direct instruction on what to change, it directly addresses a potential area of weakness in the authors' consideration of their model's behavior. The question is clear and directly relevant to the model's design choices."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point asks a question and requests experimental details, but it does not explicitly state what needs to be done or suggest an alternative. It's more of a inquiry than a direct instruction.", "grounding_specificity_rationale": "The reviewer is asking a *question* about the framework's compatibility with specific policy gradient approaches, but the connection to a specific part of the framework or the paper isn't explicitly stated. The question about the number of random seeds used in the experiments is specific to the experimental setup. However, the broader question about framework compatibility is less specific.", "verifiability_rationale": "The review point is a question and a request for information, not a statement that needs verification or justification.", "helpfulness_rationale": "The review point is a question seeking information, but it doesn't actively guide the authors towards a solution or provide a concrete takeaway."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The reviewer suggests that the considerations in the paper are also applicable to kernel (ridge) regression. While this is a valid point and could be a valuable extension, it is not an explicit or concrete action that the authors should take based on this review. The reviewer does not specify which part of the paper needs to be revisited or modified to incorporate this kernel regression perspective. The suggestion is more of a potential future direction than a direct action to improve the current draft.", "grounding_specificity_rationale": "The reviewer's comment, 'I am not familiar with the literature: all the considerations in this paper should also be applicable to kernel (ridge) regression, no? Maybe this could also be presented in the 'language of kernel interpolation/smoothing' as well?', does not identify a specific part of the paper being addressed. The reviewer is making a general comment about the potential broader applicability of the work. They are not pinpointing a section, table, or figure that requires clarification or modification.", "verifiability_rationale": "The reviewer's comment is a suggestion or recommendation, not a claim that requires verification based on the provided review point. The reviewer is proposing a potential extension or a different way of framing the work using kernel methods. There is no explicit claim being made about a flaw or an area that needs immediate correction within the scope of this review point.", "helpfulness_rationale": "The reviewer's comment is a suggestion for future work and a potential area for broader application. While it has the potential to be helpful in guiding future research or extending the paper's impact, it is not a direct, actionable suggestion for improving the current draft. The reviewer is not providing specific feedback on what needs to be changed or clarified in the current paper based on their lack of familiarity with the literature."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding references to existing studies. While this is a valid suggestion, it doesn't explicitly state how to add these references or where to find relevant studies. The action implied is to add references, which is a concrete action. However, the specifics of *how* to do this are missing.", "grounding_specificity_rationale": "The reviewer mentions 'critical factors' without explicitly stating which section or table of the paper they are referring to. While the factors are implied to be important, the reviewer does not clearly identify the specific part of the paper where these factors are discussed. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer states that 'Most of the above factors have been discussed in existing studies' without providing any examples, references, or logical reasoning to support this claim. The claim is that these factors have been discussed, and the justification is lacking. There is X made about what needs to be done or what is missing, so it doesn't fit the 'claim' definition of verifiability.", "helpfulness_rationale": "The review point suggests adding references. While this is a relevant suggestion, it is a request rather than a constructive solution. The reviewer does not provide any specific instructions on how to add the references or where to find relevant studies. The helpfulness is limited because the suggestion lacks concrete details and actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "6: X", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests 'unique tasks created from this nice dataset' and provides an example of 'Question Answering from images'. While this points towards a potential improvement, the reviewer does not explicitly state how these unique tasks should be implemented or what specific changes the authors should make to their current tasks to achieve this. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer mentions 'unique tasks created from this nice dataset' and gives an example of 'Question Answering from images'. However, they do not specify which part of the paper these tasks are intended to address. They do not mention a specific section, table, figure, or unique element of the paper that these tasks relate to. The grounding is implied but not explicit.", "verifiability_rationale": "The reviewer states 'It would have been nice to see some unique tasks created from this nice dataset showcasing the diversity of images/plots. e.g. some variety of interleaved imagetext tasks such as Question Answering from images'. This statement is presented as a suggestion or an observation, not as a claim that requires verification. There is no logical reasoning, common knowledge, or external reference provided to support this suggestion.", "helpfulness_rationale": "The reviewer suggests 'unique tasks created from this nice dataset' and provides an example of 'Question Answering from images'. While this is a relevant and potentially helpful suggestion for improving the dataset and tasks, the reviewer does not explicitly explain how these suggestions will help the authors or what specific problems they are addressing. The helpfulness is implied but not clearly articulated or justified."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the framework's limitations and applicability, but it doesn't explicitly state concrete actions or modifications the authors should make to address these issues. While it points to areas for further investigation and discussion, it lacks a direct, actionable suggestion on how to improve the framework itself. The reviewer asks 'what relevance does the framework have with problems of nonconvex losses and/or nonnorm type defenses?' and 'Would the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant? Or would it still give some intuitions on the risk upperbound?'. While these are valid questions, they don't directly instruct the authors on what to do. The reviewer also asks 'p.3, binary classification: If the true mean is known through an oracle, can one use the covariance or any other statistics to design a better defense?'. This is a question, not an explicit action.", "grounding_specificity_rationale": "The review point raises several questions and concerns about the framework but does not explicitly identify a specific part of the paper it is addressing. While the reviewer mentions 'nonconvex losses,' 'nonnorm type defenses,' 'duality gap,' 'maximization over nonnorm type constraints,' 'binary classification,' 'true mean,' and 'covariance,' these are general concepts and not specific sections, tables, or figures within the paper. The reviewer is making a broad critique of the framework's limitations and potential applicability, rather than focusing on a particular aspect of the work. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point raises claims about the framework's limitations and suggests potential alternatives. For example, the reviewer asks 'Would the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant?'. This is a claim that the reviewer is questioning. However, the paper does not explicitly discuss nonconvex losses or nonnorm type defenses in detail, nor does it provide specific examples or citations to support this claim. The reviewer also asks 'p.3, binary classification: If the true mean is known through an oracle, can one use the covariance or any other statistics to design a better defense?'. This is a question posed by the reviewer, not a claim made by the paper. The paper does not explicitly state that the framework is irrelevant or that it cannot be improved upon. While the reviewer is making logical deductions based on the framework's limitations, these deductions are not explicitly stated as claims within the paper itself.", "helpfulness_rationale": "The review point raises valid concerns about the framework's limitations and suggests potential avenues for improvement. The reviewer asks 'what relevance does the framework have with problems of nonconvex losses and/or nonnorm type defenses?' and 'Would the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant? Or would it still give some intuitions on the risk upperbound?'. These questions highlight potential weaknesses in the framework. The reviewer also asks 'p.3, binary classification: If the true mean is known through an oracle, can one use the covariance or any other statistics to design a better defense?'. This suggests a desire for improvement. However, the review point does not offer concrete actions or suggestions for the authors to take based on these concerns. It is more of a critical evaluation of the framework's limitations rather than a direct guide for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the action of 'sparsify the trained models' and compares it to the 'proposed model'. While the method of sparsification isn't specified, the act of sparsifying is clear. The comparison to the proposed model is also a direct action.", "grounding_specificity_rationale": "The reviewer refers to 'the baselines on the left hand side' of Figure 3. This implies they are specifically pointing to a subset of the baselines presented in the figure. The mention of 'unique aspect' is implicit through the context of comparing to the 'proposed model'. While the exact section isn't named, the relevant baselines are visually identifiable.", "verifiability_rationale": "The reviewer is suggesting a new experiment (sparsifying the models) and asking a question (how the accuracy compares). There isn't a direct claim about the paper's content itself. However, the suggestion is related to the existing experiments in Figure 3. The reviewer is implicitly suggesting that this is a worthwhile experiment to explore. The 'verifiability' here is more about the potential usefulness and direction of the experiment rather than a direct claim about the paper's content. It's not a logical deduction, but a suggestion for a new one.", "helpfulness_rationale": "The reviewer suggests a modification to the existing baselines (sparsification) and asks a comparative question. While this points towards a potentially useful experiment, it doesn't provide concrete guidance on how to sparsify or why this would be beneficial. The suggestion is openended and requires further investigation from the authors. It's not a definitive improvement suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the lack of detail regarding the techniques, sparsification, landmark generation, feature types, fixed radius, and shape invariance. While the reviewer doesn't provide a direct solution, they clearly identify the missing components. This is an explicit statement of what is missing and what is missing.", "grounding_specificity_rationale": "The reviewer refers to 'the techniques' and 'landmark features' without specifying the exact section or table. While they point to specific concepts, they don't provide a precise reference to a specific part of the paper. This is weak grounding as the exact location isn't identified.", "verifiability_rationale": "The reviewer makes a claim about the lack of detail. While they provide examples of what is missing, they don't offer any external references or logical reasoning to support this claim within the review itself. The claim is based on the absence of information, not on verifiable facts. Therefore, it is not verifiable based on the information provided in the review point alone.", "helpfulness_rationale": "The reviewer points out a significant weakness in the paper: the lack of detailed information about the techniques. While the feedback is explicit about the missing details, the absence of this information means the reviewer is not providing a solution or guidance on how to reproduce the results. Therefore, it is not helpful in the sense of providing actionable steps for improvement. It is a potential area for improvement, but not a helpful suggestion within the review itself."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem of premature evictions based on utility scores and suggests considering chunk age as an action to address this issue. The action is clear and directly related to the identified problem.", "grounding_specificity_rationale": "The review point discusses the FIITED framework and the concept of utilitybased eviction. While it doesn't explicitly name a section or table, it clearly identifies the issue as 'premature evictions' within the context of the 'utilitybased approach.' This makes it fully grounded in the described framework, although it could be more specific by naming the eviction algorithm or section.", "verifiability_rationale": "The review point makes a claim about the potential for bias in utilitybased eviction. It provides a logical explanation and an example of how recent chunks with temporary high utility could lead to premature evictions of other valuable chunks. This logical reasoning and example support the claim, making it verifiable.", "helpfulness_rationale": "The review point is clear, identifies a specific problem within the FIITED framework, and provides a concrete suggestion for improvement by considering chunk age. The feedback is directly actionable and relevant to the chunk eviction strategy."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer suggests improvements to the framework, such as 'quantitative experiments and comparison between selection of algorithms' and 'detailed explanations on the presented ones.' While these suggestions point towards actionable improvements, the current review point lacks specific details on *how* these improvements should be implemented. The reviewer doesn't provide concrete steps or methodologies for conducting the experiments or developing the explanations. Therefore, while the reviewer identifies a need for improvement, the specific actions required are not clearly defined, making it only 3.", "grounding_specificity_rationale": "The reviewer mentions 'how the different part of this framework performs' and 'contribute to the final result.' This indicates a desire to understand the function and impact of each component. They also refer to the 'result section' and 'experiments,' suggesting they are aware of where performance is discussed. However, the review point does not explicitly identify *which specific parts* of the framework are being discussed or *how they contribute* to the results. The information is general and lacks specific grounding within the framework's architecture or implementation details.", "verifiability_rationale": "The reviewer *claims* to be providing information about the framework's performance by stating 'it lacks either quantitative experiments and comparison between selection of algorithms, or a more detailed explanations on the presented ones.' However, the review point itself does not provide any specific examples, details, or references to support this claim. The statement is presented as a general observation without backing. Therefore, the claim is not wellsupported and lacks verifiability.", "helpfulness_rationale": "The reviewer explicitly states that the framework's 'exact performance and individual parts compared to other solutions is unclear.' This directly points to a lack of helpful information. While the reviewer identifies a gap in the provided information, they do not offer any suggestions or improvements to address this lack of clarity. The review point itself highlights the unhelpful nature of the current information."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a question, not a statement that provides explicit or implicit actions for the authors to take. While it raises a concern, it doesn't directly instruct the authors on how to modify their work or clarify specific aspects. The question is about the *potential* of the model, not a direct instruction on how to implement it.", "grounding_specificity_rationale": "The reviewer's question is about the *potential* of the model to generate novel knowledge or testable hypotheses about neuron data. While the question targets a specific area of research (neuron data and its potential impact), it doesn't explicitly point to a specific section, table, or figure within the paper being reviewed. The reviewer is asking about the *potential* impact, which is a broader question than pinpointing a specific element.", "verifiability_rationale": "The review point is a question, not a statement that makes a claim or assertion. Questions, by their nature, do not have verifiable components. The reviewer is asking for clarification on the *potential* of the model, not making a judgment about the paper's current state or suggesting a specific improvement that can be verified immediately.", "helpfulness_rationale": "The review point is a question, not a statement that provides actionable feedback. Questions, by their nature, do not directly improve the authors' work. They do not provide explicit or implicit actions for the authors to take, nor do they ground the authors in specific parts of the paper or verify any claims. The question is about the *potential* of the model, not a direct request for improvement strategies."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question prompting the authors to consider a simplification, but it does not explicitly state what needs to be done or provide a method for achieving this simplification. The action is implied but not directly stated, making it implicit.", "grounding_specificity_rationale": "The review point refers to 'definition 2 and theorem 2' generally, without specifying which particular definition or theorem is being discussed. The authors cannot confidently determine which part the comment addresses, making the grounding weak.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a suggestion for improvement, not a statement that needs to be supported by evidence or references.", "helpfulness_rationale": "The review point raises a valid concern about the accessibility of complex definitions for a general audience. It encourages the authors to consider simplifying their presentation, which is a relevant and potentially helpful suggestion. However, it does not provide a concrete solution or specific guidance on how to implement this simplification, making it 3 but lacking in actionable detail."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point suggests an experiment (using larger resolution) and asks a question about its potential impact. While it doesn't explicitly state how to implement this, it is concrete in identifying the change (larger resolution).", "grounding_specificity_rationale": "The review point explicitly mentions the resolution (224*224) and asks about the impact on performance, clearly identifying the specific part of the paper and the issue.", "verifiability_rationale": "The review point presents a suggestion (running an experiment) and a question (how performance will be) without providing any justification or evidence to support these claims.", "helpfulness_rationale": "The review point identifies a potential improvement (larger resolution) and asks a relevant question, but it doesn't provide any guidance on how to implement this or why it might be beneficial. It's a suggestion without concrete steps or reasoning."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests an action (mentioning the sampled policy), which indicates an intention to improve the paper. However, the suggestion is vague and doesn't explicitly state how the policy is applied or where it's used within the algorithm. While the reviewer implies an action, the lack of detail makes it somewhat implicit.", "grounding_specificity_rationale": "The reviewer refers to 'these algorithms' without explicitly identifying a specific section, table, figure, or unique aspect of the algorithm. While the reference is somewhat grounded in mentioning 'the sampled policy,' it doesn't pinpoint the exact location or detail within the algorithm's description. The grounding is weak because the reviewer can't confidently determine which part of the paper they are addressing without further context.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It's a suggestion for the authors to consider mentioning the sampled policy. Therefore, it's not verifiable in the sense of supporting a claim with evidence. The suggestion itself doesn't present a judgment or opinion that needs justification.", "helpfulness_rationale": "The review point is relevant to the topic of algorithms and their behavior, suggesting a potential area for clarification. However, the suggestion is vague and doesn't provide specific details on *how* or *where* the policy should be mentioned. While it prompts the authors to think about their algorithm, the lack of specificity makes it 3 but not entirely constructive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitations of the paper's contribution by pointing out that proving lower bounds for round complexity is a major part of the work and that the paper exploits an easy reduction from collaborative ranking, making the lower bound results follow as an easy corollary. The reviewer identifies a specific aspect of the paper's contribution and provides details about it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'proving lower bounds for round complexity' as a specific aspect of the paper's contribution. They also imply that this is a significant portion of the work. The reviewer refers to the method as 'exploits an easy reduction from the problem of collaborative ranking', further specifying the approach.", "verifiability_rationale": "The reviewer makes a claim about the paper's methodology and results by stating that the paper exploits an easy reduction from collaborative ranking, and hence, the lower bound results follow as an easy corollary. However, the review point itself does not provide any evidence to support this claim. The claim is about the paper's content, not just a statement within this review point.", "helpfulness_rationale": "The reviewer identifies a weakness in the paper's contribution (lack of novel lower bound results) and suggests a potential reason (easy reduction). However, the review point does not offer concrete suggestions or actionable steps for the authors to improve their work. The feedback is primarily a critique of the contribution without proposing solutions."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the current prompting technique is 'basic' and that 'carefully curated prompts' could lead to better results. While it implies an action (improving the prompts), the specific action to be taken is not explicitly stated. The suggestion is general and lacks concrete steps on how to curate better prompts. Therefore, it is Implicit and Vague.", "grounding_specificity_rationale": "The review point criticizes the 'prompting technique' in general without specifying which particular aspect or part of the paper the technique is being referred to. There is no mention of a specific section, table, figure, or unique element of the paper being addressed. The grounding is weak because the specific part being discussed is not clearly identified. Therefore, it is 2.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a statement of opinion or suggestion about the prompting technique. There is no assertion that something is lacking, requiring justification or evidence. Therefore, it falls under the X category.", "helpfulness_rationale": "The review point offers a potential improvement direction by suggesting that 'carefully curated prompts' could lead to better results. While it identifies a weakness (the 'basic' prompting technique) and suggests a general improvement, it does not provide specific steps or actionable advice on how to achieve this. The feedback is somewhat general and lacks concrete examples or guidance. Therefore, it is 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the similarity to ConsiStory's approach ('mirrors the approach used in ConsiStory') and highlights the difference in the *source* of the mask ('utilizing CLIPseg and OTSU segmentation rather than crossattention'). This is an *explicit* statement of the action the reviewer is taking \u2013 pointing out a similarity and a difference. The reviewer also clearly identifies the *method* being compared (framewise SDSA) and the *specific components* involved (CLIPseg, OTSU, crossattention). This provides concrete information for the authors to consider. The reviewer's point directly suggests that the novelty is limited due to the similarity to existing work. This provides a clear direction for the authors to investigate and potentially address.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'framewise SDSA' as the method being compared. While they don't pinpoint a specific section of the paper, they clearly refer to a core methodological aspect. This can be considered 'weak grounding' as the authors can infer the section or component being discussed. The reviewer also specifies the components involved (CLIPseg, OTSU) and the alternative used in the compared work (crossattention). This adds a layer of detail, but the grounding is still somewhat implicit.", "verifiability_rationale": "The reviewer makes a claim about the similarity of the *method* to ConsiStory. This is a claim that needs to be supported. While the reviewer names the components, they don't provide *external references* to support the claim about the similarity of the *method*. The support is more based on the description of the components. The claim is somewhat supported by the description of the components, but lacks explicit references to external works directly comparing these components in the context of storyboarding.", "helpfulness_rationale": "The reviewer clearly states the weakness: 'Limited Novelty in Video Storyboarding.' The suggestion is concrete: 'The primary method relies on framewise SDSA, which largely mirrors the approach used in ConsiStory.' The reviewer identifies a specific difference: 'The only notable difference lies in the mask source, utilizing CLIPseg and OTSU segmentation rather than crossattention.' The reviewer's point directly helps the authors understand a potential limitation in their approach and a direction for improvement by considering alternative mask sources. While it could be expanded, it's a valuable starting point for the authors to consider."}
{"actionability_label": "1", "grounding_specificity_label": "1: 2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer criticizes the claim of zeroshot policy transferability but does not explicitly state what action or improvement should be taken based on this criticism. They argue that the difficulty gap between source and target tasks makes transferability questionable, but they do not provide concrete steps for the authors to address this issue. The reviewer's point is more about critiquing the approach rather than suggesting a direct action to be taken.", "grounding_specificity_rationale": "The reviewer makes a general comment about the limitations of the zeroshot approach and the sufficiency of the experimental setup for transfer. They do not explicitly identify which specific part of the paper or method they are referring to. The reviewer is making a general statement about the overall approach rather than pinpointing a specific section or detail.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the zeroshot approach and the sufficiency of the experimental setup. However, they do not provide direct evidence or reasoning within the review point itself to *support* this claim. The reasoning is presented as an argument, not a verifiable fact within the review itself. The reviewer is making a general statement about the overall approach rather than providing specific examples or references to support their claim.", "helpfulness_rationale": "The reviewer provides information and arguments related to the limitations of the zeroshot approach and the sufficiency of the experimental setup. While they are offering insights that could be helpful for the authors to understand the limitations of their current method, they do not directly recommend a different approach or provide concrete solutions. The reviewer is critiquing the method without offering a clear alternative, which limits the helpfulness of the feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point is somewhat vague in its actionable nature. While it points out a potential issue with the number of datasets, it doesn't explicitly state which part of the evaluation process is affected or how the authors should address it. The reviewer mentions 'many methods aim at one of the three tasks, having 5, 6 and 4 datasets for the tasks respectively, might not be enough for a very rigorous evaluation', but doesn't specify which task or dataset is causing the concern. The suggestion that 'not all algorithms can be used on them' is also general and lacks specific examples or guidance on which algorithms are problematic. The lack of explicit action or concrete steps makes it somewhat implicit.", "grounding_specificity_rationale": "The review point is 1 in the specific paper or its content. The reviewer is making a general comment about evaluation practices and the number of datasets used for different tasks. There is no mention of a specific section, table, figure, or unique aspect of the paper being addressed. The comment is about the evaluation setup rather than a specific issue within the paper itself. Therefore, the grounding specificity is low as the authors cannot identify the referenced part of the paper.", "verifiability_rationale": "The verifiability of the review point is low. The reviewer states a potential issue about the number of datasets but doesn't provide any specific evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that 'many methods aim at one of the three tasks, having 5, 6 and 4 datasets for the tasks respectively, might not be enough for a very rigorous evaluation'. The statement is presented as a possibility without concrete justification. Therefore, there is no clear verification of the claim.", "helpfulness_rationale": "The helpfulness of the review point is limited. While the reviewer raises a valid concern about the number of datasets potentially affecting the rigor of evaluation, the review point itself is general and lacks specific details or actionable suggestions. The reviewer doesn't pinpoint a specific problem or offer concrete guidance on how the authors should proceed. The lack of specific examples or recommendations makes it difficult for the authors to take concrete steps based on this review point alone. The helpfulness is further diminished by the lack of verifiability, as the authors cannot confirm the issue or its impact on their specific work."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point lacks explicit and concrete actions. It raises questions and observations but doesn't provide clear steps for the authors to take. The reviewer asks 'How does this method address sparse reward problems in a better way?' which is a question, not an action. The reviewer then states 'From the experiments, this does not support well,' which is a statement of observation, not an actionable suggestion. The reviewer also asks 'in practice, the proposed method requires subtaskspecific rewards to be specified...' which is a question about a limitation, not an action. The reviewer poses a hypothetical question: 'If given the sum of lowlevel reward as the global reward, will the other methods (Qmix) solve the sparsereward tasks as well?' which is a speculative question, not a suggestion for improvement. The lack of explicit instructions or concrete steps makes the review 1.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper or method being discussed. The reviewer refers to 'this method' and 'sparse reward problems' generally. While they mention 'subtaskspecific rewards' and 'Qmix,' they do not point to a specific section, table, or figure in the original paper. The references are more conceptual than specific. The lack of explicit identification of a section, table, or figure makes the grounding weak.", "verifiability_rationale": "The review point makes a claim but does not provide sufficient evidence or justification. The reviewer states 'From the experiments, this does not support well.' This is a claim, but it is not supported by any specific evidence or logical reasoning within the review point itself. The reviewer also asks a question: 'in practice, the proposed method requires subtaskspecific rewards to be specified...' This question implies a lack of support but does not provide any evidence to back it up. The absence of explicit evidence or logical reasoning makes the claim 1.", "helpfulness_rationale": "The review point raises a valid concern about the practicality of the proposed method and its similarity to dense rewards. However, it does not offer any concrete solutions or actions to address this concern. The reviewer asks 'How does this method address sparse reward problems in a better way?' and 'in practice, the proposed method requires subtaskspecific rewards to be specified...' These are questions and observations, not actionable suggestions. While the reviewer identifies a potential issue, they do not provide any steps or guidance for the authors to improve their draft based on this feedback. The lack of actionable suggestions makes the review point 2."}
{"actionability_label": "1: Not Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point is not actionable because it doesn't specify *where* the authors should look in the paper or what questions they should ask to clarify the dataset usage. The reviewer identifies a gap in information but doesn't provide a direct path to resolution.", "grounding_specificity_rationale": "The grounding is weak because the authors cannot definitively determine which part of the paper the comment addresses. The reviewer mentions the AH36M dataset but doesn't explicitly state whether it's used for training or provide context within a specific section.", "verifiability_rationale": "The verifiability is low because the reviewer makes a claim about the lack of clarity and potential unfairness without providing any supporting evidence or logical reasoning within the review point itself. The statement is a claim that requires justification but lacks it.", "helpfulness_rationale": "The helpfulness is moderate because the review points out a crucial experimental detail that affects the interpretation of the results. However, it doesn't provide concrete guidance on how to address the ambiguity or what specific steps the authors should take. It highlights a potential issue but doesn't offer a solution."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out issues with the motivation, experimental comparison, and model size. While these are valid concerns, the reviewer does not explicitly state how the current motivation is unclear or suggest an alternative. The claim about the unfair comparison and the larger model is presented as a general observation rather than a specific actionable suggestion. The model size is mentioned as a potential issue, but without a specific recommendation for improvement. The use of pretrained models is also noted as a concern, but without a concrete suggestion for addressing it. Therefore, while the reviewer identifies areas for improvement, the lack of explicit suggestions or actions makes the comment somewhat vague and less actionable.", "grounding_specificity_rationale": "The reviewer mentions 'motivation,' 'experimental results,' 'other models,' 'CAT and GAN,' and 'pretrained model' as areas of concern. While these are specific parts of the paper, the reviewer doesn't clearly identify *what* is specifically wrong within these areas. For example, the reviewer states the motivation is unclear but doesn't specify *why* it's unclear. Similarly, the claim about unfair comparison is general and doesn't pinpoint the specific issues. The lack of clear identification of the specific part and the issue makes the grounding weak.", "verifiability_rationale": "The reviewer states that the motivation is unclear, the experimental comparison is unfair, and the model is bigger. These statements can be considered claims. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The statements are presented as observations without any justification or evidence. Therefore, while the reviewer makes claims, they are not wellsupported, making them 1.", "helpfulness_rationale": "The reviewer's comments are valid points for improvement. However, the lack of specific suggestions or actionable steps makes the review point less helpful. The reviewer identifies issues with the motivation, experimental setup, and model size, but doesn't offer concrete solutions or alternative approaches. The general nature of the feedback makes it difficult for the authors to take concrete steps to address the identified problems. Therefore, while the reviewer raises important concerns, the lack of specific guidance makes the review point somewhat unhelpful."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "1", "actionability_rationale": "The reviewer's point about the inconsistent performance of the proposed method lacks specific actionable feedback for the authors. While they mention the performance is only compared with few methods, they don't explicitly state what needs to be done to improve the method based on these comparisons. The lack of concrete suggestions makes it difficult for the authors to follow up and address the identified weaknesses. The reviewer also states that the results violate the motivation, but doesn't provide specific analysis for the inferior results, which further limits the actionable insights.", "grounding_specificity_rationale": "The reviewer's point about the inconsistent performance is somewhat general and doesn't explicitly identify a specific part of the paper or method that needs improvement. While they mention the performance is only compared with few methods, they don't pinpoint which comparison is lacking or which specific aspect of the method is underperforming. The criticism is broad and doesn't provide a clear reference point for the authors to focus their attention.", "verifiability_rationale": "The reviewer's claim that the results violate the motivation is verifiable. They state that the performance is only compared with few methods and the proposed method is not consistently better than other methods. This is a clear claim that can be supported by the information provided. However, the reviewer does not provide specific examples or analysis to explain *why* the results violate the motivation, making it only partially verifiable.", "helpfulness_rationale": "The reviewer's statement that the review point is '1' is a direct and clear indication of unhelpfulness. They explicitly state that the review point fails to identify meaningful weaknesses or suggest improvements, leaving the authors with no actionable feedback. The lack of specific analysis for the inferior results further exacerbates the unhelpfulness of the review point."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the *problem* (insufficient experimental demonstration) and highlights the *missing element* of the comparison with Mid Vision Feedback (MVF). It also suggests a *specific improvement* by including this comparison. This makes the action clear and directly actionable for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions the *missing element* of the experimental comparison, which is the 'image classification result of Mid Vision Feedback (MVF)'. It also clearly states *why* this comparison is needed to prove the superiority of the schema searched by ELF (the author's method). The authors can easily identify the specific part of the paper being addressed (the experimental section) and understand what is missing (the MVF comparison). This is 5.", "verifiability_rationale": "The review point makes a claim about the *lack of sufficient evidence* and the *lack of a crucial comparison*. However, it does not provide any *justification* or *explanation* for why the experimental comparison is insufficient or why the comparison with MVF is necessary. The claim is presented without any supporting reasoning or references. Therefore, it is 1.", "helpfulness_rationale": "The review point directly points out a significant weakness in the experimental validation. It clearly states that the current comparison is insufficient and that a comparison with MVF is needed. This information is directly helpful for the authors to understand their limitations and what they need to do to strengthen their work. The reviewer is providing a clear direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the variable 'D' is used for two different concepts (dimensionality and dilation factor), which can lead to confusion. This is an explicit statement of an actionable issue that the authors can directly address by using distinct notation for each concept. The reviewer clearly identifies the ambiguity and provides a clear solution.", "grounding_specificity_rationale": "The reviewer points out a potential source of confusion for the authors by highlighting the dual use of the variable 'D'. While the reviewer doesn't explicitly state which part of the paper this refers to (e.g., a specific equation or section), the mention of 'dimensionality' and 'dilation factor' suggests a lack of precise grounding. The reviewer identifies a potential ambiguity but doesn't provide specific details about the location or the exact nature of the issue within the paper.", "verifiability_rationale": "The reviewer's comment is a suggestion for improvement rather than a declarative statement containing a claim that needs verification. Therefore, it doesn't fit the criteria for verifiability, which requires a claim to be evaluated. The reviewer is offering a recommendation, not making a statement that requires justification or evidence.", "helpfulness_rationale": "The reviewer has identified a potential point of confusion for the authors by highlighting the dual use of the variable 'D'. This is a constructive suggestion that directly addresses a potential ambiguity and offers a solution (using different notation). While it doesn't critique the authors' work directly, it provides a clear direction for improvement, making it helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their understanding of 'state' and directly asks a question about the meaning of 'elements' in the context of lines 186187. This is a clear and direct action that the authors can take to clarify the concept. The reviewer also provides a concrete example of what they perceive 'state' to be (agent position), making the action quite specific.", "grounding_specificity_rationale": "The reviewer does not explicitly identify a specific section, table, or figure in the paper. While they are referring to the general concept described in lines 186187, they do not point to a specific location within the paper. Therefore, the grounding is not fully explicit. The reviewer is also asking for clarification, which is a request rather than a statement of what needs to be addressed.", "verifiability_rationale": "The reviewer is not making a claim that requires verification or justification. They are asking for clarification of a definition, which is a request for information rather than a statement that needs to be proven or supported by evidence.", "helpfulness_rationale": "The reviewer's request for clarification is a valid point that could help the authors understand the underlying concepts better. However, it does not directly instruct the authors on how to improve their draft. It's a request for information rather than a directive to make changes. Therefore, while helpful, it doesn't actively guide the authors towards improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states that the proposed FRM is a 'simple combination' of channel and spatial attention. However, they do not specify how this combination is achieved or what the specific innovative aspect is, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'channel attention' and 'spatial attention,' which are specific techniques. However, they do not point to a specific section, table, figure, or unique aspect of the paper they are addressing. The grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The reviewer makes a claim: 'The proposed FRM is a simple combination of channel attention and spatial attention. The innovative should be given in detail.' However, within this claim, there is no supporting evidence or justification provided to back up the assertion that the FRM is a 'simple combination' or what the lack of 'indepth innovative detail' implies. The verifiability is low as the reasoning is missing.", "helpfulness_rationale": "The reviewer's comment is critical and points out a perceived weakness in the paper's novelty. While it identifies a potential issue, it lacks specific details and constructive suggestions for improvement. The feedback is more of a critique than a helpful suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'reorganize Sections 3 and 4,' which is a direct and clear action. The reviewer is not asking for clarification or interpretation, making it an explicit action. Once the action is identified, the authors can easily understand the suggested change and implement it. The suggestion is very specific, indicating it is also concrete.", "grounding_specificity_rationale": "The reviewer refers to 'Sections 3 and 4,' which are specific parts of the paper. They also mention 'the first paragraph of sec 4' and 'the remainder of sec 4,' further grounding the suggestion in the document. The reviewer doesn't need to infer where these sections are. The comment specifies what needs to be addressed in these parts.", "verifiability_rationale": "The reviewer is suggesting a reorganization. While there isn't a claim being *proven* or *disproven*, the suggestion itself is a factual proposal about the structure of the paper. The reviewer is pointing out a potential issue (redundancy) and offering a solution. The solution is presented as a concrete rearrangement. The reviewer is not making a claim that is either logically sound or supported by external references, but the suggestion itself is a proposal that can be evaluated for its potential impact.", "helpfulness_rationale": "The review point directly addresses a potential issue (redundancy) and offers a clear solution. It empowers the authors to make a structural adjustment. The suggestion is specific and actionable, providing a clear path for improvement. This is a very helpful suggestion that directly addresses a potential weakness."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a missing action: 'a potentially more novel and interesting contribution would be to find out through theorical analyses or extensive experiments the reasons why simple greedy selection approach outperforms more principled acquisition functions (if that\u2019s true) on NAS and why deterministic MLP predictors, which is often overconfident when extrapolate, outperform more robust probabilistic predictors like GPs, deep ensemble or Bayesian neural networks, and such rigorous analyses are missing in the paper.' This action is direct and clear.", "grounding_specificity_rationale": "The reviewer's request is not explicitly identifying a specific part of the paper they are referring to. They state: 'Given the strong empirical results of the proposed method, a potentially more novel and interesting contribution would be to find out through theorical analyses or extensive experiments the reasons why simple greedy selection approach outperforms more principled acquisition functions (if that\u2019s true) on NAS and why deterministic MLP predictors, which is often overconfident when extrapolate, outperform more robust probabilistic predictors like GPs, deep ensemble or Bayesian neural networks.' The request is general and does not pinpoint a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer makes a claim: 'such rigorous analyses are missing in the paper.' They also provide verification by stating the *specific areas* for analysis (theoretical and experimental) and *specific methods* to investigate (greedy selection, MLPs, GPs, etc.). The claim is clearly stated and supported by logical reasoning and specific examples.", "helpfulness_rationale": "The reviewer provides a detailed comment suggesting improvements to the paper by adding 'detailed analyses' and investigating 'why simple greedy selection approach outperforms more principled acquisition functions (if that\u2019s true) on NAS and why deterministic MLP predictors, which is often overconfident when extrapolate, outperform more robust probabilistic predictors like GPs, deep ensemble or Bayesian neural networks.' This comment directly suggests a concrete and likely beneficial improvement for the authors, indicating a clear value proposition."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the need to find where the kmax problem was discussed and to provide a citation. This directly points to a missing element and clearly states what needs to be done, making it concrete. The request is also explicit about the kmax problem, making it actionable.", "grounding_specificity_rationale": "The reviewer asks 'Where else was the kmax problem discussed?' without specifying which paper or section. While the topic ('kmax problem') is specific, the lack of context makes it impossible to pinpoint the exact location. Therefore, the grounding is weak. The request clearly specifies what needs to be found ('where else' and 'citation'), making it specific in its request, but the lack of grounding limits its helpfulness.", "verifiability_rationale": "The review point is a question asking for information ('where else' and 'citation') rather than making a claim. There is no assertion or judgment being made, so it does not contain a claim. Therefore, it has X (X).", "helpfulness_rationale": "The reviewer directly requests a citation for the kmax problem, which is a crucial piece of information for researchers. This directly addresses a potential gap in the reviewer's knowledge and provides a concrete action for the authors to take. The request is actionable and directly addresses a need for information."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly mentions 'forward referencing in the paper' and 'material is introduced without proper explanation' as issues. While it identifies these problems, it doesn't provide specific actions or steps the authors should take to address them. The reviewer points out the *problem* but not the *solution*. Therefore, the action is implied but not explicitly stated and detailed.", "grounding_specificity_rationale": "The review point explicitly refers to 'Figure 1' as a specific part of the paper. While it doesn't provide the exact section, table, or unique aspect within Figure 1, it clearly identifies the *type* of element being referred to. This can be considered a form of implicit grounding by mentioning a specific visual element of the paper.", "verifiability_rationale": "The review point makes clear statements about the issues: 'material is introduced without proper explanation' and 'is explained in later sections'. These statements are logical and can be verified by examining the paper's structure and content. There are no claims that require external references or logical reasoning to be considered verifiable.", "helpfulness_rationale": "The review point identifies two distinct areas for improvement: 'forward referencing in the paper' and 'material is introduced without proper explanation'. While it doesn't offer specific solutions, it clearly points out concrete weaknesses in the paper's presentation. This provides the authors with a clear direction for revision."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states 'analyze the security (i.e., protection of the privacy) of the proposed framework.' This clearly identifies the action the authors should take. However, it doesn't specify *how* to analyze the security, leaving the authors with a general direction but lacking concrete steps. The action is identified, but the implementation details are missing.", "grounding_specificity_rationale": "The comment refers to 'the proposed framework' without specifying a particular section, table, figure, or unique element within it. While the authors can infer the intended scope, the grounding is not explicit. The reference is broad, requiring the authors to make an educated guess about where the analysis should occur.", "verifiability_rationale": "The comment contains a claim: 'The authors do not analyze the security (i.e., protection of the privacy) of the proposed framework.' This is a clear statement of a deficiency. While it doesn't provide specific evidence or references, the claim itself is logically sound and identifies a potential weakness in the authors' work. The claim is present, but lacks supporting evidence.", "helpfulness_rationale": "The comment directly points out a significant omission in the authors' work: the lack of security analysis. This is a valuable piece of feedback as it highlights a crucial aspect that needs to be addressed. While it lacks specifics, it clearly identifies a problem that needs improvement, making it helpful in guiding the authors towards a more comprehensive analysis."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "5 (5)", "verifiability_label": "5 (5)", "helpfulness_label": "1 (1)", "actionability_rationale": "The reviewer identifies a missing explanation regarding the value of PPP maps but does not explicitly state what action the authors should take to address this. They point out a gap in the paper's content rather than directly instructing the authors on how to improve their understanding.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'PPPMaps' and 'understanding PPP effects' in their review point, clearly identifying the specific part of the paper and the concept being discussed.", "verifiability_rationale": "The reviewer makes a claim that 'such an explanation or understanding is not explicitly given in the article' and provides a logical reasoning to support this claim by pointing out the absence of the information.", "helpfulness_rationale": "The reviewer's point is relevant and addresses a potential gap in the paper's contribution. However, it does not provide actionable guidance on how to improve the understanding of PPP effects through PPP maps. It highlights a deficiency rather than offering a solution."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitation of RBI to rewarded actions and the consequence of ignoring useful supervision from rewardless actions. This is a clear and direct criticism of a methodological aspect. While the reviewer doesn't provide a specific solution, the identification of the problem is actionable for the authors to consider alternative approaches or improve their current method.", "grounding_specificity_rationale": "The reviewer refers to 'RBI' and 'rewarded actions,' which are specific concepts within the paper. They also mention 'rewardless actions' and provide an example ('No, the answer is Timothy Dalton.' in Task 3), making the referenced part relatively clear. This is strong grounding as the reviewer identifies the specific area of the paper being discussed and provides a concrete example.", "verifiability_rationale": "The reviewer makes a claim about the potential impact of ignoring rewardless actions on the performance of FP + RBI compared to RBI alone. However, the reviewer does not provide any evidence or logical reasoning to support this claim within the review point. The suggestion for a 'stronger baseline' is a constructive idea but lacks specific details or justification within the provided text. Therefore, the claim is not wellsupported, leading to a low verifiability score.", "helpfulness_rationale": "The reviewer raises a valid point about a potential limitation of the RBI method and suggests that FP + RBI might be an improvement. However, the reviewer does not directly critique or identify specific weaknesses in the author's current draft. Instead, they are offering a suggestion for future work or a discussion point. While the suggestion is valuable, it doesn't directly address the needs of the authors in improving their existing work, making it less immediately helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their understanding of the multiscale statement and provides a clear explanation of why they believe it's misleading (logical time scale). They also explicitly state the benefit of the slow RNN (reduced gradient path). The action is clearly identified, and the details are provided.", "grounding_specificity_rationale": "The reviewer directly addresses the 'multiscale statement' without needing to infer what part of the paper they are referring to. They also clearly specify what they believe is the correct understanding (logical time scale) and what the benefit is (reduced gradient path). This shows strong grounding and specific identification of the issue.", "verifiability_rationale": "The reviewer presents a claim about the misleading nature of the multiscale statement. They provide logical reasoning to support their claim, explaining why they think it's about logical time scale and not physical time scale. While they don't provide external references, their reasoning is clear and logical, making the claim 3.", "helpfulness_rationale": "The reviewer points out a potential area of confusion for the authors regarding the multiscale statement. They explain their understanding and highlight the benefit of the slow RNN. This is a valuable point that could help authors better understand the architecture and its advantages. The reviewer's statement is clear and identifies a specific benefit, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a reason for preferring the stochastic objective function, which is a direct action for the authors to consider. The phrase \"It would be good to make this distinction clearer upfront\" directly suggests a concrete change to the paper.", "grounding_specificity_rationale": "The reviewer mentions \"the expected objective function and observation noise,\" which are specific concepts within the paper. However, they do not explicitly name a specific section, table, or figure. The reviewer is making a general comment about common practices, which implies a general understanding of where these concepts are typically discussed.", "verifiability_rationale": "The reviewer provides a clear logical argument for why the stochastic objective function is preferred. They explain the difference in the decisionmaker's interests and how noise is treated in each case. This reasoning is wellsupported and verifiable.", "helpfulness_rationale": "The review point offers a valuable insight for authors working with noisy data. It highlights a potential point of confusion and provides a clear rationale for considering the stochastic objective function. This information is directly helpful for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a weakness ('poor longrange modelling ability of DGNs') and attributes it to a specific cause ('oversquashing and vanishing/exploding gradients'). It also mentions an alternative explanation ('oversmoothing'). While the point identifies potential causes, it doesn't explicitly state what the authors *should* do to address these issues. The suggestions are presented as possibilities rather than concrete actions.", "grounding_specificity_rationale": "The review point mentions 'DGNs' (Deep Graph Networks) and 'longrange modelling ability' and specifically names 'oversquashing and vanishing/exploding gradients' as a potential cause. It also mentions 'oversmoothing' as an alternative. While the point does identify the specific model and the aspect of performance being discussed, the connection between the identified causes and the weakness in longrange modeling isn't explicitly stated. The reviewer is pointing out related phenomena in deep graph networks as potential contributing factors.", "verifiability_rationale": "The review point presents an alternative explanation ('oversmoothing') and provides a citation for it. While the reasoning behind oversmoothing is generally understood, the reviewer doesn't explicitly link the cited paper to the specific connection between oversmoothing and the poor longrange modeling ability of DGNs. The reasoning is generally accepted, but the connection to the specific point isn't explicitly made.", "helpfulness_rationale": "The review point identifies a potential weakness in DGNs and offers an alternative explanation. While the point is relevant to understanding the limitations of the model, it doesn't provide concrete, actionable advice to the authors on how to improve their own models or address the identified issues. The suggestions are more like observations or alternative possibilities rather than direct solutions."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a problem ('the problem formulation is somewhat unclear') but does not explicitly state how the authors should address it. While it implies the need for clarification, the specific steps or actions are not detailed.", "grounding_specificity_rationale": "The comment mentions 'statement and introduction examples,' providing some grounding. However, it does not specify which exact part (sentence, paragraph, etc.) within those examples is unclear. The term 'somewhat unclear' also adds to the lack of specificity.", "verifiability_rationale": "The review point is a statement of observation ('The problem formulation is somewhat unclear...') rather than a claim that requires verification. There is no assertion of correctness or incorrectness, and no references to external sources are provided.", "helpfulness_rationale": "The review point identifies a weakness in the paper's introduction. While it doesn't provide specific instructions on how to fix it, it points to an area for improvement, making it more helpful than a completely uninformative comment."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The statement explicitly identifies a limitation of a method, stating 'This method only works for generative models that can be finetuned as an in/outpainting model.' This is an explicit action that tells the author what the method cannot be used for. The action is also concrete, as it clearly states the requirement for finetuning.", "grounding_specificity_rationale": "The reviewer makes a general statement about a method's limitations regarding finetuning. They do not explicitly point to a specific section, table, figure, or unique aspect of the author's draft where this limitation would be relevant. While the statement mentions 'in/outpainting model,' which could be considered specific, the overall grounding of the *review point* itself is weak because it doesn't directly link to a specific part of the author's draft.", "verifiability_rationale": "The statement contains a claim about the limitations of a method regarding finetuning. However, the review point itself does not provide specific evidence or references to support this claim. It's a general statement about the method's requirements, but without further context or evidence within this review point, it's difficult to definitively verify. It's not a claim that can be logically deduced from the review point itself.", "helpfulness_rationale": "The statement is informative and directly tells the author about a limitation of a method. This is helpful because it guides the author to avoid using this method if it doesn't fit their needs. The action is clear and directly actionable for the author."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential misunderstanding between the 'curve finding' method and FGE. While the reviewer doesn't explicitly state what action or suggestion they are implying, the act of identifying a discrepancy and proposing an alternative interpretation can be considered an implicit action. However, the reviewer doesn't provide specific details on how the authors should adjust their understanding or implementation of the 'curve finding' method. The suggestion is highlevel and requires further investigation by the authors.", "grounding_specificity_rationale": "The reviewer refers to 'the curve finding (the first part)' and 'FGE (the second part)'. While they mention specific components, the connection between them is described in a general way. The reviewer doesn't explicitly state which section, table, figure, or unique aspect of the paper they are addressing. The mention of 'the first part' and 'the second part' is a general reference rather than a precise grounding. The description of the potential misunderstanding is also general.", "verifiability_rationale": "The reviewer states a potential misunderstanding and suggests an alternative interpretation. This statement itself is a claim that requires some level of justification. While the reviewer doesn't provide explicit examples or references to external works to support their claim, the suggestion of an alternative interpretation implies a logical reasoning process. However, the claim is not fully supported by concrete evidence or references.", "helpfulness_rationale": "The reviewer identifies a potential misunderstanding between the 'curve finding' method and FGE. This is a valuable piece of information for the authors, as it clarifies a point of confusion. The reviewer also suggests an alternative interpretation of the 'curve finding' method, which is a helpful suggestion for the authors to consider. While the reviewer doesn't provide a definitive solution, they offer a potential cause and a direction for further investigation. The raised concern about computational demands is also a valuable insight that the authors should consider. The reviewer's comment is informative and points towards a potential area for clarification and further exploration, making it 3."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point starts with \"while it is interesting to see the grounding of the proposed method in neuroscience...\" This immediately suggests a critique or comparison. However, the critique is vague. It's not explicitly telling the authors what to do. It's more of an observation about the novelty of the ideas. The phrase \"general ideas are already present in other methods for exploration...\" is a statement of opinion without any specific action or suggestion. The reviewer doesn't tell the authors to compare their method to specific existing methods or provide any concrete steps for improvement based on this observation.", "grounding_specificity_rationale": "The review point mentions \"general ideas are already present in other methods\" and names specific methods like \"generalized Voronoi graph, semantic maps, pose graphs, and curiositydriven exploration.\" While it names specific methods, it doesn't explicitly state which of these methods the authors' method *should* be compared to. The reference to the appendix is also a point of weakness \u2013 it's not a standard citation. The reviewer doesn't specify *how* the proposed method should be compared to these existing methods (e.g., are there advantages/disadvantages in terms of computational cost, exploration quality, etc.). The reference to the appendix without a specific section number makes it difficult to pinpoint the relevant information. Therefore, while the review mentions specific methods, it doesn't explicitly ground the comparison to a particular method or provide sufficient specificity for the authors to understand the implications.", "verifiability_rationale": "The review point contains the claim \"the general ideas are already present in other methods for exploration...\" This is a clear statement of opinion. However, the reviewer *mentions* specific methods as evidence for their claim. While the methods are named, the *review point itself doesn't provide detailed explanations, citations, or concrete evidence to support the claim that these methods are directly comparable or superior to the proposed method. The reference to the appendix is again a lack of concrete evidence within the review point itself. The claim is stated, but the supporting evidence is external and not fully detailed within the review.", "helpfulness_rationale": "The review point raises a valid concern about the novelty of the proposed method by pointing out the existence of similar ideas in other exploration methods. However, it lacks concrete suggestions for improvement. The reviewer mentions specific methods but doesn't provide actionable steps for the authors to take. For example, they could suggest a comparison of computational costs, a direct comparison of exploration quality in specific scenarios, or a discussion of the advantages and disadvantages of using a neuroscienceinspired approach versus existing graphbased methods. The lack of specific suggestions makes the review point more of a critique than a helpful guide."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states the problem (experimental setup in the appendix makes interpretation hard) and suggests a solution (move some details back). However, the action of 'moving some details back' is not explicitly defined or actionable. The reviewer doesn't specify which details or how this would be done. The suggestion is general and lacks specific guidance.", "grounding_specificity_rationale": "The reviewer refers to 'experimental setup, tasks, and other details,' which are generally found in the 'experiments' section of the paper. While not a literal mention, this section is a clear reference point within the paper's structure. The reviewer also specifies the *type* of details (related to experimental setup and tasks), adding clarity to the grounding.", "verifiability_rationale": "The review point is a suggestion ('I would suggest...') rather than a claim that needs to be supported by evidence. There is no explicit statement of what is wrong with the appendix or why moving details would be beneficial, relying on general assumptions.", "helpfulness_rationale": "The reviewer points out a common issue (information in the appendix making interpretation difficult) and offers a constructive suggestion (move details back). This is a relevant comment that directly addresses a practical concern for the authors. However, the suggestion is somewhat general and lacks specific details on which aspects to move or why the appendix is problematic."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment identifies a gap but doesn't fully instruct the authors on the next step. While it points out the absence of a reference for 'Memb', it doesn't explicitly state how the authors should go about finding or implementing a reference.", "grounding_specificity_rationale": "The review point mentions 'Memb' but doesn't specify *where* in the paper 'Memb' is relevant. It also doesn't explain *why* there's no reference. The reference to 'Memb' is vague.", "verifiability_rationale": "The review point makes a claim: 'there is no mention to any reference.' It *does* provide evidence for this claim by stating the absence of a reference. However, it doesn't explain the *implications* of this missing reference or provide any guidance on how to address it beyond finding a reference.", "helpfulness_rationale": "The reviewer is highlighting a common practice in academic writing (the need for references) and pointing out a deviation from that practice ('Memb' being the 'previous stateoftheart'). This is a valid observation that would likely be helpful for the authors in terms of improving their draft by ensuring proper referencing."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point suggests a *direction* for future research (studying the impact of unseen classes) but does not provide a specific *action* or *change* to be made in the current draft. It lacks concrete steps on how to implement this suggestion.", "grounding_specificity_rationale": "The review point mentions 'unseen classes' in general, without specifying a particular section, table, figure, or unique aspect of the paper that it addresses. The grounding is weak because the authors cannot confidently determine which part the comment refers to.", "verifiability_rationale": "The review point is a suggestion for future research and does not contain a claim that can be verified. It does not state that the current work has a flaw or needs improvement based on this suggestion.", "helpfulness_rationale": "The review point identifies a relevant area of investigation (the impact of unseen class ratios) and suggests a valuable direction for future work. While it doesn't directly change the current draft, it provides a meaningful feedback point that can guide further research and potentially lead to improvements in the future. It is more than just a suggestion; it points towards a concrete area of exploration."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer is asking for a definition of epsilongreedy exploration, which is a direct action for the authors to take in order to understand the implementation. The request is clear and directly points to a missing piece of information. The reviewer is asking for a direct explanation of a concept, which is an explicit action.", "grounding_specificity_rationale": "The reviewer refers to 'training' and 'epsilongreedy exploration' in the context of the proposed strategy. While they don't explicitly name a section, the context strongly suggests they are referring to the training process described in the paper. However, they don't provide a specific section or table number, making the grounding somewhat weak. The reviewer is asking for clarification on a part of the method, which implies they are unsure about a specific detail.", "verifiability_rationale": "The reviewer is asking for a definition of epsilongreedy exploration. This is a claim that needs to be supported. The paper should define epsilongreedy exploration, and if it does, the reviewer's request is a request for that definition. The request is clear and points to a missing justification or explanation. The reviewer is asking for a definition, which is a claim that needs to be verified.", "helpfulness_rationale": "The reviewer's question is directly aimed at improving the authors' understanding and implementation of the proposed strategy. It is a valid and helpful request because it addresses a potential point of confusion for the authors regarding the training process. The reviewer is asking for a clarification that would allow them to replicate or build upon the work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states their assessment of the method's novelty directly, which is an explicit action. However, they do not specify *how* the method is a combination of GCN and normalizing flow, nor do they pinpoint the exact lack of new stuffs. The action is present, but lacks detail.", "grounding_specificity_rationale": "The reviewer's assessment is general and does not specify *which* part of the method they find lacking in novelty. They do not mention specific sections, tables, figures, or unique elements of the paper. The grounding is weak or nonexistent.", "verifiability_rationale": "The reviewer makes a claim about the lack of novelty. However, they do not provide any evidence or reasoning to support this claim. The verifiability is low as there is no justification for the statement.", "helpfulness_rationale": "The reviewer clearly states their assessment of the method's novelty, which is a helpful piece of feedback for the authors. However, the criticism is general and lacks specific suggestions for improvement. While it points to a valid concern, it doesn't offer actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of the former framework (Line 167174, Sec. 4) and suggests a concrete improvement by focusing on representation learning. This is an explicit statement of a problem and a proposed solution, making it actionable.", "grounding_specificity_rationale": "The reviewer refers to 'the former framework (Line 167174, Sec. 4)'. While they mention the section, they do not explicitly identify the specific subsection or element within that section that has the limitation. Therefore, the grounding is weak. However, the reviewer does specify the *content* of that section (mask selection and rawlevel features) and the *lack of limitation to representation learning*. This provides a basis for grounding, even if not perfectly precise. Thus, it is '3'.", "verifiability_rationale": "The reviewer makes a claim: 'The former framework (Line 167174, Sec. 4) seems not limited to rawlevel selection.' However, within the provided review point, there is no evidence or reasoning provided to support this claim. The reviewer suggests an improvement *because* they believe this, but the claim itself lacks justification.", "helpfulness_rationale": "The reviewer provides a clear criticism of the former framework and offers a specific suggestion for improvement: focusing on representation learning. This is a direct and actionable feedback that empowers the authors to improve their draft. The suggestion is concrete and directly addresses the identified limitation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a gap in information (missing details on reward design) but does not explicitly state how the authors should address this gap. While it points out a problem, it lacks a direct, actionable instruction.", "grounding_specificity_rationale": "The comment mentions 'how to design the rewards is not fully understandable' but does not specify which section, table, figure, or unique aspect of the paper this refers to. The reference to 'the paper' is vague.", "verifiability_rationale": "The comment states a problem ('some details are missing') but does not make a claim that requires verification. It's a statement of a lack of information, not a definitive assertion that needs supporting evidence.", "helpfulness_rationale": "The comment identifies a valid issue (missing details) that could hinder the authors' progress. However, it does not provide any suggestions or guidance on how to address this issue, making it less helpful overall."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks the authors to discuss the runtime of Prithvi WxC, which is a crucial aspect for MLbased emulators. It also links this to a common selling point of these models, making the action clear and direct. The reviewer is prompting the authors to take a specific action (discuss runtime) based on a general understanding of the field.", "grounding_specificity_rationale": "The review point explicitly mentions 'Prithvi WxC' and asks about its 'runtime.' This direct identification of the model and the specific aspect being addressed makes it 5. The reviewer is not making an inference but rather directly pointing to a specific part of the paper and the issue with it.", "verifiability_rationale": "While the review point doesn't present a claim that *something is wrong* about the authors' work, it provides a suggestion based on general knowledge of MLbased emulators. It points out a relevant consideration (runtime) for the specific model, making it 3 but not strictly verifiable in the sense of providing proof. The reviewer is making a logical suggestion based on common knowledge.", "helpfulness_rationale": "The review point is 5 as it directly addresses a common justification for using MLbased emulators (computational efficiency) and prompts the authors to include a relevant detail (runtime). This is a concrete piece of information that will be beneficial for their readers. It provides a clear and actionable suggestion for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1 (1)", "actionability_rationale": "The reviewer points out a problem (unclear paraphrases) and the consequence (impact on subsequent steps and training data quality). However, they do not explicitly state what the authors should do to improve the paraphrases or how to implement that improvement. The suggestion is implicit: 'You should make sure your paraphrases are very different.'", "grounding_specificity_rationale": "The reviewer does not specify which paraphrases are unclear. They are general about the process of generating paraphrases but don't pinpoint specific sentences, examples, or sections of the paper where the issue lies.", "verifiability_rationale": "The reviewer states a problem ('When generating paraphrases... it is unclear how different the paraphrases are...') and a consequence ('This crucially impacts the subsequent steps...'), which constitutes a claim. However, they do not provide any evidence or reasoning to support their claim about the paraphrases being unclear. They don't offer any examples of unclear paraphrases or suggest ways to verify the quality difference.", "helpfulness_rationale": "The review points out a potential issue (poor paraphrase quality) but doesn't offer any concrete solutions or guidance on how to address it. It's a valid observation but lacks actionable advice. The impact on subsequent steps is mentioned, but the reviewer doesn't suggest *how* to mitigate the negative effects."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment states 'The writing could be improved,' which is an implicit action suggesting the need for better writing. However, it does not explicitly state what needs to be improved or how to improve it, making it only partially actionable.", "grounding_specificity_rationale": "The comment refers to 'the main idea' and 'the theoretical analysis' without specifying which parts of these areas are unclear or require improvement. This lack of specificity means the feedback is 1 in a particular section or element of the paper.", "verifiability_rationale": "The statement 'The writing could be improved' is a suggestion or judgment about the clarity of the writing. It does not present a claim that requires external verification or logical reasoning to be accepted. It is a statement of opinion rather than a factual assertion.", "helpfulness_rationale": "The review identifies a specific difficulty the reviewer had in understanding certain parts of the paper. However, it does not offer any concrete suggestions or actionable steps for the authors to take to improve their writing. It points out a problem but does not provide a solution."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review points out a discrepancy in the experimental setup (Pix3D training and testing) and compares it to zeroshot methods. This doesn't directly tell the authors *what to do*. It highlights a potential flaw in their evaluation strategy. While the reviewer identifies a problem, they don't provide specific instructions or actions the authors should take to address it.", "grounding_specificity_rationale": "The reviewer mentions \"Pix3D training and testing\" and \"zeroshot singleimage 3D reconstruction models.\" While they *mention* Pix3D, they don't explicitly *identify* the specific section, table, or figure in the paper related to the Pix3D experiments. They also don't pinpoint the exact nature of the unfair comparison.", "verifiability_rationale": "The reviewer states a fact about the experimental setup: \"The domainspecific model is trained on Pix3D. And the experiments are conducted on Pix3D.\" This is a factual statement. They also make a judgment: \"Such comparisons to those zeroshot singleimage 3D reconstruction models are even more unfair,\" which is a logical consequence of the identified flaw. The claim is supported by logical reasoning and common knowledge about the nature of zeroshot methods.", "helpfulness_rationale": "The reviewer points out a potential flaw in the experimental design. While it's a valid point, it doesn't directly guide the authors on *how* to improve their method or experiments. It highlights a limitation of their current evaluation strategy. The authors would likely benefit from a suggestion on how to conduct more robust experiments or a discussion of the limitations of their current evaluation setup. The current review point doesn't provide that."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X (X)", "helpfulness_label": "None", "actionability_rationale": "The review point suggests *what* to do (additional experiments) but doesn't specify *how* to do it or what specific results are needed. The phrase \"more support\" is vague.", "grounding_specificity_rationale": "The comment explicitly mentions \"C2D\" and provides a specific example of a dataset (\"WebVision\") that could be used to evaluate it. However, the initial reference to \"C2D\" could be interpreted as an inference by the authors rather than a direct mention of a specific section or table.", "verifiability_rationale": "The review point is a suggestion for an *action* (additional experiments) rather than a claim that needs to be verified or supported. It doesn't present a statement that needs to be proven or supported.", "helpfulness_rationale": "The review point suggests a relevant action (additional experiments) that aligns with the goal of providing more support for C2D. However, the lack of specificity in the suggestion makes it less immediately actionable and therefore slightly less helpful than a more detailed recommendation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem ('I have a lot of problems with these abstract visual reasoning tasks') but does not explicitly state a concrete action the reviewer should take. While it suggests an alternative ('simpler visual reasoning tasks') it doesn't tell the reviewer how to address their problems or why the current formulation is problematic beyond the general statement of being 'overly difficult.'", "grounding_specificity_rationale": "The review point refers to 'these abstract visual reasoning tasks' but does not specify a particular section, table, or unique element within the paper that it is addressing. While it implies the reviewer is referring to the abstract visual reasoning tasks discussed in the paper, it doesn't provide a precise location or detail within the paper. However, it does specify the type of tasks.", "verifiability_rationale": "The review point makes a claim ('we seem to be overly difficult... Having multiple rows and having multiple and different factors changing between each frame is very confusing... it seems like it would be hard to interpret how much these models actually learn the pattern or just exploit some artifacts') and asks for justification ('Do we have any proof that more simpler visual reasoning tasks wouldn\u00e2\u0080\u0099t do and this formulation in the paper is the way to go?'). This demonstrates an attempt to provide evidence or reasoning to support the claim.", "helpfulness_rationale": "The review point is clearly intended to be helpful. The reviewer explicitly states their problems and asks for evidence to support their concerns. By asking for 'proof' and suggesting 'simpler visual reasoning tasks,' the reviewer is providing a concrete suggestion and asking for justification, which are key elements of helpful feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a potential weakness ('lack of essential visualization') but doesn't explicitly state what should be visualized or how the visualizations should be used. While it implicitly suggests that visualizations are needed, it lacks concrete action. The reviewer doesn't provide specific steps or changes the authors should make based on this comment.", "grounding_specificity_rationale": "The review point mentions 'intermediate processes' and 'comparisons' generally. It doesn't specify which particular intermediate processes or types of comparisons are lacking. This makes it difficult for the authors to pinpoint exactly what needs to be improved.", "verifiability_rationale": "The review point makes a claim ('There is a lack of essential visualization...') but doesn't provide any evidence, reasoning, or references to support this claim. It simply states that something is missing without explaining *why* it's important or *how* it should be done.", "helpfulness_rationale": "The review point criticizes a potential weakness ('lack of essential visualization') but doesn't offer any suggestions or guidance on how to address this issue. It's a critique without a proposed solution."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states their concern about the importance of the result and expresses a lack of surprise given the findings in 15. While they mention the change in iteration complexity, the action they suggest ('I believe the authors should reframe the significance of their results') is not explicitly stated in the review point itself. The reviewer points out a potential gap in the paper's framing of its contributions.", "grounding_specificity_rationale": "The reviewer explicitly mentions the paper 15 and draws a connection to the theoretical results, specifically mentioning the change in iteration complexity. This clearly identifies the specific part of the paper being addressed and provides details about what is wrong or missing (the lack of dimensionfree complexity). Therefore, the grounding is explicit and specific.", "verifiability_rationale": "The reviewer makes a claim that the results are not surprising given the prior work and the change in complexity. This claim is presented as a statement of opinion without providing external references or logical reasoning within the review point itself. Therefore, it is not verifiable based on the information provided in this review point.", "helpfulness_rationale": "The reviewer's comment raises a valid point about the significance of the results and the connection to prior work. However, they do not provide a specific action or suggestion for the authors to improve their draft based on this concern. They are more of a question or critique of the paper's framing rather than a direct improvement suggestion. Therefore, it is not 5 in terms of directly guiding improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggestion. While it implies a potential issue with the grid search not being performed on the validation set, it does not provide concrete steps on how to address this. The phrasing 'Minor problems' suggests a question rather than a definitive statement. Therefore, the actionability is not fully realized.", "grounding_specificity_rationale": "The review point explicitly mentions 'grid search of learning rate' and asks a question about the 'validation set'. This clearly identifies the specific part of the paper and the element being discussed. The issue is framed as a potential 'minor problem', indicating a specific area of concern. Therefore, the grounding specificity is high.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a question prompting clarification about a potential issue. While it implies a potential problem with the grid search process, it does not provide a statement that needs to be supported by evidence or reasoning. Therefore, there is X to verify.", "helpfulness_rationale": "The review point identifies a potential issue with the grid search not being performed on the validation set. While this could be a valuable piece of information for the authors, the review point itself does not offer a solution or further explanation. It is more of a question than a suggestion, limiting its helpfulness. Therefore, the helpfulness is somewhat limited."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a question about a specific aspect of the sample (racial/economic diversity) and its implications for generalizability. The phrasing 'How well might these results generalize to other groups, especially marginalized groups?' directly indicates an action the authors should take: investigate the diversity and its impact on generalizability. This is a clear and direct request for information, making it 5.", "grounding_specificity_rationale": "The reviewer refers to 'racial/economic diversity' within the sample, providing a specific element being analyzed. This demonstrates strong grounding as the authors can directly identify the referenced part. Furthermore, the reviewer asks a question about the *generalizability* of the results, which is a specific issue related to the identified diversity. This specificity goes beyond simply mentioning the diversity and delves into its implications.", "verifiability_rationale": "The reviewer poses a question about a potential limitation (the lack of diversity) and its impact on the results' generalizability. This is a claim that requires further investigation or data. While the reviewer's point is logically sound, it lacks explicit external references within this specific review point to support the claim about the impact of diversity on generalizability. Therefore, it is 3 as it requires further evidence to be fully substantiated.", "helpfulness_rationale": "The reviewer's question directly addresses a potential weakness in the sample and its implications for the results' generalizability. This is a clear and actionable feedback point that guides the authors to consider the diversity of their sample and how it might affect the broader applicability of their findings. While it doesn't provide a definitive answer, it prompts the authors to investigate this important aspect, making it 5 in guiding further analysis and potentially improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the concern about the dataset size and its impact on validating the approach. They also specify the number of images and categories, making the action quite clear. While they don't provide a solution, they identify a concrete area for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"VioT dataset\" and provides specific numbers for the number of images per category and the number of categories. This allows the authors to precisely identify the dataset being referred to. The reviewer also specifies the \"texting\" aspect, adding further specificity.", "verifiability_rationale": "The reviewer makes a claim about the dataset size being small and its impact on validating the approach. While the verifiability isn't *fully* verifiable without more context about the specific approach and analysis methods, the reviewer *does* provide information that could be used to argue for the smallness of the dataset in some contexts. The claim is based on observable information (the stated number of images).", "helpfulness_rationale": "The reviewer clearly identifies a potential weakness in the dataset and suggests investigating its impact on the textual analysis. This is a direct and relevant suggestion for the authors, guiding them towards a specific area of concern."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer states that the paper is hard to follow and suggests more intuitive explanations for mathematical derivations. While the reviewer identifies a need for improvement, they do not specify *how* to achieve this. The request is broad and lacks concrete action.", "grounding_specificity_rationale": "The reviewer mentions 'mathematical derivations,' 'figure captions,' and 'figure elements' without specifying *which* derivation or which part of which figure. The reviewer implies areas needing improvement but does not pinpoint the exact sections or elements. This is weak grounding.", "verifiability_rationale": "The reviewer states a problem ('the paper is hard to follow') and suggests improvements ('more intuitive explanations,' 'explanations for figure elements'). This constitutes a claim that *can* be verified. However, the reviewer does not provide specific references or logical reasoning to *prove* that these suggestions are necessary or beneficial. The suggestions are general and lack specific evidence.", "helpfulness_rationale": "The reviewer explicitly states the need for explanations and points out the lack of figure explanations. This clearly identifies a weakness and a desire for improvement. The suggestions are directly aimed at addressing the stated problem."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific technical detail about the crossencoder architecture, suggesting it 'attends to all candidates at once' to obtain matching scores. While the reviewer doesn't explicitly state the mechanism, the phrasing implies a specific behavior, which could be actionable for someone looking to understand or improve the architecture. However, the reviewer doesn't provide explicit instructions on how to leverage this information or apply changes based on this observation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'crossencoder architecture' and 'crossentity comparison' as areas of concern. This clearly identifies the specific part of the paper being addressed, making it fully grounded. The reviewer also states that the crossencoder is 'not ignoring crossentity comparison' and 'attends to all candidates at once,' which are specific observations about the architecture.", "verifiability_rationale": "The reviewer makes a claim about the crossencoder's behavior regarding 'crossentity comparison' and 'attending to all candidates at once.' However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support this claim within the review point itself. The statement is presented as a finding rather than a deduction or inference supported by evidence.", "helpfulness_rationale": "The reviewer raises a significant concern about the motivation and a specific technical aspect of the paper (the crossencoder). This points to a potential weakness and offers an opportunity for the authors to improve their work. While the reviewer doesn't provide specific suggestions for improvement, the identification of a problem is valuable and can be 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points out a problem but doesn't explicitly state how to fix it. The implications are vague, making it only partially actionable.", "grounding_specificity_rationale": "The review mentions 'GNN model' and related terms but doesn't pinpoint a specific section or element, leading to weak grounding despite identifying a specific issue.", "verifiability_rationale": "The review states a problem and suggests improvement, making it a claim. However, it lacks specific citations, making it only 3.", "helpfulness_rationale": "The review identifies a significant problem and suggests a general direction for improvement, making it helpful, though perhaps not with the depth of more specific feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of the experiment and provides concrete suggestions for improvement. The points about the reliance on Proposition 3.2 and large perturbation values, and the suggestion to strengthen the experiment, are direct and actionable. The reviewer identifies a gap in the number of perturbations and proposes specific ways to address it.", "grounding_specificity_rationale": "The reviewer refers to 'the experiment,' 'pseudo feature importance,' 'Proposition 3.2,' and 'large enough perturbation value.' These references are specific enough to identify the relevant aspects of the paper being discussed. The reviewer clearly identifies the components of the experiment being critiqued and the specific factors (proposition and perturbation value) that are crucial for its validity.", "verifiability_rationale": "The reviewer makes a claim about the reliance of the correctness of pseudo feature importance on Proposition 3.2 and large perturbation values. However, the reviewer does not provide any evidence or logical reasoning to support this claim within the review point itself. The suggestions for strengthening the experiment offer a potential path to verification, but the claim itself lacks justification.", "helpfulness_rationale": "The reviewer provides a clear critique of a specific aspect of the experiment and offers concrete suggestions for improvement. The points about the reliance on Proposition 3.2 and large perturbation values, and the suggestion to strengthen the experiment, are directly actionable and would empower the authors to improve their draft. The reviewer identifies a potential weakness in the experimental design and proposes specific ways to address it, making the review highly constructive."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'The experimental settings are not mentioned properly' which is a direct action. However, it doesn't specify what aspects of the experimental settings are missing, making it somewhat vague on how to apply this action.", "grounding_specificity_rationale": "The comment identifies the 'experimental settings' as the area lacking information, which can be considered weakly grounded as it points to a general area rather than a specific section or table. It also specifies 'not mentioned properly' which adds some specificity about the nature of the missing information.", "verifiability_rationale": "The comment contains a claim 'The experimental settings are not mentioned properly'. While it implies this is a problem for reproducibility, it doesn't provide specific examples or references to support this claim, making it 3.", "helpfulness_rationale": "The review point identifies a practical issue (lack of proper experimental settings) that directly impacts the ability to reproduce results, which is a concern for the authors. It provides a clear direction (improve experimental settings) but lacks specific details on what needs to be changed."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests making feedback diverse but doesn't specify how. It's an implicit action but lacks concrete details on implementation.", "grounding_specificity_rationale": "The comment is general and doesn't point to a specific part of the paper. It's about the process of feedback in general.", "verifiability_rationale": "The comment is a statement of intent, not a claim requiring verification. It doesn't make a judgment that needs evidence.", "helpfulness_rationale": "The comment raises a valid point about the need for diverse feedback, prompting the author to consider different types of feedback. However, it doesn't offer specific advice on how to achieve this."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the desire for the main text to clarify the presence of additional experiments in the supplement and to summarize their results. This is a clear and direct action for the authors to take. The reviewer is not just implying the need for more information, but directly instructing the authors on what to do with the supplementary material. This action is both explicit and concrete, making it 5.", "grounding_specificity_rationale": "The reviewer implicitly refers to the 'supplement' as the source of additional experiments. While the concept of supplementary material is generally understood in the context of research, the reviewer does not explicitly point to a specific section, table, figure, or unique element within the paper. The reviewer also specifies that the main text should *summarize* the results, which adds a degree of specificity to the information they expect to be present in the supplement. However, the initial request is not a direct pointer to a specific part of the paper. Therefore, while the reviewer has some grounding (understanding supplementary experiments are common), it's not a strong grounding. The specificity is also present in the request to summarize results, making it somewhat specific about the type of information needed.", "verifiability_rationale": "The reviewer makes a claim: 'The main text should make it more clear that there are additional experiments in the supplement (and preferably summarize their results).' This is a statement of expectation and a suggestion for improvement. While the reviewer doesn't provide external evidence or references to support this claim, it's a reasonable expectation for researchers to understand the content of supplementary material. The implication is that the current main text is lacking in this regard. However, without specific evidence or references, the claim is not fully supported by logical reasoning, common knowledge, or external references. Therefore, it is not 5, but it has some supporting elements (the expectation that supplementary material exists and should be summarized).", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for improvement: 'The main text should make it more clear that there are additional experiments in the supplement (and preferably summarize their results).' This is a direct and actionable feedback for the authors. The reviewer is not just pointing out a problem but also suggesting a concrete way to address it. This type of feedback is highly valuable as it directly guides the authors on what changes to make in their draft. The specificity of summarizing results makes this feedback particularly helpful."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states 'It is also recommended to compare the performance with' and 'This is also recommended', indicating an intention for the authors to perform this comparison. This is an explicit action that the authors can directly follow.", "grounding_specificity_rationale": "The reviewer mentions 'It is also recommended to compare the performance with' and 'MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer' and 'Multilingual unsupervised neural machine translation with denoising adapters.' While the reviewer doesn't explicitly state the section or table where these comparisons should be made, they clearly identify the *type* of comparison and the *papers* involved. However, the lack of specificity in the *general area* of the paper being compared makes the grounding somewhat underspecific.", "verifiability_rationale": "The reviewer makes a claim by stating 'It is also recommended to compare the performance with' and 'This is also recommended'. However, the reviewer does not provide any justification or reasoning for *why* these comparisons are necessary or beneficial. The claim is made without supporting evidence or logical reasoning.", "helpfulness_rationale": "The reviewer provides a specific suggestion: 'It is also recommended to compare the performance with' and 'MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer' and 'Multilingual unsupervised neural machine translation with denoising adapters.' This suggests a concrete action the authors should take. While the suggestion lacks justification, it is a clear direction for the authors to improve their draft by exploring these specific comparisons."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a direct question about the limitations of the approach and how it can be extended to more general settings. This is a clear and actionable question that directly addresses a potential weakness of the method. The reviewer is explicitly stating a concern and asking for a solution, which is a very actionable request.", "grounding_specificity_rationale": "The reviewer's question is not directly tied to a specific part of the paper. While the limitations mentioned (model dependency, episodic setting, delayed reward) are implied, the question itself is about the general applicability of the approach. Therefore, the grounding is weak as the authors cannot pinpoint the exact area being addressed in the question itself.", "verifiability_rationale": "The reviewer's question is not a claim that can be directly verified or unverified. It's a question about the possibility of extending the approach. While the implications of the current limitations are logical, the question itself doesn't present a concrete claim that requires evidence. Therefore, it's difficult to categorize as 5 or 1, making it 2.", "helpfulness_rationale": "The reviewer's question is likely to be helpful for the authors. It encourages them to think critically about the limitations of their work and consider how the approach might be generalized. While it doesn't provide a specific solution, it prompts a valuable reflection and discussion, which can be beneficial for improving their draft. The question is about the potential for extension, which is a valuable direction for future work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification on a specific detail (the feature extractor) related to the dimensionality of the regions. While they are pointing out a detail, they are not explicitly stating an action they want the authors to take. Instead, they are asking a question. Therefore, it is not a direct and explicit action.", "grounding_specificity_rationale": "The reviewer is explicitly pointing to a specific detail in the paper (the dimensionality of each region being 512) and asking about the feature extractor used. This clearly identifies the specific part of the paper being referenced and the issue being raised. The request is very specific about the feature extractor. Therefore, the grounding is explicit and the specificity is high.", "verifiability_rationale": "The reviewer is posing a question. While it is verifiable that the paper should mention the feature extractor, the review point itself does not contain a claim or suggestion for improvement. It's a request for information rather than a critique or recommendation.", "helpfulness_rationale": "The reviewer is asking a question about a specific detail in the paper. While the question is valid and could be helpful for the authors, it does not directly point out a weakness in the paper or suggest an improvement. It's more of a request for clarification than constructive feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a request for more information, which is an implicit action requiring the author to infer where and how to provide it. The action is also vague. For example, the reviewer could have specified 'Add a section detailing the implementation' or 'Appendix B for the algorithm'. Without this specificity, the author has to make their own assumptions, making the action implicit and vague.", "grounding_specificity_rationale": "The review point is very general and does not specify a particular section, table, figure, or any unique element of the paper. It simply states 'It would be helpful for readers if computation/algorithm/implementation details are given.' This lack of specificity means the reviewer cannot confidently identify where the author should find or address these details.", "verifiability_rationale": "The review point is a suggestion, not a claim that needs verification. It does not make any definitive statements about what is wrong with the paper or the implementation. Therefore, there is X to be verified.", "helpfulness_rationale": "The review point is a good suggestion for improvement. It points out a potential area where the paper could be clearer and more accessible. While it doesn't provide specific details, it encourages the author to add more information, which can be helpful for readers. However, because it lacks specificity, its helpfulness is limited."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'lack of analysis' and 'lack of comparison' regarding the data augmentation methods. While it identifies the problem, it doesn't specify the exact nature of the analysis or comparison that is missing, making it somewhat vague in terms of actionable steps. For example, is the analysis missing qualitative insights, quantitative metrics, or both? Is the comparison missing to specific methods or just a general statement?", "grounding_specificity_rationale": "The review point identifies the areas of lacking analysis (data augmentation methods) and lacking comparison (to other paraphrasing methods). However, it does not specify *which* particular data augmentation method or *which* specific aspect of the comparison is missing. Therefore, while it points out the *type* of deficiency, it lacks the specificity to pinpoint the exact area needing improvement.", "verifiability_rationale": "The review point makes a claim that there is a 'lack of analysis' and a 'lack of comparison'. It also provides a reasoning for this claim by suggesting that comparing to other methods would clarify the unique advantages. The claim is supported by the suggestion to compare to other methods, which is a logical argument and a reference to established practices in the field. However, it doesn't explicitly cite specific metrics or detailed analysis techniques that are missing.", "helpfulness_rationale": "The review point clearly identifies a weakness in the authors' approach \u2013 the lack of analysis and comparison. It provides a suggestion for improvement: comparing their method to other paraphrasing techniques. This is a direct and actionable suggestion that could help the authors understand the strengths and weaknesses of their approach. While it doesn't specify *how* the comparison will lead to improvement, it directly points to a concrete next step."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment implicitly suggests an action: to perform ablation studies with different loss functions to understand the contribution of each component. However, the action itself is vague and lacks detail on how to implement it.", "grounding_specificity_rationale": "The comment identifies the issue with the MMD component in the context of 'learning with MMD' and suggests alternative ablation targets like 'typical knowledge distillation loss' or 'distilling a Hydra architecture with MMD loss'. This provides a clear grounding of the problem and suggests specific solutions.", "verifiability_rationale": "The comment proposes 'learning the proposed model with typical knowledge distillation loss' or 'distilling a Hydra architecture with MMD loss' as alternative ablation studies. This is a suggestion, not a claim that something is wrong, and therefore not verifiable.", "helpfulness_rationale": "The comment identifies a valid limitation in the experimental setup (lack of ablation study) and provides concrete suggestions for improvement. These suggestions are actionable and directly address the identified problem, making it 5 for the authors to understand the effectiveness of the MMD component."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a very basic baseline experiment: assigning all negative samples to a distractor class. While this is a valid point for discussion, the authors need to infer the implicit action of understanding the implications of this baseline and how it relates to their own methodology. The action is somewhat concrete once the authors understand the concept, but the initial suggestion requires some interpretation.", "grounding_specificity_rationale": "The reviewer's point is 1 in a specific part of the paper. They are suggesting a general baseline experiment without linking it to any particular section, table, or figure. The specificity of the suggestion is also lacking as it doesn't detail how this baseline would be relevant or what aspect of the paper it would address.", "verifiability_rationale": "The reviewer suggests a baseline experiment but doesn't provide any specific justification or evidence for why this is important or how it relates to the paper's content. The claim is vague and lacks supporting references or logical reasoning. The reviewer is simply suggesting a comparison point without explaining its significance.", "helpfulness_rationale": "The reviewer's point, while valid, is a very basic and potentially trivial observation. It highlights the importance of defining negative samples, which might be helpful for basic debugging or understanding model behavior on simple cases. However, it doesn't offer deep, actionable insights for improving the core methodology or results of the paper. The helpfulness is limited as it doesn't directly address the authors' specific concerns or contributions."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'lacks specific measurements or comparisons' as the weakness in the paper's claim of computational gains. This is an explicit action the reviewer is pointing out is missing. Furthermore, the reviewer provides concrete examples of what constitutes these measurements (GPU hours, memory usage, training time), making the weakness concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'quantitative analysis' and provides examples of what should be measured (GPU hours, memory usage, training time) to ground the claim about computational gains. This indicates a strong grounding as the reviewer can accurately pinpoint the type of analysis needed.", "verifiability_rationale": "The reviewer makes a clear claim: 'While the paper claims computational benefits...it lacks specific measurements or comparisons.' This is a claim that needs verification. The reviewer also provides examples of how to verify this claim (mentioning specific metrics), making the verification method somewhat specific.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'A quantitative analysis\u2014such as GPU hours, memory usage, or training time\u2014would provide stronger evidence of the efficiency improvements.' This is a helpful suggestion for the authors as it directly addresses the identified weakness and provides a concrete next step."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the consequence of *not* considering the time for COLMAP and scenebyscene finetuning, which is the method becoming less efficient for these scenes. This is an explicit action that is also concrete, as the reviewer clearly identifies the inefficiency and the specific areas where the time is relevant. The reviewer directly points out what needs to be addressed (considering the time) and how it will affect the method (less efficiency).", "grounding_specificity_rationale": "The review point refers to 'COLMAP' and 'scenebyscene finetuning,' which are specific terms within the context of the paper being reviewed. While it doesn't explicitly state the section, figure, or unique element where these terms are prominently featured, the reviewer's mention strongly implies a specific part of the method description. Therefore, it can be considered 'fully grounded' as the terms themselves are strong indicators of a specific area. The comment specifies what needs to be improved (considering the time) in this specific part of the method.", "verifiability_rationale": "The review point makes a claim that 'rendering the method less efficient for these scenes.' While this is a likely implication and a valid point, the review point itself doesn't provide specific evidence or logical reasoning to *prove* that considering the time will *definitely* make the method less efficient. There's an assumption that more time invested in these steps will lead to better results, which is generally true, but it's not explicitly stated or supported within the review point itself. Therefore, it's '3' as there's an implication but lacking key elements like examples or references.", "helpfulness_rationale": "The review point directly identifies a limitation of the method (inefficiency due to ignoring time) and suggests a potential improvement (considering the time). This directly addresses a practical aspect of the method and provides a clear direction for the authors to improve their draft. The reviewer's comment is actionable and points out a specific area for attention, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides clear suggestions and questions for improvement. The reviewer asks 'Did authors experiment with any other architectures for FMN?' and 'How does the adaptive convolutions scale with the number of filter parameters?'. These are direct actions the authors can take to address potential limitations or areas for further exploration. The reviewer also suggests 'Can FMN scale reasonably well when the number of filter parameters is huge (say, 128 to 512 input and output channels?)', which is a concrete question about a potential limitation.", "grounding_specificity_rationale": "The reviewer asks specific questions about the 'filter manifold network' (FMN), such as 'Did authors experiment with any other architectures for FMN?' and 'How does the adaptive convolutions scale with the number of filter parameters?'. However, the reviewer does not explicitly state which specific part of the paper they are referring to when discussing FMN. While the general area is mentioned, the grounding of *which specific section* of the paper is being addressed is not clear. The reviewer also asks about the scaling of adaptive convolutions but doesn't specify what aspect of the scaling they are interested in.", "verifiability_rationale": "The reviewer poses questions that could be answered with further evidence or analysis. The reviewer asks 'Did authors experiment with any other architectures for FMN?' and 'How does the adaptive convolutions scale with the number of filter parameters?'. While the paper might contain some information relevant to these questions, the reviewer is asking for more specific details that are not explicitly provided. The reviewer also suggests 'Can FMN scale reasonably well when the number of filter parameters is huge (say, 128 to 512 input and output channels?)', which implies a need for further investigation or analysis to verify.", "helpfulness_rationale": "The review point provides clear suggestions for improvement and asks clarifying questions. The reviewer suggests exploring alternative architectures for FMN and analyzing the scaling behavior of adaptive convolutions. These are concrete actions the authors can take to address potential limitations or areas for further exploration. The reviewer also asks 'It seems that in all the experiments, the number of input and output channels is small (around 32). Can FMN scale reasonably well when the number of filter parameters is huge (say, 128 to 512 input and output channels?)', which is a helpful question for understanding the limitations of the current approach."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the potential benefit of adding an exponential moving average (EMA) to the model and suggests isolating the EMA's contribution by analyzing a noisefree version (\u03a0 model). This is an explicit action with a clear goal. However, the action is somewhat vague as the reviewer doesn't specify *how* to isolate the EMA's contribution or what metrics to use for comparison. The reviewer suggests comparing the performance of the full model to the \u03a0 model, but the exact methodology for this comparison is not detailed.", "grounding_specificity_rationale": "The review point explicitly mentions 'noise' and 'exponential moving average' as factors contributing to the model's benefits. It also names the \u03a0 model as the component capturing the 'noise' part. This demonstrates strong grounding as the reviewer accurately identifies the specific aspects of the model being discussed. The specificity is high because the reviewer clearly pinpoints the components and suggests a specific analysis (comparing the full model to the \u03a0 model).", "verifiability_rationale": "The review point makes a claim about the potential benefit of the EMA and suggests a method to verify this benefit by comparing the full model to the \u03a0 model. The claim is that the EMA contributes to performance improvement. The reasoning provided is that the \u03a0 model isolates the noise, allowing for a clearer assessment of the EMA's impact. This is a logical and verifiable claim as it relies on the established function of the \u03a0 model. The evidence is the known role of the \u03a0 model in capturing noise and the implied understanding that the EMA is intended to smooth out these noise effects. The claim is supported by the understanding of how these components function within the model.", "helpfulness_rationale": "The review point is 5 as it identifies a specific area for further investigation (the individual contributions of noise and EMA) and provides a concrete suggestion for analysis (comparing the full model to the \u03a0 model). This actionable feedback directly addresses a potential area for improvement in the model. The reviewer's suggestion is clear and directly targets a potential optimization strategy. It provides a clear direction for the authors to explore and potentially enhance their model."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "Not Helpful", "actionability_rationale": "The review point does not explicitly state what the authors should do or how their work could be improved based on the observation that results are only reported after training. While the reviewer speculates about the model's early state, this is a conjecture, not a direct instruction. The lack of a concrete action makes it 1.", "grounding_specificity_rationale": "The reviewer mentions 'training has occurred' generally, which is weak grounding. However, the reviewer also speculates about 'early in training' and 'model parameters', which provides some grounding. The mention of 'model parameters' is specific, making it somewhat grounded. The speculation about 'planning component' adds a specific area of concern, making it somewhat grounded and specific.", "verifiability_rationale": "The reviewer states an observation ('the results are only reported after a bunch of training has occurred') without providing logical reasoning, common knowledge, or external references to support it. The reviewer also makes a speculative conjecture ('I presume that early in training the model parameters are essentially garbage') without providing evidence or justification. Therefore, the claims are not verifiable.", "helpfulness_rationale": "The review point raises a relevant concern about the reporting process and the model's early state. However, it does not provide concrete, actionable feedback on how the authors should improve their draft. The reviewer's speculation about the planning component and the potential performance of the CNN with less data does not offer specific, actionable steps for the authors. While the feedback is relevant, the lack of concrete actions limits its helpfulness."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer states their opinion directly: 'The contribution looks marginal...'", "grounding_specificity_rationale": "The reviewer does not identify a specific part of the paper as the source of the marginal contribution. They offer a general assessment.", "verifiability_rationale": "The reviewer makes a claim ('The contribution looks marginal...') and provides a reason ('all the methods used in different stage are well designed and demonstrated') as justification.", "helpfulness_rationale": "The reviewer explicitly states their opinion: 'The contribution looks marginal to me.' This indicates a lack of actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment acknowledges the existence of the Appendix but does not specify any actions or suggestions related to it. It expresses a positive sentiment but lacks direction for the author.", "grounding_specificity_rationale": "The comment refers to 'the Appendix' generally, without specifying which part or section is being addressed. It lacks specificity in identifying a particular aspect of the paper.", "verifiability_rationale": "The comment is a statement of appreciation and a reason for not engaging with a specific part of the paper. It does not contain a claim that requires verification or justification.", "helpfulness_rationale": "The comment is a suggestion not to read something, rather than providing constructive feedback or identifying areas for improvement. It lacks actionable steps and specific insights."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the concern about the age of the MULT baseline. However, it does not provide specific actions or suggestions to address this issue. The reviewer identifies the problem but doesn't offer concrete steps for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions the publication years of the mentioned papers (ACM MM 2020, CVPR workshop 2022, ICASSP 2022) and the name of the baseline paper, MULT. This provides strong grounding as the specific parts of the paper being addressed are clearly identified.", "verifiability_rationale": "The claim that MULT is 'out of fashion' is verifiable based on its publication year (2019). However, the reviewer does not provide specific examples or references to support this claim further. The justification for 'out of fashion' is based on the general understanding of research trends rather than specific evidence within the review point itself.", "helpfulness_rationale": "The review point identifies a valid concern regarding the age of the MULT baseline. However, it does not offer any specific suggestions or guidance to the authors on how to address this issue. The comment is informative but lacks actionable steps to improve the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out that W1 and W2 are not defined and suggests they denote the Encoder and Decoder network. While the reviewer doesn't explicitly state what the authors should do, they clearly identify a lack of clarity regarding these terms. The reviewer also mentions that p.3, A4, eq.3: W and V are not defined, which is a clear indication of an actionable issue. The reviewer's guess about W1 and W2 being the Encoder and Decoder network is a potential action the authors could take, but it's not explicitly stated as a recommendation.", "grounding_specificity_rationale": "The reviewer explicitly states that W1 and W2 are not defined and suggests they are the Encoder and Decoder network. This implies the reviewer has identified specific parts of the paper (W1 and W2) where information is lacking. However, the reviewer does not explicitly state that they understand the unique elements being addressed. The reviewer's guess about the nature of W1 and W2 (Encoder and Decoder) is an inference, not a direct statement of understanding the specific section or element being referred to.", "verifiability_rationale": "The reviewer states that W1 and W2 are not defined and suggests they are the Encoder and Decoder network. This constitutes a claim that something is missing or unclear. The reviewer's suggestion that they denote the Encoder and Decoder network provides some justification, as it's a common understanding in the field. However, the reviewer does not provide any external references or logical reasoning to support this claim within the review point itself.", "helpfulness_rationale": "The reviewer points out that W1 and W2 are not defined and suggests they are the Encoder and Decoder network. This is a clear indication that there is a lack of clarity in the paper. While the reviewer doesn't explicitly recommend a specific action, the identification of undefined terms is a helpful piece of feedback for the authors to understand what needs clarification. The reviewer's suggestion about the nature of W1 and W2 is a potential action the authors could take, but it's not explicitly recommended as a solution."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a question about the state and generation of negative chips and their role in RPN training. It doesn't explicitly state what action should be taken or how to improve the process. While it raises a valid point about the relationship between generation and training, it doesn't provide a clear action or solution.", "grounding_specificity_rationale": "The review point doesn't explicitly state where the negative chips come from (e.g., specific layers, attention heads) or what they contain. The source is implied (generated), but not explicitly stated. The process of generation and training is also not detailed, making it difficult to pinpoint the exact referenced element. Therefore, the grounding is weak. The specificity is also low as it doesn't detail the content or process of the negative chips.", "verifiability_rationale": "The review point is a question and a suggestion for improvement, not a declarative statement containing a claim that needs verification. It doesn't specify what is wrong with the current approach or how the suggested alternative would be better justified. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point is a question and a suggestion for improvement, but it doesn't directly address a weakness or provide concrete actionable feedback on the RPN training process. It's more of a query and a potential improvement idea rather than a direct critique or suggestion of change. Therefore, it is not very helpful in pinpointing specific issues or providing actionable feedback."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the need to evaluate the approach differently for new and returning patients. It also provides a reason for this differentiation, mentioning the lack of historical reports for new patients. This clearly identifies an action to be taken: evaluate separately. The comment also provides guidance on *how* to do this, by using historical reports for new patients. Therefore, the action is both explicit and concrete.", "grounding_specificity_rationale": "The comment explicitly mentions 'new patients' and 'historical reports' as the key aspects that need to be addressed. This is a literal mention of specific sections or elements of the paper. The comment also implies the need to evaluate the approach differently based on the presence or absence of historical reports. This makes the grounding explicit and the issue specific to these parts of the paper.", "verifiability_rationale": "The comment itself does not contain a claim or assertion that requires verification. It is a suggestion for a methodology. Therefore, it does not fall under the 'Claim Extraction' step. Since there is X, it cannot be evaluated for verifiability in the sense of supporting evidence. However, the *suggestion* for evaluation can be considered verifiable if the authors can agree on the methodology. For the *comment itself*, it is not a claim, so it would be 'X'.", "helpfulness_rationale": "The comment directly identifies a potential flaw in the evaluation process \u2013 the lack of historical reports for new patients \u2013 and proposes a concrete solution: evaluating the approach separately for new and returning patients. This is a clear and actionable suggestion that directly addresses a potential issue and provides a path for improvement. Therefore, it is 5 for guiding the authors in their evaluation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'No indepth analysis' and 'why?'. This directly points to a missing action. The action is to provide an indepth analysis, and the application is to explain the observed inverse scaling with compute. The reviewer clearly states what needs to be done.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'analysis of the inverse scaling happens over compute'. This clearly identifies the specific part of the paper or analysis that is lacking. The reviewer uses a literal mention of the observed phenomenon to pinpoint the area needing improvement.", "verifiability_rationale": "The reviewer makes a claim by stating 'No indepth analysis' and 'why?'. This indicates a need for justification. However, the reviewer does not explicitly state *why* indepth analysis is crucial or provide supporting evidence for this claim. The 'why' is implied but not explicitly stated or justified.", "helpfulness_rationale": "The reviewer directly points out a weakness in the paper ('No indepth analysis') and suggests a concrete improvement ('It would make the paper much more solid if the authors can provide some analysis explaining such training dynamics'). This is a clear and actionable suggestion that directly addresses a missing element."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not contain explicit or implicit actions or suggestions on how to improve the draft. It poses questions about the performance of the algorithm on different datasets, which require the authors to conduct further experiments or provide additional information, but doesn't directly instruct them on what changes to make. The reviewer is asking for more data and analysis rather than providing a clear path for improvement.", "grounding_specificity_rationale": "The review point does not explicitly identify any specific part of the paper or dataset being discussed. The questions are general and apply to the algorithm in general, without pinpointing a specific section, table, figure, or unique aspect of the paper. The reviewer is asking about the algorithm's performance broadly, not about a specific issue in a particular section.", "verifiability_rationale": "The review point does not contain a claim or suggestion that can be verified or unverified. It is a question about the performance of the algorithm, not a statement that needs evidence. The reviewer is asking for more data and analysis, not making a claim about the paper's quality or content.", "helpfulness_rationale": "The review point does not provide actionable feedback or insights that would help the authors improve their draft. It asks questions that require further experimentation or data collection, but does not directly point out weaknesses or suggest concrete improvements. The reviewer is prompting for more information rather than providing constructive criticism or actionable advice."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the paper *does not describe what hyperparameters are used by each defense nor how those hyperparameters are derived*. This is an explicit statement of missing information. However, the reviewer does not provide guidance on how to derive these hyperparameters, making the action only partially actionable. The reviewer could infer that optimizing hyperparameters is important for a fair evaluation, but this is not explicitly stated.", "grounding_specificity_rationale": "The reviewer's statement that the paper 'does not describe what hyperparameters are used by each defense' does not explicitly identify a specific part of the paper (e.g., a section, table, or unique element) where this information is missing. The reviewer is making a general claim about the paper's content. Therefore, the grounding is weak. The specificity is also weak because the reviewer does not specify what needs to be addressed in this part.", "verifiability_rationale": "The reviewer makes a claim about the paper's content: 'The paper does not describe what hyperparameters are used by each defense nor how those hyperparameters are derived.' This claim is verifiable based on the reviewer's examination of the paper. While the paper lacks the specific details about hyperparameters, the reviewer's statement is based on a logical analysis of the paper's content.", "helpfulness_rationale": "The reviewer's point is highly relevant and actionable for the authors. By highlighting the missing information about hyperparameters, the reviewer identifies a crucial aspect of evaluating defense mechanisms. Suggesting that the authors optimize hyperparameters is a concrete and helpful suggestion that can significantly improve the evaluation process. While the paper doesn't explicitly state the need for hyperparameter optimization, the reviewer infers its importance for a fair evaluation."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review points to a 'main takeaway point' and a specific action ('query a cluster proportionally to the square root of its size'), but it doesn't explicitly state how to implement this action. The action is implied, but the details are missing.", "grounding_specificity_rationale": "The review refers to 'theoretical results' and 'the main takeaway point,' which are general concepts. While it mentions a specific finding ('query a cluster proportionally to the square root of its size'), it doesn't explicitly link it to a specific section, table, or figure in the paper.", "verifiability_rationale": "The review makes claims about the novelty of the finding ('it's unclear if this is a novel finding in this paper') and the lack of practical implications for practitioners. While the 'square root of its size' part is specific, the overall claims are somewhat subjective and lack strong supporting evidence or references.", "helpfulness_rationale": "The review identifies a potential theoretical finding and highlights a limitation for practitioners. It points to a specific aspect of the theory. However, it doesn't offer concrete steps *how* to translate the finding into a practical algorithm or how to address the lack of practical implications."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for an explanation of why separators are introduced in section 4 and what their additional benefit is beyond T/O. This is an explicit request for clarification. While the reviewer is asking a specific question, the paper does not explicitly state the reason for their existence or their additional benefit, making it somewhat implicit. The action is clear (explain the purpose of separators), but the implementation details (the 'additional benefit') are vague.", "grounding_specificity_rationale": "The reviewer is asking about separators in section 4, which implies they believe this part of the paper is relevant. However, the paper does not explicitly identify which specific separators are being referred to. The reviewer is making an educated guess about the section being addressed, indicating weak grounding. The comment specifies what needs to be addressed (the purpose of separators), making it somewhat specific.", "verifiability_rationale": "The reviewer is making a claim (or a question implying a lack of clarity) about the purpose of separators in section 4. The paper does not explicitly state the reason for their introduction or their additional benefit beyond T/O. The claim is not supported by explicit reasoning, common knowledge, or external references, making it 2. The claim is about what needs to be addressed (the purpose of separators), which is 3 if the paper implicitly suggests a lack of explanation.", "helpfulness_rationale": "The reviewer's question is directly related to the lack of clarity regarding the purpose and benefits of separators. Since the paper does not adequately explain this, the reviewer's question is not very helpful. The feedback is clear about the missing information, but the lack of a clear explanation limits its impact. The helpfulness is somewhat limited by the lack of a clear explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'there could be different approaches to pooling the tokens' and provides concrete suggestions for exploring these approaches by asking 'why is it that mean pooling works? What about other pooling strategies?'. This indicates a clear and direct identification of a potential improvement and a specific method for investigating it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'mean pooling' and the broader area as 'pooling strategies for tokens'. This precise identification of the specific part of the paper being addressed demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer makes a claim that 'there could be different approaches to pooling the tokens' and provides a suggestion by asking 'why is it that mean pooling works? What about other pooling strategies?'. This claim is supported by the reviewer's general knowledge of different pooling techniques and their suggestion acts as a pointer to existing knowledge, making it 5.", "helpfulness_rationale": "The reviewer directly addresses a potential improvement (exploring different pooling methods) and provides a clear direction for investigation (asking about the rationale of mean pooling and suggesting alternatives). This is a highly specific and actionable suggestion that directly benefits the authors by guiding them towards a more robust implementation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4: Mostly Verifiability", "helpfulness_label": "5", "actionability_rationale": "The reviewer asks a direct question about whether the VQGAN is pretrained and what dataset it was trained on. While it's a question, it clearly points to a missing detail in the paper. The reviewer is implicitly asking for clarification on a crucial implementation detail that would allow the authors to understand how the VQGAN was used. The information is either present or absent, making it relatively easy to infer if the details are missing. Therefore, it's actionable in the sense that if the information is indeed missing, the authors would know exactly what they need to look for.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'VQGAN' and 'Computer Vision Figures dataset' in their question. This strong naming makes it highly likely that the authors can identify the specific part of the paper being referred to. The reviewer is not just asking for any information, but specifically about the VQGAN and a particular dataset. This indicates a good understanding of the paper's structure and content.", "verifiability_rationale": "The reviewer is asking a question that can be answered by checking the paper. There is no subjective opinion being expressed. The information is either present or absent. While the information is missing, the request for clarification is logical and based on standard practices in reporting model training details. Therefore, it's 4 as the information is clearly missing and can be verified by checking the paper.", "helpfulness_rationale": "The reviewer is directly addressing a potential point of confusion for the authors. They are asking for crucial information about the VQGAN training process, specifically whether it was pretrained and on which dataset. This is a very actionable and specific request. The reviewer is essentially asking for a clarification that is likely to resolve a key uncertainty for the authors regarding the implementation details of their work. The information is either present or absent, and the request is clear and direct."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the importance of taskoriented dialogue systems and the need to differentiate their work from 'chatbox' research. They also provide concrete examples of relevant works and a direction for discussion. This constitutes an explicit action with concrete details on how to implement it.", "grounding_specificity_rationale": "The reviewer mentions 'taskoriented recommendation' as a general perspective, which is not a specific part of the paper being criticized. However, the reviewer also suggests comparing to specific works and discussing differences from other approaches, which are specific actions. While the initial framing is general, the suggestions are grounded.", "verifiability_rationale": "The reviewer states that the suggested works are 'important to include' and that the discussion on differences is 'very useful'. This is a claim that is supported by the logical reasoning that these comparisons would be beneficial. While the specific evidence for their importance isn't detailed, the claim itself is verifiable.", "helpfulness_rationale": "The reviewer provides specific suggestions for improvement, such as comparing to specific works and discussing the differences from other approaches. This directly addresses the paper's weaknesses and offers concrete improvements, making the review 5."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states that the performance of DualIS and DualDIS on the MSVD dataset shows 'minor improvements'. While this points to a potential issue, it doesn't explicitly tell the reader how to address this. The reader would need to infer that the lack of 'generic performance' is a concern. The action is implicit rather than explicit.", "grounding_specificity_rationale": "The review point explicitly mentions the 'MSVD dataset' and the 'performance of DualIS and DualDIS'. This clearly grounds the comment in a specific part of the paper and the models being discussed. However, it doesn't specify *what* aspect of the performance is showing minor improvements (e.g., retrieval accuracy, precision, recall).", "verifiability_rationale": "The review point contains a claim: 'the performance of DualIS and DualDIS on the MSVD dataset shows minor improvements'. However, it does not provide any justification or evidence for this claim. There are no logical reasoning, common knowledge, or external references provided to support this observation.", "helpfulness_rationale": "The review point identifies a potential issue with the performance of specific models on a particular dataset. While this is relevant information, it doesn't offer concrete suggestions or directions for improvement. The term 'minor improvements' is vague and doesn't provide actionable insights. The feedback is primarily a statement of observation rather than a constructive suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a potential alternative to the proposed method (vanilla Adam) and highlights a discrepancy in the number of runs required. The reviewer points out that running vanilla Adam with multiple restarts is a more efficient approach than the proposed method's exhaustive search over 40 networks. This suggests a concrete action for the authors to consider: evaluating the performance of vanilla Adam as a simpler alternative. The reviewer provides a clear comparison and a quantifiable difference in computational cost, making the criticism explicit and actionable.", "grounding_specificity_rationale": "The reviewer's comment is 1 in a specific part of the paper. While the comment is about the 'experimental strengths,' it does not point to a particular section, table, or figure. The reviewer is broadly criticizing the experimental setup without pinpointing a specific detail that needs improvement. The comment is at a higher level, addressing the overall approach rather than a specific element within it.", "verifiability_rationale": "The reviewer makes a claim about the 'experimental strengths' of the approach and suggests a potential improvement by using vanilla Adam. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support their claim about the limitations of the proposed method. They simply state their opinion without backing it up. The comment is presented as a suggestion for improvement rather than a verifiable claim about the paper's content or methodology.", "helpfulness_rationale": "The reviewer clearly articulates a potential weakness in the experimental setup by suggesting that a simpler alternative (vanilla Adam with multiple restarts) could achieve the same goal with less computational cost. The reviewer's point is actionable and directly challenges the authors' choice of experimental method. If the authors believe that vanilla Adam is indeed a better approach, this review would significantly impact their work by suggesting a more efficient way to find the global minimum. The reviewer provides a clear direction for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment identifies a potential issue with FedSP's performance but does not explicitly state what needs to be improved or how to address it. It's a general observation rather than a specific, actionable suggestion.", "grounding_specificity_rationale": "The comment mentions 'FedSP' and 'Table 1/2' but does not explicitly identify the specific part of the table or dataset where the performance is lacking. The reference to 'some datasets' is also vague and doesn't pinpoint the exact issue.", "verifiability_rationale": "The comment makes a claim about FedSP's performance not being the best but does not provide any evidence or references to support this claim. It lacks logical reasoning or external references to back up the assertion.", "helpfulness_rationale": "The comment points out a potential weakness in FedSP's performance but does not offer any constructive suggestions or guidance on how to improve it. It is a simple observation without actionable steps."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete change to be made. It is a suggestion for future exploration, not immediate feedback for improvement.", "grounding_specificity_rationale": "The reviewer suggests exploring the new dataset but does not specify which part of the paper or section this exploration should focus on. The reference to 'the paper' is general and lacks precision.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a suggestion for future work, not a critique or assertion about the paper's content.", "helpfulness_rationale": "The review point suggests exploring a new dataset, which is relevant to the broader context of research but does not directly identify weaknesses in the current paper or provide concrete steps for improvement. It is more of a suggestion for future research than immediate feedback for enhancing the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The review points out a limitation or a missed opportunity. While it identifies a *problem* (difficulty realizing efficiency gains), it *doesn't* explicitly tell the authors *what* to do about it. There's no actionable step suggested.", "grounding_specificity_rationale": "The review makes a general statement about the difficulty of realizing efficiency gains on GPUs in *general* pruning work. It doesn't explicitly refer to a specific section, table, figure, or any particular detail in the paper. The reference to \"most work on pruning\" is broad.", "verifiability_rationale": "The review makes a claim about a limitation in the current work. It is based on the reviewer's experience and understanding of the field, which can be considered common knowledge. However, it lacks specific external references within this review point.", "helpfulness_rationale": "The review points out a limitation of current approaches. While it doesn't offer a solution, it identifies a potential area for future research or improvement. It highlights a gap in the current work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point asks a question about the outcome of applying a method. While it implies an action (analyzing costs), it doesn't explicitly state what needs to be done or how to achieve it. The action of 'applying the method' is assumed from the context of the paper. Therefore, it is not an explicit action, and while it points to an area for improvement, the specific steps are not laid out, making it only partially actionable.", "grounding_specificity_rationale": "The review point refers to 'men' and 'women,' which are specific groups, and 'insurance,' a specific service. However, the phrase 'after this method is applied' is somewhat vague and doesn't explicitly point to a specific section, table, or figure where the method's results are likely presented. While the *what* (amount paid) and *who* (men and women) are clear, the *where* is less specific. Therefore, it is not fully grounded, but the elements being compared are specific.", "verifiability_rationale": "The review point is a question about a specific outcome (the amount paid by men and women after applying a method). It does not contain an explicit claim, judgment, or suggestion. It is a request for information rather than a critique or recommendation. Therefore, it has X.", "helpfulness_rationale": "The review point is a question about a specific outcome. While it points to a potential area for analysis, it does not provide actionable feedback or suggestions for improvement. It does not tell the author what needs to be changed or how to proceed based on this information. Therefore, it is not helpful in terms of guiding the author's work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"The meta solvers seem to be centralized controllers\" and provides a clear next step: \"The authors should clarify the difference between the meta solvers and the centralized RL where agents share the weights.\" This directly points out a potential ambiguity and suggests a concrete action the authors should take to improve their draft.", "grounding_specificity_rationale": "The reviewer refers to \"meta solvers\" and contrasts them with \"centralized RL where agents share the weights.\" While \"meta solvers\" might not be a universally standard term within the specific subfield the paper focuses on, the comparison to a wellknown centralized RL concept provides a clear anchor. The reviewer implicitly suggests the paper needs more clarity on this comparison. The authors can deduce the referenced concept, but the reviewer is asking for a specific clarification.", "verifiability_rationale": "The reviewer is making an observation about the potential interpretation of \"meta solvers\" and suggesting a clarification. This is a statement of interpretation and a request for information, not a definitive claim requiring proof. It's a suggestion for improvement based on a potential point of confusion. There is X that needs to be verified, and no examples or references are provided in this suggestion.", "helpfulness_rationale": "The reviewer is highlighting a potential ambiguity in the paper's description of \"meta solvers\" and wants clarification on how they differ from \"centralized RL\" where agents share the weights. This directly addresses a potential point of confusion for the authors and encourages them to be more precise in their terminology or provide a clearer distinction. This is a valuable suggestion that directly contributes to improving the clarity and understanding of the paper."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review points out a problem with the paper's categorization but doesn't offer a specific action or solution. It criticizes the method of splitting papers by publication year but doesn't suggest an alternative or how to implement a change. The reviewer identifies the unfairness of papers posted on arxiv before the ACL anthology was officially released, but doesn't propose a concrete step to address this issue.", "grounding_specificity_rationale": "The review states a fact about the BERT paper being available on arxiv before the ACL anthology was officially released. However, it does not explicitly identify which specific part of the paper being reviewed this fact relates to. The reviewer mentions the unfairness of the categorization but does not specify how this affects the particular paper under consideration or suggest a way to ground the criticism in the paper's content or analysis.", "verifiability_rationale": "The review contains a factual statement about the BERT paper being available on arxiv before the ACL anthology was officially released. This statement is presented as a fact without any claim, judgment, or suggestion. It does not require verification through logical reasoning, common knowledge, or external references. The statement is general and does not specify what needs to be addressed in this part.", "helpfulness_rationale": "The review raises a valid concern about the potential bias in the paper's categorization due to the difference in posting dates between arxiv and the ACL anthology. This concern could influence the authors' interpretation of the review and their decision on how to proceed. While the review doesn't offer a direct solution, it highlights a potential issue that could impact the authors' perception of the fairness of the process. The authors might consider this review when evaluating the paper's placement or the evaluation criteria."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their lack of understanding regarding the motivation for using \u03b2 and the difference between QRS and RS. This directly points to unclear actions and vague actions.", "grounding_specificity_rationale": "The reviewer mentions 'Algorithm 1' and specific components like '\u03b2' and 'QRS'. While they point to a specific algorithm, they don't explicitly state which section or table they are referring to, making the grounding somewhat weak. Furthermore, they don't explain *why* these components are unclear, making the specificity limited.", "verifiability_rationale": "The reviewer makes claims about their lack of understanding of the motivation for \u03b2 and the difference between QRS and RS. However, they don't provide any evidence or references to support these claims within the review point itself. The support is implied but not explicitly stated.", "helpfulness_rationale": "The reviewer's statement about their lack of understanding is a clear and actionable feedback. They are directly pointing out areas where the paper is unclear. The request for clarification on specific algorithmic components is also a helpful suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue: 'a) The experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method'. This is an explicit statement of a problem. However, the reviewer does not explicitly state what needs to be done to improve the experiments. While the problem is stated, the action to address it is not. Therefore, the review is partially actionable.", "grounding_specificity_rationale": "The reviewer refers to 'the experimental results on the last two datasets' and 'the performance is similar to IRM'. This indicates a clear identification of the specific part of the paper being addressed. The reviewer also specifies what is being compared ('performance' to 'IRM'). This demonstrates a high level of grounding and specificity in identifying the issue. However, the reviewer does not specify *why* the performance is similar to IRM, which limits the specificity of the identified problem. Therefore, the grounding is fully grounded and somewhat specific.", "verifiability_rationale": "The reviewer states the problem: 'a) The experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method' and provides a reason: 'since the performance is similar to IRM'. However, the reviewer does not provide any external references, logical reasoning, or examples to support their claim that the results are 'not convincing enough' or that the performance is 'similar to IRM'. The reviewer expresses a doubt but does not provide sufficient evidence to back up their claims. Therefore, the claim is not verifiable.", "helpfulness_rationale": "The reviewer's comment clearly identifies a significant weakness in the experimental validation of the proposed method. They point out the similarity in performance to IRM, which raises concerns about the effectiveness of the proposed method. This is a valuable piece of feedback as it directly addresses a key aspect of the paper's empirical evaluation. The reviewer's comment is focused and directly relevant to improving the understanding of the method's effectiveness. Therefore, the review is 5."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "3 (3)", "verifiability_label": "4 (4)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer is asking a question about the *why* behind detecting both entities, which is a request for justification rather than a direct statement of an action to be taken. While the *action* of detecting entities is implicit, the lack of explicit justification makes it 3.", "grounding_specificity_rationale": "The reviewer refers to 'Figure 2' and 'long one' which grounds the discussion in the paper. They also ask a specific question about the *difference*, indicating they are seeking clarification on a specific aspect of the concept. However, the *content* of Figure 2 and the *long one* are not defined within the review point itself, leaving ambiguity about what exactly is being compared.", "verifiability_rationale": "The reviewer states a question, which is a factual statement about their understanding or expectation. While there's X being made, the *question itself* is verifiable in the sense that it's a factual statement about the reviewer's understanding or expectation. The *answer* to the question would be verifiable if provided.", "helpfulness_rationale": "The reviewer is asking a question, seeking clarification. While it's a valid question, it doesn't directly *improve* the draft. It's more about guiding the authors to improve their explanation of entity detection rather than pointing out a specific weakness that needs fixing. Therefore, it's not 5."}
{"actionability_label": "3", "grounding_specificity_label": "2: 5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification on the meaning of 'chunks' in the context of nonsequential information. While the action is implicit (identifying a potential point of confusion), the reviewer is not inferring the action of ' chunking ' but rather asking for a definition. Therefore, it is not explicitly stated, requiring the authors to deduce the meaning of ' chunks ' in this specific context. This implies a need for clarification rather than a direct instruction on what to do.", "grounding_specificity_rationale": "The reviewer is directly addressing the term ' chunks ' in the paper and asking a specific question about its meaning in the context of ' nonsequential information '. The authors can identify the specific part of the paper being addressed (the definition of ' chunks '), and the comment clearly specifies what needs to be understood (the meaning in the context of nonsequential information). Therefore, the grounding is explicit, and the issue being addressed is specific.", "verifiability_rationale": "The review point is a question seeking clarification, not a claim or assertion. There is no statement that needs to be verified or supported by evidence. It's a request for a definition or explanation.", "helpfulness_rationale": "The reviewer is asking for clarification on a potentially confusing term (' chunks ') in the paper. This can be helpful for the authors to understand the paper's concepts better. While it doesn't directly point out a flaw, it seeks to resolve a potential ambiguity, which can ultimately improve the authors' understanding and the paper's clarity. Therefore, it is 3 in this regard."}
{"actionability_label": "Actionable", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly points out a potential issue with Theorem 1, specifically regarding isolated nodes. This is an explicit and concrete question about how the theorem applies in a specific scenario. The authors can identify the need to reexamine the theorem's conditions and implications for nodes with zero neighbors. The action is clear: investigate the theorem's applicability to isolated nodes.", "grounding_specificity_rationale": "The reviewer refers to 'Theorem 1,' which explicitly grounds the comment to a specific part of the paper. The question is also specific, asking about the case of a node with 0 neighbors. The authors can clearly identify the theorem being discussed and the specific scenario being questioned. This is 5.", "verifiability_rationale": "The reviewer presents a question about the validity of Theorem 1 in a specific case. This can be considered a claim that the theorem's upper bound applies even to isolated nodes. However, the paper hasn't explicitly stated this as a claim that requires verification. The reviewer is posing a question that needs to be investigated, but the paper itself hasn't made a definitive claim about the theorem's correctness in this scenario. Therefore, it is 1 because the paper hasn't made a claim that needs to be supported by evidence within the paper itself.", "helpfulness_rationale": "The reviewer's question directly relates to a key theorem discussed in the paper. It highlights a potential area of confusion or a need for clarification regarding the theorem's applicability. This is 5 for the authors as it directly addresses a point of uncertainty and encourages them to think critically about the theorem's conditions and limitations. The authors can use this feedback to seek further clarification or investigate the specific case of isolated nodes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a weakness in the paper's analysis of GPTgenerated rumors (lack of deeper analysis) but does not explicitly recommend a specific action to address it. While the reviewer points out a specific issue, the suggestion to 'further analyze or propose solutions' is general and lacks concrete steps for the authors to take.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the handling of rumors generated by GPT' and asks a specific question about why GPTgenerated rumors are as hard to detect as natural ones. This demonstrates a clear grounding of the comment in a specific part of the paper and a specific issue within it.", "verifiability_rationale": "The reviewer makes a claim about the paper's analysis (lack of deeper analysis) and provides a logical explanation based on the difficulty of detecting GPTgenerated rumors being similar to natural ones. This claim is supported by reasoning and common knowledge, making it verifiable.", "helpfulness_rationale": "The reviewer's comment is critical and points to a specific area for improvement in the paper (the lack of deeper analysis of GPTgenerated rumors). While it doesn't offer a direct solution, it clearly identifies a limitation and suggests a direction for improvement, making it helpful for the authors to focus their attention."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states 'The technical contribution is limited' and provides a specific example ('the contents of Section 4 are not about a formal and principled solution, but most about heuristics'). This makes the action somewhat explicit as the authors can infer that the draft needs a more formal and principled approach, particularly in Section 4. However, the action is not fully concrete as the authors are not given explicit steps on how to achieve this.", "grounding_specificity_rationale": "The comment explicitly mentions 'Section 4' as a specific part of the paper. This clearly identifies the area being addressed, making the grounding fully explicit. The comment also specifies that the content of Section 4 is 'not about a formal and principled solution, but most about heuristics', which further clarifies the nature of the issue.", "verifiability_rationale": "The comment states 'The technical contribution is limited' and provides an example ('the contents of Section 4 are not about a formal and principled solution, but most about heuristics'). These statements are claims that require justification. However, the review point does not provide any logical reasoning, common knowledge, or external references to support these claims. The claims are presented as observations rather than welljustified statements.", "helpfulness_rationale": "The comment identifies a potential weakness in the paper's technical contribution and points to a specific section. However, it does not offer concrete suggestions or actionable steps for the authors to take. The comment is more of a critique of the current state rather than a constructive suggestion for improvement. The authors would likely need to engage with the comment to understand the limitations and potential areas for improvement, but they wouldn't get direct, actionable guidance from this comment alone."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests exploring 'various probability mass functions' to add depth to the experimental setting. While not explicitly stating which distributions to use, the suggestion is clear and points towards a concrete area for improvement. The reviewer also suggests considering learners individually, which is a specific action point. However, the suggestion is somewhat vague in terms of implementation details.", "grounding_specificity_rationale": "The reviewer's comment is a general critique of the experimental setup, specifically the use of a quasiuniform distribution for the probability mass function. They do not explicitly refer to a specific section, table, figure, or unique aspect of the paper. While they later suggest considering learners individually, this is a suggestion for improvement rather than a direct reference to a specific part of their work. The comment is broadly applicable to the experimental setup.", "verifiability_rationale": "The reviewer makes a claim that the quasiuniform distribution is 'well suited' and suggests that exploring other distributions would be 'further depth.' This is a claim that requires justification. The reviewer provides a general rationale for their suggestion but lacks specific examples of why certain distributions would be suitable or how considering learners individually would work. While the reasoning is logical, the lack of concrete evidence makes the claim somewhat underjustified.", "helpfulness_rationale": "The reviewer's comment is relevant to the authors as it points out a potential area for improvement in their experimental setup \u2013 exploring different probability mass functions. The suggestion to consider learners individually is also a valuable direction for enhancing the experimental design. While the suggestions are broad, they are clear and point towards specific actions the authors could take to refine their work. The reviewer's regret about the unexploited PMF suggests a genuine interest in improving the experimental rigor."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point does not propose a specific action or improvement based on the observed difference in abstention rates. It raises a question about the fairness of comparing models with different behaviors, but does not offer a concrete step to address this issue.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or model where grounding is lacking. It is a general comment about the behavior of ChatGPT compared to other models.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a question about the methodology of comparing model accuracies based on abstention rates, not a statement that needs to be supported by evidence.", "helpfulness_rationale": "The review point raises a valid concern about the fairness of comparing model accuracies when one model has a significantly higher abstention rate. This provides the authors with information to consider when evaluating the models' performance and potentially adjust their comparison methodology."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'Missing references: the references below are relevant to your topic, especially a. Please discuss connections with a' and names a specific paper (a Samulowitz, Horst, and Roland Memisevic. \"Learning to solve QBF.\"). This is an explicit and concrete action, as the reviewer identifies a deficiency and provides a specific suggestion for improvement.", "grounding_specificity_rationale": "The reviewer explicitly mentions a specific paper (a Samulowitz, Horst, and Roland Memisevic. \"Learning to solve QBF.\") and explains why it is relevant ('especially a. Please discuss connections with a which uses supervised learning in QBF solving, where QBF generalizes SMT'). This makes the grounding 5.", "verifiability_rationale": "The reviewer makes a claim that the paper a is relevant and provides a justification for this claim by stating its use of supervised learning in QBF solving and the generalization of QBF over SMT. This claim is wellsupported by logical reasoning and specific examples.", "helpfulness_rationale": "The reviewer directly addresses a potential weakness by pointing out missing relevant references and suggesting a concrete solution (discussing connections with a specific paper). This is a 5 comment as it guides the authors to potentially improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a specific detail: 'a monotonic relationship is imposed between the degree of a singletask predictor participation and the weight of the corresponding task loss.' This action is directly identified by the reviewer. The reviewer also points to the consequence of this imposed relationship: 'the ensemble engenders a subspace that explicitly encodes tradeoffs and results in a continuous parameterization of the Pareto Front.' This shows a clear action that the authors can identify and understand.", "grounding_specificity_rationale": "The reviewer mentions 'a specific part of the paper' where the monotonic relationship is imposed, which implies they are referring to a particular section or concept within the paper. However, they do not explicitly name the section, table, figure, or unique aspect. The grounding is present but not fully explicit. The reviewer also states 'the degree of a singletask predictor participation' and 'the weight of the corresponding task loss,' which are specific elements within the paper. The specificity of the claim is about the *variables* involved, not a precise location.", "verifiability_rationale": "The reviewer poses a question: 'Whether the mono tonic relationship can be replaced by other relationships?' This constitutes a claim that requires verification. However, the reviewer does not provide any evidence, justification, or reasoning to support or refute this claim. There are no logical arguments, references to external works, or examples provided to back up their suggestion.", "helpfulness_rationale": "The reviewer suggests 'Explaining this point may be better' and provides a relevant citation: '1Navon A, Shamsian A, Fetaya E, et al. Learning the Pareto Front with HypernetworksC//International Conference on Learning Representations. 2020.' This indicates a desire to improve the clarity and provide context for the point. While the reviewer doesn't explicitly offer a solution or a detailed explanation, they are suggesting a concrete action (improving the explanation) and providing a resource. This makes the point 3 as it highlights a potential area for improvement in the presentation of the method."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests a comparison, making it an explicit action. However, the comparison is vague, lacking specific details about which aspects or methods are being compared, making it less actionable.", "grounding_specificity_rationale": "The reviewer refers to 'computation cost / running time' generally, without specifying a particular section, table, figure, or unique element of the paper. Therefore, the grounding is weak. While the topic is specific (computation cost), the aspect within the paper being addressed is not clearly defined.", "verifiability_rationale": "The review point poses a question ('How about the comparison...') rather than making a definitive claim. While it requests information, it doesn't provide a clear justification or reasoning for why such a comparison is needed or how to perform it, making it 2.", "helpfulness_rationale": "The review point suggests a comparison, which is relevant to understanding the computational demands of the work. However, it lacks specificity, making it 3 but not immediately actionable for the author. The authors would need to infer what kind of comparison is intended."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks two questions: 'Why is this approach more privacy preserving than other federated learning approaches?' and 'One would think that this is a very bad example of an application of federated learning. Is privacy preservation an issue for traffic signal control, i.e. one traffic signal not to know what is the color of the next one?'. Both questions are direct requests for information or clarification, making them actionable for the authors.", "grounding_specificity_rationale": "The reviewer's questions are not directly tied to a specific section, table, or figure of the paper. While the *topic* of privacy preservation is relevant, the *specific* part of the paper being questioned is not explicitly mentioned. However, the question about the traffic signal application is quite specific.", "verifiability_rationale": "The reviewer does not make any claims or judgments. They are asking questions and seeking information. Therefore, there is no verifiable claim in the review point.", "helpfulness_rationale": "The reviewer's questions are openended and encourage the authors to elaborate on their privacy mechanisms and justify their choice of application. This promotes selfreflection and potentially leads to improvements in their work. While it doesn't directly point out flaws in their work, it encourages them to consider alternative applications and refine their approach, making it helpful in that regard."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the section description is unclear and points to a later part as the solution. This suggests an implicit suggestion for improvement, but the specific action (e.g., 'improve the introduction') is not directly stated. The reviewer identifies a lack of clarity, which implies an actionable suggestion, but it's not explicitly stated.", "grounding_specificity_rationale": "The reviewer states the description is 'hard to understand' without specifying which part of the section, paragraph, or unique aspect is unclear. The comment is general and doesn't identify a specific section, table, figure, or unique element of the paper. The reviewer's comment is vague and doesn't pinpoint the problematic part of the paper.", "verifiability_rationale": "The reviewer makes a claim: 'this description of the neural network is hard to understand.' This is a statement of opinion or difficulty. The reviewer also provides a reason for their claim: 'The final paragraph of the section makes it clear, however.' This offers a basis for understanding the issue and a suggestion for resolution. While not a direct citation, it provides a basis for verification.", "helpfulness_rationale": "The reviewer's comment directly points out a weakness ('lack of clarity') and suggests a solution ('starting the section with it'). This is a constructive critique aimed at improving the paper. The reviewer clearly identifies a problem and offers a potential improvement strategy. Addressing this point would likely improve the reader's understanding of the section."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests an alternative training approach (attentionbased loss) to the current CTC loss. This directly implies a potential action the authors could take to improve their model. The suggestion is explicit about a change they could make to their training methodology.", "grounding_specificity_rationale": "The reviewer mentions 'CTC loss' as a point of comparison but doesn't specify where in the model or architecture this loss is applied. They don't provide a unique element or section that clearly identifies the issue. The reference is general.", "verifiability_rationale": "The reviewer proposes an alternative training approach but doesn't provide any justification or evidence for why this would be beneficial or how it compares to CTC. There's no logical reasoning, common knowledge, or references provided to support this claim.", "helpfulness_rationale": "The reviewer offers a concrete suggestion for improvement (training with attentionbased loss) but lacks any justification or explanation of why this is a good idea. It's a valid suggestion, but without further context or reasoning, it's not particularly helpful."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the observation about tables being divided into three types. However, the action of investigating or providing a solution is not explicitly stated, making it partially actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'Section 3 (line 247252)', which is a precise reference. However, the specificity is limited to the observation about table formatting and does not delve into the reasons or propose a complete solution, making it 4.", "verifiability_rationale": "The reviewer is asking for confirmation or clarification, which can be seen as an implicit suggestion that the current formatting might be an issue. While the reasoning is logical (checking formatting), there are no external references provided, making it partially verifiable.", "helpfulness_rationale": "The review points to a specific area and raises a valid question. While it doesn't directly point out a flaw, it prompts the authors to examine a specific detail more closely, which can be helpful in improving attention to detail. However, it doesn't provide a concrete solution, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of the two attack methods used in the paper and suggests using 'more classical attack methods in NLP' as alternatives. This is a clear identification of a weakness and a direct suggestion for improvement, making it actionable. While the reviewer doesn't provide specific details on how to implement these alternative methods, the suggestion itself is a concrete action pointing towards a potential improvement in the experimental setup.", "grounding_specificity_rationale": "The reviewer refers to 'the two attack methods' described in the paper, indicating a clear understanding of the specific methods being criticized. However, the suggestion of 'more classical attack methods in NLP' is general and doesn't specify which methods are being referred to or how they differ from the two already used. This lack of specificity makes the grounding somewhat weak.", "verifiability_rationale": "The reviewer's point does not contain a direct claim that needs to be verified. It's a suggestion for improvement rather than a statement that requires evidence. Therefore, it doesn't fit the criteria for verifiability. It leans towards being 'X' (X) as it doesn't present a statement that needs to be supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer's point directly addresses a potential weakness in the paper's experimental setup by suggesting alternative attack methods. This provides the authors with concrete feedback on how their work could be further evaluated. The suggestion to use 'more classical attack methods in NLP' is intended to improve the robustness of their findings, making the review 5 in guiding future research or analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential methodological flaw (leakage of information) that could affect the validity of comparisons. While the reviewer identifies a *potential* risk, they don't specify *how* this leakage occurs or what specific steps need to be taken to prevent it. This makes the action implicit and vague.", "grounding_specificity_rationale": "The reviewer mentions \"pretrained visual model\" and \"target dataset,\" which are specific parts of the paper being discussed. The comment specifies what needs to be addressed in this part, which is the potential for information leakage.", "verifiability_rationale": "The comment contains a claim (\"potential risk\") without any supporting evidence or justification. The reasoning is presented as a statement of concern rather than a logical argument backed by facts or references.", "helpfulness_rationale": "The reviewer identifies a relevant issue that could impact the validity of comparisons. However, the feedback is limited to stating the problem without offering specific solutions or detailed explanations of how the leakage occurs. The suggestions are not actionable."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review point expresses a surprise and a potential misunderstanding, but does not explicitly state an action or suggestion for the authors. The reviewer is reacting to the dominance of function words, not proposing a concrete step to address it.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Figure 1' and discusses 'function words' and 'content words', clearly identifying the specific part of the paper and the issue being addressed.", "verifiability_rationale": "The reviewer's statement is an opinion or judgment about the content of Figure 1, specifically the dominance of function words. There is X that is explicitly supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point raises a question about the clarity of Figure 1's explanation regarding word frequencies. While it identifies a potential issue, it does not provide a concrete suggestion or actionable step for the authors to improve their draft based on this observation."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their suggestion: \"I think the minimal kmeans objective over multiple seeds is more reasonable.\". This is a clear and direct action. Furthermore, the reviewer provides a reason for this action: \"It's more reasonable\", and references (1 Jin, Chi, et al. \"Local maxima in the likelihood of gaussian mixture models: Structural results and algorithmic consequences.\" Advances in neural information processing systems 29 (2016): 41164124. 2 Fr\u00e4nti, Pasi, and Sami Sieranoja. \"Kmeans properties on six clustering benchmark datasets.\" Applied Intelligence 48.12 (2018): 47434759.\" that support their claim. Therefore, the action is both explicit and concrete.", "grounding_specificity_rationale": "The reviewer directly addresses the calculation of the baseline kmeans objective by stating: \"Minor suggestion: the average of k means objectives with multiple seeds are used as a baseline, I think the minimal k means objective over multiple seeds is more reasonable.\". This clearly identifies the specific part of the method being discussed (the baseline calculation). The reviewer also provides a justification for their suggestion: \"I think the minimal kmeans objective over multiple seeds is more reasonable.\". This indicates a level of specificity in their comment, explaining *why* they believe the minimal objective is better. While the initial part of the sentence could be interpreted as a general suggestion, the subsequent part clarifies the specific aspect being addressed.", "verifiability_rationale": "The reviewer makes a claim by stating: \"I think the minimal kmeans objective over multiple seeds is more reasonable.\". This claim is supported by the reviewer's reasoning: \"It's more reasonable\" and by providing references (1 Jin, Chi, et al. \"Local maxima in the likelihood of gaussian mixture models: Structural results and algorithmic consequences.\" Advances in neural information processing systems 29 (2016): 41164124. 2 Fr\u00e4nti, Pasi, and Sami Sieranoja. \"Kmeans properties on six clustering benchmark datasets.\" Applied Intelligence 48.12 (2018): 47434759.\". These references, while not directly providing a mathematical proof, are relevant to the discussion of kmeans objectives and support the reviewer's assertion. Therefore, the claim is wellverified.", "helpfulness_rationale": "The reviewer's suggestion directly addresses a methodological choice in calculating a baseline metric for kmeans. This is a specific and actionable improvement that could potentially impact the interpretation of results and the conclusions drawn from the data. The reviewer clearly identifies the area of concern (the baseline calculation) and proposes a concrete alternative. The references provided further contextualize the suggestion within the existing literature on kmeans. This makes the reviewer's point directly actionable and potentially impactful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'Important reference missing' and names the specific paper 'Lista' with its URL. This is a clear and actionable item for the authors to address.", "grounding_specificity_rationale": "The authors can accurately pinpoint the section, table, figure, or unique aspect being addressed by the reviewer's statement that a 'closely related reference' is missing. They can also clearly identify the 'appropriate context' the reviewer is referring to.", "verifiability_rationale": "The comment contains a claim that the paper is 'closely related' to 'Lista' and that it is 'important that the paper talks about them and places itself in appropriate context'. However, the comment does not provide any specific justification or evidence to support this claim. It does not mention specific examples, external references, or logical reasoning to back up the assertion of a close relationship.", "helpfulness_rationale": "The review point is helpful in identifying a gap in the related work section by highlighting the importance of discussing the connection to 'Lista'. However, it does not provide specific guidance on how to analyze this relationship or what aspects of 'Lista' are most relevant for the proposed work. The reviewer is pointing to a relevant area but lacks detailed instructions for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of clarity regarding the definition of sparsity and requests evidence for the sparsity assumption across various noisy cases. While the reviewer identifies these as areas needing improvement, they do not provide specific actions or suggestions on how to clarify the definition or gather the requested evidence. The reviewer's request for a comparison with existing methods is also stated but not acted upon with concrete steps. Therefore, while the reviewer identifies issues, the lack of specific actions makes the points 3 but not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions the sparsity of the residual term and the need for evidence across noisy cases. However, they do not explicitly identify the specific section, table, or unique aspect of the paper being addressed. The reviewer's comment is general and does not pinpoint the exact location of the information being referred to. Therefore, the grounding is weak. The request for a comparison with existing methods is also general and does not specify which methods are being referred to. Thus, the specificity is also weak. Combining the weak grounding with weak specificity leads to '2'.", "verifiability_rationale": "The reviewer states that the specific definition of the sparsity of the residual term is unclear. This is a claim that needs to be supported. The reviewer also claims that evidence for the sparsity assumption across various noisy cases is missing, which also needs to be supported. Finally, the reviewer claims that the proposed method's assumptions have advantages over existing methods, which also requires justification. All these claims are stated but lack sufficient evidence or justification, making them partially verifiable.", "helpfulness_rationale": "The reviewer points out the lack of clarity regarding the definition of sparsity, which is a valid concern for the authors. They also request evidence for the sparsity assumption, which is a constructive suggestion. Similarly, they request a comparison with existing methods, which is also a constructive suggestion. While the reviewer identifies valid areas for improvement, they do not offer concrete solutions or detailed explanations, making the points 3 but not fully helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that 'connectivity' is misleading. This is a direct action the reviewer is taking \u2013 pointing out a specific issue with the terminology. The reviewer also specifies what they believe 'connectivity' should refer to (structural connections between the brain and body). This makes the actionable suggestion both explicit and concrete.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly grounded in a specific section, table, or figure of the paper. They are making a general comment about the terminology used. However, the reviewer is very specific about *what* they believe 'connectivity' should refer to, which is the structural connections between the brain and body. This specificity is about the concept being discussed rather than a literal reference to a specific part of the paper.", "verifiability_rationale": "The reviewer makes a claim: 'connectivity is misleading'. However, they do not provide any evidence or justification to support this claim. There are no references to external works or logical reasoning provided to back up their assertion. Therefore, the claim is not wellsupported.", "helpfulness_rationale": "The reviewer points out a potential ambiguity in the terminology used. While it might not be a critical flaw that requires immediate correction, it is a valid point that could improve the clarity of the paper for some readers. The reviewer is suggesting a specific change (clarifying the term) and providing a clear explanation of what they believe it should refer to. This makes the feedback actionable and potentially helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point identifies the paper as 'not polished and not ready to publish' and points out 'missing details' in 'related work', 'experiment', and 'writing'. While this is a valid observation, it doesn't explicitly state how to improve the polish or add the missing details. The reviewer implicitly suggests improvements but lacks concrete steps. Therefore, the action is identified but not explicitly stated or detailed.", "grounding_specificity_rationale": "The review point mentions 'related work', 'experiment', and 'writing' as areas needing improvement. While this provides some context, it doesn't pinpoint specific subsections, figures, or tables within these broader categories. The grounding is present but not fully precise. Therefore, the parts of the paper are somewhat identified, but the specificity is limited.", "verifiability_rationale": "The review point makes claims about the paper's 'polish', 'readiness for publication', and the presence of 'missing details'. However, it doesn't provide any logical reasoning, common knowledge, or external references to support these claims. The statements are presented as opinions without justification. Therefore, the claim is made but lacks any supporting evidence or justification.", "helpfulness_rationale": "The review point identifies areas where the paper needs improvement, specifically mentioning 'related work', 'experiment', and 'writing' as lacking 'missing details'. However, it doesn't offer any specific suggestions or guidance on how to address these issues. The feedback is present but lacks actionable steps and concrete examples. Therefore, the feedback is identified but not sufficiently detailed to be 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer implicitly points out a potential gap or missing justification regarding the use of orthogonal matrices, particularly in the context of steps 2 and 3. However, the reviewer does not explicitly state the next steps or actions the authors should take to address this. The suggestion is more of a constructive comment than a direct instruction.", "grounding_specificity_rationale": "The reviewer mentions 'orthogonal matrix' and 'steps 2 and 3' in their review point. While they don't specify a particular section or equation, they do identify a general area of the methodology that might be unclear. This provides some level of grounding, but it's not as precise as identifying a specific section or table. The mention of 'steps' adds a bit more specificity than just mentioning 'orthogonal matrix'.", "verifiability_rationale": "The reviewer makes a claim about the potential simplification in step 3 and the lack of study on the essentialness of orthogonal matrices. This claim could be considered verifiable if supported by further investigation or evidence. However, the reviewer doesn't provide any specific examples or references to back up their claim about the lack of study. The claim about the potential simplification is more of a hypothesis that could be explored.", "helpfulness_rationale": "The reviewer's comment is clear and identifies a potential issue with the paper's methodology. By pointing out the lack of justification for using orthogonal matrices and suggesting further study, the reviewer provides a constructive critique that could guide the authors. While it doesn't offer a direct solution, it highlights a missing element that is valuable for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the models and datasets are 'toylike' and provides specific examples of what they consider more realistic benchmarks: CIFAR100, ResNet 34/50, and ViTtiny/small. This indicates a direct and clear identification of a problem with the current experimental setup.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'models and datasets' and then narrows it down to specific examples like 'CIFAR100', 'ResNet 34/50', and 'ViTtiny/small'. This demonstrates a strong grounding of the comment in the specific parts of the paper being discussed. The reviewer also provides concrete examples of what they consider *good* models and datasets, specifying the architecture and size.", "verifiability_rationale": "The review point makes a clear claim that the models and datasets are 'toylike'. While this claim itself might not be directly verifiable *within this review point* without access to the paper's experimental details, the reviewer's suggestion to use more realistic benchmarks and their question about language tasks indicate a desire for more robust experimentation. The intent is to highlight a potential gap in the current experimental setup.", "helpfulness_rationale": "The review point is 5 as it directly addresses the experimental setup, a crucial aspect of any research. It provides specific examples of what the reviewer considers to be more realistic models and datasets. The reviewer also raises a question about the challenges of applying these to language tasks, which is a valuable point for the authors to consider. The suggestions and questions are actionable and constructive."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing nature of ablation studies and proposes a specific experiment (scratchGAN) and a question ('do you *do* pretrain?') to address it. This provides clear guidance for the authors.", "grounding_specificity_rationale": "The reviewer clearly identifies the 'central argument against pretraining' as the basis for their suggestion and proposes a specific experiment (scratchGAN) to test it. While they don't explain *why* MLE pretraining might result in similar models, they identify a specific area of interest and suggest a way to investigate it.", "verifiability_rationale": "The reviewer states a claim about the limitations of MLE pretraining and provides a concrete suggestion (the scratchGAN experiment and the question 'do you *do* pretrain?') to test this claim. This offers a clear methodology for the authors to investigate.", "helpfulness_rationale": "The reviewer clearly articulates a specific weakness (missing ablation studies) and provides a concrete suggestion (scratchGAN) and a question to address it. This directly empowers the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the absence of comparison against baselines as a significant omission. This is a direct and clear action that the authors should take. The reviewer also implies the importance of this comparison for understanding the contribution of the work.", "grounding_specificity_rationale": "The reviewer mentions 'binary analysis application' and further specifies 'architectureagnostic similarity comparison' or 'codesearch'. This provides a clear and specific reference point for the missing baselines, indicating strong grounding.", "verifiability_rationale": "The reviewer provides a justification for the lack of baselines by stating that 'this is a widelyunderstood binary analysis application' and 'many papers have developed architectureagnostic similarity comparison (or often reported as codesearch)'. This provides a logical reasoning and references existing work, making the claim verifiable.", "helpfulness_rationale": "The reviewer's comment directly points to a crucial missing element in the related work section \u2013 comparisons to existing similarity analysis techniques in binary analysis. This is a clear and actionable suggestion that would significantly improve the understanding of the paper's contribution and context."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the evaluation in SI 6.5 is 'slightly different' and specifically mentions the absence of 'human starts' compared to Mnih et al. 7. This is an explicit statement of a change that the authors would need to implement or understand. The reviewer directly points out a concrete action the authors should take (understanding the impact of no human starts).", "grounding_specificity_rationale": "The review point explicitly refers to 'SI 6.5' and 'Mnih et al. 7' and highlights the specific difference in the evaluation method ('no human starts'). This clearly grounds the comment to the relevant section and points to the specific detail being discussed. The reviewer provides a precise reference point.", "verifiability_rationale": "The review point makes a clear claim about a difference in the evaluation methodology ('slightly different...no human starts'). Authors can infer the nature of this difference by looking at the original Mnih et al. paper or by having access to the code. While the reviewer themselves hasn't done the detailed comparison, the claim is logically supported by the context of the comparison. The information is verifiable, even if the reviewer themselves hasn't done the detailed comparison.", "helpfulness_rationale": "The review point identifies a specific methodological difference in the evaluation of SI 6.5. While it doesn't directly tell the authors what to change, it points out a relevant detail that could impact their interpretation of the results. By highlighting this difference, the reviewer is providing information that could be valuable for understanding and replicating the work. It helps the authors understand a specific aspect of the experimental setup."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the absence of efficiency metrics, which is a clear indication of an action the authors should take. The suggestion to include metrics is direct and actionable.", "grounding_specificity_rationale": "The reviewer explicitly identifies the missing metrics related to training efficiency, which directly points to a specific aspect of the paper. This demonstrates strong grounding as the reviewer can accurately pinpoint the section where the issue lies (the results section, implicitly, where efficiency metrics should be). The specificity is high as the reviewer names the type of metric needed.", "verifiability_rationale": "The reviewer makes a claim about the absence of efficiency metrics. This claim is verifiable by the logical reasoning that the paper focuses on 'advantages in terms of efficiency' without providing specific numerical evidence. The reviewer implicitly suggests that including such metrics would address the identified gap.", "helpfulness_rationale": "The review point provides a clear and actionable suggestion for the authors to improve their draft. By highlighting the missing metrics related to training efficiency, the reviewer guides the authors on what information is needed and how it should be presented. This is a valuable piece of feedback that directly addresses a gap in the paper's reporting."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete change. The criticism is general and the suggestion is about a limitation, not a direct action to take.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper being addressed. It is a general statement about the contribution.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is a subjective assessment and a suggestion for further evaluation.", "helpfulness_rationale": "The review point provides a critique of the contribution and suggests a direction for improvement. While the criticism is subjective, the suggestion is concrete and actionable for the authors. This makes the review point helpful in guiding the authors towards further analysis and refinement of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly asks for details on the statespace, action space, and the nature of theta. While they could potentially infer the need for this information, the phrasing strongly suggests they do not understand the current explanation and require more specific information. The questions are direct requests for clarification, indicating a lack of explicitness. However, the need for this information can be inferred from the context of the review point.", "grounding_specificity_rationale": "The reviewer does not explicitly state which part of the paper they are referring to when asking about the statespace, action space, and the nature of theta. They simply state these questions in a general way. This indicates a lack of explicit grounding. However, the questions themselves are quite specific, suggesting a degree of grounding, albeit not fully explicit. The reviewer could potentially infer the section or concept being discussed, but they do not provide a clear reference.", "verifiability_rationale": "The reviewer makes a claim by stating they 'need more details' regarding the statespace, action space, and the nature of theta. They also request justification for assuming theta is a parameter. This claim is not explicitly stated but is implied by their need for clarification. The reviewer requests justification, which aligns with the concept of verifiability. However, the justification is currently lacking, as the reviewer does not provide any reasoning or references to support their assumption about theta.", "helpfulness_rationale": "The reviewer asks specific, targeted questions aimed at improving their understanding of the model described in the paper. They are directly asking for clarification on key parameters and their roles. This directly contributes to the helpfulness of the review point. The questions are directly aimed at improving the authors' understanding and implementation of their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: 'the proof relies on a special case where a contradiction arises as matrix norms approach infinity.' They also explicitly mention the inapplicability of Theorem 1 due to normalization. This is a clear indication of a specific weakness in the proof technique. The reviewer directly points to a condition under which the proof's logic breaks down and highlights a consequence of this limitation.", "grounding_specificity_rationale": "The reviewer refers to 'Appendix A,' 'Section 3,' and 'Theorem 1.' This is a clear and specific identification of the relevant parts of the paper. They don't just say 'Section X is unclear,' but rather pinpoint the specific section and theorem where the issue arises. This strong referencing makes the grounding very clear.", "verifiability_rationale": "The reviewer makes a claim: 'the proof relies on a special case...'. This is a statement about the proof technique. The reviewer provides context by referencing 'Section 3' and 'Theorem 1,' which supports the claim that this is a known limitation. While the reviewer doesn't provide a new proof or example, they do point to existing information that confirms the issue. The claim is supported by references, making it 3.", "helpfulness_rationale": "The reviewer clearly identifies a potential issue with the proof technique by pointing out the special case and the inapplicability of Theorem 1. This is valuable information for the authors to understand the limitations of their results. The reviewer's comment directly helps the authors understand a specific scenario where their proof might not hold, which is a helpful piece of feedback. While it doesn't offer a direct solution, it highlights a potential area for further investigation or clarification."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests an alternative downstream task (LiDAR segmentation) and provides a reason (accurate locations and poses, relevance to IoUbased metrics) for why it might be better for the model's strengths. This suggests a potential action: evaluate the current downstream task's suitability for the model's strengths or explore alternative tasks that better align with the model's capabilities. The reviewer's statement implies a clear action to be taken.", "grounding_specificity_rationale": "The reviewer mentions \"LiDARbased segmentation\" and names \"KITTI and Waymo\" by their names. This indicates a degree of grounding specificity. They are pointing to a specific area where their alternative might be more effective. While they don't explicitly *point to a specific section* of the paper, they are referring to specific concepts and datasets relevant to the task.", "verifiability_rationale": "The reviewer states their opinion about the strengths and weaknesses of different approaches and provides a *reason* (accurate locations and poses, relevance to IoUbased metrics) for their belief. While they don't provide direct evidence to *verify* their claim, they offer a rationale based on the nature of the tasks and metrics. The claim is inferential based on the provided information, lacking specific references to external works or logical reasoning beyond the stated reasons.", "helpfulness_rationale": "The reviewer clearly states their opinion and provides a *rationale* for it, explaining why they believe the criticism is valid and what improvements could be made. The reasons provided offer a basis for improvement and actionable feedback for the authors. The comment is not just a criticism but also suggests a direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a potential issue with the objective of Eq (12) in relation to the IPO principle. While the reviewer identifies a potential problem, the comment does not explicitly state what needs to be done to address this. The authors would need to investigate further to determine if there is a contradiction and how to resolve it. Therefore, the comment is not immediately actionable as it requires further analysis by the authors.", "grounding_specificity_rationale": "The reviewer mentions 'Eq (12)' in their comment. While they do not explicitly state the section, table, figure, or unique aspect being addressed, the reference to 'Eq (12)' itself can be considered a form of grounding. However, the reviewer does not specify *what* is wrong with Eq (12)'s objective in relation to IPO. The authors would need to locate 'Eq (12)' themselves to understand the potential contradiction. Therefore, the grounding is implicit and not fully specific.", "verifiability_rationale": "The reviewer raises a concern about a potential contradiction between the objective of Eq (12) and the IPO principle. However, they do not provide any evidence, reasoning, or external references to support this claim. The reviewer simply states the *possibility* of a contradiction. Without any supporting evidence, the claim remains 1. The reviewer's comment is essentially a hypothesis that needs to be investigated.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the alignment of the objective function with the IPO principle. This is a relevant piece of feedback for the authors. However, the comment does not provide concrete steps or evidence to help the authors address this issue. The authors would need to investigate further to determine if there is a contradiction and how to resolve it. Therefore, while the comment is relevant, it is not immediately helpful as it requires further investigation by the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a question about the assumption, which can be interpreted as an implicit action to seek clarification or justification. However, the action is vague as the reviewer doesn't specify how the assumption should be addressed or what evidence they expect. Therefore, while the intent is actionable, the lack of explicitness and concreteness makes it 3 but not fully explicit or concrete.", "grounding_specificity_rationale": "The reviewer mentions 'geometrically distinctive concepts' and 'concepts where class label correlates more with semantics.' This provides a specific reference point for the discussion, grounding the concern in particular types of concepts. The comment clearly specifies what needs to be addressed in this part (the adaptation capacity for different types of concepts). This is 5.", "verifiability_rationale": "The reviewer is asking for clarification, which is a claim (the assumption is worth questioning) that requires justification. However, the verifiability of this claim depends on external knowledge about DINO representations, which is not contained within the review point itself. The reasoning for questioning the assumption is based on general knowledge about the nature of DINO embeddings, not a direct verification within the review text. Therefore, while the topic is verifiable, the review point itself doesn't provide the verification, making it 4.", "helpfulness_rationale": "The reviewer is asking a question to gain insight into the model's behavior, specifically regarding the adaptation capacity for different types of concepts. While this is a valuable question for understanding the model, it doesn't directly provide actionable feedback or suggestions for improvement to the authors. It's more of a query for information than a direct suggestion for change. Therefore, it's 3 in providing context but not directly improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly names the loss functions (CenterLoss, ASoftmax, AMSoftmax, ArcFace), which constitutes an explicit action. However, it does not provide concrete instructions on how to compare them, making the action somewhat vague.", "grounding_specificity_rationale": "The review point explicitly mentions the names of specific loss functions, which allows for accurate identification of the part of the paper being addressed. However, it does not specify what aspects of these loss functions should be compared or why they are relevant to the current paper's focus. Therefore, while grounded in terms of section identification, the specifics of the comparison are missing, making it only weakly specific.", "verifiability_rationale": "The review point contains a claim that the comparison of stateoftheart loss functions should be added. While the suggestion is based on common knowledge within the field, it lacks specific justification or examples to support the claim, making it 3.", "helpfulness_rationale": "The review point suggests adding a comparison of loss functions. While this is a relevant suggestion for improving the paper, it does not directly address any specific weaknesses or areas for improvement within the paper being reviewed. It is a suggestion for future work or a related paper, rather than direct feedback on the current work."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point is a question, which is not inherently actionable. However, the question implies a desire for the author to clarify the intent of Section 5.2. This lack of clarity is a potential actionable gap. The reviewer is implicitly suggesting that the section's purpose is not wellunderstood, which is a form of actionable feedback.", "grounding_specificity_rationale": "The review point explicitly refers to 'Section 5.2'. This is a clear and specific identification of a part of the paper. The reviewer is asking about the content and purpose of this specific section, demonstrating strong grounding specificity.", "verifiability_rationale": "The review point is a question. Questions are generally not considered verifiable in the same way as statements that make claims or provide information. While the reviewer might be inferring a lack of clarity, the question itself does not contain a claim that can be supported or unsupported. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point is a question. While a question can highlight areas for improvement, it does not directly point out weaknesses or suggest concrete improvements. It is more of a diagnostic tool than a direct directive for improvement. Therefore, it is not 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer does not explicitly state what needs to be done regarding the threat model. They ask for a definition, which implies an action, but the specifics of that action are not laid out. The reviewer suggests defining the attacker's level of access, capabilities, and defender resources, but doesn't directly tell the authors how to do this. The action is implied but not explicit.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific part of the paper where the threat model is discussed. They refer to the 'entire threat model' concept, which is 1 to a particular section, table, or figure. While the suggestion is specific (defining the threat model), the grounding of this suggestion to a concrete part of the paper is weak. The reviewer is criticizing the lack of detail in the discussion of the threat model, not the lack of specificity within a defined section.", "verifiability_rationale": "This review point does not contain a claim that needs verification. It is a suggestion for improvement rather than a statement of fact or opinion.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: to define the threat model more explicitly. This directly addresses a potential weakness for the authors (lack of clarity on the threat model). The suggestion is specific, involving details like attacker level of access, capabilities, and defender resources. The reviewer also provides a justification for why this is important (ensuring meaningful security analysis). This makes the review point 5 for guiding improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a deficiency in the experimental methodology and provides a clear suggestion for improvement. The phrase 'should be presented as a mean over many runs (at least 10)' directly points to a specific action the authors should take. The suggestion to 'present results as a mean over many runs (at least 10), ideally with errorbars' is a concrete action with a defined implementation. The reviewer is not just pointing out a problem but also suggesting a specific and measurable way to address it.", "grounding_specificity_rationale": "The review point explicitly mentions the 'results comparing standard vs. evolutional dropout on shallow models' and the 'plotted curves are obviously from single runs'. It also specifies the desired outcome: 'presented as a mean over many runs (at least 10), ideally with errorbars'. The reviewer accurately identifies the specific experiment and the type of analysis that should have been performed. The mention of 'plotted curves' indicates a clear understanding of the visual representation of the results. The suggestion to use 'errorbars' further specifies the desired statistical representation.", "verifiability_rationale": "The review point makes a claim about the 'lack of statistical rigor' in the experimental analysis. It provides a specific suggestion for improvement by stating that the results 'should be presented as a mean over many runs (at least 10), ideally with errorbars'. This claim is supported by the understanding of statistical best practices, where presenting results as means with error bars is a standard way to show variability and reliability. The reviewer provides a logical reasoning for why the current presentation is lacking (lack of statistical rigor) and suggests a verifiable method for improvement (mean with error bars).", "helpfulness_rationale": "The review point is highly specific about a deficiency in the experimental methodology and provides a clear and actionable suggestion for improvement. The reviewer directly points out the lack of statistical rigor and proposes a concrete solution: 'present results as a mean over many runs (at least 10), ideally with errorbars'. This is a 5 and constructive comment that directly addresses a potential weakness in the authors' work. It provides a clear direction for the authors to improve their analysis and potentially strengthen their conclusions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action: 'describe the experimental environment in more detail'. It also provides concrete information on what needs to be added ('CUDA version', 'PyTorch version') and even hints at the consequences of this omission ('training speed', 'inference speed'). This makes the action very clear and actionable.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper it is addressing. While it mentions 'experimental environment', it does not specify which section, table, or figure this refers to. The grounding is implied rather than explicitly stated.", "verifiability_rationale": "The comment contains a claim: 'The authors need to describe the experimental environment in more detail'. This claim is supported by the implicit reasoning that different versions of the experimental environment can impact training and inference speed. While not explicitly stated as 'because different versions of the experimental environment will have a certain impact on training speed and inference speed', the implication is logical and provides a basis for improvement.", "helpfulness_rationale": "The review point is 5 because it directly tells the authors what information is missing ('CUDA version', 'PyTorch version') and why it is important ('training speed', 'inference speed'). It provides a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The suggestion to 'mention the evaluation metric' is an explicit action that tells the authors exactly what to do. The reviewer is not inferring anything, they are directly stating their preference. The action is also concrete, as it specifies 'mention the evaluation metric' without ambiguity.", "grounding_specificity_rationale": "The reviewer explicitly states 'For clarity, it would be better if the evaluation metric is mentioned here'. This directly identifies the specific part of the paper being addressed, which is the evaluation metric. The reviewer is not inferring what needs to be clarified, they are clearly pointing to a specific area. The grounding is strong as the section or table is mentioned explicitly.", "verifiability_rationale": "The reviewer makes a claim that 'mentioning the evaluation metric will improve clarity'. While this is a reasonable suggestion, the review does not provide any specific evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that mentioning the metric will *definitely* *improve* *every* instance of unclear writing. The claim is presented without sufficient justification.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for improvement. The suggestion is directly related to the potential issue of unclear writing regarding evaluation metrics. The suggestion is specific, telling the authors what to do. The reviewer is directly addressing a potential area of confusion for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a limitation of the approach, making it implicitly actionable. However, it lacks specific details on how the authors should address this limitation, resulting in it being 3 but not 5.", "grounding_specificity_rationale": "The review point refers to general aspects like 'bounds' and 'previously known results' without explicitly naming a specific section or table, resulting in weak grounding. While it mentions 'arbitrarily long inputs,' the specificity is limited as it doesn't pinpoint the exact nature of the bounds or the specific results being compared.", "verifiability_rationale": "The review point makes a claim about the limitations of the approach based on the properties of 'bounds' and 'previously known results,' which are verifiable through established mathematical concepts. The claim is supported by logical reasoning without the need for external references.", "helpfulness_rationale": "The review point identifies a limitation of the approach, which is not inherently helpful without further guidance on how to address it. It highlights a potential drawback but doesn't offer concrete suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states they were confused about whether the paper targets singletoken or multitoken cloze queries and only understood this after reading the conclusion. This implies an implicit request for clarification. While the information is present in the paper, the reviewer couldn't easily access it, making the action implicit and vague.", "grounding_specificity_rationale": "The reviewer's comment does not specify which part of the paper they are confused about. They broadly state they were confused about the paper's scope (singletoken vs. multitoken). They do not pinpoint a specific section, table, figure, or unique element of the paper as being unclear.", "verifiability_rationale": "The reviewer states they did not see a clear clarification until reading the conclusion. This is a claim that can be somewhat verified by reading the conclusion. The reviewer's statement provides a basis for understanding their confusion, but it lacks specific details about *where* the lack of clarity was or *what* was unclear.", "helpfulness_rationale": "The reviewer explicitly states they were confused and only understood the paper's scope after reading the conclusion. This indicates the information was missing and would have been helpful. The reviewer's confusion highlights a lack of immediate clarity in the paper."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a problem ('It is unclear what the major contributions of the paper are') but does not explicitly state the action the authors should take to address it. While the suggestion ('Analyzing previous work does not constitute as a contribution') is implicit, the authors are left to interpret what needs to be done. The action is not concretely defined, leaving the authors without a clear starting point for improvement.", "grounding_specificity_rationale": "The review point discusses the 'major contributions of the paper' generally. It does not specify which section, table, figure, or unique element of the paper is being referred to. The reviewer is not pointing to a specific location within the document, making the grounding of the issue unclear.", "verifiability_rationale": "The review point does not contain a claim in the defined sense. It is a statement of observation ('It is unclear...') and a critique of a common practice ('Analyzing previous work does not constitute as a contribution'). There is no assertion that something is wrong, needs verification, or requires justification.", "helpfulness_rationale": "The review point raises a valid concern about the lack of clarity regarding the paper's major contributions. This is a fundamental aspect of academic writing and can hinder the review process. However, the point does not offer specific, actionable suggestions for how the authors should identify these contributions. While it highlights a problem, it doesn't provide a clear path towards resolution, making it 3 but lacking in constructive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests a concrete change (vector representation) based on a specific example (multiple attributes). This is actionable.", "grounding_specificity_rationale": "The reviewer refers to a specific concept ('protected feature A') and provides context ('A represents multiple attributes'), making it clear what they are suggesting. However, they don't explicitly point to a specific section or table.", "verifiability_rationale": "The review point is a question prompting a change, not a statement of a problem or a claim about the current state of affairs.", "helpfulness_rationale": "The suggestion to extend the feature to a vector form is a concrete and actionable step that is likely to be beneficial for the author looking to enhance their representation. It provides a specific goal for implementation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states the similarity between two methods ($kNNECD$ and $kNNMT$) and the implication for the technical contribution. This indicates an action (identifying a potential weakness). However, the action is vague as it doesn't specify how this similarity impacts the contribution.", "grounding_specificity_rationale": "The reviewer mentions specific method names ($kNNECD$ and $kNNMT$), indicating a weak grounding as the relevance to the paper isn't explicitly stated.", "verifiability_rationale": "The reviewer makes a claim about the limited contribution and provides a reason based on the similarity of two methods. However, the reasoning lacks specific evidence or citations, making it only 2.", "helpfulness_rationale": "The review points out a potential limitation in the technical contribution and suggests considering similar methods. This is a helpful but somewhat general suggestion."}
{"actionability_label": "2", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The review point suggests *what* would be helpful (an example/figure) but doesn't explicitly state *how* to create or implement it. This leaning towards 'implicit' is key.", "grounding_specificity_rationale": "The review mentions 'uniform shattering' without specifying *which* definition or context it's referring to. There's no mention of a specific section, table, or unique aspect of the paper.", "verifiability_rationale": "The review states 'an example and perhaps a figure' would be *helpful*. This is a statement of opinion or judgment about the clarity of the explanation. It's a claim that the current explanation is lacking. However, the reviewer offers *suggestion* as the solution but doesn't provide *evidence* or *reasoning* for why the current explanation is unhelpful or unclear.", "helpfulness_rationale": "The review identifies a specific area of confusion ('the definition of uniform shattering') and suggests a potential solution ('an example and perhaps a figure'). While it lacks the explicit action and supporting evidence, it does point to a concrete area for improvement."}
{"actionability_label": "High", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states their belief about the novelty of the method, indicating a clear action the authors should take. The mention of 'selftraining methods in semisupervised learning' suggests they understand the connection, though the exact nature might need clarification.", "grounding_specificity_rationale": "The reviewer attempts to ground their claim by mentioning 'selftraining methods in semisupervised learning,' which is a specific area of related work. However, they do not specify which part of the paper or method they are referring to, making the grounding somewhat weak. The specificity is in the *area* of related work, not a specific detail within the paper.", "verifiability_rationale": "The reviewer makes a claim about the method's novelty but does not provide any evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up their statement. The claim is presented without any verification.", "helpfulness_rationale": "The reviewer's comment is primarily a statement of opinion about the novelty of the method. While it might prompt the authors to consider related work, it does not directly identify specific weaknesses in the paper or provide concrete suggestions for improvement. The feedback is more of a critique than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point states 'Though the formulation or definition in this manu. is somewhat trivial' and 'its highlight lies in optimization and theoretical property analysis'. While the reviewer identifies a characteristic of the formulation/definition, they do not explicitly state what needs to be done about it. The reviewer's statement is more of an observation or critique rather than a direct instruction for the author. Therefore, it lacks the explicit and concrete nature required for high actionability. It points out a potential issue but doesn't tell the author how to address it.", "grounding_specificity_rationale": "The review point refers to 'the formulation or definition in this manu.' which is a very general reference. The reviewer does not specify which particular formulation or definition they are referring to, nor does they pinpoint the exact location within the manuscript. Therefore, the reviewer cannot confidently identify the specific part of the paper being addressed, making the grounding weak. Additionally, the reviewer does not specify what is 'somewhat trivial' about the formulation/definition, further lacking specificity.", "verifiability_rationale": "The review point states 'Though the formulation or definition in this manu. is somewhat trivial' and 'its highlight lies in optimization and theoretical property analysis'. This is a statement of opinion or judgment about the nature of the formulation/definition. While the reviewer identifies a characteristic, they do not present a claim that requires verification using logical reasoning, common knowledge, or external references. The statement is more of an observation than a claim that needs to be supported.", "helpfulness_rationale": "The review point expresses a negative opinion about the 'triviality' of a formulation/definition and suggests focusing on 'optimization and theoretical property analysis'. While it identifies a potential weakness, it does not offer specific, actionable steps or suggestions on how to make the formulation/definition more practical or how to improve the manuscript based on this assessment. The reviewer highlights a potential issue but does not provide concrete guidance for the author."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a problem (lack of understanding) and highlights a specific issue (the dominance of the paraphrase similarity view). While they don't explicitly state what needs to be done, they identify a clear area for improvement. The lack of concrete suggestions makes it 3 but not fully explicit.", "grounding_specificity_rationale": "The reviewer mentions 'multiview clustering approach' and 'other views' which provides some grounding. However, they don't explicitly identify the specific section, table, or unique aspect of the paper where these views are discussed. The single empirical example of clustering 'slip' paraphrases is a specific instance, but it doesn't pinpoint the exact location of the discussion. The lack of a detailed analysis about the differences between views further reduces grounding specificity.", "verifiability_rationale": "The reviewer states a factual observation: 'almost all across the board, the paraphrase similarity view does significantly better than other views and their combination.' While this is a verifiable statement, the reviewer doesn't provide any logical reasoning, external references, or examples to support why this observation is a problem or what we should learn from it. The lack of justification makes it 3 but not 5.", "helpfulness_rationale": "The reviewer clearly identifies a gap in understanding and directly suggests a need for 'further analysis' about the different views. They highlight the lack of insights into the usefulness of other views despite the superior performance of the paraphrase similarity view. This directly addresses a need for improvement and provides a clear direction for the authors to focus. The reviewer's desire for a more detailed analysis makes this comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the problem ('it sounds unreasonable...') and provides a clear action ('provides detailed...'). The action is also concrete, as it directly points to the need for detailed experimental results.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'model size' and 'performance' and connects it to a specific paper ('Ni et al.'). The reviewer also refers to 'Wikipedia experiments' to provide context for the discrepancy.", "verifiability_rationale": "The reviewer makes a claim ('it sounds unreasonable...') and asks for verification ('provides detailed...'). While not directly providing a justification, the request itself indicates a desire for evidence to address the potential issue.", "helpfulness_rationale": "The reviewer directly addresses a potential issue the authors might face (confusion about model scaling) and provides a clear direction for them to seek more information. This is likely to be 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests *related experiments* that the information axis tool can help with. This indicates an intention to explore further applications of the tool. While this points towards a potential area for improvement, it doesn't explicitly state what needs to be done or how to implement it. The reviewer doesn't provide concrete steps or actions, making it partially actionable but not fully explicit or detailed.", "grounding_specificity_rationale": "The reviewer explicitly refers to the 'conclusion' of the paper when expressing their curiosity about related experiments. This demonstrates a clear identification of the specific part of the paper being addressed. Furthermore, the suggestion to 'see some related experiments' is a specific suggestion within that section, indicating a clear specification of what needs to be improved.", "verifiability_rationale": "The reviewer states their curiosity about 'related experiments' that the information axis tool can help with. This is a statement of a desire or suggestion, not a claim that needs to be verified or supported by evidence. There is no assertion of a deficiency or a requirement that needs justification.", "helpfulness_rationale": "The reviewer's comment primarily focuses on expressing a desire for *related experiments* rather than providing direct feedback or suggestions on how to improve the current draft. While it points to a potential area for future work, it doesn't offer immediate actionable steps or insights on how to address any specific weaknesses in the current work. The suggestion is more about guiding future research directions than providing immediate actionable feedback on the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the question but does not provide a concrete action or suggestion for the authors to take based on this information. They are asking a question, not recommending a specific improvement.", "grounding_specificity_rationale": "The reviewer mentions 'multilingual pretraining setups' and 'Greek', indicating a weak grounding as they are not precisely identifying a specific section, table, figure, or unique aspect of the paper. The grounding is implicit rather than explicit.", "verifiability_rationale": "The reviewer states a possibility ('I\u2019d be interested to know if...') which can be considered a claim. However, they do not provide any evidence, reasoning, or references to support this claim, making it 1.", "helpfulness_rationale": "The reviewer's point is relevant to the authors as it raises a potential issue with multilingual models and a specific language. However, they do not provide any concrete suggestions or guidance on how to address this issue or improve the authors' draft. The point is more of a question seeking information rather than a direct suggestion for change."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The action is implied but not explicitly stated. The action is also vague. It's difficult to determine what the reviewer is suggesting as an improvement.", "grounding_specificity_rationale": "The grounding is weak as the authors cannot confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part  the clarity of the sentence. The specificity is low as it doesn't specify *how* the evaluation was done or *what* was unclear.", "verifiability_rationale": "The claim extraction is 'It would be difficult for readers to understand and evaluate' which is a valid claim. The verifiability verification is 'X' as there is no external evidence or logical reasoning provided to support this claim. It's an observation, not a claim that requires verification.", "helpfulness_rationale": "The reviewer is pointing out a potential issue with the writing clarity. This is a valid concern for the authors. However, the suggestion to 'manually observed' is very general and doesn't offer concrete advice on how to improve the clarity. It's a valid *complaint*, but not a very specific *solution*."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a concrete action: 'Please reorganize the proofs'. It also provides a specific area of concern: 'make the logic clean and easier to follow'. This directly points to a actionable improvement for the authors.", "grounding_specificity_rationale": "The review point explicitly mentions 'proofs' in general but then narrows the focus to 'Lemma 3' and the polynomial function. This demonstrates a clear grounding of the issue to a specific part of the paper, making it easy for the authors to identify the relevant section.", "verifiability_rationale": "The review point raises a valid concern about the generality of the polynomial function in Lemma 3, asking if the result holds for 'any polynomial function'. This requires verification and justification to confirm the claim's validity for all cases.", "helpfulness_rationale": "The review point provides clear and actionable suggestions for improving the organization and clarity of the proofs. Specifically, the reviewer suggests 'reorganize the proofs' and implies a need for 'cleaner logic', both of which are helpful for the authors. The question about Lemma 3 also provides a concrete direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review points out a lack of realworld experiments and suggests conducting them. This is an implied action. The authors are inferred to need to add realworld datasets and potentially adjust their experimental setup. While the action is clear, the specifics of which realworld datasets to use are not provided, making it partially actionable.", "grounding_specificity_rationale": "The review refers to 'this paper' and the 'outofdistribution setting.' While it identifies the general area of concern, it doesn't pinpoint a specific section, table, or figure within the paper. The suggestion to use 'realworld datasets' is general and doesn't specify a particular element within the paper being addressed, making the grounding weak.", "verifiability_rationale": "The review states that conducting realworld experiments would be better for validating the 'realistic scenario' claim. This is a clear statement or suggestion. The support for this claim is the critique of synthetic datasets in the context of the paper's stated goal, making it a verifiable claim, albeit with implicit justification.", "helpfulness_rationale": "The suggestion to use realworld datasets is directly relevant to the paper's claim of addressing a 'realistic scenario.' It provides a clear direction for improvement. While it doesn't specify which datasets, the general suggestion is valuable and directly addresses a potential limitation. Therefore, it is 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review points out a missing element (important references) and suggests an action (cite and discuss). While the action is stated, it lacks specific details on *which* references are important and *how* they should be discussed, making it somewhat vague. However, the reviewer does identify an actionable step, which is to cite and discuss the missing references.", "grounding_specificity_rationale": "The review refers to 'important references for domain adaptation' without specifying which part of the paper these references relate to or what specific issues they address. The reviewer doesn't point to a specific section, table, figure, or unique element of the paper. The mention of 'important' is general and doesn't pinpoint the exact nature of the missing information.", "verifiability_rationale": "The review states 'This paper lacks some very important references for domain adaptation' which is a claim. However, the suggestion to 'cite and discuss' does not provide sufficient evidence or justification to verify this claim. The reviewer doesn't provide specific examples of why these references are important or how they relate to the paper's content. The suggestion is a direction for improvement but lacks the necessary supporting evidence to be considered 5.", "helpfulness_rationale": "The review identifies a significant weakness in the paper (lack of important references for domain adaptation) and provides a clear suggestion for improvement (cite and discuss). This directly addresses a potential issue and offers a concrete action the authors can take. While the suggestion lacks specific details, it is a clear and actionable point for the authors to consider. The reviewer's feedback is directly related to a potential deficiency and offers a direct path towards improvement, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a suspicion ('suspicious') and provides a potential explanation ('hyperparameter tuning', 'suspiciously large distance'). While the exact next best model isn't specified, the *concept* of a suspiciously large distance and the potential link to hyperparameter tuning are clear. The reviewer is implicitly asking the authors to investigate this further.", "grounding_specificity_rationale": "The reviewer refers to 'hyperparameter tuning' generally and 'the distance to the next best model' without specifying which model or how the distance was calculated. While the reviewer identifies a potential issue, the *specifics* of the hyperparameter tuning and the *exact* model are missing, making it difficult for the authors to pinpoint the exact area of concern.", "verifiability_rationale": "The reviewer presents a claim ('suspicious') and offers a potential explanation based on the 'lucky' outcome and the 'suspiciously large distance' to the next best model. The reviewer draws on general understanding of hyperparameter tuning and the potential for a large performance gap to indicate an issue. While specific references are not provided, the reasoning is based on logical connections between model performance, hyperparameter space, and potential overfitting or underfitting.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the SCNN's performance on domain pricing and suggests investigating hyperparameter tuning. This is a relevant and actionable suggestion for the authors. The reviewer points out a specific area where the model might be struggling and proposes a concrete direction for improvement, even if the *exact* next best model isn't specified."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state what needs to be improved. While it implies a need for clarification, the specific actions or modifications are not directly identified. The reviewer points out the lack of clarity but doesn't specify *how* to improve the draft based on this feedback.", "grounding_specificity_rationale": "The reviewer mentions 'the experimental setup,' 'corpora,' and 'datasets,' which are specific parts of the paper. However, they do not identify a *specific* section, table, figure, or unique element within these areas that is problematic. The grounding is present, but it is not fully precise.", "verifiability_rationale": "The review point identifies a problem ('some aspects of the experimental setup were unclear or poorly motivated') but does not provide any evidence, reasoning, or references to support this claim. It lacks a clear justification for why these aspects are problematic.", "helpfulness_rationale": "The review points out potential issues in the experimental setup, which could be helpful for the authors to identify areas for improvement. However, it lacks specific details about what is unclear or poorly motivated. The feedback is general and does not provide concrete suggestions for action. Therefore, it is not strongly prescriptive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly asks for the size of the hourglass modules, which is a direct and concrete action the authors should take. The phrasing 'how big each hourglass module is' directly identifies the missing information and how to find it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'hourglass modules' and asks about their 'size (in terms of depth or number of parameters)'. This directly and accurately identifies the specific part of the paper being addressed, making the grounding 5.", "verifiability_rationale": "The reviewer is making a judgment about what information is missing from the paper. While there isn't a direct citation, it's a logical deduction based on the information provided (the model has 4 hourglass modules, but no further detail on their size). This makes the claim 3 through logical reasoning.", "helpfulness_rationale": "The review point is a direct question about a crucial detail that is missing from the paper. It clearly identifies a gap in the authors' understanding and provides a specific direction for them to seek the missing information. This type of feedback is 5 for improving the clarity and completeness of the paper."}
{"actionability_label": "4", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the paper's metric learning theory doesn't give better results than existing generalization theory and that the metric perspective doesn't seem to work. While the implications are clear, the reviewer doesn't specify *how* these issues should be addressed or what concrete changes are needed. The reviewer identifies the problem but lacks specific guidance on how to improve the metric learning aspect.", "grounding_specificity_rationale": "The reviewer mentions 'the part of metric learning' but doesn't specify which section, table, figure, or unique aspect of the paper this refers to. While the general area is implied, the specific part isn't clearly identified, making the grounding weak. The claim that the metric perspective doesn't work is also not specific to a particular section or detail.", "verifiability_rationale": "The reviewer makes claims about the paper's theoretical contribution, stating that it doesn't give better results and that the metric perspective doesn't seem to work. However, these claims are not supported by any evidence or logical reasoning within the review point. There is no justification provided for why these claims are true or what evidence would support them.", "helpfulness_rationale": "The reviewer identifies a potential weakness in the paper's theoretical contribution (lack of better results in metric learning) and suggests focusing on the metric perspective. While the reviewer points out a problem, they don't offer specific, actionable improvements or suggestions to address it. The feedback is a critique without concrete solutions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the potential for confusion and suggests a specific action: 'clarify the distinction'. This is a clear and direct indication of an actionable suggestion.", "grounding_specificity_rationale": "The reviewer uses the exact same notation ('r') to refer to two different concepts, indicating a clear identification of the specific part of the paper being addressed. They also specify the nature of the confusion (dual use of 'r'). This demonstrates full grounding and specificity.", "verifiability_rationale": "The reviewer claims that using 'r' for two different things is 'confusing'. While there's no direct evidence *within this review point* to verify this claim, the suggestion to 'clarify the distinction' implies a belief in the lack of clarity. The reviewer provides a specific example ('r' for risk and primal risk) to support their claim, making it 3.", "helpfulness_rationale": "The reviewer provides a specific and actionable suggestion: 'clarify the distinction'. This is a clear and direct piece of feedback that directly addresses the potential confusion, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The comment explicitly states a potential issue with the test example and suggests investigating it using a specific method (corpus residual value). This constitutes an explicit action. The method is also concrete, as it specifies the type of analysis to perform.", "grounding_specificity_rationale": "The comment mentions 'the patient of Figure 8' which attempts to identify a specific part of the paper. However, it does not explicitly state the section, table, or unique aspect of the paper being addressed. The comment clearly specifies the issue (different patient population and the potential use of the American corpus) and the method (corpus residual analysis).", "verifiability_rationale": "The comment contains a suggestion (a claim) about a potential issue and proposes a method (corpus residual value) to investigate it. This claim is 3 as it suggests a potential problem and a method to investigate it, but it doesn't provide a definitive answer or extensive justification.", "helpfulness_rationale": "The comment suggests a potential problem with the test example and proposes a method (corpus residual analysis) to investigate it. This is a helpful suggestion as it points towards a potential flaw in the analysis and provides a direction for further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment suggests using a different dataset (WebQuestions) instead of the current one (WebQuestionsSP). While this can be considered an implicit suggestion to improve clarity or facilitate comparison, it doesn't explicitly state an action or provide concrete steps on how to implement this change. The action is implied but not directly stated.", "grounding_specificity_rationale": "The comment states 'The authors use WebQuestionsSP as the testbed. Why not using the most popular WebQuestions (Berant et al., 2013) benchmark set?'. This directly identifies the specific part of the paper being addressed (the choice of dataset) and explains *why* a different dataset might be beneficial. The grounding is explicit as it directly refers to the dataset used. The specificity is also high as it clearly states the suggestion and its potential advantage.", "verifiability_rationale": "The comment is a question, not a statement of a claim. Therefore, it doesn't contain a claim that needs to be verified. Based on the provided definitions, a 'X' (X) would be appropriate.", "helpfulness_rationale": "The comment suggests using a different dataset, which could be helpful for improving clarity, facilitating comparison with other work, or aligning with more common practices. While it doesn't provide a strong justification for the current dataset's choice, it offers a concrete direction for the authors to consider. The suggestion is actionable in the sense that it points to a specific change they could make."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a lack of clarity regarding the desirability of sparsity but does not explicitly identify an action or improvement to be made. The comment is about questioning the motivation, not suggesting a concrete change.", "grounding_specificity_rationale": "The reviewer makes a general comment about the concept of sparsity without pointing to a specific section, table, figure, or unique aspect of the paper. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer makes a claim that sparsity is desirable and that it's not obvious. While the claim is present, the justification is lacking. There's no logical reasoning, common knowledge, or external references provided to support the claim. The verification methods are not met.", "helpfulness_rationale": "The reviewer raises a valid concern about the motivation for sparsity and asks for demonstration. This prompts the authors to think about their design choices and provides a direction for further investigation. While not a direct solution, it is a valuable prompt and therefore 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem 'Unclear model design' and provides concrete suggestions for improvement: 'provide a plot of model illustration, pseudocode table, or code repository'. These suggestions are direct actions the authors should take to address the identified issue.", "grounding_specificity_rationale": "The reviewer mentions 'model architecture and learning details' and specifically names 'Neurochaos Learning'. While they don't give the exact section number, they clearly identify the specific part of the paper being addressed.", "verifiability_rationale": "The review point makes a judgment about the paper: 'model architecture and learning details are fragmented or missing' and 'Neurochaos Learning is not a wellknown method'. While it doesn't provide specific examples of the missing information, it clearly identifies an area that requires further clarification and suggests potential solutions, which can be considered as implicit evidence for verifiability.", "helpfulness_rationale": "The review point is 5 because it directly addresses a clear weakness ('Unclear model design') and offers concrete, actionable steps for improvement ('provide a plot, pseudocode, or code repository'). These suggestions are directly aimed at helping the authors understand and implement changes to their model."}
{"actionability_label": "High", "grounding_specificity_label": "5", "verifiability_label": "High", "helpfulness_label": "High", "actionability_rationale": "The review point explicitly identifies a limitation in the paper's discussion of applying DIMES to the Traveling Salesman Problem (TSP), specifically the generalization gap between DIMES's training on largescale problems and its application to specific TSP instances. The reviewer suggests a concrete action: to clarify this in the paper and to include a comparison with other methods on TSP100 with and without metalearning. This is an explicit action that the authors can directly address. The suggestions are also concrete, providing a clear direction for improvement.", "grounding_specificity_rationale": "The review point explicitly mentions 'DIMES' and 'TSP instances' as the specific parts of the paper being addressed. This is a clear and precise identification of the relevant section and problem. The reviewer is not making an educated guess; they are directly referring to the method and the problem at hand. Therefore, the grounding is fully grounded.", "verifiability_rationale": "The review point contains a claim: that the paper's discussion of DIMES' generalization to TSP instances is lacking and that the suggested improvements (clarifying the gap and conducting a metalearning comparison) are valuable. The suggestions are specific and actionable. The claim is supported by logical reasoning (identifying a limitation) and common knowledge (the importance of addressing generalization gaps). The reviewer provides concrete examples of what constitutes a valuable improvement. Therefore, the claim is 5.", "helpfulness_rationale": "The review point is 5 because it directly points out a specific area where the paper can be improved. The suggestions are concrete and actionable, providing the authors with a clear direction for future work. The reviewer is not just criticizing; they are offering specific and valuable insights that can enhance the paper's contribution. The suggestions are directly relevant to the paper's content and address a clear need for more specific experimental evaluations on TSP instances."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential flaw in the paper's interpretation of its dataset analysis. While the initial statement is somewhat vague ('This depends on the method/features used for answer detection'), the reviewer immediately suggests a concrete action: 'Apply this feature analysis to reevaluate the relationship.' This suggests a clear understanding of how to address the identified issue.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'dataset analysis suggested that the readability of RC datasets does not directly affect the question difficulty.' This is a clear identification of the specific part of the paper being addressed, indicating strong grounding. Furthermore, the reviewer provides a specific example of a feature ('POS/dependency parse features') that could explain this observation, adding to the specificity of the grounding.", "verifiability_rationale": "The reviewer makes a claim: 'This depends on the method/features used for answer detection.' However, they do not provide any evidence or references to support this claim. While the suggestion to reevaluate with specific features is a step towards verification, the lack of a concrete justification or citation makes the claim 1 at this point.", "helpfulness_rationale": "The reviewer's point is helpful in that it highlights a potential factor that could influence the authors' results and suggests a direction for further investigation. By pointing out the dependence on the method/features, the reviewer is prompting the authors to consider alternative explanations for their findings. While it doesn't directly provide a solution, it encourages a more thorough analysis and is therefore 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The question is framed as a direct inquiry about the meaningfulness of the learned space, which can be interpreted as an implicit request for the authors to consider how to determine this meaningfulness. While not explicitly stating an action, it encourages them to think about the implications and potential methods. Therefore, it can be considered 3 as it prompts a consideration of a relevant aspect.", "grounding_specificity_rationale": "The question is about the general interpretability of the learned space and does not specifically target a particular part of the paper or a specific function. Therefore, it is 1 in a specific section or element. The question is about the *meaning* of the space, not a specific *part* of it.", "verifiability_rationale": "The review point explicitly states a claim: 'Do you have any evidence that the geometry of the space you end with is meaningful. E.g. does \"looking\"  \"look\" + \"walk\" = \"walking\"?' The inclusion of the example 'e.g. does \"looking\"  \"look\" + \"walk\" = \"walking\"?' provides a specific reference point and a potential method for verification, making the claim verifiable.", "helpfulness_rationale": "The review point raises a valid concern about the interpretability of the learned space and suggests a potential method for investigation. However, it does not provide a concrete solution or a definitive answer. It encourages further analysis and consideration, which can be helpful for exploration but lacks immediate actionable steps for the authors. Therefore, it is 3 in prompting further thought but not in providing immediate guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly mentions an action regarding space allocation between memory networks and the forward model. However, the general comment about writing quality is implicit, lacking a direct action.", "grounding_specificity_rationale": "The review point explicitly names specific sections or concepts (basic memory networks, forward model) and suggests concrete improvements in related work by naming specific areas (reinforcement learning tasks). This indicates strong grounding and specificity.", "verifiability_rationale": "The review point makes claims about writing quality, space allocation, and related work. While not explicitly supported by citations in this review point, the suggestions themselves offer a basis for improvement, making it 3.", "helpfulness_rationale": "The review point provides specific suggestions for improvement, directly addressing identified weaknesses and offering concrete actions. This makes it 5 for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point asks a question about the nature of interactions in a simulation, which doesn't directly instruct the authors on what to do or how to improve their draft. While it points to a potential area for clarification, it doesn't provide a specific action to take.", "grounding_specificity_rationale": "The review point explicitly mentions 'physical interaction' and asks about its presence in a 'simulation'. This directly identifies the specific aspect of the paper being addressed, making it fully grounded. It also specifies the type of interaction being considered, making it specific.", "verifiability_rationale": "The review point is a question, not a claim that requires verification. It doesn't present a statement that needs to be supported by evidence. Therefore, it doesn't have verifiability in the sense of supporting a claim.", "helpfulness_rationale": "The review point directly addresses a potential point of confusion for the authors by asking about the nature of physical interactions in their simulation. This is a clear and actionable question that encourages the authors to clarify a specific aspect of their work, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies two specific areas for improvement: the lack of categorical features in most datasets and the omission of onehot encoding for a specific dataset. While these are valid points, the reviewer does not explicitly state how the authors should address these issues. They suggest 'identifying the missing categorical features' and 'suggesting onehot encoding,' but don't provide concrete steps on how to implement these suggestions or what specific changes are needed. Therefore, while the reviewer points out actionable areas, the lack of explicit instructions on how to act makes it partially actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'categorical features,' 'numerical features,' and 'onehot encoding' in relation to specific datasets. They clearly identify the *what* and the *which* dataset involved. While they also mention 'conclusions' and 'performance,' these are implicit consequences of the identified issues rather than direct, explicit mentions of the dataset content or handling. Therefore, the reviewer grounds the specific features and the handling of onehot encoding, making it 4 regarding the dataset.", "verifiability_rationale": "The reviewer states that the 'omission of categorical features and onehot encoding may affect conclusions' and that 'this omission may negatively affect performance for some models.' These are claims that could be supported by logical reasoning (e.g., categorical features are often important), common knowledge about data preprocessing, and potentially references to specific models known to be sensitive to feature types. The reviewer provides a clear justification for why these omissions are potentially problematic. Therefore, the reviewer makes a verifiable claim by linking the identified issues to potential negative outcomes.", "helpfulness_rationale": "The reviewer provides specific weaknesses (lack of categorical features, omission of onehot encoding) and suggests concrete improvements (identifying missing categorical features, suggesting onehot encoding). They also implicitly criticize the work for not being 'thorough' and not using a 'wide range' of datasets, which are expected qualities. By pointing out these specific issues and offering clear suggestions, the reviewer provides valuable feedback that the authors can directly use to improve their work. Therefore, the reviewer's feedback is highly specific and actionable, making it 5."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of pruning with large networks and distributed training regarding global top Q values and its impact on acceleration techniques like quantization and sparsification. This provides a clear action for the authors to consider and potentially address.", "grounding_specificity_rationale": "The reviewer mentions 'distributed settings' which grounds the comment to the context of the paper. Furthermore, they specify 'large networks,' 'global top Q values of the metric,' and 'average of gradients,' providing concrete details about the network and training process being referenced.", "verifiability_rationale": "The reviewer makes a claim that 'Pruning majorly works with large networks, which are usually trained in distributed settings, authors do not mention anything about potential necessity to find global top Q values of the metric over the average of gradients.' This claim can be verified by examining the paper's discussion on pruning and distributed training. While the reviewer doesn't provide a solution, they identify a gap in the paper's discussion regarding a specific metric and its calculation in a distributed setting.", "helpfulness_rationale": "The reviewer's point is directly aimed at helping the authors improve their work by highlighting a potential limitation of a common pruning technique in their specific context (distributed training). They identify a specific area where more information is needed and suggest a potential impact on acceleration techniques. This is a valuable piece of feedback that can guide the authors in their work."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests a potential issue with the subfigures in Figs 1 and 2. While this points to a specific area that needs attention, the review point itself is a question rather than a directive for improvement. Therefore, while there's an implicit suggestion for investigation, the reviewer doesn't explicitly state what action should be taken based on this observation. The lack of a specific 'how' makes it less actionable than a review that proposes a concrete change.", "grounding_specificity_rationale": "The reviewer mentions 'some of the subfigures in Figs 1 and 2' and suggests they might have been swapped. This indicates a level of grounding as the reviewer is identifying a specific part of the paper (subfigures in Figs 1 and 2) as potentially problematic. However, the reviewer does not specify *which* subfigures or *why* they are suspect. The grounding is present, but it's not fully specific.", "verifiability_rationale": "The reviewer's statement about the subfigures being potentially swapped is presented as a suspicion or a negative opinion. There is X or suggestion offered for improvement. The statement is purely evaluative and lacks any supporting evidence or reasoning. Therefore, it doesn't meet the criteria for verifiability, which requires a claim supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer points out a potential error in the subfigures of Figs 1 and 2. This is a valuable piece of feedback because it highlights a potential issue that could affect the interpretation of the results or the validity of the figures themselves. It provides a clear direction for the authors to investigate and potentially correct the figures. While it doesn't offer a solution, it's a concrete observation that can lead to further action."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the potential for increased false positives as a concern. While the action of identifying this concern is clear, the lack of specific details about *how* this might manifest or *why* it's a problem makes the action somewhat implicit. The reviewer suggests this should be discussed, indicating a desire for the authors to address this potential limitation.", "grounding_specificity_rationale": "The reviewer refers to 'dropout probe' and 'syntactic representations,' indicating a degree of grounding in specific aspects of the work. However, the concern about 'false positives' is presented generally, without specifying which aspects or types of false positives are being considered. This lack of specificity means the grounding, while present, is not fully precise.", "verifiability_rationale": "The reviewer makes a claim that 'I would think this should be a substantial part of the discussion.' This claim is presented without any supporting evidence or logical reasoning within the review point itself. There are no references to external knowledge or experimental results to back up this assertion.", "helpfulness_rationale": "The reviewer provides a balanced perspective, acknowledging the strengths of the dropout probe while raising a valid concern about false positives. This suggests the review is informative and prompts the authors to consider the limitations of their method. While the concern is not substantiated, the identification of a potential issue is valuable and contributes to a more comprehensive discussion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the regret bound for the minibatch method is cast to the appendix. This is an explicit action the reviewer believes the authors should have done. While the reviewer doesn't provide a specific section within the appendix, the claim to have located the information makes the action explicit. However, the reviewer also states they did not find the regret bound in the appendix, indicating a lack of clarity or completeness in the authors' presentation. The action is not fully concrete as the specific location within the appendix is not provided.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'supplementary' as the potential location for the regret bound. This indicates a clear attempt to identify the specific part of the paper being addressed, even if it's a broader category like 'supplementary'. The reviewer's subsequent statement that they 'didn\u2019t find the regret bound for the minibatch estimator in the supplementary' suggests that while they attempted to ground the comment, they could not precisely identify the referenced part. Therefore, the grounding is somewhat weak.", "verifiability_rationale": "The reviewer makes a claim that the regret bound is in the appendix. This is a claim that needs to be verified. The reviewer attempts to verify this claim by stating they did not find the regret bound in the supplementary. While the reviewer attempts to provide evidence, the lack of finding the bound within the appendix suggests that the claim is not fully supported by verifiable evidence. Therefore, the claim is 3.", "helpfulness_rationale": "The reviewer is asking a direct question to seek clarification on the location of the regret bound. This is a helpful feedback point as it points to a potential issue in the paper's organization or completeness. The reviewer is essentially asking the authors to improve the clarity of their paper by providing the missing information. While the request itself doesn't directly suggest an improvement to the content, it highlights a lack of clarity in the presentation, making it a helpful point for the authors to address."}
{"actionability_label": "5", "grounding_specificity_label": "Highly Grounded and Specific", "verifiability_label": "Not Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the lack of discussion and comparison of relevant exploration methods, providing a clear action for the authors to take. They identify the specific area of the paper that needs improvement and suggest a concrete direction for addressing it.", "grounding_specificity_rationale": "The reviewer names specific exploration methods (countbased, RND, ICM) and points out the lack of discussion and comparison in the paper. This demonstrates a strong grounding in the relevant literature and identifies a specific area lacking detail.", "verifiability_rationale": "While this point doesn't directly present a claim needing verification, it sets the stage for future feedback that could be verifiable. The reviewer points to a potential area for further, verifiable improvement by suggesting the paper should discuss and compare these methods.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper (lack of exploration method discussion) and suggests a concrete improvement. This feedback is actionable and guides the authors towards a valuable area for revision."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks questions about the model's capabilities (inference speed, ability to perform inference without labels) and requests clarification on a specific coefficient. These are direct actions the authors can take to understand the model better. The questions are clear and identify specific areas of interest.", "grounding_specificity_rationale": "The reviewer asks about the model's inference capabilities generally, without specifying which part of the paper or model architecture they are referring to. While they mention 'line 307', they don't provide the context or explain what that line refers to in the paper or code. The critique about writing is also general and doesn't point to a specific section or issue.", "verifiability_rationale": "The reviewer asks about the coefficient of the p(L, E | X) term in line 307. While they mention the line number, they don't provide the code or the surrounding text to verify the coefficient's value. The critique about hyperparameters and ablation studies is also a general statement about the experimental setup and reporting, lacking specific justification for the claims.", "helpfulness_rationale": "The review point raises several valid concerns about the model's limitations, technical details, and the experimental setup. The questions about inference and the coefficient are pertinent and could be helpful for the authors. However, the lack of specific grounding and the reliance on subjective assessments make it less immediately actionable for the authors. The writing critique is also subjective and doesn't provide concrete suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that 'the proposed compression performs worse than PQ' which is a direct action or suggestion. However, it does not specify exactly *how* it performs worse, leaving the authors with a general idea but lacking concrete details on the nature of the performance difference. Therefore, while it points to an area for improvement, the action is not fully actionable due to the lack of specific guidance on what needs to be changed or how the performance should be improved.", "grounding_specificity_rationale": "The review point refers to 'the proposed compression' and 'PQ' without explicitly naming the specific method implementations. While it identifies a weakness, it doesn't pinpoint the exact section, table, or figure where the performance difference manifests. Therefore, the grounding is weak as the authors still need to infer the specific parts being compared.", "verifiability_rationale": "The review point makes a claim that 'the proposed compression performs worse than PQ' and provides a reason ('when a small code length is allowed, which is the main weakness of this method, in view of a practical side'). While it offers a justification, it doesn't provide specific examples or external references to support the claim. The reasoning is present but lacks the depth and evidence expected for full verifiability.", "helpfulness_rationale": "The review point directly compares the proposed method to a known good alternative (PQ) under a specific condition. It highlights a potential weakness and suggests a direction for improvement. While it doesn't quantify the performance difference, it clearly identifies a problem and offers a solution path, making it 5 for the authors to consider and potentially implement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states an action: 'I was wondering whether there would be some interesting observations comparing them language/nationality.' This action is direct and clear.", "grounding_specificity_rationale": "The reviewer mentions 'language/nationality' and provides examples like 'Japanese, Chinese, English, Arabic, German... (~20 different types)'. This explicitly grounds the suggestion in a specific aspect of the paper and provides concrete examples.", "verifiability_rationale": "The reviewer makes a claim: 'Some analyses can be more detailed. For example, in \"language/nationality\", the data includes Japanese, Chinese, English, Arabic, German... (~20 different types). Biases towards different languages/nationalities are different. I was wondering whether there would be some interesting observations comparing them.' This claim requires further justification and exploration, but the suggestion itself is a basis for further investigation and thus provides a basis for verification.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'I was wondering whether there would be some interesting observations comparing them language/nationality.' This directly points to a potential area for improvement and is a valuable direction for further analysis."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point poses a question about the behavior of F^\u2020 regarding conservation properties, which can be interpreted as an implicit request for clarification. While not explicitly stating an action, it encourages the authors to investigate this specific aspect. The request for numerical illustrations also provides a concrete action for the authors to take. However, the action is somewhat implicit, making it less actionable than a direct instruction. The reviewer could have explicitly stated, 'Can you show how F^\u2020 affects conservation in Hamiltonian systems?' to be more actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'symplectic integrators' and 'Hamiltonian systems,' which are specific technical terms. This grounds the discussion in established numerical methods. The request for 'numerical illustrations' also makes the question concrete and actionable. The reviewer provides clear elements for the authors to understand the context and the type of analysis requested.", "verifiability_rationale": "The review point presents a question about a potential property of F^\u2020 (conservation). While it doesn't directly state a claim that something is true or false, it poses a valid question that could be investigated through literature review or experimentation. If the authors can find relevant literature on the conservation properties of similar learning methods, they could verify the behavior of F^\u2020. The question itself is a form of implicit verification by asking for evidence.", "helpfulness_rationale": "The review point raises a valid concern about the potential lack of conservation properties in F^\u2020, which is a relevant difference compared to traditional numerical methods. The question about how F^\u2020 behaves in this regard is a clear and relevant inquiry. The request for numerical illustrations provides a concrete way for the authors to investigate and demonstrate the conservation properties. The reviewer is directly addressing a potential limitation or area for improvement in the proposed method."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states actions or suggestions. It tells the authors what is wrong (extensiveness and distraction of footnotes) and how they should improve it (move to the main body). It also suggests moving important content and details to improve space, all of which are concrete actions the authors can take.", "grounding_specificity_rationale": "The review point explicitly mentions 'footnotes' and 'important content' without needing to infer their location or nature. The reviewer also suggests moving specific types of details (parameter settings) to a specific section (appendix), providing clear grounding. The reviewer also provides a location (e.g., L468) for the appendix, further grounding the suggestion.", "verifiability_rationale": "The review point makes a judgment about the current structure and presentation of the paper (footnotes being distracting, important content being in the appendix). It does not claim to be verifiable with external references or logical reasoning within the review itself. The reviewer's assessment is based on their own experience and observation.", "helpfulness_rationale": "The review point provides clear and actionable feedback on the paper's structure and presentation. It tells the authors *what* needs to be changed (footnote extensiveness, moving important content, moving details) and *where* it should be changed (main body, appendix). All suggestions are concrete and directly address issues identified by the reviewer."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the absence of a discussion on the fewshot demonstrations and suggests zeroshot generation as an alternative. While this points to a potential improvement, it does not offer explicit, actionable steps the authors *should* take *now* to address this. The criticism itself is a suggestion, not a directive.", "grounding_specificity_rationale": "The review point criticizes the 'set of fewshot demonstrations' and suggests a 'discussion about this.' It does not specify which section, table, or unique aspect of the paper this refers to. The criticism is general and lacks specific references to parts of the paper.", "verifiability_rationale": "The review point states a preference for a 'discussion about this' and suggests 'zeroshot generation results' as an alternative. While there's a stated preference and a suggestion, there's no explicit claim being *made* about the paper's current state or a specific problem being highlighted with supporting evidence. It's more of a suggestion than a critique requiring justification.", "helpfulness_rationale": "The review point suggests a 'discussion about the fewshot demonstrations' and proposes 'zeroshot generation results' as an alternative. While this points to a potential improvement and offers a concrete alternative, it doesn't provide explicit, actionable steps the authors *should* take *now* to address the lack of discussion. The suggestion is for improvement, not a directive for action."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a desired improvement ('it would be good to acknowledge some of the older works too') but does not explicitly state the action to be taken. While the intent is clear, the specific steps or method for acknowledging older works are not provided.", "grounding_specificity_rationale": "The review point mentions 'related works' generally, indicating a lack of specific identification of a particular part of the paper or a unique element within that section. The reference is broad and does not pinpoint a specific section, table, figure, or unique aspect of the 'related works' section.", "verifiability_rationale": "The review point itself is not a declarative statement of a claim. However, the implied claim is that the current 'related works' section lacks acknowledgment of older works. This claim could be considered 3 by pointing to the absence of such acknowledgements. However, it lacks specific examples or references to support this claim.", "helpfulness_rationale": "The review point suggests a specific area for improvement ('acknowledge some of the older works too') and provides a constructive suggestion. However, it does not provide specific details on how to achieve this improvement, making it 3 but lacking concrete actionability."}
{"actionability_label": "2", "grounding_specificity_label": "3: Somewhat Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The reviewer points out potential weaknesses related to time complexity and identifies specific components (itemoriented autoencoder, elementwise function, number of hidden units) as potential sources. While the reviewer implies these components might be problematic, they don't explicitly state what needs to be done about them. The action is somewhat implicit, as the reviewer is suggesting these aspects are worth considering, but lacks direct instructions on how to address them.", "grounding_specificity_rationale": "The reviewer mentions specific components of the method (itemoriented autoencoder, elementwise function, number of hidden units) as potential sources of high time complexity. However, the connection between these components and the high time complexity is implied rather than explicitly stated. The authors would need to infer the relevance of these components to the complexity issue.", "verifiability_rationale": "The reviewer states that the time complexity seems 'rather high' but does not provide any evidence, justification, or references to support this claim. There is X extraction, and the reasoning behind the concern is not logically derived or supported by external references.", "helpfulness_rationale": "The reviewer identifies potential weaknesses in the method (high time complexity) but does not offer any concrete suggestions or actionable steps for the authors to address these issues. The feedback is present but lacks practical guidance on how to improve the method."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a change to the figures, stating 'many of the figures would be more clear if they said pretrained solution encoders & solution decoders'. This indicates an implicit action: the reviewer suggests a specific change to improve the clarity of the figures. While the action itself isn't directly stated as 'improve clarity', the suggestion is clear and actionable. The reviewer proposes a concrete alternative to the current labeling of the autoencoders.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'pretrained solution encoders & solution decoders' when suggesting an improvement to the figures. This clearly identifies the specific aspect of the paper being addressed. The reviewer can accurately pinpoint the section, table, or unique aspect being discussed (in this case, the type of autoencoders used). This falls under the 'Full Grounding' category as the reviewer provides a literal mention of the specific element. The suggestion is also specific, detailing what the reviewer believes would improve the clarity of the figures.", "verifiability_rationale": "The reviewer's point is a suggestion for improvement based on their understanding of clarity in figures and the specific terminology used for autoencoders. While it doesn't present a claim requiring external evidence, it's a wellunderstood concept that clarity can be improved by using more precise terminology. This could be considered '3' as it's a deduction based on common sense and understanding of the field.", "helpfulness_rationale": "The review point directly suggests a concrete improvement to the figures by recommending the use of more specific terminology ('pretrained solution encoders & solution decoders') to enhance clarity. This is a clear and actionable suggestion that directly addresses a potential weakness in the figures. The reviewer provides a specific alternative, making it 5 for the authors to implement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out the absence of comparisons with specific NeRFbased methods and questions the relevance of the occlusion experiment. While the reviewer implies actions (including the comparisons and explaining the experiment's relevance), the actions are not explicitly stated or detailed. The lack of specificity makes the actionable nature of the review less clear.", "grounding_specificity_rationale": "The reviewer refers to 'NeRFbased methods' generally and 'the method' in a broad sense when discussing the occlusion experiment. There is no specific identification of a particular section, table, figure, or unique aspect of the paper that the reviewer is addressing. The references are vague and do not pinpoint the exact location of the issue.", "verifiability_rationale": "The reviewer states that the paper lacks comparison with specific methods and questions the relevance of the occlusion experiment. These statements act as claims that need to be supported. However, the reviewer does not provide any external references, logical reasoning, or examples to justify these claims. The statements are presented as observations or suggestions for improvement without sufficient backing.", "helpfulness_rationale": "The reviewer's comments highlight significant omissions and raise a question about a method's novelty. While the reviewer's suggestions are valid, the lack of context and justification makes the feedback less impactful. The authors are left wondering why these points are important and how they relate to their specific work. The feedback is presented as a list of issues without a clear connection to the authors' specific contributions or weaknesses."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer asks 'how the parts of sentences and documents are extracted?' and 'Do the rules of extraction have any effect on the experiment?'. While the reviewer doesn't explicitly state an action or a concrete method, they are asking for information on how a specific calculation (proportion) is performed. The lack of a stated method makes the action implicit. The reviewer is also asking for clarification on the *how*, which is a concrete action. The effect on the experiment is a request for justification, making it 3. The reviewer's desire for a more detailed analysis implies they believe the current information is lacking in actionability.", "grounding_specificity_rationale": "The reviewer asks 'how the parts of sentences and documents are extracted?' and 'Do the rules of extraction have any effect on the experiment?'. They are asking for a method to identify proportions, sentences, and documents. They are not explicitly stating which specific proportion, sentence, or document they are referring to. The request is about the *how* of extraction, not the specific instance. This indicates a lack of explicit identification, pointing towards 'Weakly Grounded'. The reviewer is asking about the *where* of the information, which aligns with the 'Weakly Grounded' category as they are not pinpointing a specific section or table. The request is about the method of extraction, not the specific content being extracted.", "verifiability_rationale": "The reviewer is asking for clarification on the *how* of extraction. There is no explicit claim being made. The reviewer is asking for information about a process, not making a judgment about its validity. The request is for clarification and understanding, not a claim that needs verification. Therefore, there is X extracted, making it 'X'. The request is for information that, while potentially verifiable, is not presented as a claim.", "helpfulness_rationale": "The reviewer explicitly states 'I hope to see a more detailed analysis.' This indicates a desire for more information, which implies the current level of detail is insufficient for helpfulness. The reviewer is asking for clarification on the *how* of extraction, which is a request for more actionable information. The lack of a stated claim makes it difficult to assess the helpfulness directly, but the desire for more detail suggests a need for actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point directly asks a question about the training procedure, specifically when the meta sampler is applied. While it doesn't explicitly state an action or provide details on how to implement it, it points to a potential area of ambiguity in the methodology. The reviewer is implicitly suggesting that clarifying this timing would improve understanding.", "grounding_specificity_rationale": "The review point refers to 'the meta sampler' and 'the training process' generally. While it doesn't pinpoint a specific section or table, the context strongly implies the methodology section. The reviewer is asking about a specific component within that broader context, indicating a level of grounding, but it's not as precise as identifying a specific table or figure.", "verifiability_rationale": "The review point is a question, not a declarative statement. Therefore, it doesn't contain a 'claim' in the sense defined for verifiability. However, it *asks* for information (when the meta sampler is applied), which implies an expectation of that information being present in the paper.", "helpfulness_rationale": "The review point is a valuable question that directly addresses a potential ambiguity in the methodology. By asking about the timing of the meta sampler application, the reviewer is prompting the authors to clarify a specific implementation detail. This is helpful because it can improve the clarity and reproducibility of the work."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the 'lack of related fairnessaware metrics like Equality odds (EO)' and suggests 'conduct more experiments on more datasets like COMPAS and Drug Comsumptionm'. While the reviewer identifies a deficiency, they don't explicitly state what the current 'vanilla metric' is or how the suggested metrics would improve it. The suggestions are present, but the connection to the existing work is not fully elaborated, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer states 'Authors use their own defined vanilla metric, and lack related fairnessaware metrics like Equality odds (EO)'. This criticism is general and doesn't specify which part of the paper is lacking these metrics or why. The reviewer doesn't point to a specific section or element of the paper being addressed. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer suggests 'conduct more experiments on more datasets like COMPAS and Drug Comsumptionm' and recommends 'please kindly follow this AAAI paper which authors have cited: Exacerbating Algorithmic Bias through Fairness Attacks'. While the suggestions are present, the reviewer doesn't provide a detailed explanation of *why* these experiments or the cited paper are relevant to the current work. The connection between the recommendation and the specific issues in the paper isn't fully established, making the verifiability somewhat lacking.", "helpfulness_rationale": "The reviewer clearly identifies the problems ('lack of related fairnessaware metrics') and offers suggestions ('use...fairnessaware metrics', 'conduct more experiments', 'cite this paper'). While the suggestions are present, they lack specific details about *how* to implement them or *why* they are particularly relevant to the paper at hand. The connection between the general recommendations and the specific context of the paper isn't fully clear, making the helpfulness somewhat limited."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a preference for considering baselines but does not provide a specific action or instruction on how to implement this preference. It is a statement of opinion rather than a direct command or guidance on what to do. Therefore, it lacks explicit and concrete actionability.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or methodology that would benefit from considering baselines. The suggestion is general and applies to the entire paper or the process of performance improvement. There is no mention of a unique element or section that requires attention in this regard. Thus, the grounding is weak as the relevant part is not clearly identified.", "verifiability_rationale": "The review point suggests considering baselines as a potential improvement to the validation process but does not provide any justification, reasoning, or references to support this suggestion. It is presented as a nicetohave rather than a claim that requires verification. Therefore, the claim, if any, is not wellsupported.", "helpfulness_rationale": "The review point suggests considering baselines as a potential improvement to the validation process. Performing additional experiments, especially with established methods like Rope and Alibi, is a standard and valuable practice in research. This suggestion directly contributes to the rigor and robustness of the paper's findings. It provides a concrete direction for the authors to take next steps in their research. Therefore, the review point offers valuable and actionable guidance."}
{"actionability_label": "4", "grounding_specificity_label": "Mostly Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the importance of the neighborhood size 'h' and its influence on the model's performance, which is an implicit action. However, it doesn't provide concrete details on how to determine the appropriate value of 'h' or how the model's performance varies with different values. The reviewer also points out the inconsistency in using different hyperparameter sets per dataset, which is an implicit action but lacks concrete guidance on how to address this issue. Therefore, while the reviewer identifies a valid gap in the paper, the action is not explicitly stated and lacks concrete details.", "grounding_specificity_rationale": "The review point explicitly mentions 'neighborhood size h' and its 'influence over the model's performance'. It also mentions 'different hyperparameter sets per dataset'. These are explicit statements that identify specific parts of the paper being addressed. The reviewer is also asking for 'intuitive knowledge of the value of h to use', which implies a desire to ground the discussion in practical application. Therefore, the grounding is explicit, and the parts being addressed are relatively clear.", "verifiability_rationale": "The review point explicitly states the importance of 'neighborhood size h' and its 'influence over the model's performance'. While it doesn't provide specific examples or references, the reviewer is making a general statement about a key parameter in the proposed strategy. The implications of this statement are that a consistent hyperparameter set should be used across datasets to improve the robustness of the method. This is a logical inference, but it lacks specific references or examples to support it. Therefore, the claim is somewhat justified but lacks key elements like examples or references.", "helpfulness_rationale": "The review point clearly identifies a missing element in the paper: the value of the neighborhood size 'h' and its influence on the model's performance. This is a crucial piece of information for readers to understand and potentially reproduce the work. The reviewer also points out the inconsistency in using different hyperparameter sets per dataset, which is a valid concern. Providing insights into how performance varies with a constant set of parameters and addressing the robustness of the method with respect to different neighborhoods would be highly beneficial for the authors. This information would directly improve the completeness and clarity of the paper. The reviewer's request is clear and directly addresses a gap in the current presentation. Therefore, the review point provides valuable information that would significantly improve the authors' understanding and the overall quality of the paper."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about the model's behavior with imperfect multimodal data. It doesn't explicitly state what needs to be done. Therefore, it's unlikely to be 5. It's more about understanding a phenomenon than providing a direct, actionable step.", "grounding_specificity_rationale": "The review point refers to \"multimodal data,\" \"higherorder interactions,\" \"polynomial tensors,\" and asks about the impact of *imperfect* data. It doesn't explicitly pinpoint a specific part of the paper or model. The reviewer isn't specifying *which* model, *which* specific interaction, or *which* part of the tensor is being affected. Therefore, it's weakly grounded. It doesn't specify what needs to be addressed in this part either, making it also not specific.", "verifiability_rationale": "The review point contains a claim: \"Since the model builds higherorder interactions, does missing data at the input level lead to compounding effects that further affect the polynomial tensors being constructed, or is the model able to leverage additional modalities to help infer the missing ones?\" This is a question posed with an implicit expectation that the model will or won't be able to handle it. However, the question itself doesn't provide any evidence or justification for this claim. It's presented as a question for investigation, not a statement that has been proven or is widely accepted. Therefore, it's not verifiable.", "helpfulness_rationale": "The review point asks a question that, while relevant to understanding model behavior, doesn't directly provide actionable advice or insights for improving the reviewer's own draft. It's more of a question for the authors of the model paper. The reviewer isn't given any specific steps to take in their own paper based on this point. It doesn't offer a solution or a direction for their own research. Therefore, it's not 5 for the reviewer's current work."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests an analysis of the SST dataset, which implies an action (analyzing the dataset). However, the specifics of how to perform this analysis are not explicitly stated. The reviewer is implicitly suggesting an action, but lacks detail on how to apply it.", "grounding_specificity_rationale": "The reviewer refers to the 'SST dataset' generally, not a specific section, table, figure, or unique element. While the suggestion is clear about the dataset, the lack of a precise reference makes the grounding weak.", "verifiability_rationale": "The reviewer suggests an analysis and its potential benefits. This is a suggestion, not a claim that requires verification. There is no explicit claim being made or supported by evidence within the review point itself.", "helpfulness_rationale": "The reviewer's suggestion is related to understanding the dataset better, which could be helpful for the authors. However, it is not a direct critique or solution, and it does not provide specific guidance on how to implement the suggested analysis. It is more of a suggestion for further investigation rather than a direct improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of OOD benchmark testing and provides a specific action: testing the stability of OGEAug on OOD benchmarks like DrugOOD. This is a clear and actionable suggestion, directly addressing a potential weakness in the authors' work. The reviewer identifies a gap in their methodology and proposes a concrete next step.", "grounding_specificity_rationale": "The reviewer mentions 'OOD benchmarks such as DrugOOD' which grounds the suggestion in a specific dataset. However, they do not explicitly identify the specific part of the paper that needs improvement related to this suggestion. While the suggestion is somewhat specific (testing on a particular dataset), the connection to a specific section or table in the authors' paper is not clearly established. The suggestion is about testing on a dataset, not about a specific issue within a section.", "verifiability_rationale": "The reviewer makes a claim: 'Authors don\u2019t verify the stability of the OGEAug on OOD benchmarks such as DrugOOD.' However, the review point does not provide any evidence, justification, or reasoning to support this claim. The reviewer suggests using SPE for validation but does not explain why the authors are not already doing this. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the authors are failing to verify stability.", "helpfulness_rationale": "The review point directly addresses a potential weakness in the authors' work (lack of OOD benchmark testing) and provides a clear and actionable suggestion (testing on DrugOOD). This is immediately actionable for the authors and directly addresses a likely area of concern. The suggestion is specific and provides a concrete next step for the authors to take."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests alternative methods to SVD for dimensionality reduction, specifically mentioning freezing layers in BERT and parameterefficient methods like LoRA. While it implies the need to explore these methods, it doesn't explicitly state how to implement them or provide concrete steps for the authors to take. The suggestion is present, but the action is implicit.", "grounding_specificity_rationale": "The review point explicitly mentions 'freezing some layers of the model' and 'other parameterefficient methods such as LoRA' as potential alternatives to SVD. It also states the purpose of these suggestions: 'These methods are natural to think about and could provide a valuable basis for experimental comparison.' This clearly identifies the specific aspects of the paper being addressed and specifies what is being considered for improvement.", "verifiability_rationale": "The review point presents a suggestion and a reason for that suggestion. It doesn't make a claim that something is wrong with the original approach (SVD on BERT embeddings). Instead, it proposes alternative methods and states that these are 'natural to think about' and 'valuable for comparison.' While the reasoning is reasonable, it lacks external references or logical deduction to definitively verify the effectiveness or potential issues of these alternatives. Therefore, it's not 5, as it doesn't provide strong evidence to support the suggested improvements.", "helpfulness_rationale": "The review point directly suggests alternative methods for dimensionality reduction and explicitly states their potential value in providing a basis for experimental comparison. It encourages the authors to explore further, which is a constructive and helpful suggestion. While it doesn't provide specific implementation details, it identifies a relevant area for improvement and proposes concrete alternatives."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The action is explicitly stated as 'Expand the related work section' and 'Compare to the strong baselines that use the coordinates'. However, the reviewer does not specify how to expand the related work or which specific baselines to compare to, making the action potentially vague and less actionable.", "grounding_specificity_rationale": "The reviewer does not identify a specific part of the paper being addressed. The comment is a general suggestion about improving the related work section and comparing to baselines, without specifying which section, table, figure, or unique aspect of the paper is being referred to.", "verifiability_rationale": "The review point is a suggestion or recommendation, not a claim that requires verification. There is no assertion of what the related work *should* contain or *why* it should be compared to certain baselines. It's a request for improvement, not a statement of fact or opinion.", "helpfulness_rationale": "The review point directly suggests improving the related work section by comparing to specific baselines. This is a relevant and actionable suggestion for authors who want to better contextualize their work within existing literature."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests a change (training on multiple seeds) and identifies a problem (difficulty assessing significance). The suggestion is concrete, stating 'multiple seed experiments' and implying 'more robust evaluation'.", "grounding_specificity_rationale": "The review point refers to 'Single Seed Experiments' and 'performance differences' generally, without explicitly identifying a specific part of the paper being addressed. While it implies the problem with singleseed runs, it doesn't specify which section, table, or figure is affected. The suggestion 'multiple seed experiments' is general and lacks specific details about how to implement or analyze these experiments within the paper.", "verifiability_rationale": "The review point contains a claim: 'Multiple seed experiments would provide a more robust evaluation.' However, it does not provide any logical reasoning, common knowledge, or external references to support this claim within the review point itself. The suggestion is presented as a statement of opinion without evidence.", "helpfulness_rationale": "The review point identifies a potential limitation in the experimental setup ('Single Seed Experiments') and suggests a solution ('multiple seed experiments'). While the suggestion is broad and lacks specific implementation details, it directly addresses a potential weakness and offers a concrete direction for improvement. The reviewer clearly understands the issue and proposes a relevant fix."}
{"actionability_label": "4", "grounding_specificity_label": "3 and Grounded", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for a justification for a specific methodological choice (the use of VMF and truncated normal distributions) rather than directly asking for a calculation or application of a concept. While they are not explicitly asking for a formula or stepbystep explanation, they are asking *why* a particular choice was made, which is a key aspect of actionability. The reviewer is indicating a lack of clarity on this point, which is an action the authors would need to take to understand the methodology.", "grounding_specificity_rationale": "The reviewer is explicitly asking about the *motivation* behind using VMF and truncated normal distributions for the angle and magnitude of the target vector. They are specifying *which* aspect of the methodology they are questioning, indicating good grounding specificity. They are pointing to a specific part of the paper (the characterization of the angle and magnitude) and asking about the rationale behind a particular choice within that section.", "verifiability_rationale": "The reviewer is asking for a justification for a methodological choice. While the *answer* to their question isn't provided, the *request itself* is a form of evidence \u2013 the reviewer has identified a gap in the explanation. The lack of clarity on the motivation for using these specific distributions is a missing element of verifiability. The reviewer is indicating a need for further explanation to understand the methodology.", "helpfulness_rationale": "Understanding the motivation behind the choice of distributions is crucial for correctly interpreting and applying the model. The reviewer is asking a question that, if answered, would likely provide the authors with a significant improvement in their understanding of the methodology. This question directly impacts their ability to implement the model correctly. The reviewer is asking for a clarification that would directly benefit their understanding and application of the work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'As the current system captures the semantics through RNN based models' and 'So, it would be better to compare this system, which also captures semantics'. These statements directly identify an action: to compare the two systems. However, the action lacks specific details on *how* this comparison should be done. Therefore, while explicit, the action is vague and not fully concrete.", "grounding_specificity_rationale": "The review point mentions 'RNN based models' and 'semantics capture' but does not explicitly identify a specific part of the paper or system being discussed. The mention is general and lacks precision. Therefore, the comment is 1 at identifying a specific area of concern or improvement.", "verifiability_rationale": "The review point contains a claim: 'As the current system captures the semantics through RNN based models. So, it would be better to compare this system, which also captures semantics.' This is a statement of opinion or judgment. However, the support for this claim is weak. The suggestion to compare with Ref2 is a suggestion, not a verifiable claim with supporting evidence. The general idea of comparing systems is a common practice, but lacks specific justification for *why* this particular comparison is valuable. Therefore, the claim is somewhat supported but lacks robust evidence.", "helpfulness_rationale": "The review point suggests a comparison and a specific reference (Ref2). While this points towards a potential improvement, the suggestion is vague and lacks concrete details on *how* the comparison should be done or *what specific improvements* are anticipated. The suggestion is a general direction rather than a detailed, actionable improvement. Therefore, the feedback is 3 but lacks the detail to be fully actionable."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the issue: 'It is unclear why the model does not fully succeed in identifying the true sources in the triangle dataset.' This directly points to a problem the model is facing. While it doesn't provide specific details on *how* the model failed, it identifies a clear area of concern. The reviewer also suggests potential reasons ('Is one of the assumptions not satisfied? Are there learning difficulties?'), indicating an awareness of possible underlying issues. This makes it more than just a general comment about the model's performance.", "grounding_specificity_rationale": "The reviewer mentions 'the triangle dataset' and 'the model's failure' but doesn't specify *which* part of the model or the dataset is experiencing the issue. They offer possibilities like 'one of the assumptions not satisfied' or 'learning difficulties,' but these are general hypotheses, not specific instances of failure within a defined section or element of the paper. The grounding is present in identifying the dataset, but the specificity of the issue within that dataset is not clearly defined.", "verifiability_rationale": "The review point begins with 'It is unclear why the model does not fully succeed...' This statement presents a claim (the model's failure is unexplained) without providing any supporting evidence or justification. The reviewer then suggests potential reasons, but these are hypotheses rather than verifiable claims backed by data or references. There is no logical reasoning, common knowledge, or external references provided to support the claim of uncertainty.", "helpfulness_rationale": "The review point raises a relevant question about the reasons for the model's failure in the triangle dataset. However, it does not directly suggest a specific improvement or action the author should take. It prompts further investigation but doesn't provide concrete guidance on how to address the identified issue. The suggestions are more about potential causes than actionable steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the criticism of the metrics and the scenario where they wouldn't be applicable. The metrics (continual learning, loss after switch, recovery time after switch) are directly mentioned, and the characteristic of the datasets (lack of clear task boundaries) is also clearly identified. The action being criticized is the *use* of these metrics in such scenarios.", "grounding_specificity_rationale": "The reviewer attempts to ground the criticism by mentioning the specific metrics (continual learning, loss after switch, recovery time after switch) and the general characteristic of the datasets (lack of clear task boundaries). However, the grounding is more about the *general* appropriateness of the metrics rather than pinpointing a specific section or table in the paper being criticized. The reviewer doesn't explicitly state which part of the paper is being evaluated based on these metrics in the context of no task boundaries.", "verifiability_rationale": "The reviewer makes a claim that 'these metrics are not suitable for such scenarios' without providing immediate specific examples or references within the review point itself to support this claim. While the *implication* is that the metrics are unsuitable, the direct evidence for this claim within the review point is not strong enough to be definitively '4' or '5'. It leans towards '2' as the reviewer states the issue but doesn't fully elaborate on the reasons or provide supporting evidence within this specific point.", "helpfulness_rationale": "The reviewer clearly criticizes the metrics and explains *why* they are problematic in the context of datasets without clear task boundaries. The reviewer provides a direct criticism and a rationale for it. This suggests the review point is intended to be helpful to the authors by highlighting the limitations of the proposed evaluation framework in a specific context."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks a question about the information flow in the decoder, which is a direct action the reviewer is taking. However, the action is not very concrete; the reviewer doesn't immediately suggest a solution or modification. The reviewer identifies a potential misunderstanding or gap in the author's knowledge.", "grounding_specificity_rationale": "The reviewer is asking a question about a specific technical detail of the decoderdecoder model. While the question is specific about the mechanism, it doesn't directly identify a specific part of the paper that needs improvement. The reviewer is trying to understand *why* something is the case, not *where* the problem lies in the author's work. Therefore, the grounding is weak as the reviewer needs to infer the relevance.", "verifiability_rationale": "The review point is a question, not a statement that requires verification. Therefore, it doesn't fit the verifiability category.", "helpfulness_rationale": "The review point raises a valid question about the model's operation. While this can be helpful for the author to understand the underlying mechanism, it doesn't directly provide a concrete solution or actionable advice on how to improve their draft. The reviewer is pointing out a potential area of confusion or a missing piece of information in the author's understanding."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a potential confounding factor ('Given that induction heads and FV heads appear at different locations (layers) within the model') and proposes a controlled baseline ('there should perhaps be a controlled baseline that ablates heads at different locations in the model'). Both the identification of the issue and the proposed solution are direct and actionable.", "grounding_specificity_rationale": "The comment explicitly mentions 'head location' as the confounding factor and proposes ablating 'heads at different locations'. This clearly identifies the specific part of the model being referred to and the nature of the ablation, demonstrating strong grounding specificity.", "verifiability_rationale": "The comment proposes a 'controlled baseline' by ablating 'heads at different locations'. While it doesn't provide a specific example of how this baseline would be implemented or what results to expect, the *method* for creating a more controlled baseline is clearly stated and logically sound. The reasoning is that ablating heads at different locations would isolate the effect of head position, making the comparison between induction and FV heads more valid.", "helpfulness_rationale": "The review point is 5 as it directly identifies a potential flaw in the experimental design (the lack of a controlled baseline for head location) and provides a clear and actionable suggestion for improvement. It directly addresses a potential confounding factor that could affect the interpretation of the ablation results. The suggestion is specific and provides a clear path for the authors to refine their methodology."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly names the missing section ('A section on synonym identification is missing') and suggests its location ('under similarity measurement'). This is a clear and direct action that authors can readily follow. The suggestion to include 'synonym identification' is also concrete, indicating the specific type of information needed.", "grounding_specificity_rationale": "The comment is highly specific about the type of synonym identification ('likely related to similarity measurement') and the location where it should be placed ('within the 'similarity measurement\" section'). This precise identification helps authors understand exactly what is needed and where to add it.", "verifiability_rationale": "The comment identifies a gap in the paper's content (the missing section) but does not provide any evidence or justification for its existence. It does not claim that the section is incorrect or should be removed. The suggestion is based on observation rather than logical deduction or external references.", "helpfulness_rationale": "The comment is directly addressing a clear need for more information about synonym identification within the similarity measurement section. It tells the authors what is missing and where it should be located, which is a valuable piece of information for improving their draft. The suggestion is actionable and constructive."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states that an overview is needed, which is an explicit action. However, it does not specify what aspects of the workflow or model require this overview, making it vague and not fully actionable.", "grounding_specificity_rationale": "The comment refers to the 'workflow' and 'model' generally, without identifying a specific section, table, figure, or unique element of the paper. Therefore, it is 1 at all.", "verifiability_rationale": "The comment states that an overview is needed, which can be considered a claim. However, it does not provide any evidence or reasoning to support this claim, making it 1.", "helpfulness_rationale": "The comment suggests providing an 'overview' of the 'workflow' and 'model.' While this is a general suggestion that could be helpful, it lacks specific details about what kind of overview is needed, making it less helpful than a more specific suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their concern about the practicality of obtaining d_lambda and its potential impact on debiasing, and they suggest a potential issue. This is a clear and actionable point for the authors.", "grounding_specificity_rationale": "The reviewer identifies a specific missing piece of information, d_lambda, and implies its importance for the method. They also point out a potential issue arising from its computation or lack thereof. This demonstrates strong grounding as the authors can precisely identify the missing element and the potential problem it causes. The reviewer also mentions a similar issue when computing the surrogate sketch, further emphasizing the specific nature of their concerns.", "verifiability_rationale": "The reviewer raises a concern about the potential bias introduced by the lack of accurate computation of d_lambda and its impact on the sketching process. However, the paper does not explicitly discuss this issue. While the reviewer's concern is valid and points to a potential flaw, the paper lacks any evidence or references to support this claim. Therefore, the verifiability is low as the reviewer's concern is not wellsupported by the paper itself.", "helpfulness_rationale": "The reviewer's concern is directly related to the practical application and effectiveness of the proposed method. They highlight a crucial parameter, d_lambda, and its potential impact on the debiasing process. The lack of clarity on how to obtain this parameter and the potential bias it could introduce makes the review 5 for the authors to understand the limitations and potential pitfalls of the method. The reviewer's questions also directly address key aspects of the method's implementation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the problem: 'The ablations seem to deserve better experiment setup'. This indicates a direct and clear action the authors should take. However, the action itself is vague, as it doesn't specify which ablations are unclear or what aspects of the 'better setup' are desired. Therefore, while the reviewer identifies an actionable point, the lack of detail makes it only partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'ablations' and 'experiment setup' generally. They don't specify a particular section, table, figure, or unique element of the paper that is affected. While they express a desire for improvement, they don't detail *what* is unclear within these broad categories. Therefore, the reviewer identifies an area that needs improvement, but it lacks the specificity to pinpoint the exact location and nature of the problem.", "verifiability_rationale": "The reviewer makes a claim: 'The ablations seem to deserve better experiment setup'. However, they do not provide any evidence, reasoning, or references to support this claim. They express a desire for improvement but don't explain *why* the current ablations and setup are problematic. Without supporting evidence, the reviewer's statement is not verifiable.", "helpfulness_rationale": "The reviewer points out a potential weakness in the paper (the ablations and setup) and suggests improvement. However, because the *specificity* of the issue and the *reason* for the suggestion are lacking, the reviewer's point is vague and doesn't provide concrete guidance for the authors. While it highlights a potential area for improvement, the lack of detail makes it unhelpful in guiding concrete changes."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests an experiment: 'It would have been interesting for the authors to look deeper into this.' This indicates a clear action for the authors to take, which is to investigate the proposed models for lowfrequency words. While the exact details of the experiment are not provided, the intent is clear.", "grounding_specificity_rationale": "The review point refers to 'the proposed models' and 'word similarity data sets' generally. It does not explicitly identify a specific section, table, figure, or unique element of the paper where the lack of evidence is being pointed out. The reviewer uses general terms, suggesting weak grounding.", "verifiability_rationale": "The review point makes claims about the lack of empirical evidence and the potential for the sememe mapping not explaining improvements. However, it does not provide specific examples, references, or logical reasoning to support these claims within the review point itself. The claims are presented as suggestions for further investigation rather than verifiable statements.", "helpfulness_rationale": "The review point suggests a specific experiment (looking at lowfrequency words) and highlights a potential issue (frequent word pairs in datasets). This provides the authors with a direction for further investigation and considers a potential confounding factor. While it doesn't provide a complete solution, it offers valuable insights and constructive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'the error analysis on the movie dataset is missing.' This is a clear and direct statement of a deficiency in the work. The reviewer implies the need to provide this missing information, making the action clear and actionable. The language is direct and does not require inference to understand the intended feedback.", "grounding_specificity_rationale": "The review point explicitly mentions 'the movie dataset.' This is a specific reference to a dataset being used in the research. While it doesn't provide a literal section number, it clearly identifies the specific part of the work the reviewer is referring to. The reviewer is also specific about the *type* of analysis missing (error analysis). Therefore, the grounding is strong.", "verifiability_rationale": "The review point is a statement of a problem ('the error analysis is missing') and a request for information ('what are the cases that such model fails'). It does not present a claim that requires verification. The language is declarative and points to a factual absence. Therefore, it does not meet the criteria for verifiability.", "helpfulness_rationale": "The review point directly identifies a crucial missing piece of information ('error analysis on the movie dataset') that is directly relevant to the task and would benefit other researchers. The reviewer clearly states the need for this information, making the feedback 5 and directly helpful. The request to know the 'cases that such model fails' further enhances the practical value of the feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states that 'Some details of the proposed method are missing, as noted in the questions section below.' This is a general statement pointing to a location where information is lacking. While it identifies a problem, it doesn't explicitly state what is missing or how the author should address it. The action is implicit (identifying a missing element), but the specifics are vague. Therefore, it is 2.", "grounding_specificity_rationale": "The review point states, 'Some details of the proposed method are missing, as noted in the questions section below.' While the reviewer implies the missing details relate to the 'proposed method,' they do not explicitly identify the specific part of the paper or section where these details are supposed to be found. The grounding is implied but not precise. Therefore, it is 2.", "verifiability_rationale": "The review point states, 'Some details of the proposed method are missing, as noted in the questions section below.' This is a factual statement about the absence of information, not a claim that requires verification. While it points to a problem, it doesn't make an assertion that needs supporting evidence. Therefore, it is not verifiable in the sense of requiring external references or logical reasoning. It's more of a factual observation.", "helpfulness_rationale": "The review point identifies a gap in the proposed method by stating, 'Some details of the proposed method are missing, as noted in the questions section below.' While this highlights a problem, it does not provide any specific guidance on how the author should address or implement the missing details. The action to be taken is not specified. Therefore, it is not 5 as it does not guide the author on how to proceed."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the problem ('lack of ablation analysis') and suggests a solution ('it makes it easier to pinpoint the source of performance gain'). The phrase 'it makes it easier to pinpoint the source of performance gain' is a clear action that the authors can take. The reviewer is not just pointing out a missing element but also suggesting a concrete improvement. The action is quite explicit and concrete, indicating a clear direction for the authors.", "grounding_specificity_rationale": "The review point refers to 'the lack of ablation analysis (in the main paper)'. The phrase '(in the main paper)' is a strong indicator of grounding. The reviewer is specifically pointing out a deficiency related to the location of information within the paper. The authors can infer that the ablation analysis is missing and should be in the main paper. This shows a clear understanding of where the relevant information should be located.", "verifiability_rationale": "The review point identifies a potential issue ('lack of ablation analysis') and proposes a solution ('in the main paper'). This can be considered a claim that 'the ablation analysis should be in the main paper to improve understanding of performance gains'. While the reviewer doesn't provide external evidence to support this claim, they clearly state what they believe is missing and where it should be. The suggestion is presented as a solution, implying its verifiability through action. The claim is stated directly, making it 3.", "helpfulness_rationale": "The review point directly addresses a common concern for researchers: the difficulty of understanding the impact of their work through ablation studies. By highlighting the lack of this information in the main paper, the reviewer is directly helping the authors improve their paper by making it more informative. The suggestion to 'put the ablation analysis in the main paper' is a clear and actionable improvement that directly addresses a practical issue in academic writing. This is a valuable suggestion that empowers the authors to better understand their work's impact."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The review points out a finding from experiment 2 and suggests further investigation of a threshold. While the action of referring to experiment 2 is explicit, the vagueness of 'Th.' makes the action less concrete.", "grounding_specificity_rationale": "The review refers to 'experiment 2' which is explicit. It also compares the 'noise rate of similarity labels' with 'class labels', which are specific aspects. However, the reference to 'Th.' is not specific, making the grounding partially underspecific.", "verifiability_rationale": "The review states a claim based on the results of experiment 2. It suggests further investigation, which provides a justification for the observation. While the reasoning is highlevel, it does provide some support.", "helpfulness_rationale": "The review provides context for the authors' findings and suggests further investigation. This is helpful for guiding the authors' next steps, although it could be more specific about the threshold."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point does not explicitly state what is wrong with the CNN experiments or how the authors should improve them. It is a statement of opinion rather than a directive. Therefore, it is not actionable.", "grounding_specificity_rationale": "The reviewer refers to 'the CNN experiments' generally, without specifying which part of the paper or what aspect of the experiments is being addressed. This lack of specificity makes the grounding weak. Therefore, the grounding is 2.", "verifiability_rationale": "The review point contains a claim ('the CNN experiments are not fully convincing') but does not provide any supporting evidence or justification. The reasoning is subjective and lacks external references or logical reasoning to back it up. Therefore, the claim is 1.", "helpfulness_rationale": "The review point is a statement of opinion ('the CNN experiments are not fully convincing') without offering specific suggestions or reasons for why they are not convincing. It does not provide actionable feedback to the authors. Therefore, it is not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a general area for improvement (prompt design) rather than a specific action. While it implies a need for discussion, it doesn't provide explicit steps or concrete examples of how to design prompts effectively. The reviewer could have pointed to a specific section of the paper where prompt design is discussed and suggested concrete improvements for that section.", "grounding_specificity_rationale": "The review refers to 'this paper' without specifying a particular section, table, figure, or unique aspect. While it implies a general need for improvement in the area of prompt design, it doesn't clearly identify the specific part of the paper being addressed. The reviewer could have specified which section or table discusses prompt design and then provided specific feedback.", "verifiability_rationale": "The review point contains a claim ('discuss how to design prompts effectively') but lacks any supporting evidence or justification. It simply states the need for discussion without providing any examples, references, or logical reasoning to back it up. The reviewer could have provided specific examples of prompt design methods or referenced relevant literature to support their claim.", "helpfulness_rationale": "The review point identifies a relevant area for improvement (prompt design) and suggests a direction for it ('discuss how to design prompts effectively'). This is a valuable piece of feedback. However, it lacks specific details and examples, making it difficult for the authors to immediately understand how to act upon it. The reviewer could have provided more concrete suggestions or examples to make the feedback more actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about a methodological choice (why is freezing used in MLS selection?) and suggests an alternative (why not just use adaptive method?). While it points to a potential issue, it doesn't directly instruct the authors on a specific action to take. It highlights a gap in explanation.", "grounding_specificity_rationale": "The review point explicitly mentions \"MLS selection\" and the specific term \"freezing,\" clearly identifying the part of the paper being addressed.", "verifiability_rationale": "The review point states \"It's not clear why the freezing is used in MLS selection.\" This is a statement of uncertainty or a lack of justification, which can be interpreted as a claim that the justification is missing. However, the review point itself doesn't provide external evidence or logical reasoning to *prove* that freezing is used and *why*.", "helpfulness_rationale": "The review point identifies a potential lack of clarity and justification in the use of \"freezing\" in MLS selection. It encourages the authors to investigate further and consider alternative approaches. It points to a specific area for improvement in the authors' manuscript."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the proposed knowledgeCLIP model should solve the issue and suggests a specific analysis involving text modifications and a KGaugmented method. This provides a clear direction for the authors to follow, making it 5. The reviewer is not just pointing out a problem but also suggesting a potential solution or area for further investigation.", "grounding_specificity_rationale": "The reviewer refers to 'the proposed knowledgeCLIP model' and 'the specific issue'. While they don't pinpoint a specific section or table, they clearly identify the model and a general area of concern. This allows the authors to understand the context of the comment, making it somewhat grounded. However, the lack of precise identification weakens the grounding compared to a more specific comment.", "verifiability_rationale": "The reviewer proposes a specific type of analysis (text modification and KGaugmented method) but does not provide concrete evidence or references to support the claim that the proposed knowledgeCLIP model can perform this analysis. The suggestion is presented as a hypothetical or potential next step rather than a verified capability. Therefore, the claim is not 5.", "helpfulness_rationale": "The reviewer suggests an analysis involving text modifications and a KGaugmented method as a way to further evaluate the proposed knowledgeCLIP model. While this is a relevant and potentially useful suggestion, it is not a direct solution to any identified problems. It is more of a *potential* next step for the authors to explore rather than a concrete improvement they can directly implement based on the review. Therefore, it is 3 but lacks the direct impact of a 5 and verifiable comment."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the issue: 'how novel values in the test set are handled.' This clearly identifies an action the authors should take: 'explain how'. The point is direct and prescriptive about what information is missing. Therefore, it is explicit and concrete.", "grounding_specificity_rationale": "The review point refers to 'novel values in the test set.' While it doesn't explicitly name a section or table, the concept of 'novel values' within a 'test set' is quite specific. The reviewer is pointing to a particular aspect of the data. The comment also clearly identifies the issue as a lack of explanation. Therefore, it is grounded and somewhat specific in identifying the area of concern.", "verifiability_rationale": "The review point itself does not contain a definitive claim or assertion. It's a request for clarification. However, it implies a potential ambiguity or lack of clarity regarding the handling of novel values. If the authors can later confirm or clarify how these novel values are handled, the reviewer's point becomes verifiable. Therefore, it is 2.", "helpfulness_rationale": "The review point directly addresses a potential ambiguity in the implementation. By asking for clarification on how novel values are handled, the reviewer is pointing out a specific area where the authors might be struggling. This is clearly helpful as it directly targets a potential weakness or point of confusion. The request itself, while not a definitive statement, is a valuable piece of feedback that can guide the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that 'Similar methods have already been proposed...'. This indicates an action, which is identifying a lack of novelty or a related existing approach. However, the comment does not specify which method is similar or how it relates to the current paper's approach, making the action implicit rather than concrete.", "grounding_specificity_rationale": "The comment mentions 'multitask learning' as the area where similar methods exist. While the area is specific, the comment does not pinpoint the exact section, table, or figure in the paper where this similarity might be relevant. Therefore, the grounding is weak as the specific part of the paper is not clearly identified.", "verifiability_rationale": "The comment states a claim: 'Similar methods have already been proposed...'. This claim is not supported by any specific examples, references, or logical reasoning within this review point. The verifiability relies on external knowledge or a search for similar methods, which is not demonstrated within this specific review. Therefore, it is 1 based solely on the information provided in this review point.", "helpfulness_rationale": "The comment points out a potential gap in the paper's discussion of related work. While it doesn't directly suggest improvements, it highlights a relevant area and encourages the authors to consider existing methods. This can be helpful in contextualizing their work and potentially identifying limitations or areas for extension. Therefore, it is 3 in providing context and inspiration for further research."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "None", "helpfulness_label": "2", "actionability_rationale": "The reviewer asks a question related to the computational cost of FedMITR. While this relates to the aspect of actionability, the question itself does not explicitly state an action or provide concrete steps on how to compare the computational cost. The reviewer is implicitly suggesting a comparison but lacks the specifics on what data or metrics to use. Therefore, the actionability is somewhat implicit and lacks detailed guidance.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly refer to a specific part of the paper or method. The question is general about the computational cost of FedMITR without pointing to a particular section, table, figure, or unique aspect of the paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "", "helpfulness_rationale": "The comment raises a valid point about the potential higher computational cost of FedMITR compared to other methods. This is a relevant concern for authors using or implementing the method. However, the comment does not provide any specific information or suggestions on how to address this issue. It is a question rather than a constructive suggestion. Therefore, the comment is 3 in identifying a potential problem but lacks actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for the reasoning behind choosing 0.6 for Glove embedding similarity. While they are asking a question that implies an action (understanding the choice), the specific action and the details of how to apply it are not explicitly stated. The reviewer could have asked 'How did you choose 0.6 for Glove embedding similarity?' more specifically, for example, by asking 'Why was 0.6 chosen over 0.5?' or 'What is the effect of this value on performance?' to make it more actionable.", "grounding_specificity_rationale": "The reviewer is asking about a specific hyperparameter (0.6) and a specific loss function (GloVe embedding similarity). They are also asking about a validation strategy (kcrossvalidation) and alternative loss functions. The grounding is present as they are referring to specific components of the model and the training process. However, the specificity is limited. They don't specify *which* GloVe vectors were used, *how* the kcrossvalidation was performed, or the exact implementation of the alternative loss functions (mean or NDCG).", "verifiability_rationale": "The reviewer is posing questions about the methodology and potential impact. They are not making explicit claims that require verification. The questions are about *what* was done and *how* it could be improved, but they are not statements that can be easily proven true or false with logical reasoning, common knowledge, or external references. The reviewer is seeking information, not making assertions.", "helpfulness_rationale": "The reviewer's questions are relevant to understanding the methodology and exploring potential improvements. They are asking about a specific hyperparameter and a specific loss function, which are often areas of concern in research. Their questions are about understanding and potentially improving the methodology. They are not asking for criticism or personal opinions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly recommends using 'Resnet50' and 'DenseNet121' as modern backbone baselines and critiques '3 conv layers' as being too small. These are direct, actionable suggestions.", "grounding_specificity_rationale": "The reviewer explicitly names 'Resnet50' and 'DenseNet121' as examples of modern backbone baselines, grounding the suggestion in specific model architectures. They also specify '3 conv layers' and explain why it's too small, providing a clear reason.", "verifiability_rationale": "The reviewer states their skepticism about the proposed method and provides a justification based on prior experience with similar interventions failing ('lots of such robustness/domain invariance interventions have been proposed and have failed'). This provides a clear claim and supporting reasoning.", "helpfulness_rationale": "The reviewer directly addresses the reviewer's concerns about the proposed method, providing a clear critique and offering concrete alternatives ('Use modern backbone baselines...'). This makes the review 5 and helpful to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point mentions the use of multiple hyperparameters and the extensive hyperparameter search conducted. While it doesn't explicitly state an action or how to apply it, the reviewer points to a potential area for improvement in the experimental setup. The reviewer suggests the baseline should have been tuned similarly, which implies a lack of clarity on which parts of the paper are being addressed. The reviewer also mentions specific hyperparameters involved in the search, which provides some level of specificity regarding the tuning effort. However, it doesn't pinpoint *which* baseline hyperparameters are lacking or *why* they are insufficiently tuned.", "grounding_specificity_rationale": "The reviewer refers to the 'baseline' without explicitly stating *which* baseline is being referred to. This makes the grounding somewhat weak. The reviewer mentions 'multiple hyperparameters' and 'extensive hyperparameters search,' which are general statements. The reviewer also suggests the baseline should have been tuned similarly, but doesn't specify *which* parts of the paper are being addressed in the baseline. The reviewer mentions specific hyperparameters involved in the search, which provides some level of specificity regarding the tuning effort. However, it doesn't pinpoint *which* parts of the paper are being addressed in the baseline.", "verifiability_rationale": "The reviewer suggests a *potential* improvement (fairer tuning) but doesn't provide concrete evidence or justification for *why* the current tuning is insufficient. The reviewer mentions 'multiple hyperparameters' and 'extensive hyperparameters search,' which are general statements. The reviewer also suggests the baseline should have been tuned similarly, but doesn't provide specific examples or references to support this claim. The reviewer mentions specific hyperparameters involved in the search, which provides some level of specificity regarding the tuning effort. However, it doesn't pinpoint *which* parts of the paper are being addressed in the baseline.", "helpfulness_rationale": "The reviewer raises a valid concern about the fairness of the hyperparameter tuning for the baseline. This is a helpful point because it encourages the authors to consider the rigor of their experimental setup and potentially refine their approach. While it doesn't provide a specific solution, it prompts them to doublecheck their experimental design and potentially conduct further experiments to ensure a fair comparison. The reviewer's suggestion highlights a common pitfall in research: insufficient experimental rigor. This is a valuable piece of feedback that can lead to improvements in the experimental design."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer provides two explicit statements: 'Perplexity is the probability that the model generates the current sentence' and 'Eq1 looks like perplexity, not crossentropy'. Both statements are direct and identify specific issues. The reviewer also implies an action: 'This is not what perplexity is' and 'This looks like crossentropy' which suggests a desire for clarification or correction. The reviewer names specific concepts (perplexity, crossentropy, Eq1) and a specific line number, making the criticism quite precise. The reviewer is not just stating a fact but also pointing out a potential misunderstanding.", "grounding_specificity_rationale": "The reviewer explicitly names the concepts they are discussing: 'perplexity' and 'crossentropy'. They also refer to a specific equation (Eq1) and a line number (259). The reviewer then makes a direct comparison between the stated definition of perplexity and the equation, indicating a clear understanding of the specific part being addressed. The reviewer is not just mentioning these terms; they are actively engaging with them.", "verifiability_rationale": "The reviewer makes a claim about the definition of perplexity and its relation to crossentropy. These are established concepts in NLP. While the reviewer *claims* they know the correct definitions, the *review point itself* is making a statement that *can* be verified (by checking standard NLP texts or papers). The reviewer is not asking for verification, but the statement they are making can be. The reviewer is also pointing out a potential error in the paper's description, which is a specific claim.", "helpfulness_rationale": "The reviewer directly points out a potential error in the paper's description of perplexity and its relation to crossentropy. This is likely to be valuable information for the authors, as it could help them understand and correct a misunderstanding. The reviewer is specifically asking for clarification on a particular definition and comparing it to a specific equation, which is a clear and actionable feedback. The reviewer is directly addressing a specific point of confusion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential weakness in the authors' defense strategy (vulnerability to adaptive attacks) and suggests an alternative evaluation scenario (minimal structural alterations). However, it does not explicitly state how the authors should modify their defense or implement the suggested evaluation. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'adaptive attack', 'structural damage', and 'edge map' as the context for the suggested evaluation. This provides a clear grounding of the specific aspect of the defense being evaluated.", "verifiability_rationale": "The review point describes a hypothetical scenario of an adaptive attack and suggests evaluating against an attack with 'minimal structural alterations'. While it provides a general idea, it lacks specific examples of such an attack or references to existing literature on this type of adversarial defense. The reasoning is present but lacks concrete evidence.", "helpfulness_rationale": "The review point identifies a potential weakness in the authors' defense strategy and suggests an alternative evaluation scenario. While it provides a critique and a suggestion for improvement, it does not offer concrete steps or guidance on how the authors should implement these suggestions to enhance their draft. It is a critique and a suggestion, but not a direct solution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review points out that 'the experimental results do not contain standard deviations'. This is an explicit statement about a specific aspect of the paper (the experimental results) and what is missing within that aspect (standard deviations). The reviewer directly states what needs to be present for proper statistical analysis, making it a concrete action the authors can take. The reviewer also implies the consequence of this missing information, which is the difficulty in judging the significance of the results. Therefore, this is an explicit and concrete action the authors can take to improve their draft.", "grounding_specificity_rationale": "The review refers to 'the experimental results' as the specific part of the paper being addressed. This is a clear and direct reference to a specific section or data presented in the paper. The reviewer does not need to infer or make educated guesses about which part of the paper is being discussed. The mention of 'experimental results' is a literal reference, indicating full grounding. While the reviewer also mentions the 'absence' of standard deviations, the primary focus of the grounding is on the section itself.", "verifiability_rationale": "The review makes a claim that 'the experimental results do not contain standard deviations and therefore it is hard to judge the significance of the results'. This is a claim that requires verification. The reviewer states a fact (the absence of standard deviations) and provides a logical consequence (the difficulty in judging significance). The claim is supported by the absence of standard deviations, which is a verifiable fact. The reviewer does not introduce external references to support this claim, but the lack of standard deviations is a verifiable issue within the paper itself.", "helpfulness_rationale": "The review provides a clear and specific piece of feedback to the authors. It identifies a crucial missing element in their experimental results (standard deviations) and explains why its absence makes it difficult to judge the significance of the findings. This information is directly actionable for the authors, helping them understand the limitations of their current analysis and potentially reevaluate their experimental data. The reviewer's comment is not just a general observation but a specific suggestion for improvement, making it 5 for the authors to understand and address."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'Quality of generated images by proposed method is limited' and 'the realism of generated results is limited'. These are direct statements about problems. While the reviewer also mentions 'While good continuous control is achieved,' this implies that the issue lies in the *image quality* rather than the *control*. The reviewer suggests 'improving the realism of generated results,' which is a clear action to take. Therefore, the reviewer identifies a problem and suggests a concrete action to address it.", "grounding_specificity_rationale": "The reviewer refers to 'generated images by proposed method' and 'realism of generated results.' While they mention the *type* of image and a deficiency in *realism*, they do not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. The comment is about a general quality issue without pinpointing a specific part of the paper being affected. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer makes a judgment about the quality of generated images: 'Quality of generated images by proposed method is limited' and 'the realism of generated results is limited.' These are claims. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. There is no evidence presented to justify why the generated images have limited quality or lack realism. Therefore, the claims are not verifiable.", "helpfulness_rationale": "The reviewer points out a deficiency ('Quality of generated images... is limited' and 'the realism of generated results is limited') and suggests an improvement ('improve the realism of generated results'). This indicates that the reviewer has identified a problem and has a suggestion for resolution. While the suggestion is somewhat vague, it still offers a direction for the authors to focus their efforts. Therefore, the review point offers some direction for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer directly points out an inaccuracy in the authors' description of Cycle Consistency loss. They state that the authors incorrectly claim the loss function cannot perform the described alternating reconstruction phases with separate backpropagation. This is a clear and actionable piece of feedback, as the authors need to correct their description of the method. The reviewer identifies the specific aspects of the method they are referring to (ABA and BAB phases with two separate backpropagation processes), making the action clear and easily actionable.", "grounding_specificity_rationale": "The reviewer provides very specific details about the Cycle Consistency loss, including the 'ABA' and 'BAB' reconstruction phases and the involvement of 'two separate standard backpropagation processes'. This level of specificity ensures the authors can directly identify the relevant part of their paper and understand the exact issue being pointed out.", "verifiability_rationale": "The reviewer's claim is based on established knowledge of Cycle Consistency loss, commonly used in methods like CycleGAN. The statement that 'in Cycle Consistency loss you can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes' is a verifiable fact. The reviewer provides a clear statement that contradicts the authors' claim, supported by logical reasoning about the standard implementation of this loss function.", "helpfulness_rationale": "The reviewer's point is directly helpful to the authors. They are correcting a potential misunderstanding or error in the authors' description of their method. By pointing out the correct implementation of Cycle Consistency loss, the reviewer provides a concrete piece of information that will help the authors accurately understand and implement their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states what is missing ('grammar over kernels is not explained in any detail') and what should be done ('understand how this approach is applied in practice'). This provides a clear action for the authors to take.", "grounding_specificity_rationale": "The reviewer specifically mentions 'grammar over kernels' as the area lacking detail. They also specify what is missing ('not explained in any detail') and what should be included ('probabilities associated with the grammar that define a hypothesis space of kernels? How is inference performed?'). This strong identification of the specific part and the issues within it demonstrates high grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the missing details and provides specific information about what is missing ('grammar over kernels is not explained in any detail') and how it should be explained ('detailed explanation, probabilities, inference'). This claim is supported by logical reasoning and specific examples, making it 5.", "helpfulness_rationale": "The reviewer's point directly addresses a potential weakness in the paper (lack of detail on a key component) and offers concrete suggestions for improvement. This is a 5 comment as it guides the authors on what information is needed and how it should be presented."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point implicitly suggests the authors should consider showing qualitative results and using zoomedin views. However, it doesn't explicitly state what actions the authors should take with this information or how to implement it. The suggestion is present, but the explicit steps are missing, making it somewhat implicit.", "grounding_specificity_rationale": "The review point is very general and does not specify which qualitative results or which aspects of previous methods the authors should be looking at. There is no mention of a specific section, table, figure, or unique element of the paper being addressed. The comment is highly unspecific, failing to ground the request in a particular part of the paper.", "verifiability_rationale": "The review point is a suggestion for the authors to show qualitative results and analyze previous methods. It does not contain a claim that can be verified using logical reasoning, common knowledge, or external references. The point is a suggestion, not a verifiable statement about the paper.", "helpfulness_rationale": "The reviewer expresses a desire for qualitative results and analysis, which is generally helpful for understanding and improvement. However, the review point is very general and lacks specific details about what kind of qualitative results or what aspects of previous methods the authors should be considering. Without more specificity, it's difficult to immediately apply this feedback. Therefore, it's 3 but lacks immediate actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states an action: 'improve the title'. It suggests a specific change: 'clarify that you are referring to machine comprehension of text, and not human reading comprehension'. This action is directly tied to the identified weakness of the title's ambiguity.", "grounding_specificity_rationale": "The comment explicitly mentions the 'title' as the part of the paper being addressed. It also specifies the desired change: 'clarify that you are referring to machine comprehension of text, and not human reading comprehension'. This demonstrates a clear grounding of the comment in a specific aspect of the paper.", "verifiability_rationale": "The comment contains a claim: 'because \u201creading comprehension\u201d and \u201creadability\u201d usually mean that'. This claim is supported by the common usage of these terms in the context of text understanding. While it doesn't provide specific examples, it relies on a generally accepted understanding of these terms.", "helpfulness_rationale": "The review point identifies a potential weakness in the title (ambiguity) and provides a specific suggestion for improvement ('clarify that you are referring to machine comprehension of text, and not human reading comprehension'). While it doesn't directly demand a change, it offers a constructive suggestion with a reason, empowering the authors to consider the nuances of their title."}
{"actionability_label": "N/A", "grounding_specificity_label": "Partially Grounded", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggestion. The reviewer is pointing out a *criticism* of a methodological choice, not an actionable improvement to the paper itself. Therefore, it doesn't fit the definition of actionable, which requires a direct instruction or recommendation for improvement.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or the style control evaluation method. It's a general criticism about the justification of using an automatic metric. The authors can infer that the issue might be in the style control evaluation, but the grounding is implicit, not explicit.", "verifiability_rationale": "The review point contains a claim: *\"I don\u2019t understand why in the human evaluation the authors use an automatic metric TSS rather than a human metric to evaluate the style control.\"* This claim is not fully supported by evidence within the review point itself. While the reviewer expresses a lack of understanding, there's no specific reference to external works or logical reasoning to verify this claim. The verifiability relies on the reviewer's subjective experience and the lack of a clear justification provided in the point.", "helpfulness_rationale": "The review point is 3 in that it identifies a potential weakness in the human evaluation process by questioning the justification for using an automatic metric. This could prompt the authors to consider the limitations of automatic metrics and potentially seek clarification or alternative evaluation methods. However, the point itself doesn't offer a concrete solution or actionable improvement to the evaluation process. The helpfulness is limited to raising awareness of a potential issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point states the experiments *succinctly prove the point that the authors try to make*. While it identifies a *type* of experiment, it doesn't tell the author *what to change* or *how to make the experiments more diverse*. The lack of a specific action makes it *not fully actionable*.", "grounding_specificity_rationale": "The review point talks about *experiments* in general and *more diverse domains* without pinpointing a specific section, table, figure, or unique aspect of the experimental setup. The reviewer is making a general suggestion about the *type* of experiments. They aren't specifying *which* part of the current experimental section is problematic or why the TDMPC 2 experiments are lacking in *that specific part*. The suggestion lacks a clear connection to a specific element within the paper's structure or content.", "verifiability_rationale": "The review point clearly states a suggestion: *\"it would strengthen the paper to include experiments across more diverse domains (those in TDMPC 2)\"*. This is a clear recommendation or judgment. However, the statement itself is a suggestion for improvement, not a claim that *something is wrong*. While the suggestion could be considered a claim for improvement, it lacks external references or logical reasoning to justify *why* the current experiments are insufficient. The suggestion is presented as a suggestion, not a claim that needs verification.", "helpfulness_rationale": "The review point offers a relevant suggestion to include experiments across more diverse domains. This is a constructive comment aimed at improving the paper's experimental section. While it doesn't provide specific steps on how to achieve this or what specific domains to choose, it points in a useful direction and is directly related to the paper's content. The suggestion is actionable in the sense that it guides the authors towards a better experimental design, even if it lacks specific implementation details."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests two concrete actions for the authors: 'include confidence intervals' and 'expand evaluation to more diverse datasets'. These are direct and actionable steps that the authors can readily implement to improve their draft. The reviewer provides clear guidance on *what* to do and *where* to make these improvements.", "grounding_specificity_rationale": "The reviewer's comment is not explicitly tied to a specific section or table of the paper being reviewed. While they imply feedback on the paper's evaluation methodology, they don't pinpoint the exact location. However, the comment is quite specific about the *type* of improvement (confidence intervals and diverse datasets), which makes the grounding somewhat strong in terms of the *nature* of the improvement, even if the exact location isn't specified.", "verifiability_rationale": "The review point does not make a claim or assertion. It is a statement of observation and suggestion. Therefore, it does not fall under the 'claim extraction' category defined for verifiability. The reviewer is not claiming that the paper lacks confidence intervals or that the evaluation is limited to two datasets. They are simply pointing out these issues.", "helpfulness_rationale": "The review point is 5 because it provides concrete and actionable suggestions for the authors. The reviewer clearly identifies two specific areas for improvement: the inclusion of confidence intervals and the expansion of the evaluation to more diverse datasets. These suggestions are directly relevant to improving the rigor and generalizability of the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "1", "helpfulness_label": "None", "actionability_rationale": "The review points out a *specific* issue: the lack of clarity in the LUQ design process. It suggests a *potential* improvement: focusing on the goal of logarithmic and unbiased quantization. While it identifies a problem, it doesn't tell the author *how* to address the lack of clarity. The suggestion is more of an *idea* than a concrete action.", "grounding_specificity_rationale": "The review mentions \"LUQ itself,\" \"LUQ design process,\" \"logarithmic and unbiased quantizer,\" and \"LUQ itself is rather straightforward to design.\" While it touches on the topic, it doesn't pinpoint a specific section, table, figure, or unique element of the paper. It's more of a general comment about the overall process. The comment specifies what needs to be addressed (clarity in LUQ design) but doesn't identify the specific part of the paper being addressed.", "verifiability_rationale": "The review states \"I'd say the main contribution of this paper is showing that such a simple combination of existing techniques is sufficient to achieve (surpringly good) accuracy, rather than proposing novel techniques.\" This is a clear statement of opinion and judgment about the paper's contribution. However, the claim is not supported by any specific examples, references, or logical reasoning within the review point itself.", "helpfulness_rationale": "The review points out a valid concern about the clarity of the LUQ design process. However, it doesn't offer concrete suggestions or a clear path for the author to follow to address this. The suggestion to focus on the goal is a good starting point, but the review doesn't explain *how* to achieve that focus or what specific aspects need clarification. The opinion about the paper's contribution, while potentially insightful, isn't actionable for the authors. Without concrete suggestions or a clear methodology for improvement, the review's potential benefit is limited."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their wish to see training losses, which is an action. However, the action is vague as it doesn't specify how they want to see the losses (e.g., in a table, a plot, or a specific metric).", "grounding_specificity_rationale": "The reviewer mentions 'a deep localization network' and 'differentiable Sinkhorn' but does not explicitly identify the specific part of their network or the Sinkhorn implementation they are referring to. This makes the grounding weak.", "verifiability_rationale": "The review point is a question and a request for information, not a claim that needs verification. Therefore, it doesn't fit the verifiability criteria.", "helpfulness_rationale": "The reviewer has a valid point about the need for training losses. However, the request is vague and lacks specific details, making it less helpful for the author. The reviewer needs to be more specific about what kind of losses they are interested in seeing."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the computational cost of RegMixup (2x samples per iteration) and its resulting slower speed (1.5x slower). It also suggests this could lead to unfair comparisons with other methods. This is an explicit and concrete statement of a potential issue.", "grounding_specificity_rationale": "The review point explicitly mentions 'RegMixup' and the specific parameters related to its training: '2x samples per iteration'. This clearly identifies the specific aspect of RegMixup being addressed. The reviewer also mentions the consequence of these parameters: 'running speed is slow (as authors claimed 1.5 x slower)'. This specifies what is being affected. The grounding is strong and specific.", "verifiability_rationale": "The review point contains a claim: 'RegMixup seems to see 2x samples per iteration. Thus the running speed is slow (as authors claimed 1.5 x slower)'. This claim is verifiable through logical reasoning. The 2x samples per iteration directly implies a higher computational load, which can reasonably be associated with a slower running speed. While the claim itself isn't a direct citation, the reasoning supporting it is clear and logical.", "helpfulness_rationale": "The review point is highly relevant to the authors, specifically addressing a potential implementation detail of RegMixup that could impact its performance and fairness of comparison. It provides a clear observation and a potential explanation, which is actionable and directly addresses a practical concern. The feedback is specific to the method and its parameters."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point asks a question about the method's scaling behavior, which can be interpreted as an implicit request for information. However, the question is vague, asking about scaling in general without specifying the type of scaling or its implications. This makes it not fully actionable as it doesn't provide a clear direction for the authors to follow.", "grounding_specificity_rationale": "The review point asks about the method's scaling with respect to corpus size and hidden dimension size. While it targets specific parameters, it doesn't explicitly identify a *part* of the paper or a *section* where this scaling behavior is relevant. The question is about general scaling, not about a specific issue within a specific section.", "verifiability_rationale": "The review point is a question, not a statement containing a claim that requires verification. There is no assertion, opinion, or suggestion being made. It simply asks for information about the method's scaling.", "helpfulness_rationale": "The review point is a question that asks about the method's scaling behavior without providing any specific guidance or actionable information. It doesn't tell the authors what to do or why this scaling is important. Therefore, it doesn't offer any helpful feedback."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about a previous remark but does not explicitly state an action or suggestion. While it implies a desire for clarification, it doesn't directly address the original issue raised in the previous point. The reviewer is asking 'what can be done,' which is a broad question and not a direct action or suggestion.", "grounding_specificity_rationale": "The review point refers back to a 'previous remark' without providing specific details about which part of the paper or algorithm is being discussed. It does not identify a specific 'ballaction pair' or any other specific element. The reference is vague and general.", "verifiability_rationale": "The review point is a question and does not make a claim that needs verification. It's a request for information rather than a statement that can be supported or refuted.", "helpfulness_rationale": "The review point is a question seeking clarification on a previous remark. While it shows engagement with the discussion, it doesn't directly address the original issue raised in the previous point. It's a valid point of inquiry, but it doesn't provide a concrete solution or actionable feedback. It's more of a followup question than a direct improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks a question about the potential of a better encoder. While the question implies a potential action (testing a better encoder), it doesn't directly instruct the authors on *how* to implement this change or what specific steps they should take. The action is implied but not explicitly stated and detailed.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'BERT' and 'RoBERTabase' as examples of encoders. This clearly grounds the comment to a specific part of the paper (the encoder architecture) and specifies the issue being considered (potential improvement with a different encoder). The comment identifies the specific area being addressed.", "verifiability_rationale": "This review point does not contain a claim. It is a question posed to the authors. Therefore, it does not have verifiability as it lacks a statement that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer asks a question about the potential of a better encoder. While this question could be helpful in guiding the authors to explore improvements, it does not provide concrete actionable feedback. The authors are left to interpret the question and potentially conduct their own experiments or analysis. The feedback is openended and does not directly suggest specific modifications or improvements to the draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a concern about the tradeoff between fairness and predictive model performance and offers a suggestion to show how to achieve fairness without 'severely damaging the performance of predictive model'. This is an explicit action and provides concrete details on how to implement the suggestion by asking about specific methods or techniques. Therefore, it is 5.", "grounding_specificity_rationale": "The comment identifies the areas involved in the tradeoff: 'fair policy learning' and 'predictive model performance'. While it doesn't pinpoint a specific section, table, or figure, it clearly refers to these concepts. This can be considered '3' as the areas are identified, but not with literal mentions or unique elements.", "verifiability_rationale": "The comment presents a principle or guideline: 'It would be good to show how to use the proposed method to achieve fair policy learning without \"severely damaging the performance of predictive model\"'. This is a judgment or opinion about the desiderata of a method, which could be considered '3' as it implies a desirable outcome (not severely damaging performance) but doesn't provide immediate evidence or references.", "helpfulness_rationale": "The comment directly addresses a practical concern in the field \u2013 the potential negative impact of fairness interventions on predictive performance. It offers a constructive suggestion by asking about specific ways to achieve fairness without 'severely damaging the performance of predictive model'. This is a helpful comment as it guides the authors to consider a balanced approach and think about the tradeoffs involved. It is '5' because it directly tackles a relevant issue and provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a weakness (lack of implementation details) and suggests an action (including them in Section 4.1). While the action is implied, it is a clear direction for improvement.", "grounding_specificity_rationale": "The review point explicitly mentions 'Section 4.1,' indicating strong grounding. However, it doesn't specify the exact nature of the missing implementation details, making it underspecific.", "verifiability_rationale": "The review point claims that the lack of implementation details is a problem and suggests including Section 4.1 as a solution. However, it doesn't provide evidence or justification for *why* this is necessary or how it will solve the confusion.", "helpfulness_rationale": "The review point directly addresses a significant concern (lack of implementation details) and provides a clear direction for improvement (including them in Section 4.1). This is highly relevant and actionable for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper lacks empirical evaluation, comparisons with other methods, and a discussion of practical value. This directly points to a missing action for the authors to take, which is to conduct these evaluations and consider the practical implications of their theoretical contribution. The reviewer's statement is a clear and actionable suggestion for improvement.", "grounding_specificity_rationale": "The reviewer specifically points to the 'entire empirical evaluation section' as missing. This is a very precise and specific identification of where the gap lies. The reviewer doesn't just say 'there's something missing'; they pinpoint the exact area that needs attention. This high level of specificity makes the grounding very strong.", "verifiability_rationale": "The reviewer makes a claim that 'no empirical evaluation whatsoever is provided' and that 'there is no comparison (except for on an abstract level) with other methods' and that 'it is completely unclear what the practical value of the contribution even could be'. While the reviewer's point about the lack of empirical evaluation and comparisons being 'unclear' might have some basis in the paper's content, the core claim about the absence of these elements is verifiable. The reviewer doesn't present a novel argument or require external references to support their claim; it's a direct statement about the paper's content. The 'unclear practical value' is a bit weaker, as it could be argued that even theoretical contributions can have potential implications, even if not explicitly demonstrated. However, the core claim about the missing empirical evaluation and comparisons is verifiable.", "helpfulness_rationale": "The reviewer's point about the lack of empirical evaluation and practical value is a highly valuable piece of feedback for an author considering a theoretical contribution. It directly addresses a crucial gap in the paper's current form. The reviewer is not just pointing out a deficiency; they are highlighting a significant area where the authors could make a substantial impact. This information is 5 and would be very helpful for the authors in guiding their future work, even if the paper itself doesn't provide the empirical backing or practical considerations. The reviewer's assessment of the 'practical value' is a strong indicator of the potential impact of the authors' work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the method is 'limited in navigation problems' and suggests 'combining RL and planning' as a potential improvement. This indicates a clear action: to explore the applicability of the method in a broader context. While the suggestion is general, it is a direct action that can be taken.", "grounding_specificity_rationale": "The reviewer mentions 'navigation problems' and 'PRMRL' as related concepts. While they touch upon a specific area, they do not explicitly identify a specific section, table, or unique aspect of the paper being addressed. The connection is implied rather than directly stated.", "verifiability_rationale": "The reviewer states that the method is 'limited in navigation problems' and that 'combining RL and planning has already been discussed in PRMRL'. These are statements of opinion and observation. While they provide context, they do not offer verifiable evidence or logical reasoning to support these claims within the context of the paper itself. The reviewer presents these as facts without providing citations or detailed explanations.", "helpfulness_rationale": "The reviewer suggests that the paper is 'limited in navigation problems' and that 'combining RL and planning has already been discussed in PRMRL'. While this is a relevant observation and points to a potential area for future research, it doesn't directly identify a specific weakness in the paper's methodology or provide concrete, actionable advice for improvement. The suggestion is more of a generalization and a reference to related work rather than a direct critique of the paper's contribution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the problem: \"it has never been defined clearly.\" They also propose a solution: \"improve it.\" This is a clear and actionable statement.", "grounding_specificity_rationale": "The reviewer directly refers to the \"contrastive gap\" and its \"core\" and proposes a specific type of clarification: \"a clear, formal definition.\" This is a 5 statement.", "verifiability_rationale": "The reviewer makes a claim: \"the proposed *contrastive gap* lies at the core of this work; however, it has never been defined clearly.\" However, they do not provide any evidence or justification for why this lack of definition is a significant issue. There is no logical reasoning, common knowledge, or external references provided to support this claim.", "helpfulness_rationale": "The reviewer identifies a clear weakness: the lack of a clear definition. They also offer a constructive suggestion: \"improve it.\" While the suggestion is present, the reviewer doesn't explain *why* this is a crucial issue for the authors or *how* improving the definition will directly benefit their work. The connection to the authors' specific needs is missing."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states \"Ideally other baselines would also be included...\" and \"All unclear parts have been answered.\" These direct statements indicate an explicit suggestion for improvement. The reviewer also mentions 'specific papers 29, 5, 6\" which implies a concrete action to be taken by the authors.", "grounding_specificity_rationale": "The reviewer mentions \"other baselines\" and specifically names \"papers 29, 5, 6\". This indicates a clear identification of the specific aspect of the paper being addressed (likely the related work section or the experimental setup concerning these baselines). The reviewer also states \"The authors' explained why the chosen baseline makes the most sense.\" This shows a clear specification of what needs to be addressed in this part.", "verifiability_rationale": "The reviewer makes a claim: \"The authors' explained why the chosen baseline makes the most sense.\" This claim is supported by the statement \"All unclear parts have been answered.\" which implies that the authors have provided a justification for their choice of baseline.", "helpfulness_rationale": "The reviewer states \"My weakness points after been addressed in the authors' response. Consequently I raised my score.\" This indicates that the reviewer found the criticism meaningful and the suggestions helpful, leading to an increase in their score. The reviewer also states \"All unclear parts have been answered The authors' explained why the chosen baseline makes the most sense.\" which shows a clear understanding and a positive assessment of the feedback."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out the phrase 'to meet' as being unclear. While they identify a problem, the action they suggest isn't explicitly stated. The reviewer doesn't specify how the unclear phrase should be changed or what alternative phrasing is better. The action is implied but not concrete.", "grounding_specificity_rationale": "The reviewer explicitly points to the phrase 'a response candidate can meet each utterace' on line 280, indicating a clear understanding of the specific part of the paper being addressed. They mention the use of 'to meet' as a specific example within that section.", "verifiability_rationale": "The reviewer identifies a weakness in the writing ('to meet' is unclear) and suggests an improvement ('change the phrase'). This constitutes a claim. While the reviewer identifies the location of the issue, they do not provide specific examples of why 'to meet' is unclear or cite external references to support their claim. The support is present in the form of identifying the location, but lacks depth in explaining the problem or providing alternatives.", "helpfulness_rationale": "The reviewer directly points out a specific instance in the text ('a response candidate can meet each utterace' on line 280) where the phrase 'to meet' is used unclearly. This is a concrete piece of feedback that directly addresses a potential point of confusion for the authors. While the feedback is specific, it lacks suggestions for improvement beyond 'change the phrase'."}
{"actionability_label": "3. 3", "grounding_specificity_label": "3. 3", "verifiability_label": "X", "helpfulness_label": "3. 3", "actionability_rationale": "The review point is a question prompting the authors to consider limitations. While it implicitly suggests that the authors should think about the limitations of their method, it does not explicitly state what limitations to focus on or how to address them. Therefore, it is 2.", "grounding_specificity_rationale": "The reviewer asks 'is this the case here?'. The word 'here' is vague and does not pinpoint a specific part of the paper or a specific limitation mentioned in the previous review point. Therefore, the grounding is weak. While the question implies a reference to the current work, it lacks specificity about which limitations or aspects are being considered. The specificity is also lacking as the reviewer does not provide any examples or details about what they mean by 'this'.", "verifiability_rationale": "The review point itself does not contain a claim. It is a question. Therefore, it is difficult to assess verifiability directly. However, the question implicitly suggests that the authors should consider the limitations of their method, which could be seen as a form of guidance, though it's not a definitive statement or supported by evidence. The lack of a claim makes it challenging to evaluate the verification methods.", "helpfulness_rationale": "The review point is a question that is relevant to the authors' work. It encourages them to reflect on the limitations of their method and consider whether the issues observed in the graph case might be present in their current work. While it doesn't provide a specific solution, it prompts a valuable discussion and selfreflection, which can be helpful for improvement. Therefore, it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks for the dropping rate and the number of masks, which are direct and apparent actions. While the reviewer might be inferring that these details are missing from the paper, the question itself points to specific values.", "grounding_specificity_rationale": "The reviewer can infer the section of the paper being referred to (dropout mechanism) and asks very specific questions about the dropping rate and the number of masks. This indicates strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim that the paper does not specify the dropping rate and the number of masks. This claim can be verified by checking the paper for these details. Assuming the paper lacks this information, the claim is verifiable.", "helpfulness_rationale": "The reviewer's questions are clear and directly address a likely omission in the paper \u2013 the specific implementation details of the dropout mechanism. This makes the review 5 for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitations of the current evaluation and provides concrete suggestions for improvement. They point out that the justification for the twostage approach is lacking and suggest comparing against other singlestage attacks. This indicates a clear understanding of what needs to be addressed and how to do it.", "grounding_specificity_rationale": "The reviewer refers to the 'twostage optimization approach' and the 'performance drop on fusion models,' which are specific aspects of the paper. They also specify the need for 'comparisons with other singlestage attacks' as a concrete action to take. This demonstrates a clear identification of the relevant section and a specific suggestion for improvement.", "verifiability_rationale": "The reviewer makes a claim about the 'effectiveness of the technical contributions' and states that 'without proper benchmarks and comparisons with other SOTA algorithms, it is hard to justify the effectiveness.' While the reviewer identifies a problem, they do not provide specific examples of other singlestage attacks or detailed reasons why the current benchmark is insufficient. The claim is stated, but the supporting evidence is lacking.", "helpfulness_rationale": "The reviewer clearly identifies specific weaknesses in the evaluation and provides concrete suggestions for improvement. They explain *why* the current evaluation is insufficient, which empowers the authors to address the limitations and strengthen their work. The suggestions are actionable and directly related to the identified issues."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issue with the connections in Figure 2, identifying that the Perceptual Metric should connect the Second Inpainted Images with the Images Masked by Second Masks, not the Images Masked by First Masks. This is an explicit action that the authors can directly implement by revising Figure 2. The reviewer also provides a concrete suggestion of *which* images should be connected, making the action very clear and actionable. There is no ambiguity in the reviewer's intent regarding the correction.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific part of Figure 2 they are referring to, mentioning 'Figure 2', 'Perceptual Metric', 'Second Inpainted Images', and 'Images Masked by Second Masks'. This demonstrates strong grounding specificity, as the authors can easily locate the relevant section in the paper. Furthermore, the reviewer provides a clear and specific suggestion about *which* elements should be connected, making the grounding very precise.", "verifiability_rationale": "The reviewer is not making a claim that requires verification or providing a reference. Instead, they are suggesting a change to improve the clarity of Figure 2. While the suggestion itself is valuable for the authors, the lack of a claim means there is no logical reasoning, common knowledge, or external references being provided to support the suggestion. The reviewer is proposing a solution based on their interpretation of the figure's intent, but this is not a claim that needs to be proven. Therefore, it falls under 'X'.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential source of confusion for the authors regarding Figure 2. By pointing out the incorrect connections and suggesting the correct ones, the reviewer provides a concrete and actionable improvement. This is a 5 comment because it directly tackles a specific issue in the paper and offers a clear solution. The potential benefit for the authors is significant, as it will improve their understanding of the figure and potentially the overall clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "3: Weakly Verifiable", "helpfulness_label": "4", "actionability_rationale": "The reviewer raises a valid point about the clarity of the attention mechanism. While the reviewer's question is direct, the paper could benefit from explicitly stating whether nonneighboring nodes are supported or if the attention is strictly limited to neighbors. The current description, focusing on N_l^(s), might lead to ambiguity about the scope of the attention.", "grounding_specificity_rationale": "The reviewer's question highlights a potential lack of specificity in the description of the attention mechanism. While the paper mentions N_l^(s), it doesn't explicitly state whether this refers to neighboring nodes only or if nonneighboring nodes are also considered. The implication is that only neighbors are attended to, but this isn't clearly stated, making it weakly grounded.", "verifiability_rationale": "The reviewer's question is based on a potential inconsistency or lack of clarity in the description of the attention mechanism. If the description of N_l^(s) implies only neighboring nodes are attended to, and the reviewer is questioning if nonneighboring nodes are allowed, this raises a verifiability issue. The paper needs to explicitly state the scope of the attention and provide justification for any design choices.", "helpfulness_rationale": "The reviewer's question is highly relevant and directly addresses a key aspect of the method. A clear and direct answer to whether nonneighboring nodes are supported would be extremely helpful for the authors to understand and implement the proposed approach. This question directly impacts the usability and understanding of the method."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issues: 'unclear,' 'overstated,' 'not clear,' 'unclear.' These are direct actions or suggestions that authors can directly identify modifications they should apply to their draft. The reviewer points to specific aspects like 'main contribution,' 'novel properties,' 'dynamic largescale multitasking,' and 'automation,' which are concrete and actionable.", "grounding_specificity_rationale": "The reviewer refers to the 'main contribution,' 'novel properties,' 'dynamic largescale multitasking,' and 'automation.' While these are general terms, they point to specific areas within the paper that are likely discussed. The reviewer doesn't provide a definite section number, making the grounding 'weak'. However, the reviewer does specify what needs to be addressed within these areas (e.g., 'how the automation is achieved'), making the specificity 'somewhat'.", "verifiability_rationale": "The reviewer makes claims about the paper's main contribution, novelty, and automation. However, the reviewer does not provide any evidence, reasoning, or references to support these claims. The claims are presented without justification, making the verifiability '1'.", "helpfulness_rationale": "The reviewer identifies specific weaknesses in the paper, such as the unclear main contribution, overstated novelty claims, lack of clarity on the multitasking aspect, and unclear automation mechanism. While the reviewer doesn't provide specific solutions or detailed explanations, they clearly point out areas where the authors need to improve. This level of identification is helpful for guiding the authors, even if it requires further investigation and clarification from the authors."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question ('What does the system offer?') and suggests a comparison ('over the previous extractthengenerate methodologies'). While this points towards an area for improvement, it doesn't explicitly state what the author should do next. The reviewer implies the author should find out what the system does, but doesn't provide concrete steps on how to compare it to previous methods. The action is implicit, requiring the author to engage in further research or experimentation.", "grounding_specificity_rationale": "The review point is a general question about the system's functionality and its comparison to previous extractthengenerate methodologies. It does not specify which related work or methodology the reviewer is referring to, nor does it point to a specific section, table, or figure in the paper. The grounding is weak because the reviewer could be referring to many different related works, and the connection to the current paper is not explicitly stated.", "verifiability_rationale": "The review point is a question, not a declarative statement that makes a claim or judgment. Therefore, it does not contain a claim that can be verified. The point is simply asking for information or a comparison, not stating something that requires evidence or justification.", "helpfulness_rationale": "The review point is a question that is relevant to the paper's topic (long document summarization and comparison with previous methodologies). However, it lacks concrete suggestions or guidance on how to answer the question or perform the comparison. The reviewer asks 'What does the system offer?' but doesn't specify how the author should investigate this. The suggestion to compare with previous methods is also vague. Therefore, while the question is pertinent, it doesn't provide actionable steps for the author, making it only slightly helpful."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests an action: 'What's the best way to use that unlabeled target data to improve the stability of our model?'. This indicates a degree of actionability. However, the justification for this action is presented as a *disadvantage* of the original approach ('Also, the thought of having to train 3040 models to burn in in order to test this approach isn't particularly appealing.') and a potential alternative ('Another interesting direction for dealing with churn could be unlabelled data, or applying via constraints: e.g. if we are willing to accept X% churn, and have access to unlabeled target data, what's the best way to use that to improve the stability of our model?'). The reviewer's suggestion is not explicitly stated as a solution to the burnin problem, but rather presented as a potentially better approach. The connection between the burnin problem and the unlabeled data suggestion is implied but not explicitly stated as a direct solution.", "grounding_specificity_rationale": "The reviewer's review point does not explicitly identify a specific part of the paper or methodology that they are criticizing. The focus is on the *process* of training models and the *challenges* associated with it (like the burnin period). There is no mention of a specific section, table, figure, or unique element of the paper that is being addressed. The reviewer is offering a general suggestion about an alternative approach to dealing with churn, rather than criticizing a specific aspect of the current approach.", "verifiability_rationale": "The reviewer states their opinion about the burnin period being 'not particularly appealing' and suggests an alternative approach. This statement is a claim that requires verification. However, the reviewer does not provide any specific evidence or reasoning to support this claim within the review point itself. There are no references to external works, logical reasoning, or examples to justify why the burnin period is unappealing or why the alternative approach is better. The statement is presented as a subjective opinion.", "helpfulness_rationale": "The reviewer offers a potential improvement (exploring alternatives) and provides a reason for it (the perceived drawback of the current method  the burnin period). However, the justification for the alternative approach is not explicitly stated as a solution to the problem of the burnin period. Instead, the alternative is presented as a potentially better approach to dealing with churn in general. The reviewer does not provide concrete evidence or reasoning to demonstrate how the suggested approach directly addresses the inefficiency of the burnin process. The connection between the burnin problem and the unlabeled data suggestion is implied but not explicitly stated as a solution."}
{"actionability_label": "3", "grounding_specificity_label": "X: 1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests adding a quantitative measurement to address occupation bias. While this points to a potential improvement in the authors' work, the suggestion is not explicit about the *method* or *steps* to achieve this. The reviewer implies an action (adding a measurement) but doesn't provide the specifics, making it implicit and lacking detailed guidance. Therefore, while it suggests an improvement, the lack of concrete steps makes it not fully actionable.", "grounding_specificity_rationale": "The reviewer makes a general comment about the authors' lack of a quantitative measurement for occupation bias. They do not explicitly identify a specific section, table, figure, or unique aspect of the paper where this deficiency exists. The comment is a general critique of the methodology rather than a targeted suggestion for a particular part of the paper.", "verifiability_rationale": "The reviewer makes a claim about the authors' methodology (lack of quantitative measurement) and suggests comparing it to real distributions. This claim is supported by logical reasoning \u2013 the reviewer is pointing out a gap in the authors' approach. However, the reviewer does not provide specific examples, references, or logical reasoning to *justify* why this lack of measurement is a problem or how it should be addressed. The claim is stated but not thoroughly supported.", "helpfulness_rationale": "The reviewer points out a potential weakness in the authors' approach \u2013 the lack of a quantitative measurement for occupation bias. This could be helpful for the authors as it highlights a gap in their methodology and suggests a potential improvement. However, the reviewer does not provide specific, actionable steps on how to implement this improvement. The comment identifies a potential area for enhancement but doesn't fully guide the authors on how to do it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the preference for DICOM over PNG and suggests a specific dataset (FastMRI). They also mention 'inference speed,' providing a direction for experimentation. This is a clear, direct statement of a preference/ recommendation, making it 5.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the real dicom image' and 'FastMRI challenge dataset.' This is a very specific reference to parts of the paper, and they also suggest a 'metric' for comparison ('inference speed'). This indicates strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a judgment about image formats and datasets based on the expected format for 'real' data and suggests comparing 'inference speed' as a way to evaluate methods. While they don't provide direct evidence *within this review point* to support these claims, they are suggesting *what* should be done and *how* to do it, which constitutes a claim. The support is more about common practices and a suggested experiment rather than explicit references or logical reasoning within this point itself.", "helpfulness_rationale": "The reviewer provides clear and actionable feedback on a potential improvement (using DICOM and FastMRI) and suggests a way to evaluate it ('inference speed'). The suggestions are specific and point the authors towards concrete steps they can take. While it doesn't suggest improvements to the *method* itself, it's a valuable suggestion for data choices and experimental setup."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states 'ProtPainter just provides an empirical conformation estimation.' This is a statement of observation or limitation. While it implies a lack of optimization and validation, the comment itself does not explicitly state an action or suggestion on how to address this limitation. The reviewer is pointing out a problem, but not providing a concrete stepbystep guide on how to fix it.", "grounding_specificity_rationale": "The comment refers to 'ProtPainter' and 'binder design' generally. It does not pinpoint a specific section, table, figure, or unique aspect of ProtPainter related to conformation estimation. The reviewer is referring to a tool and a general area of application, but not a specific instance within the paper.", "verifiability_rationale": "The comment states 'ProtPainter just provides an empirical conformation estimation.' This is a statement of observation or limitation. While it implies a lack of optimization and validation, the comment does not explicitly claim that ProtPainter *only* does empirical estimation and lacks optimization and validation. There is no logical reasoning, common knowledge, or external references provided to support this statement as a claim that needs verification.", "helpfulness_rationale": "The comment identifies a limitation of ProtPainter regarding its conformation estimation method. While it doesn't explicitly suggest how to optimize or validate the process, it points out a clear gap in the current functionality. This highlights a potential area for improvement and suggests that the tool could be enhanced. Identifying a missing feature or optimization opportunity is generally helpful for the authors in improving their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point directly asks what happens in a specific scenario involving CAD models and SV BRDF maps. The action is to consider the implications of this association. The action is explicit because the question itself defines the action. The action is also concrete because it asks about a specific relationship between two welldefined elements.", "grounding_specificity_rationale": "The review point explicitly mentions 'CAD models' and 'spatiallyvarying (SV) BRDF maps'. This clearly identifies the specific parts of the paper being addressed. The grounding is full because the section, table, figure, or unique aspect being addressed is precisely named. The specificity is high because the review point clearly specifies what is being asked about: the association between these two specific elements.", "verifiability_rationale": "The review point is a question, not a declarative statement. It does not contain a claim that needs to be verified. However, the question prompts the authors to consider a specific scenario and its implications, which can be seen as implicitly verifiable by understanding the concepts involved. The question itself is meaningful and guides the authors to think about a potential constraint or requirement.", "helpfulness_rationale": "The review point is a direct question about a specific scenario involving CAD models and SV BRDF maps. It prompts the authors to consider the implications of associating a CAD model with spatiallyvarying BRDF maps. This is a meaningful point that guides the authors to think about a potential constraint or requirement, making it helpful for improving their draft by highlighting a specific consideration."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the connection between NGD, NGF, discretization, and IVPs. They also explicitly suggest that initialization plays a role *similar* to pretraining. This provides a clear action for the authors to take \u2013 explore the connection between initialization and pretraining in the context of NGD and NGF.", "grounding_specificity_rationale": "The reviewer refers to established concepts like \"NGD,\" \"NGF,\" \"discretization,\" and \"IVP.\" While they don't point to a specific section, these are common terms in the field. The suggestion to treat initialization like \"pretraining\" is a specific direction, even though the details of how to do this are not elaborated upon. The grounding is present, but not as explicit as pointing to a specific section or table.", "verifiability_rationale": "The reviewer makes claims about the relationship between NGD, NGF, discretization, IVPs, and initialization. They also claim that initialization should be treated like pretraining. The reviewer provides *reasoning* by stating the established connection between NGD, NGF, and discretization, and the general understanding of IVPs. They also provide a *justification* by suggesting the analogy to pretraining. However, they do not provide specific *examples* or *references* to support this specific connection in their paper.", "helpfulness_rationale": "The reviewer identifies a potential connection between existing concepts (NGD, NGF, discretization, IVPs) and suggests a practical application (initialization like pretraining). This provides a valuable direction for the authors to explore. However, the lack of concrete examples, references, or a detailed explanation of *how* this connection can be leveraged makes the suggestion somewhat vague and less immediately actionable. While it points to a potential area for improvement, it doesn't provide a fully fleshedout solution."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two potential issues. First, it states 'It is not clear how named entities were extracted from the datasets.' This implies an action, but it's not explicitly stated. Second, it suggests 'An Englishproofreading would significantly improve the readability of the paper.' This is an explicit action. While the first part could be made more explicit, the second part is clearly stated. Therefore, the review point has an implicit action and a clear action, making it 3.", "grounding_specificity_rationale": "The review point mentions 'named entities were extracted from the datasets' but doesn't specify which part of the dataset or how the extraction was performed. This makes the grounding weak. Similarly, it suggests 'An Englishproofreading would significantly improve the readability of the paper' but doesn't specify which section needs proofreading or how it should be done. Therefore, the grounding is weak for both aspects, making it 2.", "verifiability_rationale": "The review point states 'It is not clear how named entities were extracted from the datasets' but doesn't provide any evidence or justification for why this lack of clarity is a problem or how it should be addressed. Similarly, it suggests 'An Englishproofreading would significantly improve the readability of the paper' but doesn't provide evidence or justification for why proofreading improves readability or how to perform the proofreading. Therefore, the claims made are 1.", "helpfulness_rationale": "The review point identifies potential issues that could hinder the authors' work ('It is not clear how named entities were extracted from the datasets') and suggests a concrete action to address them ('An Englishproofreading would significantly improve the readability of the paper'). While the justification for the lack of clarity is weak, the suggestion for proofreading is clear and actionable. Therefore, the review point is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'Mistakes in Eqs.' which indicates a problem with the equations. While it doesn't directly tell the author what to do, it points to a specific area needing attention. Therefore, it can be considered 3 as it identifies a concrete issue.", "grounding_specificity_rationale": "The comment explicitly refers to 'Eq. W4', which is a specific equation number. This demonstrates full grounding as the author can easily identify the referenced part of the paper. The comment also asks a specific question about the 'division of the number of samples' within that equation, which clearly specifies what needs to be addressed. This makes it fully specific.", "verifiability_rationale": "The comment does not contain a claim. It is a question about the content of a specific equation. There is no assertion that something is correct or incorrect, or a suggestion to do something. Therefore, it does not have verifiability in the sense of supporting a claim.", "helpfulness_rationale": "The comment is very specific about a potential issue in the equations. By asking a question about the 'division of the number of samples' in Eq. W4, it encourages the author to carefully review that specific part of their work. While it doesn't provide a direct solution, it points to a concrete area that needs correction, making it 3 in identifying a problem."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point highlights a problem (uncertainty in annotations) but does not provide any concrete actions or suggestions for the authors to take. It asks questions, which are queries, not actions.", "grounding_specificity_rationale": "The reviewer refers to 'authors' and 'such objects' generally, without specifying which part of the paper or which objects are being discussed.", "verifiability_rationale": "The review point is a statement of observation and inquiry, not a claim that requires verification.", "helpfulness_rationale": "The review point identifies a valid limitation and asks relevant questions, prompting further discussion and consideration. While it doesn't offer a direct solution, it highlights an area where the authors might need to improve or clarify their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly suggests including GPT3.5 experiments, which is an actionable step. However, it lacks specific details on how to implement this change or what modifications are needed in the current setup. Therefore, it is 3.", "grounding_specificity_rationale": "The review point makes a general suggestion about including a different model without specifying any particular section, table, figure, or unique aspect of the paper. There is no indication that the reviewer is referring to a specific part of their work. Thus, it is 1.", "verifiability_rationale": "The review point is a suggestion to include an additional experiment, not a claim that needs verification. There is no logical reasoning, common knowledge, or external references provided. Therefore, it is 1.", "helpfulness_rationale": "The review point suggests an additional experiment using a potentially less expensive model. While this could be beneficial for costeffectiveness, it doesn't directly address any specific weaknesses or issues in the author's current work. It's a suggestion for improvement but not a critique or a solution to a problem. Hence, it is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a desire for clarification regarding the word 'confident'. This is an explicit action. However, the comment does not specify *what* is confusing about 'confident' or provide any details on how to apply it. The suggestion is general ('some slight rephrasing would be great').", "grounding_specificity_rationale": "The reviewer is referring to the word 'confident' in the context of the sentence 'We have found it easier to be confident about applying ceterus paribus convexity;'. While they could have potentially inferred the meaning of 'confident' or even pointed to the word itself, they chose to be explicit. Therefore, it's closer to 'Weak Grounding' as they are making an educated guess about the part of the text. The comment specifies what needs to be addressed (clarification on 'confident'), but it doesn't specify *why* the reviewer finds it unclear or *how* the clarification should be applied.", "verifiability_rationale": "The comment is a suggestion for clarification, not a claim requiring verification. It doesn't present an opinion, judgment, or suggestion that needs to be supported by evidence.", "helpfulness_rationale": "The reviewer is pointing out a potential area of confusion for the authors by highlighting the use of the word 'confident'. They are asking for clarification on what this word means in this specific context and if it refers to model confidence or human interpretability. While they offer a general suggestion ('some slight rephrasing would be great'), they don't provide specific examples or propose concrete changes to the text."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states several actions the authors should take, such as adding axis labels, removing maskedout portions of curves, and conducting singleseed experiments. These are all concrete and directly actionable steps. The reviewer also suggests polishing the figures, which is a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer identifies specific elements within the figures and the experimental setup that need improvement. They mention 'axis labels,' 'curves,' 'small scale datasets,' and 'single architecture type.' This demonstrates a strong grounding as the authors can directly identify the problematic parts of the paper and the issues within them.", "verifiability_rationale": "The reviewer makes a claim about the impact of the identified issues on the clarity and confidence in the empirical results. They provide specific examples (missing axis labels, masked curves, etc.) as evidence for this claim. The logical reasoning is clear: these visual and experimental issues directly hinder understanding and trust in the results.", "helpfulness_rationale": "The review point is 5 because it directly points out specific weaknesses in the figures and proposes concrete improvements. The suggestions are actionable and directly address observable issues, making it easy for the authors to understand and implement the recommendations."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The question is explicit in asking for a justification for using 'number of weight updates' instead of 'number of network updates'. While it doesn't directly instruct the authors on what to do, it clearly identifies a potential area for clarification and improvement in the paper's methodology description. The reviewer is prompting for a direct comparison and reasoning behind this choice.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'network updates' and 'weight updates', which are specific technical terms commonly used in the context of neural networks and parallel processing. They are also referencing the concept of the brain's parallel processing. This demonstrates a good understanding of the relevant terminology and the context in which these terms are used. Therefore, the grounding is strong.", "verifiability_rationale": "The reviewer is implicitly claiming that the paper lacks a clear justification for choosing 'number of weight updates' over 'number of network updates'. They are suggesting that the paper needs to provide a reasoning or explanation for this choice. While they don't provide external references or examples at this point, the implication is that the current explanation is lacking. Therefore, the claim is underspecified as it points to a potential gap in the paper's justification.", "helpfulness_rationale": "The reviewer directly asks for a justification for a methodological choice ('why is the number of weight updates a better metric than the number of network updates?'). This is a clear and actionable question that directly addresses a potential weakness in the paper's methodology description. The request for 'additional feedback' further enhances the helpfulness of this comment by prompting the authors to elaborate on their reasoning. This comment is highly valuable for improving clarity and understanding."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point asks a question about the objective of adversarial prediction accuracy, which is not a direct instruction or suggestion for the author to improve their work. It does not specify what needs to be changed or how to approach the problem. The reviewer is asking for context rather than actionable feedback.", "grounding_specificity_rationale": "The review point does not identify a specific part of the paper or a particular issue related to adversarial prediction accuracy. It is a general question about the objective of this metric, not a critique or suggestion about a specific section or element of the author's work. The reviewer is asking about the purpose of a metric, not about a flaw or improvement in the author's research.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It is a question posed to the author, not a statement that needs to be supported by evidence. While the answer to the question might involve discussing adversarial attacks or robustness, the review point itself lacks a claim to be verified.", "helpfulness_rationale": "The review point is a question seeking information about the objective of adversarial prediction accuracy. While this information might be helpful for the author to understand the context, it does not directly suggest or guide them on how to improve their draft. It is a request for clarification rather than a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The statement explicitly identifies a potential issue regarding the contrastive learning framework. However, it doesn't directly instruct the authors on what specific changes to make or how to verify this claim. The reviewer points to a specific type of framework (contrastive learning) and its potential similarity to SimCLR, but doesn't provide a clear action for the authors to take.", "grounding_specificity_rationale": "The reviewer mentions 'SimCLR' as a contrastive learning framework. This provides some grounding as 'SimCLR' is a specific technical term. However, the reviewer doesn't explicitly state which section, table, or unique aspect of the paper is being addressed. The reference to 'SimCLR' itself is somewhat vague, as there might be multiple contrastive learning frameworks discussed in the paper.", "verifiability_rationale": "The reviewer makes a direct claim: 'The contrastive learning framework is the same as SimCLR.' This is a claim that *could* be verified by checking the paper's content. However, the reviewer doesn't provide specific evidence or references to support this claim, making it difficult to verify without further information or context from the authors.", "helpfulness_rationale": "The statement is factually correct (assuming SimCLR is indeed the framework used). However, the impact of this feedback depends on the authors' understanding of the SimCLR framework and its relevance to their work. If the authors are not familiar with SimCLR, this comment might not be very helpful. If they are, it could be quite helpful in clarifying their understanding or potentially pointing out a misunderstanding."}
{"actionability_label": "3", "grounding_specificity_label": "3: UnderSpecific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point implicitly suggests a potential improvement by mentioning 'making comparisons more systematic' but does not explicitly state what needs to be done or how to achieve this systematic approach. The action is implied but not clearly defined.", "grounding_specificity_rationale": "The reviewer mentions 'the present paper explains how it is different' but does not specify which section or part of the paper this explanation refers to. This makes it difficult for the authors to pinpoint the exact location of the explanation and understand what might be improved. The grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point contains a claim that 'the present paper explains how it is different' and 'gives comparisons in simulations'. These claims could potentially be supported by checking the paper for the mentioned explanation and comparisons. However, the reasoning behind why these comparisons are not 'more systematic' is not explicitly stated, and specific examples of how the best performance of each method is determined are missing. While a claim exists, the supporting evidence is incomplete.", "helpfulness_rationale": "The review point identifies a potential area for improvement by suggesting a more systematic comparison of best performances. This is a specific and actionable suggestion that directly addresses a potential weakness in the current approach. While the suggestion itself might not be fully developed, it provides a clear direction for the authors to consider. The reviewer is pointing out a concrete area for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a missing element ('time complexity estimation') but does not explicitly state how the authors should go about estimating it or how this estimation would improve the paper. While it implies the importance of this estimation for scalability, it lacks concrete action steps. The comment is somewhat implicit, suggesting an improvement rather than directly instructing an action.", "grounding_specificity_rationale": "The comment refers to 'the learning algorithm' in general, without specifying a particular part of the paper, a section, a table, a figure, or a unique element within the algorithm. It does not clearly identify what needs to be estimated or improved within this general context. The grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The comment does not contain a claim that can be verified. It is a suggestion or a request for information ('should be estimated') rather than a statement that can be supported by evidence or logical reasoning. Therefore, it does not meet the criteria for verifiability, which requires a claim to be made and supported.", "helpfulness_rationale": "The comment is a suggestion to estimate the time complexity of the learning algorithm to prove scalability properties. While this points towards an improvement, it does not provide specific, actionable feedback on what is wrong with the current draft or how the suggested change should be implemented. It lacks constructive feedback and is more of a forwardlooking suggestion than a critique or a direct feedback point. Therefore, it is not 5 as it does not directly address the authors' work."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the suggestion to investigate the connection to universal kernels, which is a clear action. While the specifics of the investigation are not detailed, the intention to explore this connection is welldefined.", "grounding_specificity_rationale": "The reviewer mentions 'properties of universal kernels' and specifically points to 'chapter 4 of Steinwart and Christmann'. This indicates a clear identification of the section of external work being referenced, demonstrating strong grounding. However, the exact nature of the connection and the specific issue in the reviewed paper remains vague.", "verifiability_rationale": "The reviewer proposes a suggestion to investigate a connection, which constitutes a claim. However, within this review point, there is no explicit justification or evidence provided to support this claim. The suggestion is presented without a logical reasoning or reference to existing literature within this specific review.", "helpfulness_rationale": "The reviewer suggests investigating a connection to a specific area of theory, which has the potential to guide the authors towards improvements. However, the impact of this suggestion is uncertain without knowing the specific context of the reviewed paper. The reviewer's intention is to provide a direction for improvement, making it potentially helpful, but the lack of concrete details makes it difficult to definitively assess its helpfulness."}
