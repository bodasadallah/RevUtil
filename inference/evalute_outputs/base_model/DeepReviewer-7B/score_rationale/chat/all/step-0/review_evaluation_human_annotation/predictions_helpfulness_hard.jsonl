{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a potential issue with the description of HIERENC, suggesting that averaging representations of all possible entity instantiations could introduce noise. While the reviewer clearly states their understanding of the process, they do not explicitly recommend a solution or provide a concrete action for the authors to take. The reviewer's point is about identifying a potential problem, but lacks a direct, actionable recommendation.", "grounding_specificity_rationale": "The reviewer mentions 'HIERENC' in their review point, indicating an understanding of the component. However, they do not explicitly state which section, table, or figure discusses HIERENC, nor do they provide a precise description of the issue. The reviewer's comment is about the *concept* of HIERENC's input, but lacks a specific reference to the relevant part of the paper.", "verifiability_rationale": "The reviewer states their understanding of HIERENC's input calculation, describing it as the average of representations of all instantiations of context filled by every possible entity in the vocabulary. This statement is a claim that requires verification. The reviewer provides a logical reasoning to support their claim, explaining that this process could introduce noise. The claim is supported by a clear explanation of the reasoning.", "helpfulness_rationale": "The reviewer's point is about improving the clarity of the description of HIERENC and preventing potential noise in the input representation. This is a helpful suggestion for the authors as it directly addresses a potential implementation detail that could hinder their understanding and the overall quality of their work. The reviewer's point is about identifying a potential issue that could be addressed."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential bias in the interpretation of the results, which can be seen as an implicit action to highlight a limitation in the current analysis. However, the reviewer does not provide specific concrete actions or suggestions on how to address this bias. The action is implied but not explicitly stated with details on how to implement it.", "grounding_specificity_rationale": "The reviewer refers to a general cognitive bias, which is grounded in their understanding of the field. They are not referring to a specific section or table. The reviewer points out a potential bias in the interpretation of the results, which is specific to the interpretation of the results section. However, the reviewer does not explicitly name a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a subjective observation about the interpretation of the results.", "helpfulness_rationale": "The reviewer raises a valid concern about a potential bias in the interpretation of the results. This is a helpful observation for the authors, as it points out a potential area for improvement in their analysis. While the reviewer does not provide a solution, the identification of the issue is valuable. The comment is subjective but it highlights a potential weakness in the interpretation of the results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about interpreting results in Table 3 and makes comparative statements about different models. It does not explicitly state an action or provide a solution. While it implies a desire for the authors to understand the implications of the statistical similarities, it doesn't tell them *how* to achieve this. The action is implied rather than explicit.", "grounding_specificity_rationale": "The review point refers to 'results shown in Table 3' and discusses 'Chinese MOSQ', 'GT Mel A', 'Chinese and English MOSV', 'Baseline', and 'NSVB'. While it mentions specific terms and models, it doesn't explicitly identify the *specific* section, table, figure, or unique aspect of the paper being addressed. The grounding is implied but not fully explicit.", "verifiability_rationale": "The review point states that 'For results shown in Table 3, how to interpret: (a) For Chinese MOSQ, NVSB is comparable to GT Mel A. (b) For Chinese and English MOSV, Baseline and NVSB have overlapping 95% CI.' While it refers to statistical comparisons and overlapping confidence intervals, it doesn't provide any external references or logical reasoning to support these observations. The verifiability is based on the authors' existing understanding of statistical concepts rather than new evidence presented in the review point itself.", "helpfulness_rationale": "The review point asks a question about interpreting results and makes comparative statements. While it prompts the authors to consider the implications of the statistical similarities, it doesn't provide a clear action or solution. The helpfulness lies in guiding the authors towards a deeper understanding of the findings, but it doesn't offer a concrete path forward for improvement. The lack of a clear next step makes it less helpful than a point that explicitly states how to change the models based on the findings."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that using integrated gradients has been studied, which is a direct identification of a lack of novelty. They also explicitly mention the proposed postprocessing steps and the lack of an ablation study, which are concrete actions or actions that can be inferred. The reviewer provides specific details about the postprocessing steps and the absence of an ablation study, making the actionable nature quite clear.", "grounding_specificity_rationale": "The reviewer refers to 'postprocessing steps' and 'ablation study' without explicitly pointing to a specific section, table, or unique aspect of the paper. While the *concept* of postprocessing is implied, the *specific steps* are mentioned. This indicates a lack of precise identification of the referenced part. However, the reviewer clearly specifies what is missing (lack of ablation study) and what is being questioned (importance of postprocessing steps). This makes the specificity quite clear, albeit the grounding is weak.", "verifiability_rationale": "The reviewer makes claims about the lack of an ablation study and the existence of postprocessing steps. These claims can be assessed by examining the paper's content. The reviewer provides specific details about the postprocessing steps and the absence of an ablation study, which allows for logical reasoning and verification against the paper's content.", "helpfulness_rationale": "The reviewer's point is that the paper could be improved by including an ablation study to demonstrate the importance of the proposed postprocessing steps. This is a constructive criticism aimed at improving the paper's rigor and impact. The reviewer provides a clear suggestion and explains why it would be beneficial, making the feedback actionable and valuable for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a lack of clarity regarding a specific baseline (MST) and suggests the inclusion of more baselines based on related work. While the reviewer identifies a potential area for improvement, the action of clarifying the MST baseline is not explicitly stated, and the suggestion to include more baselines is presented as a request rather than a direct action. The vagueness of the suggestions makes it difficult to pinpoint exactly what needs to be done.", "grounding_specificity_rationale": "The reviewer mentions 'MST baseline' and 'soft vs. hard word sense disambiguation' in their review point. While they don't explicitly name a specific section or table, they do point to a particular aspect of the paper that they believe needs clarification. This can be considered 'Weak Grounding' as the authors can infer the relevance of the MST baseline and the comparison between soft and hard word sense disambiguation. However, the reviewer doesn't explicitly state what is unclear within this area, making the specificity somewhat lacking.", "verifiability_rationale": "The reviewer states, 'It is unclear how the proposed models compare to models that only consider different senses but not sememes.' This statement is a claim that requires justification. However, the reviewer does not provide any evidence, reasoning, or external references to support this claim. The lack of verifiability is due to the absence of any supporting arguments or references.", "helpfulness_rationale": "The reviewer's comment is a suggestion for improvement and a request for clarification. While it encourages the authors to consider additional baselines and improve their model comparisons, it doesn't directly instruct them on how to implement these changes. The suggestions are somewhat vague, and the request for clarification doesn't inherently provide a solution. Therefore, while the comment has the potential to be helpful, the lack of concrete actions makes it somewhat unhelpful in its current form."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the selection process for 'frame similarity factors' and 'attributes similarity factors' is unclear. This makes the action explicit. However, the point does not specify *how* the selection is unclear or what the implications are, making it vague.", "grounding_specificity_rationale": "The review point mentions 'frame similarity factors' and 'attributes similarity factors,' which are specific technical terms. This allows for a reasonable inference that the reviewer is referring to specific parts of the paper. However, the point does not specify *which* specific sections, tables, or figures these factors relate to, making the grounding weak. The point also identifies a lack of clarity in the *selection process* of these factors, which is a specific area of concern, but it doesn't detail *what* is unclear within that process, making the specificity underspecific.", "verifiability_rationale": "The review point is a statement of a problem: 'It's a bit unclear how the frame similarity factors and attributes similarity factors are selected.' This is a claim that needs to be addressed, but it doesn't provide any evidence, justification, or references to support this statement. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point identifies a genuine lack of clarity in the methodology regarding the selection of 'frame similarity factors' and 'attributes similarity factors.' This is a valid point that could hinder the authors' understanding and reproducibility. However, the review point does not offer any suggestions or ask clarifying questions to address this issue. It simply states the problem, which is helpful but not fully constructive."}
{"actionability_label": "Partially Actionable", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that 'sentence classification is an easier task\" and \"the proposed augmentation method has potential to be used on more NLP tasks.\" These statements identify potential weaknesses and areas for improvement. However, the reviewer does not provide specific instructions on how to address these points. For example, they don't suggest specific changes to the experimental setup to make it more challenging or how to adapt the augmentation method for other NLP tasks. Therefore, while the reviewer points out potential issues, the lack of concrete steps makes the actionable level low.", "grounding_specificity_rationale": "The reviewer mentions 'sentence classification is an easier task\" and \"the proposed augmentation method has potential to be used on more NLP tasks.\" While these statements point to potential weaknesses and areas for improvement, the reviewer does not explicitly identify a specific part of the paper being addressed. They don't mention a particular section, table, figure, or unique element of the paper where these issues are present. The weakness regarding the lowresource regime and the broader applicability are also not pinpointed to specific aspects. Therefore, the grounding of the criticism is weak.", "verifiability_rationale": "The reviewer makes claims about the task being \"easier\" and the method's \"potential\" applicability. These are opinions or judgments about the paper's content. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. There is no evidence presented to back up the assertion that sentence classification is inherently easier or that the augmentation method is definitively more applicable to other NLP tasks. Therefore, the claims are not wellsupported, resulting in low verifiability.", "helpfulness_rationale": "The reviewer identifies potential weaknesses in the experimental setup and suggests broader applicability of the proposed method. While these points are relevant and could be helpful for the authors, the feedback is somewhat vague. The reviewer doesn't specify *how* the experiments should be adjusted to be more challenging or *how* the method should be adapted for other NLP tasks. The suggestions are general and lack concrete details. Therefore, while the feedback is not entirely unhelpful, it lacks the specificity needed for immediate action. The reviewer's suggestions are in the right direction but lack the necessary detail to be fully helpful."}
{"actionability_label": "Not Applicable", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point does not explicitly state an action or suggest a concrete change to the concept map extraction process. It raises a question about the necessity of a separate task and offers a potential alternative (general summarization) but does not directly tell the author what to do or how to implement a change.", "grounding_specificity_rationale": "The reviewer mentions 'node number' as a potential reason for questioning the separate task. While 'node number' could be interpreted as a weak ground (mentioning a specific aspect of the concept map), the reviewer does not explicitly identify a specific section, table, figure, or unique element of the paper where this issue is occurring. The grounding is implied but not explicitly stated.", "verifiability_rationale": "The reviewer presents a suggestion (general summarization) and provides a reason ('redundancy, readability') for it. The reasons are logical and provide some justification for the suggestion. However, the reviewer does not provide specific examples or citations to support the claim that general summarization is sufficient or that concept map extraction is redundant.", "helpfulness_rationale": "The reviewer raises a valid point about the potential redundancy of a separate concept map extraction task and suggests that general summarization might be sufficient. This offers the author a potential alternative and prompts them to consider the efficiency and readability of their process. While the reviewer doesn't directly tell the author what to do, the point is relevant to their work and could be helpful in guiding their thinking."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points to a specific section (lines 102106) and criticizes the writing style. However, the criticism is broad and lacks specific details on what is misleading. The reviewer doesn't explicitly state what needs to be changed, making it implicit and vague.", "grounding_specificity_rationale": "The reviewer mentions \"lines 102106,\" which grounds the comment to a specific part of the paper. However, they use the vague phrase 'such distribution\" without specifying which specific aspect of the distribution is problematic.", "verifiability_rationale": "The reviewer states that the writing in lines 102106 is \"misleading,\" which is a claim. However, they do not provide any examples, references, or explanations to support this claim, making it 1.", "helpfulness_rationale": "The reviewer identifies a potential issue in the paper ('such distribution is misleading\"). However, they do not offer any concrete suggestions or explanations for how to improve the clarity of the distribution. The feedback is general and lacks actionable steps."}
{"actionability_label": "Not Actionable", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "Not Verifiable", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about the sufficiency of the dataset and the nature of style shifts, rather than explicitly stating an action or providing concrete instructions on how to improve the draft. While it encourages investigation, it doesn't tell the authors what to do or how to apply it.", "grounding_specificity_rationale": "The review point asks general questions about the dataset and style shifts without specifying a particular aspect of the paper or the authors' draft. The authors could interpret 'style shifts' broadly, and there's no clear indication of which part of their work is being referenced.", "verifiability_rationale": "The review point itself does not contain a claim that can be verified. It's a question prompting further investigation rather than a statement that requires justification. While it encourages the authors to look for evidence, it doesn't provide any specific examples or references to support its claims.", "helpfulness_rationale": "The review point raises relevant questions about the dataset and potential limitations, which could be helpful for the authors to consider. However, it doesn't provide concrete actions or evidence to help them improve their draft. It's more of a prompt than a direct critique offering actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point is a statement of fact: 'However, there is no corresponding set of tools for the reinforcement learning setting.' It does not explicitly or implicitly suggest any action or improvement based on this fact. The reviewer is pointing out a discrepancy, not proposing a solution.", "grounding_specificity_rationale": "The review point explicitly mentions 'the reinforcement learning setting.' This is a specific part of the paper, and the reviewer clearly identifies the area being addressed. This demonstrates strong grounding specificity.", "verifiability_rationale": "The review point presents a claim: 'However, there is no corresponding set of tools for the reinforcement learning setting.' This claim can be verified by examining the paper for the existence of such tools. The reviewer is making a statement that can be supported or refuted through evidence, thus having verifiability.", "helpfulness_rationale": "The review point identifies a factual error: the claim that there are no tools for reinforcement learning is false. While this is helpful in correcting a misconception, it doesn't directly suggest a specific improvement or action for the authors. It's a correction rather than a constructive suggestion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states the absence of a link to relevant prior work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. The reviewer also mentions the similarity in structure and inference capabilities of these works to the authors' approach. This provides a clear and direct suggestion for improvement, indicating a concrete action the authors should take.", "grounding_specificity_rationale": "The review point explicitly names the specific works 'Continuous Conditional Random Fields Ristovski 2013' and 'Continuous Conditional Neural Fields Baltrusaitis 2014'. This is a clear and precise identification of the relevant parts of the paper, making the grounding fully grounded. Furthermore, the reviewer explicitly states that these works have a 'similar structure' and 'ability to perform exact inference', which clearly specifies what needs to be addressed.", "verifiability_rationale": "The review point contains a claim: 'Missing link to similar work...'. This claim is supported by the reviewer explicitly naming the relevant works and highlighting their similarities in structure and inference capabilities. The logical reasoning and references provided are clear and specific, making the verifiability 5.", "helpfulness_rationale": "The review point is 5 because it directly identifies a clear weakness in the authors' work: the absence of discussion and comparison to relevant prior work with similar structures and inference capabilities. The suggestion to include a link to these works is a concrete and actionable improvement that the authors can readily implement."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a problem (tersely written section) but lacks a specific action or suggestion on how to improve it. The suggestion is vague ('slower development'). Therefore, it's not actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 4,' indicating they have identified the specific part of the paper being addressed. This is strong grounding. However, the suggestion is general and lacks specificity about *what* is wrong in that section.", "verifiability_rationale": "The review point states a fact ('Section 4 is very tersely written') but does not present a claim that requires verification or justification. It's a descriptive statement.", "helpfulness_rationale": "The review point identifies a valid weakness in the paper but fails to provide concrete, actionable feedback on how to address it. The suggestion is general and lacks specificity about *how* to make the section less terse. It's a critique without a prescription."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the need for a table showing the distribution of video lengths and an explanation of the balancing process. While it doesn't use explicit action words, the suggestions are direct and prescriptive. The reviewer is implying the need for a concrete action.", "grounding_specificity_rationale": "The reviewer points out a specific lack of information in the paper's description regarding video length distribution. They are implicitly grounding the feedback in the absence of this information. While not explicitly stating the category, the focus is very clear.", "verifiability_rationale": "The reviewer provides a clear and actionable suggestion: 'include a table showing the distribution of video lengths' and 'explain how they ensured a balanced representation'. The reasoning behind these suggestions is also stated, making the verifiability high. The reviewer is not making a claim that something is missing, but rather what is missing and how to address it.", "helpfulness_rationale": "The review point directly addresses a potential weakness in the paper's description by highlighting the missing information on video length distribution and providing concrete suggestions for improvement. The suggestions are specific and actionable, making this review point 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X (X)", "helpfulness_label": "2", "actionability_rationale": "The comment implies the dataset is missing and suggests a cautious approach, but it doesn't explicitly state what is missing or how to act upon it.", "grounding_specificity_rationale": "The comment identifies the \"dataset\" as the specific part of the paper. However, it doesn't specify what is missing about the dataset or why it's not available.", "verifiability_rationale": "The review point is a statement of fact (or lack thereof) and doesn't present a claim requiring external verification or logical reasoning to be accepted.", "helpfulness_rationale": "The review points out a potential problem but lacks specific details about the missing dataset or what the cautious approach entails, making its helpfulness limited."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the action of including related work A and provides a clear reason why it's important.", "grounding_specificity_rationale": "The review point explicitly mentions a specific related work A and highlights its importance, making it easy for the authors to identify and understand the relevance of this work.", "verifiability_rationale": "The review point makes a claim about the importance of modular networks for VQA and that related work A is crucial. It also provides a reason for this claim, which can be verified by looking at the cited work and the broader VQA literature.", "helpfulness_rationale": "The review point is highly specific about a missing element (discussion of modular networks) and provides a clear and actionable next step (include related work A). The emphasis on the cruciality of A makes this review point very helpful for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the performance drop in the ablation experiment and highlights the missing data in the tables. This provides clear information for the authors to understand a potential issue in their experimental setup and results. The reviewer directly points out a discrepancy and a lack of information, which are actionable insights.", "grounding_specificity_rationale": "The reviewer identifies a specific ablation experiment and the absence of results for 'without reinforcement learning' and 'without dependency tree' in the tables. However, they do not explicitly state where in the tables these results should be found (e.g., a separate section or highlighted rows). The grounding is present in the *content* of the ablation experiment, but the specific location of the missing data within the presented tables is not clearly indicated.", "verifiability_rationale": "The reviewer makes a claim about the absence of specific information ('the two tables do not list the cases where dependency tree and RL are not used'). This claim can be verified by examining the tables (which are not provided here, but the reviewer's statement about them is the evidence). The reviewer provides a clear statement and implies a lack of specific data.", "helpfulness_rationale": "The reviewer's point about the missing information in the tables is directly relevant to the authors' ability to understand and improve their draft. By highlighting the absence of specific results, the reviewer draws attention to a potential weakness in the experimental evaluation and encourages the authors to check their results presentation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer states they found the distinction between static and temporal features confusing because the paper doesn't clearly define 'S' and 'Xt'. While the reviewer identifies a problem, the action is implicit (implying the paper needs clearer definitions). The reviewer doesn't explicitly state what they would do to improve the paper based on this comment.", "grounding_specificity_rationale": "The reviewer explicitly states that the paper does not define 'S' and 'Xt', which are key elements of the paper. The reviewer can accurately pinpoint the section where the confusion arises, indicating strong grounding. The comment clearly specifies what needs to be addressed in this part (the lack of definition for key variables).", "verifiability_rationale": "The reviewer states that they found the notation / the explicit split between 'static' and temporal features into two variables confusing, at least initially. This is a claim that the paper is confusing. While the reviewer's confusion is based on their interpretation of the paper's lack of clarity, the claim itself is verifiable as it points to a specific area where the paper is lacking. The reviewer provides a specific example of where the paper is unclear, making it 3.", "helpfulness_rationale": "The reviewer explicitly states that they found the notation / the explicit split between 'static' and temporal features into two variables confusing, at least initially. This directly points to an area where the paper needs improvement. The reviewer's comment is specific and actionable in identifying a need for clearer definitions. The comment is directly helpful in guiding the authors to improve their draft by clarifying these variables."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states areas where more details are needed, such as the definition of 'resistance distance' and more explanations for Algorithm 1 with brief definitions of A_t, Y_t, etc. These are direct actions the authors can take to improve their paper.", "grounding_specificity_rationale": "The reviewer can identify the specific part of the paper being addressed, which is Algorithm 1, and they provide specific suggestions for improving the clarity of A_t and Y_t. The mention of 'Alg. 1 with brief sentences defining A_t, Y_t,...' indicates a clear understanding of the relevant section and its components.", "verifiability_rationale": "The review point contains a claim ('the writing is generally good though more details could sometimes be provided') but does not provide any logical reasoning, common knowledge, or external references to support this claim. It simply states an observation about the writing quality.", "helpfulness_rationale": "The review point provides actionable feedback by suggesting specific areas where more detail is needed. While it doesn't critique the work itself, it offers concrete suggestions for improvement, which is generally helpful for authors to clarify their methodology and enhance the paper's clarity."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing information: 'certain parameters are bounded on one side (acceleration and scaling parameters)'. This provides a clear target for improvement. The reviewer also suggests an action: 'Consider introducing the aspects of the specific model that are specific to this example model'. This is a direct instruction on how to address the identified weakness.", "grounding_specificity_rationale": "The review point refers to 'the specific model' and mentions 'acceleration and scaling parameters'. While it doesn't have an explicit section number or point to a unique part of the paper like a table or figure, it does specify the parameters involved. This makes the grounding somewhat specific but not fully precise.", "verifiability_rationale": "The review point makes a claim: 'Consider introducing the aspects of the specific model that are specific to this example model'. This claim is supported by the context of the paper and the mention of 'acceleration and scaling parameters'. While it doesn't provide a direct citation at this point, the suggestion itself acts as a form of implicit justification. The reviewer is indicating that understanding these specific parameters is important for the model's implementation.", "helpfulness_rationale": "The review point is 5 because it directly identifies a potential weakness in the model (lack of bounds on certain parameters) and provides a relevant suggestion for improvement (considering the specifics of the model). The language is clear and actionable."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states their opinion about the required condition for the learning rate, indicating a direct action the authors should take: investigate if the required scaling with sample size is truly necessary or if it's a theoretical construct. The concrete example of the learning rate scaling with the number of samples makes this action clear and actionable.", "grounding_specificity_rationale": "The reviewer refers to a 'required condition' mentioned within the paper they are reviewing, specifically in the context of the learning rate. This implicitly identifies a specific aspect of the paper. The reviewer then elaborates on their experience, stating they 'never see a step size grows with the sample size in practice', focusing on a specific behavior within that required condition. This specificity makes it clear what aspect of the required condition they are questioning.", "verifiability_rationale": "The reviewer makes a claim: 'I never see a step size grows with the sample size in practice'. This is a claim that requires justification. However, the reviewer does not provide any evidence, examples, or references to support this claim. The reasoning is based on their personal experience, which is subjective and lacks logical or external verification. Therefore, the claim is 1 as it stands.", "helpfulness_rationale": "The reviewer's point is helpful in highlighting a potential discrepancy between theoretical requirements and practical experience regarding learning rate scaling. It challenges the authors' assumptions about the required condition. However, the lack of verifiability means the reviewer does not provide a solution or evidence to support their claim. Therefore, while the point is actionable, the lack of supporting evidence makes it less helpful in terms of providing concrete guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states a weakness ('impractical') and suggests an alternative approach ('directly samples unlabeled data from millions of reviews'). The action is to consider the alternative, and the implementation is to sample data differently. The action is clearly defined and the implementation is concrete.", "grounding_specificity_rationale": "The comment explicitly mentions 'unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version)' and 'perfectly balanced'. These are specific elements directly related to the paper's setup. The comment also names a relevant paper in the field, 'Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018', which provides specific examples. The grounding is explicit and the examples are directly relevant.", "verifiability_rationale": "The comment provides a clear justification for the criticism ('impractical') and suggests a wellestablished method ('directly samples unlabeled data from millions of reviews'). The reasoning is logical, and the suggestion is supported by common knowledge in the field. The comment also cites a relevant paper, providing external references. The claim is thoroughly supported.", "helpfulness_rationale": "The comment directly addresses a potential limitation of the authors' setup ('impractical') and provides a concrete alternative ('directly samples unlabeled data from millions of reviews'). This is actionable and provides valuable guidance for the authors. The reviewer is not just pointing out a flaw but suggesting a more realistic and potentially better approach. The suggestion is wellgrounded and supported by a relevant paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the difficulty of sampling from the DPP when eigenfunctions are inaccessible and draws a parallel to the challenges of sampling from leverage scores. This provides a clear action for the authors to take: investigate the connection between these two methods and the implications for sampling from the DPP. The reviewer also infers that the ease of sampling from the DPP is questionable given the difficulties encountered.", "grounding_specificity_rationale": "The reviewer refers to 'Eq (10) line 130' and uses specific terms like 'eigenfunctions e_n's' and 'leverage score'. This clearly identifies the relevant section and the specific technical aspects being discussed. The reviewer also explicitly states the problem of sampling from the DPP in this context, making it clear what needs to be addressed.", "verifiability_rationale": "The reviewer makes a claim about the difficulty of sampling from the DPP when eigenfunctions are inaccessible and draws a parallel to the challenges of sampling from leverage scores. The reviewer provides a logical reasoning for this claim, explaining that the lack of access to eigenfunctions makes the sampling process unclear and draws a connection to the known difficulties of sampling from leverage scores. The reviewer also provides common knowledge about the challenges of sampling from complex distributions.", "helpfulness_rationale": "The reviewer points out a potential technical issue or lack of clarity in a method (DPP sampling). While they don't offer a direct solution, they highlight a specific area that needs attention. The reviewer's statement about the difficulty of sampling from the DPP in this context is a clear indication of a potential problem for the authors. The reviewer also suggests that the ease of sampling from the DPP is questionable given the difficulties encountered, which is a helpful observation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point states a limitation of the study. While it points out a *potential* area for future work, it doesn't directly instruct the authors on *what* to do or *how* to address it. Therefore, it's not explicitly actionable in its current form.", "grounding_specificity_rationale": "The review point refers to \"Prototypical Networks\" and \"fewshot learners\" generally. It doesn't pinpoint a *specific* section, table, figure, or unique element within the paper being addressed. The authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point is a statement of observation, not a claim requiring verification. It's a limitation, not a suggestion that needs evidence.", "helpfulness_rationale": "The review point identifies a valid limitation of the study. It highlights a potential gap in the understanding of episodic training. However, it doesn't offer any suggestions or insights on how to address this limitation. It's a critique, not a helpful suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3: 4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem with Equation 3 and provides concrete suggestions for improvement, such as considering the varying strengths of instances and proposing alternative approaches like weighting or stratified analysis. While the suggestions are highlevel, they clearly indicate an action to be taken.", "grounding_specificity_rationale": "The reviewer mentions 'Equation 3' and the concept of 'modal subset,' indicating a clear understanding of the specific part of the paper being discussed. They also explicitly state the problem with removing all instances, showing a strong grounding in the relevant section of the paper. However, the suggestions for improvement are general and lack specific details on how to implement them within the paper.", "verifiability_rationale": "The reviewer proposes solutions like 'weighting instances based on their modality strength' or 'stratified analysis,' which are logically sound and based on common practices in data analysis. However, they do not provide specific examples or references to external works to support these suggestions, making the verifiability somewhat dependent on the reader's existing knowledge.", "helpfulness_rationale": "The reviewer clearly identifies a potential issue with the current methodology (Equation 3) and offers concrete suggestions for improvement. While the suggestions are not detailed, they are actionable and directly address the identified problem, making the review 5 for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer directly asks a question about the interpretation of equations, which is a clear action the authors should take.", "grounding_specificity_rationale": "While the reviewer doesn't explicitly name the section or table, they are pointing out a specific instance of lack of significance, adding some level of specificity. The connection between the equations and the results is implied.", "verifiability_rationale": "The reviewer identifies a lack of significance and provides a specific example (OfficeHome dataset), suggesting a need for justification or further explanation. They are making a claim (the improvement is marginal) that requires verification.", "helpfulness_rationale": "The reviewer is asking a clear question and pointing out a specific issue (lack of significant improvement on a particular dataset). This has the potential to be very helpful for the authors if they can understand the connection and the significance of the results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that 'To utilize a volumetric representation in the deformation field is not a novel idea' and names a specific prior work, VolumeDeform. This directly identifies a potential lack of novelty and provides a concrete reference point.", "grounding_specificity_rationale": "The comment explicitly mentions 'volumetric representation' and names a specific prior work, VolumeDeform. This directly identifies the area of the paper being addressed and provides a specific example of related work.", "verifiability_rationale": "The comment contains a claim that 'To utilize a volumetric representation in the deformation field is not a novel idea' and provides a specific reference to VolumeDeform. While it doesn't offer a detailed comparison or proof, the mention of a specific prior work serves as evidence supporting the claim.", "helpfulness_rationale": "The comment is helpful in pointing out a lack of novelty in a specific technique and directing the authors to a relevant prior work. It provides context and helps the authors position their work within the existing literature. However, it doesn't explicitly suggest a concrete improvement or modification to the method."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states the paper's approach of using the embedding of the first subword token (\"we take the embedding of the first subword token as the verb embedding.\") and directly suggests an alternative, more common method of averaging subword representations (\"It is also quite common in cases like that to average over the subword representations, which is done e.g. by Hewitt and Manning (2019, footnote 4)(https://aclanthology.org/N191419.pdf).\"). This provides a clear and actionable suggestion for the authors to consider.", "grounding_specificity_rationale": "The comment explicitly mentions \"L.490,\" directly identifying the location in the paper where the proposed method is described. This provides strong grounding for the reviewer's point. Furthermore, the comment clearly specifies the alternative method as \"average over the subword representations.\"", "verifiability_rationale": "The comment presents a suggestion (\"It is also quite common... to average...\") and provides justification (\"which is done e.g. by Hewitt and Manning (2019, footnote 4)(https://aclanthology.org/N191419.pdf).\") to support the claim that averaging subword representations is a common practice. The reasoning is logical and the citation provides evidence.", "helpfulness_rationale": "The comment is informative and provides a concrete alternative to the proposed method. By suggesting averaging subword representations, the reviewer offers a specific and wellsupported suggestion that authors can directly implement. The inclusion of a citation further enhances the helpfulness by providing context and supporting evidence for the suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitations of the AUC and provides concrete suggestions for improvement, such as plotting calibration curves and discussing the differences with traditional methods. These suggestions are direct and actionable, indicating a clear understanding of how the AUC can be improved in the context of clinical scoring. The reviewer is not just critiquing the metric in isolation but offering specific ways to enhance its application.", "grounding_specificity_rationale": "The reviewer mentions concepts like 'AUC,' 'consistency,' 'calibration curves,' 'feasibility,' and 'traditional method.' While these are relevant to the discussion of model evaluation, the reviewer does not explicitly link these concepts to specific sections, tables, figures, or unique aspects of a hypothetical paper being reviewed. The suggestions are general and apply broadly to model evaluation rather than pinpointing a specific part of a specific paper.", "verifiability_rationale": "The reviewer makes a claim about the limitations of the AUC and suggests alternative approaches (calibration curves and feasibility studies). This claim is supported by logical reasoning and common knowledge in the field of model evaluation. The reviewer proposes specific methods to verify the claim, demonstrating a clear understanding of how to validate the suggested improvements. The suggestions are grounded in established practices and provide a clear path forward.", "helpfulness_rationale": "The reviewer provides a clear critique of the AUC's limitations in the context of clinical scoring and offers specific, actionable suggestions for improvement. The reviewer's point is directly relevant to the authors and provides a valuable contribution by highlighting the need for consistency and feasibility in clinical scoring systems. The suggestions are concrete and directly address the perceived limitations of the AUC."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states 'Besides, the experiments seem not too strong and fair to me' and 'why all the baselines use the position kernels', 'why don't we use the default settings of these baselines in the literature?'. These are clear actions or suggestions for the authors. The reviewer also states 'it seems like some baselines related to BO with discrete & categorial variables are missing' and 'The paper also needs to compare its proposed approach with these baselines', which are explicit actions requiring comparison. The reviewer also states 'I think the paper does not mention much about the limitations or the societal impacts of their proposed approach', which is an action requiring the authors to address these aspects. While the actions are somewhat general, they are still explicit and actionable.", "grounding_specificity_rationale": "The reviewer refers to 'all the baselines' and 'BO with discrete & categorial variables'. This indicates a general understanding of the experimental setup and the relevant baselines. However, the reviewer does not pinpoint specific sections, tables, or figures where these issues are occurring. The mention of 'BO with discrete & categorial variables' is a general statement about a type of baseline, not a specific reference to a particular part of the paper. Therefore, while the reviewer identifies the *areas* of concern, the lack of specific section references makes the grounding weak.", "verifiability_rationale": "The reviewer makes several claims: 'Besides, the experiments seem not too strong and fair to me', 'why all the baselines use the position kernels', 'why don't we use the default settings of these baselines in the literature', 'it seems like some baselines related to BO with discrete & categorial variables are missing', 'The paper also needs to compare its proposed approach with these baselines', and 'I think the paper does not mention much about the limitations or the societal impacts of their proposed approach'. These are claims that the reviewer is making as feedback. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The claims are presented as observations and suggestions for improvement.", "helpfulness_rationale": "The reviewer's comments are primarily about the experimental setup, missing comparisons, and lack of discussion on limitations and societal impacts. While these are valid points that could improve the paper, they are suggestions for improvement rather than direct criticisms of the current work. The reviewer does not explicitly state that the current work is flawed or needs immediate fixing. The suggestions are about guiding future work or revisions."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the observation 'Looks like all sparsity patterns do almost equally well' and then asks a question related to this observation: 'Is this something unique to the sparsity detection problem or is this true for GNN in general?'. This indicates an explicit statement with a clear request for clarification, which can be considered an implicit action to understand the implications of the observation.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 4.3: presentation bits > representation bits' when stating the observation. This clearly identifies the specific part of the paper being addressed, indicating full grounding. Furthermore, the reviewer asks a question specifically about the relationship between 'presentation bits' and 'representation bits', adding further specificity to the identified section.", "verifiability_rationale": "The reviewer states 'no insight provided as to what is happening here' and claims that the observation is 'not verified'. This directly indicates a lack of supporting evidence or justification for the observation, making it 1.", "helpfulness_rationale": "The reviewer poses a question and suggests a generalization: 'Section 4.3: presentation bits > representation bits' might be a general issue for GNNs. While the reviewer's intention is helpful in prompting further investigation or clarification, they do not provide a direct action or recommendation based on the observation. The suggestion of a generalization is interesting but not a concrete improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'compare the perspective taken' and 'analyze the perspective' regarding Section 6 and prior efforts. This directly indicates an action the authors should take. The action is to examine the content and viewpoint of Section 6 in relation to the contributions of prior work. This action is concrete as it tells the authors what to do, even if it doesn't specify the exact method of comparison.", "grounding_specificity_rationale": "The review point mentions 'Section 6' and 'prior efforts'. This provides some grounding as the authors can identify the specific part of the paper being referenced. However, it does not specify a particular subsection, table, figure, or unique element within Section 6, nor does it identify a specific prior effort being compared to. The grounding is weak because the authors have to infer the exact scope of the comparison.", "verifiability_rationale": "The review point presents a suggestion for the authors to 'compare the perspective taken' and 'analyze the perspective'. This is a request for the authors to engage in an analysis and potentially identify a benefit. However, it does not contain a claim that can be verified through logical reasoning, common knowledge, or external references. The statement is about what the authors should do, not a statement of fact that requires justification.", "helpfulness_rationale": "The review point suggests comparing Section 6 to prior efforts. This is a relevant and valuable suggestion for improving the manuscript by situating it within the existing literature. While it doesn't provide specific instructions on *how* to perform the comparison, it offers a clear direction for the authors to take, which can be helpful in improving their draft by identifying relevant prior work and contextualizing their contribution. The reviewer is making a suggestion that is likely to be beneficial for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states an assumption about the relationship between performance and the number of training scenarios and suggests an experiment to investigate this. This constitutes an explicit action with clear instructions on how to proceed (vary the number of scenarios).", "grounding_specificity_rationale": "The reviewer refers to 'scenarios used for training' and 'number of scenarios'. While not providing a specific section or table number, the concept is reasonably clear within the context of the paper's description. The reviewer also specifies the purpose of varying the number of scenarios (to examine performance).", "verifiability_rationale": "The reviewer presents an assumption (a claim) about the relationship between performance and the number of scenarios. However, the paper itself does not provide any direct verification or evidence to support this assumption. The suggestion to examine performance with different numbers of scenarios is a logical next step, but the claim itself is not verifiably supported by the paper's content.", "helpfulness_rationale": "The reviewer's point is relevant to understanding the model's behavior and potentially improving it. Suggesting to examine performance with different numbers of scenarios is a valuable direction for further experimentation. However, the point lacks specificity regarding *how* to vary the scenarios or *why* this investigation is crucial. It's a general suggestion rather than a detailed, actionable insight."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point is a question and a hypothetical scenario, not a directive or explicit action to be taken. It doesn't tell the authors what to do or how to apply a change.", "grounding_specificity_rationale": "The review point mentions 'training data disturbances' and 'quality label' generally. It doesn't specify a particular instance of disturbance or detail how it affects the label. The grounding is broad, not pointing to a specific section or table.", "verifiability_rationale": "The review point presents a question and a hypothetical scenario ('if') without providing evidence or justification for the potential impact on the quality label. It doesn't make a claim that can be verified.", "helpfulness_rationale": "The review point raises a valid concern about the impact of training data disturbances on the quality label. It prompts the authors to consider potential weaknesses and the model's robustness, which can be a helpful starting point for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states the *restrictiveness* of the bounded noise assumption and mentions *efforts to extend* it. This is an explicit statement of action. However, it lacks specific details on *how* the bounded noise assumption is restrictive or *how* the cited papers achieve their extensions.", "grounding_specificity_rationale": "The reviewer mentions \"bounded noise assumption,\" 'stochastic optimization literature,\" \"efforts to extend,\" \"bounded noise assumption,\" \"nonconvex world,\" \"TMLR 2023,\" \" Better theory for sgd,\" 'structured nonconvex functions,\" and \"AISTATS 2021.\" This provides multiple points of reference within the paper, indicating a clear understanding of the specific area being discussed. The mention of specific journals and papers adds to the specificity.", "verifiability_rationale": "The reviewer makes a claim: \"The bounded noise assumption, while common, is somewhat restrictive...\" This is a statement of opinion or judgment about a specific aspect of the literature. The reviewer also mentions specific papers (A. Khaled and P. Richt\u00b4arik. Better theory for sgd in the nonconvex world. TMLR 2023. R. Gower, O. Sebbouh, and N. Loizou Sgd for structured nonconvex functions: Learning rates, minibatching and interpolation. AISTATS 2021.) that address extensions of the bounded noise assumption. This provides evidence for the claim, even if it doesn't delve into the specifics of how these extensions work.", "helpfulness_rationale": "The review point identifies a limitation of a commonly used assumption in stochastic optimization and provides references to relevant work addressing this limitation. This is generally helpful for researchers working in this area as it directs them to existing literature and highlights the need for more general noise assumptions. While it doesn't offer a new method or solution, it points towards relevant research directions and helps contextualize the bounded noise assumption."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review points out a relevant gap in the exploration of energy models compared to GANs and VAEs. While it suggests further exploration, it doesn't explicitly state what the author should do to explore energy models further. The connection to a prior VAE paper is mentioned, but the reviewer doesn't provide a concrete action for the author to take based on this similarity.", "grounding_specificity_rationale": "The review mentions \"energy models\" and \"VAEs\" as specific types of models. While it doesn't pinpoint a specific section or table, it clearly identifies the *general area* of the paper being discussed. However, it doesn't specify *which* energy model or *which* specific VAE paper is being referenced. The specificity is limited within the broader categories.", "verifiability_rationale": "The review makes a judgment about the relative unexploredness of energy models and draws a parallel to a prior VAE paper. These are claims that require justification. The reviewer doesn't provide any specific evidence or logical reasoning to support these claims. The suggestion to acknowledge the similarity is a recommendation, not a claim requiring verification.", "helpfulness_rationale": "The review offers a direction for the author to consider exploring energy models and highlights a potential connection to existing work. While it doesn't provide specific implementation details for exploring energy models, it points out a relevant area and a potential limitation. The suggestion to acknowledge the similarity is a helpful suggestion, but the lack of concrete action makes the overall feedback somewhat limited."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment explicitly states the need for labeled data for imitation learning, making it an explicit action. However, it lacks specific details on how to obtain this data, making it vague and not fully actionable.", "grounding_specificity_rationale": "The comment criticizes the lack of experiments on data generation for imitation learning. While it implicitly refers to the experimental section, it doesn't explicitly point to a specific part of the paper (e.g., a table or section title). The critique itself is also somewhat vague, not specifying the exact nature of the difficulties or the data needed.", "verifiability_rationale": "The comment presents a claim about the absence of experiments and the lack of analysis on data size. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The statement is presented as an observation without justification.", "helpfulness_rationale": "The comment identifies a missing experimental component related to data generation for imitation learning. While this is a valid point and highlights a potential area for improvement, it doesn't offer any specific guidance or suggestions on how to address this lack of experiments. The feedback is more of a detection of a gap than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential ambiguity regarding the term 'certificate' in the context of the paper. While the reviewer identifies a specific area of concern (line 267), the action suggested is general: 'improve your own understanding'. The reviewer doesn't explicitly state what needs to be done with the term 'certificate' or how it should be interpreted.", "grounding_specificity_rationale": "The reviewer mentions 'line 267' as a potential source of confusion, which provides some grounding. However, the reviewer does not specify what is unclear about the term 'certificate' at that line or how it should be interpreted differently. The reference is vague and doesn't pinpoint the exact issue.", "verifiability_rationale": "The reviewer states a potential issue: 'the terminology \"certificate\" in some contexts (for instance at line 267) might be misinterpreted, due to its strong meaning in complexity theory.' This constitutes a claim that there is a potential for misinterpretation. However, the reviewer does not provide any external references or examples to support this claim, making the evidence for the claim itself somewhat lacking.", "helpfulness_rationale": "The reviewer's suggestion is to ask for clarification on the term 'certificate'. While this is a helpful suggestion, it is a general request and does not directly address a specific weakness or propose a concrete improvement to the paper. The suggestion lacks specificity and doesn't offer actionable steps for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point requests more experiments but lacks specific details on how to conduct them, making it implicit and vague.", "grounding_specificity_rationale": "The review explicitly mentions 'deeper networks (e.g., ResNet50)' and 'other network structures (e.g., MobileNet)' and provides references, clearly identifying the relevant parts of the paper.", "verifiability_rationale": "The review contains a claim ('More experiments... are needed') and provides references to support the value of exploring deeper and other network structures.", "helpfulness_rationale": "The review suggests exploring deeper and other network structures and provides references. While it identifies a valuable direction, it lacks specific implementation details, making it 3 but not fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their belief that the proxlinear subproblem can be reformulated using the conjugate function and that this reformulation makes the motivation of Algorithm 1 unclear. This indicates a clear action: to point out a potential simplification and its implications for the algorithm's purpose. The reviewer also suggests that this alternative approach is 'more general' and that it 'makes the motivation of Algorithm 1 unclear', indicating a concrete action of evaluating the proposed reformulation and its impact on the algorithm's purpose.", "grounding_specificity_rationale": "The reviewer directly addresses the proxlinear subproblem, which is a specific part of Algorithm 1. They state, 'I believe that the proxlinear subproblem can be reformulated using the conjugate function...' This clearly identifies the specific aspect of the paper being referred to. Furthermore, they explain the implications of this reformulation for Algorithm 1's motivation, stating, 'This makes the motivation of Algorithm 1 unclear.' This provides a specific reason for why the algorithm's purpose is being questioned. The reviewer's statement is not only about identifying a part of the paper but also about the significance of the proposed change.", "verifiability_rationale": "The reviewer makes a claim: 'Given the current stochastic problem in Eq.(1), I believe that the proxlinear subproblem can be reformulated using the conjugate function...'. This is a statement of opinion or suggestion. The reviewer also provides a reason for this belief: 'This makes the motivation of Algorithm 1 unclear.' This is a logical reasoning step, suggesting that the proposed reformulation undermines the need for Algorithm 1. However, the reviewer does not provide specific examples or references to support this claim. Therefore, while the claim is present and the reasoning is logical, the lack of concrete evidence makes the verifiability somewhat limited.", "helpfulness_rationale": "The reviewer provides a specific suggestion for improving the proxlinear algorithm by reformulating it using the conjugate function. This is a concrete suggestion that could potentially simplify the implementation of proxlinear methods for stochastic problems. The reviewer also states that this alternative approach is 'more general' and that it 'makes the motivation of Algorithm 1 unclear.' This suggests the reviewer believes their proposed change could have a significant positive impact on the field or at least on the understanding of the problem. The potential for a meaningful improvement in the algorithm's approach makes this review point potentially helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a difference in the positioning of features across categories. While it points out this difference, it doesn't explicitly state what needs to be changed or how the positions should be adjusted. The reviewer suggests considering categoryspecific feature positioning, which implies a need for modification, but the specifics of the modification are not provided.", "grounding_specificity_rationale": "The review point is very general and does not specify which features or categories are being discussed. It simply states that 'the features and their positions are not the same' without identifying the specific elements in question. There is no attempt to ground the discussion in a specific part of the paper or a unique aspect of the work.", "verifiability_rationale": "The review point is a statement of observation: 'Although it is intuitive that including multiple local prompts helps, for different categories, the features and their positions are not the same.' This is a factual statement and does not contain a claim that requires verification or justification.", "helpfulness_rationale": "The review point identifies a potential area for improvement (categoryspecific feature positioning) but does not provide specific guidance on how to achieve this. It is a suggestion for change rather than a detailed explanation of how to implement that change. The authors would likely understand the *problem* but lack the *direction* on how to solve it."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point asks for clarification on a discrepancy between tables and requests specific ablation studies. While it doesn't explicitly state an action to be taken, it points to potential issues or areas needing further explanation, which can be considered actionable in terms of guiding the authors to investigate and clarify their results. The request for ablation studies is a direct request for information that can help understand the contribution of different components of the method.", "grounding_specificity_rationale": "The review point does not explicitly identify a specific part of the paper being addressed. It refers to general discrepancies between tables and ablation studies without pinpointing a particular section, table, figure, or unique aspect. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review point asks a question about the results of Table 6 not aligning with Table 1 and requests information about ablation studies. While it implies a claim that there is a discrepancy and that ablation studies should be performed, it doesn't provide a clear justification or evidence for why this discrepancy exists or what the expected outcome of the ablation studies should be. The reasoning is implied but not explicitly stated, and there are no external references provided to support the claim.", "helpfulness_rationale": "The review point is 5 as it directly points out a potential issue (discrepancy between tables) and requests specific information (ablation studies) that can help the authors understand and improve their work. The 'why' question is valuable for identifying potential flaws, and the request for ablation studies is a very direct and actionable request for information."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states an action: 'Similar analyses are already present in prior works...'. However, it does not provide concrete steps or details on how to implement these analyses or apply the findings from prior work to the authors' draft. The action is stated but not elaborated upon in a way that provides clear guidance.", "grounding_specificity_rationale": "The review point does not identify a specific part of the authors' paper that it is addressing. It is a general statement about the field and existing research. Therefore, it is 1 in the authors' specific work.", "verifiability_rationale": "The review point does not contain a claim that requires verification. It is more of a statement about the field and existing research. Therefore, it is not verifiable in the sense of requiring evidence to support a statement.", "helpfulness_rationale": "The review point is informative and points to relevant research. It suggests that insights from prior work could be applicable to the authors' potential work. While it doesn't provide explicit instructions on how to improve the authors' draft, it offers context and motivation, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer implies an action by stating 'More discussions are required here,' suggesting they want the authors to address the perceived simplicity of the subtasks. However, they do not explicitly state what action the authors should take. The action is implied but not directly stated.", "grounding_specificity_rationale": "The reviewer refers to 'the 10 subtasks' and 'bAbi,' which are specific elements within the paper or experimental setup. This indicates a degree of grounding. The mention of 'simplistic' also implies a judgment about a specific part of the work.", "verifiability_rationale": "The reviewer makes a claim: 'The 10 subtasks are rather simplistic for bAbi.' However, they do not provide any evidence, references, or logical reasoning to support this claim. The claim is presented as an assertion without justification.", "helpfulness_rationale": "The reviewer directly addresses a potential area for improvement in the paper by pointing out the perceived simplicity of the subtasks and encouraging more discussion. This directly contributes to the authors' potential need for refinement and clarification."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification on the term 'sequence of episodes\" and implicitly suggesting that \"practice\" and \"evaluation\" are types of this sequence. While this points to a potential area for improvement, the action is not explicitly stated. The authors would need to infer the need for clarification.", "grounding_specificity_rationale": "The reviewer uses the term 'sequence of episodes\" without explicitly pointing to a specific section or table in the paper. The connection between \"practice\" and \"evaluation\" as types of this sequence is also not explicitly linked to a specific part of the paper, making the grounding somewhat weak.", "verifiability_rationale": "The review point does not contain a claim that needs to be verified. It is a request for clarification, which is a different type of feedback.", "helpfulness_rationale": "The review point identifies a potential area of confusion for the authors by asking for clarification on a specific term and its relation to other concepts. This can be helpful in guiding the authors to a better understanding, but it does not directly suggest a concrete change to the paper."}
{"actionability_label": "4", "grounding_specificity_label": "3: 4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states 'I don't think the study about different subdomain sizes is an \"ablation\" study' and suggests an alternative. This directly identifies an action the authors should take (questioning the terminology) and provides a concrete suggestion (it might be more accurate to describe it as...).", "grounding_specificity_rationale": "The review point explicitly mentions 'subdomain sizes' and 'ablation study'. This clearly identifies the specific aspect of the paper being discussed and the issue being raised. The reviewer is not making an educated guess; they are directly referring to specific elements.", "verifiability_rationale": "The review point makes a claim about the definition of an 'ablation study'. While it doesn't provide external references, the reasoning is based on the common understanding of what an ablation study entails in the research community. It's not 5 without looking up the definition, but the core reasoning is generally accepted.", "helpfulness_rationale": "The review point directly addresses a potential misunderstanding about the study's methodology. It provides a clear alternative suggestion ('It might be more accurate to describe it as...'). This directly helps the authors understand and potentially correct a misconception."}
{"actionability_label": "5", "grounding_specificity_label": "Weakly Grounded", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states: 'It would be stronger if the base DA methods were similarly evaluated with/without the architectural competitors such as AutoDial and AdaBN that are direct competitors to TN.' This is a clear and direct suggestion for an action to be taken to improve the evaluation of the TransferNorm (TN) architecture. The reviewer identifies a specific area for improvement (comparing against architectural competitors) and proposes a concrete method for achieving it (evaluating base DA methods with and without AutoDial and AdaBN).", "grounding_specificity_rationale": "The reviewer's suggestion is about the *evaluation methodology* of comparing base DA methods with and without AutoDial and AdaBN. It does not explicitly identify a specific part of the paper (e.g., a section, table, figure, or unique aspect) that needs this evaluation. While the suggestion is clear and welldefined, it lacks the explicit grounding in a specific part of the paper.", "verifiability_rationale": "The reviewer's suggestion is about proposing a *methodological improvement* to the evaluation process. It does not contain a direct claim or statement that can be logically verified or supported by evidence within the review point itself. The suggestion is presented as a desired improvement rather than a statement of fact or inference.", "helpfulness_rationale": "The reviewer's suggestion directly addresses a potential weakness in the original evaluation (lack of comparison with relevant architectural baselines) and proposes a concrete improvement. This directly benefits the authors by providing a more comprehensive understanding of the TransferNorm (TN) architecture's effectiveness relative to other architectures. The suggestion is specific and actionable, making it 5 for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states what information is missing (number, placement) and asks a direct question about it. This directly points to an actionable gap in the authors' explanation.", "grounding_specificity_rationale": "The reviewer refers to the 'attention module' and 'backbone ResNet20 architecture,' which grounds the topic. However, they don't explicitly name the section, table, figure, or unique element of the paper where this integration is described. They imply it's part of the proposed architecture, requiring the authors to infer the relevant section.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity. The 'review point itself' doesn't provide any evidence or justification for this claim. It's a statement the authors need to address, but the reviewer doesn't offer any supporting arguments within their review.", "helpfulness_rationale": "The reviewer provides a clear request for more information. While it's a valuable request, it doesn't directly critique the authors' work or suggest concrete improvements to it. It's a request for clarification, which is 3 in guiding the authors but not a direct improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states the reliance on 'Theorem 8' but does not provide specific guidance on how to use this theorem or where to find it within the paper. While the authors are informed about a potential issue, they are left to navigate the appendix and potentially struggle with a nonclear proof on their own.", "grounding_specificity_rationale": "The reviewer does not explicitly state which part of the paper 'Theorem 8' relates to, nor does they explain why it is problematic. The reference is general and does not pinpoint a specific section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The reviewer states that the proof of 'Theorem 8' is 'not clear enough' but does not provide any external references or logical reasoning to support this claim. The justification is subjective and lacks external validation.", "helpfulness_rationale": "The reviewer's concern about the unclear and potentially inaccessible 'Theorem 8' makes the review unhelpful for the authors. They are left to search the appendix and potentially struggle with a poorly explained proof, hindering their ability to improve the paper."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the analysis on BRPNAS only compares against 3 basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This is an explicit action pointing out a missing element in the analysis.", "grounding_specificity_rationale": "The reviewer mentions 'other NAS (e.g. supernet/oneshot approaches, etc...)' as missing comparisons. This provides a clear grounding by identifying the category of approaches being missed and even providing specific examples within that category.", "verifiability_rationale": "The reviewer states that the analysis on BRPNAS ignores some other NAS approaches. This is a claim that can be verified by examining the content of the paper. While the reviewer doesn't provide specific references, the suggestion itself is a verifiable point about the scope of the analysis.", "helpfulness_rationale": "The reviewer suggests that the analysis on BRPNAS would be improved by including comparisons to other NAS approaches. This is a suggestion that could help the authors better understand the context and performance of their method."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitation of the proposed method, indicating a clear action that the method cannot take for natural images. While the action is defined for digit/text images, the lack of action for natural images makes it partially actionable.", "grounding_specificity_rationale": "The reviewer mentions the limitation regarding image types (digit/text vs. natural) but does not explicitly point to a specific section, table, or figure in the paper where this limitation is discussed. The grounding is implied but not clearly stated.", "verifiability_rationale": "The reviewer makes a claim about the method's limitations without providing any supporting evidence or justification. The reasoning, common knowledge, or external references are absent.", "helpfulness_rationale": "The reviewer provides a clear and actionable feedback, pointing out a significant limitation of the method. The comment is critical and directly suggests an improvement area (applying the method to natural images)."}
{"actionability_label": "4", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue: 'While FFNs are omitted because a linear decomposition cannot be obtained (as mentioned in the paper)'. This clearly identifies a missing element and its reason. The reviewer also suggests a potential solution: 'maybe a line or two should be added that there exists no solution for this, and it is an open (hard) problem.' This provides a concrete action the authors can take to improve their draft.", "grounding_specificity_rationale": "The reviewer refers back to the paper by mentioning 'as mentioned in the paper' (referring to the linear decomposition issue). This grounds the comment to a specific part of the work. The reviewer also specifies the *reason* for omitting FFNs ('a linear decomposition cannot be obtained') and *suggests a type of solution* ('approximation'). This provides context and direction for the authors.", "verifiability_rationale": "The reviewer presents a suggestion ('maybe a line or two should be added...') and a reason ('It improves the readability...'). The core of the comment is the suggestion itself, which is a claim that *adding* this information will *improve readability*. While the reviewer doesn't provide specific evidence for this claim, the *benefit* (improved readability) is a generally accepted positive outcome of clear explanations. The lack of specific evidence doesn't make it 1 in a practical sense, as the authors can reasonably infer the benefit.", "helpfulness_rationale": "The reviewer directly addresses a specific issue related to the paper's content (omission of FFNs and the reason for it). The suggestion to clarify the situation and present the limitations upfront is constructive and helps the authors understand the scope of the work. The reviewer's comment is clear and directly points to an area for improvement in the authors' draft."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer suggests a specific action: 'It would be helpful to clarify how perplexity relates to domain drift...'. This is a direct and explicit instruction on how to improve the paper. The reviewer also suggests a method for clarification: '...and suggest a way to clarify this relationship...'. This indicates a concrete action to be taken. The reviewer is not just pointing out a problem but offering a specific direction for improvement.", "grounding_specificity_rationale": "The reviewer refers to 'perplexity' and 'domain drift' without explicitly pointing to a specific section, table, figure, or unique element of the paper. While these are valid concepts, the comment does not specify which part of the paper they are referring to. The reviewer is discussing general concepts rather than a specific instance within the paper.", "verifiability_rationale": "The reviewer states a relationship: '...perplexity is used as a measure of the model retaining semantic information after finetuning, and while that does relate to the original task, there are also aspects of domain drift which are possible and separate from catastrophic forgetting. How are such factors controlled?'. This statement presents a claim about the relationship between perplexity, semantic information retention, and domain drift. However, the reviewer does not provide any evidence, examples, or references to support how these factors are controlled. The question itself highlights a gap in understanding but does not offer a solution or justification.", "helpfulness_rationale": "The reviewer offers a suggestion: 'It would be helpful to clarify how perplexity relates to domain drift...'. This suggests a concrete action the authors could take. However, the reviewer does not provide any specific guidance on *how* to clarify this relationship. The question 'How are such factors controlled?' indicates a gap in the authors' understanding but does not offer a solution or a concrete step to address it. While a suggestion is made, the lack of specific information makes it less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment explicitly states a limitation: 'It is not clear if the method is applicable to real and categorical features too.' This indicates an implicit actionability, as the authors should now investigate the method's applicability to these feature types. However, the comment does not provide concrete steps or guidance on how to determine this applicability.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper or method that is affected by the limitation regarding real and categorical features. It is a general statement about the method's applicability. While it mentions 'real and categorical features,' it doesn't specify a unique element within a section or table.", "verifiability_rationale": "The comment contains a claim: 'It is not clear if the method is applicable to real and categorical features too.' However, this claim is not supported by any evidence or reasoning within the review point. There is no logical reasoning, common knowledge, or external references provided to back this statement.", "helpfulness_rationale": "The comment raises a potential issue regarding the method's applicability to different feature types but does not offer any suggestions or guidance on how to address this. It is a question posed, not a constructive suggestion that would empower the authors to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states that the algorithm for construction of coresets itself is not novel and points to existing coreset frameworks for classical kmeans and (k,z) clusterings being extended to the kernelized setting. This provides a clear action for the authors to consider the novelty of their algorithm in the context of existing work.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'algorithm for construction of coresets' and 'existing coreset frameworks for classical kmeans and (k,z) clusterings'. This provides a clear and specific reference point, indicating full grounding.", "verifiability_rationale": "The reviewer makes a claim about the novelty of the algorithm but does not provide any specific evidence or references to support this claim. The statement is a general observation rather than a logically reasoned or justified assertion.", "helpfulness_rationale": "The reviewer points out a potential lack of novelty in the algorithm. While this is a valid observation, it does not offer specific suggestions for improvement or further research directions. It is a critique of the algorithm's contribution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the reason for considering only ECG segments with one label assigned (to make reports easier). This is a clear and direct statement of the *why* behind a methodological choice. The reviewer also infers a potential improvement (including all reports). This inference, while not explicitly stated in the paper, is a logical next step based on the stated goal. Therefore, the reviewer's point is explicit and the action is somewhat concrete.", "grounding_specificity_rationale": "The reviewer explicitly states the *why* behind considering only ECG segments with one label (to make reports easier). This directly identifies the *referenced part* of the paper being addressed. The reviewer also specifies what they expect (easier reports). This makes the grounding explicit and the specificity somewhat clear.", "verifiability_rationale": "The reviewer presents a claim about the current method (only considering ECG segments with one label) and its potential benefit (easier reports). While the paper doesn't explicitly *state* this as a *goal* of onelabel segments, the reviewer's expectation is a reasonable interpretation or inference based on common practices in report generation. The paper's methodology *implies* this is a design choice. Therefore, the claim is somewhat justified by the context.", "helpfulness_rationale": "The reviewer directly points out a potential improvement to the authors' workflow (considering all reports instead of just those from segments with one label). This is a clear and actionable suggestion that directly addresses a potential limitation or area for improvement. The reviewer's question is directly related to the authors' work and offers a practical solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that LLMs may have limitations in modeling problems with large instance sizes and suggests generating instances with more constraints and variables. This is an explicit action that the authors can directly address. However, the comment lacks specific guidance on *how* to generate these instances, making the action somewhat vague.", "grounding_specificity_rationale": "The comment discusses the general limitations of LLMs in handling complex instances and suggests a way to address this. While it identifies a relevant issue (LLM limitations), it doesn't explicitly point to a specific section, table, or figure in the paper. The grounding is weak because the authors would need to infer the relevance of LLMs to the problem being discussed. The specificity is somewhat present as the comment mentions 'constraints and variables', which are specific aspects of instance design, but the lack of a direct reference point makes the grounding weak.", "verifiability_rationale": "The review point primarily states an observation about the potential limitations of LLMs in handling complex instances and suggests a direction for improvement by generating instances with more constraints and variables. This point does not contain a claim that requires verification or justification. It's a statement of what the authors might be experiencing or proposing as a solution, not a statement that needs to be supported by evidence within the review itself.", "helpfulness_rationale": "The comment points out a potential limitation of LLMs in handling complex instances and suggests a way to address it by generating instances with more constraints and variables. This is 3 as it highlights a relevant issue and offers a general direction for improvement. However, it lacks specific guidance on *how* to implement this suggestion, making it less impactful than a more detailed recommendation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification on the relationship between NodeSort, base nodes, key nodes for attention, and model performance. This is a direct request for information, making it explicit. The reviewer is also inferring that understanding this relationship could lead to improvements in model performance, making the action somewhat concrete.", "grounding_specificity_rationale": "The reviewer mentions 'base node,' 'key nodes for attention,' and 'model performance.' While they don't explicitly point to a specific section or table, they are referring to concepts within the paper's domain. The request implies a need for more detail on how these elements interact. This can be considered weak grounding as the reviewer can infer the relevance of these concepts but lacks precise references. The request also implies a need for justification (why this relationship matters for performance), making it somewhat specific.", "verifiability_rationale": "The review point is a question, not a statement that can be verified using logical reasoning, common knowledge, or external references. Therefore, it does not contain a claim that can be supported or unsupported. This fits the 'X' category for X.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific implementation detail. While this could be helpful for the authors if they are implementing a similar mechanism, the question is very specific and potentially niche. It doesn't offer broad guidance or address a wide range of potential issues. Therefore, it is somewhat likely to be helpful but not highly so."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a question about the diagram, which implies they are looking for clarification rather than being explicitly told what to do. While the question points towards a potential action (understanding the influence of n^(i)), the action itself is not explicitly stated in the review point.", "grounding_specificity_rationale": "The reviewer explicitly points to the arrow in Figure 2 and the specific spaces (Gaussian space and latent space) and the variable n^(i). This demonstrates a clear identification of the specific part of the paper being addressed.", "verifiability_rationale": "The reviewer is asking a question about the purpose of the arrow. This can be considered a claim (they are making a statement about the diagram's intended function). However, the verifiability depends on whether the paper adequately explains the diagram. The reviewer's question implies a lack of clarity in the paper's explanation, making it somewhat underspecific.", "helpfulness_rationale": "The reviewer is asking for clarification on a specific detail in the paper. While it doesn't directly point out a flaw, it's highly likely the lack of clarity hinders understanding and potentially the implementation of the method. Therefore, it's 3 in identifying a potential area of confusion."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly states that 'AR' stands for 'domain adaptation tasks and algorithms'. This provides a clear action for the authors to take, which is to review Table 5 and understand the context of these abbreviations. The action is also concrete as the meaning is fully specified.", "grounding_specificity_rationale": "The reviewer explicitly states 'In Table 5', which clearly identifies the location of the undefined abbreviation. The grounding is strong. The reviewer also specifies the meaning of 'AR' as 'domain adaptation tasks and algorithms', making the specificity high.", "verifiability_rationale": "The reviewer makes a claim that the lack of definition for 'AR' is a weakness. This claim is verifiable because the meaning of 'AR' in this context is a generally understood concept within the field of domain adaptation. The reviewer provides a clear and logical explanation of what 'AR' likely stands for.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors to take: review Table 5 and understand the context of the abbreviations. The suggestion is specific and directly addresses the identified issue. This level of detail and guidance makes the review point 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that VINS uses different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1. This is an explicit statement of a difference in implementation. The reviewer further claims this makes the comparison unfair. While the reviewer doesn't specify *how* it's unfair, they identify a concrete difference in the experimental setup that directly impacts the implementation. This allows the authors to directly identify the discrepancy and potentially investigate its consequences.", "grounding_specificity_rationale": "The review point refers to 'the performance comparison in Table 1' generally, without explicitly naming a specific part of the paper being addressed. While it mentions 'VINS sets different sample weights W u i' and 'most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1', it doesn't specify *which* table or figure within Table 1 is being referenced. Therefore, the grounding is weak. The specificity is also low as the review point doesn't detail *what* is unfair or *where* in the comparison the issue lies.", "verifiability_rationale": "The review point contains a claim: 'VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1.' This is a declarative statement about the experimental setup. However, the review point does not provide any justification or evidence to support this claim. It simply states the difference in weights without explaining why this difference makes the comparison unfair. There are no logical reasoning, common knowledge, or external references provided to verify the claim. Therefore, the verifiability is 1.", "helpfulness_rationale": "The review point identifies a potential flaw in the experimental design (unequal sample weights) that could affect the interpretation of the results. It highlights a discrepancy in the implementation of the compared methods. While this points to a potential issue, the review stops at identifying the problem. It doesn't offer specific suggestions or explain *why* the comparison is unfair. The reviewer simply states the difference without providing actionable steps or justifications. Therefore, while the point is relevant, it lacks the depth and guidance needed to be 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point states: \"The time complexity will be too high if the reply buffer is too large.\" This is a statement of a potential problem, not an actionable suggestion. It identifies a *problem* related to a *component* (reply buffer) but doesn't tell the authors *how* to fix it.", "grounding_specificity_rationale": "The review point refers to \"reply buffer\" without specifying which part of the paper or context this relates to. It also doesn't pinpoint the specific algorithm or component within the PRMRL framework.", "verifiability_rationale": "The review point is a statement of a potential problem: \"The time complexity will be too high if the reply buffer is too large.\" It doesn't make a definitive claim about *why* this will happen or *how* to solve it. It's more of an observation.", "helpfulness_rationale": "The review point points out a potential performance bottleneck (high time complexity) related to the reply buffer. While it highlights a problem, it doesn't offer any concrete solutions or guidance on how to address this issue. It's a symptom, not a solution."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2: Borderline Helpful", "actionability_rationale": "The review point states what needs to be done (provide a conclusion and summary) but does not specify how to do it. It lacks explicit and concrete instructions for improvement, making it only partially actionable. While it identifies a need, the lack of specific steps makes it less actionable than a review that provides a clear process for improvement.", "grounding_specificity_rationale": "The review point is a general directive and does not specify which part of the paper it is addressing. It refers to the entire 'article' and 'paper' without pinpointing a specific section, table, figure, or unique aspect. Therefore, it is 1 in a specific part of the paper.", "verifiability_rationale": "The review point is a statement of what needs to be done, not a claim that requires verification. It does not present an opinion or assertion that needs supporting evidence. Therefore, it does not contain a claim that can be assessed for verifiability.", "helpfulness_rationale": "The review point identifies a valid area for improvement (the conclusion and summary) but lacks specific guidance on how to achieve this. While it points to a necessary change, the lack of concrete suggestions makes it less helpful than a more detailed comment. It provides a direction but requires the authors to generate their own responses to the request."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states a suggestion for comparison and identifies the type of comparison (defense against multiple attacks). This constitutes an explicit action. While the action itself is not concretely implemented in the paper, the suggestion is clear and directly addresses a potential improvement. Therefore, the action is explicit and points towards a concrete action (looking for a specific type of defense).", "grounding_specificity_rationale": "The reviewer mentions 'a method that is designed to defend against multiple attacks.' This is a general description and does not specify which method is being referred to. The reviewer cannot confidently determine which part of the paper they are addressing (general comment) and does not specify what needs to be addressed in this part (the specific comparison). Therefore, the grounding is weak as the reviewer cannot confidently identify the referenced part and lacks clarity on the specific issue.", "verifiability_rationale": "The reviewer's point itself is not a claim that needs verification. They are suggesting a future comparison. However, if we were to interpret the suggestion as a claim (e.g., 'The paper should compare against methods defending against multiple attacks'), then the 'helpfulness' aspect would be more relevant. As it stands, the point is a suggestion for improvement, not a claim requiring verification. Therefore, it is not verifiable as it does not present a claim that needs support.", "helpfulness_rationale": "The reviewer's suggestion is relevant and points towards a valuable improvement for the paper. It highlights a potential gap in the comparison and suggests a relevant area for future work. While the suggestion is somewhat vague (not specifying a specific method), it is still a meaningful point that could benefit the paper. Therefore, the suggestion is helpful but could be more specific."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states the action of 'manually designing a plan' and implies a problem with this approach. However, the specific method of manual design is not detailed, making the action somewhat vague. The reviewer points out that this manual design is done 'in advance' and that learned plans are not comparable to predefined plans, indicating a lack of generalizability. While the action is stated, the lack of detail makes it only partially actionable.", "grounding_specificity_rationale": "The reviewer mentions 'predefined plans based on Table 2' and the difficulty in generalizing to 'a new dataset.' While the generalizability aspect is not explicitly tied to a specific section or table, the reviewer clearly identifies the problem as being related to the plan method and its applicability. The reviewer points out that the proposed method may be difficult to generalize, indicating a lack of specificity in the issue being raised. The reviewer's point is about the generalizability of the method, not a specific part of a particular section.", "verifiability_rationale": "The review point contains a claim: 'The proposed method may be difficult to generalize to a new dataset without the ground truth summary.' However, this claim is not supported by any logical reasoning, common knowledge, or external references. The reviewer states the difficulty without providing evidence or justification for this assertion. The claim is presented as a statement of observation without any backing.", "helpfulness_rationale": "The review point criticizes the planbased method's reliance on manual plan design and its impact on generalizability. While the reviewer identifies a valid concern about the practical limitations of the proposed method, the critique lacks broader suggestions or a comprehensive analysis. The reviewer points out a potential problem but doesn't offer a constructive solution or alternative approach. The impact is focused on the difficulty of generalizing the method, without providing any specific guidance on how to overcome this limitation. The reviewer's comment is primarily a critique of a specific aspect of the method."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'I suggest to add a first sentence to introduce what this section is about.' This action is concrete and directly tells the author what needs to be done. There are no implicit actions that require the author to infer the change. The instruction is clear and specific.", "grounding_specificity_rationale": "The review point explicitly refers to 'Section 3.2' and suggests an improvement related to this section. The authors can easily identify the specific part of the paper being addressed. The comment also specifies what needs to be added \u2013 a first sentence to introduce the section. This is a clear and precise instruction.", "verifiability_rationale": "The review point is a suggestion, not a claim that requires verification. It proposes an improvement to the paper, but it doesn't make a statement that needs to be proven true or false. Therefore, it doesn't have verifiability in the sense of supporting evidence.", "helpfulness_rationale": "The review point is very helpful because it directly points to a specific section (Section 3.2) and suggests a concrete improvement (adding an introductory sentence). This is a clear and actionable piece of feedback that the authors can easily implement. It addresses a potential weakness (lack of introduction to a section) and provides a specific direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment 'Line 44: What is meant by the initial rationale selector is perfect?' does not provide any explicit or implicit information about a specific problem or area for improvement. It raises a question about a concept rather than offering a direct instruction or suggestion. Therefore, it is not actionable.", "grounding_specificity_rationale": "The comment 'Line 44: What is meant by the initial rationale selector is perfect?' does not identify a specific part of the paper or the draft being discussed. It is a general statement about a concept, lacking grounding in the specific context of the paper. Therefore, it is 1.", "verifiability_rationale": "The comment 'Line 44: What is meant by the initial rationale selector is perfect?' does not contain a claim or assertion that requires verification. It is a question about a concept, not a statement that needs to be proven or justified. Therefore, it is not verifiable.", "helpfulness_rationale": "The comment 'Line 44: What is meant by the initial rationale selector is perfect?' is not helpful because it does not provide any actionable feedback or insights. It raises a question about a concept without offering any guidance or suggestions for improvement. Therefore, it is not helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the connection between epistemic model uncertainty and the prior distribution, and also mentions updating beliefs and conditioning on observed data through the posterior. This provides a clear action for the authors to understand the definition of uncertainty. However, the reviewer does not specify which section or table in the paper this definition is located, making the action somewhat vague in terms of implementation.", "grounding_specificity_rationale": "The reviewer does not explicitly name a specific section, table, or figure in the paper where the uncertainty definition is located. They mention 'the paper' generally, which makes the grounding weak. However, the reviewer does specify *what* kind of uncertainty they are referring to (epistemic model uncertainty) and *how* it relates to the prior and posterior distributions, making the specificity quite high in terms of the type of uncertainty being discussed.", "verifiability_rationale": "The reviewer presents a claim suggesting that the paper's definition of uncertainty is unclear and needs to be updated with information about prior distributions, likelihoods, and posterior distributions. This claim is verifiable because the reviewer provides a specific example of how the explanation could be improved. They offer a logical reasoning for why the current explanation might be insufficient.", "helpfulness_rationale": "The reviewer's suggestion to update the definition of uncertainty with more detail about prior distributions, likelihoods, and posterior distributions is 5. It directly addresses a potential ambiguity in the paper and provides a concrete direction for improvement. The suggestion is actionable and verifiable, making it likely to be beneficial for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states a weakness: \"lack of meaningful baselines\" and suggests a specific type of meaningful baseline: \"chainofthought prompting approach.\" This directly identifies an action the authors could take: \"compare with a chainofthought prompting approach.\"", "grounding_specificity_rationale": "The review point starts with a general statement about the limitations of comparisons in Section 2. It doesn't explicitly pinpoint which part of the paper the baselines are being discussed in. While it mentions \"model criticism techniques,\" it doesn't specify *where* in the paper these techniques are discussed or how they relate to the lack of meaningful baselines. The reviewer doesn't detail *why* the baselines are considered \"naive\" or what specific characteristics make them less meaningful in the context of model criticism.", "verifiability_rationale": "The review point clearly states a claim: \"the authors limit their comparisons to simple naive baselines.\" It then suggests an improvement: \"For example, the authors could compare with a chainofthought prompting approach.\" This claim is verifiable through general understanding of what constitutes a \"naive\" baseline in the context of model criticism and logical reasoning suggesting that more sophisticated baselines like chainofthought prompting would be more meaningful. While it doesn't provide specific examples of why the existing baselines are naive, the reasoning is clear.", "helpfulness_rationale": "The review point directly identifies a significant limitation in the experimental setup: the lack of meaningful baselines. It offers a concrete suggestion for improvement: comparing with a chainofthought prompting approach. This directly addresses a practical aspect of the authors' work and provides a clear direction for them to enhance their experiments."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a lack of explanation for PCA experiments. While the reviewer doesn't explicitly state 'Add a section on PCA details in the main text,' the implication is that the missing information needs to be addressed. This makes the action somewhat implicit. The reviewer suggests improvements but doesn't fully specify the action to be taken.", "grounding_specificity_rationale": "The reviewer specifically mentions 'PCA experiments in Figures 3, 7, and 8.' This clearly identifies the specific part of the paper being addressed. Furthermore, the reviewer explicitly states that these 'aren't explained,' clearly detailing what is missing within that referenced section.", "verifiability_rationale": "The reviewer makes a claim about the missing explanations for PCA experiments in specific figures. This claim is supported by the explicit statement that these 'aren't explained.' The reviewer provides a clear example (Figures 3, 7, and 8) and states a lack of explanation, which serves as the verification.", "helpfulness_rationale": "The reviewer identifies a significant issue \u2013 the lack of explanation for key experimental details \u2013 which directly impacts the authors' ability to understand and potentially reproduce the work. While the reviewer doesn't explicitly state the desired outcome (e.g., 'Add a detailed explanation of the PCA method used in the experiments'), the identification of a missing element is a valuable piece of feedback that encourages the authors to seek more clarity. The feedback is directly relevant to improving the paper's clarity and reproducibility."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a specific issue (abuse of notation) and suggests a change. While not explicitly stating the exact correction, the reviewer identifies a clear problem that authors can attempt to address by using different notation for the kernel function and the number of layers.", "grounding_specificity_rationale": "The reviewer explicitly mentions the conflicting uses of 'K' in specific line numbers (L166 and L176). This clearly identifies the part of the paper being addressed, making it fully grounded. However, the reviewer does not specify what the correct notation should be, only that a change is needed.", "verifiability_rationale": "The reviewer states that the notation 'K' is 'abused too' without providing any justification or evidence for this claim. There is no logical reasoning, common knowledge, or external references provided to support the assertion that the use of 'K' is problematic or incorrect.", "helpfulness_rationale": "The reviewer identifies a potential issue (abuse of notation) but fails to provide any justification or explanation for why this is a problem. Without this context, the suggestion to use different notation is not supported and therefore not helpful to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests that the authors' statement about the influence of cognitively basic adaptation mechanisms and CPR structure on selforganization failure/success needs clarification. While the suggestion is present, it lacks specific details on how the clarification should be done.", "grounding_specificity_rationale": "The reviewer states that the authors' comment is unclear and lacks specific identification of the part of the paper being addressed. However, the reviewer does identify a specific area of confusion (the authors' statement about the influence of factors).", "verifiability_rationale": "The reviewer points out a claim made by the authors regarding the unclear connection to human cognition but does not provide any logical reasoning, common knowledge, or external references to support this claim.", "helpfulness_rationale": "The reviewer identifies a potential issue with the paper's framing, which could be helpful for the authors. However, they do not provide specific suggestions or evidence to support their claim, making the feedback somewhat limited."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "Mostly Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the absence of comparison to simple feature acquisition baselines as a weakness. While it doesn't provide concrete suggestions on how to implement this comparison, it clearly identifies the need for it, making it actionable.", "grounding_specificity_rationale": "The review point identifies the lack of comparison to specific baselines as a weakness and pinpoints the area of the paper where this comparison is needed (the 'proposed approach'). It also specifies the type of baseline as 'simple feature acquisition baselines'. This strong identification makes it highly grounded.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to simple feature acquisition baselines. While this is a valid point, the review does not provide explicit reasoning or examples to support this claim. The justification is implied but not explicitly stated, making it 3.", "helpfulness_rationale": "The review point identifies a significant weakness in the paper (lack of comparison to baselines) and mentions writing style issues. While it points out a concrete area for improvement, the suggestions provided are somewhat general and lack specific details. The impact of this review point on guiding the authors is moderate."}
{"actionability_label": "4", "grounding_specificity_label": "Somewhat Grounded and Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the lack of innovation and the similarity to existing techniques from object detection. They also points to the fact that many MLMs can already accomplish the object detection task by themselves. This provides a clear and direct action for the authors to take: focus on the novelty of their approach and how it differs from simply applying existing techniques from object detection to MLMs.", "grounding_specificity_rationale": "The reviewer mentions 'multigranularity and multiscale' and 'object detection algorithms' as examples of common approaches, which grounds the criticism in specific techniques. They also mention that 'many MLMs can already accomplish the object detection task by themselves nowadays,' which further specifies the issue. While the grounding is not perfect, it points towards concrete areas of overlap.", "verifiability_rationale": "The reviewer makes a claim about the lack of innovation and the similarity of the approach to existing techniques. However, they do not provide any specific evidence or references to support this claim within the review point itself. The reviewer relies on their own understanding of the field to make this judgment.", "helpfulness_rationale": "The reviewer provides a helpful score of 3 ('3'). They identify a potential weakness in the paper's contribution and suggest that the approach is not novel and overlaps with existing techniques. While the criticism is present, it lacks the depth and specificity of a higher score. The reviewer could have provided more concrete examples or suggested specific areas for improvement to make it more helpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about a potential issue (oversmoothing) with a specific technique (similarityaware positive sample selection). It *doesn't* explicitly state what the reviewer *wants* to do. The concern is presented as a problem, not a direct instruction on how to fix it or what changes are needed. Therefore, it's not actionable.", "grounding_specificity_rationale": "The reviewer mentions 'similarityaware positive sample selection\" and \"GNNbased encoder oversmoothing\" as potential issues. They also suggest \"positive samples in the same dataset without introducing some perturbation noise\" as a concern. While the *terms* are specific, the *reviewer's* intent isn't entirely clear. They are raising a general concern about the method's behavior, but the connection to a *specific* part of the paper isn't explicitly stated. The suggestion to test on \"different downstream tasks and across different domains\" is a general experiment suggestion related to generalization, not a specific issue with a defined section. Therefore, it's weakly grounded.", "verifiability_rationale": "The reviewer raises concerns about a potential mechanism (oversmoothing) and suggests experiments to test generalization. There's no explicit claim being made. The reviewer is expressing a hypothesis and suggesting future experiments, not stating a definitive fact that requires verification. Therefore, it's X.", "helpfulness_rationale": "The reviewer raises concerns about a specific technique and suggests further experiments. While the suggestions are relevant, the *reviewer's* primary focus is on questioning the method's behavior and suggesting more experiments than directly pointing out a clear weakness or providing a direct solution. Therefore, it's 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point asks a direct question about the expressiveness of 'fast SMP' compared to 'SMP'. While it doesn't explicitly state an action to be taken, the question implicitly suggests an action: investigating and comparing the two architectures. The reviewer desires more discussion, which implies a need for action to explore this further. However, the action is not clearly defined or actionable.", "grounding_specificity_rationale": "The review point does not explicitly refer to a specific part of the paper or architecture. It is a general question about the expressiveness of two different types of SMP. Therefore, it lacks grounding specificity as it doesn't pinpoint a particular section, table, figure, or unique aspect of the paper.", "verifiability_rationale": "The review point presents a question and a desire for discussion. It does not contain a claim that requires verification. It is a request for more information and analysis, not a statement that needs to be proven or disproven. Therefore, it does not have verifiability as it doesn't contain a claim that needs supporting evidence.", "helpfulness_rationale": "The review point directly asks a question about a technical aspect ('expressiveness') and encourages more discussion on the power of different architectures. This directly addresses a potential area for improvement in the authors' understanding and work related to SMP. The desire for more discussion indicates a clear need for further exploration and clarification, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'evaluate the methods across different splits of trainvaltest'. This action is concrete, as it clearly indicates which part of the experimental setup should be changed. The reviewer is not just pointing out a problem but suggesting a specific improvement.", "grounding_specificity_rationale": "The review point explicitly mentions 'trainvaltest splits' as the specific part of the paper being addressed. This is a literal mention of a section of the paper, indicating strong grounding. The reviewer is not making any vague statements but directly referring to a specific aspect of the experimental setup.", "verifiability_rationale": "The review point is a statement of preference and a reason. While it doesn't present a claim that requires external verification, it does point out a limitation of the current evaluation (only using different initialisation seeds). This could be considered implicit evidence of a problem that the suggested change aims to address.", "helpfulness_rationale": "The review point directly addresses a potential limitation of the experimental evaluation and suggests a concrete improvement. It empowers the authors to potentially get better results by evaluating across different trainvaltest splits, which is a valuable suggestion for improving the robustness of their findings."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The first part of the review point explicitly states that 'some symbols are not explained clearly'. This is an explicit action that the author can directly address by providing definitions or clarifications for those symbols in the figure caption or surrounding text. The second part of the review point, 'And the reviewer is curious about that whether there is information redundancy and interference in the multisphere icosahedral discretization process', is not an actionable point. While the reviewer identifies a potential issue, they do not provide a specific action or suggestion for the author to take. The author would need to infer that the reviewer is suggesting a need for discussion or analysis of potential redundancy and interference.", "grounding_specificity_rationale": "The first part of the review point, 'The Figure 2 is a little ambiguous, where some symbols are not explained clearly', is 5. The reviewer explicitly mentions 'Figure 2' and points out the lack of explanation for 'some symbols'. This allows the author to directly identify the specific figure and the unexplained elements. The second part of the review point, 'And the reviewer is curious about that whether there is information redundancy and interference in the multisphere icosahedral discretization process', is 1. While the topic is related to the paper, the reviewer does not explicitly mention a specific section, table, figure, or unique aspect of the paper being addressed. The connection to the paper's content is implied but not direct.", "verifiability_rationale": "The first part of the review point, 'The Figure 2 is a little ambiguous, where some symbols are not explained clearly', contains a claim ('some symbols are not explained clearly') that is 1. The reviewer states the issue but does not provide any evidence or justification for it. The second part of the review point, 'And the reviewer is curious about that whether there is information redundancy and interference in the multisphere icosahedral discretization process', is not a claim in the sense of a statement requiring verification. It is a question posed to the author, not a statement that needs to be supported by evidence.", "helpfulness_rationale": "The first part of the review point, 'The Figure 2 is a little ambiguous, where some symbols are not explained clearly', is 3. The reviewer points out a specific issue (unexplained symbols) that the author can address. However, it lacks a suggestion for improvement. The second part of the review point, 'And the reviewer is curious about that whether there is information redundancy and interference in the multisphere icosahedral discretization process', is not helpful. The reviewer raises a question but does not offer any actionable feedback or suggestions to the author."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "None", "actionability_rationale": "The review point explicitly states a limitation: 'the results of the paper could be restrictive.' This directly points out a weakness that the authors should consider. While it doesn't provide a specific action, it clearly identifies an area for improvement. The suggestion to 'Consider including Matern kernels in your analysis' is a direct and actionable step.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the spectrum of a kernel' and specifically 'Matern kernels'. This clearly identifies the relevant part of the paper being discussed. Furthermore, the reviewer explains why Matern kernels are relevant by stating, 'However, another popular class of kernels such as Matern kernels are not included, since their spectrum only decay polynomially.' This provides a specific reason for highlighting the absence of Matern kernels.", "verifiability_rationale": "The reviewer presents a claim by stating, 'The limitation of the obtained results: The authors assume that the spectrum of a kernel is subgaussian. This is OK, as the popular Gaussian kernels are in this class. However, another popular class of kernels such as Matern kernels are not included, since their spectrum only decay polynomially.' This claim is supported by the explanation that Gaussian kernels have subgaussian spectra and the limitation of Matern kernels having polynomially decaying spectra. This provides a logical reasoning to support the point.", "helpfulness_rationale": "The review point directly suggests a concrete improvement: 'Consider including Matern kernels in your analysis.' This is a clear and actionable suggestion that directly addresses the identified limitation. By providing a specific direction for the authors, the reviewer offers valuable guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the importance of unsupervised pretraining and suggests its emphasis. This is considered explicit as the action of emphasizing is directly stated. It is also concrete as the action is to focus on unsupervised pretraining, and the reviewer provides a clear suggestion.", "grounding_specificity_rationale": "The review point refers to \"unsupervised pretraining\" and suggests focusing on it. While it doesn't provide a precise section number or table reference, it points to a general methodology. This can be considered weakly grounded as the authors can infer the specific part of the paper being addressed, although not with certainty.", "verifiability_rationale": "The review point makes a claim: \"there is no detailed discussion on the unsupervised pretraining in the main paper, which might be a problem.\" This claim is 3 as the reviewer suggests emphasizing pretraining based on their understanding of the typical structure of the paper and the importance of experimental results. While a more detailed justification could be provided, the suggestion itself is based on a reasonable inference.", "helpfulness_rationale": "The review point points out a valid weakness (lack of discussion on a key module) and suggests a clear improvement (emphasizing it). This is a moderately helpful suggestion as it directly addresses a potential area for improvement in the paper's presentation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'The method is only tested on two datasets.' This is a direct statement of a limitation, making it explicit. However, it doesn't provide concrete suggestions for improvement. The lack of specific details about what needs to be done to expand the testing makes it somewhat vague.", "grounding_specificity_rationale": "The comment mentions 'datasets' generally, without specifying which two datasets were used. This indicates weak grounding as the authors cannot confidently determine which part the comment addresses. However, the comment does specify what needs to be addressed in this part, which is the limited number of datasets used in the experiments.", "verifiability_rationale": "The comment contains a claim: 'The method is only tested on two datasets.' This claim is based on a factual observation about the experimental setup. It is 3 because the authors can easily check the paper for the number of datasets mentioned. However, it lacks specific details about the datasets themselves or the methodology used for testing.", "helpfulness_rationale": "The comment identifies a potential limitation in the experimental validation by pointing out the small number of datasets used. While it doesn't directly suggest specific improvements, it prompts the authors to consider this limitation and potentially try more datasets. This suggests a degree of helpfulness in identifying a potential area for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks 'What is the domain of the inputs?' and then provides a specific observation 'It seems they are lying in the same sphere, not mentioned in the paper.' This is an explicit statement identifying a potential issue. Furthermore, the reviewer provides a concrete example ('lying in the same sphere') to support their observation. This action is directly actionable for the authors to understand the data's scope and its potential redundancy.", "grounding_specificity_rationale": "The reviewer asks a general question about the 'domain of the inputs.' They do not explicitly point to a specific section, table, or figure in the paper. While they imply it's related to the current work by saying it's 'not mentioned in the paper,' this is an inference rather than a direct grounding. The reviewer does, however, specify the potential issue ('lying in the same sphere'), which provides some level of specificity regarding the nature of the inputs. Therefore, it is weakly grounded as it doesn't directly identify the referenced part but provides context. It is also specific in that it identifies the potential issue as redundancy.", "verifiability_rationale": "The reviewer poses a question ('What is the domain of the inputs?') and offers a potential explanation ('they are lying in the same sphere... not mentioned in the paper'). This can be considered a claim, as it expresses an opinion or judgment about the inputs. However, the reviewer does not provide any specific evidence, references, or logical reasoning to support this claim. The statement is presented as a concern without justification. Therefore, the claim is not wellsupported and lacks verifiability.", "helpfulness_rationale": "The reviewer points out a potential issue with the inputs (redundancy) and suggests it might be because they are in the same domain and not mentioned in the paper. While this highlights a potential problem, it doesn't offer a concrete solution or a clear benefit to the authors. The reviewer is more of a diagnostic observation than a direct improvement suggestion. The comment is not particularly actionable in terms of providing a solution, and it doesn't offer a strong justification for why this is a problem."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer points out a potential conflict between two definitions. While the reviewer doesn't explicitly state an action or a concrete step to take, the identification of a conflict is a clear action that needs to be addressed. The reviewer is suggesting that the definition of minimal conditional dependence might be flawed when considering the empty set in the context of Eq. (7). This is a direct identification of a potential issue.", "grounding_specificity_rationale": "The reviewer explicitly names the conflicting elements: 'Lemma 2', 'Eq (7)', and the 'definition of minimal conditional dependence'. They also specify the scenario: 'Taking Z\u00e2\u0080\u0099 in this definition to be the empty set'. This demonstrates a clear and specific identification of the problematic parts of the paper and the exact condition under which the conflict arises. The reviewer is pointing out a specific discrepancy, which is highly specific.", "verifiability_rationale": "The reviewer states a claim: 'Taking Z\u00e2\u0080\u0099 in this definition to be the empty set, we should have that x and y are independent given W, but Eq. (7) says otherwise.' This is a clear claim that can be investigated by examining the definitions and Eq. (7). The reviewer attempts to explain the discrepancy, indicating an effort to verify the claim. While the explanation could be more detailed, the claim itself is verifiable by looking at the relevant definitions and equation. The reviewer is making a statement that can be supported or refuted with evidence.", "helpfulness_rationale": "The reviewer raises a significant concern about a potential conflict in the theoretical framework. If the definitions are indeed conflicting, it could lead to confusion and misinterpretations for readers. This has a direct and significant impact on the clarity and correctness of the paper. The reviewer is highlighting a potential issue that needs to be resolved to ensure the integrity of the theory. This is a 5 and potentially impactful point that would greatly help the authors understand and apply the theory correctly."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point asks a question about the difference between Batch Normalization and Online Normalization regarding gradient bias. It does not explicitly state an action or provide guidance on how to address this confusion. The reviewer is seeking clarification, not taking a stance or suggesting a concrete improvement.", "grounding_specificity_rationale": "The reviewer refers to the concepts of Batch Normalization and Online Normalization but does not explicitly state which part of the paper they are addressing. While the topic is specific, the exact section or table is not mentioned, making the grounding weak.", "verifiability_rationale": "The review point expresses a belief or confusion about the bias difference between Batch Normalization and Online Normalization. While it implies a claim (that Online Normalization is unbiased and Batch Normalization is biased), it does not provide any evidence or reasoning to support this claim. The verifiability is low because the claim is presented without justification.", "helpfulness_rationale": "The review point raises a valid point of confusion regarding the bias in different normalization techniques. However, it does not offer any suggestions or actions for the authors to take based on this confusion. It is a question posed, not a constructive critique or suggestion aimed at improving the paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point is a direct question asking for clarification on the concept of 'local interactions'. This directly prompts the author to define what they mean by 'local'. Therefore, it is an explicit action, and the authors know exactly what they should do (clarify the definition).", "grounding_specificity_rationale": "The review point asks about 'local interactions' without explicitly naming a specific section, table, figure, or unique element of the paper. While the reviewer can infer the topic might be related to the method or experiments section, the specific part is 1. The reviewer can make an educated guess but cannot precisely identify the referenced part.", "verifiability_rationale": "The review point is a question, not a statement of opinion or suggestion. Therefore, there is X to verify. The classification would be 'X' for X.", "helpfulness_rationale": "The review point is a direct question seeking clarification on a potentially ambiguous concept ('local interactions'). This is helpful because it prompts the author to explicitly define their understanding, which can lead to significant improvement in their draft. While not explicitly pointing to a location, the question is quite specific about the ambiguity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states they 'would have liked' more description, indicating an expectation that something is missing. However, the exact nature of the missing information is not specified, making it difficult for the author to know exactly what to improve. This makes it 3, as the author knows the description needs more detail, but not the specifics.", "grounding_specificity_rationale": "The reviewer refers to 'the Starcraft environment,' which is a specific part of the paper. This indicates good grounding as the reviewer can identify the specific area where the issue lies. However, the reviewer does not specify what is missing or unclear about the description of this environment, making it only somewhat specific.", "verifiability_rationale": "The review point is a statement of preference and expectation, not a claim that requires verification. There is no logical reasoning, common knowledge, or external references provided. Therefore, it is not verifiable.", "helpfulness_rationale": "The reviewer clearly states their desire for more description, indicating a need for improvement. While the direction is clear, the lack of specificity means the feedback is not entirely actionable. However, it is still 5 as it points the author in the right direction."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states an action to suggest using other domain adaptation methods, which is concrete and directly actionable for the authors.", "grounding_specificity_rationale": "The reviewer refers to specific methods (adversarial attack/correction and a specific domain adaptation method) and suggests improvements within a specific category (domain adaptation), indicating an attempt to ground the criticism.", "verifiability_rationale": "The reviewer makes a claim about the methods being proposed by prior work and provides some support (the 'very old' nature) to back this claim.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion to improve the work by exploring more recent domain adaptation techniques, which is directly beneficial for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a limitation (experiments are only done on one game environment) but doesn't provide any specific steps or guidance on how to address it. It simply states the problem.", "grounding_specificity_rationale": "The comment is very general. It doesn't specify the *name* of the game environment or any *details* about it. There's no reference to a specific section, table, figure, or unique aspect of the paper being addressed.", "verifiability_rationale": "The comment is a statement of a problem, not a claim that requires verification or justification. There are no suggestions for *how* to fix the issue.", "helpfulness_rationale": "The comment highlights a valid concern about the experimental design. It alerts the authors to a potential limitation in their evaluation. While it doesn't offer solutions, it provides a clear direction for future work and improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a problem ('slow' and 'low accuracy') and provides specific numbers. This suggests it *could* be actionable. However, the reviewer doesn't explicitly state *how* to improve the speed or accuracy. They could imply that the slow speed and low accuracy are due to implementation details, but they don't explicitly say *what* is wrong. For example, is it the architecture, the training, the hardware, or the implementation itself?", "grounding_specificity_rationale": "The reviewer mentions \"ImageNet\" and \"AlexNet\" and \"ResNet18\". These are specific models and datasets. The reviewer clearly identifies the *models* being used, which helps the authors pinpoint the relevant parts of their code or implementation. The reviewer also specifies *which* models and *what* the accuracy is.", "verifiability_rationale": "The reviewer makes a judgment about the implementation being 'slow\" and \"low accuracy\" and attributes it to the authors' implementation of ImageNet. This is a claim requiring justification. However, the reviewer provides specific timing and accuracy numbers. These are factual statements that *could* be used as evidence, though they aren't explicitly linked to the implementation. The *lack* of a direct link to the implementation is a weakness.", "helpfulness_rationale": "The reviewer points out a clear problem with the implementation (slow and inaccurate). However, they don't offer *specific* solutions or actionable steps. They identify the *models* and the * issue (slow and inaccurate), but not the * cause or the * fix. The reviewer could have suggested potential reasons for the slow speed and low accuracy (e.g., inefficient code, suboptimal hyperparameters) or suggested alternative approaches. Without concrete suggestions, the review point is more of a diagnosis than a prescription."}
{"actionability_label": "High", "grounding_specificity_label": "5", "verifiability_label": "High", "helpfulness_label": "High", "actionability_rationale": "The reviewer provides a clear and actionable suggestion by stating 'I a bit doubt that its classification error is universally as good as the standard softmax network' and proposing 'report the classification accuracy of the proposed classifier on ImageNet data'. The action is explicit and directly addresses the concern about classification accuracy. The reviewer also suggests 'some theoretical justifications, if possible', which further clarifies the desired outcome. The reviewer's intent is very concrete, aiming to quantify the performance difference.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'ImageNet data' when stating their doubt about the new classification network's classification accuracy. This provides a clear and specific reference point for the authors to evaluate the performance. Additionally, the reviewer suggests 'some theoretical justifications', which further specifies the type of information the authors should be looking for. The grounding is strong because the specific dataset and the nature of the justification are clearly identified.", "verifiability_rationale": "The reviewer makes a claim by stating 'I a bit doubt that its classification error is universally as good as the standard softmax network'. This claim is then followed by suggestions for verification: 'report the classification accuracy of the proposed classifier on ImageNet data' and 'some theoretical justifications, if possible'. The reviewer provides concrete steps for the authors to take to validate their concern. The reasoning is logical \u2013 if the new network is claimed to be universally better, its performance on a standard benchmark like ImageNet should be evaluated. The suggestion for theoretical justifications indicates a desire for a deeper understanding of why the performance might differ. The evidence provided by the reviewer is sufficient to guide the authors in verifying the claim.", "helpfulness_rationale": "The reviewer's comment is 5 because it directly addresses a potential weakness in the proposed method (potential decrease in classification accuracy) and provides clear, actionable steps for the authors to take to address this weakness. By suggesting 'report the classification accuracy of the proposed classifier on ImageNet data' and 'some theoretical justifications, if possible', the reviewer guides the authors on what specific experiments and analyses they should perform. This proactive approach empowers the authors to improve their draft by identifying and addressing the potential performance gap. The reviewer's comment is not just a critique but also a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential issue with the experimental comparison and asks questions about the pretraining of compared methods. While the reviewer identifies a problem (unfair comparison) and asks a question (about pretraining), the action is not explicitly stated. The reviewer suggests investigating the pretraining details of baselines, but doesn't directly instruct the authors on how to do this. Therefore, the action is implicit.", "grounding_specificity_rationale": "The reviewer mentions 'experimental comparison with other methods' and 'pretrained model' as the areas of concern. While they identify the *type* of comparison and the *technical detail* of pretraining, they do not specify *which* part of the paper or comparison this refers to. The reviewer is vague about the specific comparison being unfair or the specific pretraining details of the baselines. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer states that the comparison 'seems to be a bit unfair' and that the 'proposed method without SSL performs inferior to most of the compared methods'. This is a claim that the reviewer is making based on their observation. However, the reviewer does *not* provide any specific evidence or reasoning within the review point to *justify* why the comparison is unfair or why the proposed method performs worse without SSL. The claim is presented without sufficient support within the review point itself. Therefore, the verifiability is low.", "helpfulness_rationale": "The reviewer raises a valid concern about the fairness of the experimental comparison and the lack of detail regarding the pretraining of compared methods. This points to a potential issue in the experimental setup and highlights the importance of clear reporting. While the reviewer doesn't provide a direct solution, they identify a potential area for improvement in the experimental design and reporting. Therefore, the review point is helpful in identifying a potential flaw."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer's comment is explicit in identifying areas where the paper could be improved. They directly point out the lack of alternate formulations for Confidence Diversity (CD) and the ambiguity surrounding the interpretation of line 113. While they don't explicitly state an action, the suggestion to describe alternate formulations and clarify the meaning of line 113 implies a desire for concrete actions to be taken. The reviewer is asking for *how* CD is being used, not just *that* it's being used. This suggests a desire for more specific and actionable feedback.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'line 113' in their comment. This demonstrates a clear grounding of their comment in a specific section of the paper. They are directly referring to a particular point in the text, indicating they understand the content of that section and have identified a specific issue within it. The comment is not just about a general area of confusion but points to a specific line number.", "verifiability_rationale": "The reviewer's comment is not a claim or a question that requires justification. They are pointing out a gap in the paper's explanation and suggesting improvements. There is X that something is correct or incorrect, and there is no suggestion for additional experiments. The comment is about the *lack* of something, not about *providing* something. Therefore, it doesn't fall under the 'verifiability' aspect, which is about the support for a claim.", "helpfulness_rationale": "The reviewer's comment is highly constructive and directly addresses specific areas of potential improvement in the paper. They are not criticizing the work itself but rather pointing out specific limitations in the explanation of Confidence Diversity (CD) and the clarity of a particular statement (line 113). They are suggesting concrete actions, such as describing alternate formulations for CD and clarifying the meaning of line 113. This makes the comment 5 for guiding the authors in improving their draft. The reviewer is not asking for a retraction or a completely different approach, but rather for a more detailed and clearer explanation of existing concepts."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer states that the human follows a speech recording for approximately 1 hour, while the model follows for about 15 hours. This difference in followup time is an explicit statement. However, the reviewer does not provide concrete instructions on how the authors should use this information. They do not specify that the authors should adjust the model's training data or adjust the evaluation protocol. The reviewer only suggests that the difference in followup time explains why the human baseline is weaker, which is an inference, not a direct action. Therefore, while the action is implicitly stated, the reviewer does not clearly guide the authors on how to act upon this information.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the abstract' as the part of the paper they are referring to. This provides a clear grounding point. However, the reviewer also mentions 'the followup time' which is not a specific section or table, but rather a concept related to the experimental setup. While the abstract is clearly identified, the reviewer does not explicitly state what is *wrong* with the abstract's discussion of followup time. The grounding is partially specific, but the issue being addressed is not fully pinpointed.", "verifiability_rationale": "The reviewer states that the human follows a speech recording for approximately 1 hour, while the model follows for about 15 hours. This is a factual statement supported by external knowledge about human attention span and model capabilities. The reviewer also states that 'in the abstract, the authors mention \"already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources\" which is a bit misleading given the 1 hour vs.' This statement is also verifiable because it is a logical deduction based on the information provided in Section 4.1. The reviewer correctly identifies a discrepancy between the human baseline and the model's performance based on the followup time. All claims are supported by logical reasoning or external knowledge.", "helpfulness_rationale": "The reviewer points out a crucial difference between human and model performance based on the followup time. This is a relevant observation for the authors who are likely working on similar tasks. The reviewer also highlights a misleading claim in the abstract, which directly relates to the authors' findings. This helps the authors interpret their results in the correct context. While the reviewer doesn't provide a direct solution, they offer valuable context and a potential misinterpretation, which is helpful for understanding the limitations of the model and the human baseline. The reviewer's point is directly relevant to the authors' work and helps them understand a potential gap in their understanding or the model's capabilities."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that 'RL methods are used in other methods' and 'none of them is used as a baseline'. This directly points to a missing element and provides a clear direction for improvement. The reviewer identifies the *what* (RL methods) and the *why* (they are used in other methods and should be baselines).", "grounding_specificity_rationale": "The reviewer mentions 'RL methods' generally. While they imply it's relevant to the *related work* section, they don't pinpoint a specific section, table, figure, or unique aspect of the paper where this omission is particularly significant. The grounding is implicit rather than explicit.", "verifiability_rationale": "The reviewer makes a claim that 'RL methods are used in other methods' and 'none of them is used as a baseline'. This claim is generally verifiable based on common knowledge in the field of NMT. While a citation would strengthen it, the reviewer's statement is plausible and supported by the reviewer's own statement that they 'discuss other methods for training NMT models beyond MLE (e.g., RL methods)'.", "helpfulness_rationale": "The reviewer's point is 5 because it directly identifies a gap in the related work discussion. By pointing out the absence of RL baselines, the reviewer provides a concrete direction for the authors to improve their understanding of the field and potentially strengthen their own work by comparing against these methods. The suggestion to include RL methods as baselines is actionable and specific."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests investigating the impact of different random projection matrices on the MFTMA scores. This is a clear and direct action the authors should take.", "grounding_specificity_rationale": "The reviewer mentions 'pathological projection matrices' and suggests 'seeing the resilience of the metric to the choice of random projection.' They also refer to the 'MFTMA capacity and width scores.' They name the method (MFTMA) and the specific aspects of the scores they are concerned about. They also suggest checking the appendix, which is a specific location.", "verifiability_rationale": "The reviewer makes a claim: 'I might have missed this in the appendix, though.' They also suggest checking the appendix as an 'external reference.' While the suggestion to check the appendix is an external reference, the core claim is that there might be a concern about the method's robustness with random projections, which could be verified by looking at the appendix (or by the authors themselves).", "helpfulness_rationale": "The reviewer provides a concrete suggestion: 'It would still be helpful to see resilience of the metric to the choice of random projection.' This is a clear and actionable suggestion that directly addresses a potential weakness of the method."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the evaluation of FGT is *leveraged* to evaluate the method performance in the ablation study. This is a clear and direct statement of how the FGT evaluation is being used. The reviewer also states it is *only* used for this purpose, which is also explicit.", "grounding_specificity_rationale": "The reviewer refers to the *evaluation of FGT* as the part being addressed, but does not explicitly name it. This can be considered 'weak grounding'. However, the reviewer clearly specifies the *purpose* of this evaluation, which is the 'evaluation of method performance in the ablation study'. This provides a clear indication of what aspect is being discussed and its intended use, making it 'specific'.", "verifiability_rationale": "The reviewer makes a claim that 'the evaluation of FGT is only leveraged to evaluate the method performance in the ablation study'. This claim is supported by the statement itself, which is a direct assertion about the methodology. The reviewer provides a clear and unambiguous description of the FGT evaluation's role in the ablation study.", "helpfulness_rationale": "The reviewer's point, while valid, is more of a metacomment about the paper's organization and clarity regarding the FGT evaluation's purpose. It doesn't directly provide actionable feedback or suggest specific improvements to the method. Therefore, it is not immediately helpful in terms of directly guiding the authors on how to improve their own work. It highlights a potential area of confusion for readers trying to understand the experimental setup."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point is a statement of fact, not a request for improvement. It doesn't explicitly *say* \"You should consider a broader change to the task or language.\" It's a declarative statement about the current focus.", "grounding_specificity_rationale": "The reviewer's comment is a general statement about the work's focus (narrow task in a specific language) and its potential broader impact. It does not explicitly identify a specific part of the paper or unique element being addressed. The comment is about the *nature* of the task and language, which is somewhat general.", "verifiability_rationale": "The review point contains a claim (\"its broader impact may be limited\") and provides a suggestion for improvement (\"So its broader impact may be limited.\"). However, the claim is not explicitly supported by logical reasoning, common knowledge, or external references within the review point itself. It's an inference based on the reviewer's understanding of the work's scope.", "helpfulness_rationale": "The review point identifies a potential limitation of the work's scope and suggests considering a broader impact. While it doesn't offer specific, actionable steps for improvement in the current draft, acknowledging a limitation can be helpful for guiding future research directions and encouraging a broader perspective. It prompts the authors to reflect on the scope and potentially expand their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a concern about the choice of a subset of MTEB and its implications for generalizability. While the reviewer doesn't explicitly propose a specific action or solution, the act of raising this concern and suggesting further investigation can be interpreted as an implicit call for the authors to consider the limitations of their evaluation strategy. The reviewer is prompting the authors to think about the scope of their evaluation and potential biases introduced by using only a subset.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Massive Text Embedding Benchmark (MTEB)' and refers to a 'subset' of it. This clearly identifies the paper and the specific aspect being discussed. The reviewer is pointing to a specific area within a larger benchmark, making the grounding quite explicit.", "verifiability_rationale": "The reviewer states a concern ('raises questions about generalizability') and suggests further investigation ('it would be helpful to understand the criteria behind this selection and whether other tasks or datasets might yield different insights'). This indicates a claim or suggestion. The reviewer offers reasons ('criteria behind this selection') and potential avenues for further exploration ('whether other tasks or datasets might yield different insights'), suggesting a degree of logical reasoning and potential for external references (though not explicitly named).", "helpfulness_rationale": "The reviewer's comment is relevant to the authors as it highlights a potential limitation in their evaluation strategy. By pointing out the use of a subset of MTEB and raising questions about generalizability, the reviewer is prompting the authors to consider the scope and potential biases of their evaluation. This is a valuable piece of feedback that could lead to a more comprehensive assessment of their work. While the reviewer doesn't provide specific solutions, the question itself is a helpful prompt for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer implies that the paper is not selfcontained and that the supplementary material is necessary to understand it. This suggests an implicit action or suggestion, but the lack of specific details about what is missing or how the supplementary material helps makes the action somewhat vague and not fully actionable.", "grounding_specificity_rationale": "The reviewer states that the paper is not selfcontained and that the supplementary material is necessary to understand 'large parts' of the main paper. This implies a lack of specific identification of which part of the paper is missing information about. The use of 'large parts' is also vague and does not pinpoint a specific section, table, figure, or unique aspect of the paper. Furthermore, the reviewer does not specify what is missing or how the supplementary material helps understand these parts, making the grounding underspecific.", "verifiability_rationale": "The reviewer makes a claim that the paper is not selfcontained and that the supplementary material is necessary to understand parts of the main paper. However, the reviewer does not provide any evidence, reasoning, or external references to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the statement, making it 1.", "helpfulness_rationale": "The reviewer identifies a clear problem: the paper is not selfcontained and requires supplementary material for understanding. While this is a valid point, the reviewer's suggestion to release the source code is a request rather than a constructive suggestion for improvement within the paper itself. The lack of specific feedback makes the review point somewhat limited in its helpfulness for the authors to improve their current draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states a suggestion for improvement by asking for the justification of the choice of the REINFORCE algorithm over alternatives like PPO. This constitutes an explicit action or statement that the authors should apply: to consider alternative algorithms and their potential benefits. The reviewer clearly identifies a methodological choice and suggests an improvement by providing more context.", "grounding_specificity_rationale": "The reviewer mentions 'REINFORCE algorithm' and 'PPO' explicitly, which are specific terms related to the paper's focus on attention models. While the reviewer doesn't provide a specific section number, the connection to the ongoing research and the specific algorithms is reasonably clear. The reviewer is grounding the suggestion within the context of the paper's focus.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are asking for a rationale, which is a request for information rather than a statement that needs to be supported by evidence. Therefore, it doesn't fall under the 'Verifiability' aspect.", "helpfulness_rationale": "The reviewer is directly asking for a justification, which is a clear and actionable suggestion for the authors. They are prompting for more information that could help them improve their draft. This is a helpful suggestion as it directly addresses a potential area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states a missing element (discussion about Set Transformer and related works) but doesn't directly instruct the authors on how to address it. It implies the need for action but lacks concrete steps.", "grounding_specificity_rationale": "The comment explicitly mentions 'Set Transformer (https://arxiv.org/abs/1810.00825)' and 'other related works that also uses summary tokens'. This provides strong grounding as the specific paper and the shared characteristic are identified. The comment also implicitly identifies the need for a 'discussion' and 'related works' section, adding further grounding.", "verifiability_rationale": "The comment points out a factual deficiency: the absence of a discussion about the mentioned works and related concepts in the paper's related work section. While the *reason* for this omission might be implicit (e.g., it's a wellknown area), the *fact* of the missing discussion is clear and verifiable by examining the paper's content. The reasoning is implicit but the claim is present.", "helpfulness_rationale": "The comment identifies a significant omission in the paper's related work section. It is likely to be helpful for the authors to understand what is missing and guide them towards including this discussion. While it doesn't provide specific content, it highlights a crucial area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3: Weakly Grounded", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer is stating a lack of information, which is not an explicit instruction or action the authors should take. While they identify a potential area of confusion, they are not directly prompting the authors to perform a specific action.", "grounding_specificity_rationale": "The reviewer is asking about a specific training detail but does not explicitly point to a particular section, table, or figure. They can infer this is related to residual learning, but not precisely where in the paper this would be discussed.", "verifiability_rationale": "The reviewer is stating a factual gap: 'I can't find details on how they make the network fit the residual instead of directly learning the input  output mapping.' They are not providing a claim that requires verification or justification.", "helpfulness_rationale": "The reviewer is pointing out a missing detail that could be relevant for understanding the method. While the information might be present elsewhere or implied, the lack of explicit mention makes it less helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking for specific details about the experiment setup, which are crucial for understanding and potentially replicating the work. While not explicitly stating an action to take, the request implies a desire for information that would be directly actionable for the authors to improve their draft. The reviewer is essentially prompting for a concrete step in the experimental process.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'BadNets' and asks for details about 'data augmentation methods' and 'learning rate'. This clearly indicates a strong grounding in the specific paper and the relevant experimental parameters. The information is not just general but points to specific elements of the experimental setup.", "verifiability_rationale": "The reviewer is not making a claim about the correctness or quality of the work. Instead, they are pointing out a missing element in the description of the experiment. While they imply a need for this information, they are not providing a claim that requires verification. Therefore, it's not verifiable in the sense of providing evidence for or against something, but it highlights a gap in the provided information.", "helpfulness_rationale": "The review points out a clear weakness in the submitted draft: the lack of specific details about the experiment setup. This is a valuable piece of feedback because it directly informs the authors how to improve their draft by including this crucial information. While it doesn't tell them *how* to choose the data augmentation methods or learning rate, it guides them towards including this information, which is essential for understanding and potentially replicating the work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer asks a question about whether statistical significance tests were done. This is an explicit question about a methodological choice. However, the reviewer does not specify which statistical significance test was used or how it was performed, making the action vague. The reviewer is asking what was done, not how to improve the draft based on the closeness of numbers.", "grounding_specificity_rationale": "The reviewer asks a general question about statistical significance tests in the context of comparing proposed methods and baselines. They do not specify which part of the paper they are referring to (e.g., a specific table, figure, or section). The question is about a general practice, not a specific issue within the paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer makes a claim by asking 'did you do any statistical significance test?'. However, the review does not provide any evidence or justification for this claim. It does not explain why the numbers are close, what the implications might be, or provide references to support the importance of statistical significance in this context. The claim is posed as a question without supporting reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer's question is directly relevant to the authors. It prompts a discussion about a standard practice in research (statistical significance testing) and raises a valid concern about the interpretation of close numerical results. While the review doesn't provide a solution, it encourages the authors to consider the statistical significance of their findings and the implications of the closeness of the numbers. It raises a relevant question that can help the authors improve their understanding and potentially their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their concern about the choice of statistical test and provides a specific alternative (Wilcoxon signedrank test) and explains why it's more appropriate given the paired nature of the data. This demonstrates a clear and actionable suggestion for improvement.", "grounding_specificity_rationale": "The reviewer clearly identifies the issue as an incorrect choice of test and then narrows it down to a specific alternative test, demonstrating strong grounding in the problem. They also specify the context (two samples from the same input), adding to the specificity.", "verifiability_rationale": "The reviewer makes a claim about the potential inappropriateness of the current test and provides a justification for the suggested alternative, making the claim verifiable. They also explain why the Wilcoxon signedrank test is suitable for paired data from the same input.", "helpfulness_rationale": "The reviewer directly addresses a potential methodological flaw and offers a clear alternative. This is 5 for the authors as it guides them towards a more appropriate analysis method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the desired actions: 'give more background knowledge' and 'bring the description of the relate literatures forward'. This indicates a clear intention to improve the paper. However, the reviewer does not specify how these actions should be implemented, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'background knowledge' and 'related literatures', indicating they understand the need for this information. However, they do not specify which particular background knowledge or which specific related literature they are referring to, making the grounding weak.", "verifiability_rationale": "The reviewer states 'The organization of this paper could be further improved' and 'such as give more background knowledge of the proposed method and bring the description of the relate literatures forward'. While these statements indicate a problem and potential solutions, the reviewer does not provide any justification or reasoning for why the current organization is problematic or why the suggested changes will be effective.", "helpfulness_rationale": "The reviewer identifies a weakness in the paper's organization and provides suggestions for improvement. While the suggestions are present, the reviewer does not explain the specific issues with the current organization or how the proposed changes will address those issues. The feedback is present but lacks detailed reasoning."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states an action: 'Some other representative panoptic segmentation models are not compared' and provides a concrete suggestion: 'like PanopticFPN, Mask2Former, etc.' This indicates a clear intention to improve the paper by including more comparisons. The action is also concrete as it specifies the *type* of models to compare. While it doesn't identify *where* the comparison should be made, it clearly states what needs to be done.", "grounding_specificity_rationale": "The comment explicitly mentions 'PanopticFPN' and 'Mask2Former', which are specific models. The reviewer is also implicitly suggesting that the current comparison is lacking by stating 'some other representative panoptic segmentation models are not compared'. This demonstrates a clear identification of the specific part of the paper (the comparison section) and the specific issue (lack of comparison with certain models).", "verifiability_rationale": "The comment contains a claim: 'Some other representative panoptic segmentation models are not compared'. This claim is supported by logical reasoning. The reviewer is stating a factual observation about the current related work and suggests a specific improvement. While there isn't a direct citation, the reasoning is clear and based on common practices in academic writing (comprehensive related work). The claim is verifiable by checking the related work section and considering standard choices in the field.", "helpfulness_rationale": "The review point directly suggests a specific improvement: comparing the proposed method with PanopticFPN and Mask2Former. This is a clear and actionable suggestion for the authors. The reviewer is not asking for a general review, but rather a specific comparison with established models. This provides a clear direction for the authors to enhance their work. The suggestion is also grounded by mentioning specific models, making it concrete. The claim is supported by logical reasoning, suggesting a need for more comprehensive comparisons."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The suggestion is not explicit or concrete. It lacks specific details on which modalities, methods, or experiments are needed. It's a general desire for more information. While the authors can infer that they should explore alternative data representations or different evaluation metrics, the comment does not explicitly state this or provide guidance on how to implement this change. The lack of explicitness makes it less actionable compared to suggestions that directly point to specific sections or tables within the paper.", "grounding_specificity_rationale": "The review point doesn't explicitly refer to any specific part of the paper. It's a general suggestion about the *type* of results. While the authors might infer that the 'other modalities' refer to different data formats or evaluation methods, the comment does not pinpoint a specific section, table, figure, or unique element of the paper that needs improvement. The lack of explicit reference makes it less grounded compared to suggestions that directly point to specific aspects of the paper.", "verifiability_rationale": "The review point is a suggestion, not a claim requiring verification. It proposes a direction for future research but does not make a statement that needs to be supported by evidence or references. Therefore, it doesn't fit into the 'claim extraction' category defined in the 'Verifiability' section, and the 'verifiability verification' process is not applicable.", "helpfulness_rationale": "The suggestion is relevant and points towards a valuable direction, but it lacks specific details to be truly helpful. It's more of a highlevel recommendation than a concrete improvement plan. While the authors understand the importance of diverse data representations, the comment doesn't provide any specific steps on how to achieve this. For example, it doesn't suggest exploring specific alternative modalities (e.g., audio, tactile data), or how to adapt the current evaluation metrics to these new modalities. The lack of specificity makes it less helpful compared to suggestions that provide concrete steps or directions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the lack of comparison with CoCoOp and suggests a necessary comparison. The action 'compare with CoCoOp' is clear and direct. The reviewer identifies a specific missing element and proposes a concrete action.", "grounding_specificity_rationale": "The review point explicitly mentions 'CoCoOp' by name. This is a clear and specific identification of the related work. The comment also specifies the action of 'comparing' with this work.", "verifiability_rationale": "The review point contains a claim: 'It is necessary to compare with CoCoOp'. The reviewer provides a justification for this claim by stating 'as the extended version of CoOp, it is necessary to compare with CoCoOp'. This justification, while not a direct logical deduction, provides a basis for the claim.", "helpfulness_rationale": "The review point is a clear and actionable suggestion for the authors. It identifies a specific gap in the related work comparison and proposes a concrete next step (comparing with CoCoOp). This directly helps the authors improve their understanding of the field and their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the limitation of the experiments and suggests the authors should consider more complex games. This is an explicit action. It also provides concrete details about the potential issues with larger depth and huge inputs, making it a concrete action to take.", "grounding_specificity_rationale": "The comment explicitly mentions 'ReBeL's performance on more complex problem' and 'bigger depth of the game'. This clearly identifies the specific aspect of the paper being addressed. The reviewer provides a specific definition of 'more complex' and even speculates on 'huge inputs', which are details relevant to the referenced part.", "verifiability_rationale": "The comment contains a claim about the limitations of the experiments and suggests improvements. While the reviewer doesn't provide new external references, the criticism of 'typical games' implies a lack of awareness of current best practices. The potential issue of 'huge inputs' is a logical consequence of increased complexity, but lacks specific citations. The claim is generally verifiable based on common knowledge in the field.", "helpfulness_rationale": "The comment directly identifies a limitation in the experimental setup and provides a clear suggestion for improvement (testing on more complex games). This is 5 and directly relevant to the authors' work. The reviewer also highlights a potential issue ('huge inputs') that the authors might not have considered, making the comment helpful in identifying areas for further investigation. While the criticism of 'typical games' might not be entirely novel, it encourages the authors to think beyond their current scope."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing information: 'the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of original QUBO.' This is a clear and direct identification of a weakness, making it actionable for the authors.", "grounding_specificity_rationale": "The review point explicitly identifies the specific area lacking discussion: 'the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of original QUBO.' This precise combination of terms demonstrates strong grounding specificity, as the authors can easily pinpoint the referenced concept.", "verifiability_rationale": "The review point implicitly suggests the importance of this theoretical guarantee by implying a lack of confidence or rigor in the method's performance. While it doesn't explicitly state 'This is important to discuss,' the context strongly suggests it. The logical reasoning is that understanding the approximation ratio provides insight into the method's efficiency and reliability compared to the optimal solution.", "helpfulness_rationale": "The review point is 5 because it directly points out a specific weakness (lack of theoretical analysis) and suggests a concrete improvement (discussing the approximation ratio). This actionable feedback is likely to guide the authors towards a deeper analysis and potentially stronger validation of their method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point implicitly suggests the need for a quantitative measure by stating its 'lack' and implying the need for one. While it doesn't explicitly state 'add a confusion matrix,' the lack of *anything* quantitative is the key. The reviewer is pointing out a missing element and suggesting its inclusion. Therefore, it's 3 as it identifies a gap and suggests a solution, but it lacks specific guidance on *how* to implement this action.", "grounding_specificity_rationale": "The review point mentions 'quantitative measure' and 'VCEs,' which are specific terms related to the paper's content. However, it doesn't explicitly state *where* these VCEs are located or if they are in a specific table or section. The reviewer is pointing out a lack of a *specific* measure, making the grounding somewhat weak. However, the focus on 'VCEs' provides a level of specificity. Therefore, it's weakly grounded as it doesn't pinpoint the exact location, but it does identify the area of concern with specific terminology.", "verifiability_rationale": "The review point makes a claim about the lack of a quantitative measure and the reliance on visual inspection. It also provides a reason for this lack \u2013 the common practice of visual inspection. This provides some level of support for the claim. Therefore, it's 3 as it identifies a claim and provides some justification for it, but it could be more robust by explicitly stating *why* visual inspection is considered insufficient.", "helpfulness_rationale": "The review point is 5 because it directly identifies a significant limitation in the evaluation process \u2013 the reliance on subjective visual inspection. It clearly suggests a concrete improvement: the inclusion of a quantitative measure. This is a valuable and actionable feedback for the authors. Therefore, it's 5 as it identifies a clear weakness and provides a constructive suggestion that directly addresses the identified problem."}
{"actionability_label": "Low", "grounding_specificity_label": "Highly Grounded and Specific", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a problem ('artifacts') but does not explicitly state how to address it. While the question ('improve') implies an action, the specifics are missing. The statement 'The action recognition performance is much below the current stateoftheart on the UCF dataset' identifies a weakness but doesn't provide a concrete step to fix it. The lack of explicit instructions makes it difficult for the authors to take immediate action.", "grounding_specificity_rationale": "The review point explicitly mentions 'generated videos' and then narrows it down to 'beach videos' in the context of the UCF dataset. It also refers to the 'UCF dataset' itself, which is a specific benchmark. The mention of 'significant artifacts' and the comparison to 'current stateoftheart on the UCF dataset' which uses 'deeper, also processing optic flow' architectures, provides clear grounding in the specific aspects of the work being discussed. The authors can easily identify the relevant parts being criticized.", "verifiability_rationale": "The review point makes a claim about the 'action recognition performance being much below the current stateoftheart on the UCF dataset'. This claim is supported by the mention of 'deeper, also processing optic flow' architectures, which are known to perform better on such tasks. While the level of detail could be increased, the core claim is supported by common knowledge in the field and the reference to a specific benchmark dataset. The logical reasoning is that deeper networks and the use of optic flow are generally accepted improvements for action recognition.", "helpfulness_rationale": "The review point clearly identifies a problem ('artifacts') and suggests a direction for improvement ('improve'). It also highlights a performance gap ('much below the current stateoftheart...deeper, also processing optic flow' architectures). This provides the authors with a clear goal and potential areas for enhancement. The questions posed are directly aimed at addressing these identified issues. The feedback is directly relevant to the work being discussed."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a question, which implies a desire for clarification. While the question prompts an action (clarification), it is not explicitly stated. The action of asking for clarification can be considered implicit. Therefore, it is 2.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the work of DoshiVelez, F., & Kim, B. (2017).', providing a clear grounding of the relevant work. They also refer to 'the notion described in the work', further specifying the area of interest. This demonstrates strong grounding specificity.", "verifiability_rationale": "The reviewer is making a claim that the concept of 'interpretable' in their work is relevant to the specific paper on interpretable machine learning. This claim is asking for a judgment (agreement or disagreement) based on the connection between the two. While the reasoning for this claim is the connection to the specific ML paper, the claim itself is not directly supported by logical reasoning or external references within the review point. Therefore, it is 3.", "helpfulness_rationale": "The reviewer is asking a focused question about the relevance of a specific concept to their work. This is likely to be helpful for the authors if they are working on interpretable machine learning. However, it is a specific question and its helpfulness depends on the authors' current focus. It is not universally high or low, but it is likely to be 3 in the context of interpretability."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The statement 'The experiments are limited to MNIST and a single realworld dataset' is explicit because it directly states a limitation of the experimental setup. It clearly identifies the datasets used, providing the reviewer with specific information. The action is to identify this limitation, and the concreteness is evident as the reviewer names the specific datasets. This provides the authors with a clear understanding of the scope of their experiments.", "grounding_specificity_rationale": "This review point is **1**. While it mentions 'experiments' and 'datasets', it doesn't specifically identify a *part* of the paper or methodology being discussed. The reviewer is making a general comment about the experimental setup. It is also **not specific** as it doesn't detail what is lacking within those datasets or the experiments themselves. It's a broad statement about the overall experimental scope.", "verifiability_rationale": "This review point is **not verifiable**. It states a limitation or a fact about the experiments but doesn't provide any justification or reasoning for why these experiments are limited. There are no external references or logical arguments presented to support this claim. It's a statement of fact without further explanation.", "helpfulness_rationale": "This review point is **not helpful**. While it identifies a valid concern (the limited scope of experiments), it fails to provide any actionable feedback or suggestions for improvement. The reviewer points out a weakness but doesn't offer any concrete steps the authors could take to address it or enhance their work. It's a factual observation without any constructive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer states a claim about ReLU's limitations in deep/convolutional networks, which is an explicit statement. However, the action of identifying these limitations isn't explicitly detailed. The reviewer also provides a counterexample (AlexNet) which implicitly supports the claim. Therefore, while the reviewer identifies a problem, the exact steps to take are not explicitly laid out, making it 3 but not fully actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'ReLU,' 'deep networks,' and 'convolutional networks,' providing a highly specific reference point. The counterexample of AlexNet further grounds the specific part of the paper being discussed. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim about ReLU's limitations and provides a specific historical example (AlexNet) to support it. This external reference makes the claim verifiable. The logical connection between ReLU's use in AlexNet and its potential limitations in deep/convolutional networks is also implied.", "helpfulness_rationale": "The reviewer identifies a relevant issue (ReLU's limitations in deep/convolutional networks) and provides a specific example (AlexNet) to illustrate it. This context is helpful for the authors and guides them towards potential improvements. While it doesn't offer a direct solution, it highlights a problem and provides a relevant reference, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a specific claim ('the consistency between training and inference can be easily satisfied') and suggests *how* it should be explained (more detail). This is an explicit action the reviewer is suggesting. However, the reviewer does not specify the *exact* nature of the smoothness or how to explain it in detail, making it only partially actionable.", "grounding_specificity_rationale": "The reviewer refers to specific line numbers (Line 9597 and Line 308310), indicating they can identify the specific part of the paper being addressed. However, the reviewer does not specify *what* is wrong or missing in that part, only that it needs more explanation. Therefore, the grounding is weak as the specific issue is not detailed.", "verifiability_rationale": "The reviewer states a claim about the paper's content ('the paper addresses many times ... I would suggest giving more explanations on this') and suggests providing more explanations. While the reviewer identifies a potential area for improvement, they do not provide any specific evidence or justification for why more explanations are needed or what kind of explanations would be beneficial. The claim is not supported by logical reasoning, common knowledge, or external references within the review point itself.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the paper ('the consistency between training and inference can be easily satisfied') and provides a constructive suggestion for improvement ('I would suggest giving more explanations on this'). This demonstrates a clear desire to help the authors improve their draft, making the review point helpful, even if the *how* of the explanation is not fully specified."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "2 (3)", "verifiability_label": "X (X)", "helpfulness_label": "4 (4)", "actionability_rationale": "The reviewer explicitly asks a question about a specific change to the model parameters: 'is there any improvements when the proposed model use larger word embedding, and LSTM parameters?'. This is a direct and concrete request for information. The reviewer is not inferring the need for larger parameters but rather asking about the *improve*.", "grounding_specificity_rationale": "The reviewer directly references the authors' claim about their model achieving superior performance with fewer parameters and smaller word embedding and LSTM sizes. The phrase 'Authors claim their model can achieve superior performance having significantly fewer parameters than baseline 1' clearly identifies the specific part of the paper the reviewer is referring to. The reviewer is also asking a specific question about the *parameters* within that referenced claim.", "verifiability_rationale": "The reviewer does not explicitly state a claim. They are asking a question to seek information about the impact of parameter changes. While the question is wellposed and relevant, it doesn't present a statement that requires verification or justification. Therefore, it falls under the 'X' category (X).", "helpfulness_rationale": "The reviewer's comment is helpful because it seeks to clarify and validate the authors' claims about parameter choices. By asking about the performance of the model with larger parameters, the reviewer is trying to understand the impact of these choices on the model's performance. This is a valuable question for understanding the methodology and potentially identifying areas for improvement or further investigation. While it doesn't directly point out a flaw, it contributes to a more thorough understanding of the work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the hyperparameters k and \u03b7 require finetuning. This directly informs the authors of a necessary action they should take to use the method effectively. The phrase 'requires finetuning' is a clear instruction on how to proceed.", "grounding_specificity_rationale": "The comment mentions the hyperparameters k and \u03b7 but does not specify which particular hyperparameter or which specific aspect of the environment or OPE method necessitates finetuning. It's a general statement about the hyperparameters requiring adjustment, not a precise identification of the problematic element.", "verifiability_rationale": "The comment states a fact: 'the hyperparameters introduced k and \u03b7 require finetuning'. However, it does not provide any justification or evidence for this claim. It simply asserts the need for finetuning without explaining *why* or providing *examples* of the issues involved.", "helpfulness_rationale": "The comment identifies a practical limitation: the need for finetuning the hyperparameters k and \u03b7. While this points out a problem users might face, it does not offer any guidance on how to overcome this limitation. It's a diagnosis of a problem, not a prescription for it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The suggestions are directly stated ('fix the form', 'correct the grammatical error', 'address the question'), indicating explicitness. However, the action of 'fixing the form' and 'correcting the grammatical error' lacks specific details on how to achieve these changes. The 'address the question' is a broad instruction without specific guidance. Therefore, while the suggestions are explicit, they are vague and lack concrete details on how to apply them.", "grounding_specificity_rationale": "The reviewer explicitly mentions the lines (108 and 115) where the issues are supposed to be. This clearly indicates strong grounding as the authors can precisely identify the referenced part of the paper. However, the reviewer does not specify the *nature* of the issues at these lines (e.g., specific typo, grammatical error). The suggestion is to 'fix the form' and 'correct the grammatical error' at these lines, which implies the errors are likely related to these, but the exact nature is not specified. Therefore, the grounding is strong, but the specificity of the issues is lacking.", "verifiability_rationale": "The reviewer states that 'line 108, the first 'f' should be 'g'' and 'extra '.' in the middle of a sentence in line 115.' These statements are claims that require verification. However, the reviewer does not provide any evidence or justification to support these claims. There is no logical reasoning, common knowledge, or external references provided to back up these assertions. The reviewer also poses a question about the convergence of a baseline method without offering any proposed solutions or justifications. Therefore, the claims are not wellsupported.", "helpfulness_rationale": "The reviewer points out potential issues with the form at line 108 and a grammatical error at line 115. They also raise a question about the convergence of a baseline method. While these are relevant points, the suggestions provided ('fix the form', 'correct the grammatical error', 'address the question') are not wellsupported by evidence or specific guidance. The lack of evidence to back up the claims makes it difficult for the authors to know how to proceed. The question about convergence is also not helpful without any proposed solutions. Therefore, the review point lacks concrete and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states the limitation of FedPCL's performance depending on pretrained models and suggests a lightweight framework as a solution. While it identifies an issue and proposes a potential improvement, it lacks specific details on how to choose appropriate pretrained models or how the framework addresses the sensitivity. The action is implicit, requiring the authors to infer the need for experimentation and the framework's role.", "grounding_specificity_rationale": "The review point generally discusses the performance of FedPCL and model accuracy. While it mentions 'different pretrained models' and 'lightweight framework,' it doesn't explicitly and precisely identify a specific section, table, or unique aspect of the paper being addressed. The reference to 'Table 4' is mentioned in the rationale but not the review point itself, indicating a lack of clear grounding.", "verifiability_rationale": "The review point makes a claim about the limitations of FedPCL and the proposed framework's ability to address them. However, it does not provide any evidence or reasoning within the review point itself to support this claim. The claim is stated without verification, making it 1.", "helpfulness_rationale": "The review point identifies a limitation of the existing work (FedPCL's dependence on pretrained models) and suggests a potential improvement (a lightweight framework). However, it does not provide specific actionable steps or justifications for why the lightweight framework is a superior solution or how it addresses the identified limitations. The critique is highlevel and lacks concrete guidance, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment suggests a specific action: 'see the tentative attention maps'. This action is explicit as it directly tells the authors what to do. Furthermore, the action is concrete as it clearly states the desired outcome, which is to visualize or analyze the attention maps. The authors know exactly what needs to be done.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper being addressed. While the suggestion to include 'tentative attention maps' is a valuable idea, the comment doesn't specify *where* these attention maps would be located or what section of the paper they relate to. Therefore, the grounding is weak as the authors cannot confidently pinpoint the referenced part.", "verifiability_rationale": "The comment lacks a claim. It is a suggestion for improvement rather than a statement of opinion or judgment. Therefore, the concept of verifiability does not apply to this review point as there is X to be supported or refuted.", "helpfulness_rationale": "The suggestion to include 'tentative attention maps' is a constructive idea that could provide additional insights into the model's behavior. It directly addresses a potential area for improvement in the qualitative analysis. While it doesn't provide a definitive solution, it offers a concrete direction for the authors to explore, making it 3 in guiding their investigation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'I don't understand Figure 5' and further specifies 'labels are wrong'. This indicates a clear and actionable issue for the authors. They need to understand the figure and correct the labels. The action is directly stated, making it very concrete.", "grounding_specificity_rationale": "The reviewer explicitly identifies 'Figure 5' as the area of concern and further specifies the issue as 'labels are wrong'. This demonstrates strong grounding as the authors can precisely identify the section being addressed. The specificity is high as the exact issue (incorrect labels) is clearly stated.", "verifiability_rationale": "The reviewer states a claim ('I don't understand Figure 5') and provides a reason ('labels are wrong'). While it doesn't provide a citation to external evidence, the claim is logically supported by the reviewer's direct observation. Therefore, it is 3 as it is based on a justified statement.", "helpfulness_rationale": "The reviewer clearly identifies a problem ('I don't understand Figure 5') and suggests a direct action to fix it ('labels are wrong'). This provides the authors with a clear and actionable step to improve their draft. The feedback is specific and directly addresses a potential issue, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review points out that the authors' derivation uses 'classical learning theorybased bounds'. While it implies these bounds might not be realistic, it doesn't explicitly state what specific aspect of the bounds needs to be changed or how to achieve realistic bounds. The suggestion to consider 'Bayesian considerations' is a potential improvement but lacks concrete steps. Therefore, while it identifies a potential issue, it doesn't provide explicit actions or concrete details on how to implement them.", "grounding_specificity_rationale": "The review explicitly mentions 'classical learning theorybased bounds' as the area of concern. This clearly identifies the specific part of the paper being addressed. Furthermore, it specifies the issue: 'do not yield realistic bounds, unless Bayesian considerations are taken into account.' This clearly states what is wrong within the identified section.", "verifiability_rationale": "The review makes a claim about the limitations of 'classical learning theorybased bounds' in yielding realistic bounds. While it doesn't provide specific examples or references to support this claim, it logically infers that the absence of Bayesian considerations might be the reason. The statement 'to the best of my knowledge' indicates that this is a claim based on the reviewer's understanding of the field, making it verifiable through common knowledge and logical reasoning.", "helpfulness_rationale": "The review identifies a potential issue with the authors' theoretical framework by pointing out the limitations of classical bounds. However, it does not provide any specific suggestions or guidance on how the authors should modify their derivation. It suggests considering Bayesian approaches but doesn't explain how or why this would be beneficial. Therefore, while it highlights a problem, it doesn't offer actionable feedback to help the authors improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point points out a *potential* issue (large training loss with suboptimal weight decay) and suggests a *consequence* (suboptimal cosine similarities). It *doesn't* explicitly tell the author *what* to do. Therefore, it's likely *not fully actionable*. While it identifies areas for improvement (training loss, cosine similarities), it doesn't provide concrete steps on how to achieve these improvements.", "grounding_specificity_rationale": "The reviewer refers to 'weight decay is applied to all layers' and 'cosine similarities.' While it names these concepts, it doesn't pinpoint a specific section, table, figure, or unique aspect of the paper where this issue is occurring. It also doesn't specify *what* is wrong with the cosine similarities at high weight decay parameters. Therefore, it's **weakly grounded**.", "verifiability_rationale": "The review point contains a claim: 'we would expect a large training loss and thus suboptimal cosine similarities for large weight decay parameters.' This claim is supported by logical reasoning (the general principle of weight decay's effect on training loss and cosine similarity) and is generally known in the field, though it doesn't explicitly cite a source. Therefore, it is **3**.", "helpfulness_rationale": "The review point identifies a potential issue (large training loss with suboptimal weight decay) and observes that cosine similarities are still good at high weight decay, as shown in the plots. While it doesn't offer concrete solutions, it raises a valid question for the author to investigate why the cosine similarities are behaving this way. This provides context and encourages further analysis, making it **3**."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the omission of the method (unsupervised random forests) in the title, abstract, introduction, and discussion. This is a clear indication of an explicit action that is also concrete, as the reviewer precisely identifies the missing information and the specific sections where it should be present.", "grounding_specificity_rationale": "The reviewer points to the title, abstract, introduction, and discussion as the specific sections where the method is missing. This is strong grounding as the reviewer can accurately pinpoint the referenced part of the paper. The reviewer also explains *why* this is important (correct interpretation of results) and *what* is missing (explanation of unsupervised random forests), making the specificity high.", "verifiability_rationale": "The reviewer makes a claim that the results are for unsupervised random forests. This claim is verifiable because the reviewer provides a logical reasoning for why this information is important (casual readers would remember the wrong conclusions) and suggests a concrete improvement (adding a clarification). While the reviewer doesn't provide external references, the reasoning is clear and the suggestion is actionable, making it 4.", "helpfulness_rationale": "The reviewer highlights a critical omission that directly affects the interpretation of the results. This omission is a significant point that would be 5 for the authors to address. The reviewer's suggestion to clarify the method is a concrete and actionable improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a gap in knowledge and suggests a research direction but does not provide a concrete action for the authors to take. It's a call for more information rather than a directive.", "grounding_specificity_rationale": "The review point refers to \"the dataset\" and \"other QFS datasets\" generally, without specifying particular sections, tables, figures, or unique aspects of the data. The language is about the need for more analysis rather than a specific critique of a defined element.", "verifiability_rationale": "The review point is a statement of a need or a desire for more information, not a claim requiring verification. It's a suggestion for further investigation rather than a statement of what is definitively wrong.", "helpfulness_rationale": "The review point identifies a potential area for improvement (more evidence on training effectiveness) but does not provide specific instructions on how to achieve this. It's a suggestion for further research rather than a direct directive for action."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks for clarification on how node importance is used in a 1shot scenario and why the paper doesn't include a 1shot experiment. While the reviewer's questions are direct, the paper doesn't provide enough detail to fully understand the implementation of the 1shot setting or the specific mechanism of using node importance in this context. The reviewer's questions are not implicit but rather explicit requests for clarification. The level of concreteness is moderate, as the reviewer understands the general concepts of 1shot learning and node importance but seeks specific details on their combination in this paper.", "grounding_specificity_rationale": "The reviewer's questions are about the methodology and implementation details of the paper, specifically regarding the 1shot setting and the use of node importance. While the paper might implicitly refer to a standard 1shot approach, the reviewer cannot confidently determine which part of the paper they are addressing. The reviewer can infer the relevance of the method to 1shot learning, but the specific section and the exact mechanism of using node importance are not explicitly stated. Therefore, the grounding is weak. The specificity is also low as the paper lacks detailed explanations for the reviewer to confidently identify the referenced part and understand the issue.", "verifiability_rationale": "The reviewer presents questions about the paper's methodology and implementation. These questions are not claims that require verification. The paper does not explicitly state a claim that needs to be supported by evidence. Therefore, the claim extraction is 'X (X)'.", "helpfulness_rationale": "The reviewer's questions are directly related to understanding and potentially improving their own work. They are asking for clarification on a key aspect of the paper's methodology. While the paper doesn't directly address the reviewer's questions, the questions are relevant and could be helpful for the authors trying to understand or reproduce the work. The helpfulness is moderate as the questions are relevant but the paper doesn't provide the requested information."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states 'There should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems.' This is a direct and clear call for action on the part of the authors. The action is to expand the discussion on a specific technical aspect of LLMs. The reviewer is confident about the need for this discussion, making it a concrete action.", "grounding_specificity_rationale": "The review point explicitly refers to 'LLMs' and 'finegrained hard constraints.' This clearly identifies the specific part of the paper being addressed. The reviewer uses specific terminology, indicating a strong grounding. The point doesn't rely on general comments or educated guesses about where the issue might lie.", "verifiability_rationale": "The review point contains a claim: 'There should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems.' However, the point itself doesn't provide any specific evidence, reasoning, or references to support this claim. It's a suggestion for improvement rather than a statement that can be verified. Therefore, it lacks verifiability.", "helpfulness_rationale": "The review point identifies a potential area for improvement in the paper (more discussion on LLM limitations) and suggests a direction for that improvement (exploring reasons and solutions). This is a valuable piece of feedback that directly addresses a potential weakness in the authors' work. It encourages the authors to delve deeper into a specific aspect of their work and explore potential solutions. While it doesn't provide a specific solution, it points in a useful direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states a limitation: 'little insights are given about why do we need to do selfsupervised learning on this kind of data.' While it doesn't provide a specific action, it clearly identifies a missing element, making it partially actionable.", "grounding_specificity_rationale": "The review point mentions 'selfsupervised learning on 360 video data which have spatial audio.' This provides a specific context, indicating that the authors can identify the relevant part of the paper. However, it doesn't specify *what* is wrong with this specific approach or data type, making it not fully specific.", "verifiability_rationale": "The review point contains a claim: 'little insights are given about why do we need to do selfsupervised learning on this kind of data.' However, it doesn't provide any evidence or reasoning to support this claim. It simply states the problem without justifying it or providing references.", "helpfulness_rationale": "The review point identifies a valid gap in the paper's explanation by highlighting the lack of insights *why* selfsupervised learning is needed for this specific data. While it doesn't offer concrete suggestions, it points to a crucial area for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states 'there is no analysis on a seemingly important (see SimCLRv2 and other recent papers that show that) part of that approach, ie the projection head.' This clearly identifies an action the authors should take \u2013 analyze the projection head \u2013 and provides a reason for its importance. The 'ie the projection head' makes the action even more explicit.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the projection head' and provides context by referencing 'SimCLRv2 and other recent papers that show that'. This strong mention of a specific part of the paper indicates full grounding. The reviewer also states the importance of this part, adding clarity on what needs to be addressed.", "verifiability_rationale": "The reviewer makes a claim: 'only the SimCLR case is covered and yet, there is no analysis on a seemingly important (see SimCLRv2 and other recent papers that show that) part of that approach, ie the projection head.' This is a claim that requires justification. The reviewer attempts to justify the importance of the projection head by referencing 'SimCLRv2 and other recent papers that show that'. While the specific papers aren't named, the direction for justification is provided, making it 3.", "helpfulness_rationale": "The reviewer identifies a specific weakness in the analysis of the SimCLR method (lack of projection head analysis) and provides a clear rationale for its importance, based on recent work. This directly points the authors towards a concrete area for improvement and provides a justification for why this is a significant gap. The reviewer's statement is actionable and directly addresses a potential area of weakness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a potential vulnerability related to the approximations but does not explicitly state an action to be taken or a specific part of the paper that needs further analysis. While the suggestion to expand the analysis is implied, it's not directly stated as an action within the review point itself.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'approximations (i iii)' and 'lines 107110', indicating a clear and precise identification of the specific part of the paper being addressed and the issue related to the approximations. This provides strong grounding specificity.", "verifiability_rationale": "The reviewer states a claim: 'The possible vulnerability (e.g., due to the assumption of attacks being in the feasible set only in lines 107110) needs to be expanded to reassure the readers that it is not a real concern.' This claim is supported by the explicit mention of the assumption and the suggestion to expand the analysis, making it 5.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'expanding the analysis' to address the potential vulnerability. This directly empowers the authors to improve their draft, making the review point 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer criticizes the comparison and the added complexity. While they identify a problem, they don't explicitly state what needs to be done. This fits the definition of implicit and vague, making it 2. The reviewer could have suggested a specific alternative experimental design or a way to control for the prior information, but they only point out the issue.", "grounding_specificity_rationale": "The reviewer refers to 'the experimental results' and 'the proposed method' generally. They don't pinpoint a specific part of the paper or methodology being affected by the unfair comparison. They mention the comparison being unfair but don't specify which part of the comparison is the issue (e.g., the use of prior information, the twomodel setup). This indicates a lack of grounding.", "verifiability_rationale": "The reviewer makes a claim about the unfairness of the comparison but provides no evidence, reasoning, or references to support their claim. They don't explain why the comparison is unfair or suggest any alternative approaches. This makes the claim 1.", "helpfulness_rationale": "The reviewer criticizes the comparison and the added complexity and suggests the comparison is unfair. Such comparison is a bit unfair, because in this case the proposed method essentially requires two representation models learned based on each dataset, ie., VAE/GAN + CL. Such extra complexity and cost need to be considered. The reviewer points out a problem but doesn't offer any suggestions for improvement. They don't suggest alternative experimental designs, ways to control for the prior information, or how to justify the added complexity. Therefore, it's not helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the limitation: 'The new proposed model can be used only with a small number of dimensions because of the curse of dimensionality imposed by the core tensor C.' This is an explicit statement of a constraint. Furthermore, the reason for this limitation is clearly stated as 'because of the curse of dimensionality imposed by the core tensor C,' providing a concrete explanation of how to implement this inferred action. The authors know exactly what the limitation is and how to understand its cause.", "grounding_specificity_rationale": "The review point explicitly mentions 'the core tensor C' as the specific part of the model being addressed. This is a literal mention of a unique element of the paper. The comment also specifies what is wrong or missing in this part, stating that the model has a limitation with a small number of dimensions due to the curse of dimensionality. This provides a specific reason for the limitation related to a unique aspect of the model.", "verifiability_rationale": "The review point contains a claim: 'The new proposed model can be used only with a small number of dimensions.' This claim is supported by the reasoning: 'because of the curse of dimensionality imposed by the core tensor C.' The curse of dimensionality is a wellknown concept in machine learning and data analysis, and its application to the core tensor C provides a logical and verifiable explanation for the limitation. The reasoning is clear and references a wellestablished principle.", "helpfulness_rationale": "The review point is 5 as it clearly identifies a significant limitation of the proposed model. By stating that the model is restricted to a small number of dimensions due to the curse of dimensionality related to the core tensor C, the reviewer provides the authors with concrete information that they can use to understand the practical constraints of their approach. This information is directly actionable and helps them make informed decisions about the applicability of the model."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the potential negative impact of homolumo gap pretraining and provides a concrete example (TransformerM, QM9). While the reviewer identifies a potential issue, the suggestion to pretrain on homolumo gap is not a fully explicit action, as it lacks specific implementation details.", "grounding_specificity_rationale": "The reviewer mentions specific models (TransformerM) and datasets (QM9), demonstrating strong grounding. They also specify the tasks where poor performance is observed, adding further specificity.", "verifiability_rationale": "The reviewer presents a claim about potential negative transfer and supports it with the example of TransformerM on QM9. This provides logical reasoning and a specific instance.", "helpfulness_rationale": "The reviewer raises a valid concern about a potential limitation of the 'generalpurpose' model. They provide a specific example and suggest a potential issue with pretraining. While they don't offer a definitive solution, the point is relevant and constructive for the authors."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "3 (3)", "verifiability_label": "3 (3)", "helpfulness_label": "1 (Not Helpful)", "actionability_rationale": "The review point criticizes the theoretical contribution but does not offer specific, actionable steps or guidance on how to improve it.", "grounding_specificity_rationale": "The reviewer identifies the theoretical contribution as a weakness but does not specify which part of that contribution is problematic.", "verifiability_rationale": "The review point contains a claim about the weakness of the theoretical contribution and provides reasons (ferences to other results) that could support this claim.", "helpfulness_rationale": "The review point criticizes the theoretical contribution but does not offer specific, actionable advice to the authors on how to improve it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer's point is somewhat explicit in identifying the locations (L240 and L428) where the word 'sufficient' might be missing or needs clarification. However, the underlying intent or 'what' is implicit, making it not fully actionable without further clarification from the author.", "grounding_specificity_rationale": "The reviewer explicitly mentions the line numbers L240 and L428, providing strong grounding. They also suggest a specific meaning for 'sufficient' in the context of sums of rewards, making the specificity very clear.", "verifiability_rationale": "The reviewer states a claim about the potential ambiguity of 'sufficient' but does not provide any evidence or logical reasoning to support this claim. There are no external references mentioned, and the reasoning is not clearly presented.", "helpfulness_rationale": "The reviewer points out a potential area for improvement by suggesting a specific meaning for 'sufficient'. While this could be helpful for the author, the reviewer does not explicitly explain why the current phrasing is problematic or how the suggested change will resolve it. The helpfulness is indirect."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a limitation of the proposed method (ACI) by highlighting the information loss compared to a method with a richer search space (likely DAGs). While the reviewer identifies a problem, the suggestion to 'understand the tradeoff' is not an explicit action or instruction on how to improve the draft. The reviewer identifies a potential area for improvement but doesn't directly suggest a concrete action to address it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the output of ACI' and 'ancestral graphs' and contrasts it with 'DAGs'. This demonstrates a clear understanding of the specific parts of the paper and the concepts being discussed, indicating strong grounding specificity.", "verifiability_rationale": "The reviewer poses a question about the information content of a method's output without providing any claims, opinions, or suggestions that require verification. Therefore, it does not fall under the verifiability aspect.", "helpfulness_rationale": "The reviewer's comment raises a valid point about the information tradeoff. While the reviewer identifies a limitation of the proposed method, they don't provide concrete suggestions or actions for the author to take based on this insight. The comment is more of a question and observation rather than a direct suggestion for improvement, making it 3 in identifying a potential area for clarification but not a direct action to take."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "Highly Verifiable", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the action the paper is taking: 'simply discards any TF bins that have a magnitude of less than epsilon.' They further explain the implications of this action, highlighting that it's not a proper Voice Activity Detection (VAD) and could lead to division by zero. The reviewer provides a clear and concrete explanation of the issue.", "grounding_specificity_rationale": "The reviewer's criticism is general and does not specify which part of the paper they are referring to. They simply state, 'Your VAD description is puzzling. What is stated in the paper...'. There is no mention of a specific section, table, figure, or unique element of the paper being addressed.", "verifiability_rationale": "The reviewer provides a clear and logical explanation of their understanding of Voice Activity Detection (VAD) and why the paper's method of discarding lowmagnitude TF bins is problematic. They mention that VAD is usually defined over time and is more likely to look for the presence of speech, not just energy. The reviewer's explanation is supported by common knowledge about VAD techniques.", "helpfulness_rationale": "The reviewer's comment is highly relevant and actionable for the authors. They point out a specific methodological issue (the paper's VAD implementation) and suggest an alternative approach (featurebased VAD). This criticism is not only informative but also provides a clear direction for potential improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests that simultaneous training may improve the teacher network's performance and requests KID/FID metrics. This is an explicit action with a concrete goal. The reviewer directly states the potential benefit and asks for specific data to support it. The request for KID/FID is a clear and actionable step for the authors to provide evidence.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'simultaneous training' and 'teacher network' in the context of the proposed improvement. This demonstrates strong grounding as the specific part of the paper being addressed is clearly identified. The request for 'KID/FID metrics' further reinforces this specificity by naming the type of evaluation being suggested.", "verifiability_rationale": "The reviewer states that 'simultaneous training may improve the performance of the teacher network.' This is a claim that requires verification. However, the reviewer does not provide any logical reasoning, examples, or references to support this claim within the review point itself. The request for KID/FID metrics is presented as a request for information rather than a statement of verified fact. Therefore, the claim is underspecified and lacks sufficient justification.", "helpfulness_rationale": "The reviewer raises a relevant point about the fairness of a comparison and provides a concrete suggestion (requesting KID/FID metrics). This directly addresses a potential issue in the authors' methodology and encourages them to provide more information. The request for specific metrics is a clear and actionable step that, if followed, would significantly improve the clarity and verifiability of the feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer suggests investigating differences in false positive rates (FPR) between specific models (e.g., GPT4o vs. InternVL2) when ReGuide is applied. While this is a concrete suggestion about *what* to look at, the reviewer does not explicitly state the *action* to be taken with this information. They don't say 'Analyze the FPR differences and compare them to the overall trends' or anything similar. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'specific models (e.g., GPT4o vs. InternVL2)' and 'false positive rates (FPR)'. This clearly grounds the comment in specific parts of the paper and identifies a specific issue (differences in FPR). The reviewer is not just saying 'look at the data' \u2013 they are pointing to specific elements of the results.", "verifiability_rationale": "The reviewer suggests 'comparing false positive rates (FPR) between models with and without ReGuide'. This is a logical suggestion that could be supported by external references or common knowledge in the field. The reviewer provides a clear reasoning for why this comparison would be useful (for better comparison). While they don't provide the actual FPR values, the *method* for verification is clear.", "helpfulness_rationale": "The reviewer's point about investigating specific models and FPR differences is relevant and could be valuable for the authors. It highlights a potential area for deeper analysis and encourages exploring modelspecific behaviors. However, the review stops short of providing a concrete conclusion or actionable step. The reviewer *suggests* an investigation but doesn't * tell the authors what to do with the results. The value is in pointing towards a useful direction, but it lacks the final push to resolve an identified issue."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states their suggestion to consider explicitness (E) and size (S) as extra evaluations. This is a clear indication of an intended action. The reviewer also provides specific examples of factors entangling DCI and ES (probing capacity, latent size) and proposes specific metrics (explicitness, size) as extra evaluations, making the action quite concrete.", "grounding_specificity_rationale": "The reviewer's criticism is general, affecting the framework as a whole. They do not explicitly identify which part of the DCI framework they are addressing. While they mention specific factors (probing capacity, latent size) that might be entangled, they do not pinpoint a specific section or unique element of the framework. Therefore, the grounding is weak. The reviewer proposes explicitness and size as extra evaluations, which are general concepts and not tied to a specific part of the paper or framework.", "verifiability_rationale": "The reviewer makes a claim that DCI and ES are entangled and that explicitness and size should be considered as extra evaluations. This is a clear statement that requires justification. While the concept of explicitness in evaluation is generally accepted, the specific proposal of using 'size' as an extra evaluation lacks a direct external reference within the provided text. The reviewer's suggestion is based on a general understanding of evaluation factors rather than a specific citation.", "helpfulness_rationale": "The reviewer's suggestion to consider explicitness and size as extra evaluations is directly related to improving the clarity and rigor of the evaluation process. It provides a concrete potential solution to the perceived entanglement of DCI and ES. While the suggestion itself doesn't have external references, it offers a specific direction for improvement within the context of the review."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states 'practical' and 'safe,' indicating it's not an 1 statement. However, it lacks concrete details on how the interventions are practical or safe. The reviewer identifies a potential issue without providing specific steps or evidence, making it 3 but lacking detail.", "grounding_specificity_rationale": "The comment refers to 'types of interventions' generally, without specifying which interventions are being discussed. It doesn't identify a specific section, table, figure, or unique aspect of the paper. While it implies a concern, it doesn't ground the discussion in a specific part of the paper, making it 1 and underspecific.", "verifiability_rationale": "The review point itself does not contain a claim that requires verification. It's a statement about the potential practicality and safety of interventions, not a critique of a specific aspect of the paper. Therefore, it doesn't fit the criteria for verifiability, which requires a claim to be supported. The review point is a metacomment about the work, not a direct claim about the paper's content.", "helpfulness_rationale": "The review point raises a valid concern about the realworld applicability of the interventions, which is a relevant and constructive point. However, it doesn't provide specific, actionable feedback on how to make the interventions practical or safe. It's a general suggestion rather than a detailed critique or improvement plan, making it 3 but lacking specific guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer implicitly suggests that the manual disentanglement is a limitation and proposes learning everything as an alternative. While the reviewer doesn't explicitly state what action to take, the 'why not something else' question implies a desire for a different approach. However, the reviewer doesn't provide concrete details on how to implement this change or what specific aspects should be learned. The action is implied but not explicitly stated, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the disentangling is done manually' and 'the semantic segmentation network is the first module'. This directly points to a specific part of the paper and a specific aspect within it. Therefore, the grounding is strong. However, the reviewer doesn't specify *why* manual disentanglement is a problem or *why* placing the semantic segmentation network first is an issue. The specificity of the problem is lacking.", "verifiability_rationale": "The reviewer presents a suggestion for an alternative approach ('Why not something else?') but doesn't provide any evidence or justification for why the current manual disentanglement and module placement are problematic. The statement is framed as a question rather than a claim requiring verification. Therefore, it lacks a claim and doesn't fit into the verifiability categories.", "helpfulness_rationale": "The reviewer offers a concrete alternative ('something else') and asks a direct question about the current approach ('Why not something else?'). This suggests a desire to improve the paper by exploring a different method. While the specific 'something else' is vague, the reviewer is clearly pointing out a potential area for improvement. Therefore, it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the lack of a strong connection between the theoretical analysis and the proposed method. They also explicitly mention the similarity of the proposed method to selfattention mechanisms. However, the reviewer does not provide concrete steps on how to improve the connection or how the method enhances generalization for distant nodes. The criticism is clear but lacks specific, actionable guidance.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific part of the paper where the connection between theory and method is unclear. While they imply a disconnect, they don't name a specific section, table, figure, or unique aspect of the paper that needs improvement. Therefore, the grounding is weak.", "verifiability_rationale": "The reviewer's criticism about the lack of clarity in the connection between theory and method is verifiable. They point out that the paper doesn't clearly explain *how* the theoretical insights inform the design of the selfattention mechanism. There are no external references provided to support this claim. The criticism is based on the absence of a clear explanation rather than a lack of information.", "helpfulness_rationale": "The reviewer provides a clear criticism regarding the lack of connection between the theoretical analysis and the proposed method. They suggest that the method, which resembles selfattention, might not effectively enhance generalization for distant nodes. While the criticism is not entirely unhelpful, it lacks the concrete suggestions needed to fully address the identified gap. The feedback is present but could be more actionable."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion about the contribution and novelty of the work, stating 'Technically speaking, the contribution of this work is incremental.' and 'The proposed pipeline is not that impressive or novel; rather, it seems to be a pack of tricks to improve defense evaluation.' This is a statement of opinion, not a direct instruction on what needs to be improved or how to do it. While the reviewer implies the work isn't novel, this is an opinion, not an explicit action the author can take.", "grounding_specificity_rationale": "The review point discusses the 'contribution of this work' and the 'proposed pipeline' in general terms. It does not specify which part of the paper or methodology is being criticized. The reviewer is making a broad statement about the overall work rather than focusing on a specific aspect.", "verifiability_rationale": "The review point makes claims such as 'Technically speaking, the contribution of this work is incremental' and 'The proposed pipeline is not that impressive or novel; rather, it seems to be a pack of tricks to improve defense evaluation.' These are statements of opinion. While the reviewer provides a reason for this opinion ('it seems to be a pack of tricks'), this reason is not supported by any evidence or references within the review point itself. The claims are presented without sufficient justification or backing.", "helpfulness_rationale": "The review point is critical in nature, stating that the contribution is 'incremental' and the pipeline is 'not that impressive or novel.' While this feedback is valid, it does not provide specific, actionable steps for the author to improve their work. The reviewer does not suggest concrete changes or provide guidance on how the author can make their contribution more significant or their pipeline more novel. The feedback is about the overall impact and novelty rather than specific technical issues or areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue: 'It is not clear why eta_ri term is noncentral chisquared distribution.' This directly points to a lack of explanation or justification for a specific aspect of the methodology. While the reviewer doesn't identify a specific action to take, they clearly identify a missing piece of information. Therefore, it can be considered 3 as the reviewer identifies a specific area needing clarification.", "grounding_specificity_rationale": "The reviewer refers to 'eta_ri term' which is a specific element of the paper. This indicates that the reviewer can identify the specific part of the paper being addressed. However, the reviewer does not specify *why* this term is a noncentral chisquared distribution. They are asking for an explanation of the *reason* rather than a description of the term itself. This makes the grounding somewhat specific but the reason behind it is missing, making it not fully specific.", "verifiability_rationale": "The reviewer is making a statement about the distribution of the eta_ri term, which can be considered a claim or at least a question prompting for justification. However, the reviewer does not provide any external references or logical reasoning *within the review point itself* to support why eta_ri is a noncentral chisquared distribution. The reviewer is asking for this information, implying a perceived lack of it. Therefore, it can be considered 1 as no supporting evidence is provided within the review point.", "helpfulness_rationale": "The reviewer is asking for an explanation of a statistical detail. While this is valuable for the reader to understand the methodology, it doesn't directly improve the methodology or results of the paper itself. It's a request for clarification, not a critique of a flaw or an actionable suggestion. Therefore, it is not 5 in improving the draft in terms of methodology or results. It is more about understanding a specific aspect."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "Both parts of the review point directly point to areas for improvement. The suggestions are explicit and actionable. The first part suggests focusing on specific RNN architectures and datasets (SNLI), and the second part suggests focusing on generalization and providing examples. These are concrete actions the authors can take to improve their work.", "grounding_specificity_rationale": "The first part of the review point is highly grounded as it explicitly mentions 'vague' and provides a specific example ('see for instance the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/'). The second part is slightly less grounded as it criticizes the 'reinforcement learning / agent analogy' and suggests focusing on 'generalization capabilities' without immediately providing specific examples. However, the general concept of generalization is implied by the suggestion to provide 'examples later in the paper'.", "verifiability_rationale": "The first part of the review point makes a claim ('the paper is too vague') and provides a specific example (SNLI) and a general suggestion (focusing on RNNs for NLP), making it verifiable. The second part criticizes the 'reinforcement learning / agent analogy' and suggests focusing on 'generalization capabilities' and providing 'examples later in the paper'. While the general concept of generalization is implied, the specific suggestions are not immediately verifiable without reading further into the paper. However, the reviewer's point about the analogy being outofplace is a valid critique that can be supported by arguments about its relevance to the paper's core contributions.", "helpfulness_rationale": "The review point provides specific suggestions for improvement. The first part suggests focusing on 'specific RNNs and datasets (SNLI)', which is a concrete and actionable suggestion. The second part suggests focusing on 'generalization capabilities and providing examples later in the paper', which is also a helpful suggestion. These suggestions are directly related to improving the paper's clarity and impact."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer identifies a lack of positioning in the literature, suggesting a thorough literature review. However, the action is not very specific or actionable. The reviewer doesn't specify which aspects of the method need to be better positioned or what specific literature should be cited. The action is implied rather than explicitly stated with concrete steps.", "grounding_specificity_rationale": "The reviewer does not explicitly refer to a specific part of the paper or method being addressed. The focus is on the general property of the marginal score. Therefore, the grounding is 1 at all.", "verifiability_rationale": "The reviewer makes a claim about the known property of the marginal score and suggests a literature review as an action. However, the claim itself is not wellverified. The reviewer doesn't provide specific examples, references, or logical reasoning to support the claim that this property is widely used in the literature. The verifiability relies on the reviewer's assertion rather than a detailed explanation or evidence within the review point itself.", "helpfulness_rationale": "The reviewer points out a valid concern regarding the literature positioning of the proposed method and suggests a standard and helpful action (a thorough literature review). However, the advice is somewhat generic and lacks specific guidance on how to conduct the literature review or what specific papers to focus on. The helpfulness is limited as it doesn't offer concrete alternatives or a detailed roadmap for addressing the identified issue."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly suggests an experiment ('If you have the resources...') and implies a comparison ('how the \u201csmall learning rate for attention parameters\u201d benchmark... would compare with the proposed approach'). However, the action of suggesting a comparison is vague, as the authors are not explicitly told what to do next with this comparison. The suggestion itself is concrete, but the implied action lacks detail.", "grounding_specificity_rationale": "The comment refers to a specific technical detail ('small learning rate for attention parameters') and implicitly mentions the 'proposed approach'. While the specific learning rate is mentioned, the exact nature of the 'proposed approach' is not explicitly named, making the grounding somewhat specific but not fully grounded.", "verifiability_rationale": "The comment contains a suggestion ('I would be very interested to see how...') which can be interpreted as a claim. The action of running the experiment ('If you have the resources...') is a logical and verifiable step. However, the comment does not provide any justification or evidence for why this experiment would be relevant or how the comparison would be conducted.", "helpfulness_rationale": "The comment offers a very specific and actionable suggestion ('I would be very interested to see how...') by proposing a concrete experiment ('small learning rate for attention parameters') and a direct comparison. This is a valuable and focused suggestion that directly addresses the need to validate the proposed approach. While the comparison itself is vague, the suggestion of the experiment is highly concrete and actionable."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the paper 'carelessly resolves a debate' (L29) and suggests conducting experiments to disentangle distribution shifts from the removal of information. This provides a clear and actionable suggestion for the authors to consider. The reviewer identifies a potential flaw in the paper's methodology and proposes a concrete solution, making this a 5 comment.", "grounding_specificity_rationale": "The reviewer refers to 'a previously careful to leave open (L29)'  implying they are pointing out a specific location in the paper where the debate was previously handled. While the paper *should* contain this information, the reviewer does not explicitly state the section or table number where this discussion occurs. Therefore, the grounding is somewhat implicit. However, the reviewer *does* specify the *issue* they are addressing (the potential for distribution shifts and the lack of disentanglement experiments), making the specificity quite high.", "verifiability_rationale": "The reviewer makes the claim that the paper 'carelessly resolves a debate' and provides a suggestion to conduct experiments. This claim requires justification. The reviewer's suggestion to conduct experiments provides external references (the suggested experiments) to support their claim. The reasoning is logical, and the references, if performed, would be verifiable. Therefore, the verifiability is mostly supported by logical reasoning and potential external references.", "helpfulness_rationale": "The reviewer's comment is 5 because they identify a potential flaw in the paper's methodology (the careless resolution of a debate) and propose a concrete and actionable solution (conducing experiments to disentangle distribution shifts). This directly addresses a potential area for improvement and provides a clear direction for the authors to take. The comment is not just a critique but also a suggestion for improvement, making it highly constructive."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The suggestion to explore the combination of SOTA and an adaptive metric is an explicit action, as it directly points to a potential improvement. However, it lacks specific details on how this combination should be implemented, making it less actionable than it could be.", "grounding_specificity_rationale": "The suggestion mentions 'SOTA method' and 'adaptive metric,' which grounds the comment to specific parts of the paper. However, it does not specify which SOTA method or how the adaptive metric is being used, making it weakly grounded but not specific.", "verifiability_rationale": "The suggestion to explore the combination of SOTA and an adaptive metric is a claim that requires justification. However, the review point itself does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion is presented as a request for insight without any backing.", "helpfulness_rationale": "The review point, while relevant to research, lacks specific details and actionable suggestions. It suggests exploring a combination of methods but doesn't provide concrete guidance on how to do this or what to expect. This makes it 3 but not very actionable."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states multiple issues with the plots: they are 'terrible,' 'too small,' have 'hard to distinguish' colors (specifically mentioning pink vs red), have 'poorly labeled' axes (asking 'what error?'), and have 'visually too similar' labels (specifically mentioning sdropout(tr) vs edropout(tr)). These issues are all clearly defined and actionable. The reviewer provides specific examples of problems and even gives examples of the labels, making it easy for the authors to understand what needs to be improved.", "grounding_specificity_rationale": "The reviewer states that the issues with the plots are the 'main presentation of the experimental results' and that this is why they rated the clarity as 'substandard'. While the reviewer identifies specific issues with the plots, they do not explicitly identify *which* plot or section of the paper is being referred to. The reference is general ('the plots'). However, the reviewer *does* specify *what* is wrong with the plots (size, color, labels).", "verifiability_rationale": "The review point contains claims about the plots being 'terrible,' 'too small,' having 'hard to distinguish' colors, having 'poorly labeled' axes, and having 'visually too similar' labels. These are claims that could potentially be supported by evidence or reasoning. However, the review point itself does *not* provide any supporting evidence or references to back up these claims. The claims are presented as statements of opinion without justification.", "helpfulness_rationale": "The review point criticizes the plots, stating they are 'terrible,' 'too small,' have 'hard to distinguish' colors, have 'poorly labeled' axes, and have 'visually too similar' labels. While these criticisms are valid and could be helpful for improving clarity, the review point itself does not offer any concrete suggestions or solutions for the authors to improve the plots. It simply criticizes them without proposing any specific changes. Therefore, while the criticism is relevant to a 'substandard' clarity rating, the review point itself is not constructive and does not provide actionable feedback for improvement."}
{"actionability_label": "High", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states the performance gains are 'not very high' and quantifies the difference as 'less than 1%'. This directly identifies an actionable finding regarding the impact of the proposed changes.", "grounding_specificity_rationale": "The comment does not specify which part of the paper or experiment the performance gains are referring to. It's a general statement about the overall performance, making it 1 in specific details.", "verifiability_rationale": "The comment contains a claim about the performance gains and provides a specific metric ('less than 1%') to support this claim, making it verifiable.", "helpfulness_rationale": "The comment is a critique of the magnitude of the performance gains, suggesting that the improvements are not substantial. While it provides information for the authors to consider, it doesn't directly suggest specific improvements or actions to take to achieve better results. Therefore, it's helpful in informing the authors of the limited impact but not fully helpful in guiding them to improve further."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer's question about the 'better Unary baseline' is a direct, actionable suggestion for the authors to investigate further. They are asking for clarification on a specific aspect of their experimental setup and results, which is a clear indication of a potential area for improvement. The reviewer is not just pointing out a problem but also suggesting a concrete step to take. This makes the comment actionable and directly relevant to improving the draft.", "grounding_specificity_rationale": "The reviewer's comment is about the interpretation of the results and the comparison of different model types (LinearTop, NLTop, Unary). While they are referencing these model types, they are not explicitly pointing to a specific section, table, or figure in the paper. The grounding is implied rather than directly stated. Therefore, while the reviewer is referring to specific elements of the paper, they are not doing so with the level of precision required for full grounding specificity.", "verifiability_rationale": "The reviewer makes a claim about the performance of different models based on their perceived number of parameters. The verifiability of this claim depends on whether the paper explicitly states the number of parameters for each model type and whether this information is sufficient to verify the reviewer's interpretation. Without access to the paper's details, it's difficult to definitively assess verifiability. However, the reviewer's point about the potential for misinterpretation of 'additional parameters' suggests a lack of clarity in the presentation, which could hinder verification. Therefore, the verifiability is somewhat dependent on the clarity of the paper's reporting.", "helpfulness_rationale": "The reviewer's comment provides a concrete question about the 'better Unary baseline.' This question directly addresses a potential area for improvement in the experimental setup or analysis. It is a valuable piece of feedback that the authors can use to refine their work. The reviewer is not just pointing out a problem but also suggesting a specific direction for investigation. This makes the comment 5."}
{"actionability_label": "High", "grounding_specificity_label": "High", "verifiability_label": "Low", "helpfulness_label": "Medium", "actionability_rationale": "The comment explicitly states the desire to improve the related work section and provides a clear action: 'not only describing the related works, but also discussing the differences to the presented work'. This is a concrete action with a clear implementation strategy.", "grounding_specificity_rationale": "The comment explicitly refers to the 'related work section' of the paper, making it fully grounded. It also specifies the desired improvement as 'more detailed discussion' and 'differences to the presented work', making it specific about the content and focus.", "verifiability_rationale": "The comment contains a claim ('the paper would benefit from a more detailed discussion...') and suggests a method for achieving this ('by not only describing the related works, but also discussing the differences to the presented work'). However, it does not provide any logical reasoning, common knowledge, or external references to support this claim. The suggestion is presented as a desire rather than a verifiable proposition.", "helpfulness_rationale": "The comment identifies a potential weakness in the related work section (lack of detail and discussion of differences) and suggests a direction for improvement (more detailed discussion). While it doesn't provide specific suggestions for what those improvements should be, it clearly points to an area for enhancement and a type of enhancement. Therefore, it is 3 in guiding the authors towards a specific area and a potential improvement strategy."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly suggests exploring 'other architecture' and 'classification tasks', indicating an intention to improve the draft by broadening the experimental scope. However, it lacks specific details on which architectures or tasks are relevant, making the action somewhat vague.", "grounding_specificity_rationale": "The comment mentions 'other architecture' and 'classification tasks' but does not identify a specific section, table, figure, or unique element of the paper where these changes should be applied. The grounding is weak because the authors cannot confidently determine the referenced part. The specificity is also low as the comment does not detail what needs to be addressed in these parts.", "verifiability_rationale": "The comment does not contain a claim that requires verification. It is a suggestion for future work rather than a critique of existing methodology or results. Therefore, it does not fall under the 'X' category as defined in the provided guidelines.", "helpfulness_rationale": "The comment suggests exploring the performance of attacks on different architectures and tasks, which is a valuable direction for research and could potentially improve the draft. However, it lacks specific details on how to implement this suggestion or what specific architectures and tasks are most relevant. Without these specifics, the suggestion is somewhat vague and lacks immediate actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly states an action: 'clarify the algorithm'. However, it does not provide specific details on how the order of data processing might affect the output. The action is stated, but the implementation is left vague.", "grounding_specificity_rationale": "The review point refers to 'the algorithm' in general, without specifying a particular part, section, table, figure, or unique element of the paper. The reviewer is making a general observation about the algorithm's behavior based on the order of data. Therefore, the grounding is weak as the specific part of the paper being addressed is not clearly identified.", "verifiability_rationale": "The review point contains a claim: 'the output from the algorithm depends on the order in which the data are processed.' However, it does not provide any evidence, reasoning, or references to support this claim. The statement is presented as an observation without justification or explanation.", "helpfulness_rationale": "The review point identifies a potential issue ('the output from the algorithm depends on the order in which the data are processed') but does not provide any specific information or guidance on how to address this issue. It lacks concrete details on what the dependency is or how the data order affects the algorithm. Therefore, it is not helpful for the author to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the importance of the sampling method for convergence and provides a concrete example by mentioning a comparison to uniform sampling. This clearly indicates an action the authors should take: understand the impact of different sampling methods on convergence and compare their current method to uniform sampling.", "grounding_specificity_rationale": "The review point mentions the importance of 'sampling' for 'convergence'. While it doesn't explicitly name a specific section or table, the context implies it refers to the sampling method used in the optimization process. It also specifies the comparison to 'uniform distribution', adding a level of specificity to the grounding.", "verifiability_rationale": "The review point makes a claim about the importance of the sampling method and suggests further investigation. It also points to a comparison in the supplementary material, which can be seen as a form of implicit verification. However, the main paper lacks a deep dive into why the current sampling is insufficient or a detailed justification for the supplementary material's findings.", "helpfulness_rationale": "The review point is 5 as it directly addresses a potential issue (sampling affecting convergence) and provides a concrete next step (comparing to uniform sampling). It guides the authors to take action and provides a specific area for investigation."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer raises several questions about the rationale behind the comparisons with 9 and 16. While the questions themselves are explicit actions (asking 'why'), the paper doesn't provide clear answers or justifications for these choices. The lack of explicit reasoning makes the action implicit. The reviewer also questions the focus on computational cost, again without clear justification for why this specific aspect is prioritized over others. The actions are present, but the lack of explanation makes them less actionable.", "grounding_specificity_rationale": "The reviewer's questions about the rationale and computational cost are not explicitly linked to specific sections, tables, or figures in the paper. The questions are general and lack context, making the grounding weak. While the questions are specific about the *comparison* and *computational cost*, the paper doesn't clearly identify *where* these comparisons and discussions occur within the paper. The grounding is present in terms of the questions themselves, but the lack of specific references makes it weakly grounded. The specificity of the questions about the rationale and computational cost is also debatable, as they are more about the *purpose* of the comparison rather than specific details within a section.", "verifiability_rationale": "The reviewer's concerns about the rationale and computational cost are presented as claims (questions) without clear supporting evidence or justification within the paper. The paper doesn't explicitly explain the logic behind the comparisons with 9 and 16, nor does it provide sufficient reasons for focusing on computational cost with 9 and excluding 16. The lack of explicit reasoning and supporting evidence makes the claims 1. The reviewer's statement that the justification is 'weird' and lacks discussion further emphasizes the lack of verifiability.", "helpfulness_rationale": "The reviewer's questions and concerns about the rationale and computational cost are actionable and provide specific feedback to the authors. The reviewer clearly identifies areas for improvement and asks direct questions. However, the paper doesn't provide answers to these questions, making the feedback somewhat incomplete. The actions are present, but the lack of resolution makes the feedback somewhat unhelpful."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests an interesting aspect of multimodal data but does not provide explicit or concrete actions or suggestions on how to improve the current draft. It poses a question about the model's capabilities with tabular data, which is a suggestion rather than a directive. Therefore, it is not actionable.", "grounding_specificity_rationale": "The review point discusses the potential of tabular data as multimodal data but does not explicitly identify a specific part of the paper or unique element being addressed. It is a general suggestion rather than a focused critique of a particular section or table. Therefore, it is weakly grounded.", "verifiability_rationale": "The review point is a suggestion about the model's ability to handle tabular data, not a claim that needs verification. There is no assertion of what the model *should* do or how it *should* process tabular data. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point suggests exploring multimodal data, specifically tabular data, as an interesting avenue. While this could be valuable for broadening the reviewer's perspective, it does not directly address a likely weakness or improvement area in the reviewer's specific paper. It is a suggestion rather than a critique or actionable advice. Therefore, it is not 5."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Not Specific", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment identifies a need for more details on 'attention' but lacks specifics on how to achieve this. It suggests adding these details as an appendix, which is a vague action without further instructions.", "grounding_specificity_rationale": "The comment refers to 'attention' generally and suggests adding details as an 'extra appendix' without specifying a particular section, table, figure, or unique element in the paper.", "verifiability_rationale": "The comment is a suggestion for improvement rather than a claim that requires verification. It doesn't state what is wrong or what should be done, making it not a claim that needs supporting evidence.", "helpfulness_rationale": "The comment suggests adding more details about 'attention' as an appendix. While it points to a valid improvement area, it lacks specific details on what needs to be added and how the appendix should be structured, making it less immediately helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly points out the discrepancy between the claim of broad applicability and the limited experimental validation using only Gaussian noise. The reviewer also asks a direct question ('Is there any particular reason for the same?') which implies they are seeking clarification on this action. The action is explicit because the reviewer identifies the specific gap in the paper. The action is also concrete because the reviewer identifies the specific area of the paper (results and discussion) where the lack of diversity in noise types is evident.", "grounding_specificity_rationale": "The reviewer's comment implies a lack of specific information about which part of the paper is being addressed. While the reviewer clearly states the issue is with the experimental validation, they don't explicitly point to a specific section, table, or figure. The grounding is implied through the mention of 'results' and 'discussion', but it's not a literal mention or a unique element of the paper. Therefore, it leans towards 'Full Grounding' in intent, but the actual grounding is 'Weakly Grounded' because the reviewer doesn't explicitly identify the section.", "verifiability_rationale": "The reviewer makes a claim about the discrepancy between the model's claimed versatility and the limited experimental validation. This claim is 3 because the reviewer identifies a logical gap: the lack of diverse noise testing in the experiments, which is a common practice for validating generalizability. However, the reviewer does not provide external references or specific examples to support this claim. The reasoning is present (lack of diverse noise testing), but the evidence is not explicitly provided by the reviewer.", "helpfulness_rationale": "The reviewer's comment is 5. They directly point out a concrete flaw in the experimental design by highlighting the discrepancy between the claimed broad applicability of the model and the limited experimental validation using only Gaussian noise. They also ask a direct question ('Is there any particular reason for the same?') which encourages the authors to provide more details about their experimental setup. This feedback is actionable and constructive for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The suggestion is directly stated, making it explicit. Furthermore, the suggestion is very concrete, clearly stating that the empirical version of the objective (3) should be moved to the supplementary materials. This provides the authors with a clear action to take.", "grounding_specificity_rationale": "The comment does not specify *which* empirical result is affected by moving it to the supplementary materials. It refers to 'the empirical version of the objective (3)' in a general sense. Therefore, the grounding is weak as the authors cannot precisely identify the referenced part. While the suggestion is clear about *what* to do (move to supplementary materials), it doesn't specify *where* within the supplementary materials this should go or if there are any specific sections to consider. The comment implies the relevant parts without explicitly naming them.", "verifiability_rationale": "The review point does not contain a claim. It is a suggestion for a change in presentation rather than a critique or assertion about the paper's content. Therefore, the concept of verifiability does not apply as there is no statement that needs justification or support.", "helpfulness_rationale": "The suggestion, while not identifying a specific weakness, is still helpful in guiding the authors' attention and potentially improving their writing style. It provides a constructive comment that encourages the authors to consider the presentation of their results. While it doesn't pinpoint an error, it offers a valuable piece of feedback that can contribute to the overall quality of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3: 5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point directly addresses a specific claim in the paper (Corollary 10) and asks a question about the implications of a certain property. It encourages the authors to clarify the relationship between minimizing the expected 01 loss and the expected convex surrogate. This provides a clear action for the authors to take, making it actionable.", "grounding_specificity_rationale": "The review point explicitly refers to 'Corollary 10' and discusses the concepts of 'expected 01 loss' and 'expected convex surrogate'. This provides a clear and specific reference point within the paper, making it fully grounded. It also clearly identifies the issue being raised, making it specific to the technical details.", "verifiability_rationale": "The review point makes a claim about the interpretation of Corollary 10. It argues that the corollary, which shows uncertainty sampling moves in descent directions of the expected 01 loss, does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This claim is verifiable by examining the definitions and properties of these concepts. The reviewer is making a logical argument based on established concepts in optimization theory.", "helpfulness_rationale": "The review point is highly relevant to readers trying to understand the implications of Corollary 10. By highlighting the distinction between minimizing the expected 01 loss and the expected convex surrogate, the reviewer provides valuable insight that could help the authors clarify their work and improve the understanding of readers. This is a very relevant and helpful feedback point."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the missing details: 'There are missing details about division to train and test sets, numbers as well as how the division was made (simply random? Any other considerations?)'. This directly points to what needs to be added. The reviewer also states that the authors should 'Add the following details: 1. The number of samples in the training and testing sets. 2. How the division was made (e.g., random, stratified, based on time).', which is a direct instruction on what to add. The reviewer's statement is clear and points to specific missing information.", "grounding_specificity_rationale": "The reviewer does not explicitly point to a specific section or table in the paper where the division to train and test sets should be mentioned. The reviewer's statement is general: 'There are missing details about division to train and test sets...'. While the reviewer implies it's important information, they don't specify *which* part of the paper is being referred to. The reviewer also doesn't specify *which* details are missing (e.g., are they asking for the train/test sizes, the splitting method, or both?).", "verifiability_rationale": "The reviewer makes a claim that 'There are missing details about division to train and test sets...'. However, the reviewer does not provide any justification or reasoning for why these details are important or missing. The reviewer simply states the absence of information without explaining its significance or providing references.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion: 'Add the following details: 1. The number of samples in the training and testing sets. 2. How the division was made (e.g., random, stratified, based on time).'. This is a direct and constructive feedback for the authors, guiding them on what information is needed. The reviewer's suggestion is specific and addresses the identified weakness."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question about the scope of the evaluation and does not propose a specific action or suggestion for improvement. Therefore, it is not actionable.", "grounding_specificity_rationale": "The review point is a general question about the *bAbI* task and does not explicitly identify a specific part of the paper or methodology being addressed. Therefore, it is not fully grounded.", "verifiability_rationale": "The review point is a question, not a claim that needs verification. Therefore, it does not address verifiability.", "helpfulness_rationale": "The review point raises a valid concern about the limited scope of the evaluation on the *bAbI* task. This could be helpful information for the authors to consider the generalizability of the findings. While it doesn't directly suggest an improvement, it provides context and highlights a potential limitation, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Specific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer explicitly states 'the dataset used in the experiments are all very small' and suggests 'medium or even large dataset such as ImageNet'. While the reviewer identifies a limitation, the action is not fully concrete as it doesn't specify *which* datasets are small or how to improve the current ones. The vagueness makes it less actionable than a comment that directly suggests a change to a specific part of the paper.", "grounding_specificity_rationale": "The reviewer mentions 'the dataset used in the experiments are all very small' but does not explicitly identify a specific part of the paper (e.g., a section, table, figure) as being problematic. The comment is about a general characteristic of the datasets, making the grounding implicit.", "verifiability_rationale": "The reviewer states a fact ('the dataset used in the experiments are all very small') but does not provide any evidence or justification for this claim within the review point itself. They also do not suggest any external references or logical reasoning to support their assertion. The claim is presented without sufficient backing.", "helpfulness_rationale": "The reviewer points out a potential issue with the experimental setup (small datasets) but immediately qualifies it as a 'minor issue'. This downplays the significance of the point and reduces its helpfulness for the authors who are likely focused on the current submission."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly suggests 'adding empirical justification' as a way to improve the paper. This is a direct and concrete action that authors can take to address the identified weakness. The suggestion is not just a statement of opinion but a clear direction for improvement.", "grounding_specificity_rationale": "The reviewer specifically refers to the 'first claimed contribution' of the paper and suggests adding empirical justification 'to that specific contribution'. This demonstrates strong grounding as the comment directly identifies the relevant part of the paper and the specific issue within that part. The reviewer is not just saying 'the paper needs more experiments' but 'the paper needs more experiments related to this specific claim'.", "verifiability_rationale": "The reviewer suggests 'adding empirical justification' to the claimed contribution. While the suggestion itself isn't a claim that *something is missing*, it implies that the paper lacks this justification and suggests a concrete way to address it. The reviewer is pointing out a potential weakness (lack of empirical justification) and providing a constructive suggestion. Therefore, it is 3 as it points to a missing element that can be addressed through a specific action.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion. They identify a specific area for improvement (lack of empirical justification for a claimed contribution) and offers a concrete way to address it (adding empirical justification). This is a constructive and helpful comment for the authors as it directly targets a potential weakness and provides a clear path forward."}
{"actionability_label": "2", "grounding_specificity_label": "Somewhat Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a similarity between the proposed S1DBED algorithm and RMED, suggesting a lack of sufficient discussion on this comparison. While the reviewer identifies a potential issue, the exact nature of the similarity and the specific areas needing discussion are not explicitly stated. The reviewer's suggestion is a general call for more comparison, rather than a direct instruction on how to improve the algorithm itself. Therefore, while the reviewer's point is relevant, it lacks the specificity needed for full actionability.", "grounding_specificity_rationale": "The reviewer refers to the 'S1DBED algorithm' and 'RMED (Komiyama et al. 2015)' by name, indicating some level of grounding in the specific algorithms. However, the reviewer's concern is about the *novelty* of the process or implementation, not a specific element within the algorithms themselves. The reviewer suggests a *lack of sufficient discussion*, implying a gap in the explanation of the relationship between the two algorithms. While the algorithms are mentioned, the *discussion* around their similarity is not pinpointed to specific parts of the paper, making the grounding somewhat underspecific.", "verifiability_rationale": "The reviewer makes a clear claim: 'The paper needs to give a sufficient discussion on the comparison with RMED.' This claim requires justification. However, the reviewer does not provide specific examples of where the discussion is lacking or what specific aspects of the comparison need improvement. The justification is general and lacks concrete evidence or references. Therefore, while the reviewer identifies a potential issue, the lack of specific supporting evidence makes it only 3.", "helpfulness_rationale": "The reviewer's comment directly addresses a potential weakness in the paper's presentation by highlighting a lack of comparison between the proposed algorithm and RMED. This is a clear and actionable feedback for the authors, pointing out a specific area where the paper could be improved. While the reviewer doesn't provide a solution, they clearly identify a gap in the discussion, which is valuable feedback for the authors. Therefore, the reviewer's point is helpful in identifying an area for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states 'GCG could craft adversarial prompts and transfer them to other LLMs.' This is a clear action that authors can readily apply. The suggestion to include such a comparison is also concrete, indicating a specific experiment to be conducted.", "grounding_specificity_rationale": "The reviewer refers to their own work (GCG) but does not specify which section, table, or unique aspect of their paper the comparison relates to. The suggestion is general, implying a need for transferability experiments but lacking specific details about the paper's content.", "verifiability_rationale": "The reviewer's point is framed as a suggestion ('It would be good if such a comparison could be included') rather than a direct claim requiring verification. While they mention a 'minor point' about the jailbreaking percentage, this is presented as a potential benefit of the comparison rather than a flaw in the paper that needs verification.", "helpfulness_rationale": "The reviewer's suggestion is actionable, as it proposes a specific experiment. However, it lacks concrete details on how this experiment should be conducted or what specific results are expected. While it has the potential to be helpful, the lack of specific guidance makes it less immediately useful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point does not propose any specific actions or modifications to be made to the authors' draft. It is a question about the capabilities of a unified framework, not a direct critique or suggestion for improvement within the authors' work. Therefore, it lacks explicit or implicit actionable information.", "grounding_specificity_rationale": "The review point asks about the limitations of a unified framework in general POMDP formulations. It does not explicitly identify a specific part of the authors' paper (e.g., 'Section 3', 'Figure 2') where this limitation might be relevant. The reference to 'general POMDP formulations' is not tied to a specific element of the authors' work, making the grounding weak.", "verifiability_rationale": "The review point is a question about the limitations of a unified framework. It does not contain a claim that is being asserted as true or false about the authors' work or their specific submission. It is a question about the framework itself, not a critique of the authors' current draft.", "helpfulness_rationale": "The review point is a question about the limitations of a unified framework. It does not provide specific feedback or suggestions on how the authors' current draft could be improved. It is a metacomment about the framework, not a direct critique or suggestion for action on the authors' part."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point does not explicitly state what the authors should do with the information presented. While it suggests using the Kialo dataset as an alternative, it doesn't force the authors to adopt it or provide specific steps on how to implement this suggestion. The authors are presented with an option, but not a mandatory action.", "grounding_specificity_rationale": "The reviewer explicitly states the problem: 'the creation of the dataset is optional.' They then specify the alternative: 'Kialo dataset, wellstudied in the community, provides exactly what the authors need, pairs of short claims and their counters. It is even cleaner than the dataset the authors created since no automatic processes exist to construct it.' This clear identification of the relevant concept and its benefits demonstrates strong grounding specificity.", "verifiability_rationale": "The claim that 'Kialo dataset, wellstudied in the community, provides exactly what the authors need' is somewhat supported. While the phrase 'wellstudied in the community' is subjective and lacks a direct citation, the claim that it 'provides exactly what the authors need' is generally verifiable, even if a specific citation isn't provided. The reviewer is making a claim about the dataset's content and utility, which can be supported by common knowledge in the field.", "helpfulness_rationale": "The review point is 5. It identifies a potential improvement (using the Kialo dataset) and explains why it might be beneficial ('pairs of short claims and their counters', 'cleaner'). It directly addresses the perceived limitation of the current dataset ('optional'). This provides the authors with a concrete alternative and a clear reason to consider it."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states a limitation regarding the number of tasks but does not explicitly suggest how to address this limitation. While the weakness is identified, the action is not clearly defined. The reviewer points out a potential area for improvement but doesn't offer a concrete solution.", "grounding_specificity_rationale": "The reviewer mentions 'the number of tasks' as a limitation, which is a specific aspect of the paper. However, they do not specify which particular tasks are limited or provide details about why the current number is insufficient. The weakness is identified at a general level.", "verifiability_rationale": "The reviewer expresses a preference for sequential results over epochs and questions the current approach. This is an opinion about the presentation of results, not a claim that requires verification. There is no assertion that the current results are incorrect or need justification.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the experimental setup (limited tasks and result presentation). This criticism is directly related to the quality and clarity of the information presented. While it doesn't offer a solution, it points to a potential area for improvement, making it 3 in highlighting an issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states the *why* of limiting analysis to the last layer. The *action* implied is 'analyze only the last layer.' This is a clear, albeit implicit, action.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the last convolutional layer' as the specific part of the paper being addressed. This clearly identifies the section being referred to.", "verifiability_rationale": "The reviewer is *stating* that the motivation is unclear and asks *why*. This is a statement of observation, not a claim requiring verification. There's no assertion that something is correct or incorrect.", "helpfulness_rationale": "The reviewer points out a logical gap in the reasoning. They are suggesting that the paper could be improved by analyzing earlier layers. This provides a suggestion for improvement, even though the *why* is not explicitly stated."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point is a question, not a statement that tells the author what to do. It identifies a problem but lacks a concrete action.", "grounding_specificity_rationale": "The review point refers to 'parameter S' generally, without specifying which part of the paper or context this parameter is in. It lacks specific details.", "verifiability_rationale": "The review point is a question, not a claim that needs verification.", "helpfulness_rationale": "The review point identifies a valid issue but fails to provide any actionable feedback or suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the 'choice' of employing a convex or concave constraint, and an increasing/decreasing constraint as a hyperparameter that needs to be chosen or tuned. While technically true that no *parameter* of a convex function needs tuning, the decision to *use* these types of constraints is a choice that involves tuning a higherlevel decision or hyperparameter. The reviewer does not explicitly state how to implement this 'choice' or what the implications are, making it somewhat vague on how to execute it.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the choice of employing a convex or concave constraint' and 'an increasing/decreasing constraint'. This clearly identifies the specific aspect of the paper being addressed, providing strong grounding. The reviewer pinpoints the specific types of constraints being referred to, making the grounding very precise.", "verifiability_rationale": "The reviewer provides a justification for their point by explaining that while technically true that no *parameter* of a convex function needs tuning, the decision to *use* these types of constraints is a choice that involves tuning a higherlevel decision or hyperparameter. The reviewer provides a logical reasoning to support their claim, explaining the distinction between parameter tuning and architectural choices. This provides sufficient evidence to understand the point.", "helpfulness_rationale": "This review point is 5. It directly addresses a potential point of confusion for the authors by clarifying that the decision to use specific types of constraints is a form of hyperparameter tuning, even if the parameters within those constraints are not tuned. The reviewer provides a clear explanation of why the original statement might be an oversimplification and offers a practical suggestion for exploration. This helps the authors understand a more nuanced aspect of their model design."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies limitations in the scope of bias benchmarks, specifically mentioning the limited assessment of gender, race, and religion. While it implicitly suggests that these are areas needing improvement, it does not explicitly state what actions should be taken to address these limitations. The reviewer could have suggested concrete steps, such as proposing new bias benchmarks that cover a broader range of sensitive attributes or recommending the inclusion of evaluations on stateoftheart generative models like GPT. The lack of explicit and concrete actions makes the point less actionable.", "grounding_specificity_rationale": "The review point explicitly mentions 'bias benchmarks' and specifies the biases it currently assesses: 'gender, race, and religion'. It further elaborates on the limitations by stating 'other important biases and datasets are not measured' and 'missing are assessments on stateoftheart generative models like GPT'. This direct identification of the section and the specific issues within that section demonstrates strong grounding. The reviewer not only identifies the area being discussed but also clearly pinpoints the specific problems.", "verifiability_rationale": "The review point makes a statement about the limitations of current bias benchmarks, specifically stating that they 'only assess gender, race, and religion'. This is a claim that can be verified by examining the current landscape of bias evaluation methods. While the review point does not provide specific examples of how to measure these other biases or evaluate generative models like GPT, it identifies areas where measurement is lacking, making it verifiable in principle. The reviewer points out what is missing, which can be considered a form of verification by highlighting gaps in the current approach.", "helpfulness_rationale": "The review point identifies a clear weakness in the current evaluation of bias, specifically the limited scope of assessed attributes. By highlighting this limitation, the reviewer provides the authors with a specific area to consider when designing their own evaluations or comparing existing ones. While the review point does not propose concrete solutions, it points out a meaningful gap in the current assessment. By identifying what is missing, the reviewer provides a valuable piece of information that can guide the authors' future work and contribute to a more comprehensive understanding of bias evaluation. The reviewer's observation of what is lacking is a helpful insight."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer states 'Figure 3 is challenging to understand' and 'the workflow and captions are unclear'. This indicates a lack of explicit instructions. While the reviewer points to specific elements (workflow and captions) as being unclear, they don't explicitly state what needs to be done to improve the figure. The reviewer also mentions 'communication modes on the left side is confusing' which implies an implicit understanding of what needs to be clarified. Therefore, the comment lacks explicit instructions but points to specific areas needing improvement, making it 3.", "grounding_specificity_rationale": "The reviewer explicitly names 'Figure 3', 'workflow', 'captions', and 'communication modes' as unclear. This demonstrates a strong ability to identify the specific part of the paper being addressed, fulfilling the 'Full Grounding' criteria. However, the reviewer does not explain *why* these specific elements are unclear, which falls short of the 'Specificity' requirement. The comment clearly identifies the issue, but doesn't detail what is wrong or how to fix it.", "verifiability_rationale": "The reviewer states 'Figure 3 is challenging to understand' and 'the workflow and captions are unclear'. There is no explicit claim being made or verified in this statement. The reviewer is describing the state of the figure, not making a claim that requires justification or support. Therefore, this comment does not contain a claim that can be assessed for verifiability.", "helpfulness_rationale": "The reviewer states 'Figure 3 is challenging to understand' and 'the workflow and captions are unclear'. This directly points to a concrete issue that could hinder the authors' ability to understand and potentially reproduce their work. While the comment doesn't explicitly instruct the authors on how to fix the figure, it highlights a significant area for improvement. Therefore, the comment identifies a clear weakness that could impact the authors' work, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'Error analysis plays a crucial role in evaluating model performance and identifying potential issues.' This is an explicit action, and the reviewer further specifies 'We encourage the authors to conduct error analysis in the paper and provide detailed explanations of the model's performance under different scenarios.' This is an explicit action that is concrete, guiding the authors on *what* to do and *how* to do it.", "grounding_specificity_rationale": "The review point mentions 'model performance' which is a specific area within the paper. While it doesn't pinpoint a specific section, table, or figure, it clearly identifies the aspect of the paper being addressed. The reviewer also mentions 'under different scenarios,' which adds a level of specificity to the area of model performance being considered.", "verifiability_rationale": "The review point contains claims such as 'Error analysis plays a crucial role in evaluating model performance and identifying potential issues' and 'We encourage the authors to conduct error analysis in the paper and provide detailed explanations of the model's performance under different scenarios.' However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The importance of error analysis and the benefits of explaining performance under different scenarios are generally accepted in the field but are not explicitly justified in this review point.", "helpfulness_rationale": "The review point suggests conducting error analysis and explaining model performance under different scenarios. While this is a relevant suggestion for improving the research, it lacks specific details on *how* the authors should perform the error analysis or *what* specific scenarios they should consider. The 'encouragement' is also vague and lacks concrete reasons for encouraging this specific type of analysis. Therefore, while the suggestion is relevant, it does not provide the authors with a clear and actionable path forward, making it 3 but lacking the necessary specificity."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer's statement is a direct critique of the authors' claim, but it doesn't explicitly state an action the authors should take. While it implies a desire for the authors to verify the NLP aspect, it lacks concrete instructions on how to do so.", "grounding_specificity_rationale": "The reviewer's statement is general and doesn't pinpoint a specific part of the paper being addressed. They are criticizing the authors' characterization of their work as a 'preliminary work' in NLP, but not identifying a specific section or element.", "verifiability_rationale": "The reviewer makes a claim ('I don't see anything NLPspecific') but doesn't provide external references or logical reasoning to support it. They are stating their belief about the authors' work, but not verifying it.", "helpfulness_rationale": "The reviewer's statement is a critique of the authors' claim and doesn't offer any specific, actionable feedback on how to improve the paper. It's a statement of opinion rather than a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests including a comparison with at least one NCEbased method, which is an explicit action. However, it lacks specific details on which method to compare or how the comparison should be conducted.", "grounding_specificity_rationale": "The review point suggests including a comparison with at least one NCEbased method. While it implies a comparison, it doesn't specify which NCE method or provide context about the existing work being critiqued.", "verifiability_rationale": "The review point makes a claim about a specific paper 1 showing that with a strong noise distribution, NCEbased methods can learn EBMs on natural images. However, without knowing the details of 1 or the specific 'this line of work,' the claim is not verifiable within the provided context.", "helpfulness_rationale": "The review point offers a suggestion for comparison, which is a helpful direction for improvement. However, it lacks specifics on which method to compare or how to perform the comparison. The mention of 1 is isolated and doesn't directly address the paper being reviewed."}
{"actionability_label": "4", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states two actions: 'carry significance test on the human evaluation results' and 'compare the proposed method with some most recent LLM'. These actions are both clear and direct, providing the authors with specific steps to improve their work. The reviewer is not just pointing out a weakness but suggesting concrete modifications.", "grounding_specificity_rationale": "The review point mentions 'human evaluation results' and 'proposed method'. While it doesn't specify the exact section or table within the paper, it clearly identifies the area of the paper being addressed. The reviewer is pointing to specific parts of the paper, even if they are not the most granular elements (like a specific figure or table).", "verifiability_rationale": "The review point makes two claims: 'It is better to carry significance test on the human evaluation results' and 'It is beneficial to compare the proposed method with some most recent LLM'. Both claims are supported by common knowledge and accepted practices in the field. Significance tests are a standard statistical method, and comparing with recent LLMs is a relevant suggestion for improvement. The reviewer provides logical reasoning and commonsense arguments to support their claims.", "helpfulness_rationale": "The review point provides two clear and actionable suggestions: adding significance tests to human evaluation results and comparing the proposed method with recent LLMs. These suggestions are directly relevant to improving the paper and are supported by logical reasoning and common practices. The reviewer provides concrete examples of what the authors should do, making the feedback very actionable and helpful."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states that the comparison with SOTA methods might be unfair and provides a specific example of the dataset size difference between their method (209M) and GEM (20M). This directly identifies a potential flaw in the experimental setup and offers a clear direction for improvement. The reviewer also suggests that the superior performance could be due to the larger dataset, which is a concrete action the authors can take to investigate the source of the improvement.", "grounding_specificity_rationale": "The reviewer's statement about the comparison with SOTA methods being potentially unfair is a general criticism about the experimental setup. While they mention the dataset sizes, they don't specifically point to a particular section, table, or unique aspect of their paper being affected by the dataset size difference. The criticism is about the comparison itself, not a specific element within a section.", "verifiability_rationale": "The reviewer makes a claim about the potential unfairness of the comparison due to dataset size but doesn't provide any specific evidence or justification for this claim. They suggest the larger dataset (209M) might be the reason for the superior performance of their method compared to SOTA methods that use smaller datasets. While the suggestion is a possible explanation, it lacks concrete supporting evidence or references to external works.", "helpfulness_rationale": "The reviewer's point about the potential unfairness of the comparison is a valuable piece of feedback for the authors. They are highlighting a potential flaw in the experimental design and offering a concrete suggestion for the authors to investigate the impact of dataset size on their method's performance. This actionable feedback can help the authors improve their understanding and validation of their approach."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the issue (biases and prediction shifts exist) and asks a direct question about its generalizability, which is an explicit action. The action is also concrete as the reviewer clearly identifies the specific areas (section 3.2 and Theorem 1) where the biases and prediction shifts are discussed. This means the authors know exactly what needs to be considered.", "grounding_specificity_rationale": "The reviewer explicitly refers to 'section 3.2' and 'Theorem 1', which are specific parts of the paper. This indicates strong grounding as the reviewer can accurately pinpoint the referenced section. The specificity is also high as the reviewer asks a specific question about the generalizability of the content discussed in these sections.", "verifiability_rationale": "The reviewer makes a claim by stating that the generalizability of the discussed biases and prediction shift is unclear. While the paper presents specific examples of these biases and prediction shifts, it does not explicitly provide a general rule or justification for why they might be general or specific. Therefore, the claim is supported by the provided context (section 3.2 and Theorem 1), making it 3. The reviewer is asking a question that can be logically inferred from the provided information, but it doesn't provide a definitive answer.", "helpfulness_rationale": "The reviewer's question directly addresses a potential weakness in the paper's analysis. By asking about the generalizability of the discussed biases and prediction shifts, the reviewer is prompting the authors to critically evaluate the scope and applicability of their findings. This question is likely to be helpful for the authors in understanding the limitations of their method and guiding future research. While it doesn't provide a solution, it encourages a deeper analysis of the identified issues."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the method in Section 3.1 seems to follow the previous work, Luciddreamer. While this indicates a potential lack of explicitness, the reviewer doesn't provide specific details on what is being followed or how it differs. The action is implied, but the details are missing, making it difficult to act upon.", "grounding_specificity_rationale": "The reviewer mentions 'Sec. 3.1' and 'Luciddreamer' but doesn't explicitly point to a specific part within Section 3.1 that they are criticizing. The grounding is weak because the authors can only infer the reference to Luciddreamer.", "verifiability_rationale": "The reviewer makes a claim that the method 'seems to just follow the previous work'. To verify this claim, we would need to examine Section 3.1 of the paper in question and compare it to Luciddreamer. The reviewer does not provide any evidence to support this claim within their review point, making it 1 based on the information given.", "helpfulness_rationale": "The reviewer's comment raises a valid concern about the novelty of the method in Section 3.1. However, they do not provide any specific suggestions or explanations for how the method might differ from Luciddreamer. While the comment points out a potential issue, it doesn't offer concrete help for the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the DNN introduction is 'entirely devoted to a general introduction of DNNs' and lacks any mention of drift. They then state, 'Given that the paper's core focus is on detecting drift types and drift magnitude, I believe the DNNrelated introduction is not central to this paper...'. This is an explicit statement identifying a weakness and a direct action to take: remove or reframe the paragraph. The reviewer also specifies the *nature* of the weakness: it's a general DNN introduction rather than something directly related to drift detection. Therefore, the action is both explicit and concrete.", "grounding_specificity_rationale": "The reviewer explicitly identifies the specific part of the paper being addressed: 'the Introduction' and then more specifically, 'a general introduction of DNNs' within that section. They also clearly specify the *issue* within that section: the lack of mention of 'drift,' which is the core focus of the paper. The reviewer's statement 'Given that the paper's core focus is on detecting drift types and drift magnitude...' directly links the identified section to the paper's stated goal. This strong identification of the section and the specific problem within it constitutes full grounding.", "verifiability_rationale": "The reviewer makes a claim: 'the DNNrelated introduction is not central to this paper and provides little valuable information to readers.' While the paper itself might not explicitly state this, the logical connection between the stated focus on drift detection and the relevance of the DNN introduction is clear. The reviewer's assessment is based on the understanding of the paper's core topic and the logical deduction that a general DNN introduction is not directly informative about drift detection. This provides a basis for verification, even if the paper doesn't explicitly state it. The reviewer's reasoning is based on common knowledge within the field of time series analysis and machine learning.", "helpfulness_rationale": "The reviewer's assessment is directly about the value of the information. They believe the DNN introduction is distracting and uninformative for their specific paper, which focuses on drift detection. This is a clear and helpful suggestion for improving the clarity and focus of the paper. The reviewer's point is actionable and directly addresses a potential source of confusion or distraction for the readers."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is a question prompting the authors to consider a simplification. It doesn't directly instruct them on how to simplify, what parts to change, or how to validate such a simplification. Therefore, it lacks explicit and concrete instructions on what needs to be done.", "grounding_specificity_rationale": "The review point refers to \"definition 2 and theorem 2\" generally, without specifying a particular section, paragraph, or element within those. It doesn't identify a specific part of the paper being addressed.", "verifiability_rationale": "The review point itself doesn't make a claim. It's a suggestion, not a statement that requires verification. While it implies a problem (the current presentation is hard to digest), it doesn't explicitly state a claim that needs supporting evidence.", "helpfulness_rationale": "The review point is a suggestion to simplify the presentation of a theorem. It's a helpful suggestion, as it points out a potential area for improvement. However, it lacks specific steps or guidance on how to achieve this simplification, making it not fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests an experiment (using larger resolution) but does not explicitly state how the author should implement this change. While the suggestion is related to an action (modifying the experimental setup), the lack of concrete steps makes it difficult to consider it fully actionable. The reviewer asks how performance will be, implying a need for an action, but doesn't detail it.", "grounding_specificity_rationale": "The review point does not explicitly mention a specific part of the paper or experiment. It refers to 'all the experiments,' making it difficult for the author to pinpoint the exact area that needs adjustment. The lack of a clear reference point reduces the grounding specificity.", "verifiability_rationale": "The review point suggests an experiment (using larger resolution) and asks a question about the potential impact on performance. However, it does not provide any justification, reasoning, or references to support this suggestion. There is no logical reasoning, common knowledge, or external references provided to back up the claim that performance might change with a larger resolution.", "helpfulness_rationale": "The review point suggests an experiment (using larger resolution) and asks a question about the potential impact on performance. While this points to a valid area for future investigation, it lacks concrete action and justification. The reviewer does not provide any specific steps on how to implement the change or any reasoning for why performance might be affected. This makes the review point less immediately helpful as it doesn't offer a clear path for the author to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point suggests a potential issue (algorithms following the sampled policy for awhile) and proposes a solution (mentioning the sampled policy). However, it does not explicitly state how to identify if the policy is being followed or how to implement the mention. The action is implied but not explicitly stated, making it implicit. Once the action is identified (mentioning the policy), the authors still don't know how to carry out this action, making it vague. Therefore, it's 2.", "grounding_specificity_rationale": "The review point explicitly mentions 'sampled policy' as a specific aspect of the algorithm. This directly identifies the specific part of the paper being addressed. The mention of 'sampled policy' is also clear and specific, detailing what needs to be considered. Therefore, it is 5.", "verifiability_rationale": "The review point makes a suggestion (algorithms might want to follow the sampled policy) but does not provide a claim or a statement that requires justification. It's a suggestion, not a claim that needs to be supported by evidence. Therefore, it contains X and is not verifiable.", "helpfulness_rationale": "The review point directly addresses a potential implementation detail of the algorithm and suggests a specific change (mentioning the sampled policy). This is a clear and actionable suggestion that directly addresses a potential implementation issue. The authors can directly identify the modification they should apply to their draft. Therefore, it is 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly suggests 'Additional experiments on larger data sets' as a potential improvement. This is a direct and clear action that the authors can readily apply. While the reviewer also mentions 'I understand that compute might be an issue', this is a constraint rather than a direct action. The core action is to add more experiments.", "grounding_specificity_rationale": "The comment directly refers to 'computational might be an issue' and 'large batch size'. While it doesn't explicitly state which part of the paper is being addressed, the context implies it relates to the experimental setup and computational aspects of the work. The reviewer mentions 'maintaining the probabilities', which could be a specific aspect, but the primary focus is on the broader issue of compute and batch size. The grounding is somewhat implied but not fully explicit.", "verifiability_rationale": "The comment raises a concern about 'maintaining the probabilities' in 'large batch size'. This is a claim that requires justification. The reviewer states 'I still think maintaining the probabilities might become an issue', indicating a lack of clear evidence or reasoning to support this concern. The verifiability relies on the reviewer's understanding and experience, which might not be universally accepted or easily verifiable without further investigation.", "helpfulness_rationale": "The comment offers a suggestion for improvement ('Additional experiments on larger data sets') and raises a concern ('I still think maintaining the probabilities might become an issue, in particular at large batch size'). While the suggestion is valid, it's not a concrete, actionable step that the authors can immediately implement without further clarification or experimentation details. The concern about probabilities is also raised, but the reviewer deems it less critical. The overall feedback is positive ('Thanks for the author response. I still think maintaining the probabilities might become an issue, in particular at large batch size, but I don't think this aspect is critical. Generally, the response addressed my concerns well.')."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'I think the paper could greatly benefit from more explanation of the meaning of the bounds (perhaps in the appendix).' This action is to suggest adding more detail to a specific aspect of the paper (the bounds). The reviewer clearly indicates what they want to change, making it an explicit action. While the specific bounds are not mentioned, the general action of explaining their meaning is clear and directly actionable for the authors.", "grounding_specificity_rationale": "The review point refers to 'the meaning of the bounds' generally. While the concept of bounds is implied, the specific bounds are not explicitly identified. The reviewer does not mention a specific section, table, or figure. The suggestion is at a high level, not pointing to a particular location within the paper. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses. However, the reviewer does specify what they believe is missing \u2013 the explanation of the bounds. This makes the specificity somewhat clear, as the authors know the area of improvement.", "verifiability_rationale": "The review point contains a claim: 'I think the paper could greatly benefit from more explanation of the meaning of the bounds.' This is a statement of opinion. However, the reviewer does not provide any evidence or justification for this claim. They are stating their preference for more explanation without citing specific examples, external references, or logical reasoning. Therefore, the claim is not supported by any verifiable evidence, making it 1.", "helpfulness_rationale": "The review point directly points out a weakness in the paper \u2013 the lack of explanation for the bounds \u2013 and suggests a concrete improvement: 'perhaps in the appendix'. This is a constructive criticism that directly addresses a specific area of the paper. The reviewer provides a clear suggestion for improvement, making the comment actionable and valuable for the authors. While the suggestion is specific about the location (appendix), the initial identification of the missing explanation is also helpful."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "6: X", "helpfulness_label": "2", "actionability_rationale": "The review point focuses on a critique regarding the number of datasets used for evaluation, which is a valid concern for rigorous assessment. However, the point lacks specific details about the nature of the datasets, the tasks, or the specific issues with the dataset numbers. The reviewer doesn't explicitly state what action or improvement is being suggested based on this information, making it difficult to assess actionability.", "grounding_specificity_rationale": "The review point does not explicitly mention any specific part of the paper (e.g., a particular section, table, figure, or dataset) in relation to the critique about the number of datasets. There is no grounding of the comment to a specific aspect of the paper. Therefore, it cannot be considered grounded in terms of identifying a specific part.", "verifiability_rationale": "The review point raises a concern about the number of datasets but doesn't provide any specific evidence or reasoning to support this concern. There is X being made, and therefore no verifiability is involved.", "helpfulness_rationale": "The review point raises a concern about the number of datasets used for evaluation. While this is a valid point for discussion and could lead to improvements in the experimental design, the review point itself does not offer any concrete suggestions or guidance on how to improve the draft based on this information. It is a critique without a direct solution."}
{"actionability_label": "1 (1)", "grounding_specificity_label": "None", "verifiability_label": "None", "helpfulness_label": "None", "actionability_rationale": "The review point states the absence of results for larger models but does not provide any explicit or implicit instructions for the authors to take any action.", "grounding_specificity_rationale": "None", "verifiability_rationale": "None", "helpfulness_rationale": "None"}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review points out a *potential* advantage of the method and then criticizes its practical limitations. While it identifies a *problem* (sparse rewards, subtask rewards), it doesn't *explicitly* tell the author *how* to fix it or what specific changes are needed. The connection to \"actionability\" is weak.", "grounding_specificity_rationale": "The review refers to \"this method\" and 'sparse reward problems,\" implying a connection to the paper's content. It points out a *potential* issue with the method's practical implementation (subtask rewards). While it hints at the *where* (method), it doesn't explicitly state *which specific section/figure/table* is being criticized. The criticism is about the *application* of the method, not a specific technical detail within it.", "verifiability_rationale": "The review makes a claim: \"From the experiments, this does not support well.\" It also raises a question: \"in practice, the proposed method requires subtaskspecific rewards to be specified, which would be similar to providing a dense reward signal.\" The reviewer does not provide external references or logical reasoning to support *either* part of the claim. The claim is based on an interpretation of the experiments and a logical comparison.", "helpfulness_rationale": "The review criticizes a potential application and suggests an alternative (dense rewards). However, it doesn't *teach* the author how to implement subtask rewards or how to diagnose issues with dense rewards. The feedback is more of a *criticism* and a *suggestion* rather than a constructive *howto*. The minor comments are also not addressed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The reviewer states that the paper 'lacks a detailed discussion' and 'seemed not to give any new insight'. While these are valid points, the reviewer does not explicitly state what specific action the authors should take to address these issues. The language is more about identifying problems than providing clear, actionable steps. For example, the reviewer could have suggested the authors add a section on the limitations of their approach or explicitly discuss how their work builds upon existing research. The lack of specific action makes it 3 but not fully actionable.", "grounding_specificity_rationale": "The reviewer states that the paper 'lacks a detailed discussion' and 'seemed not to give any new insight'. However, the reviewer does not specify *where* in the paper these issues are located or *what* aspects are missing. The statements are general and do not pinpoint the specific section, table, figure, or unique element being addressed. Therefore, the grounding is weak. For example, the reviewer could have specified that the discussion lacks a detailed analysis of the experimental setup or that the paper doesn't adequately discuss the limitations of the proposed method. The lack of specific references makes it 2.", "verifiability_rationale": "The reviewer makes claims about the paper 'lacking a detailed discussion' and 'not giving any new insight'. These are claims that need to be supported. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to back up these statements. The claims are presented without sufficient justification. For example, the reviewer could have referenced existing literature on the depth of discussion required in this field or provided a brief explanation of what constitutes a 'new insight'. The lack of supporting evidence makes it 1.", "helpfulness_rationale": "The reviewer states that the paper 'lacks a detailed discussion' and 'seemed not to give any new insight'. While these are valid points, the reviewer does not provide any suggestions or recommendations for the authors to improve their work based on these observations. The language is more about criticizing the paper than offering constructive feedback. For example, the reviewer could have suggested the authors add a section on the limitations of their approach or explicitly discuss how their work builds upon existing research. The lack of actionable suggestions makes it 1."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that the motivation is unclear and that the experimental comparison is unfair. However, the reviewer does not explicitly state what specific aspects of the motivation are unclear (e.g., the problem statement, the novelty of the approach, the benefits of the adversarial network). Similarly, the reviewer claims the comparison is unfair but does not specify what makes it unfair (e.g., differences in training data, evaluation metrics, hyperparameter tuning). While the reviewer identifies the issues, they do not actively engage with the authors to improve their work by suggesting specific changes or asking clarifying questions. The reviewer points out problems but doesn't actively seek to make the authors' work better.", "grounding_specificity_rationale": "The reviewer states that the motivation is unclear and that the experimental comparison is unfair. While the reviewer mentions the motivation, they do not specify which part of the motivation is unclear (e.g., the problem statement, the novelty of the approach, the benefits of the adversarial network). Similarly, the reviewer claims the comparison is unfair but does not identify the specific aspects of the comparison that are problematic (e.g., differences in training data, evaluation metrics, hyperparameter tuning). The reviewer also mentions 'CAT and GAN' but does not specify which part of the model these components are applied to or how they contribute to the overall model size. The reviewer points out issues but lacks specificity in identifying the exact areas of concern within the paper.", "verifiability_rationale": "The reviewer states that the motivation is unclear and that the experimental comparison is unfair. These statements can be considered claims that need to be supported. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to support these claims. The reviewer simply states that the motivation is unclear and the comparison is unfair without providing evidence or explaining why. The reviewer also mentions 'CAT and GAN' but does not provide any information or justification for their relevance or impact. The reviewer's statements are presented as assertions without sufficient backing or explanation.", "helpfulness_rationale": "The reviewer provides a general critique of the paper, pointing out that the motivation is unclear, the experimental comparison is unfair, and the model is bigger. While these are valid concerns, the reviewer does not offer specific, actionable suggestions or requests for clarification that would empower the authors to improve their work. The reviewer states the problems but does not actively engage with the authors to make their research better by suggesting concrete changes or asking specific questions. The reviewer's comments are informative but lack the specific, actionable feedback needed to significantly improve the authors' research."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment defines adversarial loss and states a property it should have, but it doesn't provide explicit instructions on how to implement or apply this to the author's draft. It's a definition, not a direct action.", "grounding_specificity_rationale": "The comment does not specify which part of the paper it is referring to. It is a general statement about adversarial loss and its properties, without pinpointing a specific section, table, figure, or unique aspect of a potential paper. Therefore, the grounding is weak.", "verifiability_rationale": "The comment defines adversarial loss and states a property it should have. While it provides information, it doesn't make a claim that requires verification or justification. It's more of a specification than a verifiable statement.", "helpfulness_rationale": "The comment provides information about adversarial loss, but it doesn't offer specific suggestions or guidance on how this relates to improving the author's draft. It's more of a definition and a constraint than a helpful suggestion."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The reviewer points out that the performance is only compared with few methods, which implies an actionable suggestion to improve the comparison. However, the core issue is the inconsistent performance, which is a more direct action the authors should take. The reviewer's willingness to change the rating suggests an action, but the content of the review point itself is more about the lack of consistent improvement.", "grounding_specificity_rationale": "The reviewer mentions 'a few methods' for comparison. While this identifies a specific part (the comparison methodology), they don't specify *which* part of their method or experiment is being compared. The general idea of limited comparison is not fully grounded in a specific section, table, or unique aspect.", "verifiability_rationale": "The reviewer states that the results violate the motivation. This is a claim that needs justification. However, the reviewer's statement itself doesn't provide the necessary evidence or reasoning to verify this claim. The verifiability comes from the *motivation* of the work, not from the reviewer's statement alone.", "helpfulness_rationale": "The reviewer explicitly states that the comment is 1 because it doesn't explain *why* the results are inferior and doesn't suggest improvements. The lack of justification and actionable suggestions makes the comment unhelpful."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point is a question about comparing support, which does not directly instruct the author on what to do or how to implement this comparison. It asks 'how' to compare, which is a question, not an action. The action is implied but not stated explicitly. Therefore, it is not actionable.", "grounding_specificity_rationale": "The review point is about comparing support but does not specify which part of the paper this comparison is being made with respect to. It does not identify a specific section, table, figure, or unique aspect of the paper. The grounding is missing. Therefore, it is 1.", "verifiability_rationale": "The review point is a question, not a declarative statement that makes a claim. It does not contain a claim that needs to be verified. Therefore, it is not verifiable.", "helpfulness_rationale": "The review point is a question about comparing support, which does not directly provide actionable feedback or insights for the author on how to improve their draft based on this comparison. It is a question, not a direct instruction or insight into the author's work. Therefore, it is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential issue regarding the originality of the work by drawing a similarity to a previous study. While it points out the concern, it does not explicitly state the action the author should take to address this. The suggested action, 'demonstrate novelty,' is broad and lacks specific details on how to achieve this. Therefore, the action is implicit and requires the author to infer the next steps.", "grounding_specificity_rationale": "The review point mentions the 'reasoning and writing logic' of the article but does not specify which part of the paper or a particular element is being criticized. The reference is general and does not point to a specific section, table, figure, or unique aspect. Therefore, the grounding is weak as the reviewer cannot confidently determine the area being addressed.", "verifiability_rationale": "The review point contains a claim: 'It raises the question of whether this work is merely an extension of the previous study or if it introduces novel contributions.' This claim requires justification and verification. However, the review does not provide any specific evidence, examples, or references to support this claim. The reasoning is lacking, and there are no external references provided to back up the assertion. Therefore, the claim is not wellsupported.", "helpfulness_rationale": "The review point raises a valid concern about the originality of the work and questions whether it is an extension of a previous study. However, it does not offer any specific suggestions or guidance on how the author can address this concern or demonstrate the novelty of their contributions. The suggested action, 'demonstrate novelty,' is too vague and lacks concrete steps. Therefore, the review point is not particularly helpful in providing actionable feedback to the author."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the 'verylongterm forecasting task is of limited practical significance' and provides concrete suggestions for improvement, such as 'conducing experiments on more datasets' and 'training the baseline models with the \"correct\" forecast horizon to put the results in a proper context'. These suggestions are direct and actionable, indicating a clear direction for the authors to follow.", "grounding_specificity_rationale": "The reviewer mentions the 'verylongterm forecasting task' but does not explicitly identify a specific section, table, figure, or unique aspect of the paper being addressed. While the reviewer provides suggestions related to this task, the reference itself is general and does not pinpoint a specific part of the paper.", "verifiability_rationale": "The reviewer makes a claim about the 'limited practical significance' of the verylongterm forecasting task. While this claim is relevant, the reviewer does not provide any external references or logical reasoning to support this assertion. The suggestions for improvement are practical but lack a strong theoretical or empirical basis within the review itself.", "helpfulness_rationale": "The reviewer identifies a limitation of the verylongterm forecasting task and provides concrete suggestions for improvement, such as conducting experiments on more datasets and training baseline models with the 'correct' forecast horizon. These suggestions are directly actionable and aim to address the identified limitation, making the feedback valuable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests that the paper lacks 'deeper theoretical or experimental exploration'. While this points to an actionable direction for future research, the suggestion itself is vague and doesn't specify *how* to conduct this exploration. The action is implied, but the details are missing.", "grounding_specificity_rationale": "The reviewer points out a gap in the paper's analysis but doesn't specify *which* part of the analysis is lacking depth. They mention 'why simple greedy selection approach outperforms more principled acquisition functions' and 'why deterministic MLP predictors outperform more robust probabilistic predictors', but don't pinpoint the exact section, table, or figure where this analysis is missing. The grounding is weak because the paper's content is mentioned, but the specific area of analysis is not.", "verifiability_rationale": "The reviewer makes a claim that the paper lacks 'rigorous analyses'. This claim is verifiable because the paper primarily focuses on empirical results and doesn't provide detailed explanations or justifications for the observed performance differences between methods. The reasoning is present, but the depth of analysis is missing.", "helpfulness_rationale": "The reviewer's comment is helpful in guiding future research directions by suggesting a deeper analysis of the paper's findings. While it doesn't directly provide a solution, it points towards a valuable area for further investigation, which can be helpful for researchers building upon this work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly states the action of 'analyze the security...of the proposed framework'. However, it does not specify how to perform this analysis, making it somewhat vague on how to implement the action.", "grounding_specificity_rationale": "The comment refers to 'the proposed framework' generally, without identifying a specific section, table, figure, or any unique element of the paper. This makes it 1 at all.", "verifiability_rationale": "The comment makes a claim about the lack of analysis of the security of the proposed framework. However, it does not provide any logical reasoning, common knowledge, or external references to support this claim, making it 1.", "helpfulness_rationale": "The comment identifies a significant omission in the paper \u2013 the lack of analysis of the security (privacy) of the proposed framework. This is a crucial aspect for assessing the practical applicability and trustworthiness of the framework. By highlighting this, the reviewer provides valuable information to the authors, prompting them to address this critical gap."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the perceived limitation of the framework in Section 4.1 and the discussion in the appendix, and clearly suggests considering representation learning for improvement in Section 4.2. This provides a clear direction for the authors to enhance their method. The suggestion is direct and points to a specific area for change.", "grounding_specificity_rationale": "The reviewer mentions 'mask selection' and 'rawlevel features' in Section 4.2, which are terms used in the paper. However, they do not explicitly state which specific part of the paper they are referring to within Section 4.2. While the suggestion is related to Section 4.2, the grounding is not as precise as it could be. The connection to the framework in Section 4.1 and the appendix is implied but not explicitly stated as the basis for the criticism.", "verifiability_rationale": "The reviewer states a suggestion for improvement ('I think the feature selection...could be further improved...') in Section 4.2. This constitutes a claim. However, the suggestion itself is quite general and lacks specific examples of how representation learning could be applied to the feature selection process. There are no external references provided to support this suggestion. The connection to the framework in Section 4.1 and the appendix is implied but not explicitly verified as supporting evidence for the suggestion.", "helpfulness_rationale": "The reviewer provides a clear criticism of a potential limitation in the proposed method (invariant learning module) and offers a specific suggestion for improvement (considering representation learning). This criticism is directly aimed at the authors and provides a concrete direction for them to enhance their work. The suggestion is specific enough to guide the authors towards a potential area of further research or implementation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer suggests considering the impact of paraphrase quality on subsequent steps. While this is a clear direction for the authors to take, the reviewer does not provide specific actions or concrete steps on how to *consider* this impact. The suggestion is general and lacks actionable details.", "grounding_specificity_rationale": "The reviewer explicitly states 'how different the paraphrases are from the original sentences.' This clearly identifies the specific aspect of the paraphrasing process being addressed, indicating strong grounding. However, the reviewer does not specify *what* constitutes 'different' or provide examples of expected differences. The grounding is present but lacks specific details about the nature of the difference.", "verifiability_rationale": "The reviewer makes a claim about the impact of paraphrase difference on training data quality. They provide a general explanation of *why* they believe this is important, stating that the model 'greatly relies' on the quality of paraphrases. While this provides some logical reasoning, the reviewer does not provide specific examples of how this reliance manifests or cite any external references to support this claim. The claim is supported by inference but lacks concrete evidence.", "helpfulness_rationale": "The reviewer clearly identifies a potential issue (low paraphrase quality) and highlights its significance for the training process. They explain the *consequences* of this issue, stating that it will 'greatly rely' on the quality of paraphrases and that this 'crucially impacts the subsequent steps'. This provides valuable information for the authors and is directly relevant to improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests 'further verify the effectiveness and universality to nonLLMbased models'. This implies an action, but it is not explicitly stated what needs to be done. It is an implicit suggestion to test the framework on other types of models. Therefore, while it points towards an action, the specifics are not clearly defined, making it 3 but not fully so.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'LLMbased models' and even names specific examples like 'HiTeA and InternVideo' as potential nonLLMbased models to test the framework on. This clearly identifies the specific part of the paper (the evaluation of generative VideoQA models) being addressed and provides concrete examples. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The reviewer states 'I believe the FlippedQA is a general framework for various generative VideoQA models' and then suggests 'further verify the effectiveness and universality to nonLLMbased models'. This statement contains a claim (the belief about the framework's generality) that requires justification. However, the reviewer does not provide any specific evidence or references within the review point to support this claim. The suggestion to 'verify' implies a need for logical reasoning and potentially external references, but these are not explicitly provided in the review point itself. Therefore, the claim is 3 but lacks immediate supporting evidence within the review point.", "helpfulness_rationale": "The reviewer provides a clear and actionable suggestion for the authors: 'further verify the effectiveness and universality to nonLLMbased models'. This directly addresses a potential limitation of the current evaluation and provides a concrete direction for improvement. This is a helpful and constructive suggestion for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "While the reviewer states that the method is a combination of existing methods and lacks theoretical novelty, they do not explicitly state what specific actions the authors should take to address this. The reviewer's statement points to a potential issue, but not directly actionable steps.", "grounding_specificity_rationale": "The reviewer names specific methods (ClopperPearson intervals and Gaussian elimination), which grounds the criticism in the technical details of the proposed approach. However, the criticism is about the *lack of novelty* of *combining* these methods, which is a higherlevel issue than a direct criticism of the methods themselves.", "verifiability_rationale": "The reviewer makes a claim about the lack of theoretical novelty without providing any supporting evidence or logical reasoning to support this claim. The statement is an opinion, not a verifiable fact.", "helpfulness_rationale": "The reviewer identifies a weakness (lack of theoretical novelty) but doesn't provide specific suggestions or actionable steps to address it. The statement itself indicates a lack of complete helpfulness."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "N", "helpfulness_label": "None", "actionability_rationale": "The reviewer is asking for clarification, which implies an action (understanding the text input), but it's not explicitly stated. It's borderline because the action is implicit.", "grounding_specificity_rationale": "The reviewer is asking about concatenating text input by the four text elements of an object. This directly references a specific part of the text input process and the unique aspect being addressed.", "verifiability_rationale": "The comment is a question, not a claim that needs verification.", "helpfulness_rationale": "The question is directly relevant to how authors input text and addresses a potential technical hurdle. While it doesn't offer a solution, it points to a common (or at least potentially confusing) scenario for authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests improving the paper's motivation but doesn't explicitly state what needs to be done. The phrase 'could do better' implies an expectation but lacks specific action.", "grounding_specificity_rationale": "The comment doesn't specify which part of the paper needs better motivation. It's a general suggestion without pinpointing a section, table, or figure.", "verifiability_rationale": "The comment presents a preference for better motivation but doesn't provide any justification or examples to support this claim. It lacks logical reasoning or references.", "helpfulness_rationale": "The comment provides a clear direction for improvement by suggesting better motivation. It's a constructive suggestion that would likely be helpful for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point suggests *what* to do (additional experiments) but doesn't specify *how* to do it or what specific results are needed. The phrase \"more support\" is vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions \"realistic noisy datasets like WebVision,\" clearly identifying the specific aspect of the paper being addressed and naming the relevant dataset. This demonstrates strong grounding and specificity.", "verifiability_rationale": "The review point is a suggestion for additional experiments, not a claim that is being asserted or verified. There is no explicit statement of opinion, judgment, or suggestion about the paper itself within this point.", "helpfulness_rationale": "The review point suggests *additional experiments* on a specific dataset, which directly addresses the weakness identified in the paper (lack of support for C2D). This is a valuable suggestion that would likely improve the paper. However, the lack of specificity regarding the *type* of experiments or the *expected results* makes it less impactful than a more detailed suggestion. It's helpful in pointing towards a solution but lacks some of the finer details that would make it fully \"5.\""}
{"actionability_label": "3", "grounding_specificity_label": "3: Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states 'lack of essential visualization of intermediate processes and comparisons'. This is an implicit suggestion that the authors should add visualizations. While the reviewer points out a missing element, they don't explicitly state what should replace it or how to implement it, making it only implicitly actionable.", "grounding_specificity_rationale": "The review point mentions 'intermediate processes' and 'comparisons' generally, without specifying *which* processes or *what kind* of comparisons. This lack of specificity means the authors cannot confidently identify the exact area that needs improvement. Furthermore, the criticism focuses on the *absence* of something rather than the *lack* of specific details within existing visualizations, making it underspecific.", "verifiability_rationale": "The review point states 'a lack of essential visualization of intermediate processes and comparisons'. This is a statement of a problem, not a claim that needs verification. There is no evidence provided to support or refute the existence of these visualizations. Therefore, it does not meet the criteria for verifiability, which requires a claim supported by logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The review point identifies a potential weakness ('lack of essential visualization') but does not offer any concrete suggestions or actionable steps for the authors to improve their draft. It is a negative statement about a missing element without proposing a positive alternative. Therefore, it does not provide helpful feedback to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer raises a valid point about the significance of the result and provides specific examples to support their concern. While the reviewer doesn't explicitly state an action, the question implies a desire for clarification on how the findings relate to prior work and the implications of the dimension dependence. The reviewer is implicitly asking for an action to be taken to address this concern, making it 3.", "grounding_specificity_rationale": "The reviewer explicitly mentions a prior work (15) and points out a specific change in the iteration complexity (from dimensionfree to dependent on dimension). This clearly indicates that the authors can identify the specific aspect of the paper being addressed (the result about escaping saddle points and its relation to prior work). Therefore, the grounding is fully specific.", "verifiability_rationale": "The reviewer is not making a claim that requires verification. They are expressing a concern about the significance of a result and pointing out a change in complexity. There is X being made, let alone one that needs logical reasoning, common knowledge, or external references to support. Therefore, it is 'X' (X).", "helpfulness_rationale": "The reviewer's primary concern is the lack of justification for the significance of the result and the change in iteration complexity. While the reviewer provides context, they do not offer a new insight or significantly improve understanding. The review primarily raises a question rather than providing a clear and actionable improvement. Therefore, it is '2' (2) as it raises a valid point but lacks a clear justification or improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review points out a potential issue (sensitivity to hyperparameters) but does not explicitly state an action the authors should take. While the concern itself is actionable, the lack of explicit guidance makes it 2.", "grounding_specificity_rationale": "The review does not specify which part of the paper is being addressed regarding hyperparameter sensitivity. It is a general concern about the method, not a specific issue within a particular section or table. Therefore, the grounding is weak.", "verifiability_rationale": "The review contains a claim ('This second point is especially crucial...') but does not provide any evidence or justification for this concern. It is a statement of potential problem without supporting data or reasoning. Therefore, it is 1.", "helpfulness_rationale": "The review raises a valid concern about a critical aspect of the method (hyperparameter sensitivity). This is helpful because it highlights a potential weakness that needs addressing. The reviewer also offers a concrete suggestion ('I will be willing to reconsider my rating if this particular issue is resolved'), which indicates a desire for more information or clarification on this point. The concern itself is actionable and relevant to the authors' work."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the work 'utilizes existing attack methods on a surrogate model' and 'is similar to use the transferability of adversarial examples directly'. This directly points out a potential lack of novelty and suggests the authors need to clarify their contribution. The reviewer provides a clear action for the authors to consider: they should explicitly claim the novelty and contribution of their method. The reviewer identifies a problem and suggests a direction for the authors to address it.", "grounding_specificity_rationale": "The reviewer's statement is general and does not specify which part of the paper or method they are referring to. They are making a broad claim about the similarity of their approach to existing methods. While they imply it's a problem, they don't identify a specific section, table, figure, or unique aspect of the paper that is affected. The reviewer's comment is at a high level of abstraction and lacks specificity.", "verifiability_rationale": "The reviewer makes a claim: 'This work utilizes existing attack methods on a surrogate model. It is similar to use the transferability of adversarial examples directly.' However, the reviewer does not provide any evidence, references, or logical reasoning to support this claim. They are stating an observation but not providing any justification for it. The reviewer's statement is a claim without any supporting evidence or justification.", "helpfulness_rationale": "The reviewer's point highlights a potential lack of novelty in the proposed method. While the reviewer identifies a valid concern about the method's similarity to existing techniques, they do not offer a concrete solution or actionable steps for the authors to take. The reviewer's comment is more of a pointer to a potential issue rather than a direct solution or improvement strategy. The authors still need to spend time thinking about how to address this issue themselves. The reviewer's comment is more of a pointer than a direct solution."}
{"actionability_label": "3", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the limitations of the experiment and provides suggestions for improvement. The criticism of the current experiment is clear, but the suggestion is quite general, focusing on 'strengthen the experiment in two ways' without specifying the nature of these ways. This makes the criticism somewhat explicit but the suggestion somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to specific elements of the paper, such as 'Prop 3.2' and 'large enough perturbation value,' indicating a clear understanding of the paper's content and the specific aspects being criticized. The comment also specifies what needs to be addressed in this part (the correctness of the pseudo feature importance).", "verifiability_rationale": "The reviewer makes claims about the limitations of the experiment and provides some justification, stating that the difference between the tested method and the pseudo feature importance is 'only the number of perturbations.' However, this justification is highlevel and lacks specific examples or references to external works to support the claims about Prop 3.2 and the necessity of a 'large enough' perturbation value. Therefore, while the claim is somewhat justified, it lacks key elements like examples or references, making it 3.", "helpfulness_rationale": "The reviewer clearly identifies a weakness in the experiment (the reliance on Prop 3.2 and perturbation size) and offers suggestions for improvement ('strengthen the experiment in two ways'). These suggestions are relevant and address the core issue. However, the suggestions are quite general, and the reviewer does not provide specific details on how the authors should implement these improvements. This makes the criticism helpful and the suggestions 3 but not fully actionable for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a potential alternative to the authors' current understanding regarding nonconvexity and SGD convergence. It suggests that if the loss function 'Z' has 'good properties', the issue might not be as significant. This points to a potential improvement or clarification for the authors. While the action is stated, the lack of specific details on what constitutes 'good properties' makes it less concrete.", "grounding_specificity_rationale": "The comment explicitly refers to 'Z' by name, which grounds the discussion about the loss function. However, it then mentions 'some good properties' without specifying which properties these are or how to identify them. This weakens the grounding as it doesn't pinpoint a specific aspect of 'Z'.", "verifiability_rationale": "The comment contains a claim: 'Nonconvexity may not be an issue for the SGD to converge, if the function Z has some good properties.' The reviewer attempts to support this claim by stating, 'SGD can converge to a stationary point even in nonconvex settings.' This provides a logical argument, although it lacks detailed examples or references. Therefore, the claim is somewhat supported by reasoning, making it verifiable but not 5.", "helpfulness_rationale": "The comment challenges the authors' assumption about nonconvexity and suggests an alternative perspective. This can be a valuable point of discussion and potentially helpful for the authors' understanding. However, the suggestion is general and doesn't provide specific actionable steps for the authors to take. It's a constructive comment but lacks immediate practical guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that 'The experimental settings are not mentioned properly.' While it identifies the issue, it doesn't specify *which* aspects of the experimental settings are missing or how they are missing. This makes it somewhat explicit but somewhat vague on the specifics of the missing information.", "grounding_specificity_rationale": "The comment refers to 'experimental settings' generally. While it doesn't point to a specific section, table, or figure, the term 'experimental settings' is a clear indicator of where the missing information might be located. Therefore, it can be considered weakly grounded as it doesn't precisely identify the referenced part, but it's also not entirely ungrounded as the category is clear.", "verifiability_rationale": "The comment contains a claim: 'The experimental settings are not mentioned properly.' This claim is wellsupported by the reasoning that these missing settings are critical for result reproducibility. The implication is that providing these details is necessary for the authors to replicate the results. This provides a clear justification for the claim.", "helpfulness_rationale": "The comment is clear and directly points out a critical issue: the lack of proper mention of experimental settings, which is crucial for reproducibility. It suggests that providing these details is necessary. This is a helpful comment as it guides the authors to focus on the experimental aspects of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer identifies a lack of support for the claim but doesn't explicitly state what is missing or how to improve the prompts, making it partially actionable.", "grounding_specificity_rationale": "The reviewer points out that the claim about effectiveness across various language pairs and domains is not fully supported by evidence from only two tables, indicating weak grounding and lack of specificity.", "verifiability_rationale": "The reviewer's statement that the slight improvement doesn't support the broad claim is verifiable based on the data in Tables 6 and 7, making it 5.", "helpfulness_rationale": "The reviewer's point is clear and directly addresses a potential issue with the claim made in the paper, making it 5 for the authors to understand the limitations of their claims."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the current method of aligning features and suggests specific alternative designs (sampling intervals and sample size). This provides a clear action for the authors to explore different configurations. The reviewer directly addresses the identified issue of different spatial locations being aligned to the same channel, making the action clear and actionable.", "grounding_specificity_rationale": "The reviewer explicitly identifies the 'Cycle FC' as the part of the model being discussed, clearly pinpointing the section being addressed. The reviewer also suggests specific experiments or analysis with different sampling intervals and sample size, which are concrete examples of what needs to be done. This strong grounding allows the authors to directly focus on the identified component and the proposed modifications.", "verifiability_rationale": "The reviewer presents a claim that exploring different sampling intervals and sample size could improve the model. This claim is supported by the suggestion to conduct experiments or analysis with these specific parameters. While the reviewer doesn't provide results, the suggestion to vary these parameters provides a verifiable method for the authors to investigate and potentially improve the model's performance.", "helpfulness_rationale": "The reviewer provides a clear direction for the authors to improve their model by suggesting specific experiments or analysis with different sampling intervals and sample size. This actionable feedback is more helpful than a general comment about the need for further analysis. The reviewer's suggestions are concrete and provide a clear path for the authors to explore potential improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The reviewer is asking for clarification on the feature extractor used, which is an implicit request for information about the methodology. While they are asking for what was used, they are not explicitly stating what steps should be taken next or how to apply the information. Therefore, it is 2.", "grounding_specificity_rationale": "The reviewer is specifically pointing to the dimensionality of the regions (512) and asking about the feature extractor used. This directly references a specific part of the paper and clearly identifies the issue related to that part. The request is precise and directly linked to the mentioned dimensionality. Therefore, it has high grounding specificity.", "verifiability_rationale": "The reviewer is posing a question about a specific detail in the paper (the feature extractor used for a region with dimensionality 512). This can be considered verifiable in the sense that the information to answer the question should exist in the paper. However, the reviewer is not presenting a claim or suggestion for improvement, but rather asking for information. Therefore, it is partially verifiable as it can be verified, but it doesn't present a claim that needs justification.", "helpfulness_rationale": "The reviewer is asking a question about a specific detail in the paper. While this is a valid request and could potentially be helpful for the authors, it doesn't directly point out a weakness in the paper or suggest an improvement. It's more of a request for clarification than a constructive critique. Therefore, it is not 5 in the sense of providing actionable feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment identifies a potential issue (unclear motivation) but doesn't directly instruct the authors on how to address it or what specific changes to make. It suggests investigating the reason but doesn't provide concrete steps.", "grounding_specificity_rationale": "The comment refers to 'CMD in federated learning' generally and doesn't specify a particular section, table, figure, or a unique aspect of the application within the paper. It's a broad statement about the motivation.", "verifiability_rationale": "The comment is an observation or statement of opinion about the clarity of the motivation, not a claim that requires verification or support from evidence.", "helpfulness_rationale": "The review points out a potential area for improvement (unclear motivation) which is a valuable piece of feedback. It encourages the authors to investigate this area further, even if it doesn't provide a specific action to take. It's better than a completely vague comment but could be more direct."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The comment explicitly identifies a potential ambiguity in the method description regarding the contribution of the UNet part in the CoNO model. It asks a direct question about whether the performance boost is due to the fractional transform or the UNet operation in the fractional Fourier domain. This suggests a clear action for the authors: to investigate and compare the performance of the CoNO model with a standard UNet architecture.", "grounding_specificity_rationale": "The comment explicitly mentions the 'UNet part' and the 'fractional transform' within the CoNO model. It also suggests comparing the proposed architecture to 'standard UNets'. This clearly identifies the specific components and the type of comparison the authors should perform, making the grounding highly specific.", "verifiability_rationale": "The comment doesn't present a claim that requires verification. Instead, it suggests experiments and comparisons. While the suggestions are valuable, the core of the comment is the *question* itself, which doesn't inherently require external verification to understand its basis.", "helpfulness_rationale": "This review point is 5 because it directly addresses a potential ambiguity in the method description. By asking whether the performance boost comes from the fractional transform or the UNet operation, it guides the authors to conduct crucial comparative experiments. The suggestion to compare against standard UNets is a concrete and actionable step that would significantly improve the understanding and validation of the proposed CoNO model. This directly helps the authors refine and validate their approach."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states their opinion directly ('marginal'), which is explicit. However, the reviewer does not specify *how* the contribution is marginal or what aspects of the contribution are lacking. The lack of specific details makes the action implicit.", "grounding_specificity_rationale": "The reviewer does not identify a specific part of the paper as being the issue. They offer a general assessment of the contribution's quality ('marginal'). Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer makes a claim ('the contribution looks marginal...'), which requires justification. However, the reviewer does not provide any evidence or reasoning to support this claim. The statement is presented as an opinion without backing.", "helpfulness_rationale": "The reviewer provides a clear and direct assessment of the contribution's value ('marginal...not a major contribution'). While negative, this is a straightforward evaluation that the authors can understand. The lack of specific evidence makes it 3 in identifying a potential weakness, even if 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly asks a question about the relationship between the described 'active learning pipeline' and traditional active learning, indicating a clear desire for clarification and a direct action to be taken on their part. While the action itself isn't immediately obvious, the question prompts the authors to distinguish between the two, making it 5.", "grounding_specificity_rationale": "The reviewer asks a specific question about the relationship to 'traditional active learning,' which directly targets a key aspect of the methodology. While they don't explicitly point to a specific section or table, the question is very focused on the core concept, indicating a high level of grounding. The specificity comes from the direct comparison being requested.", "verifiability_rationale": "The reviewer makes a claim that the authors 'claimed that they used active learning in step 2' and then asks for verification of this claim and a comparison to traditional active learning. This involves a clear claim and a request for supporting evidence (the comparison), making it highly verifiable.", "helpfulness_rationale": "The reviewer directly points out a potential ambiguity or misstatement in the paper regarding the novelty of the 'active learning pipeline.' This is a clear and actionable suggestion that is likely to be helpful for the authors to clarify their methodology and avoid potential confusion for readers. The question is specific and directly addresses a potential point of misunderstanding."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states a problem: 'Most baselines do not use 300WLP dataset in their training. Is 300WLP used in all experiments or just some? If it is used in all this would provide an unfair advantage to the proposed method.' This is an explicit statement identifying a discrepancy in the methodology. The reviewer clearly indicates that the proposed method uses 300WLP while the baselines do not (or might not have used the same procedure as the baselines). This is a clear indication of an actionable point.", "grounding_specificity_rationale": "The reviewer's statement is weakly grounded. While they identify the potential issue (300WLP usage affecting fairness), they do not explicitly point to a specific section, table, or figure in the paper where this methodology is discussed. The grounding is implicit \u2013 the reviewer is inferring the relevance of the 300WLP dataset to the fairness concern. The lack of a direct reference point makes the grounding weak.", "verifiability_rationale": "The reviewer's point is not verifiable as a claim. They are raising a concern about the experimental setup and methodology, but they are not proposing a specific claim or suggestion for improvement. The statement is a question and a potential flaw, but without a proposed solution or evidence, it cannot be considered verifiable.", "helpfulness_rationale": "The reviewer's point is 3 in that it highlights a potential flaw in the experimental methodology. It prompts the authors to doublecheck their methodology and consider the impact of the 300WLP dataset on their results. However, it doesn't directly suggest a concrete improvement or solution. The helpfulness is limited to raising a concern."}
{"actionability_label": "3", "grounding_specificity_label": "1: 2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a potential weakness in the algorithm's novelty but does not explicitly state what actions the authors should take to address this. It is an implicit statement of a potential issue rather than a direct instruction.", "grounding_specificity_rationale": "The review point refers to 'algorithm' generally and does not specify a particular technique or aspect within the paper. It lacks grounding and specificity regarding the nature of the potential lack of novelty.", "verifiability_rationale": "The review point expresses an opinion about the potential lack of novelty in the algorithm but does not present a claim that requires verification or support from evidence within the review itself.", "helpfulness_rationale": "The review point identifies a potential issue but does not provide specific guidance or suggestions on how the authors can address this issue. It raises a question rather than offering constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer points out a potential limitation in the model's assumption about how observations are generated, suggesting alternative aggregation methods. While the reviewer identifies a potential issue with the model's formulation, the suggestion to consider alternative aggregation methods is not an explicit action the authors should take. The reviewer implies the problem but doesn't provide a concrete stepbystep action. The lack of explicit guidance makes the action implicit.", "grounding_specificity_rationale": "The reviewer mentions 'Equation (1)' and refers to external papers, indicating they are referencing specific elements of the paper. However, they do not explicitly state which section, table, or figure they are referring to, nor do they provide a clear explanation of what is wrong with the referenced element. The grounding is weak because the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer claims that the model *assumes* averaging and *infers* that this might be incorrect. The claim is that the model *assumes* averaging, which is an implicit claim. There is no direct evidence or reference to external works within the review point to verify this claim. The reviewer is making an inference based on their understanding of the model, but the claim itself is not explicitly stated or supported within the provided text.", "helpfulness_rationale": "The reviewer suggests alternative aggregation methods, which could be helpful for improving the model's accuracy. While they don't provide specific implementation details, they offer a direction for improvement. The reviewer's comment is constructive and points towards a potential solution, making it 3 in guiding the authors towards a better model."}
{"actionability_label": "3", "grounding_specificity_label": "1 and Weakly Specific", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The reviewer points out a lack of comprehensive analysis of the method and experiments. They also criticize the underperformance compared to baselines and question the attribution of improvement. While they identify a problem, they don't explicitly state *how* the authors should address these issues. They point to a gap in the analysis but don't specify *what* needs to be added. Therefore, it's implicit and not very specific.", "grounding_specificity_rationale": "The reviewer criticizes the presentation of results and the lack of comprehensive analysis. They don't explicitly state which *part* of the paper or experiment is lacking analysis. They criticize the *overall* presentation and analysis but don't point to a specific section or figure. Therefore, the grounding is weak and not specific.", "verifiability_rationale": "The reviewer states that 'the analyses of the method itself and the experimental outcomes are not comprehensive enough' and 'Given that the authors' method underperforms the baseline in some instances' and 'one might question to what extent the performance improvement brought by this pretraining method can be attributed to the authors' claim...'. These are claims requiring improvement. However, the reviewer doesn't provide any specific evidence or reasoning to support their claims. They pose questions but don't offer answers or references. Therefore, the claims are not wellverified.", "helpfulness_rationale": "The reviewer criticizes the presentation of results, the lack of comprehensive analysis, and the questionable attribution of improvement. While they identify areas for improvement, they don't offer concrete *suggestions* on *how* to improve the analysis or address the underperformance. They raise concerns but don't provide actionable steps. Therefore, the feedback is critical but lacks specific solutions."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review points to a 'main takeaway point' and a specific action ('query a cluster proportionally to the square root of its size'). However, it doesn't explicitly state how to implement this action. The formula or algorithm isn't provided, making the action somewhat vague.", "grounding_specificity_rationale": "The review refers to 'the main takeaway point' of the theoretical results. While this mentions a specific aspect, it doesn't pinpoint the exact section, table, figure, or unique element within the paper where this takeaway is most relevant. It's a general statement about the results, lacking specific grounding.", "verifiability_rationale": "The review contains a suggestion ('ideal to see...') which is a form of opinion or judgment. It doesn't make a claim that can be definitively proven or disproven based on the information provided. Therefore, it's 2.", "helpfulness_rationale": "The review offers a suggestion for improvement ('query a cluster proportionally to the square root of its size') but lacks the specifics on how to do this. It also raises a question about novelty without providing any evidence. While it points to a potential area for improvement, the lack of concrete guidance makes it less helpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly asks 'why' and 'what additional info' regarding the use of separators in section 4. This is a direct and clear question about the purpose and utility of a specific element in the paper. The action is to explain the reason and additional benefits, which is concrete and directly addresses the reviewer's query.", "grounding_specificity_rationale": "The reviewer directly refers to 'section 4' when asking about the separators. This is a clear and specific identification of the part of the paper being addressed. The grounding is literal and points to a specific section.", "verifiability_rationale": "The reviewer's question about the 'additional info' beyond T/I/O requires external knowledge or a deeper understanding of distributed systems. While the need for separators exists within the context of communication, the specific *additional* information might not be explicitly stated within the paper itself. Therefore, the claim is somewhat supported by common knowledge in the field but lacks explicit references within the paper.", "helpfulness_rationale": "The reviewer's question directly addresses a potential area of confusion or lack of clarity regarding the use of separators. It is a relevant feedback point that could help improve the explanation in section 4. While the question itself is verifiable, the specific *additional* information might require external context to be fully helpful to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states the limitation of using short video sequences (16 frames) and suggests exploring longer sequences as a potential improvement. While the suggestion is clear, it doesn't specify *how* to implement the change within the current framework, making it somewhat concrete but not fully actionable.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'short video sequences (e.g., 16 frames)' and provides examples of issues (inconsistent motion, changing color, object disappearing). This strong mention and examples clearly indicate full grounding and specificity.", "verifiability_rationale": "The reviewer states that short video sequences have limitations based on their observed results. However, they don't provide external references or logical reasoning to *prove* these limitations. The suggestion for longer sequences is a potential improvement, not a verifiable claim about the current method's flaws.", "helpfulness_rationale": "The reviewer identifies a limitation of the current approach (short video sequences) and suggests exploring a different experimental setup (longer sequences). While helpful in guiding future research, it doesn't directly address the current issue with the 16frame method, making it 3 in pointing towards a relevant direction."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The review point asks a question about the outcome but does not specify how the authors should use this information. It lacks explicitness and concreteness.", "grounding_specificity_rationale": "The authors cannot confidently determine which part the comment addresses. Further, the comment does not specify what needs to be addressed in this part.", "verifiability_rationale": "The review point is a question about the paper's findings, not a claim that needs verification.", "helpfulness_rationale": "The review point is a question for clarification, not a critique or suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review points out a *problem* (unequal access to information) but doesn't offer a *specific action* to address it. It criticizes the *splitting method* but doesn't suggest an alternative or how to implement a change. The criticism is explicit about the *cause* (unequal access) but doesn't specify *how* the split is unfair or what should be done about it. Therefore, it lacks explicit and concrete actions that authors can directly implement.", "grounding_specificity_rationale": "The review states a fact about the BERT paper's arXiv posting date being before the typical ACL anthology publication date. However, it doesn't explicitly identify the BERT paper or the ACL anthology split being discussed in the authors' work. The reviewer provides a general example related to the topic but doesn't ground it to the specific paper or the split the authors used. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The review makes a factual observation: 'The paper split the papers according to their publication years on the ACL anthology. However, many papers are posted on arxiv much earlier than ACL anthology.' This is a description of a situation, not a claim that requires verification. There is no logical reasoning, common knowledge, or external references needed to understand this point. Therefore, it doesn't contain a claim that needs to be verified.", "helpfulness_rationale": "The review points out a potential *bias* in the data split used by the authors. While this is a valid observation, it doesn't offer any actionable feedback or insights on how the authors can improve their own draft based on this observation. The review focuses on a potential issue with the evaluation setup rather than providing concrete steps for the authors to take. Therefore, the review is not particularly helpful in guiding the authors towards improving their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out two specific areas where they lack understanding. The first is the motivation behind using an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p q. The second is the difference between QRS and RS in Algorithm 1. These are explicit points of confusion, and the reviewer clearly states what needs to be done (explain the motivation and the difference). The reviewer also mentions that these points are unclear in the paper, making the action concrete.", "grounding_specificity_rationale": "The reviewer states that they 'do not know what they should do after reading the comment' and that the comment lacks meaningful information. While the reviewer mentions 'the paper' generally, they do not specify a particular section or table. Therefore, the grounding is weak. The reviewer also states that the comment 'does not specify what needs to be addressed in this part' regarding the motivation and the difference between algorithms, making the specificity underspecific.", "verifiability_rationale": "The reviewer states that they 'fail to understand why the authors did not directly use Importance sampling' and that they 'fail to see a difference between QRS and RS'. These are claims that need to be supported. However, the reviewer does not provide any specific examples, references, or logical reasoning to support these claims. The support is vague and insufficient. The reviewer also states that the comment requires 'justification' to be understood or accepted, which aligns with the need for verifiable claims.", "helpfulness_rationale": "The reviewer's point is about clarifying the paper's content, which is inherently helpful. The reviewer explicitly states their lack of understanding and their desire to change their opinion if the authors can point out a value of u for which QRS and RS will behave differently. This indicates a desire for more specific and detailed explanations. However, the reviewer does not provide any concrete suggestions or propose any experiments to validate their claims, making the helpfulness somewhat limited."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out a potential misunderstanding regarding the term 'chunks' in the context of nonsequential information. They correctly identify the explicit nature of the comment, as it directly addresses a specific point of confusion. The reviewer is asking for clarification on how 'chunks' can be nonsequential, which is a direct action the authors should take.", "grounding_specificity_rationale": "The reviewer identifies the term 'chunks' as the specific part of the paper being addressed. However, they do not specify what is wrong with the use of 'chunks' in the context of nonsequential information. The grounding is weak because it doesn't identify a specific issue related to 'chunks'.", "verifiability_rationale": "The reviewer is not making a claim or suggesting a change. They are asking for clarification on a specific term. Therefore, there is no verifiable claim in this review point.", "helpfulness_rationale": "The review point directly addresses a potential point of confusion for the authors. While it doesn't propose a solution, it does highlight an area where the authors might need more information. Therefore, it is 3 in identifying a potential area of improvement."}
{"actionability_label": "1", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the paper has 'limited technical novelty' and draws parallels to two specific papers. This is a statement of fact, but it does not provide explicit or concrete suggestions for how the authors should improve their draft. The reviewer is pointing out a potential weakness but is not instructing them on what to do differently.", "grounding_specificity_rationale": "The reviewer mentions the 'idea, coattention mechanism, and architecture' as being similar to previous papers. While they identify a potential issue, they do not explicitly state which specific part of the paper (e.g., a particular section, table, or figure) is affected by this similarity. The connection between the similarity and the lack of novelty is implied but not clearly defined.", "verifiability_rationale": "The reviewer claims that the paper's idea, coattention mechanism, and architecture are similar to previous graphbased approaches. This is a claim that could be supported by referencing the mentioned papers or providing a detailed comparison. However, the reviewer does not provide any immediate evidence or reasoning to back up this claim.", "helpfulness_rationale": "The review point identifies a potential weakness in the paper's technical novelty and suggests a comparison to previous work. While this points to an area for improvement, it does not offer specific, actionable advice on how the authors should address this weakness. The reviewer is diagnosing a problem but not providing a solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer poses a question, which can be interpreted as an implicit request for clarification. While they don't explicitly state what is wrong with the current approach or what needs to be changed, the question itself points towards a potential limitation or area for improvement. However, the exact action or suggestion is not clearly defined, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions the potential for the problem to apply to 'other downstream tasks' and contrasts it with the specific context of 'binding affinity prediction'. This demonstrates a clear identification of the specific part of the paper or problem being discussed, indicating strong grounding. They are also asking for a justification, which specifies what needs to be addressed.", "verifiability_rationale": "The review point is a question, not a declarative statement that makes a claim. Therefore, it does not contain a claim that can be verified.", "helpfulness_rationale": "The reviewer is asking a question to gain clarity and understanding. While it doesn't directly improve the draft itself, it helps the authors understand the limitations of their model and potentially identify areas for future improvement. This indirect form of guidance can be considered helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly suggests a comparison in terms of computation cost and running time, which can be considered an action. However, the specifics of the comparison are not detailed, making it vague and not fully actionable.", "grounding_specificity_rationale": "The reviewer mentions 'computation cost' and 'running time' as aspects for comparison. While these are specific metrics, the review does not explicitly identify a specific part of the paper or section where this comparison should be made. The grounding is present in the *what* (computation cost/runtime), but the *where* is not clearly defined.", "verifiability_rationale": "The reviewer makes a suggestion about comparing computation cost and running time. This can be considered a claim or suggestion. However, the review does not provide specific examples, references, or logical reasoning to support this suggestion, making it not 5.", "helpfulness_rationale": "The reviewer's suggestion to compare computation cost and running time is relevant to understanding the efficiency of the method. It points towards a concrete direction for improvement and provides a valuable insight for the authors. While it lacks specifics, it is a meaningful suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states the observation about tables being divided into three types and asks a question about this. While the observation is clear, the action of investigating and potentially changing the division is not explicitly stated or concrete.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 3 (line 247252)' and asks a question about the division of tables, indicating a precise identification of the part of the paper being addressed. The specificity is in questioning a particular detail (three types) within that section.", "verifiability_rationale": "The review point is a question and does not contain a claim that requires verification.", "helpfulness_rationale": "The review point raises a question about a potential inconsistency or area for clarification. While it doesn't directly criticize or suggest an improvement, it points to a potential point of confusion that could be helpful for the authors to understand the paper better. However, it lacks a clear direction on how to address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses an opinion about the nature of the task, stating 'To me, the task looks closer to Argument Mining rather than Summarization.' While this suggests a potential area for discussion, it does not explicitly state an action or provide a concrete direction for improvement. The reviewer is expressing a perspective rather than a direct instruction on how to proceed. Therefore, it is not 5 as it lacks a clear next step for the authors.", "grounding_specificity_rationale": "The review point is a general statement about the task's nature and does not specify which part of the paper it is referring to. The reviewer is making a broad comment about the task being closer to Argument Mining or Summarization, without pinpointing a specific section, table, figure, or element in the paper. Therefore, the grounding is weak as the authors cannot confidently determine the referenced part.", "verifiability_rationale": "The review point is a subjective opinion and does not contain a claim that can be verified. The statement 'To me, the task looks closer to Argument Mining rather than Summarization' is a perspective, not a statement that requires evidence or justification. Therefore, it is not verifiable as it lacks a claim to be supported or unsupported.", "helpfulness_rationale": "The review point is a subjective opinion and does not provide specific feedback or suggestions for improvement. The reviewer is stating their opinion about the task's nature but does not offer concrete advice on how the authors should approach it. Therefore, it is not 5 as it lacks actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly asks for clarification on the definition of the sparsity of the residual term. While this is a request for information, it can be interpreted as an action the authors should take to better understand the paper's core concepts. The request for evidence and comparison, though more detailed, also points towards actions the authors need to take to validate the assumptions and understand the method's advantages. However, the request is somewhat general and lacks specific details on how the authors should seek clarification.", "grounding_specificity_rationale": "The reviewer refers to the 'residual term' in the paper, which grounds the issue to a specific part of the paper. However, the request for 'evidence' and 'comparison' is somewhat general and doesn't pinpoint a specific section, table, or figure within the paper. The authors need to *refer* to these specific parts when providing the requested information.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity regarding the sparsity definition and asks for evidence and comparisons. This requires justification and support. However, the evidence and comparison themselves are not provided within the review point. The reviewer is *asking* for this evidence, not *providing* it.", "helpfulness_rationale": "The reviewer is asking questions that are likely to be helpful for the authors in understanding the paper better. However, the tone is somewhat directive ('Could you please clarify...') rather than a constructive question that would actively engage the authors in the review process. The questions are relevant and address key aspects of the method and assumptions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the models and datasets used are 'toylike' and provides specific examples of what they consider more realistic benchmarks: CIFAR100, ResNet 34 or 50, and ViTtiny or small. This is an explicit statement of the issue and a clear suggestion for improvement. The reviewer also raises a question about the challenges of extending this to language tasks, which is a direct suggestion for improvement in that specific area.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'models' and 'datasets' used in the paper, which are the specific parts of the paper being addressed. While they don't point to a specific section, the technical terms strongly imply they are referring to the experimental setup. The reviewer also specifies what they consider to be better alternatives (CIFAR100, ResNet 34/50, ViT tiny/small), which clearly details what is wrong or missing in the referenced part.", "verifiability_rationale": "The reviewer makes a claim that the models and datasets are 'toylike' and suggests improvements. The reviewer provides reasoning for why they believe the current setup is lacking and offers specific examples of better alternatives. While the reviewer doesn't cite external references, the suggestions are based on common knowledge in the field regarding the complexity and performance of different models/datasets. The reviewer's suggestions are logically reasoned and provide clear examples of what should be used instead.", "helpfulness_rationale": "The reviewer clearly identifies a significant limitation of the paper's experimental setup (the 'toylike' models and datasets). They provide concrete suggestions for improvement, such as using CIFAR100, ResNet 34/50, and ViT tiny/small. The reviewer also raises a question about the challenges of extending this to language tasks, which shows a proactive attitude and further engagement with the paper. These points directly address the identified problem and offer clear directions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the absence of comparison against baselines as a weakness. This is an explicit action, as the reviewer directly points out what is missing. Furthermore, the reviewer suggests comparing against baselines as a concrete action to improve the paper.", "grounding_specificity_rationale": "The reviewer explicitly identifies the area of the paper where the issue lies: 'no comparison against baselines.' This is a clear grounding of the comment to a specific part of the paper. Furthermore, the reviewer clearly specifies what is missing: 'baselines'. This is a fully specific reference to the missing elements.", "verifiability_rationale": "The reviewer provides context by stating that 'this is a widelyunderstood binary analysis application and many papers have developed architectureagnostic similarity comparison (or often reported as codesearch, which is a similar task).' This provides a basis for understanding the importance and relevance of the missing comparison. While it doesn't provide a novel method, it justifies the need for such a comparison.", "helpfulness_rationale": "The reviewer's point about the lack of comparison against baselines is highly relevant for researchers in the field of binary analysis and code similarity. It directly addresses a common challenge in evaluating novel techniques and provides valuable guidance for improving the paper's contribution and impact."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point does not explicitly identify any specific weaknesses or actions to take. It is a general statement about the contribution being insufficient.", "grounding_specificity_rationale": "The reviewer mentions the 'overfitting problem of training GAN with limited data' and 'proposed the differentiable augmentation'. This indicates some grounding, but it is not fully specific. The reviewer does not pinpoint the exact section or table where the issue lies, nor does it clearly specify what needs to be addressed in this part.", "verifiability_rationale": "The statement 'The contribution is not enough' is a subjective opinion without any supporting evidence or justification. There is X being made, let alone one that is verifiable.", "helpfulness_rationale": "The review point is a negative statement about the contribution being 'not enough' without offering any specific suggestions or actionable feedback. It does not provide any helpful information for the authors to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the issue with the proof technique in Appendix A and connects it to a previously mentioned problem (normalization and Theorem 1). This provides a clear action for the authors to investigate the proof. While the action is not directly stated as 'improve the proof,' the identification of a potential flaw is a concrete step. The reviewer points to a specific scenario (contradiction with matrix norms approaching infinity) and links it to a concrete problem (inapplicability of Theorem 1 due to normalization).", "grounding_specificity_rationale": "The reviewer explicitly refers to 'Appendix A' and 'Section 3' to locate the relevant parts of the paper. This demonstrates strong grounding as the sections are directly mentioned. The reviewer also specifies the *type* of contradiction ('a special case where a contradiction arises as matrix norms approach infinity') and the *specific* issue ('the results from Theorem 1 inapplicable' due to normalization). This specificity allows the authors to understand exactly what needs to be considered.", "verifiability_rationale": "The reviewer makes a claim about the proof technique in Appendix A, specifically mentioning a potential issue with a contradiction arising as matrix norms approach infinity. This is a clear statement that requires justification. The reviewer then provides evidence by stating that this is 'acknowledged by the authors in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable.' This provides a logical reasoning and a specific reference to a location in the paper where the authors themselves have acknowledged this issue. The claim is fully supported by explicit references and logical connections.", "helpfulness_rationale": "The reviewer's comment directly points to a potential flaw in the proof technique and highlights a constraint mentioned by the authors (normalization and Theorem 1). This provides the authors with a clear area to investigate and potentially address. While the review doesn't propose a solution, it identifies a specific issue that needs attention, making it helpful in guiding the authors' work. The reviewer's statement is a clear observation that requires further investigation, and the provided context helps the authors understand the specific problem."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states a concrete action: \"replace 't' with the size of T\". This suggests a direct, actionable change to the code or implementation. The reviewer is proposing a specific textual modification, which is a clear and actionable suggestion.", "grounding_specificity_rationale": "The review point explicitly refers to \"histogram intersection kernel\" and suggests a change related to it: \"replace 't' with the size of T\". This clearly identifies the specific part of the paper being addressed and provides a concrete suggestion for improvement within that area. The comment is literal and points directly to the relevant section and variable.", "verifiability_rationale": "The review point makes a claim in the form of a suggestion: \"replace 't' with the size of T\" for clarity. While the reviewer hypothesizes that 't' can be arbitrary, the claim itself is the suggestion for improvement. This claim is based on a perceived lack of clarity but lacks explicit external references or logical reasoning to definitively prove the issue. The suggestion is based on an assumption, not a verified claim.", "helpfulness_rationale": "The review point is 5 as it directly addresses a specific part of the paper, \"histogram intersection kernel\", and provides a clear, actionable suggestion: \"replace 't' with the size of T\" for improved clarity. The suggestion is specific and directly related to the identified area, making it a valuable piece of feedback for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking a question about the difference between two types of Gaussian distributions and whether it's possible to use the general one. While the reviewer isn't directly telling the authors what to do, the question points to a potential area for improvement in the paper's clarity regarding the algorithm's implementation. The request is specific to the technical details of the algorithm, making it 3 in terms of identifying a potential ambiguity.", "grounding_specificity_rationale": "The reviewer is asking a question about a specific methodological choice (Gaussian distribution) within the algorithm. However, the paper section where this choice is made is not explicitly mentioned in the review point. The specificity of the question is high regarding the type of Gaussian distribution, but the grounding is implied rather than explicitly stated in the review point.", "verifiability_rationale": "The review point is a question, not a statement containing a claim. Therefore, it doesn't fall under the verifiability aspect.", "helpfulness_rationale": "The reviewer's question is relevant to understanding the algorithm's implementation. By clarifying the choice of Gaussian distribution, the authors could better understand and potentially implement the proposed method. While the review point isn't directly instructing the authors, it points to a potential area for improvement in the paper's clarity, making it 3 in that context."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The reviewer is asking a question, which is not a direct instruction or directive for the authors to take a specific action. While the question implies a desire for clarification, it doesn't explicitly state what the authors should do or what needs to be changed. The action is inferred rather than stated.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'Section 5.2' in their question. This indicates a clear identification of the specific part of the paper being addressed. The grounding is literal and precise.", "verifiability_rationale": "The reviewer is posing a question about the intent of a section. This is not a claim that requires verification. There is no assertion of what the section is intended to do or what is missing. It's a request for information, not a statement that needs to be proven.", "helpfulness_rationale": "The reviewer is asking a question about the intent of a section. While this can be helpful for the authors to understand the context and improve their work, it is not a direct critique or suggestion. The helpfulness is moderate as it encourages understanding rather than directly addressing a flaw."}
{"actionability_label": "3 (3)", "grounding_specificity_label": "2 (3)", "verifiability_label": "1 (1)", "helpfulness_label": "3 (3)", "actionability_rationale": "The reviewer identifies a weakness in the proposed approach (reliance on traditional FEM components) and suggests an alternative (operator learning). While this points to a potential area for improvement, the criticism is somewhat general and doesn't pinpoint a specific, actionable step to take *now* within the current approach. The reviewer suggests operator learning *could* replace these steps, but doesn't explicitly state that these specific FEM components *are* a weakness of the current method. Therefore, while the reviewer points out a deficiency, the suggestion of an alternative is more of a suggestion than a direct action.", "grounding_specificity_rationale": "The reviewer mentions 'traditional FEM components' and 'operator learning methods' as areas for improvement. While they categorize these broad areas, they don't explicitly identify a *specific* component of FEM (e.g., a particular type of basis function or mesh) or a *specific* aspect of operator learning that is lacking. The reviewer also doesn't provide a concrete example of a deficiency. The mention of 'traditional FEM components' is general and doesn't pinpoint a specific section, table, figure, or unique element of the paper. The reviewer's comment is more about the *type* of approach rather than a specific location within the current method.", "verifiability_rationale": "The reviewer makes a claim about the proposed approach 'still requiring carefully choosing basis functions and meshes and assembling stiffness matrices'. This is a claim that *could* be verified by examining the details of the proposed method. However, the reviewer does not provide any evidence or justification to support this claim. They also point out that 'operator learning methods can not yet achieve the same accuracies as specialized numerical solvers', which is a valid observation, but it's a general statement about the current state of operator learning, not a specific claim about the *proposed* approach. Therefore, the reviewer's claim is not fully supported by evidence or justification.", "helpfulness_rationale": "The reviewer offers an alternative approach (operator learning) and highlights its potential advantages (universality, adaptability) compared to the current approach. This suggests the review *could* be helpful by pointing towards a potential improvement. However, the reviewer doesn't directly critique the *current* approach based on the identified weakness. They are more of a suggestion for a different approach rather than a direct critique of the current one. The reviewer's point is relevant to improving the field, but it's more of a suggestion than a direct critique of the current draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer identifies a lack of clarity regarding the type of cloze queries the paper targets (singletoken vs. multitoken). While the reviewer understands the ambiguity, the paper likely uses both. The reviewer's suggestion to clarify this in the conclusion is a direct, actionable point for improvement. The action is to explicitly state the query type the paper focuses on, and the information needed to implement this action is the specific focus of the paper.", "grounding_specificity_rationale": "The reviewer identifies a lack of clarity regarding the type of cloze queries the paper targets (singletoken vs. multitoken). This is a specific issue within the paper. The reviewer does not explicitly state which type of query the paper focuses on within the review point itself. The grounding is weak because the authors cannot confidently determine the specific area of concern the reviewer is highlighting. However, the specificity is high because the reviewer clearly specifies the ambiguity as being between singletoken and multitoken queries.", "verifiability_rationale": "The comment states a factual observation about the lack of clarity regarding the type of cloze queries the paper targets. It does not contain a claim that requires verification. The information provided is a statement of fact, lacking any logical reasoning, common knowledge, or external references.", "helpfulness_rationale": "The reviewer points out a potential source of confusion for readers. By clarifying the type of cloze queries the paper targets, readers can better understand the paper's focus and the context of the experiments. While the information is helpful in identifying a potential area of confusion, it is presented as a lack of clarity rather than a direct, actionable suggestion. The authors need to infer the specific issue the reviewer is highlighting."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "None", "actionability_rationale": "The comment asks a question about code availability but doesn't provide a specific action or suggestion if the code is not publicly available. It lacks a clear direction for improvement.", "grounding_specificity_rationale": "The comment asks about the availability of code but does not specify which part of the paper this refers to, making it 1.", "verifiability_rationale": "The comment is a question, not a claim that needs to be supported with evidence.", "helpfulness_rationale": "The comment is a question about code availability and does not provide specific guidance or suggestions on how this relates to improving the paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The statement explicitly identifies the similarity between $kNNECD$ and $kNNMT$ and directly links it to a limitation in the paper's technical contribution. This is a clear indication of an actionable suggestion for the authors to consider further investigation or a clearer articulation of their novelty.", "grounding_specificity_rationale": "The reviewer mentions specific method names ($kNNECD$ and $kNNMT$), which suggests an attempt to ground the comment to the related work. However, the comment itself does not pinpoint a specific part of the submitted paper that is being criticized or improved. The focus is on the *idea* of similarity rather than a specific section or element within the submitted work.", "verifiability_rationale": "The reviewer makes a claim that the technical contribution is limited due to the similarity to another method. This claim is supported by the observation of similarity. The reasoning is logical and directly connects the identified similarity to the claimed limitation. Therefore, the claim is verifiable.", "helpfulness_rationale": "The comment is 5 as it directly points out a potential weakness in the paper's technical contribution and provides a clear suggestion for the authors to investigate further or clarify their novelty. This actionable feedback is valuable for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that they were 'not clear' on the numbers of parameters. This indicates an explicit action that needs to be taken \u2013 to clarify the parameter counts. However, the action itself is vague, as the reviewer doesn't specify *which* parameters or *how* they are used. Therefore, while the action is explicit, it is vague on how to execute it.", "grounding_specificity_rationale": "The reviewer mentions 'parameters used in each approach' and refers to section B.3. This demonstrates a degree of grounding, as they can identify the section where the information might be located. However, they do not specify *what* information within that section is missing or unclear. The grounding is weak because they cannot confidently pinpoint the exact referenced part and its specific issue.", "verifiability_rationale": "The review point is a statement of lack of clarity ('I wasn\u2019t clear on the numbers of parameters used in each approach'). It does not contain a claim that can be verified. It's a statement of what the reviewer *wasn't* able to find, not a critique or suggestion about the paper's content.", "helpfulness_rationale": "The reviewer points out a lack of clarity in the paper. While this can be helpful for the author to improve their writing, it is not a constructive critique or suggestion. The reviewer does not provide any specific feedback or actionable steps for improvement. Therefore, it is not 5 in terms of providing direct feedback for changes."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point criticizes the statistical significance of the evaluation results but does not provide explicit or concrete actions for the authors to take. It focuses on the methodology and interpretation rather than suggesting specific changes to the paper itself. Therefore, it lacks actionable feedback.", "grounding_specificity_rationale": "The review point mentions 'the evaluation results reported in table 1' and the number of trials. While it identifies a part of the paper being criticized, it doesn't specify *which* column or row in the table or *exactly* what the issue is with the trials. This makes it somewhat vague in its grounding. It could be considered '2' as it doesn't clearly identify the issue within the table, but it does point to a section of the paper being evaluated.", "verifiability_rationale": "The reviewer *claims* that the results are not statistically significant based on the small sample size. This is a claim that *could* be supported by examining the table and the statistical methods used. However, the claim is about the *review process* and interpretation, not a direct critique of the paper's content. The reviewer is making a statement that could be verified, but it's not a direct critique of the paper's content or methodology. Therefore, it's 2 as the claim is about the interpretation of the results, which could be supported.", "helpfulness_rationale": "The review point is a critique of the statistical analysis and the interpretation of the results. It does not provide any actionable feedback or suggestions for improvement to the authors. It's a statement about the limitations of the evaluation, not a suggestion on how to make the evaluation better. Therefore, it is not helpful for the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the problem ('it sounds unreasonable...') and suggests a solution ('provides detailed...'). This indicates an attempt to identify a missing element and propose a concrete action. However, the exact scope of the problem isn't immediately clear, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer mentions 'increasing model size can hurt the performance' and 'model size should be provided in detail.' While the general idea is grounded in the observed discrepancy, the specific experiments (Wikipedia) are not explicitly mentioned, making the grounding somewhat weak. However, the reviewer is very specific about the *nature* of the suggested improvement ('provides detailed').", "verifiability_rationale": "The reviewer infers a contradiction between their experiments and the general scaling law. While they state their observation ('it sounds unreasonable...'), they don't explicitly claim that this observation is incorrect or require verification. The inference is implied but not stated as a claim needing justification.", "helpfulness_rationale": "The reviewer directly addresses a potential issue ('increasing model size can hurt the performance') and suggests a concrete solution ('provides detailed...'). This is a clear attempt to help the authors improve their draft by providing more information about a specific experimental result. The suggestion is actionable and directly addresses the identified problem."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states their interest in knowing if other multilingual pretraining setups struggle with Greek, indicating an awareness of a potential issue. However, they do not provide a concrete action or suggestion on how to investigate this further. The action is implied but not explicitly stated.", "grounding_specificity_rationale": "The reviewer mentions 'multilingual pretraining setups' and then specifically 'other multilingual pretraining setups also struggle with Greek'. This demonstrates a clear identification of the type of pretraining setup and the language involved, showing strong grounding. However, the reviewer does not specify what aspect of Greek is struggling or point to a specific part of their own work where this issue might be present, making the specificity limited.", "verifiability_rationale": "The reviewer presents a statement about multilingual pretraining setups struggling with Greek. While this can be considered a claim, it lacks supporting evidence or justification. There are no logical reasoning, common knowledge, or external references provided to back up this claim.", "helpfulness_rationale": "The reviewer raises a valid point about the potential struggles of multilingual pretraining with Greek. However, they do not offer any concrete suggestions or guidance on how to address this issue. The feedback is identified as a potential problem but lacks actionable steps for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the limitation of considering only one truck and one drone and poses a question about extending this to multiple units. While the reviewer doesn't provide specific details on the difficulty of this extension, the action of identifying the limitation and suggesting a potential improvement makes it actionable. The reviewer clearly indicates what needs to be addressed (the single truck and drone) and what the desired outcome is (extending to multiple).", "grounding_specificity_rationale": "The reviewer explicitly mentions 'ONE truck' and 'ONE drone' in the review point. This provides a clear and precise identification of the specific aspect being discussed. The reviewer also suggests extending this to 'multiple trucks and drones', further specifying the desired scope. This strong identification of the specific units and the proposed extension demonstrates high grounding specificity.", "verifiability_rationale": "The reviewer states a fact: 'It only consider ONE truck and ONE drone'. This is a verifiable statement. The suggestion to 'Would it be easy to extend to multiple trucks and drones?' is a logical inference based on the stated limitation. However, the reviewer also adds a subjective judgment: 'This seems to be a more interesting and practical setting'. This subjective element makes the claim partially verifiable, as it's based on opinion rather than strict fact. The core limitation is verifiable, but the overall assessment of interestingness and practicality is not.", "helpfulness_rationale": "The reviewer points out a clear limitation in the scope of the work (focusing on a single truck and drone) and suggests a relevant and potentially valuable extension (multiple trucks and drones). This is a constructive and actionable suggestion that directly addresses a potential area for improvement. The reviewer's framing of the extended scenario as 'more interesting and practical' highlights the potential impact of this suggestion."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests a change to be made to the code (remove the subtraction) and provides a detailed explanation of why this might be beneficial. The reviewer states 'In addition, in Equation 8, if s contains dynamic factors, subtracting s from the dynamic information may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This suggests that the subtraction should be removed to ensure all relevant dynamic information is preserved and utilized effectively by the LSTM.', which clearly indicates an explicit action to be taken.", "grounding_specificity_rationale": "The review point refers to 'Equation 8' and 'the dynamic information' within that equation. The reviewer uses the specific term 'dynamic information' to pinpoint the area of concern. The statement 'if s contains dynamic factors, subtracting s from the dynamic information may result in the loss of some dynamic information' directly identifies a specific part of the mathematical formulation. The reviewer does not explicitly state the section, table, figure, or unique aspect of the paper being addressed beyond 'the paper containing Equation 8'. However, the focus on a specific mathematical element within an equation demonstrates a clear understanding of the relevant part of the paper.", "verifiability_rationale": "The review point contains a claim: 'In addition, in Equation 8, if s contains dynamic factors, subtracting s from the dynamic information may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes.' The reviewer provides a logical reasoning for this claim by explaining that subtracting 's' might lead to information loss and hinder the LSTM's ability to capture 'complete dynamic changes'. While the reviewer does not provide specific examples or citations to external works, the reasoning is based on an understanding of the potential impact of the subtraction on the information flow within the LSTM. The claim is supported by a logical argument, making it 3.", "helpfulness_rationale": "The review point is 5 because it directly addresses a potential issue in the authors' code implementation. The reviewer provides a clear and actionable suggestion: 'remove the subtraction'. The reviewer also explains *why* this might be beneficial, linking it to the potential loss of dynamic information and the difficulty for the LSTM to capture complete dynamic changes. This provides the authors with a concrete direction to improve their implementation and understand the potential limitations of their current approach. The suggestion is specific and directly addresses a potential flaw in the code."}
{"actionability_label": "3", "grounding_specificity_label": "3: 4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point is a question, not a direct instruction. While it implies a desire for information, it doesn't explicitly state what the reviewer wants the authors to do with this information. The reviewer is asking about the relationship between MC samples, performance, and network structure, but doesn't specify how this information should be used or what actions the authors should take based on it.", "grounding_specificity_rationale": "The review point is a general question about the relationship between MC samples, performance, and network structure. It does not specify which part of the paper or model this refers to. The reviewer is asking about a broad topic without pinpointing a specific section, table, figure, or unique aspect of the work. The question is vague and lacks a clear reference point within the paper.", "verifiability_rationale": "The review point itself is not a claim that requires verification. It's a request for information or an investigation into a relationship. However, if we were to interpret the request as a claim, it would lack specific examples or references. The reviewer is asking 'how does the number of MC samples affect performance, empirically?' and 'how does the network structure affect this?' These are questions, not explicit claims that can be verified with logical reasoning, common knowledge, or external references within the review point itself.", "helpfulness_rationale": "The review point identifies a gap in the reader's knowledge regarding the empirical relationship between the number of Monte Carlo (MC) samples, performance, and network structure. While the reviewer doesn't explicitly state what information they need, the question itself is a valid point of inquiry. It encourages the authors to provide more detailed information about their experimental setup and the impact of different network architectures on their results. This could be helpful for other researchers trying to understand or replicate their work. However, the request is quite broad and lacks specific details, making it difficult to pinpoint exactly what information would be most helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a problem ('inconsistent notation'), which is a direct indication of an actionable issue. However, it does not specify *how* the notation is inconsistent or *where* in Section 2 this problem occurs. The action is identified, but the details are missing.", "grounding_specificity_rationale": "The comment refers to 'Section 2', which is a specific part of the paper. This indicates that the authors can identify the section being addressed. However, the comment does not specify *what* the inconsistent notation is or *how* it is inconsistent. The grounding is present, but the specificity is lacking.", "verifiability_rationale": "The comment identifies a potential issue ('inconsistent notation') that could impact the clarity and correctness of the paper. However, it does not provide any specific evidence or reasoning to support why this inconsistency is a problem. The claim is present, but the verification is minimal or nonexistent.", "helpfulness_rationale": "The comment points out a potential area for improvement ('inconsistent notation'). While identifying a problem is helpful, it does not provide specific guidance on how to address it or what changes are needed. The feedback is present, but the actionable steps are not detailed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer states \"the part of metric learning does not seem to work.\" This is an explicit statement about a lack of effectiveness. However, the reviewer does not specify *what* does not work, making it somewhat vague.", "grounding_specificity_rationale": "The reviewer refers to \"the metric learning theory in this paper basically comes from the generalization theory of neural networks Bartlett et al. (2017)\". This grounds the comment to a specific part of the paper. However, the reviewer also states \"Compared with the previous theoretical results, the metric perspective analysis proposed in this paper does not give better results\". While the grounding is present, the specific details about *which* previous results and *how* the metric perspective doesn't work are not explicitly identified, making it somewhat underspecific.", "verifiability_rationale": "The reviewer makes a claim: \"the paper's part of metric learning does not seem to work.\" This is a claim that needs verification. However, the reviewer does not provide any specific evidence or reasoning within this review point to support the claim that the metric perspective analysis does not give better results. The reasoning and common knowledge are missing.", "helpfulness_rationale": "The reviewer states that the metric learning theory \"basically comes from the generalization theory of neural networks Bartlett et al. (2017)\" and that \"Compared with the previous theoretical results, the metric perspective analysis proposed in this paper does not give better results.\" While this points to a potential weakness, the reviewer does not offer any specific suggestions or improvements based on this feedback. The feedback is primarily a critique of the existing content without proposing actionable steps."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The reviewer states that using 'r' to denote different risk types is confusing. While this points to a potential area for improvement, the reviewer does not explicitly state what the authors should do about it. The suggestion is implicit, making it only partially actionable. The authors would need to infer that they should clarify the notation or potentially introduce a more distinct notation to avoid confusion.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'r', 'risk for minimization problems', and 'primal risk for minimax problem'. This clearly identifies the specific part of the paper being addressed, demonstrating strong grounding. The reviewer is also stating what is wrong (something is confusing), making it specific.", "verifiability_rationale": "The reviewer makes a claim ('is confusing') about a specific aspect of the paper (the notation 'r'). This claim can be verified by examining the paper and seeing if the notation is indeed ambiguous or poorly explained. Therefore, the claim is verifiable.", "helpfulness_rationale": "The reviewer points out a potential issue ('is confusing') but does not offer a solution or guidance on how the authors should address it. While identifying a problem is valuable, a 5 comment would also suggest a way forward. The lack of a clear direction makes it less helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3: Somewhat Grounded and Specific", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their confusion about the desirability of sparsity, indicating an implicit need for clarification. While they don't directly state 'I don't know what to do,' the phrasing suggests a lack of understanding of why sparsity is being considered. The action they would take is to seek clarification on the desirability of sparsity, making the action somewhat implicit.", "grounding_specificity_rationale": "The reviewer's comment is 1 at all in a specific part of the paper. They are commenting on the *concept* of sparsity in general, not referencing a particular section, table, or figure. However, the comment clearly specifies the ambiguity surrounding the *desirability* of sparsity, making it somewhat specific to this concept.", "verifiability_rationale": "The reviewer makes a claim about the lack of clarity regarding the desirability of sparsity. However, this claim is not wellsupported. The reviewer is raising a question about the *motivation* for sparsity, which is a fundamental assumption in the paper. There is no external reference or logical reasoning provided to *disprove* the reviewer's point. The claim is presented without sufficient justification or evidence.", "helpfulness_rationale": "The reviewer's comment is primarily critical, questioning the *necessity* of sparsity. While they are asking for clarification, the tone is questioning the *justification* of a key concept. The helpfulness is limited because the reviewer is not providing a clear, actionable suggestion, but rather highlighting a potential weakness in the paper's presentation. The feedback is more of a question than a constructive improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "None", "actionability_rationale": "The reviewer explicitly asks for evidence regarding the meaningfulness of the geometry of the space, which is an explicit action. However, the action is not concrete as it doesn't specify which part of the analysis or what specific evidence is needed. The reviewer is asking a general question about the space, making the action somewhat vague.", "grounding_specificity_rationale": "The reviewer's question is about the general meaningfulness of the geometry of the space and does not explicitly point to a specific part of their paper or analysis where this question arises. Therefore, the grounding is weak as the authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The reviewer makes a claim by asking 'Do you have any evidence that the geometry of the space you end with is meaningful?' and provides a suggestion for how the authors could investigate it ('It would be nice to have some analysis that suggests the morphfitting results in a more meaningful space, not just better embeddings'). This provides a method for the authors to check the claim, making it 3. However, the reviewer does not provide the actual evidence within their review point itself.", "helpfulness_rationale": "The reviewer's comment is relevant to the authors as it points out a potential area for improvement in their geometry analysis. They provide a suggestion for investigation, which is helpful. However, the comment is quite broad and doesn't pinpoint a specific issue or provide concrete guidance, making it 3 but not highly so."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests looking at accuracy or specific properties if FLOPs and inference time are not improved. While they don't explicitly state that the current approach is flawed, they offer a clear alternative direction. The suggestion is direct and implies that focusing on accuracy could be beneficial. However, it doesn't specify *how* to improve accuracy or identify a specific problem with the current approach, making it somewhat vague on the action execution side.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'accuracy' and provides a specific example of 'specific properties' in the context of 'recurrent models and sequential relationships'. This clearly identifies the specific aspect of the paper being addressed, making it fully grounded.", "verifiability_rationale": "The reviewer doesn't make a claim that the current approach (FLOPs and inference time) is incorrect or lacking. Instead, they offer an alternative path. While they imply that improving these metrics might be desirable, they don't provide specific reasons *why* they are unhelpful in this context. Therefore, the claim is underspecified, making it 1.", "helpfulness_rationale": "The reviewer provides a clear direction for the authors: explore accuracy metrics and consider the context of recurrent models and sequential relationships. They explicitly suggest 'looking at' these areas, which is a direct and actionable suggestion. While they don't diagnose *why* FLOPs and inference time were unhelpful, they offer a concrete alternative, making it 5 in guiding the authors towards exploring other aspects of their work."}
{"actionability_label": "Explicitly Vague", "grounding_specificity_label": "1 and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "4 and UnderSpecific", "actionability_rationale": "The reviewer explicitly states that the 'scoring function' and its components (components of the function and threshold values/ranges) are unclear. While the reviewer identifies the *what* (unclear scoring function), they don't explicitly state *why* it's unclear or what specific parts of the scoring function are unclear. This suggests a lack of explicitness in the explanation of the scoring process. The lack of clarity makes it difficult to understand how the scoring is intended to work, which is a key aspect of actionability.", "grounding_specificity_rationale": "The reviewer's comment does not explicitly identify a specific part of the paper being addressed in relation to the 'scoring function'. The criticism is directed at the *process* of scoring itself, rather than pinpointing a specific section or issue within the paper. Therefore, the comment lacks grounding specificity as it doesn't clearly identify the area of the paper being discussed.", "verifiability_rationale": "The reviewer's comment criticizes the 'scoring function' and its thresholds without providing any specific examples or justifications. There is X being made about the paper itself, nor is there any logical reasoning or external references provided. The comment is a statement of criticism about the methodology used to evaluate the paper. Therefore, according to the provided definition of verifiability, this comment does not contain a claim and is not verifiable.", "helpfulness_rationale": "The reviewer's comment is critical of the 'scoring function' and its lack of clarity. This directly impacts the helpfulness of the review point to the authors. Without understanding how the scoring function works and what thresholds are used, the authors cannot effectively use this feedback to improve their draft. The lack of clarity makes the review point less actionable and less useful, reducing its helpfulness. While the comment itself is not a direct suggestion for improvement, it's a critique of the mechanism through which such suggestions would be made, making it somewhat indirectly unhelpful."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the limitations of the dataset selection and the lack of onehot encoding for a specific dataset. The actions suggested are directly derived from these limitations. The reviewer recommends adding categorical features and using onehot encoding, which are direct and actionable steps based on the identified issues. The language is clear and directly points to the areas needing improvement.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific datasets that lack categorical features and the specific dataset that lacks onehot encoding. The language is precise and directly points to these aspects of the paper. The reviewer's comments are grounded in the specific parts of the paper being discussed.", "verifiability_rationale": "The reviewer makes a claim about the inadequacy of the dataset selection and the omission of onehot encoding. The reviewer provides logical reasoning to support these claims, such as stating that categorical features are generally more challenging and that onehot encoding is a common practice. While the reviewer does not provide external references, the reasoning is based on common knowledge and logical deduction, making the claim verifiable. The language is clear and the reasons are wellarticulated.", "helpfulness_rationale": "The review point identifies specific weaknesses in the dataset selection and encoding methods used in the paper. The reviewer provides concrete suggestions for improvement, such as adding categorical features and using onehot encoding. These suggestions are directly actionable and address the identified limitations. The language is clear and the recommendations are specific and wellfocused, making the review point 5 for the authors to improve their work."}
{"actionability_label": "4", "grounding_specificity_label": "4: 5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states the issues with the dataset choices and suggests improvements. The suggestions are direct and actionable, indicating a clear understanding of how the authors can address the identified weaknesses. The reviewer points out the lack of followup for the chosen datasets and proposes alternative, more common options, which are concrete steps for the authors to consider.", "grounding_specificity_rationale": "The reviewer explicitly mentions the 'FlatCam Face' and 'Headpose detection' datasets, accurately pinpointing the specific parts of the paper being addressed. The suggestions for alternative datasets are also specific, indicating a clear understanding of the issues with the current choices.", "verifiability_rationale": "The reviewer's opinion on the popularity of the datasets is based on common knowledge within the field. While they don't provide external references, the reasoning is logical and understandable. The reviewer's suggestions are also logical and based on common practices in the field.", "helpfulness_rationale": "The reviewer provides a clear critique of the dataset choices and offers specific, actionable suggestions for improvement. The reviewer points out the limitations of the chosen datasets and proposes wellestablished alternatives, directly helping the authors to consider more relevant benchmarks. The suggestions are concrete and directly address the identified weaknesses."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the regret bound for the minibatch method is in the appendix and then attempts to verify this claim by searching the supplementary material. This action is clear and directly addresses a specific aspect of the paper. Once the reviewer identifies the potential location (appendix), they also attempt to find the specific result (regret bound) within that location, making the action concrete.", "grounding_specificity_rationale": "The reviewer explicitly asks for the location of the regret bound within the supplementary material. They mention 'appendix' as a potential location and then ask for the specific section containing the regret bound. This demonstrates a clear understanding of where the information might be located and a desire to find a specific detail within that location, indicating full grounding and specificity.", "verifiability_rationale": "The reviewer makes a claim about the location of the regret bound (in the appendix) and then attempts to verify this claim by searching the supplementary material. The attempt to find the regret bound constitutes a verification attempt. While the actual content of the supplementary material is not provided, the reviewer's *effort* to find the specific result indicates that the claim is intended to be verifiable.", "helpfulness_rationale": "The reviewer directly points out a discrepancy: the paper claims the regret bound is in the appendix, but they couldn't find it. This is a clear and actionable piece of feedback. The reviewer is directly informing the authors of a specific location issue, which is highly valuable for improving the paper's clarity and completeness. The request for the location of a specific result is directly actionable for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that 'the proposed compression performs worse than PQ', which is a direct and clear indication of a weakness. The action is to compare the performance of the proposed method with PQ. The information 'when a small code length is allowed' provides a specific context for this comparison, making the action concrete. The implication 'which is the main weakness of this method' further clarifies the significance of this performance difference, indicating a concrete area for improvement.", "grounding_specificity_rationale": "The review point refers to 'the proposed compression' and 'PQ' without explicitly naming a specific section, table, or unique element of the paper. While it implies a comparison, the authors would need to infer which specific compression method and PQ implementation are being referred to. Therefore, the grounding is **Weak**. However, the review point clearly specifies the comparison is based on 'performance' and attributes the weakness to 'a small code length', providing some level of specificity about the area being discussed. Thus, the specificity is **Partially Specific**.", "verifiability_rationale": "The review point makes a claim: 'the proposed compression performs worse than PQ'. This is a statement that requires justification. However, the subsequent part, 'when a small code length is allowed, which is the main weakness of this method, in view of a practical side', is more of an inference or a general statement rather than a direct, logically supported justification. There are no specific references, examples, or external data provided to back up the claim that the proposed compression performs worse than PQ under these conditions. The 'in view of a practical side' is a general observation, not a specific, verifiable argument. Therefore, the claim is **1**.", "helpfulness_rationale": "The review point identifies a weakness in the proposed compression method by comparing its performance to PQ under specific conditions. It highlights that the weakness is significant from a practical perspective. While it doesn't provide specific suggestions for improvement, it clearly points out a key area where the method falls short. This makes the review point **3** as it guides the authors to focus on the performance issue related to code length. However, it lacks the actionable and specific nature of a **5** comment, which would directly suggest concrete improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states their suggestion and explains the reasoning behind it. They identify the action of using summation and propose an alternative action of using the minimum. The rationale is clear and directly addresses the potential issue of masking bad policies.", "grounding_specificity_rationale": "The reviewer clearly identifies the specific aspect of the evaluation they are criticizing: the performance in the 'worst MDP'. They also explain why this is important and how the summation might obscure this. The comment is specific about the part of the evaluation being addressed and the metric being used (performance in the worst MDP).", "verifiability_rationale": "The reviewer's point is based on a logical argument about the potential downsides of summation. They argue that summation might hide the performance in a subset of MDPs while highlighting it in others, potentially masking the performance in the worst MDP. While the logic is present, it lacks specific examples or citations to support the claim about the limitations of summation. The reasoning is sound but could be strengthened with concrete examples.", "helpfulness_rationale": "The reviewer provides a clear and relevant suggestion for improving the evaluation methodology. They directly address a potential weakness in the current approach (the use of summation) and offer a specific alternative (using the minimum). This is a valuable and actionable suggestion for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for clarification on a method (extraction of proportions) rather than directly proposing an action or improvement. While they are asking about a specific aspect (proportion of documents), the request itself is about understanding a process, not directly improving it. The action of extracting proportions is not inherently actionable without further guidance on how to apply it to the authors' draft.", "grounding_specificity_rationale": "The reviewer is asking about the *methods* of extracting proportions, sentences, and documents. While they are asking about specific elements (proportions, sentences, documents), the request itself doesn't pinpoint a *specific* part of the paper being addressed. The grounding depends on the *specific* extraction techniques being discussed, which are not detailed in the review point. Therefore, the grounding is not explicitly tied to a specific element of the paper being discussed.", "verifiability_rationale": "The reviewer is asking a question about a methodology (extraction of proportions) rather than making a claim that needs verification. They are seeking information, not evaluating the validity of a statement. Therefore, there is X being made, and it does not fall under the verifiability aspect.", "helpfulness_rationale": "The reviewer is asking for information about a methodology (extraction of proportions) rather than directly proposing an improvement or actionable suggestion. While understanding the extraction process can be helpful for the authors, the request itself does not directly empower them to improve their draft. It provides information, but not a direct path to improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer states that the content at L107114 is 'speculative or overly opinionated'. While this points to a potential area for improvement, it doesn't explicitly tell the authors *what* needs to be changed. The suggestion is to 'state as a remark, or an aside in a Discussion section, or removed', which are actions, but the reviewer doesn't specify *how* to implement these actions. The lack of a concrete action makes it less actionable than a comment that directly suggests a change like 'Replace the current paragraph with a more objective analysis'.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'L107114', which grounds the comment to a specific part of the paper. However, the reviewer does not specify *what* is wrong with this section. They only state that it is 'speculative or overly opinionated'. This lack of specificity means the comment is not fully grounded in terms of detailing the issue.", "verifiability_rationale": "The reviewer makes a claim that the content at L107114 is 'speculative or overly opinionated'. This is a claim that needs to be supported. However, the reviewer does not provide any logical reasoning, common knowledge, or external references to back up this claim. The suggestions provided ('state as a remark, or an aside in a Discussion section, or removed') are recommendations, not verifiable statements about the paper itself. The lack of supporting evidence makes the claim 1.", "helpfulness_rationale": "The reviewer points out a potential issue with the clarity or objectivity of the writing in L107114. This is a clear indication of a weakness in the current draft. While the reviewer does not offer specific suggestions for improvement, identifying a lack of clarity or objectivity is a valuable piece of feedback that can help the authors improve their writing. The reviewer's statement directly highlights a problem that needs addressing."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer is asking for justification for a methodological choice, which directly implies a lack of explicit or clear action. They are not directly asking for a calculation or a stepbystep procedure, but rather why a specific method was chosen. This fits the definition of an implicit action that needs to be inferred.", "grounding_specificity_rationale": "The reviewer explicitly states 'Why use the VMF distribution and the truncated normal distribution...'. This directly identifies the specific aspect being questioned, indicating full grounding. The reviewer is asking about the specific part of the paper related to the characterization of the target vector.", "verifiability_rationale": "The reviewer states their belief that the motivation is unclear. While they are pointing to a specific area (the motivation behind the distribution choice), they are expressing a subjective assessment of its clarity. This suggests some justification is present, but it's lacking in detail or support. The reviewer is asking *why*, implying a need for more explanation or justification.", "helpfulness_rationale": "The reviewer's request for clarification on the motivation is a valuable piece of feedback for the authors. They are pointing out a gap in the explanation, which could hinder understanding and implementation. This provides some helpful insights, making the review 3."}
{"actionability_label": "3", "grounding_specificity_label": "3: 2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that the paper does not explain how the quantitative results are obtained. This directly points to an actionable piece of information that is missing. The action the reviewer is pointing out is: 'I need to find out what data and procedures were used to generate these quantitative results.' This information is crucial for understanding and potentially replicating the findings.", "grounding_specificity_rationale": "The reviewer can identify the *area* of concern (the methodology/implementation details related to quantitative results) but cannot pinpoint the exact section or table where this information might be located. This indicates weak grounding. The reviewer can infer that the paper lacks details about data usage, but cannot precisely identify where this information is missing.", "verifiability_rationale": "The reviewer makes a claim: 'it is not clear how the quantitative results are obtained'. This is a verifiable claim. The lack of detail makes it difficult to assess the verifiability. The reviewer is stating a lack of justification for a claim (the existence of quantitative results). The paper does not provide sufficient information to verify how these results were derived.", "helpfulness_rationale": "The reviewer's inability to understand how the quantitative results are obtained significantly hinders their ability to interpret and potentially build upon this work. This lack of clarity makes the information provided less helpful for the authors. The reviewer needs this information to understand the basis of the quantitative claims made in the paper."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly asks 'how does it help?' which indicates an implicit request for an explanation of the mechanism. While the reviewer doesn't provide the explanation, the request itself is a clear indication of a missing actionable piece of information. The action is 'explain how the framework helps,' but the details are lacking.", "grounding_specificity_rationale": "The reviewer mentions a specific paper (1 Luo, et al. \"Neural architecture search with gbdt.\") by name, which grounds the comment. However, the reviewer does not specify how this particular framework is relevant to the authors' work. The specificity of the connection remains vague.", "verifiability_rationale": "The reviewer makes a claim by stating 'Why this SE framework can help to improve, how does it help?' This is a declarative statement that requires justification. However, the reviewer does not provide any evidence or reasoning to support this claim.", "helpfulness_rationale": "The reviewer identifies a weakness in the authors' understanding by asking 'how does it help?'. While this is a valuable feedback point as it prompts clarification, the reviewer does not offer any suggestions or insights beyond the request itself. The helpfulness is limited because the request is not followed up with an explanation."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer states their desire for the system to generalize to more views, but does not specify how this should be achieved or what those additional views would entail. The action is implied but not explicitly stated in a way that the authors can directly apply.", "grounding_specificity_rationale": "The reviewer's comment is about the limitations of the current approach (two views) without specifying which view or aspect of the approach is problematic. The comment lacks a clear reference to a specific part of the paper or methodology.", "verifiability_rationale": "The reviewer's statement that the approach is 'limited to two views' is a claim that requires justification. However, the reviewer does not provide any logical reasoning, examples, or references to support this limitation. The claim is presented without sufficient backing.", "helpfulness_rationale": "The reviewer's comment is a suggestion for improvement (generalizing to more views) rather than a direct critique or identification of a specific problem. While the suggestion is valuable, it lacks concrete steps or evidence to guide the authors on how to implement it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the chosen metrics are not suitable for datasets without clear task boundaries. It provides a clear action for the authors: consider alternative metrics that are more appropriate for such scenarios. The suggestion is concrete, identifying specific areas where the metrics might be unsuitable (continual learning, loss after switch, recovery time after switch). This allows the authors to directly address the issue and potentially implement changes.", "grounding_specificity_rationale": "The comment does not explicitly identify a specific part of the paper or methodology that is problematic. It critiques the general approach of using these metrics in a setting without known task boundaries. While it mentions specific metrics (continual learning, loss after switch, recovery time after switch), it does not pinpoint where their inappropriateness lies within the paper's structure or content. The grounding is weak because the authors cannot confidently determine the exact area of concern. The specificity is somewhat present in the mention of the metrics, but the broader critique lacks a clear reference point within the paper.", "verifiability_rationale": "The comment makes a claim that the chosen metrics are not suitable for the given context. However, it does not provide specific examples or references to support this claim. The reasoning is general and lacks concrete evidence. While the suggestion to consider alternative metrics is present, the verifiability of *why* these metrics are unsuitable in this specific context is not strongly supported. Therefore, the claim is 3 as it is supported by general reasoning but lacks key elements like examples or references.", "helpfulness_rationale": "The review point is not 5 because it is general and lacks specific actionable feedback for the authors. While it identifies a valid concern (the unsuitability of the chosen metrics), it does not provide concrete guidance on how to implement the suggested changes. The lack of specific examples or references makes it difficult for the authors to understand the exact issues and how to address them. The suggestion to use alternative metrics is too broad and lacks direction. Therefore, the feedback is 3 but could be significantly improved by providing more specific and actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states the problem with 'ablations' and 'experiment setup', indicating a direct identification of an actionable issue. However, the specifics of what is unclear within these areas and how to improve them are not detailed, making the action somewhat vague. The reviewer suggests improvements but doesn't specify the exact steps or changes needed.", "grounding_specificity_rationale": "The reviewer refers to 'ablations' and 'experiment setup' generally, without pinpointing a specific section, table, figure, or unique element of the paper. While they express a desire for better setup, they don't detail where the current setup is lacking, making the grounding weak. The issue is broad and not specific to a particular part of the paper.", "verifiability_rationale": "The reviewer makes a claim that 'ablations seem to deserve better experiment setup' but does not provide any evidence, reasoning, or references to support this claim. The suggestion is general and lacks specific justification, making the verifiability borderline. The reviewer identifies a problem but doesn't explain why it's a problem or how it should be addressed.", "helpfulness_rationale": "The reviewer points out a potential issue with the experimental setup and suggests it needs better handling. However, the feedback is general and lacks specific details about what the ablations are, what aspects of the setup are unclear, or how to improve them. The suggestion is vague and doesn't provide concrete guidance for the authors, making it not 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the missing 'error analysis on the movie dataset' and suggests focusing on 'cases that such model fails'. These are direct statements about what needs improvement, making the action clear and actionable. The reviewer directly points out a specific area for the authors to focus their efforts.", "grounding_specificity_rationale": "The review point mentions 'error analysis on the movie dataset' and 'cases that such model fails'. While it doesn't explicitly name a specific section or table, it clearly refers to a specific dataset and a specific type of analysis within that dataset. This allows the authors to infer the relevant part of the paper where the error analysis should be conducted. Therefore, it is grounded, although not as precisely as identifying a specific table or figure.", "verifiability_rationale": "The review point contains a clear claim: 'The error analysis on the movie dataset is missing' and 'In order for other researchers to continue on this task, they need to know what are the cases that such model fails'. This claim is supported by logical reasoning, indicating the importance of error analysis for future research and the need for this information. The reviewer provides a clear justification for their point.", "helpfulness_rationale": "The review point is 5 because it directly identifies a specific and actionable weakness ('missing error analysis') and provides a clear suggestion for improvement ('know what are the cases that such model fails'). This guides the authors on what to focus on and how to address a potential bottleneck for other researchers. The feedback is specific and directly addresses a likely area of concern."}
{"actionability_label": "4", "grounding_specificity_label": "N/A", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states that there is a lack of a 'separate part or subsection' and that the 'how to use the multiple prompts in the test stage' is not clear. This directly points to a missing explicit action and a lack of detail, making it actionable.", "grounding_specificity_rationale": "While the reviewer points out a missing section, the primary issue is the lack of *explanation* of how to use the multiple prompts. The grounding specificity aspect would be relevant if the comment *mentioned* a specific section but didn't *explain* its content. Here, the focus is on the missing information itself, not its location within the paper.", "verifiability_rationale": "The comment is a statement of what is missing, not a claim that needs verification. Therefore, it fits the 'X' category.", "helpfulness_rationale": "The comment clearly identifies a missing piece of information that would be beneficial for the authors. It points to a specific, actionable suggestion (the inference strategy and prompt usage), making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The reviewer explicitly states their intention to ask a question about the results of an ablation experiment, implying they want to know *how* these results were obtained and why they are so low. This suggests a clear action: to understand the reasons behind the observed performance. The phrase 'I wonder why' indicates a desire for explanation, making the action explicit. The request for 'more explanations' further reinforces this intent.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'the ablation experiments' and names specific methods ('fCLSWGAN' and 'fVAEGAND2') being compared to their own ablation study. This clearly identifies the specific part of the paper being referenced and the specific comparison being made. The reviewer's statement about the results being 'even lower' further specifies the nature of the discrepancy being pointed out. This demonstrates a high level of grounding specificity.", "verifiability_rationale": "The reviewer states that the results of their ablation study are 'so low' and 'even lower than some simple early methods'. This is a claim that requires verification. The reviewer is suggesting a discrepancy exists that needs to be explained. While the reviewer doesn't provide the *reasons* for the low performance, the *statement* about the results being lower is a verifiable claim based on the experimental outcomes (which we don't have access to, but the claim itself is stated). Therefore, it is 3 as it points to a potential issue that can be investigated.", "helpfulness_rationale": "The reviewer's comment is primarily a question about the results of an ablation experiment. While this can be helpful for the authors to understand their model's performance, the comment itself does not directly provide actionable feedback or suggestions for improvement. The reviewer is asking for *explanations*, not *actions* to take. Therefore, while it can lead to helpful discussions, it doesn't currently offer direct guidance on how to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is not actionable because it lacks specific details on how the authors plan to address the limitations. While it suggests a 'more detailed plan,' this is vague and lacks concrete steps.", "grounding_specificity_rationale": "The review point is 1 because it does not specify which limitations or parts of the paper are being discussed. It is a general suggestion about the future work.", "verifiability_rationale": "The review point is not verifiable because it does not contain a claim that requires justification or support. It is a statement of what the authors should do.", "helpfulness_rationale": "The review point is 3 because it identifies a valid area for improvement and offers a general suggestion for the authors to focus on. It provides a direction for the authors' future work."}
{"actionability_label": "3", "grounding_specificity_label": "Weakly Grounded and Somewhat Specific", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out the existence of similar methods in the field of multitask learning. While the reviewer implies this is a weakness, the actionability lies in identifying the *existence* of similar approaches. However, the reviewer does not specify *how* these methods are similar or *what specific aspects* of multitask learning are missing. The action is explicit (identifying similar methods), but the execution is vague.", "grounding_specificity_rationale": "The reviewer mentions 'similar methods have been proposed' and 'multitask learning'. While the paper might discuss multitask learning in general, the reviewer doesn't pinpoint a *specific* section, table, figure, or unique aspect of their work that needs improvement. The grounding is through the general topic 'multitask learning', which is a weak ground. The specificity is in mentioning 'similar methods' and 'multitask learning', which are clear topics, making it somewhat specific. However, the lack of detail makes it weakly grounded and somewhat specific.", "verifiability_rationale": "The reviewer states a fact: 'Similar methods have been proposed for multitask learning and has not been disccussed in this paper'. This is a claim requiring justification. The paper does not provide any external references or specific examples to support this claim within the review point itself. The claim is stated without sufficient evidence or justification.", "helpfulness_rationale": "The reviewer points out a gap in the related work by highlighting the existence of similar methods for multitask learning that are not discussed. This is a valuable piece of feedback as it guides the authors to consider alternative approaches or clearly differentiate their work. While the feedback is specific to the topic of multitask learning, the lack of discussion of similar methods is a concrete weakness that can help the authors improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment implicitly suggests comparing the computational cost of FedMITR to other methods, but it does not explicitly state how this comparison should be done. The action is inferred but not clearly defined.", "grounding_specificity_rationale": "The comment does not specify which part of the paper it is referring to (e.g., a specific section, table, or figure). It is a general question about the computational cost of a method.", "verifiability_rationale": "The comment does not contain a claim or assertion. It is a question posed to the authors.", "helpfulness_rationale": "The comment raises a valid point about the potential lack of comparison of computational costs in the paper. It identifies a potential area for improvement and encourages the authors to clarify this aspect. However, it does not provide any specific information or guidance on how to perform this comparison."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests improvements related to using an external knowledge base but doesn't explicitly state what needs to be changed in the paper itself. The focus is on a general strategy rather than specific actionable steps on the paper's content. While it implies a potential improvement, the specific action on the paper is not clearly defined.", "grounding_specificity_rationale": "The review point is a general statement about the writing being 'too confusing' and does not identify a specific part of the paper being addressed. The reviewer is making a broad observation about the writing quality without pinpointing a particular section, table, figure, or unique element of the paper.", "verifiability_rationale": "The review point makes a claim that the writing is 'too confusing' but does not provide any evidence or reasoning to support this claim. There is no logical reasoning, common knowledge, or external references provided to back up the assertion that the writing is unclear or difficult to understand.", "helpfulness_rationale": "The review point raises a concern about the writing being confusing but does not offer specific feedback or actionable steps on the paper itself. It lacks concrete suggestions for improvement and focuses on a general issue without addressing its specific manifestation in the paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the missing theoretical elements (existence and smoothness of SDE solutions, discretization guarantees) and provides specific examples, making the action clear and concrete.", "grounding_specificity_rationale": "The reviewer mentions 'theoretical work on sampling and particlebased optimization methods' which is a general area, indicating weak grounding. However, they also identify specific theoretical aspects that seem missing, showing some level of specificity in pointing out what is lacking.", "verifiability_rationale": "The reviewer claims the analysis seems weak in light of the theoretical work but doesn't provide specific evidence or reasoning to support this claim. There's no logical reasoning, common knowledge, or external references provided to back up their assertion about the weakness.", "helpfulness_rationale": "The reviewer's point directly addresses a perceived weakness in the analysis by suggesting the authors consider established theoretical work. This provides a clear direction for improvement and is a constructive suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "Explicitly states an action (pointing out missing information) but is vague on how to execute it (identify the components and hyperparameters).", "grounding_specificity_rationale": "Authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "Comment contains a claim (statement about missing information) without any supporting evidence or justification.", "helpfulness_rationale": "Identifies a weakness or improvement area but is vague, lacks clarity, or provides minimal guidance, making it only slightly beneficial for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states 'show some qualitative results' and 'zoomedin view'. These are clear actions the authors should take. However, the suggestions are quite broad and lack specific details on *what* kind of qualitative results or *how* the zoomedin view should be generated. For example, the reviewer doesn't specify if they want visualizations of specific components, how they should be filtered, or what metrics are used for the zoomedin view. This makes the actions somewhat explicit but not fully concrete.", "grounding_specificity_rationale": "The reviewer's comment explicitly refers to 'qualitative results' and 'zoomedin view', which directly points to specific aspects of the paper's output. This indicates strong grounding as the reviewer can accurately identify the section or part of the paper being addressed. However, the comment lacks specificity regarding *what* constitutes 'qualitative results' or *how* the 'zoomedin view' should be created. While the grounding is explicit, the specificity of the suggestion is low.", "verifiability_rationale": "The reviewer makes a suggestion about *what* to show and *how* to show it ('qualitative results', 'zoomedin view'). This is a claim or suggestion. However, the review point does not provide any logical reasoning, common knowledge, or external references to support why showing qualitative results and zoomedin views would be beneficial or how they would improve the understanding of the method. There is no justification provided to back up the suggestion.", "helpfulness_rationale": "The reviewer suggests showing 'qualitative results' and 'zoomedin view' as a way to improve the understanding of the method. While this is a reasonable preference for some readers who might find visualizations helpful, it is not universally beneficial. Some readers might prefer quantitative results or different visualization styles. The helpfulness of this suggestion depends on the individual reader's preferences and the specific context of their understanding of the method. The review point lacks any analysis of the potential benefits or limitations of this suggestion for a broader audience."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states a weakness ('the paper does not evaluate the magnitude of interpretability tax associated with the method') but does not directly instruct the authors on what to do to address it. While it points to a problem, it lacks a clear action or suggestion on how to improve the paper based on this observation.", "grounding_specificity_rationale": "The comment refers to the 'paper' in general, without pinpointing a specific section, table, figure, or unique aspect of the paper. It mentions 'the interpretability tax' generally, without specifying which tax or how it should be evaluated. Therefore, it is 1 in a specific part of the paper or a specific issue within that part.", "verifiability_rationale": "The comment contains a claim ('the paper does not evaluate the magnitude of interpretability tax associated with the method') and this claim is not supported by any logical reasoning, common knowledge, or external references. It is presented as a statement of fact without justification.", "helpfulness_rationale": "The comment identifies a potential area for improvement (evaluating the interpretability tax) but does not provide any specific suggestions or guidance on how to achieve this. It points out a deficiency without offering actionable steps to address it."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states their *wish* to see training losses, which is a clear, direct action. However, the request lacks specific details about the losses or the training process, making it less concrete.", "grounding_specificity_rationale": "The reviewer mentions 'a deep localization network' and 'differentiable Sinkhorn,' showing some grounding. However, they don't specify *which* part of their network or *how* the Sinkhorn algorithm is being used. The request for 'training losses' adds some specificity, but it's not a clear indication of a specific issue within their implementation.", "verifiability_rationale": "The reviewer is *suggesting* that it might be stable and *asking* for evidence (training losses). This can be seen as a claim (a suggestion that it's stable) that requires evidence. However, the reviewer doesn't provide any *justification* for their belief that it might be stable. The request for training losses is the evidence they are asking for, but it's not a logical deduction from their initial statement.", "helpfulness_rationale": "The reviewer is asking for information (training losses) related to a specific implementation. While this information could be helpful, its value depends on the user's background and expertise. Without further context or a clear request for a specific type of loss or training procedure, it's not immediately actionable. The framing as a question and a desire for evidence makes it less of a direct critique or suggestion of improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The reviewer explicitly states 'overclaims' and lists specific aspects like 'geometric interpretability,' 'Theorem 1,' 'high/low entropy representations,' and 'hardnegative mining.' This indicates a clear and actionable criticism. While the reviewer doesn't provide a specific *action* to take, the criticism itself is a direct call to the authors to review their presentation and avoid this kind of overclaiming. The reviewer identifies a potential area for improvement in the authors' communication.", "grounding_specificity_rationale": "The reviewer's criticism is not explicitly tied to a specific section, table, or figure of the paper. While they mention 'theoretical analysis' broadly, they don't point to a particular element within that section. However, they do name specific aspects of the theoretical analysis (geometric interpretability, Theorem 1, etc.), which adds some level of specificity to the *content* they are criticizing, even if not the *location*.", "verifiability_rationale": "The reviewer makes a claim ('the paper overclaims...') but does not provide any specific evidence or reasoning to support this claim. They present an argument for why this overclaiming might exist but do not cite specific instances where they've observed this. Therefore, while they identify a potential issue, they don't provide the necessary evidence to back up their claim.", "helpfulness_rationale": "The reviewer's point is that the paper overclaims the strength of the BC loss. While this is a valuable critique and points to a potential area for improvement in the paper's presentation, it does not directly provide the authors with a clear, actionable step to take. The reviewer doesn't suggest an alternative approach or a specific way to revise the paper to avoid this overclaiming. Therefore, while the feedback is relevant, it lacks the direct guidance needed for the authors to act on it immediately."}
{"actionability_label": "3", "grounding_specificity_label": "2: 3", "verifiability_label": "4", "helpfulness_label": "1", "actionability_rationale": "The reviewer criticizes the proposed method's effectiveness in the abstract section and the unsuitability of arenabased evaluation systems for single dialogue system evaluation. While the reviewer doesn't explicitly state an action or suggestion for improvement, the criticism implies a desire for a more effective and affordable evaluation method. The reviewer suggests that current scorebased systems are less relevant to the authors' motivations and that arenabased systems, while useful for comparison, don't solve the problems of current scorebased systems. This implies a desire for a more direct and actionable feedback mechanism. However, the criticism itself isn't a direct, explicit, or concrete action the reviewer proposes. The reviewer is more critical of the *evaluation system* rather than suggesting a specific improvement to it.", "grounding_specificity_rationale": "The reviewer mentions the 'abstract section' and 'single dialogue system evaluation' when criticizing the proposed method and arenabased systems. While the reviewer doesn't explicitly name *which* part of their paper they are referring to, they clearly indicate the context of their criticism. The reviewer is pointing to a specific area of concern, which suggests a good level of grounding. The reviewer is able to identify the specific type of evaluation they believe is needed (more relevant to authors' motivations and less reliant on expensive human evaluation).", "verifiability_rationale": "The reviewer makes claims about the limitations of automatic scores (effectiveness and affordability) and the unsuitability of arenabased systems for single dialogue system evaluation. These claims are generally supported by common knowledge in the field. The reviewer's statement about automatic scores not being effective and human evaluation being expensive is a generally accepted understanding. The reviewer's assertion that arenabased systems are not suitable for single system evaluation is also a reasonable argument based on their purpose (comparison between systems). The reviewer provides logical reasoning to support their claims, making them verifiable.", "helpfulness_rationale": "The reviewer explicitly states their dissatisfaction with the proposed framework FFAEVAL and similar systems, highlighting a clear lack of helpfulness. They state, 'I do not think it can be directly used to evaluate a single dialogue system, like give a fluency score or something like that.' This directly criticizes the utility and value of the proposed method for the authors. The reviewer's statement clearly indicates a negative assessment of the proposed solution's ability to provide meaningful feedback or assistance. The reviewer's dissatisfaction is a direct and strong statement about the lack of helpfulness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The reviewer explicitly states the reason for their criticism: 'focal loss is famous for doing class imbalance problem. It has lower gradients on easy samples, which is a good property for classification. But for regressing the IoU, lower weight for easy samples may cause inaccurate problem.' This clearly identifies an action the authors should take: 'This paper gives me a feeling that the authors only want to have a unified form, but didn't consider the difference between the classification and regression tasks.' The reviewer also identifies a potential problem: 'This paper gives me a feeling that the authors only want to have a unified form, but didn't consider the difference between the classification and regression tasks.' This suggests a concrete action the authors could take: 'This paper gives me a feeling that the authors only want to have a unified form, but didn't consider the difference between the classification and regression tasks.'", "grounding_specificity_rationale": "The reviewer explicitly mentions 'regression tasks' and 'IoU' as the context of the criticism. They also mention 'easy samples' and 'lower gradients'. While the reviewer doesn't directly name the section or table, the context is clear. The reviewer also implicitly grounds the issue by pointing out the difference between 'classification' and 'regression' tasks, which are distinct. The reviewer's statement 'focal loss is famous for doing class imbalance problem. It has lower gradients on easy samples, which is a good property for classification. But for regressing the IoU, lower weight for easy samples may cause inaccurate problem' directly identifies the specific aspect being addressed.", "verifiability_rationale": "The reviewer provides a claim: 'focal loss is famous for doing class imbalance problem. It has lower gradients on easy samples, which is a good property for classification. But for regressing the IoU, lower weight for easy samples may cause inaccurate problem.' The reviewer then provides a reasoning: 'focal loss is famous for doing class imbalance problem. It has lower gradients on easy samples, which is a good property for classification. But for regressing the IoU, lower weight for easy samples may cause inaccurate problem.' This reasoning is logical and based on established knowledge about focal loss and its properties. The reviewer also implicitly connects this to the potential issue in regression by stating 'This paper gives me a feeling that the authors only want to have a unified form, but didn't consider the difference between the classification and regression tasks.' While not a direct counterexample, the reasoning is wellsupported.", "helpfulness_rationale": "The reviewer provides a critique of the use of focal loss for regression, pointing out a potential flaw in the unified approach. They offer a possible explanation: 'focal loss is famous for doing class imbalance problem. It has lower gradients on easy samples, which is a good property for classification. But for regressing the IoU, lower weight for easy samples may cause inaccurate problem.' This critique is relevant and could help the authors understand a potential limitation of their approach. The reviewer's statement 'This paper gives me a feeling that the authors only want to have a unified form, but didn't consider the difference between the classification and regression tasks.' suggests a desire for improvement, which is a helpful suggestion."}
{"actionability_label": "2", "grounding_specificity_label": "Weakly Grounded and UnderSpecific", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about the method's scaling behavior, which can be interpreted as an implicit action. However, the question is broad and lacks specific details on how the method scales with corpus size or hidden dimension size. The action is implied but not explicitly stated, and the details are missing, making it vague.", "grounding_specificity_rationale": "The review point asks about the method's scaling with 'corpus size' and 'hidden dimension size'. While the authors can infer that these parameters are relevant to the method, the question itself does not specify which part of the paper or which unique aspect is being addressed. The grounding is present in the parameters being discussed, but the specificity of the question is lacking.", "verifiability_rationale": "The review point is a question and does not contain a claim or suggestion that requires verification. It is a request for information rather than a statement that needs to be supported by evidence.", "helpfulness_rationale": "The review point is relevant to the authors as it raises a pertinent question about the method's scalability, which is a crucial aspect for practical application. While it doesn't provide a direct solution, it encourages the authors to investigate and potentially improve their method. Therefore, it has some level of helpfulness in guiding further development."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly suggests trying a different encoder (RoBERTabase) as a potential improvement. This is a direct and concrete action that authors can readily consider and implement.", "grounding_specificity_rationale": "The review point does not specify which part of the paper the suggestion relates to. It is a general question about the encoder, not a comment on a specific section, table, or figure.", "verifiability_rationale": "The review point presents a suggestion (using RoBERTabase) without providing any justification or evidence *within the review itself*. It is a question, not a claim that needs verification.", "helpfulness_rationale": "The review point raises a relevant question about a potential improvement (using a better encoder). It prompts the authors to consider a modification that could benefit their work. While it doesn't provide a definitive answer, it is a valid and potentially helpful suggestion."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The comment identifies a problem ('This paper does not provide the type of GPUs, and inference time when testing.') but does not specify how the authors should address it or what steps they should take. It points out a missing piece of information without providing a concrete action.", "grounding_specificity_rationale": "The comment refers to 'this paper' in a general sense, indicating a lack of specific section or detail. It mentions 'GPUs' and 'inference time' without pointing to a specific table, figure, or unique aspect of the paper. The authors cannot confidently determine which part the comment addresses.", "verifiability_rationale": "The comment is a statement of fact ('This paper does not provide the type of GPUs, and inference time when testing.') and does not make a claim that requires verification. It describes the current state of the paper without offering a judgment or suggestion.", "helpfulness_rationale": "The comment points out a factual omission ('This paper does not provide the type of GPUs, and inference time when testing.') but does not offer any actionable feedback or suggestions for the authors to improve their draft. It highlights a potential area for improvement without providing guidance on how to achieve it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The reviewer explicitly states that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image, implying a specific action: to correct the connections in the figure. The reviewer also suggests that the current connections (Images Masked by Second Masks) are incorrect, indicating a clear understanding of what needs to be done. While the reviewer doesn't provide a detailed explanation of *why* these specific connections are incorrect, the identification of the specific elements and the desired action makes this point actionable.", "grounding_specificity_rationale": "The reviewer directly refers to 'Figure 2,' 'Inpainted Images,' and 'Images Masked by Second Masks,' explicitly identifying the specific parts of the paper and the issue within that figure. The reviewer clearly states that the connections should be between the 'Second Inpainted Images' and the 'Inpainted Image,' further emphasizing the grounding of the comment. The comment is specific about the *images* that are misconnected.", "verifiability_rationale": "The reviewer makes a claim about the figure's accuracy, stating that the connections are incorrect. While they don't provide external references, the reasoning is based on the likely intended function of the Perceptual Metric in showing the impact of the second inpainting. The reviewer's statement is a claim that can be verified by examining Figure 2 and understanding the typical usage of such metrics in the context of inpainting. The claim is supported by the visual representation in the figure and the implied purpose of the metric.", "helpfulness_rationale": "The reviewer provides a clear and specific suggestion for improving Figure 2. They identify a potential error in the connections and explain *why* they believe the connections should be different. This directly addresses a potential point of confusion or misinterpretation for the author. The reviewer's comment is actionable and directly suggests a change to improve the clarity and accuracy of the figure, making it 5 for the author."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests considering an alternative optimization method (adaptive gradient vs. SGD) but does not explicitly state how to implement or test this change. While it implies a potential improvement, the specific action is not detailed.", "grounding_specificity_rationale": "The review point mentions 'hard features' without providing a clear definition or linking it specifically to the paper being reviewed. This makes the grounding somewhat weak.", "verifiability_rationale": "The review point raises a question about the potential impact of a different optimization method on the findings. It does not present a claim that can be directly supported or verified based on the existing paper's content.", "helpfulness_rationale": "The review point raises a valid concern about the optimization method used. However, it does not offer a specific suggestion or action for the authors to take based on this concern. It is a question rather than a constructive feedback point."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The reviewer points out specific shortcomings in the experiments, such as 'limited types of teacher architectures' and 'most compared methods are proposed before 2019'. While the reviewer doesn't explicitly state how to address these issues, they clearly identify the problems. The suggestions, though not detailed, imply actions like 'improving the experiments' or 'including more recent methods'.", "grounding_specificity_rationale": "The reviewer refers to 'teacher architectures' and 'compared methods' and even mentions 'Tab.' (presumably a table). While the reviewer identifies the areas of concern, they do not explicitly name the specific section, table, or unique aspect of the paper being addressed. The reviewer refers to these elements generally.", "verifiability_rationale": "The reviewer makes a claim that 'the experiments are not sufficient enough'. They support this claim by stating 'limited types of teacher architectures' and 'most compared methods are proposed before 2019'. While the reasoning is present, the reviewer does not provide specific examples or references to external works to back up these claims within the provided text.", "helpfulness_rationale": "The reviewer criticizes the sufficiency of the experiments, which is a valid concern for authors. While the reviewer doesn't offer very specific, actionable suggestions beyond the points already made (limited teacher architectures, pre2019 methods), the criticism itself is a valuable piece of feedback. The reviewer identifies a problem with the experiments, which can guide improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The reviewer suggests a comparison between sequential and combinational design, which implies an action, but the specific steps or methods for this comparison are not explicitly stated. Therefore, while the intent is clear, the explicit action is somewhat vague.", "grounding_specificity_rationale": "The reviewer explicitly mentions 'pure combinational logic' and 'sequential design', providing a clear reference point for the comment. This strong identification of the specific aspect being addressed indicates high grounding specificity.", "verifiability_rationale": "The reviewer's statement about the proposed method 'seems' to perform better in combinational logic and suggests a comparison between sequential and combinational design. This is a claim that requires justification, but the reviewer does not provide any evidence or references to support this claim. Therefore, the verifiability is low as there is no clear supporting evidence.", "helpfulness_rationale": "The reviewer suggests an interesting comparison between sequential and combinational design. While this could be a valuable insight for the authors, the review itself does not provide explicit instructions or suggestions on how to perform this comparison. It is more of a suggestion for further investigation rather than a direct critique or improvement plan. Therefore, the helpfulness is moderate as it points to a potential area for improvement but lacks concrete guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states an action: 'The reviewer is concerned about the practicality of this work.' This action is clear and actionable for the authors. They can consider alternative approaches if prior knowledge is unreliable. The reviewer directly points out a limitation of the proposed method, which is a concrete action for the authors to take.", "grounding_specificity_rationale": "The review point identifies a specific aspect of the paper as a concern: 'prior knowledge about causal relationships between features.' While the phrasing is somewhat general, the authors can reasonably infer the specific area being addressed. The reviewer directly mentions a potential weakness in the paper's methodology, which is a key area for improvement. The comment clearly specifies what needs to be addressed.", "verifiability_rationale": "The review point is primarily a concern and a question about practicality, rather than a claim that needs verification. The statement 'This paper proposes to use known causal relationships between features' is a description of the method, not a claim that requires supporting evidence within the review itself. Therefore, it falls under the 'X' category (X).", "helpfulness_rationale": "The review point raises a valid and practical concern about the limitations of relying on potentially flawed prior knowledge. This directly impacts the authors' ability to apply the proposed method effectively. The reviewer's question about the practicality of the work is a direct and helpful feedback point for the authors, guiding them to consider alternative approaches or datadriven methods."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states the 'lack of comparative experiments' in Section 4.3 and suggests 'comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2'. This is an explicit statement that directly identifies a missing element and implies an action: 'The authors should have included these experiments'. The action is also concrete as the specific block types are mentioned.", "grounding_specificity_rationale": "The review point explicitly refers to 'Section 4.3' and specifically mentions 'bottleneck in ResNet' and 'linear bottleneck in MobileNetV2'. This allows the authors to accurately pinpoint the section and the type of nonlinear blocks being referred to, making it fully grounded. The specificity is also high as the exact types of blocks are mentioned.", "verifiability_rationale": "The review point identifies a potential gap in the experimental evaluation by pointing out the 'lack of comparative experiments' with specific nonlinear block types. While it doesn't explicitly state that these experiments are 'required' or 'necessary', it strongly suggests their inclusion would be beneficial. This implies an inferred action: 'The authors should consider adding these experiments to provide a more comprehensive evaluation'. The specificity is also high as the exact block types are mentioned, and the reviewer is suggesting a concrete improvement.", "helpfulness_rationale": "The review point directly identifies a specific weakness in the experimental section (lack of comparative experiments with certain nonlinear blocks) and suggests a concrete and actionable improvement ('include these experiments'). This is a valuable piece of feedback for the authors as it directly addresses a potential area for strengthening their work. The suggestion is clear and directly linked to a potential benefit for the authors."}
