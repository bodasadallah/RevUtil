{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the quality of the dataset, specifically questioning the \"pristine\" set of tweets and suggesting that it might contain misinformation and outofcontext images. The reviewer implies that more analysis is needed to assess the dataset\"s quality and potential noise. While the comment highlights an important area for improvement, it does not provide explicit guidance on how the authors should conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to analyze the dataset\"s quality but are not given concrete steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the quality of the dataset, specifically questioning the \"pristine\" set of tweets and suggesting that it might contain misinformation and outofcontext images. However, it does not specify which part of the paper discusses the dataset, making it weakly grounded. The comment is specific in detailing the concern about the dataset\"s quality and suggesting additional analysis, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the quality of the dataset, specifically questioning the \"pristine\" set of tweets and suggesting that it might contain misinformation and outofcontext images. The reviewer expresses a desire to see more analysis around the dataset\"s quality and potential noise. However, the comment lacks specific examples or references to support the claim that the dataset is not pristine or that it contains misinformation. This makes the claim 3, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the quality of the dataset, specifically questioning the \"pristine\" set of tweets and suggesting that it might contain misinformation and outofcontext images. This is an important point that the authors should address to ensure the reliability and validity of their results. The comment provides a clear direction for improvement by suggesting that more analysis is needed around the dataset\"s quality and potential noise. However, it could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it identifies a critical area for improvement and provides a general direction for further analysis, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of HIERENC is unclear and suggests that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, stating that only one of these instantiations is likely to be correct and that this could introduce noise. While the comment identifies a potential issue with the description and suggests a possible reason for concern, it does not provide explicit guidance on how to clarify the description or address the potential noise issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the description and potentially explore alternative approaches. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by describing the unclear description of HIERENC and providing a detailed explanation of what is unclear. This provides clear guidance on what needs to be clarified or improved in the description. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, stating that only one of these instantiations is likely to be correct and that this could introduce noise. While the comment provides a logical reasoning for the potential issue, it lacks specific examples or references to support the claim fully. The authors would need to further explore and substantiate the reasoning to fully understand and address the concern. Therefore, the comment is 3, as it provides a logical basis but requires additional evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, suggesting that the input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. The reviewer questions the validity of this approach, noting that only one of these instantiations is likely to be correct and that this could introduce noise. This feedback is clear and actionable, as it highlights a potential weakness in the methodology and suggests a possible source of error. By pointing out this issue, the comment provides the authors with a specific area to clarify or improve their description, which can lead to a more robust and understandable presentation of their work. However, the comment could be more helpful if it offered suggestions on how to address the potential noise issue or provided examples of alternative approaches. Overall, the comment is 4, as it effectively directs the authors to a critical area needing clarification or improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. While it implies that the authors should provide an explanation or justification for this selection, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the selection process and its potential impact on performance estimation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. While it identifies a potential area of concern, it does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be clarified or improved. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests clarification regarding the splits used for obtaining the ATIS numbers in Table 4. The comment is clear and direct, providing a specific action for the authors to take. The authors know exactly what needs to be clarified and can address this by providing the necessary information. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs clarification: the splits used for obtaining the ATIS numbers. This provides clear guidance on what the authors need to address to improve the clarity of their work. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point is a request for clarification regarding the splits used for obtaining the ATIS numbers in Table 4. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement by requesting clarification on the splits used for obtaining the ATIS numbers in Table 4. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the clarity and transparency of their work. However, the comment could be more helpful if it included suggestions on how to present this information or why it is important. Despite this, the feedback is 4 as it guides the authors toward improving the clarity and completeness of their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential cognitive bias among NLP researchers, noting that instances where the authors perform worse are often labeled as \"on par,\" while instances where they perform better are labeled as \"better.\" The reviewer suggests that this wording should be corrected, implying that the authors should be more precise in their descriptions. However, the comment does not provide specific guidance on how to correct this wording or what alternative phrasing might be more appropriate. While the action is explicit, it lacks concrete details on how to implement the suggested change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 791, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential cognitive bias among NLP researchers and suggests that the wording \"on par or better\" should be corrected. The comment provides a clear direction for improvement by specifying what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a general cognitive bias among NLP researchers, suggesting that instances where they perform worse are often labeled as \"on par\" while instances where they perform better are labeled as \"better.\" The reviewer provides a specific example from line 791 to support this claim. However, the comment lacks detailed evidence or references to substantiate the claim further, such as examples of similar instances or studies that have observed this bias. While the reasoning is logical, the lack of additional support makes the claim 3, as it requires more evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential cognitive bias among NLP researchers, specifically noting that instances where the authors perform worse are often labeled as \"on par,\" while instances where they perform better are labeled as \"better.\" This observation is relevant and could be a source of confusion for readers. The reviewer suggests that the wording should be corrected to avoid this bias, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific suggestions on how to rephrase the results to avoid this bias. Overall, the comment is 4 as it highlights an important issue and offers a direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the lack of novelty in the paper, noting that adversarial attacks by perturbing text have been done on many NLP models and imagetext models, and that the related work section nicely summarizes this. The reviewer suggests that the only new effort is to apply similar ideas to videotext models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue of novelty or improve their work. Without actionable suggestions or a clear direction for improvement, the authors are left without a path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the lack of novelty in the paper, specifically regarding adversarial attacks by perturbing text. It references the related work section, suggesting that the only new effort is to apply similar ideas to videotext models. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the lack of novelty, but without clear grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, specifically regarding adversarial attacks by perturbing text. It supports this claim by referencing related work that has already explored this concept on NLP models and imagetext models. The reviewer further notes that the only new effort is to apply similar ideas to videotext models. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to the related work mentioned, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment critiques the paper for lacking novelty, specifically in the context of adversarial attacks by perturbing text. It acknowledges that this concept has been explored in related work, but suggests that the only new effort is to apply it to videotext models. While the comment identifies a potential weakness in the paper, it does not provide actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without specific feedback or recommendations, the authors are left without a clear path for improvement. Therefore, the comment is 3, as it highlights a concern but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about how an antecedent would be identified when the prediction is a pronoun, given the authors\" proposed method of matching the head of noun phrases. It questions the applicability of this method when the head word is not a pronoun. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or modify their method to handle situations where the head word is not a pronoun. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a specific concern about the identification of antecedents when the prediction is a pronoun, particularly in the context of the authors\" proposed method of matching the head of noun phrases. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the proposed method and how it might not handle situations where the head word is not a pronoun. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the identification of antecedents when the prediction is a pronoun, specifically questioning the applicability of the authors\" proposed method of matching the head of noun phrases. The comment highlights a potential issue with the method\"s limitations, but it does not provide specific examples or detailed reasoning to fully substantiate the claim. While the authors are alerted to a potential weakness, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" proposed method for identifying antecedents when the prediction is a pronoun. It questions how the method would handle situations where the head word is not a pronoun, which is a relevant and important point for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might improve their method to handle these situations. While it highlights a potential weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include discussions on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. This feedback is explicit in its request for additional discussion, but it lacks concrete guidance on what specific aspects should be included in these discussions. While the authors are given a clear direction to improve their draft, the lack of detailed instructions on how to implement the suggested discussions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that discussions are needed on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for additional discussion on convergence, but without clear grounding, the authors may struggle to identify the exact section where this discussion should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that discussions are needed on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to help readers understand how stable points in the probabilistic metric space are obtained. The comment implies that without such discussions, it may be difficult to replicate the results. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current explanation is insufficient. This makes the claim 3, as it provides a general direction for improvement but lacks the necessary details to fully substantiate the need for additional discussion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that discussions on the convergence of the proposed joint learning process are needed. It highlights the importance of understanding how stable points in the probabilistic metric space are obtained, which is crucial for replicating the results. While the comment provides a clear direction for improvement, it lacks detailed guidance on what specific aspects of the convergence process should be discussed or how to present this information. This limits the comment\"s usefulness, as it does not offer comprehensive suggestions for enhancing the draft. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. However, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment mentions \"Comments  I like attacking implicit offensive texts with reasoning chains, but not yet convinced with the example of Fig,\" which appears to be a separate issue unrelated to the main concern about biases. The lack of actionable advice and the disconnected nature of the comment make it difficult for the authors to know what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. However, it does not specify which part of the paper this concern pertains to, making it weakly grounded. The comment also lacks specificity as it does not provide detailed guidance on what needs to be addressed or how to address the issue of societal biases. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the lack of description regarding whether the knowledge bases used are free from societal biases and whether the issue is affected by such restrictions. This is an important consideration, especially in the context of AI and natural language processing, where biases can significantly impact the accuracy and fairness of the models. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to ensure their knowledge bases are biasfree. Additionally, the mention of \"Comments  I like attacking implicit offensive texts with reasoning chains, but not yet convinced with the example of Fig\" appears to be a separate issue unrelated to the main concern about biases. The lack of actionable feedback and the disconnected nature of the comment make it 3, as it identifies an important area for improvement but does not offer detailed guidance on how to address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to provide more information about the traits of the experts and to justify why annotation must be carried out by the experts, rather than focusing solely on commercial values. It also asks specific questions about the expertise of the annotators, whether the annotation process was different from what nonexperts would do, and if it introduced any linguistic challenges. These questions provide clear guidance on what the authors need to address, making the comment 5. The authors know exactly what information to include and what questions to answer to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: a more detailed description of the traits of the experts and a justification for why annotation must be carried out by the experts, rather than focusing solely on commercial values. The comment also asks specific questions about the expertise of the annotators and the nature of the annotation process, which further clarifies the areas needing attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the need for more information regarding the traits of the experts and the justification for using expert annotation. However, it does not provide any specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples that would help the authors understand the basis of the suggestion. Without such support, the claim remains 1, as the authors are left without a clear understanding of why this information is necessary or how it would improve the paper. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should describe more about the traits of the experts involved in the annotation process and justify why expert annotation is necessary, rather than focusing solely on commercial values. It also asks questions about the expertise of the annotators, whether the annotation process differed from what nonexperts would do, and if it introduced any linguistic challenges. This feedback is clear and detailed, offering the authors a structured approach to enhance their draft by addressing these critical aspects. By providing specific questions and areas for improvement, the comment empowers the authors to make significant enhancements to their work. Therefore, it is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include examples of their system applied to actual texts rather than focusing solely on other components or models. While the comment implies that the authors should provide such examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the type of examples or how they should be presented. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including examples of the system applied to actual texts, rather than focusing on other components or models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of examples, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. However, the comment does not provide any specific reasoning, examples, or references to support why this would be valuable or necessary. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion or how to implement it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the authors should include examples of their system applied to actual texts, rather than focusing solely on other components or models. This feedback is 3 as it provides a specific direction for enhancing the paper by demonstrating the system\"s practical application. However, the comment lacks depth and does not offer detailed guidance on how to present these examples or what specific aspects of the system should be highlighted. While it points out a potential area for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of the Challenge Set (CS) and its role in the evaluation and training process. It explicitly asks whether the CS is used to augment the training material and requests information about the data split. While the comment does not provide explicit instructions, it does imply that the authors should clarify these aspects. The action is implicit but concrete, as it directs the authors to provide specific information about the use of the CS. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises questions about the use of the Challenge Set (CS) in the evaluation and training process, specifically asking if it is used to augment the training material and requesting information about the data split. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its questions about the use of the CS and the data split, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the use of the Challenge Set (CS) in the evaluation and training process. It seeks clarification on whether the CS is used to augment the training material and requests information about the data split. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or important. Without additional context or explanation, the authors may find it challenging to understand the basis of the questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the use of the Challenge Set (CS) in the evaluation and training process. It seeks clarification on whether the CS is used to augment the training material and requests information about the data split. This feedback is valuable as it prompts the authors to provide more detailed information about their methodology, which can help readers better understand the study. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided guidance on how to present this information in the paper. Overall, the comment is 3 as it identifies a gap in the paper and encourages the authors to clarify their approach, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the relatively poor performance of TWSI on nouns, which is expected due to its nature. It also notes that the oracle GAP for PPDBClus is higher than most clustering approaches, which is disconcerting. The reviewer suggests understanding the gap better and points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. While the comment identifies areas of concern and suggests further exploration, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the gap and reconcile the contradictory claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of TWSI on nouns, which is expected due to its nature, and the fact that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. However, the comment does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about performance and the contradiction with the claim, but without explicit references to sections, it is challenging for the authors to pinpoint the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the relatively poor performance of TWSI on nouns is disconcerting, especially given the oracle GAP for PPDBClus being higher than most clustering approaches. The reviewer also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. While the comment highlights a concern, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The authors might infer that the performance gap is significant, but the comment does not provide enough evidence or explanation to fully support the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific concern about the performance of TWSI on nouns, which is expected due to its nature. It also highlights the fact that the oracle GAP for PPDBClus is higher than most clustering approaches, which is disconcerting. The reviewer suggests understanding the gap better and points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech. This feedback is 3 as it directs the authors to investigate the performance gap and reconcile the contradictory claims. However, it could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to improve the generalizability claim. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests the authors to provide examples of spurious structures in the discussion of section 5.2, which is a direct and concrete action. The authors know exactly what is expected of them, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, namely its abstract nature and the lack of insights into why the new model is better than MH. The comment further requests examples of spurious structures, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in section 5.2 is abstract and lacks insights into why the new model is better than MH. The reviewer requests examples of spurious structures to clarify the discussion. However, the comment does not provide specific examples or detailed reasoning to support the claim that the discussion is abstract or why examples of spurious structures are necessary. This lack of detailed justification or examples makes the claim 3, as the authors may need to infer the exact issues and how to address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion in section 5.2, noting that it is abstract and lacks insights into why the new model is better than MH. It provides a clear and actionable suggestion by requesting examples of spurious structures, which would help clarify the discussion and enhance the paper\"s contribution. This feedback is valuable as it directs the authors to a particular area needing improvement, offering a concrete step toward enhancing the manuscript. However, the comment could be more helpful if it included additional guidance on how to present these examples or what specific aspects of the discussion need clarification. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the probabilistic connection is not drawn well and recommends either cementing the connection more formally or adjusting the language to clarify. While the comment implies that the authors should take action to improve the clarity of the probabilistic connection, it does not provide specific guidance on how to achieve this. The action is explicit but somewhat vague, as it lacks concrete details on how to formalize or adjust the language. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the probabilistic connection in the paper, suggesting that it is not drawn well and is not formally established. However, it does not specify which part of the paper discusses this probabilistic connection, making it weakly grounded. The comment is specific in suggesting that the authors either formalize the connection or adjust the language to clarify it. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the probabilistic connection is not drawn well and suggests that it is not formally established. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or evidence to substantiate the assertion that the connection is not welldrawn, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the probabilistic connection, suggesting that it is not drawn well and lacks formalization. It provides a clear and actionable suggestion for the authors to either formalize the connection more rigorously or adjust the language to clarify it. This feedback is specific and offers a concrete direction for improvement, making it 4. However, the comment could be more helpful if it included examples or further guidance on how to formalize the connection or adjust the language. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. This is an explicit request for additional data or analysis to substantiate the claim made in the paper. The action is clear and concrete, as it specifies what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what specific evidence or analysis is needed. This makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its request for empirical evidence but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the algorithm is better suited for this problem. Without such evidence or justification, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for the Column Subset Selection problem. This feedback is clear and actionable, as it identifies a specific area where the paper could be strengthened by including additional data or analysis. However, the comment could be more helpful if it provided guidance on how to conduct this empirical evaluation or suggested specific metrics to consider. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the choice of datasets and the sufficiency of the time period (4 years) to study style shifts. It questions what kind of style shifts occur within this timeframe and suggests that without these answers, it is difficult to appreciate what the model is capturing. While the comment implies that the authors should provide more information on the datasets and the time period, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address these questions, but they are not given specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of datasets and the sufficiency of the time period (4 years) to study style shifts. However, it does not specify which part of the paper discusses these datasets or the time period, making it weakly grounded. The comment is specific in questioning the adequacy of the time period and the nature of style shifts, providing a clear direction for the authors to address these concerns. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the sufficiency of the time period (4 years) to study style shifts and asks for clarification on the kind of style shifts that occur within this timeframe. However, it does not provide any specific reasoning, examples, or references to support the claim that 4 years is insufficient. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of datasets and the sufficiency of the time period (4 years) to study style shifts. It questions what kind of style shifts occur within this timeframe and suggests that without these answers, it is difficult to appreciate what the model is capturing. This feedback is 3 as it prompts the authors to provide more context and justification for their dataset selection and the time period considered. However, the comment could be more helpful if it offered specific suggestions on how to address these concerns or provided examples of alternative datasets or time periods that might be more appropriate. Overall, the comment identifies a critical area for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the paper is generally easy to follow but identifies specific areas that may cause confusion. However, it does not provide explicit guidance on how to address these potential sources of confusion. The comment lacks actionable details, such as suggesting specific changes or improvements to clarify these areas. As a result, the authors are left without a clear understanding of what steps to take to enhance the clarity of their draft. Since the action is not explicitly stated and lacks concrete details, the comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the paper is generally easy to follow but identifies specific areas that may cause confusion. However, it does not specify which parts of the paper are confusing or what aspects need clarification. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine which parts of the paper are being addressed. This lack of grounding and specificity makes it difficult for the authors to understand and address the issues raised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any examples or detailed reasoning to support this claim. Without specific references or explanations, the authors may find it challenging to understand and address the potential sources of confusion. Therefore, the comment is considered 1, as it lacks sufficient evidence or justification to substantiate the claim.", "helpfulness_rationale": "The comment acknowledges that the paper is generally easy to follow but identifies specific areas that may cause confusion. However, it does not provide any details or examples of what these confusing areas are, nor does it offer suggestions on how to address them. Without specific guidance or actionable feedback, the authors are left without a clear understanding of what needs to be improved or clarified. This lack of detail makes the comment 2, as it highlights potential issues but does not provide the authors with the necessary information to address them effectively."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of the results being nonobvious or how to make them more accessible to a broader audience. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the results section, specifically mentioning that they are based on \"standard\" techniques but are not obvious a priori. However, it does not specify which results or techniques are being referred to, making it weakly grounded. The comment is specific in pointing out the issue of the results being nonobvious and requiring technical competency, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, the comment does not provide specific examples of these \"standard\" techniques or explain why they are not obvious to a broader audience. This lack of detailed reasoning or references makes it difficult for the authors to understand and address the issue. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. This observation highlights a potential limitation in the accessibility of the results, suggesting that they may not be immediately understandable to a broader audience. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as by providing additional explanations, examples, or references to make the results more accessible. Without actionable advice, the feedback is 3 as it identifies a potential area for improvement but lacks depth and specificity. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is clearly superior, given the small difference in performance. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the data usage or analysis. The action is implicit and vague, as the authors are left to infer that they should reconsider their data usage or analysis, but without concrete steps or suggestions, the comment lacks actionability. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is clearly superior, given the small difference in performance. However, the comment does not specify which part of the paper discusses these models or their performance, making it weakly grounded. The comment is specific in detailing the issue with the data usage and the implications for the conclusion, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the conclusion that the direct model is clearly superior, given the small difference in performance compared to the endtoend system. The comment highlights a discrepancy in the amount of data used for training, suggesting that this may impact the conclusion. However, the comment lacks specific examples or references to support the claim that the difference in data usage is significant or that it affects the conclusion. The reasoning is somewhat logical but requires more detailed evidence or examples to be 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the conclusion that the direct model is clearly superior, given the small difference in performance compared to the endtoend system. It highlights a discrepancy in the amount of data used for training, which could impact the validity of the conclusion. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two main issues with the paper: the lack of motivation for GaRare compared to GaLore and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. The comment provides explicit actions for the authors to take, such as providing evidence or justification for GaRare\"s advantages and clarifying the algorithmic presentation. However, it does not specify how the authors should present the theoretical analysis or provide detailed guidance on how to clarify the algorithmic process. While the actions are clear, the lack of concrete details on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GaRare\" and \"GaLore,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for GaRare and does not provide evidence or justification for its advantages over GaLore. It also suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed reasoning or evidence makes the claim 3, as it requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it points out the lack of motivation for GaRare, suggesting that the paper does not provide evidence or justification for its advantages over GaLore based on theoretical analysis. This feedback is clear and actionable, as it directs the authors to enhance their explanation of GaRare\"s benefits. Second, the comment highlights the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This suggestion is also actionable, as it provides a specific area for improvement that would enhance the paper\"s clarity. Overall, the comment is 4 as it offers clear and actionable feedback that can guide the authors in improving their draft. However, it could be more comprehensive by suggesting how to present the theoretical analysis or provide examples of the algorithmic process. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF), which have a similar structure to the CRF and can perform exact inference. This feedback provides a clear and specific action for the authors to take, which is to include references to these works in their paper. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely, a reference to these works that have a similar structure to the CRF and can perform exact inference. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF), which have a similar structure to the CRF and can perform exact inference. This claim is 3 as it references specific works that could be relevant to the paper. However, the comment does not provide detailed reasoning or examples of how these works are similar or how they could enhance the paper, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks context by pointing out the absence of references to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF). These references are relevant because they have a similar structure to the CRF and can perform exact inference, which could provide valuable insights or comparisons for the authors. However, the comment could be more helpful if it included specific suggestions on how to integrate these references or why they are important for the paper. Despite this, the feedback is clear and actionable, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It explicitly asks the author to provide more clarification on this issue. This request is clear and direct, giving the authors a specific action to take to address the reviewer\"s concern. The feedback is concrete, as it specifies what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises a concern about the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not specify which part of the paper this similarity is observed in, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for clarification, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not provide any further explanation, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the similarity or how it affects their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the similarity between the method described in the paper and the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" It raises a concern that the authors should clarify this similarity to avoid confusion or potential overlap with existing work. While the comment highlights an important area for clarification, it lacks specific guidance or suggestions on how the authors might address this issue. Providing more detailed feedback, such as recommending ways to differentiate the methods or explaining the unique contributions of the paper, could enhance the helpfulness of the comment. As it stands, the comment is 3, as it prompts the authors to address a potential weakness but does not fully guide them in doing so."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment does not provide explicit guidance or suggestions on how the authors should address these questions or improve their draft. The actions are implicit and vague, leaving the authors without clear direction on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work, but this does not provide specific guidance on how to improve the paper. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The comment also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work, but this is not a claim that requires verification. Therefore, the comment lacks verifiability, as it does not provide sufficient evidence or reasoning to support the claims made. The authors would need to infer the issues and address them without clear guidance from the review. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises questions about the fairness of comparing the proposed method with other methods and whether the proposed technique promotes existing Class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address the questions raised or how they could enhance their work. As a result, the comment is 2, as it identifies some areas of concern but does not provide enough detail or direction for the authors to make meaningful improvements to their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Section 4 is tersely written and suggests that it could have benefitted from a slower development for easier readability. However, it does not provide specific guidance on how to achieve this or what aspects of the section need to be expanded. The action is implicit and somewhat vague, as the authors are left to infer that they should make the section more detailed without concrete suggestions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the section is tersely written and suggests that it could have benefitted from a slower development for easier readability. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 4 is tersely written and suggests that it could have benefitted from a slower development for easier readability. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing style of Section 4, noting that it is tersely written and could benefit from a slower development for easier readability. This feedback is 3 as it points out a potential area for improvement, suggesting that the authors might need to expand or clarify their explanations in that section. However, the comment lacks specific suggestions or guidance on how to achieve this slower development or what aspects of the section could be expanded. While it provides some direction, it does not offer detailed actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"benchmark\" and the \"distribution of videos of different lengths,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of a table showing the distribution of video lengths across the dataset and an explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the distribution of videos of different lengths within the benchmark is crucial for assessing reasoning ability and robustness, but the paper does not provide relevant explanations. The reviewer suggests that the authors include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is 4 as it provides a clear and logical reasoning for the importance of the distribution analysis, and it suggests specific actions for improvement. However, the comment could be strengthened by referencing similar studies or benchmarks that support the need for this analysis. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a critical aspect of the paper that is not adequately addressed: the distribution of videos of different lengths within the benchmark. It highlights the importance of this distribution for assessing reasoning ability and robustness, and it provides specific suggestions for improvement, such as including a table showing the distribution of video lengths across the dataset and explaining how the authors ensured a balanced representation of different video lengths across the 11 categories. This feedback is actionable and detailed, offering the authors clear guidance on how to enhance their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly advises the authors to take a cautious approach regarding their contribution until the promised dataset is made publicly available. This is a clear and direct action for the authors to take, as it specifies the need to wait for the dataset to be accessible before making any claims or contributions based on it. The comment provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of the promised dataset not being publicly available, which is a specific concern regarding the contribution of the paper. However, it does not specify which part of the paper discusses the dataset or where the promise was made, making it weakly grounded. The comment is specific in its request for caution until the dataset is openly accessible, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the promised dataset has not been made publicly available, which is a factual statement. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment highlights a critical issue regarding the promised dataset not being publicly available, which is a significant concern for the contribution of the paper. By pointing out this gap, the comment provides the authors with a clear and actionable area for improvement. It advises the authors to take a cautious approach until the dataset is openly accessible, which is a logical and necessary step to ensure the validity and reproducibility of the research. However, the comment could be more helpful if it suggested ways to address this issue, such as providing a timeline for dataset release or offering alternative approaches to validate the findings. Overall, the comment is 4 as it identifies a critical problem and guides the authors toward a solution, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed method is too similar to other attentional modules proposed in previous works, specifically mentioning [1, 2, 3] and ResNeSt [4]. It notes that although these works did not evaluate their performance on object detection and instance segmentation, the overall structures are similar. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to differentiate their work. The action is implicit and vague, as the authors are left to infer that they need to clarify the novelty of their method and potentially discuss the differences with existing works. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed method, specifically mentioning its similarity to other attentional modules in previous works and its relationship to ResNeSt. However, it does not explicitly mention which part of the paper discusses these comparisons or the proposed method, making it weakly grounded. The comment is specific in detailing the similarities and lack of discussion regarding ResNeSt, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. It provides specific references to [1, 2, 3] and mentions a potential relationship with ResNeSt [4]. However, the comment lacks detailed comparisons or examples of how the proposed method is similar to these works, making it difficult for the authors to fully understand and address the critique. The claim is 3 as it provides some references but lacks comprehensive evidence or detailed analysis to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the novelty of the proposed method, noting that it is too similar to other attentional modules proposed in previous works. It specifically mentions the group attention design and its potential relationship to ResNeSt, which is not discussed in the paper. While the comment highlights a critical weakness, it lacks actionable suggestions or guidance on how the authors might differentiate their work or address the similarity concerns. The feedback is 3 as it points out a key area for improvement, but it could be more beneficial with specific recommendations or examples of how to enhance the novelty of the proposed method. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their claims. The comment implies that the authors should conduct comparisons with existing detection methods, but this is not directly stated. The action is implicit and lacks concrete details, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, questioning the validity of this claim. It suggests that the performance is primarily due to the first step and implies that comparisons with existing detection methods are necessary. However, the comment does not specify which part of the paper discusses these claims or where the authors should conduct comparisons. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections needing revision. While the comment is specific in its critique, it is 1, as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. The reviewer provides a logical reasoning by questioning the validity of the claim and suggesting that comparisons with existing detection methods are necessary. However, the comment lacks specific examples or references to support the claim that the performance is primarily due to the first step. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is primarily due to the first step. It implies that comparisons with existing detection methods are necessary to validate the claim. While the comment identifies a potential weakness in the paper\"s claims, it lacks specific guidance or suggestions on how the authors might address this issue or improve their methodology. The feedback is 3 as it points out a critical area for improvement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point identifies a specific issue with the \"implicit call to the Witness oracle,\" describing it as confusing. However, it does not provide any guidance or suggestions on how to clarify this aspect or what changes should be made to improve the clarity. The comment lacks explicit instructions or concrete details on how to address the confusion, leaving the authors uncertain about the necessary actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the \"implicit call to the Witness oracle,\" suggesting that it is confusing. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact location of the problem. Additionally, the comment lacks specificity regarding what aspect of the call is confusing or how it could be clarified. Without explicit references or detailed guidance, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the \"implicit call to the Witness oracle\" is confusing. However, it does not provide any supporting evidence, reasoning, or examples to explain why this is the case. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the \"implicit call to the Witness oracle\" is confusing. However, it does not provide any further explanation, reasoning, or suggestions on how to clarify this aspect or improve the clarity of the paper. Without additional context or guidance, the authors are left without actionable feedback to address the issue effectively. Therefore, the comment is 1, as it does not offer any meaningful direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, questioning why it cannot condition headpose parameters like a previous work (Gafni et al. ICCV 2021). While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The authors are left to infer that they should explore ways to incorporate headpose control into their method, but without concrete guidance on how to implement this, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method\"s inability to handle headpose, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the proposed method cannot condition headpose parameters like a previous work (Gafni et al. ICCV 2021). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the proposed method\"s inability to handle headpose, questioning why it cannot condition headpose parameters like a previous work (Gafni et al. ICCV 2021). The comment provides a specific reference to a previous work that addresses this issue, which helps support the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the previous work handles headpose control. Overall, the claim is 4, as it provides a solid foundation but lacks comprehensive evidence or detailed explanation. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant limitation in the proposed method, specifically its inability to handle headpose. It questions why the method cannot condition headpose parameters like a previous work (Gafni et al. ICCV 2021), which is already able to control both facial expression and headpose. This feedback is clear and actionable, as it prompts the authors to consider how they might incorporate headpose control into their method, potentially leading to a more comprehensive and competitive approach. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue. Overall, the comment is 4, as it highlights a critical area for improvement and guides the authors toward enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization is a main component of the paper and has been emphasized several times, but it also notes that the optimization algorithm appears to be directly from previous works. The reviewer suggests that this reduces the contribution of the paper. While the comment implies that the authors should clarify the originality of their optimization algorithm, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context or justification for the optimization algorithm. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"structural optimization,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the optimization algorithm appears to be directly from previous works, which reduces the contribution of the paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the structural optimization is a main component of the paper, but it also notes that the optimization algorithm is directly from previous works, which reduces the contribution. The comment provides a logical reasoning by suggesting that the originality of the work is diminished due to the use of existing optimization algorithms. However, it lacks specific references or examples to support the claim about the direct use of previous works. This makes the claim 3, as the authors would need to investigate the claim further to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the structural optimization is a main component that has been emphasized several times, but it also suggests that the optimization algorithm is directly from previous works. This observation raises a concern about the originality and contribution of the paper, as it implies that the authors may not be adding significant value to the field by simply using existing optimization algorithms. The comment is 3 as it points out a critical area for improvement, but it lacks specific suggestions or guidance on how the authors might address this issue. To be more helpful, the comment could include recommendations on how to enhance the originality or contribution of the work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the pipeline style method, which includes two models, does not provide better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the introduction of baseline models or how to enhance the pipeline style method to achieve better results. Without specific suggestions or instructions, the authors are left without a clear understanding of what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of the pipeline style method, which includes two models, and the introduction of baseline models in the experiments. However, it does not specify which sections of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact parts that need attention. The comment is specific in its critique of the results and the introduction of baseline models, but it lacks grounding as it does not explicitly mention the sections where these issues are discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the pipeline style method, which includes two models, does not provide better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the performance of the pipeline style method, which includes two models, and the introduction of baseline models in the experiments. It points out that the method does not provide better average results for both XVNLI and MaRVL, which is a critical observation. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to improve the performance or introduce the baseline models more effectively. Without detailed feedback or recommendations, the authors are left with a general understanding of the issues but without a clear path to address them. Therefore, the comment is 3, as it highlights areas for improvement but does not provide sufficient detail or direction for the authors to make meaningful changes."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use their \"coarse\" methodology, which involves passing a binary stance classifier over ChatGPT\"s output, to make this observation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might improve their methodology or what specific changes they should consider. Without actionable suggestions or feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use their \"coarse\" methodology, which involves passing a binary stance classifier over ChatGPT\"s output, to make this observation. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, while it provides some context about the literature and the methodology, it lacks specific guidance on how the authors might improve their work. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use their \"coarse\" methodology, which involves passing a binary stance classifier over ChatGPT\"s output, to make this observation. The comment references the evolution of language models, from word2vec to BERT to ChatGPT, and suggests that the observation is not novel. However, the comment lacks specific references or detailed reasoning to substantiate the claim that the observation is not novel or that the methodology is inadequate. This makes the claim 3, as it provides some context but lacks comprehensive evidence or examples to fully support the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors for reproducing a wellknown result in the literature regarding left political bias in ChatGPT and LLMs in general. It questions the need for the authors to use their \"coarse\" methodology, which involves passing a binary stance classifier over ChatGPT\"s output, to make this observation. The comment points out that this observation has been made at each step of the evolution of language models, from word2vec to BERT to ChatGPT, and suggests that the authors should provide a more novel or insightful contribution. However, the comment lacks specific suggestions or guidance on how the authors might improve their work or what alternative approaches they could explore. While it identifies a potential weakness, it does not offer actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing [A]. This provides a clear and direct action for the authors to take, ensuring that their discussion of related work is comprehensive. The comment also specifies the type of work to include, which is concrete guidance. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work\" and \"modular networks for VQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: mentioning related work on modular networks for VQA. This provides clear guidance on how to improve the introduction, ensuring that it accurately reflects the current state of the field. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction does not accurately represent the current state of the field regarding modular architectures for VQA, as it does not mention related work on modular networks. The reviewer suggests that this omission creates a misleading impression. However, the comment does not provide specific examples of relevant work or detailed reasoning to support the claim. Without such evidence or references, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of related work on modular networks for VQA. This feedback is valuable as it highlights a potential gap in the introduction, which could lead to a more comprehensive and accurate representation of the current state of the field. By mentioning specific work, the comment offers a concrete step for the authors to take, ensuring that their draft is more thorough and uptodate. However, the comment could be more helpful if it provided additional context or examples of how this related work might be integrated into the discussion. Overall, the comment is 4 as it directs the authors toward a specific improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. While the comment highlights an area for improvement, it does not provide explicit guidance on how the authors should address this issue or suggest specific methods for comparison. The action is implicit and somewhat vague, as the authors are left to infer that they should include comparisons with these methods but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific area of focus in the paper, namely the authors\" emphasis on SSC and their lack of comparison with other subsequent methods like TSC and greedy subspace clustering by Park. However, it does not specify which part of the paper this observation is based on, such as a particular section or experiment. While the authors might infer that it relates to the methodology or results sections, the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in pointing out the need for comparisons with other methods, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. The comment provides a logical reasoning by pointing out the lack of comparison with other methods, which is a common practice in research papers. However, it does not provide specific examples or references to these subsequent methods, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks detailed evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as TSC and greedy subspace clustering by Park, which are computationally efficient and have similar guarantees. This feedback is clear and actionable, as it suggests that the authors should include comparisons with these methods to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to remove the statements about semantic segmentation being a lowlevel cue from the paper. This is a clear and direct action that the authors can take to address the comment. The feedback is specific and provides a concrete step for improvement, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of semantic segmentation being categorized as a lowlevel cue, suggesting that this categorization is incorrect. However, it does not specify which part of the paper discusses this categorization, making it weakly grounded. The comment is specific in its request to remove the statements about semantic segmentation being a lowlevel cue, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that \"semantic\" segmentation is not lowlevel since the categories are specified for each pixel. This claim is based on a logical reasoning that contradicts the categorization of semantic segmentation as a lowlevel cue. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to understand the context of the categorization to fully grasp the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the categorization of semantic segmentation as a lowlevel cue, suggesting that this categorization is incorrect. It provides a clear and actionable suggestion to remove the statements about semantic segmentation being a lowlevel cue from the paper. This feedback is valuable as it directs the authors to correct a potential misconception in their work, which could improve the accuracy and clarity of their claims. However, the comment could be more helpful if it provided additional context or examples to support the reasoning behind the categorization of semantic segmentation. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the validity of the claim that the proposed modules improve both accuracy and completeness, as stated in the table. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. While the comment implies that the authors should consider using a different dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the validity of a claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The suggestion to use an alternative dataset is specific, as it provides a concrete example of what could be done to address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the validity of a claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This is a logical suggestion to verify the claim, as it proposes a method to test the robustness of the results. However, the comment lacks specific reasoning or evidence to support why the current dataset may not be sufficient or why the suggested alternatives would be more appropriate. While the suggestion is reasonable, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the validity of a claim made in the paper regarding the improvement in accuracy and completeness of the proposed modules. It suggests using an alternative dataset, such as the training set of Tanks & Temples or ETH3D, for the ablation study. This feedback is 3 as it points out a potential weakness in the current dataset choice and provides a specific suggestion for improvement. However, the comment could be more helpful if it explained why the current dataset might not be suitable or how using an alternative dataset would enhance the study. Overall, the comment provides a direction for improvement but lacks depth and detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It suggests that previous work has considered multiple CVEs or CWEs simultaneously and questions whether the authors are arguing that identifying one vulnerability at a time is an intended use case. The comment also notes that the results are difficult to interpret or are marginal improvements at best. While the comment implies that the authors should address the ecological validity of their study and consider multiple vulnerabilities, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the specific changes needed to improve the study. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It references previous work that considers multiple CVEs or CWEs simultaneously and questions the authors\" approach. However, the comment does not explicitly mention which part of the paper discusses this methodology, making it weakly grounded. The comment is specific in detailing the issue with the methodology and suggesting that the results are difficult to interpret. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the ecological validity of the vulnerability discovery methodology, specifically the authors\" approach of considering a single vulnerability at a time. The reviewer references previous work that considers multiple CVEs or CWEs simultaneously and suggests that the results are difficult to interpret or are marginal improvements at best. This claim is 3 as it provides a logical reasoning based on the comparison with previous work, but it lacks specific examples or detailed references to substantiate the claim fully. The authors would need to explore the referenced literature to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a significant concern about the vulnerability discovery methodology used in the paper. It questions the ecological validity of considering a single vulnerability at a time, noting that previous work has considered multiple CVEs or CWEs simultaneously. The comment also points out that the results are difficult to interpret or are marginal improvements at best. This feedback is valuable as it highlights a potential limitation in the study\"s methodology and suggests that the authors should consider a more comprehensive approach. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of alternative methodologies. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for more explanation regarding how a small degree of bias can be obtained from a clear community structure. It references Theorem 1 and 2, which prove that GCL conforms to a clearer community structure, but notes that the relationship with degree bias is not intuitive enough. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how to address this issue or suggest specific steps for improvement. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the need for more explanation regarding the relationship between a small degree of bias and a clear community structure, as well as the lack of intuitive understanding of the relationship between GCL and degree bias. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the relationship between a small degree of bias and a clear community structure is not intuitive enough, despite Theorem 1 and 2 proving that GCL conforms to a clearer community structure. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed explanation or references leaves the claim 3, as it requires more information to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the relationship between a small degree of bias and a clear community structure needs more explanation. It references Theorem 1 and 2, which prove that GCL conforms to a clearer community structure, but notes that the relationship with degree bias is not intuitive enough. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the relationship between these concepts. However, the comment could be more helpful if it offered specific suggestions on how to enhance the explanation or provided examples of similar approaches in the literature. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to understand, but it also notes that the writing is generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and more explanations for Algorithm 1, including brief sentences defining A_t, Y_t, and so on. While the comment implies that the authors should provide more details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment acknowledges that the paper deals with many graph notions, which can make it challenging to understand, but it also notes that the writing is generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and more explanations for Algorithm 1, including brief sentences defining A_t, Y_t, and so on. However, the comment does not specify which part of the paper these suggestions pertain to, such as a particular section or chapter. While the authors might infer that it relates to the sections discussing graph notions or algorithms, the lack of explicit grounding makes it difficult to pinpoint the exact parts that need attention. The comment is specific in suggesting what details could be added, but it is weakly grounded due to the absence of explicit references. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that the paper deals with many graph notions, which can make it challenging to understand, but it also notes that the writing is generally good. It suggests that more details could be provided, specifically mentioning the definition of the resistance distance and more explanations for Algorithm 1, including brief sentences defining A_t, Y_t, and so on. However, the comment does not provide specific examples or references to support the claim that more details are needed, making it 3. The authors would need to infer the specific areas that require more detail, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the paper deals with many graph notions, which can make it challenging to understand, but it also notes that the writing is generally good. It provides specific suggestions for improvement, such as providing more details on the definition of the resistance distance and offering more explanations for Algorithm 1, including brief sentences defining A_t, Y_t, and so on. This feedback is clear and actionable, as it identifies areas where additional details could enhance the paper\"s clarity and accessibility. However, the comment could be more helpful if it included specific examples or references to guide the authors in implementing these suggestions. Overall, the comment is 4 as it provides valuable insights for improving the draft, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is not new. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the originality of their work. There is no explicit or implicit action for the authors to take, leaving them without any direction on how to enhance the originality of their paper. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is not new. However, it does not specify which part of the paper this claim pertains to, such as a specific section or methodology. Without explicit references to sections or elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the originality are lacking or how the authors could address these issues. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is not new. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or references to existing works that have already explored variable splitting or similar algorithms, the claim remains 1. The authors are left without a clear understanding of why the originality is limited or how to address this issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is not new. However, it does not provide any specific examples or references to existing works that have already explored variable splitting or similar algorithms. Without detailed guidance or suggestions for improvement, the comment lacks actionable feedback that could help the authors enhance the originality or novelty of their work. As a result, the comment is 1, as it does not offer any constructive direction for the authors to address the issue raised."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the evaluation of shape model invariance, specifically questioning whether the results on transformations of training images are sufficient to prove the point. It suggests that quantitative results on testing images might be needed to fully validate the claim. While the comment implies that the authors should provide such results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the evaluation or what metrics to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the sufficiency of the evaluation on transformations of training images and suggests that quantitative results on testing images might be needed. This provides clear guidance on what aspect of the study needs further evaluation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the sufficiency of the evaluation on transformations of training images for proving shape model invariance. It suggests that quantitative results on testing images might be necessary. However, the comment does not provide specific examples, references, or detailed reasoning to support why testing images are crucial or how they would provide additional evidence. The lack of detailed justification makes the claim 3, as the authors would need to infer the importance of testing images based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of shape model invariance, questioning whether the results on transformations of training images are sufficient to prove the point. It suggests that quantitative results on testing images might be necessary to fully validate the claim. This feedback is clear and actionable, as it directs the authors to consider an additional aspect of their evaluation that could strengthen their findings. However, the comment could be more helpful if it provided specific suggestions on how to conduct the evaluation on testing images or what metrics to use. Overall, the comment is 4, as it guides the authors toward a potential improvement in their study, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss and compare their work with the AAAI15 paper by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. This feedback is explicit and provides a clear action for the authors to take, which is to include a discussion and comparison with this related work. The comment also specifies the reason for this action, highlighting the relevance of the AAAI15 paper to the authors\" work. Therefore, the comment is 5, as it gives the authors a concrete step to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the AAAI15 paper by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, a discussion and comparison of the authors\" work with the AAAI15 paper. This provides clear guidance on how to improve the paper by incorporating a relevant related work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the AAAI15 paper by Ghoshdastidar and Dukkipati is a related work that should be discussed and compared to provide a better understanding of the stateoftheart. The comment provides a specific reference to the AAAI15 paper, which is a clear and explicit source of evidence supporting the claim. This makes the claim 4, as it offers a concrete reference for the authors to consider. However, the comment could be strengthened by providing more detailed reasoning or examples of how the AAAI15 paper relates to the current work, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential gap in the authors\" work by pointing out a related paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data using tensors. The comment suggests that this paper should be discussed and compared to provide a better understanding of the stateoftheart. This feedback is clear and actionable, as it directs the authors to include a relevant related work in their discussion, which can enhance the comprehensiveness and depth of their analysis. However, the comment could be more helpful if it provided specific guidance on how to integrate this comparison into the paper or highlighted key aspects to focus on. Overall, the comment is 4, as it offers a valuable direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the scalability of the method for computing optimal transport distance and questions the approach used to compute it. It explicitly asks for an evaluation of the method\"s scalability on normal machines with a few cores and inquires about the process of converting a doubly stochastic matrix into optimal transport. These questions provide clear and specific actions for the authors to take, such as testing the method\"s scalability and clarifying the conversion process. The feedback is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the scalability of the method and questions the approach used to compute optimal transport, specifically asking about the Sinkhorn method and how it relates to optimal transport. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the scalability of the method for computing optimal transport distance and questions the approach used to compute it. The reviewer points out that the Sinkhorn method provides a doubly stochastic matrix, but it is not clear how this relates to optimal transport. The comment suggests that the authors should clarify the scalability of their method and the conversion process from a doubly stochastic matrix to optimal transport. While the comment identifies areas for clarification, it lacks specific examples or references to support the claim about scalability or the conversion process. This makes the claim 3, as it provides a direction for improvement but requires more detailed justification or evidence.", "helpfulness_rationale": "The review comment raises important concerns about the scalability of the method for computing optimal transport distance and questions the approach used to compute it. It specifically asks for an evaluation of the method\"s scalability on normal machines with a few cores and inquires about the process of converting a doubly stochastic matrix into optimal transport. These questions are clear and actionable, providing the authors with specific areas to address and improve their draft. By seeking clarification on these points, the authors can enhance the comprehensiveness and robustness of their work. Therefore, the comment is 4, as it offers constructive feedback that can guide the authors in making significant improvements to their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment indicates that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on how the authors might clarify or simplify the experimental procedures or evaluations to make the paper more accessible. Without actionable advice or specific recommendations, the authors are left without a clear path to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, it does not specify which part of the paper is particularly challenging to follow, making it weakly grounded. The comment is specific in identifying the issue with understanding the experimental procedures and evaluations, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the paper is difficult to follow, specifically mentioning issues with understanding the experimental procedures and evaluations. However, it does not provide any specific suggestions or guidance on how the authors might improve the clarity or organization of their work. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issues raised. Therefore, the comment is 1, as it does not offer any constructive direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should introduce specific aspects of the model that are relevant to the example model being discussed. It provides a concrete example of what should be clarified, such as the fact that the model operates in a setting with finite subdivisions for certain parameters and that some parameters are bounded on one side. This feedback is explicit and provides clear guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 132, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be introduced, namely the specific aspects of the model that are relevant to the example model being discussed. The comment specifies that certain parameters are bounded on one side and that the model operates in a setting with finite subdivisions. This level of detail provides the authors with a clear understanding of what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify specific aspects of the model, such as the finite subdivisions for certain parameters and the boundedness of parameters like acceleration and scaling. This feedback is based on logical reasoning, as it highlights potential areas of confusion or misunderstanding for readers. However, the comment does not provide specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is 3, as it provides a logical basis for the suggestion but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors introduce the aspects of the specific model that are specific to the example model being discussed. It highlights the need to clarify that the model operates in a setting with finite subdivisions for certain parameters and that some parameters are bounded on one side. This feedback is clear and offers a concrete way for the authors to enhance the clarity and comprehensiveness of their draft. By addressing these points, the authors can improve the readability and understanding of their work for the audience. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the required condition on the learning rate, specifically its scalability and the unrealistic nature of the condition. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the practicality of the condition. While the comment identifies an issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider the condition or find an alternative approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the required condition on the learning rate, specifically its scalability and the unrealistic nature of the condition. However, it does not explicitly mention which part of the paper discusses this condition, making it weakly grounded. The comment is specific in detailing the issue with the condition and the need for a more realistic approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the required condition on the learning rate (scaling with the number of samples) is not scalable and is not seen in practice. The reviewer provides a logical reasoning by stating that this condition would lead to unreasonably large learning rates when working with largescale datasets. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the reasoning and potentially conduct further research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the required condition on the learning rate, noting that it is not scalable and is not seen in practice. It highlights the concern that this condition would lead to unreasonably large learning rates when working with largescale datasets. The reviewer acknowledges the need for a way to characterize the benefit of large learning rates but questions the practicality of the current condition. While the comment points out a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or explore alternative approaches. The feedback is 3 as it prompts the authors to reconsider the condition, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about sampling from the DPP when the eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. The reviewer compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify the sampling process or provide additional information, but without concrete steps or examples, the action remains unclear. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (10) line 130,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible. The comment further compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. The reviewer compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. However, the comment lacks specific examples or references to support the claim that sampling from the DPP is more difficult than from the leverage score. This makes the claim 3, as it provides a logical comparison but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, as mentioned in Equation (10) on line 130. It compares this issue to sampling from the leverage score, suggesting that it may not be easier than sampling from the leverage score. This feedback is clear and actionable, as it points out a potential area of confusion in the paper and prompts the authors to clarify the sampling process. However, the comment could be more helpful if it provided additional guidance or suggestions on how to address this issue, such as recommending specific methods or examples to clarify the sampling process. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment provides feedback on the abstract, noting that it effectively explains the proposed idea but lacks description of how the idea was evaluated and what the outcome was. It also mentions minor language issues. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made to improve the abstract. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details on evaluation and outcomes, but they are not given concrete steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of description of how the proposed idea was evaluated and what the outcome was, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the abstract effectively explains the proposed idea but lacks description of how the idea was evaluated and what the outcome was. This is a subjective opinion that requires justification, as it suggests that the abstract is incomplete in terms of evaluation and outcome. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 2, as it lacks sufficient evidence or reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific weakness in the abstract, noting that it effectively explains the proposed idea but lacks description of how the idea was evaluated and what the outcome was. This feedback is clear and actionable, as it directs the authors to enhance the abstract by including details on the evaluation and outcomes of their proposed idea. However, the comment could be more helpful if it provided suggestions on how to effectively present this information in the abstract. Overall, the comment is 4 as it highlights a critical area for improvement and guides the authors toward enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses skepticism about the experimental results and questions the usefulness of the experiments section. It points out that the paper aims to solve POMDP problems with nonconvex value functions but does not provide experiments on the specific settings mentioned, such as surveillance in museums with thresholded rewards or privacypreserving data collection. The comment implies that the authors should include experiments on these settings to better motivate their solution. However, it does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors can infer that they need to add experiments but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"POMDP problem with nonconvex value function,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the lack of experiments on specific settings, such as surveillance in museums with thresholded rewards or privacypreserving data collection. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses skepticism about the experimental results, questioning the usefulness of the experiments section. It suggests that the paper should include experiments on specific settings, such as surveillance in museums with thresholded rewards or privacypreserving data collection, to better motivate the solution. However, the comment lacks specific examples or detailed reasoning to support why these experiments are necessary or how they would improve the paper. The lack of concrete evidence or detailed justification makes the claim 3, as the authors would need to infer the importance of these experiments based on the general critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a significant concern about the experimental results, questioning their relevance and usefulness. It points out that the paper aims to solve POMDP problems with nonconvex value functions but does not provide experiments on specific settings mentioned, such as surveillance in museums with thresholded rewards or privacypreserving data collection. This feedback is clear and actionable, as it highlights a gap in the experimental section that the authors need to address to better motivate their solution. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these experiments or what additional data or analysis would be beneficial. Overall, the comment is 4 as it identifies a critical area for improvement and guides the authors toward enhancing the experimental section of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. While the comment identifies specific areas that need attention, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors are left to infer that they should include these citations and algorithms, but the comment lacks detailed guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not provide direct steps for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"your code\" and \"the details in the article,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the incremental nature of the contribution, the lack of citation for key baselines, and the absence of essential RAG algorithms like MedRetriever and KGRAG. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the contribution of the article is incremental, stating that it is essentially a combination of GraphRAG and GraphCare. It also points out the lack of citation for key baselines and suggests that essential RAG algorithms like MedRetriever and KGRAG should have been introduced. While the comment provides some reasoning by referencing specific algorithms, it lacks detailed justification or examples to fully substantiate the claim about the incremental nature of the contribution. The mention of specific algorithms and baselines adds some support, but the overall justification is not robust. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, identifying several areas for improvement. It highlights the incremental nature of the contribution, noting that it is essentially a combination of existing methods like GraphRAG and GraphCare. The comment also points out the lack of citation for key baselines and suggests that essential RAG algorithms, such as MedRetriever and KGRAG, should have been introduced. This feedback is valuable as it helps the authors understand the limitations of their work and provides specific suggestions for enhancing the paper. However, the comment could be more helpful if it offered guidance on how to integrate these algorithms or provided examples of how to improve the contribution. Overall, the comment is 4 as it identifies clear areas for improvement and offers actionable suggestions, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include a graph showing the plot of T versus the number of images and Expectation(T) over the ImageNet test set. This provides a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the draft. The comment also offers a rationale for why this information is important, which further clarifies the action. Therefore, the comment is 5, as it provides explicit guidance and concrete details on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a graph showing the plot of T versus the number of images and Expectation(T) over the ImageNet test set. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added to the paper, namely, a graph to understand the performance improvement and whether it stems from the network design or the nature of ImageNet. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a graph showing the plot of T versus the number of images and Expectation(T) over the ImageNet test set. The reviewer provides a logical reasoning for why this information is important, stating that it would help understand whether the performance improvement stems from the network design or the nature of ImageNet. However, the comment lacks specific references or examples to support the claim that the nature of ImageNet provides an unfair advantage. While the reasoning is clear, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include a graph showing the plot of T versus the number of images and Expectation(T) over the ImageNet test set. This request is clear and directly addresses a gap in the paper, offering a concrete way for the authors to enhance their analysis and understanding of the performance improvement. The comment also raises an important question about whether the performance improvement is due to the network design or the nature of ImageNet, which is a valuable consideration for the authors to explore. However, the comment could be more helpful if it provided additional context or examples to further guide the authors in interpreting the results. Overall, the feedback is 4 as it offers clear and actionable suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, as shown in Figure 5. It suggests that the proposed method might be more effective under scenarios where the training and evaluation timesteps are different. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve the draft. The action is implicit and somewhat vague, as it leaves the authors to infer that they should explore scenarios with different timesteps but does not specify how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of the proposed methods when the training and evaluation timesteps are the same. The comment suggests that the proposed method might be more effective under scenarios where the training and evaluation timesteps are different. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed methods is questionable when the training and evaluation timesteps are the same, as shown in Figure 5. The reviewer suggests that the proposed method might be more effective under scenarios where the training and evaluation timesteps are different. However, the comment lacks specific examples or detailed reasoning to support this claim. It provides a logical suggestion but does not fully substantiate the claim with evidence or references, making it 3. The authors would need to explore this suggestion further to fully understand and address the issue.", "helpfulness_rationale": "The review comment raises a valid concern about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, as shown in Figure 5. It questions the significance of the proposed methods in achieving good performance when the timesteps are identical. The comment suggests that the proposed method might be more effective under scenarios where the training and evaluation timesteps are different. This feedback is clear and actionable, as it prompts the authors to explore and discuss scenarios where the timesteps differ, potentially leading to a more comprehensive understanding of the method\"s effectiveness. However, the comment could be more helpful if it provided specific examples or suggestions on how to address this issue. Overall, the comment is 4, as it identifies a potential weakness and offers a direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the clarity of how disentanglement is guaranteed in the paper. It suggests that while the \"Broader Impacts and Limitations\" section mentions disentanglement as a limitation, it is still important to highlight how disentanglement is realized and guaranteed without certain bias types. This feedback provides a clear and explicit action for the authors to take, which is to further elaborate on the disentanglement process and its guarantees. The comment is specific and provides a concrete direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed and suggesting that the authors highlight how disentanglement is realized without certain bias types. However, it does not specify which part of the paper discusses disentanglement, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding disentanglement, such as highlighting how it is realized and guaranteed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which mentions disentanglement as a limitation, but suggests that further explanation is needed. The comment provides a logical reasoning by pointing out the importance of highlighting how disentanglement is realized and guaranteed without certain bias types. However, it lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to provide additional information to fully address the concern, hence the label 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how disentanglement is guaranteed in the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions disentanglement as a limitation, it is still important to highlight how disentanglement is realized and guaranteed without certain bias types. This feedback is clear and actionable, as it directs the authors to provide more detailed information on the disentanglement process and its guarantees. By addressing this point, the authors can enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it provided specific suggestions on how to present this information or examples of what to include. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. While the comment implies an action, it does not provide specific details on which regularization trick to use or how to implement it. The authors can infer that they need to incorporate a standard regularization technique, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Without explicit references, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in its recommendation to use a standard regularization trick but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. While it identifies a potential area for improvement, it lacks specific guidance or examples on which regularization trick to use or how to implement it. The comment provides a general direction but does not offer detailed, actionable advice, leaving the authors with a vague understanding of what needs to be done. Therefore, the comment is 3, as it points out a possible enhancement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the handling of different types of inputs, such as biomedical signals or speech, and suggests that the authors should discuss and present their solutions in the paper. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to do so or what aspects of the solutions should be discussed. The mention of \"citation\" being \"a bit disordered\" is vague and does not offer actionable advice. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement the suggested changes.", "grounding_specificity_rationale": "The comment raises a concern about the handling of different types of inputs, such as biomedical signals or speech, and suggests discussing and presenting solutions in the paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting that the authors should discuss and present their solutions regarding different types of inputs. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the handling of different types of inputs, such as biomedical signals or speech, and suggests discussing and presenting solutions in the paper. However, the comment does not provide specific examples or detailed reasoning to support why this is an issue or how it could be addressed. The mention of \"citation\" being \"a bit disordered\" is vague and lacks context. Without additional information or examples, the claim is difficult for the authors to understand and address, making it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should discuss and present their solutions for handling different types of inputs, such as biomedical signals or speech. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that could enhance its applicability and relevance. However, the comment could be more helpful if it provided specific examples or suggestions on how to approach this discussion or solution. Despite this, the feedback is 4 as it guides the authors toward a meaningful enhancement of their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the generalization of their model. The action is implicit and vague, as the authors are left to infer that they need to explore alternative methods or improve the template mapping process. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the question answering process, namely the use of template mapping to transform questions into masked statements. However, it does not specify which part of the paper discusses this process, making it weakly grounded. The comment is specific in detailing the potential issue with generalization for questions that are not \"Whtypes\" or transformable. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process might cause poor generalization due to the use of template mapping to transform questions into masked statements. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to similar cases or studies that demonstrate the potential issue with generalization. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient support for the authors to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization for questions that are not \"Whtypes\" or transformable. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or explore alternative methods. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or recommendations. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant drop in accuracy scores (from 70.4 to 55.6) after implementing the ICLHAR, which is a method aimed at improving consistency and verifiability. The comment suggests that this issue should be discussed or acknowledged in more detail in the main text. While the action is explicit, it lacks concrete guidance on how to discuss or acknowledge this issue in detail. The authors are given a clear direction to address the problem but may not be entirely sure of the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ICLHAR, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the significant drop in accuracy scores (from 70.4 to 55.6 on TRIP) and suggests that this should be discussed or acknowledged in more detail. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the implementation of ICLHAR has significantly impacted the accuracy scores, specifically noting a drop from 70.4 to 55.6 on TRIP. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant drop in accuracy scores (from 70.4 to 55.6) after implementing the ICLHAR method, which is aimed at improving consistency and verifiability. It suggests that this issue should be discussed or acknowledged in more detail in the main text. This feedback is clear and actionable, as it highlights a potential tradeoff between consistency and accuracy that the authors should address. By pointing out this issue, the comment provides the authors with a specific area to focus on and improve their draft. However, it could be more helpful if it offered suggestions on how to discuss or acknowledge this tradeoff effectively. Overall, the comment is 4, as it directs the authors to a critical area that requires further exploration and clarification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to cite the source of the rockpaperscissors example, which is clearly inspired by an example from previous work. This is a direct and concrete action, leaving no ambiguity about what the authors need to do. The comment provides a clear and specific instruction, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rockpaperscissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by pointing out that the example is inspired by previous work and requests appropriate citation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rockpaperscissors example is inspired by an example from previous work and requests appropriate citation. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to verify the claim or identify the source of inspiration. Without detailed evidence or references, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rockpaperscissors example is inspired by an example from previous work and requests appropriate citation. This feedback is clear and actionable, as it directs the authors to address a potential issue with plagiarism or lack of attribution. By citing the original source, the authors can ensure proper credit and avoid any potential ethical or academic integrity concerns. However, the comment could be more helpful if it provided examples of similar work or suggested how to integrate the citation into the text. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that comparing the performance of the model only pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors. It also specifies that the authors should provide the performance of the models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. The explicit nature of the action and the detailed suggestion make this comment 5.", "grounding_specificity_rationale": "The comment suggests that comparing the performance of the model only pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors. It also specifies that the authors should provide the performance of the models pretrained on synthetic data but finetuned on realworld datasets with different losses. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental results or methodology sections. The suggestion is specific in detailing what needs to be addressed, making the comment weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that comparing the performance of the model only pretrained on synthetic data is unfair and suggests that demonstrating the importance of the proposed three projection errors is more appropriate. The comment provides a logical reasoning by suggesting that the performance should be evaluated on realworld datasets with different losses. However, it lacks specific examples or references to support the claim that the current approach is unfair or to substantiate the suggestion for alternative evaluations. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that comparing the performance of the model only pretrained on synthetic data is unfair. It suggests that the authors should instead demonstrate the importance of the proposed three projection errors by providing the performance of the models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is clear and actionable, offering a specific suggestion for improving the experimental design and analysis. By addressing this point, the authors can enhance the validity and comprehensiveness of their results. Therefore, the comment is rated as 5, as it provides detailed guidance that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is an implicit action. It also encourages the authors to discuss the difference between their method and traditional methods. While the comment provides a clear direction for improvement, it does not specify how to conduct the calibration curves or what specific aspects of the difference should be discussed. The authors can infer the actions but may need guidance on how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"model AUC\" and \"calibration curves,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the consistency between predicted scores and actual risks, and suggests conducting calibration curves to demonstrate this consistency. Additionally, it encourages discussing the difference between the traditional method and the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model AUC can assess discriminant ability but may not show consistency between predicted scores and actual risks, which is crucial for clinical scoring systems. The reviewer encourages the use of calibration curves to demonstrate this consistency. While the comment provides a logical reasoning for the need to show consistency, it lacks specific examples or references to support the claim. The suggestion to discuss the difference between the traditional method and the proposed method is also not fully substantiated. Therefore, the comment is 3, as it provides a reasonable argument but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential limitation in the model\"s ability to assess discriminant ability, specifically the lack of consistency between predicted scores and actual risks. It suggests that calibration curves could be used to demonstrate this consistency, which is a valuable suggestion for improving the paper. Additionally, the comment encourages the authors to discuss the difference between their method and traditional methods, which could provide a more comprehensive understanding of the work. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to conduct the calibration curves or discuss the differences. Overall, the feedback is 4 as it offers clear directions for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of insight into why all sparsity patterns perform similarly and suggests that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. It also points out a typo in the text, suggesting a correction. While the comment identifies a potential area for further exploration and provides a specific correction, it does not offer explicit guidance on how the authors should address the lack of insight or conduct further analysis. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the reasons behind the similar performance of sparsity patterns and consider whether this is a unique aspect of the sparsity detection problem or a general characteristic of GNNs. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of insight into why all sparsity patterns perform similarly and suggesting that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. Additionally, it corrects a typo in the text. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of insight into why all sparsity patterns perform similarly and suggests that this might be a unique aspect of the sparsity detection problem or a general characteristic of GNNs. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that all sparsity patterns seem to perform similarly without providing insight into why this is the case. It raises a question about whether this is a unique aspect of the sparsity detection problem or a general characteristic of GNNs. This feedback prompts the authors to consider the implications of their findings and potentially explore further analysis or discussion to provide a deeper understanding of the results. Additionally, the comment points out a typo in the text, which is a minor but important correction. However, the comment could be more helpful if it offered suggestions on how to address the lack of insight or provided specific guidance on what additional analysis might be beneficial. Overall, the comment is 3 as it highlights an area for improvement and provides a specific correction, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide a more robust justification for using Shapely values over other methods, such as CaCE or raw gradients, by conducting experimental comparisons. It also recommends including a significant discussion on the advantages and disadvantages of different methods for transforming highdimensional data to lowdimensional latent space. While the comment implies that the authors should conduct additional experiments and provide a more comprehensive discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Shapely values\" and \"other methods,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as comparing Shapely values with other methods like CaCE or raw gradients, and discussing the advantages and disadvantages of different methods for transforming highdimensional data. This level of detail provides clear guidance on what the authors need to improve, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a more robust justification for using Shapely values over other methods, such as CaCE or raw gradients, by conducting experimental comparisons. It also recommends including a significant discussion on the advantages and disadvantages of different methods for transforming highdimensional data to lowdimensional latent space. While the comment provides a logical reasoning for the need to compare methods and discuss their advantages, it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to provide additional evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should provide a more robust justification for using Shapely values over other methods, such as CaCE or raw gradients. It also recommends including a significant discussion on the advantages and disadvantages of different methods for transforming highdimensional data to lowdimensional latent space. This feedback is clear and actionable, as it guides the authors on how to strengthen their argument and enhance the comprehensiveness of their paper. However, the comment could be more helpful if it provided specific examples or references to support the suggested comparisons or discussions. Overall, the comment is 4, as it offers valuable insights for improving the draft, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that the authors should include a comparison or discussion of their work in relation to existing literature, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a comparison or discussion. However, the comment provides a clear direction on what needs to be addressed, making it 4.", "grounding_specificity_rationale": "The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 is being addressed, making it weakly grounded. The comment is specific in suggesting a comparison with prior efforts, which provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, the comment does not provide specific examples or references to support this claim, nor does it explain why such a comparison is necessary or beneficial. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is 3 as it points out a specific aspect of the paper that could be strengthened through a comparative analysis. However, the comment lacks detailed guidance on how to conduct this comparison or what specific aspects should be highlighted. While it provides a direction for improvement, it does not offer comprehensive or actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the performance is likely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not provide explicit instructions on how to conduct this analysis or what specific steps the authors should take to address this suggestion. The action is implicit and somewhat vague, as the authors can infer that they need to explore the impact of varying the number of scenarios, but they are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the performance is likely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or analysis. The authors can infer that it relates to the experimental setup or results, but the comment lacks full grounding as it does not explicitly mention a specific part of the paper. It is specific in suggesting an area for further exploration, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the performance is likely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the performance of the model is likely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. This feedback is 3 as it identifies a potential area for further exploration and improvement in the paper. However, it lacks specificity and does not provide detailed guidance on how to conduct this analysis or what specific aspects of the performance should be examined. While it points out a relevant area for investigation, the comment could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not provide any explicit or implicit suggestions for improvement or areas that need further exploration. Without any actionable feedback or guidance, the authors are left without a clear understanding of what aspects of their work could be enhanced or how to address any potential limitations. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not specify which part of the paper these experiments are discussed in, nor does it provide any specific feedback or suggestions for improvement. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not express any opinions, judgments, or suggestions that require verification. It is purely descriptive, making it a factual statement without a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not provide any feedback, suggestions, or critique that could help the authors improve their work. Without any actionable advice or guidance, the comment lacks value and does not assist the authors in enhancing their draft. Therefore, it is rated as 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with Appendix A.2, noting that it does not clearly illustrate the state space representation of the environment. However, it does not provide any explicit or implicit guidance on how to address this issue or improve the clarity of the representation. The authors are left without any actionable steps to take, such as suggestions for additional explanations, examples, or changes to the representation. Without specific instructions or examples, the comment lacks actionability, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be addressed in the appendix. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of the state space representation of the environment in Appendix A.2. This feedback is 3 as it points out a particular area that needs improvement, allowing the authors to focus their attention on enhancing the clarity of their representation. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the issue, such as what aspects of the representation need clarification or how to improve its presentation. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation of the authors\" approach, stating that it is only applicable for small or mediumscale problems and that largescale problems may overwhelm current LPsolvers. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their approach to handle largerscale problems. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the authors\" approach, stating that it is only applicable for small or mediumscale problems and that largescale problems may overwhelm current LPsolvers. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the approach need to be improved or how the authors might address this limitation. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors\" approach is only applicable for small or mediumscale problems, and that largescale problems may overwhelm current LPsolvers. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation of the authors\" approach, noting that it is only applicable for small or mediumscale problems and may struggle with largescale problems. However, it does not provide any suggestions or guidance on how the authors might address this limitation or improve their approach to handle largerscale problems. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a common assumption in stochastic optimization literature, namely the bounded noise assumption, and notes that it is somewhat restrictive. It further mentions that there have been efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not provide explicit guidance or suggestions for the authors on how to address this issue in their own work. While it identifies a potential area for improvement, it lacks actionable details on how the authors should incorporate these extensions or address the bounded noise assumption. Therefore, the comment is 3, as it points out a limitation but does not offer concrete steps for improvement.", "grounding_specificity_rationale": "The comment addresses the bounded noise assumption, which is a common practice in stochastic optimization literature. It mentions that there have been efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\"arik, and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not specify which part of the paper discusses the bounded noise assumption, making it weakly grounded. The authors can infer that it relates to the theoretical or methodological sections, but this inference is not explicit. The comment is specific in detailing the issue with the bounded noise assumption and providing references to works that have addressed it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounded noise assumption is somewhat restrictive in stochastic optimization literature and references specific works that have made efforts to extend these noise conditions. The inclusion of references to these works provides some support for the claim, making it 3. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a common assumption in stochastic optimization literature, namely the bounded noise assumption, and notes that it is somewhat restrictive. It provides references to specific works that have made efforts to extend these noise conditions, which is a valuable contribution to the discussion. However, the comment does not offer specific guidance or suggestions on how the authors might address this issue in their own work, such as recommending particular extensions or methods to consider. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity for the authors to effectively improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the motivation behind using characteristic function regularization is unclear. However, it does not provide any explicit or implicit suggestions on how the authors might clarify this motivation or improve the clarity of their explanation. Without guidance on what specific aspects of the motivation are unclear or how to address this issue, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the overall motivation for using characteristic function regularization, but it does not specify which part of the paper this issue pertains to, such as a specific section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being discussed. Additionally, the comment lacks specificity because it does not provide details on what aspects of the motivation are unclear or how they could be clarified. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the overall motivation for using characteristic function regularization is unclear. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a critical issue with the paper, noting that the overall motivation for using characteristic function regularization is unclear. This is an important observation that could impact the paper\"s clarity and impact. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might clarify this motivation or improve the explanation. Without actionable feedback or examples, the authors are left without a clear path to address the issue. Therefore, the comment is 2, as it highlights a significant weakness but does not offer meaningful guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the paper for being limited to a combination of existing techniques, suggesting that the contribution is incremental. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to enhance the originality or novelty of the work, nor are there suggestions for potential areas of improvement or additional contributions. As a result, the comment lacks any actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the paper for being limited to a combination of existing techniques, specifically mentioning the adaptation to an unknown level of corruption (Lykouris et al., 2018), varying variances treated with a weighted version of OFUL (Zhou et al., 2021), and variable decision sets (standard in contextual linear bandits). However, it does not specify which part of the paper these techniques are discussed in, making it weakly grounded. The comment is specific in detailing the combination of existing techniques and the perceived lack of originality, but it lacks grounding as it does not direct the authors to a specific section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is limited to a combination of existing techniques, which is not surprising and thus considered incremental. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the assertion. Without additional context or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the paper for being limited to a combination of existing techniques, suggesting that the contribution is incremental. While it identifies a potential weakness in the originality of the work, it lacks actionable feedback or suggestions for improvement. The comment does not provide guidance on how the authors might enhance the novelty or originality of their work, nor does it offer specific areas for further exploration or development. As a result, the comment is not particularly helpful, as it does not offer constructive feedback that could assist the authors in improving their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the aggregation operation after \"Integration\" in the main paper. It also suggests acknowledging the structure of other architectures if they are referred to. This feedback is clear and provides specific actions for the authors to take, making it 5. The authors know exactly what needs to be done to address the comment, ensuring a clear path for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Multiscale modeling,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by requesting further clarification on the aggregation operation after \"Integration\" and suggesting the inclusion of more details in the main paper. Additionally, it advises acknowledging the structure of other architectures if they are referred to. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the aggregation operation after \"Integration\" needs further clarification and requests more details in the main paper. It also advises acknowledging the structure of other architectures if they are referred to. However, the comment does not provide specific examples or references to support the claim that the aggregation operation is unclear or how it should be clarified. Without detailed justification or examples, the authors may find it challenging to understand the exact nature of the issue and how to address it. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the aggregation operation after \"Integration\" in the context of multiscale modeling. It suggests that the authors provide more details in the main paper and, if referring to other architectures, acknowledge their structure properly. This feedback is clear and actionable, as it directs the authors to clarify a particular aspect of their work and ensures transparency in referencing other architectures. By addressing these points, the authors can enhance the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it provided specific suggestions on how to clarify the aggregation operation or examples of how other architectures are acknowledged. Overall, the comment is 4, as it guides the authors toward improving their draft but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the novelty of using energy models for image generation compared to GANs and VAEs, and encourages the authors to explore this area further. However, it also points out that the motivation and goals of the model are similar to those of a prior VAE paper, as discussed in the related work review. While the comment highlights a potential overlap with existing work, it does not provide specific guidance on how the authors should address this issue or differentiate their work. The action is implicit and somewhat vague, as it suggests exploring the energy model approach but does not specify how to do so or how to distinguish the work from the prior VAE paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of energy models for image generation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the motivation and goals of the model are similar to those of a prior VAE paper, as discussed in the related work review. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of energy models for image generation is less explored compared to GANs and VAEs, and suggests that the motivation and goals of the model are similar to those of a prior VAE paper. The comment provides a logical reasoning by comparing the model to existing work, which is a common practice in the field. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to explore the related work section to fully understand the basis of the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the novelty of using energy models for image generation compared to GANs and VAEs, and encourages the authors to explore this area further. It also points out a potential overlap with a prior VAE paper, suggesting that the motivation and goals of the model are similar. This feedback is valuable as it highlights a potential area for differentiation and improvement in the paper. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this overlap or differentiate their work. Overall, the comment is 3 as it identifies a potential issue and encourages further exploration, but it lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly recommends running experiments on a different benchmark, such as Atari, to evaluate the method\"s generalizability to other domains. It also suggests verifying the method\"s performance with discrete action spaces and highdimensional observations. This feedback provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The suggestion is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation being conducted only on the tasks from Meta World, a robotic manipulation domain. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests running experiments on a different benchmark, such as Atari, to evaluate generalizability and verify the method\"s performance with discrete action spaces and highdimensional observations. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited to a single domain, Meta World, and suggests running experiments on a different benchmark like Atari to assess generalizability. The comment provides a logical reasoning for the need to evaluate on multiple domains, as it would help determine the method\"s applicability to other domains. However, it lacks specific references or examples of how Atari or other benchmarks could be used to verify the method\"s performance with discrete action spaces and highdimensional observations. While the suggestion is logical, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the method, noting that it is only tested on tasks from the Meta World domain, a robotic manipulation domain. It suggests running experiments on a different benchmark, such as Atari, to assess the method\"s generalizability and performance in other domains. Additionally, it recommends verifying the method\"s performance with discrete action spaces and highdimensional observations, which are common in Atari games. This feedback is clear and actionable, providing the authors with specific suggestions to enhance the robustness and applicability of their work. By addressing these points, the authors can significantly improve the comprehensiveness and validity of their evaluation. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the method is presented well and the experiments are good and complete, but it suggests that the paper lacks analysis on what the model does, which could be interesting. However, it does not provide specific guidance on how to conduct this analysis or what aspects of the model should be explored. The comment implies that the authors should consider the feedback or suggestions provided, but it does not specify what those suggestions are. As a result, the action is implicit and somewhat vague, leaving the authors with a general direction but without concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges that the method is presented nicely and the experiments are good and complete, but it suggests that the paper lacks analysis on what the model does, which could be interesting. However, it does not specify which part of the paper lacks this analysis or provide examples of what kind of analysis would be beneficial. The comment is 1 as it does not identify a specific section or aspect of the paper being addressed, and it is also not specific in detailing what kind of analysis is missing. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges that the method is presented well and the experiments are good and complete, but it suggests that the paper lacks analysis on what the model does, which could be interesting. However, the comment does not provide specific examples or detailed reasoning to support why this analysis is necessary or how it could enhance the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the method is presented well and the experiments are good and complete, but it points out a missing aspect: analysis on what the model does, which could be interesting. This feedback identifies a specific area for improvement, suggesting that the authors should include an analysis of the model\"s behavior or functionality. However, the comment does not provide detailed guidance on how to conduct this analysis or what specific aspects should be explored. While it highlights a potential enhancement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a lack of clarity in the task setup, specifically questioning which notes from the EHR (electronic health records) are used as input and how far away the outcomes are from the last note date. This feedback provides clear guidance on what aspects of the task setup need to be clarified, making it explicit and concrete. The authors know exactly what information is missing and can address it by providing detailed explanations in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the task setup, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: which notes from the EHR are used as input and how far away the outcomes are from the last note date. This provides clear guidance on what aspects of the task setup need to be clarified, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the clarity of the task setup, specifically asking which notes from the EHR (electronic health records) are used as input and how far away the outcomes are from the last note date. This is a factual question seeking clarification, rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the task setup, namely the lack of clarity regarding which notes from the EHR (electronic health records) are used as input and how far away the outcomes are from the last note date. This feedback is clear and actionable, as it prompts the authors to clarify these aspects of their methodology. By addressing this point, the authors can enhance the comprehensibility and reproducibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify these aspects or offered examples of similar setups in the literature. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the modulator being heuristically designed, questioning whether there might be scalability issues that require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the scalability of their modulator. The comment lacks actionable details, such as recommending specific methods or approaches to address the scalability issue. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper discusses the modulator or its design, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not provide detailed guidance on how to address the scalability issue or improve the modulator\"s design. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support the claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the modulator being heuristically designed, questioning its scalability and potential need for tedious hyperparameter tuning for diverse training data. While it identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve the scalability of their modulator. The comment provides some insight into a possible weakness but does not offer actionable advice, leaving the authors with a general understanding of the issue but without a clear path to improvement. Therefore, the comment is 3, as it highlights an area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the application of imitation learning and the challenges in obtaining labeled data. It suggests that the authors should conduct experiments to determine if there are difficulties in obtaining the corresponding data and how performance changes with varying labeled data sizes. While the comment implies that the authors should conduct these experiments, it does not provide specific guidance on how to design or execute them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the application of imitation learning and the challenges in obtaining labeled data. However, it does not specify which part of the paper discusses imitation learning or where the experiments on data acquisition and performance changes are lacking. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in terms of the issues it raises, it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are no experiments on the difficulties in obtaining labeled data for imitation learning and how performance changes with varying labeled data sizes. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the application of imitation learning and the challenges in obtaining labeled data. It suggests that the authors should conduct experiments to determine if there are difficulties in obtaining the corresponding data and how performance changes with varying labeled data sizes. This feedback is clear and actionable, as it provides a specific area for improvement and a direction for further experimentation. However, the comment could be more helpful if it offered suggestions on how to design these experiments or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward enhancing their draft by addressing a critical aspect of their methodology."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper provides valuable insights for contrastive learning in code search tasks but does not thoroughly explore the implications of the proposed method for other NLP tasks. This limitation is noted as it somewhat restricts the generalizability of the results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this limitation or expand the exploration of the proposed method for other NLP tasks. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not specify which part of the paper this limitation pertains to, such as specific sections or experiments that could be expanded. Additionally, the comment lacks specificity in terms of what aspects of other NLP tasks should be explored or how the generalizability could be improved. Without explicit references to specific parts of the paper or detailed suggestions for improvement, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper provides valuable insights for contrastive learning in code search tasks but does not thoroughly explore the implications of the proposed method for other NLP tasks. This limits the generalizability of the results. However, the comment lacks specific examples or references to other NLP tasks that could be explored, making it difficult for the authors to understand the exact scope of the limitation. The claim is 3 as it highlights a potential gap in the paper, but it requires more detailed justification or examples to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation highlights a potential area for improvement, as it suggests that the generalizability of the results could be enhanced by exploring the method\"s applicability to other NLP tasks. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their exploration. While it points out a relevant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the use of the term \"certificate\" in some contexts, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide explicit guidance on how to address this issue or suggest alternative terminology. The action is implicit, as the authors need to infer that they should reconsider the use of \"certificate\" and potentially replace it with a more appropriate term. Additionally, the comment lacks concrete details on how to implement this change, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"certificate,\" explaining that it might be misinterpreted due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of the term \"certificate\" in some contexts might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any specific examples or references to support this claim, nor does it explain how the term might be misinterpreted or why it is problematic. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the term \"certificate\" in the paper, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. This is a relevant observation that could lead to confusion among readers, especially those unfamiliar with the term. However, the comment lacks specific examples or suggestions on how to address this issue, such as recommending alternative terminology or clarifying the context in which the term is used. While it points out a potential problem, the feedback is incomplete and does not provide actionable guidance for improvement. Therefore, the comment is 3, as it highlights an area for consideration but does not fully support the authors in making necessary changes."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests conducting more experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet, to strengthen the paper. It provides specific examples of references that could guide the authors in their experiments. This feedback is clear and actionable, as it directly instructs the authors on what additional experiments to perform and provides concrete examples of relevant references. The authors know exactly what actions to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment suggests conducting more experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet, to strengthen the paper. It provides specific references to relevant works, which helps ground the suggestion in the context of the paper. However, the comment does not specify which part of the paper these experiments should be conducted in, making it weakly grounded. The suggestion is specific in terms of the types of experiments needed, but without explicit references to sections or parts of the paper, the authors may find it challenging to determine where to implement these changes. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting more experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet, to strengthen the paper. This suggestion is supported by references to specific works, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing. These references provide a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these experiments would contribute to the paper\"s strength. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending additional experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet. This feedback is specific and offers concrete examples of references that could guide the authors in their experiments. By suggesting these specific experiments, the comment empowers the authors to enhance the depth and breadth of their work, which is highly valuable for improving the draft. However, the comment could be more helpful if it included a rationale for why these experiments are necessary or how they would contribute to the paper\"s strength. Overall, the comment is 5 as it provides clear and actionable guidance for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results and analysis are detailed and comprehensive, but it notes that only two relatively old and small models are evaluated. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on whether the authors should evaluate additional models, what types of models should be considered, or how to address the issue of evaluating only a limited number of models. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the evaluation of results and analysis, noting that only two relatively old and small models are evaluated. However, it does not specify which part of the paper this critique pertains to, such as the results section or the discussion of model evaluation. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment highlights a specific issue with the models evaluated, it does not provide detailed guidance on how to address this issue or what alternative models should be considered. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the results and analysis are detailed and comprehensive, but it notes that only two relatively old and small models are evaluated. This claim is 3 as it provides a specific critique about the scope of the evaluation, which could be addressed by expanding the model selection. However, the comment lacks detailed reasoning or examples of how this limitation affects the comprehensiveness of the analysis. To fully substantiate the claim, the reviewer could provide additional context or references to support the importance of evaluating a broader range of models. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a limitation in the evaluation of results and analysis, noting that only two relatively old and small models are evaluated. While the comment identifies a specific area for improvement, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. Without specific recommendations or examples of alternative models or evaluation strategies, the feedback is 3 as it highlights a potential weakness but does not fully support the authors in improving their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that KD and LS are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or how it might impact the paper. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the relationship between KD (Knowledge Distillation) and LS (Label Smoothing), suggesting that KD can be viewed as a special form of LS under specific conditions. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its claim about the equivalence of KD and LS under certain conditions, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that KD (Knowledge Distillation) can be viewed as a special form of LS (Label Smoothing) under specific conditions. The reviewer provides a logical reasoning by stating that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS are equivalent. This reasoning is based on a clear understanding of the concepts and their relationship, which provides a solid foundation for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Overall, the claim is 4, as it provides a logical basis but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. The reviewer provides a logical reasoning by stating that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS are equivalent. This observation could be valuable for the authors, as it offers a deeper understanding of the relationship between these two methods. However, the comment lacks actionable suggestions or guidance on how this insight might impact the paper or its presentation. While it provides some insight, it does not fully support the authors in improving their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include more recent works in their comparison and provide results on largescale datasets, such as ImageNet, to further verify the effectiveness of their proposed method. While the comment implies that the authors should update their literature review and conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on which recent works to include or how to conduct the additional experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"No.3. 2021\" and \"Competing dynamicpruning methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more recent works and results on largescale datasets like ImageNet to further verify the effectiveness of the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should include more recent works and results on largescale datasets to verify the effectiveness of the proposed method. However, it does not provide specific examples of recent works or detailed reasoning for why the current results are insufficient. The comment lacks supporting evidence or references, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It points out that the dynamicpruning methods included in the study are outdated and suggests including more recent works. Additionally, it highlights the need for results on largescale datasets, such as ImageNet, to further verify the effectiveness of the proposed method. This feedback is clear and actionable, providing the authors with specific directions to enhance the comprehensiveness and validity of their study. However, the comment could be more helpful if it offered suggestions on which specific recent works to include or how to conduct the additional experiments. Overall, the comment is 4 as it guides the authors toward improving the scope and rigor of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task more difficult. It explicitly asks for an explanation of why this particular dimension of difficulty is interesting. This request is clear and direct, providing the authors with a specific action to take: explaining the rationale behind this choice. The feedback is concrete, as it specifies what the authors need to address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of randomly sampled CIFAR images as backgrounds, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind this choice and asks for an explanation of why this particular dimension of difficulty is interesting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task more difficult. It challenges the choice by asking why this particular dimension of difficulty is interesting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is not wellmotivated. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task more difficult. It challenges the choice by asking why this particular dimension of difficulty is interesting, suggesting that the authors should provide a clear rationale for this decision. This feedback is 3 as it prompts the authors to reconsider their choice and articulate the reasoning behind it. However, the comment could be more helpful if it offered suggestions on how to better motivate this choice or provided examples of alternative approaches. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the text inside the figure and the labels are too small to read without zooming, and it suggests that this text should be roughly the same size as the manuscript text. This feedback provides a clear and direct action for the authors to take, ensuring that the text is legible and consistent with the rest of the manuscript. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"figure\" and \"labels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text being too small and suggests that it should be the same size as the manuscript text. This provides clear guidance on what needs to be addressed to improve the figure\"s readability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text inside the figure and the labels are too small to read without zooming, and suggests that they should be the same size as the manuscript text. This is a factual observation about the figure\"s readability, which does not require any additional justification or evidence. The comment is purely descriptive and does not contain subjective opinions, suggestions, or claims that need verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the figure, noting that the text and labels are too small to read without zooming. It provides a clear and actionable suggestion to improve the figure by recommending that the text should be roughly the same size as the manuscript text. This feedback is direct and offers a concrete way for the authors to enhance the readability and accessibility of their figures, which is crucial for effective communication of their results. By addressing this issue, the authors can significantly improve the clarity and impact of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation of the paper is unclear and recommends revising the introduction to make it easier to follow. However, it does not provide specific guidance on what aspects of the motivation are unclear or how the introduction should be revised. The action is implicit and somewhat vague, as the authors are left to infer what needs to be changed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the motivation of the paper is unclear and recommends revising the introduction to make it easier to follow. However, it does not specify which parts of the introduction are unclear or what aspects of the motivation need clarification. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need revision. Additionally, the comment does not mention any specific sections or elements of the paper, making it weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the motivation of the paper is unclear, suggesting that the introduction should be revised to make it easier to follow. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the motivation is unclear. It suggests that the introduction should be carefully revised to make the paper easier to follow. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the motivation are unclear or how the introduction should be revised. Without concrete suggestions or examples, the authors are left with a general direction but no clear steps to take. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that including multiple local prompts can be intuitive but notes that the features and their positions may not be the same for different categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to ensure consistency across categories or proposing alternative methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of including multiple local prompts and notes that the features and their positions may not be the same for different categories. However, it does not specify which part of the paper this observation pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in its observation about the features and positions, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including multiple local prompts can be intuitive but notes that the features and their positions may not be the same for different categories. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that including multiple local prompts can be intuitive but points out a potential issue: the features and their positions may not be the same for different categories. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or improve their methodology. Without actionable advice or detailed feedback, the authors are left without a clear understanding of how to enhance their work based on this observation. Therefore, the comment is 2, as it identifies a potential area of concern but lacks depth and specificity in its feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the alignment of relabeled reward data with human annotator judgments, suggesting that it is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to validate the alignment or what specific steps should be taken to improve the validation process. As a result, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the alignment of relabeled reward data with human annotator judgments, suggesting that it is insufficiently validated. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in identifying the issue of insufficient validation but lacks grounding, as the authors cannot confidently determine which part of the paper this critique relates to. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the alignment of relabeled reward data with human annotator judgments, suggesting that it is insufficiently validated. This is a relevant observation that could impact the reliability and validity of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the validation process. Without actionable feedback or specific recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not offer detailed guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. The reviewer suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the generalizability of their method. The action is implicit and vague, as the authors are left to infer that they should expand their experiments to a broader range of molecules or improve the generalizability of their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the issue of limited generalizability and the need for broader testing, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s value is limited due to its focus on a limited number of molecules and indistribution testing. However, the comment lacks specific examples or references to support this claim. It does not provide detailed reasoning or evidence to substantiate why the method\"s value would be limited or how it could be improved. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. The reviewer suggests that the method\"s value would be limited if it requires training for each molecule individually. While the comment highlights a potential weakness, it lacks specific suggestions or guidance on how the authors might address this limitation or improve the generalizability of their method. The feedback is 3 as it points out an area for improvement, but it could be more actionable with additional details or recommendations. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the symbols are complicated and take time to understand, but it does not provide any explicit or implicit actions for the authors to take. It lacks specific suggestions or guidance on how to simplify or clarify the symbols, leaving the authors without a clear understanding of what changes are needed. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that symbols are complicated and take time to understand, but it does not specify which symbols or parts of the paper are being referred to. This lack of explicit reference to a specific section or element of the paper makes it difficult for the authors to identify the exact areas that need attention. Additionally, the comment does not provide specific details on what aspects of the symbols are confusing or how they could be simplified. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the symbols are complicated and take time to understand. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanation or references to particular symbols or their complexity, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the symbols used in the paper are complicated and take time to understand. However, it lacks specificity and does not provide any actionable feedback or suggestions on how to simplify or clarify the symbols. Without detailed guidance or examples, the authors are left without a clear understanding of what changes are needed to improve the clarity of the symbols. This lack of actionable advice makes the comment 2, as it identifies a potential issue but does not offer a path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to allow it to capture all of the results at a similar level to the explicitly compositional model. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to conduct additional experiments or analyses to address the question. The action is implicit and somewhat vague, as it lacks specific guidance on how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It references the comparison model, which cannot capture periodic relationships, and the experiments involving periodicity. However, the comment does not specify which sections of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its question about the impact of adding periodicity to the spectral kernel, but without explicit references to sections or experiments, the authors may find it challenging to pinpoint the exact parts of the paper that need attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that the comparison model, which cannot capture periodic relationships, may not be able to replicate the results seen in the experiments involving periodicity. The comment implies that adding periodicity to the spectral kernel might be sufficient to capture all of these results. However, the claim lacks specific examples or references to support the assertion that periodicity is the primary factor in the results. This makes the claim 3, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises an interesting question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It points out that the comparison model cannot capture periodic relationships, and in most experiments, the relationships involve periodicity. The comment suggests that adding periodicity to the spectral kernel might be enough to allow it to capture all of these results at a similar level to the explicitly compositional model. This feedback is 3 as it prompts the authors to consider the role of periodicity in their results and potentially explore its impact on the model\"s performance. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the paper is not wellwritten and suggests that it was possibly written in a hurry, making it difficult to read. It also mentions that there is a lack of presentation and formatting, particularly in figures and tables. However, the comment does not provide specific guidance on how to improve the writing, presentation, or formatting. It lacks actionable details, such as suggesting ways to enhance clarity or providing examples of how to improve the figures or tables. As a result, the authors are left without a clear understanding of what changes to make to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general observation about the paper being poorly written and suggests that it was possibly written in a hurry, making it difficult to read. It also mentions a lack of presentation and formatting, particularly in figures and tables. However, the comment does not specify which parts of the paper are particularly problematic or provide detailed feedback on how to improve the writing or formatting. Without specific guidance or references to particular sections, the authors cannot effectively address the issues raised. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not wellwritten and possibly written in a hurry, making it difficult to read. It also mentions a lack of presentation and formatting, particularly in figures and tables. However, the comment lacks specific examples or detailed reasoning to support these claims. Without concrete evidence or examples of what makes the paper difficult to read or how the presentation and formatting could be improved, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the paper is not wellwritten and possibly written in a hurry, making it difficult to read. It also mentions a lack of presentation and formatting, particularly in figures and tables. While the comment identifies areas for improvement, it lacks specific guidance or actionable suggestions on how to enhance the writing, presentation, or formatting. Without detailed feedback or examples, the authors are left with a general understanding of the issues but without a clear path to address them. Therefore, the comment is 3, as it highlights areas for improvement but does not provide sufficient detail to be fully actionable."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide specific guidance on what aspects of the introduction should be expanded or how to improve the detail. The action is implicit, as the authors need to infer that they should add more detail, and it is vague, as it lacks concrete instructions on what specific details to include. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not specify which part of the introduction is lacking in detail or what specific aspects need to be expanded. This makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment lacks specificity regarding what kind of detail is needed or how it could be improved. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific examples or reasoning to support why this is necessary or how the introduction could be improved. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement in the paper, suggesting that the introduction to orthogonality in Part 2 could be more detailed. This feedback is 3 as it points out a potential weakness in the paper and encourages the authors to enhance the clarity and depth of their introduction. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the introduction should be expanded or how to improve the detail. To be more helpful, the comment could include suggestions or examples of what additional information could be included. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that similar analyses are already present in prior works, suggesting that the results are not particularly surprising. It references specific examples, such as the robustness of CIFAR10 models on distribution shifts, which were studied in RobustBench and by [A, B]. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue. It lacks actionable details on how the authors might differentiate their work or present their findings in a novel or more impactful manner. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific prior works and analyses, such as the robustness of CIFAR10 models on distribution shifts, which were studied in RobustBench and by [A, B]. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the existing analyses and their similarities to the current work, providing a clear basis for the authors to understand what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that similar analyses are already present in prior works, suggesting that the results are not particularly surprising. It supports this claim by referencing specific examples, such as the robustness of CIFAR10 models on distribution shifts, which were studied in RobustBench and by [A, B]. This provides a clear and logical basis for the claim, making it 5. The inclusion of specific references and examples enhances the credibility of the claim, allowing the authors to understand the context and potential limitations of their work. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment highlights that similar analyses are already present in prior works, suggesting that the results are not particularly surprising. It references specific examples, such as the robustness of CIFAR10 models on distribution shifts, which were studied in RobustBench and by [A, B]. This feedback is 3 as it alerts the authors to the potential limitations of their work and the need to differentiate it from existing studies. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or present their findings in a novel or more impactful manner. While it identifies a potential weakness, it does not provide actionable advice, making it 3 but incomplete."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue or what changes, if any, should be made to their draft. Without actionable suggestions or instructions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. However, it does not specify which part of the paper this discussion is based on, making it difficult for the authors to pinpoint the exact section being addressed. The comment lacks specificity as it does not provide details on why the study is not considered an ablation or what alternative categorization might be more appropriate. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. The comment provides a logical reasoning by explaining that an ablation study typically involves removing a component to assess its impact. However, it does not provide specific examples or references to support this claim, which would help the authors understand the basis of the critique. Therefore, the comment is 3, as it provides a logical argument but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment questions whether the study on different subdomain sizes can be considered an \"ablation\" study, as it does not involve removing a component of the method. While the comment raises a valid point about the categorization of the study, it lacks depth and does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this issue or what alternative categorization might be more appropriate. Therefore, the comment is 2, as it identifies a potential problem but does not offer constructive advice for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation could be strengthened by including a comparison of base DA methods with and without architectural competitors like AutoDial and AdaBN. While the comment implies that the authors should consider adding this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the inclusion of a comparison of base DA methods with and without architectural competitors like AutoDial and AdaBN. This provides clear guidance on how to strengthen the evaluation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation could be strengthened by including a comparison of base DA methods with and without architectural competitors like AutoDial and AdaBN. The comment provides a logical reasoning for this suggestion, as it highlights the importance of comparing the proposed TransferNorm architecture with direct competitors. However, it does not provide specific examples or references to these competitors, which would strengthen the claim. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improving the evaluation section of the paper. It acknowledges the current evaluation, which compares several base DA methods with and without the proposed TransferNorm architecture, and suggests that the evaluation would be stronger if it included comparisons with architectural competitors like AutoDial and AdaBN. This feedback is clear and actionable, as it directs the authors to consider additional comparisons that could strengthen the evaluation of their work. However, the comment could be more helpful if it provided specific guidance on how to incorporate these competitors into the evaluation or suggested particular metrics to use. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the evaluation as weak and notes that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit suggestions for how the authors might improve the evaluation or select more appropriate baselines. Without guidance on what specific changes should be made or what alternative baselines could be considered, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the evaluation as weak and mentions that the baselines used in the paper are not designed for fair classification. However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment. Without explicit references to specific sections or examples, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what aspects of the evaluation are weak or how the baselines could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the baselines are inappropriate or how the evaluation could be strengthened. Without specific details or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a significant weakness in the evaluation of the paper, noting that the baselines used are not designed for fair classification. This is a critical observation that highlights a fundamental issue with the evaluation methodology. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or select more appropriate baselines. Without detailed feedback or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a problem but does not offer sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the first three paragraphs of Section 2 need to be clarified to spell out the setting more clearly. It implies that the authors may be claiming credit for a more general approach than what is actually presented, which muddles the exposition. However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be addressed. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first three paragraphs of Section 2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the exposition, suggesting that the setting needs to be clarified to avoid misleading the reader about the generality of the work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first three paragraphs of Section 2 need to be clarified to spell out the setting more clearly. It suggests that the authors may be claiming credit for a more general approach than what is presented, which muddles the exposition. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of evidence or detailed explanation makes the claim 3, as it requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the exposition in the first three paragraphs of Section 2, suggesting that the setting needs to be clarified to avoid misleading the reader about the generality of the work. This feedback is clear and actionable, as it directs the authors to improve the clarity and accuracy of their presentation. However, the comment could be more helpful if it provided specific suggestions on how to clarify the setting or what aspects need further elaboration. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the experiments, specifically questioning the choice of the old baseline and suggesting that the proposed method should be tested on newer 3D CNNs like X3D and SlowFast. The reviewer also asks for a comparison with these approaches to highlight the advantages of the proposed method. While the comment implies that the authors should test their method on these newer approaches and provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments and comparisons. However, the comment provides a clear direction for improvement, making it 4.", "grounding_specificity_rationale": "The comment addresses the experiments, specifically questioning the choice of the old baseline and suggesting that the authors should test their method on newer 3D CNNs like X3D and SlowFast. It also asks for a comparison with these approaches to highlight the advantages of the proposed method. However, the comment does not explicitly mention which part of the paper discusses the experiments, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be addressed, such as testing on newer 3D CNNs and comparing with existing approaches. Therefore, the comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point questions the validity of the experiments by suggesting that the choice of the old baseline, such as R3D and C3D, may not be sufficient. It proposes that newer 3D CNNs like X3D and SlowFast should be considered to reduce computation complexity. The reviewer also asks for a comparison with these newer approaches to highlight the advantages of the proposed method. While the comment raises valid points about the experimental setup, it lacks specific examples or references to support the claim that newer approaches are more effective. This makes the claim 3, as it provides a logical basis for improvement but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment raises a valid concern about the experiments, specifically questioning the choice of the old baseline and suggesting that newer 3D CNNs like X3D and SlowFast should be considered to reduce computation complexity. It also asks for a comparison with these newer approaches to highlight the advantages of the proposed method. This feedback is clear and actionable, as it prompts the authors to consider expanding their experiments to include more recent and relevant approaches. By addressing these points, the authors can enhance the credibility and comprehensiveness of their experimental results. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4, as it directs the authors to improve their experimental setup and analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests clarification on how the attention module is attached to the backbone ResNet20 architecture during the search process. It asks for specific details about the number of attention modules used and their placement, such as whether they are used after each block or stage. This feedback provides clear and direct actions for the authors to take, ensuring they know exactly what information needs to be clarified in their draft. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attention module\" and the \"backbone ResNet20 architecture,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, such as the number of attention modules used, their placement, and whether they are used after each block or stage. This provides clear guidance on what the authors need to address to improve the clarity of their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the attachment of the attention module to the backbone ResNet20 architecture during the search process. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the attachment of the attention module to the backbone ResNet20 architecture during the search process. It asks for clarification on the number of attention modules used and their placement, such as whether they are used after each block or stage. This feedback is clear and actionable, as it directs the authors to provide more detailed information that could enhance the clarity and understanding of their methodology. By addressing these questions, the authors can improve the comprehensibility of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4, as it guides the authors toward improving the clarity of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific concerns: the performance of the proposed method at different bitrates and the suggestion to discuss or compare with a related work. The reviewer explicitly asks for the precise bitrate range used for BDrate comparison and suggests discussing or comparing with a specific related work. These requests are clear and direct, providing the authors with concrete actions to take. The comment is 5 as it specifies what needs to be addressed and how to do so, giving the authors a clear path forward.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"bitrate range used for BDrate comparison,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear request for the precise bitrate range used for BDrate comparison and suggests discussing or comparing with a related work. The inclusion of a specific reference to a related work further enhances the specificity of the comment. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a claim about the performance of the proposed method at different bitrates and a suggestion to discuss or compare with a related work. The first part is a factual statement describing the performance of the method, which does not require verification. The second part is a suggestion to discuss or compare with a specific related work, which is a request for additional content rather than a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two specific pieces of feedback. First, it points out a potential weakness in the performance of the proposed method, noting that it is stronger at high bitrates but closer to baselines at low bitrates. This observation prompts the authors to clarify the precise bitrate range used for BDrate comparison, which is a clear and actionable suggestion. Second, the comment suggests discussing or comparing with a related work on content adaptive algorithms in learned video compression, specifically referencing Guo Lu et al., \"Content Adaptive and Error Propagation Aware Deep Video Compression.\" This recommendation is valuable as it could help the authors enhance their work by considering relevant literature. Overall, the comment is 4 as it identifies a specific area for improvement and provides a concrete suggestion for further exploration, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. While the comment implies that the authors should clarify this distinction, it does not provide specific guidance on how to make this distinction or what aspects of the paper need to be revised to achieve this. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, it does not specify which part of the paper this distinction should be made in, nor does it provide details on how to make this distinction. Without explicit references to sections or examples, the authors cannot confidently determine where to address this feedback. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, the comment does not provide any supporting evidence, reasoning, or references to explain why this distinction is important or how it would benefit the paper. Without additional context or justification, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish the \"allornothing\" or \"cutoff\" phenomenon from the usual statistical bounds that the machine learning and NeurIPS community is familiar with. While it identifies a potential area for clarification, the comment lacks specificity and does not provide detailed guidance on how to make this distinction or what aspects of the paper need to be revised. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the strong requirement of Gaussian features and noise for the theoretical result, and the lack of comparison with existing rates in the literature. The comment suggests that the authors should address these issues by relaxing the Gaussian assumption and comparing their rates with existing rates. While the comment implies that these actions should be taken, it does not explicitly instruct the authors to do so. The actions are concrete, as they specify what needs to be done, but they are implicit in nature. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" and the \"proposed algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the theoretical result, namely the strong requirement of Gaussian features and noise, and suggests comparing the rates achieved by the procedure with existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main theoretical result in the paper provides utility guarantees only when the features and noise are Gaussian, which is a strong requirement on the data. It also suggests that the authors should compare their rates with existing rates in the literature. The comment provides a logical reasoning by pointing out the limitations of the theoretical result and the need for comparison with existing work. However, it lacks specific references or examples of existing rates or algorithms that could be used for comparison, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence or references to be 5.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, specifically the strong requirement of Gaussian features and noise for the theoretical result. It points out that this assumption is a strong constraint on the data, especially given that previous algorithms do not require it. Additionally, the comment suggests that the authors should compare the rates achieved by their procedure with existing rates in the literature, which would provide a more comprehensive evaluation of the algorithm\"s performance. This feedback is clear and actionable, as it highlights a critical area for improvement and offers a specific suggestion for enhancing the paper. However, it could be more helpful if it provided examples of existing rates or algorithms for comparison. Overall, the comment is 4, as it guides the authors toward improving the theoretical rigor and practical applicability of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This comment implies that the authors should include a comparison with the original approach, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or analysis. This makes it weakly grounded, as the authors cannot confidently determine where to make the suggested addition. The comment is specific in suggesting a comparison with the original approach, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This claim is 3 as it provides a logical suggestion for enhancing the paper by comparing it to a relevant prior work. However, the comment lacks specific details or references to the original approach, which would strengthen the justification. The authors would need to infer the importance of this comparison and how it could benefit their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is 3 as it identifies a potential area for improvement by suggesting a comparison with a relevant prior work. However, the comment lacks specificity and does not provide detailed guidance on how to conduct the comparison or what aspects to focus on. While it points out a direction for enhancement, it does not offer actionable steps or detailed suggestions, leaving the authors with a general idea of what to consider but without a clear path to implementation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should add more experiments to demonstrate the effectiveness of their proposed method. It explicitly states that the authors should compare their work with additional baselines, specifically mentioning several works that focus on the same questions. This provides a clear and direct action for the authors to take, making the comment 5. The suggestion is concrete, as it specifies the need to include more experiments and references specific works that could be used for comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting the addition of more experiments to demonstrate the effectiveness of the proposed method. The comment provides examples of works that focus on the same questions, which further guides the authors on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should add more experiments to demonstrate the effectiveness of their proposed method. It claims that the current experimental section only compares with two baselines, and it provides examples of other works that focus on the same questions. This claim is 3 as it references specific works that could be used for comparison, providing a basis for the suggestion. However, the comment lacks detailed reasoning or examples of how these additional experiments would improve the paper, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental section, noting that the authors have only compared their work with two baselines. It suggests that the authors should add more experiments to demonstrate the effectiveness of their proposed method, providing examples of other works that focus on similar questions. This feedback is clear and actionable, as it directs the authors to expand their experimental comparisons, which could significantly enhance the paper\"s credibility and impact. However, the comment could be more helpful if it offered specific suggestions on which additional baselines or experiments to include. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis on BRPNAS is somewhat barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet or oneshot approaches. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider including more NAS approaches in their analysis, but it lacks concrete details on which specific approaches to include or how to integrate them into the analysis. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the analysis on BRPNAS, specifically noting that it is somewhat barebones and only compares against three basic alternatives, ignoring other NAS approaches like supernet or oneshot approaches. However, it does not specify which part of the paper this analysis is presented in, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being discussed. The comment is specific in detailing what is missing in the analysis, namely the inclusion of other NAS approaches. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is somewhat barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet or oneshot approaches. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to justify why these other approaches should be included. The lack of supporting information makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the analysis of BRPNAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like supernet or oneshot approaches. This feedback is 3 as it points out a gap in the analysis that could be addressed to provide a more comprehensive evaluation. However, the comment lacks specific suggestions or guidance on how the authors might expand their analysis to include these other approaches, which would make it more actionable. To be fully helpful, the comment could offer examples of how to incorporate these additional approaches or suggest specific metrics or methods to consider. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that more information is needed regarding the filtering process used to create the Arabic climate change QA dataset, specifically mentioning the translation and filtering methodology. This provides a clear and direct action for the authors to take, which is to provide additional details on these aspects. The comment is explicit and concrete, as it specifies exactly what information is missing and how the authors can address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filtering process\" used to create the Arabic climate change QA dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking, namely more information on the translation and filtering methodology, which is necessary to assess the dataset quality. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details around the filtering process used to create the Arabic climate change QA dataset are lacking, specifically mentioning the need for more information on the translation and filtering methodology. This claim is 3 as it highlights a gap in the paper that could impact the assessment of the dataset quality. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Providing more detailed information on the filtering process would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the importance of providing more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that requires further elaboration. By addressing this point, the authors can enhance the transparency and credibility of their dataset, which is crucial for the evaluation and application of their work. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details to include. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. While the comment implies that the authors should expand their experiments to include these aspects, it does not provide specific guidance on how to implement these changes or what specific attacks or thresholds should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing improvement. The comment is specific in suggesting what could be added to enhance the results, but it is 1 because it does not indicate where these additions should be made. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment does not provide specific examples, references, or detailed reasoning to support why these additions would be beneficial or how they would enhance the study. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient justification to be fully actionable.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental results, suggesting that the authors should enrich their experiments by including attacks with different strengths and exploring how different thresholds influence detection performance. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their study by expanding their experimental scope. However, the comment could be more helpful if it offered specific examples of attacks or thresholds to consider, which would provide even more guidance for the authors. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide information on how much performance difference using different image sizes and different variations of ResNets can lead to. This is an explicit request for additional data or analysis, but it does not specify how the authors should go about obtaining this information or what specific metrics or methods to use. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line number 170, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: information on how much performance difference using different image sizes and different variations of ResNets can lead to. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking for more information on how much performance difference using different image sizes and different variations of ResNets can lead to. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors provide information on how much performance difference using different image sizes and different variations of ResNets can lead to. This is a clear and actionable suggestion that could help the authors improve their draft by addressing a specific gap in their analysis. However, the comment could be more helpful if it provided additional context or examples of how this information might be presented or analyzed. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the algorithm should be presented and described in detail, which is a clear and explicit action for the authors to take. However, it does not provide specific guidance on how to present or describe the algorithm in detail, leaving the authors with a general idea of what needs to be done but without concrete steps to follow. While the action is explicit, the lack of detailed instructions makes it somewhat vague, as the authors may not be entirely sure of the exact changes needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the algorithm should be presented and described in detail, which is a general request for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the algorithm is discussed. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the algorithm need more detail or how it should be presented. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the algorithm should be presented and described in detail, which is a claim that requires justification. However, the comment does not provide any reasoning, examples, or references to support why this level of detail is necessary or how it would benefit the understanding of the proposed method. Without such evidence or explanation, the claim remains 1, as the authors are left without a clear understanding of what specific aspects need more detail or why. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the algorithm should be presented and described in detail, which is a valid point as it can help readers better understand the proposed method. However, the comment lacks specificity and does not provide guidance on how to achieve this level of detail or what aspects of the algorithm need more explanation. Without actionable suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is 3, as it identifies an area for improvement but does not provide enough detail to be fully actionable."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the omission of FFNs due to the inability to obtain a linear decomposition, as mentioned in the paper. It suggests that if there is no existing work offering a way around this issue, the authors should consider adding a line or two to acknowledge the lack of a solution and the open (hard) nature of the problem. This feedback is explicit in its suggestion to address the omission and provides a clear direction for the authors to improve their draft by adding a statement about the open problem. The action is concrete, as it specifies what needs to be done, making this comment 5.", "grounding_specificity_rationale": "The comment addresses the omission of FFNs due to the inability to obtain a linear decomposition, as mentioned in the paper. It suggests that the authors should consider adding a line or two to acknowledge the lack of a solution and the open (hard) nature of the problem. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the discussion of FFNs or linear decompositions. The suggestion is specific in terms of what needs to be addressed, namely, acknowledging the lack of a solution and the open nature of the problem. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the omission of FFNs due to the inability to obtain a linear decomposition, as mentioned in the paper. It suggests that if there is no existing work offering a way around this issue, the authors should consider adding a line or two to acknowledge the lack of a solution and the open (hard) nature of the problem. The comment provides a logical reasoning for the suggestion, noting that the omission of FFNs could impact the paper\"s readability and overall understanding. However, it lacks specific references or examples of existing work that could provide an approximation or solution, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence or references to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the omission of FFNs due to the inability to obtain a linear decomposition. It suggests that the authors should consider adding a line or two to acknowledge the lack of a solution and the open (hard) nature of the problem. This feedback is 3 as it points out a specific area for improvement and provides a clear suggestion for addressing it. However, the comment could be more helpful if it offered additional context or examples of how this omission might impact the paper\"s overall contribution or readability. Overall, the feedback is actionable but incomplete, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. While it implies that the authors should address these issues, the comment does not provide explicit instructions or concrete suggestions on how to do so. The authors can infer that they need to conduct additional analysis or provide explanations, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification on the impact of image number and the explanation of BYOL, but without clear references to sections or parts of the paper, the authors may struggle to pinpoint where these issues need addressing. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the questions and address them effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of images on model performance and the need to explain BYOL in the abstract. These are relevant points that could help the authors improve their draft by addressing potential gaps in their explanation or analysis. However, the comment lacks specificity and does not provide detailed guidance on how to address these issues, such as suggesting specific experiments or explanations to include. While it identifies areas for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the effectiveness of the method, specifically the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly what kind of arguments or intuitions are needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the effectiveness of the method, particularly regarding the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. However, the comment does not specify which part of the paper discusses the L_pixel component, making it weakly grounded. The comment is specific in its request for stronger arguments or intuitions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the observed effects are strong but questions the clarity of why the method works, particularly regarding the L_pixel component. The reviewer suggests that providing stronger arguments or intuitions about why these particular losses are beneficial would be welcome. However, the comment lacks specific examples or references to support the claim that the method is unclear or that the L_pixel component is not wellexplained. Without detailed reasoning or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3, as it provides some justification but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the method\"s effectiveness, particularly the L_pixel component. It suggests that the authors provide stronger arguments or intuitions to explain why these particular losses are beneficial. This feedback is clear and actionable, as it directs the authors to enhance their explanation of the method\"s workings. However, the comment could be more helpful if it offered specific suggestions or examples of what kind of arguments or intuitions would be most beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. The reviewer suggests that LLMs are typically trained on trillions of tokens, implying that the dataset size is insufficient. However, the comment does not provide explicit guidance on how the authors should address this concern or suggest ways to improve the dataset. The action is implicit and vague, as the authors are left to infer that they need to increase the dataset size but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. The reviewer compares this dataset size to the typical training data for LLMs, which are often trained on trillions of tokens. However, the comment does not specify which part of the paper this concern pertains to, such as a specific section or analysis, making it weakly grounded. The comment is specific in its critique of the dataset size and its implications for capturing user traits and personalities, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. The reviewer compares this dataset size to the typical training data for LLMs, which are often trained on trillions of tokens. However, the comment lacks specific examples or references to support the claim that 44k dialogues are insufficient. The reasoning is logical but could be strengthened with more detailed evidence or comparisons. Therefore, the comment is 3, as it provides a logical basis for the claim but requires additional support to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. The reviewer compares this dataset size to the typical training data for LLMs, which are often trained on trillions of tokens, suggesting that the dataset may not be large enough to capture the necessary combinations of personalities and topics. While the comment identifies a potential issue with the dataset size, it lacks specific suggestions or guidance on how the authors might address this concern or improve the dataset. The feedback is 3 as it highlights an area for improvement, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses skepticism about the use of binary classification as a baseline metric, questioning its suitability for assessing models\" understanding of finegrained errors like technique errors. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their approach. The comment lacks actionable details, such as recommending alternative metrics or methods to assess the models\" understanding. As a result, the authors are left without a clear path forward to address the issue raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the use of binary classification as a baseline metric, suggesting that it may not adequately assess models\" understanding of finegrained errors like technique errors. However, it does not specify which part of the paper discusses the binary classification or where the authors introduce the baseline metrics. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what alternative metrics or methods could be used to assess the models\" understanding. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the use of binary classification as a baseline metric, suggesting that it may not adequately assess models\" understanding of finegrained errors like technique errors. The reviewer provides a logical reasoning by questioning the suitability of a coarsegrained binary classification for assessing a finegrained task. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of binary classification as a baseline metric, questioning its suitability for assessing models\" understanding of finegrained errors like technique errors. This is a relevant point that could impact the validity and effectiveness of the evaluation methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or explore alternative metrics. Without actionable advice, the authors are left with a general critique but no clear path to improvement. Therefore, the comment is 3, as it identifies a potential weakness but does not provide sufficient detail or direction for the authors to effectively address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their SynTextBench metric to other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SynTextBench metric,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing the SynTextBench metric to other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that there has been a significant amount of work on LLM evaluation, with some metrics not satisfying the proposed desiderata. It further suggests that it would be beneficial to compare the SynTextBench metric to other metrics proposed in the literature. However, the comment lacks specific examples or references to the \"large amount of work\" or the metrics that do not satisfy the desiderata. This makes the claim 3, as it provides a general direction but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that there has been a significant amount of work on LLM evaluation, with some metrics not satisfying the proposed desiderata. It suggests that the authors should compare their SynTextBench metric to other metrics proposed in the literature, such as MMLU or Big Bench, to understand under what conditions one should use SynTextBench. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by comparing their metric to existing ones. However, the comment could be more helpful if it included examples or references to the existing metrics, which would further guide the authors in making the comparison. Overall, the comment is 4, as it offers a clear path for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. While the comment implies that the authors should reconsider their approach, it does not explicitly instruct them to do so or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their methodology but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. However, it does not specify which part of the paper discusses this methodology, making it weakly grounded. The comment is specific in its critique of the approach, questioning the rationale behind the chosen methodology. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. The comment provides a logical reasoning by implying that considering all reports would lead to a more comprehensive analysis. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider the implications of including all reports to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the rationale behind considering only ECG segments with one label assigned, suggesting that including all reports would be more beneficial. This feedback highlights a potential limitation in the methodology and prompts the authors to reconsider their approach. However, the comment does not provide specific suggestions or examples on how to address this issue or improve the methodology. While it identifies a potential area for improvement, it lacks depth and actionable guidance, making it 3. The authors gain insight into a possible weakness in their work but are not fully supported in making improvements. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of thorough exploration of the scalability bounds of FedDES and the absence of a clear discussion on memory requirements and computational complexity. While it identifies specific areas that need attention, it does not provide explicit guidance on how the authors should address these issues or what specific aspects should be included in the discussion. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand the discussion on scalability bounds, memory requirements, and computational complexity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paper\" and \"FedDES,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of limited discussion on scalability bounds, including the lack of exploration of upper limits, memory requirements, and computational complexity. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a thorough discussion of scalability bounds, specifically mentioning the absence of clear discussions on memory requirements and computational complexity. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth and thoroughness, namely the discussion of scalability bounds for FedDES. It points out the absence of a clear exploration of upper limits, memory requirements, and computational complexity, which are crucial aspects for understanding the scalability of the proposed method. This feedback is clear and actionable, as it directs the authors to expand their discussion on these critical aspects, providing a concrete area for improvement. However, the comment could be more helpful if it offered suggestions on how to approach this discussion or what specific aspects should be included. Overall, the comment is 4, as it effectively guides the authors toward enhancing their draft by addressing a key limitation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It asks whether the base node affects the ordering, the key nodes for attention, and the model performance. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or clarify the statement in their draft. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the meaning of a statement in the paper, specifically regarding the effect of the base node on the ordering, key nodes for attention, and model performance. However, it does not specify which part of the paper this statement is from, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its inquiry about the implications of the base node, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification about the statement \"NodeSort differentially sorts nodes depending on the base node.\" It does not express an opinion, judgment, or suggestion that requires verification. It is a request for clarification, which is factual and does not contain a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of a statement in the paper, specifically regarding the effect of the base node on the ordering, key nodes for attention, and model performance. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify or address this issue in their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be improved. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the direction of the arrow in Figure 2, asking why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). The reviewer suggests that the main purpose might be to influence n^(i). While the comment raises a specific question about the arrow direction, it does not provide explicit guidance on how the authors should address this issue or what changes, if any, are needed. The action is implicit and somewhat vague, as the authors can infer that they might need to clarify the arrow direction or its purpose, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the direction of the arrow in the figure and suggests that the main purpose might be to influence n^(i). This provides clear guidance on what aspect of the figure needs clarification or revision. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the direction of the arrow in Figure 2, suggesting that it should be from the latent space to n^(i) rather than from a Gaussian space. The reviewer provides a logical reasoning by questioning the main purpose of the arrow, which is to influence n^(i). However, the comment lacks specific references or detailed explanations to fully substantiate the claim. While the reasoning is clear, the lack of additional evidence or references makes the claim 3, as the authors may need to further explore the rationale behind the arrow direction. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the direction of the arrow in Figure 2, questioning why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). It suggests that the main purpose might be to influence n^(i), which provides a clear and actionable point for the authors to clarify or revise their explanation. However, the comment could be more helpful if it offered additional context or suggestions on how to address this issue, such as explaining the rationale behind the current arrow direction or suggesting alternative ways to present the information. Overall, the comment is 3 as it identifies a potential area for clarification, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with abbreviations in Table 5, noting that \"AR\" stands for domain adaptation tasks and algorithms. This feedback is explicit and provides a clear action for the authors to take, which is to define the abbreviations used in the table. The comment is concrete because it specifies exactly what needs to be done to improve the clarity of the table. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with abbreviations, namely that \"AR\" stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed to improve the clarity of the table. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definition and cause confusion, specifically mentioning that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This claim is 3 as it provides a specific example of an abbreviation that is unclear, but it lacks broader context or justification for why other abbreviations might also be problematic. The comment could be strengthened by explaining how this lack of definition impacts the reader\"s understanding or by suggesting ways to improve clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with abbreviations in the paper, noting that many of them lack definition and cause confusion. It provides a concrete example by pointing out that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is actionable as it directs the authors to clarify the meaning of abbreviations used in their work, which can significantly improve the clarity and accessibility of the paper. However, the comment could be more helpful if it suggested ways to address this issue, such as providing a glossary or defining abbreviations in the text. Overall, the comment is 4 as it highlights a clear area for improvement and provides a specific example to guide the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using advantage instead of q value for conducting the analysis. While it implies that the authors should consider other technical considerations for this choice, it does not explicitly instruct them to do so or provide specific guidance on what those considerations might be. The action is implicit and somewhat vague, as the authors can infer that they should explore other technical reasons but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using advantage instead of q value for conducting the analysis, suggesting that there might be other technical considerations. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the technical considerations, but without clear grounding, the authors may struggle to determine where to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of using advantage instead of q value for conducting the analysis, suggesting that there might be other technical considerations. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is more common in practice or what specific technical considerations might exist. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using advantage instead of q value for conducting the analysis, suggesting that there might be other technical considerations. While it identifies a potential area for exploration, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The comment prompts the authors to consider other technical aspects but does not offer actionable advice or detailed feedback on how to improve their draft. As a result, the comment is 3, as it provides a direction for further inquiry but lacks the depth needed for significant improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the performance comparison in Table 1, specifically regarding the sample weights used in the training process. It points out that VINS sets different sample weights, while most compared baselines use a weight of 1. This feedback implies that the authors should clarify or justify the use of different sample weights in VINS, as it may affect the fairness of the comparison. However, the comment does not explicitly instruct the authors to make changes or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the sample weight setting but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance comparison, specifically mentioning the use of different sample weights in VINS compared to other baselines. This provides clear guidance on what needs to be addressed, such as clarifying the sample weight setting or justifying its use. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair due to the use of different sample weights in VINS compared to other baselines. This claim is 3 as it provides a specific reason for the perceived unfairness, namely the use of different sample weights. However, the comment lacks detailed explanation or references to support why this difference is significant or how it affects the fairness of the comparison. Providing more context or examples would strengthen the justification, making the claim more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the performance comparison in Table 1, specifically regarding the use of different sample weights in VINS compared to other baselines. This feedback is 3 as it points out a specific area where the authors might need to clarify or justify their methodology. However, the comment lacks detailed guidance on how to address this issue or what specific changes might be necessary to ensure fairness in the comparison. While it provides some insight into a potential weakness, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the time complexity if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to optimize the buffer size or alternative methods to reduce complexity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the time complexity issue related to the reply buffer being too large, but it does not specify which part of the paper this issue is discussed in. Additionally, it does not provide specific details or examples on how to address this complexity, leaving the authors without clear guidance on what needs to be improved. The comment lacks grounding as it does not identify a specific section or part of the paper, and it is also not specific in detailing the issue or suggesting solutions. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the time complexity will be too high if the reply buffer is too large, and it references PRMRL as a source. However, the comment does not provide detailed reasoning or examples to support this claim, such as how the time complexity is calculated or how the buffer size affects it. The reference to PRMRL is a general reference to a related work, but it does not directly address the specific issue raised in the comment. Therefore, the claim is 3, as it provides some support but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the reply buffer being too large, which could impact the overall performance of the system. However, it does not provide any specific suggestions or guidance on how to address this issue, such as recommending ways to optimize the buffer size or suggesting alternative methods to reduce complexity. Without actionable advice or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a concern but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not provide specific guidance on which baselines to include or how to implement these suggestions. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative perspectives and baselines to consider, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide specific examples or references to support the claim that these alternative perspectives are necessary or beneficial. Without detailed justification or evidence, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it identifies a potential area for improvement by suggesting alternative perspectives that could enhance the paper\"s contribution. However, the comment lacks specific guidance on which baselines to consider or how to implement these suggestions, leaving the authors with a general direction but not a detailed plan for improvement. Therefore, the comment is rated as 3, as it provides some insight but could be more actionable with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, as the current comparison with APEGAN may not be comprehensive. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. Additionally, it does not provide specific guidance on which method to compare with or how to present the results. The action is implicit and somewhat vague, as the authors can infer that they need to expand their comparison but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, rather than just APEGAN. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where comparisons are made. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. The comment is specific in suggesting a comparison with a method that defends against multiple attacks, but it is 1 because it does not specify where this comparison should be made. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, as the current comparison with APEGAN may not be comprehensive. The comment provides a logical reasoning for the suggestion, noting that such a comparison would make the results more meaningful. However, it does not provide specific references or examples of methods that defend against multiple attacks, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should expand their comparison by including a method designed to defend against multiple attacks, rather than just APEGAN. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically the comprehensiveness of the comparisons. However, the comment does not provide specific guidance on which method to compare with or how to present the results, leaving the authors with a general direction but without detailed actionable steps. To be more helpful, the comment could include suggestions on which methods to consider or how to structure the comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to define the bounds for \tau_i^l, which is crucial for understanding the timewarp function. This is a clear and direct action for the authors to take, providing them with a specific task to complete. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be defined, which is the bounds for \tau_i^l, and why it is important for understanding the timewarp function. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, specifically asking the authors to define the bounds for \tau_i^l. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback. By requesting the authors to define the bounds for \tau_i^l, the reviewer highlights a critical aspect of the paper that is essential for understanding the timewarp function. This feedback is clear and direct, giving the authors a clear direction on how to improve their draft by providing missing information. The comment is specific and actionable, making it highly beneficial for the authors to enhance the clarity and comprehensiveness of their work. Therefore, it deserves a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the efficiency of pairwise matching, suggesting that it is not suitable for practical application systems. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve efficiency or what specific changes could be made to enhance the practicality of the system. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the efficiency of pairwise matching, suggesting it is not suitable for practical application systems. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of efficiency are problematic or how they could be improved. Without clear guidance or references to specific sections, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the efficiency of pairwise matching is low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to justify the assertion, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the efficiency of pairwise matching, suggesting that it may not be suitable for practical application systems. However, it lacks specificity and does not provide any actionable advice or suggestions on how the authors might address this concern. Without detailed guidance or examples, the authors are left without a clear understanding of what changes or improvements could be made to enhance the efficiency of their approach. As a result, the comment is not particularly helpful, as it identifies a problem but does not offer a path for resolution. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance on how the authors could improve this allocation or what aspects of the figure could be edited to make it more effective. The comment also mentions that the authors could have edited the space of the main paper more wisely, but again, it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, leaving the authors uncertain about how to address the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not specify which part of the paper this figure is located in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the figure are considered naive or how it could be improved. Without explicit references to sections or figures, the authors cannot confidently determine the part of the paper being addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples, reasoning, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance or suggestions on how the authors could improve the allocation or what aspects of the figure could be edited to make it more effective. Additionally, the comment mentions that the authors could have edited the space of the main paper more wisely, but again, it lacks detailed advice on how to achieve this. The feedback is vague and lacks actionable insights, making it 2 for the authors to address the issues effectively. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to rewrite the first sentence of the abstract. This is a clear and direct action, leaving no ambiguity about what needs to be done. The comment provides a specific and concrete instruction, making it 5. The authors know exactly what step to take to improve their draft, which aligns with a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first sentence of the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to rewrite the first sentence of the abstract. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point is a request for a change, specifically asking for the first sentence of the abstract to be rewritten. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for modification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is clear and direct, instructing the authors to rewrite the first sentence of the abstract. This feedback is actionable and provides a specific area for improvement, which is beneficial for the authors. However, it lacks further explanation or guidance on how to improve the sentence or what aspects of it need revision. While it points out a clear issue, it does not offer detailed suggestions or examples to help the authors enhance their draft. Therefore, the comment is 3, as it provides a clear direction but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the addition of a method to improve transferability as a positive step but suggests that it is not a significant contribution. However, it does not provide any explicit or implicit guidance on how the authors might address this feedback or improve their contribution. There is no suggestion of what specific aspects could be enhanced to make the contribution more significant or how the authors might differentiate their work from others. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper discusses the addition of a method to improve transferability. It also lacks specificity because it does not provide details on what aspects of the contribution are considered insufficient or how it could be improved. Without clear references to the paper or specific suggestions for improvement, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that adding a method to improve transferability is a positive step but not a significant contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition is not significant. Without specific details or references to compare the contribution with other methods or studies, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the addition of a method to improve transferability as a positive step but suggests that it may not be a significant contribution. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might enhance their contribution or differentiate it from other methods. Without detailed feedback or constructive advice, the authors are left without a clear path to address the feedback effectively. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the challenges when analyzing Adam under the (L0, L1)smoothness condition. It suggests that the authors should explain these challenges, particularly the differences between their approach and that of Zhang et al. While the comment implies that the authors should provide more explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to address the challenges or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the challenges when analyzing Adam under the (L0, L1)smoothness condition. It suggests that the authors should explain these challenges and differentiate their approach from that of Zhang et al. However, the comment does not explicitly mention which section or part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as explaining the challenges and differences. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that it is unclear what the challenges are when analyzing Adam under the (L0, L1)smoothness condition and suggests that the authors should explain these challenges. The comment implies that the analysis could be straightforward, but it lacks specific reasoning or examples to support this claim. Without detailed justification or references to external works, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper regarding the challenges when analyzing Adam under the (L0, L1)smoothness condition. It suggests that the authors should clarify these challenges and differentiate their approach from that of Zhang et al. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations and comparisons, which could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific examples or questions to guide the authors in addressing the challenges. Overall, the comment is 4, as it effectively points out a gap in the paper and offers a direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that most person reID methods are based on pedestrian detectors (twostep method) and mentions the existence of endtoend methods that combine detection and reID. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this information or how it relates to their work. Without any actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"most of person reID methods\" and \"pedestrian detector\" without specifying which part of the paper these methods are discussed in. This makes it difficult for the authors to pinpoint the exact section being addressed. Additionally, the comment provides a general observation about the existence of endtoend methods but does not specify what needs to be addressed or improved regarding this information. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point makes a factual statement about the basis of person reidentification methods, mentioning that most are based on pedestrian detectors (twostep method) and that there are also endtoend methods that combine detection and reID. This statement is based on common knowledge in the field and does not require additional evidence or references to be considered factual. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a factual observation about the basis of person reidentification methods, noting that most are based on pedestrian detectors (twostep method) and that there are also endtoend methods that combine detection and reID. While this information is relevant and could be useful for the authors to consider, it does not offer any specific feedback or suggestions for improvement. The comment lacks depth and does not provide actionable guidance for the authors to enhance their draft. As a result, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding a first sentence to introduce the content of Section 3.2. While it explicitly states an action, it lacks specific guidance on what should be included in the introduction sentence. The authors are aware of the need to introduce the section but may struggle to determine the exact content of the introduction. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a first sentence to introduce the section, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a first sentence to introduce Section 3.2. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or improvement, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment suggests adding a first sentence to introduce Section 3.2, which is a straightforward and actionable piece of feedback. By doing so, the authors can ensure that readers are immediately aware of the content and purpose of the section, enhancing the clarity and accessibility of the paper. However, the comment lacks depth and does not provide specific guidance on what should be included in the introduction sentence. While it offers a clear direction for improvement, it could be more helpful if it provided more detailed suggestions or examples. Therefore, the comment is rated as 3, as it provides a useful suggestion but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the meaning of the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify or address this point in the draft, nor are there suggestions for improvement or alternative phrasing. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of the phrase \"initial rationale selector is perfect\" and provides a logical critique by suggesting that if it were perfect, no additional work would be needed. This level of detail helps the authors understand what needs to be clarified or addressed in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this assumption is problematic or how it affects the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the phrase \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This critique highlights a potential inconsistency or misunderstanding in the paper, which could be clarified or addressed by the authors. However, the comment does not provide specific suggestions or guidance on how to resolve this issue or improve the clarity of the text. While it identifies a potential area for improvement, it lacks depth and actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether the authors experimented with the use of domain ontologies to avoid placeholder generation in the evaluated responses. It also asks for specific details regarding the number of questions created for the zeroshot intent classifier and its accuracy. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of domain ontologies and asks for details regarding the number of questions created for the zeroshot intent classifier and its accuracy. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the use of domain ontologies to avoid placeholder generation in the evaluated responses. It does not contain a claim or opinion but rather seeks clarification on a specific aspect of the methodology. The comment is factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a specific question about the use of domain ontologies to avoid placeholder generation in the evaluated responses. It also requests information about the number of questions created for the zeroshot intent classifier and its accuracy. This feedback is clear and actionable, as it prompts the authors to provide additional details that could enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to address the issue or why this information is important. Overall, the comment is 4 as it directs the authors to specific areas needing clarification, providing a clear path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include additional citations to set their work in the context of other MultiAgent Reinforcement Learning (MARL) work, specifically mentioning recent papers on selfplay and populationplay with respect to exploration and coordination. The comment provides specific examples of papers that could be included, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This guidance is clear and concrete, giving the authors a direct action to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for additional citations to set the work in the context of other MultiAgent Reinforcement Learning (MARL) work, specifically referencing recent papers on selfplay and populationplay with respect to exploration and coordination. The authors can accurately identify the part of the paper that needs attention, which is the section on citations. The comment is also specific because it provides examples of relevant papers that could be included, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This level of detail helps the authors understand exactly what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point suggests that the paper lacks citations to place it in the context of other MultiAgent Reinforcement Learning (MARL) work, specifically mentioning recent papers on selfplay and populationplay with respect to exploration and coordination. The reviewer provides specific examples of papers that could be included, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019. This level of detail and reference to specific works supports the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these references would enhance the context of the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper lacks citations to place it in the context of other MultiAgent Reinforcement Learning (MARL) work, particularly recent papers on selfplay and populationplay with respect to exploration and coordination. The comment provides specific examples of relevant papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which can guide the authors in selecting appropriate references. This feedback is clear and actionable, offering a concrete way for the authors to enhance the context and relevance of their work. However, the comment could be more helpful if it included a rationale for why these references are important or how they would contribute to the paper. Overall, the comment is 4 as it provides specific guidance for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the abstention process, specifically whether it is based on a prediction probability threshold or a decision threshold used by the models. It requests clarification from the authors on this matter. While the comment does not explicitly instruct the authors to provide clarification, it implies that they should address the question by clarifying the difference between the two thresholds. The action is implicit but concrete, as the authors know exactly what information is needed to clarify the issue. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the basis of the abstention process, whether it is based on a prediction probability threshold or a decision threshold used by the models, and requests clarification on this point. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the abstention process, specifically whether it is based on a prediction probability threshold or a decision threshold used by the models. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, which is consistent with the \"No\" label.", "helpfulness_rationale": "The review comment raises a question about the abstention process used in the paper, specifically whether it is based on a prediction probability threshold or a decision threshold used by the models. It requests clarification on this point, which is a relevant and important aspect of the methodology that could impact the interpretation of the results. However, the comment does not provide any suggestions or guidance on how the authors might clarify this aspect or improve their explanation. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a lack of meaningful baselines in the paper, specifically noting that the authors limit their comparisons to simple naive baselines. It suggests that the authors could compare with a chainofthought prompting approach, providing a concrete example of a more meaningful baseline. This feedback is clear and actionable, as it directly instructs the authors on how to enhance their comparisons by including a specific alternative. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking meaningful baselines and suggests a comparison with a chainofthought prompting approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks meaningful baselines, specifically noting that the authors limit their comparisons to simple naive baselines. The reviewer suggests comparing with a chainofthought prompting approach as a more meaningful baseline. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples of how the current baselines are insufficient. The suggestion for a chainofthought prompting approach is a logical next step, but the comment could be strengthened by explaining why the current baselines are inadequate or how the chainofthought approach would provide a more meaningful comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of meaningful baselines in the comparisons. It points out that the authors limit their comparisons to simple naive baselines, suggesting that this limits the paper\"s contribution. The comment provides a specific suggestion for improvement by recommending a comparison with a chainofthought prompting approach, which could offer a more meaningful baseline. This feedback is clear and actionable, offering the authors a concrete way to enhance the depth and relevance of their comparisons. However, it could be more helpful if it included additional suggestions or examples of other potential baselines to consider. Overall, the comment is 4 as it directs the authors toward a specific improvement that could significantly enhance the paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the pretraining process for the cardiac signal representation learning model. It asks whether the model is pretrained on the entire dataset or just the training set, and if the latter, how well it generalizes to settings without associated labels. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should clarify this aspect in their paper. The action is implicit but concrete, as the authors know exactly what information is needed to address the question. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the pretraining process for the cardiac signal representation learning model, specifically asking whether it is trained on the entire dataset or just the training set. It also inquires about the generalization of the model to settings without associated labels. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup sections, but this inference is not direct. The comment is specific in its inquiry about the pretraining process and generalization, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification about the pretraining process for the cardiac signal representation learning model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the pretraining process for the cardiac signal representation learning model. It asks whether the model is pretrained on the entire dataset or just the training set, and if the latter, how well it generalizes to settings without associated labels. This question is relevant and could help the authors clarify their methodology, potentially leading to improvements in the robustness and generalizability of their model. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending a particular approach or methodology. While it identifies a critical area for clarification, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific changes should be made to improve the draft. Without any actionable steps or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which parts of the paper this applies to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact parts of the paper being addressed. Additionally, the comment lacks specificity regarding which observations or design decisions are hardware or software dependent, leaving the authors without clear guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the paper, suggesting that some observations and design decisions might be hardware and software dependent. This is a relevant observation that could impact the generalizability and applicability of the findings. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or mitigate its impact. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 2, as it highlights a potential concern but does not offer meaningful guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. However, it does not provide explicit instructions or suggestions for the authors to address these questions or improve their draft. The comments are more like clarifications or requests for additional information, leaving the authors without clear actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. However, it does not specify which part of the paper these questions pertain to, such as which sections or tables discuss the ground truth or the ablation study. Without explicit references, the authors cannot confidently determine the exact parts of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the ground truth or results are unclear or need clarification. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions: one about the accuracy of the ground truth and the other about the differences in the results reported in the ablation study. Neither question contains a claim or opinion that requires verification. They are factual inquiries seeking clarification or additional information. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the accuracy of the ground truth and the differences in the results reported in the ablation study. However, it does not provide any suggestions or guidance on how the authors might address these questions or improve their draft. The comment lacks actionable feedback or specific recommendations, leaving the authors without a clear path for improvement. As a result, the comment is 1, as it does not offer any constructive direction for the authors to enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of important experimental details and explanations in the main text and the Appendix. It specifically mentions that the PCA experiments in Figures 3, 7, and 8 are not explained. This feedback provides a clear and explicit action for the authors to take, which is to include detailed explanations and interpretations of these experiments in the main text. The comment is specific and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (3, 7, and 8) and the Appendix, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what is missing, namely explanations and interpretations of the PCA experiments. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations or interpretations. It specifically mentions that the PCA experiments in Figures 3, 7, and 8 are not explained. This claim is 3 as it provides specific examples of missing details, which could be addressed by the authors. However, the comment lacks detailed reasoning or references to support the claim that all important details are missing, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations or interpretations. It specifically points out that the PCA experiments in Figures 3, 7, and 8 are not explained, which is a specific and actionable piece of feedback. By highlighting these gaps, the comment provides clear guidance on what the authors need to address to improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to incorporate these details or explanations into the main text. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It also suggests that the experimental analysis section should include an indepth exploration of the reasons for the experimental results. While the comment implies that the authors should provide more detailed analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the indepth exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of new evaluation metrics and the linear combination of existing metrics in the experimental analysis section. It suggests that there should be an indepth exploration of the reasons for the experimental results. However, it does not specify which part of the experimental analysis section needs this exploration, making it weakly grounded. The comment is specific in its request for an indepth exploration, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It further suggests that the experimental analysis section lacks an indepth exploration of the reasons for the results. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the reasoning behind the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that no new evaluation metrics are proposed and that only existing metrics are linearly combined. It also suggests that the experimental analysis section lacks an indepth exploration of the reasons for the results. This feedback is clear and actionable, as it highlights an area where the authors could enhance their work by introducing new evaluation metrics or providing a more detailed analysis of the experimental results. However, the comment could be more helpful if it offered specific suggestions on how to introduce new metrics or what aspects of the analysis should be explored. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the notation \"K,\" which is used for both a known kernel function and the number of layers. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on whether the notation should be changed, clarified, or if there is a better way to differentiate between these two uses. Without any actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (L166 and L176) where the notation \"K\" is used for different purposes. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly points out the issue of the notation being abused, indicating that it is used for both a known kernel function and the number of layers. This provides clear guidance on what needs to be addressed to avoid confusion. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"K\" is abused, as it is used for both a known kernel function and the number of layers. This claim is 3 as it highlights a potential issue with notation clarity, but it lacks specific examples or references to support the assertion. The authors would need to review the relevant sections to understand the context fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"K,\" which is used for both a known kernel function and the number of layers. This is a clear and actionable feedback that highlights a potential source of confusion for readers. By pointing out this inconsistency, the comment provides the authors with a specific area to address and clarify in their draft. However, the comment could be more helpful if it suggested alternative notations or provided guidance on how to differentiate between these two uses of \"K.\" Despite this, the feedback is still valuable as it directs the authors to a critical area that needs attention. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer questions the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising if a behavioral economist would ignore these aspects. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their statement. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more context or references to support their claim. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific concern about the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. It questions the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising if a behavioral economist would ignore these aspects. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the relevance of human cognition and the need for more citation for comparison. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer challenges the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising if a behavioral economist would ignore these aspects. The comment provides a logical reasoning by contrasting the reductionist nature of the problem with the need for humanlike mechanisms, but it lacks specific references or examples to fully substantiate the claim. This makes the comment 3, as it provides a logical basis but requires more detailed evidence or references to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the relevance of bringing connections to human cognition into the study, given that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. It questions the authors\" statement about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, suggesting that it would be surprising if a behavioral economist would ignore these aspects. The comment also points out the need for more citation for comparison against \"previously appreciated.\" While the comment identifies a potential issue and suggests a need for clarification or additional references, it lacks specific guidance on how the authors might address this concern or improve their draft. The feedback is 3 as it highlights an area for improvement but could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and that the word choice is \"flamboyant\" in multiple places. However, it does not provide specific suggestions or guidance on how to revise the wording or tone. The action is implicit, as the authors can infer that they need to tone down the language, but it lacks concrete details on how to achieve this. Therefore, the comment is 3, as it identifies an issue but does not offer detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of overly exaggerated wording and provides a concrete example of the problematic phrase, \"our pioneering contributions herald a new era in robotic adaptability.\" This specificity helps the authors understand what needs to be addressed in the conclusion. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated and that the word choice is \"flamboyant\" in multiple places. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim 3, as the authors may struggle to identify and correct the issues without further guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and \"flamboyant.\" This feedback is clear and actionable, as it points out a potential weakness in the paper\"s presentation and suggests a need for more modest language. However, the comment could be more helpful if it provided specific examples of where the language is excessive or offered suggestions for alternative wording. Despite this, the comment still provides valuable insight into how the authors might improve the clarity and impact of their conclusions. Therefore, it is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, specifically mentioning TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve their draft. The comment is concrete and actionable, as it outlines a specific analysis that can be conducted to enhance the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests performing ablation experiments to compare the proposed method with other methods, specifically mentioning TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its request for ablation experiments and comparison with TubeR, but without clear grounding, it aligns with a score of 1. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests performing ablation experiments to compare the proposed method with other methods, specifically mentioning TubeR, in terms of the number of learnable parameters and GFLOPs. This is a request for additional analysis and comparison, rather than a claim or opinion. It does not contain subjective judgments, suggestions, or deductions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to improve their draft. It recommends performing ablation experiments to compare the proposed method with other methods, specifically mentioning TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is specific and provides a concrete direction for the authors to enhance their analysis and evaluation of their method. By following this advice, the authors can provide a more comprehensive understanding of their approach and its performance relative to existing methods. However, the comment could be more helpful if it included additional guidance on how to conduct these ablation experiments or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It also notes that the text mentions separate embedding and addition with positional encoding but lacks clarification on how the embeddings are combined and fed into the CSCM. While the comment identifies a specific area needing clarification, it does not provide explicit instructions on how to address this issue. The authors can infer that they need to provide more detailed explanations, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It also mentions the use of separate embedding and addition with positional encoding but notes the need for clarification on how the embeddings are combined and fed into the CSCM. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections where these concepts are discussed. The comment is specific in detailing what is unclear and what needs clarification, but it lacks full grounding as it does not explicitly reference a specific section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It also notes that the text mentions separate embedding and addition with positional encoding but lacks clarification on how the embeddings are combined and fed into the CSCM. While the comment identifies a gap in the explanation, it does not provide specific reasoning or examples to support the claim. The lack of detailed justification or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to be 5.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the combination of historical observations with inputs known over all time, given differences in sequence lengths. It points out that the text mentions separate embedding and addition with positional encoding but lacks clarification on how these embeddings are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations in the methodology or results sections. By addressing this point, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided specific suggestions on how to present the combination or offered examples of similar approaches. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and the impact on generalization performance. It suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps on how to conduct these experiments or what specific aspects to focus on. The authors can infer that they need to conduct additional experiments, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and its impact on generalization performance. It suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarityaware positive sample selection or where the experiments on transfer performance are mentioned. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these topics are discussed, the lack of explicit references makes the comment weakly grounded. The comment is specific in suggesting additional experiments, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection and its impact on generalization performance. The reviewer suggests conducting additional experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current experiments do not allay the reviewer\"s concerns. This makes the claim 3, as it provides a logical basis for the concern but lacks sufficient evidence or examples to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the potential oversmoothing of GNNbased encoders due to similarityaware positive sample selection, which could lead to excessive convergence and the loss of unique features. It also questions the generalization performance of the model when selecting positive samples from the same dataset without introducing perturbation noise. The reviewer acknowledges that the authors have conducted experiments on transfer performance but suggests that more experiments on different downstream tasks and across different domains would be beneficial. While the comment identifies specific areas of concern and provides a direction for further experimentation, it lacks detailed guidance on how to conduct these experiments or what specific aspects to focus on. The feedback is 4 as it highlights important areas for improvement, but it could be more actionable with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the question or what specific aspects of the discussion should be expanded upon. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not specify which part of the paper this discussion should be included in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not provide details on what aspects of the discussion should be expanded or how the expressiveness of different architectures should be compared. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is important or how it could be addressed. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to SMP and expresses a desire for more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue. The comment does not offer detailed feedback or examples of what additional discussion could include, leaving the authors with a general idea of what might be lacking but without a clear path to improvement. Therefore, the comment is 2, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the types of situations or social norms, such as physical or psychological safety, are not clear in the main paper. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or clarify these aspects. There is no suggestion on what specific information should be included or how it should be presented. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Since the comment lacks actionable details, it is 1.", "grounding_specificity_rationale": "The comment identifies a lack of clarity regarding the types of situations or social norms, such as physical or psychological safety, in the main paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what is unclear, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the types of situations or social norms (e.g., physical or psychological safety) are not clear in the main paper. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the clarity of the types of situations or social norms discussed in the main paper, such as physical or psychological safety. This feedback is 3 as it points out a potential weakness in the paper that could benefit from further clarification or elaboration. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue, such as recommending specific sections to revise or examples to include. While it highlights an area for improvement, the feedback could be more helpful with additional detail or direction. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the inclusion of more baselines and the testing of the method in more domains. It also suggests that the weighting and learning density functions should be better motivated. The reviewer asks for stronger empirical results, specifically mentioning the need for baselines with different design choices and testing in more domains. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that more baselines should be compared and more domains should be tested, and it mentions the need for stronger empirical results. However, it does not specify which parts of the paper these suggestions pertain to, such as which sections discuss baselines or domains. Additionally, while it mentions the lack of motivation for the weighting and learning density functions, it does not provide specific guidance on how to address this issue. The comment is weakly grounded as it does not identify a specific part of the paper, but it is specific in suggesting additional comparisons and empirical results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more baselines should be compared and more domains should be tested, and it questions the motivation behind the weighting and learning density functions. However, the comment lacks specific examples or references to support the claim that these changes are necessary or would improve the paper. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: the need for more baselines to be compared and more domains to be tested, and the lack of motivation for the weighting and learning density functions. It provides a clear and actionable suggestion for the authors to strengthen their empirical results by including additional baselines and testing in more domains. Additionally, it highlights the importance of better justifying the choices made in the methodology, which could help the authors improve the clarity and robustness of their work. However, the comment could be more helpful if it offered specific examples of baselines or domains to consider or provided guidance on how to better motivate the weighting and learning density functions. Overall, the feedback is 4 as it directs the authors toward meaningful improvements, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the results of the proposed methods are not comparable to existing methods, implying that there is limited significance in the proposed methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the results more comparable or what specific changes could be made to enhance the significance of the proposed methods. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results of the proposed methods are not comparable to existing methods, implying that there is limited significance in the proposed methods. However, it does not specify which results or methods are being compared, making it difficult for the authors to identify the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what aspects of the results or methods are not comparable or how they could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results are not comparable to existing methods, suggesting that the proposed methods lack significance. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific comparisons or references to existing methods, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the results of the proposed methods are not comparable to existing methods, implying that there is limited significance in the proposed methods. However, the comment lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address this issue. It does not offer guidance on how to make the results more comparable or what specific aspects of the proposed methods could be improved to enhance their significance. Without actionable advice or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived lack of novelty in the paper, noting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It points out that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment identifies a lack of novelty and suggests that the paper lacks insights into the unique challenges of overcorrelation, it does not provide explicit guidance on how the authors should address these issues or improve the paper. The action is implicit and somewhat vague, as the authors are left to infer what specific changes or additions are needed to enhance the novelty and insights of the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper, specifically mentioning the application of existing literature, such as DeCorr, in a specific domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the introduction and discussion sections, where the novelty and contributions of the paper are typically discussed. The comment is specific in detailing what aspects are lacking in terms of novelty and insights. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It provides a detailed explanation of how the paper merely transposes DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific sections or examples where the lack of novelty is evident, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a perceived lack of novelty in the paper, noting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\"s insights into graph collaborative filtering with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items but suggests that the paper lacks insights into the unique challenges of overcorrelation in recommender systems. While the comment points out a potential weakness, it does not provide specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it prompts the authors to consider the uniqueness of their contribution, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the obtained results, specifically the assumption that the spectrum of a kernel is subgaussian. It notes that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest ways to include Matern kernels in their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they should consider expanding their analysis to include other kernel classes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a limitation in the obtained results, specifically the assumption that the spectrum of a kernel is subgaussian. It mentions that while this assumption is acceptable for Gaussian kernels, it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. However, the comment does not specify which part of the paper discusses these assumptions or results, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in detailing the limitation and the need to consider other kernel classes, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results of the paper could be restrictive due to the assumption that the spectrum of a kernel is subgaussian. It provides a logical reasoning by explaining that while Gaussian kernels are included in this class, other popular classes like Matern kernels are not, as their spectrum only decays polynomially. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s results, specifically the assumption that the spectrum of a kernel is subgaussian. It acknowledges that this assumption is acceptable for Gaussian kernels but points out that it excludes other popular classes like Matern kernels, which have a polynomial decay in their spectrum. This feedback is valuable as it highlights a potential restriction in the paper\"s scope and suggests that the authors should consider including other kernel classes in their analysis. However, the comment could be more helpful if it provided specific suggestions on how to address this limitation or expand the analysis to include Matern kernels. Overall, the comment is 3 as it directs the authors\" attention to a specific area for improvement but lacks detailed guidance on how to implement these changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowledge of the speaker\"s gender beforehand. It also suggests that the accuracy should be calculated after using a gender detection model in the pipeline. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the choice of ELM and its implications for accuracy. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of ELM (male/female) and its implications for accuracy, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the choice of ELM and its implications for accuracy. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male/female) and its implications for accuracy, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. This is a logical claim based on the assumption that the accuracy should be evaluated after considering the speaker\"s gender. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the reasoning behind the suggestion and potentially conduct additional analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the choice of ELM (male/female) and its implications for accuracy. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, which could be a drawback if the speaker\"s gender is not known beforehand. This feedback is clear and actionable, as it prompts the authors to consider the implications of their choice of ELM and how it might affect the accuracy of their model. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered examples of how other researchers have handled similar challenges. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that requires further consideration."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the paper is incremental and lacks technical substance, merely adding a new loss to a previous work. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to enhance the technical substance or what specific changes could be made to add more value to the paper. Without any actionable suggestions or details, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper for being incremental and lacking technical substance, specifically mentioning that it adds a new loss to a previous work ([31]). However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the paper\"s lack of technical substance, but without clear grounding, it is difficult for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is incremental and lacks technical substance, stating that it merely adds a new loss to a previous work. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment critiques the paper for being incremental and lacking technical substance, specifically mentioning that it adds a new loss to a previous work. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might enhance the technical content or originality of their work. Without specific advice or constructive criticism, the authors are left without a clear path to address the issues raised. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the applicability of the model to realworld diffusion processes and suggests that the authors provide empirical evidence to support this claim. While the comment implies that the authors should conduct empirical studies to validate the model\"s applicability, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the empirical studies or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the model to realworld diffusion processes. It suggests that the authors provide empirical evidence to support the claim that the proposed model captures the diffusion phenomena in realworld scenarios. However, the comment does not specify which part of the paper this concern pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact area needing attention. The comment is specific in its request for empirical evidence but lacks grounding, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the applicability of the model to realworld diffusion processes. It suggests that the authors provide empirical evidence to support the claim that the proposed model captures the diffusion phenomena in realworld scenarios. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the model is not applicable. This lack of evidence or detailed justification makes the claim 3, as the authors would need to infer the basis of the concern and develop their own evidence to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical concern regarding the applicability of the model to realworld diffusion processes. It acknowledges the novelty and elegance of the proposed solutions but highlights the need for empirical evidence to validate the model\"s applicability in realworld scenarios. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address by conducting empirical studies or providing additional evidence. However, the comment could be more helpful if it offered suggestions on how to conduct these empirical studies or what specific aspects of the model should be tested. Overall, the comment is 4 as it directs the authors to a crucial area for enhancing the validity and applicability of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a plot of how different weights of the model move after unlearning, specifically to see which layers are affected the most. This is a clear and direct action that the authors can follow to improve their draft. The comment provides a specific and concrete suggestion, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the method,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is the need for a plot showing how different weights of the model move after unlearning, particularly to see which layers are affected the most. This provides clear guidance on what the authors should include in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a plot showing how different weights of the model move after unlearning, specifically to see which layers are affected the most. This is a request for additional information or analysis, rather than a claim or opinion. It does not contain subjective judgments, suggestions, or deductions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends that the authors include a plot showing how different weights of the model move after unlearning, particularly to see which layers are affected the most. This feedback is clear and offers a concrete way for the authors to enhance their analysis and presentation of results. By following this suggestion, the authors can provide a more comprehensive understanding of the model\"s behavior and potentially identify areas for further exploration. However, the comment could be more helpful if it explained why this analysis is important or how it might impact the interpretation of the results. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty of the paper, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. However, the comment does not provide any explicit or implicit actions for the authors to take in response to this critique. It lacks guidance on how the authors might address the perceived lack of novelty or improve their contribution. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically mentioning the ENCODE part and the incremental contribution in the decomposition part. However, it does not specify which part of the paper these aspects are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment lacks specificity as it does not detail what aspects of the ENCODE part or the decomposition part are problematic or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part. However, the comment does not provide any references or detailed reasoning to support this claim, such as comparing the proposed method to the existing work in [10] or explaining how the decomposition part differs from previous approaches. Without specific evidence or detailed analysis, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the novelty of the paper, specifically pointing out that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and the notation in Chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure of key concepts in Section 3 would be helpful. While the comment implies that the authors should consider adding such a figure, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a figure and determine what specific concepts should be illustrated. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"chapter 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the presentation, noting that it is too equationdriven and the notation is convoluted, making it hard to follow. The suggestion to include an illustrative figure of key concepts in section 3 is clear and provides a specific direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation is too equationdriven and the notation in Chapter 3 is convoluted, making it hard to follow. The suggestion to include an illustrative figure of key concepts in Section 3 is a logical recommendation to improve clarity. However, the comment lacks specific examples or detailed reasoning to support the claim that the notation is particularly challenging. This makes the claim 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and the notation in Chapter 3 is convoluted, making it hard to follow. It suggests that an illustrative figure of key concepts in Section 3 would be helpful. This feedback is clear and actionable, providing the authors with a specific suggestion to improve the clarity and accessibility of their work. By offering a concrete recommendation, the comment empowers the authors to enhance the readability and comprehensibility of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the visual presentation of data in Figure 3 could be improved for better readability and aesthetic appeal, specifically mentioning the subscripts. However, it does not provide explicit guidance on how to enhance the visual presentation or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to improve the visual presentation but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular aspect of the visual presentation, namely the subscripts, and suggests that they could be improved for better readability and aesthetic appeal. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the visual presentation of data in Figure 3 could be improved for better readability and aesthetic appeal, specifically mentioning the subscripts. However, the comment does not provide any specific examples or detailed reasoning to support why the current presentation is inadequate or how it could be improved. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the visual presentation of data in Figure 3, noting that the subscripts could be enhanced for better readability and aesthetic appeal. This feedback is clear and actionable, as it provides a concrete suggestion for improving the visual clarity of the data presentation. However, the comment could be more helpful if it offered specific examples or guidance on how to enhance the subscripts or the overall visual appeal. Despite this, the comment is 4 as it directs the authors to a specific aspect of their work that could be improved, providing them with a clear path for enhancing the visual appeal of their data presentation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. However, it does not provide any explicit or implicit actions for the authors to take. The comment does not suggest any changes or improvements to the draft, nor does it offer guidance on how the authors might clarify the issue. As a result, the authors are left without any actionable steps to address the confusion. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. However, it does not specify which part of the paper discusses these normalization methods, making it weakly grounded. The comment is specific in questioning the rationale behind the claim that Online Normalization is unbiased and Batch Normalization is biased, but it lacks grounding as it does not point to a specific section or context in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. The reviewer acknowledges having read other reviews and the author\"s response, but the comment does not provide any additional reasoning, evidence, or references to support the claim that Online Normalization is unbiased and Batch Normalization is biased. Without further explanation or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the distinction between Online Normalization and Batch Normalization, specifically regarding their impact on gradient bias. It acknowledges having read other reviews and the author\"s response, but it does not provide any additional insights, suggestions, or constructive feedback to help the authors clarify the issue or improve their draft. The comment lacks depth and does not offer actionable guidance, leaving the authors without a clear understanding of how to address the confusion. Therefore, it is rated as 2, as it provides minimal value for improving the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It further suggests that this is grounds for rejection because it effectively violates the 9page paper limit. The comment provides a clear and direct action for the authors to address, which is to increase the whitespace in their paper to comply with the page limit. The feedback is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of reduced whitespace, crammed equations, and captions too close to figures, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the problem of violating the 9page paper limit due to these formatting issues. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It suggests that this is grounds for rejection because it effectively violates the 9page paper limit. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the problem or how it violates the page limit. Without detailed evidence or examples, the claim is 3, as it provides a general observation but lacks the necessary justification or specificity to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of the paper, noting that the authors have reduced whitespace, resulting in equations being crammed together and captions being too close to the figures. It suggests that this is grounds for rejection because it effectively violates the 9page paper limit. While the comment highlights a critical issue, it does not provide actionable suggestions on how to address the problem or improve the formatting. The feedback is clear in its observation but lacks depth and guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the technical details and formulations are limited, suggesting that the main novelty lies in the scheme or procedure. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the technical details or formulations, nor is there a suggestion on how to better highlight the scheme or procedure novelty. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"technical details and formulations\" as being limited, suggesting that the main novelty lies in the scheme or procedure. However, it does not specify which parts of the paper are lacking in detail or what specific aspects need improvement. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical details and formulations are limited, suggesting that the main novelty lies in the scheme or procedure. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical details and formulations of the paper, suggesting that the main novelty lies in the scheme or procedure. However, it does not provide specific guidance or suggestions on how the authors might enhance these details or highlight the novelty more effectively. Without actionable feedback or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results presented in Table 3, specifically questioning the validity and diversity of the proposed constrained method. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors should address this issue, such as suggesting ways to improve the validity or diversity of the results or explaining the discrepancy. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, questioning the validity and diversity of the proposed constrained method. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents better results in the Molecule generation experiment (Table 3), but it questions the validity and diversity of the proposed constrained method. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or comparisons to other methods, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the results presented in Table 3, specifically questioning the validity and diversity of the proposed constrained method. This is a relevant observation that could potentially impact the interpretation of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the validity and diversity of their results. Without actionable feedback or specific recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it identifies a potential issue but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more description of the Starcraft environment, possibly in an appendix. While the comment implies an action, it does not explicitly instruct the authors to add this description or specify where it should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add more description and determine where it should be placed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more description of the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper currently lacks this description, making it weakly grounded. The comment is specific in suggesting that additional information about the environment should be included, but it does not provide details on what aspects of the environment need more description. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from more description of the Starcraft environment, potentially in an appendix. However, it does not provide any specific reasoning or examples to support why this additional description is necessary or how it would enhance the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the need for this change. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the paper would benefit from more description of the Starcraft environment, potentially in an appendix. While it identifies a specific area for improvement, it lacks detailed guidance on what aspects of the environment should be described or how this additional information would enhance the paper. The feedback is 3 as it points out a potential gap in the paper, but it could be more actionable with specific suggestions or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include a discussion on the prompt dataset creation and its source for the fewshot case. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific area for enhancement, making it 5. The authors know exactly what needs to be added to their draft, and the feedback is concrete in its guidance. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that a discussion on the prompt dataset creation and its source for the fewshot case should be included. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in its request for a discussion on the prompt dataset and its source, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a discussion on the prompt dataset creation and its source should be included. However, it does not provide any reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors include a discussion on the prompt dataset creation and its source for the fewshot case. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by addressing a potential gap in the discussion. However, the comment could be more helpful if it offered additional guidance on how to structure this discussion or what specific aspects should be covered. Despite this, the feedback is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses difficulty in understanding the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity of their motivation or the content of their paper. The comment lacks actionable details, such as what aspects of the motivation are unclear or how the authors might address the perceived incremental nature of the work. Without concrete steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in understanding the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not specify which part of the paper is unclear or what aspects of the motivation are challenging to follow. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is 1 as it does not identify a specific area for improvement, and it is also not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that it is difficult to follow the motivation of the paper and labels it as an \"incremental engineering paper.\" However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses difficulty in understanding the motivation of the paper and labels it as an \"incremental engineering paper.\" However, it does not provide specific feedback or suggestions on how the authors might improve the clarity of their motivation or the content of their paper. Without actionable guidance or detailed critique, the authors are left without a clear understanding of what needs to be addressed or how to enhance their work. Therefore, the comment is 1, as it does not offer any constructive feedback or direction for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that an ablation study on the weighting method of the crossentropy loss would be beneficial. It provides a specific example of a scenario where the weighting method might have helped, such as in the Atlantis game where repetitive background sounds could be addressed. While the comment implies that the authors should conduct this ablation study, it does not explicitly instruct them to do so. The action is concrete but implicit, as the authors can infer the need for an ablation study based on the suggestion. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests an ablation study on the weighting method of the crossentropy loss, specifically mentioning the Atlantis game as an example where the weighting method might have helped. This provides a clear suggestion for improvement and a specific context for the authors to consider. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting an ablation study and providing a context for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an ablation study on the weighting method of the crossentropy loss would be beneficial, particularly in the context of the Atlantis game where repetitive background sounds could be addressed. The reviewer provides a specific scenario where the weighting method might have helped, which adds some level of justification to the claim. However, the comment lacks detailed reasoning or references to support the claim that the weighting method would be beneficial in other scenarios. This makes the claim 3, as it provides a starting point for the authors to consider but requires further elaboration or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting an ablation study on the weighting method of the crossentropy loss, which is a specific and actionable recommendation. It provides a concrete example from the Atlantis game, where repetitive background sounds could be addressed using the weighting method. This feedback is clear and offers a clear direction for the authors to improve their draft by exploring the impact of different weighting methods on the model\"s performance. However, the comment could be more helpful if it included additional context or examples of how the weighting method might be applied in other scenarios. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a critical weakness in the paper, namely the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and that it involves a new dataset, which is a different train/test split of an existing dataset SQUALL. The comment also mentions another synthetic benchmark paper that is based on a single question template. However, the comment does not provide any explicit or implicit actions for the authors to take to address these issues. It lacks guidance on how the authors might enhance the novelty or incremental nature of their work, or how they could improve the dataset or benchmark. Without specific suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It references the problem of column operations in designing semantic parsers for TexttoSQL and mentions the use of a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in detailing the lack of novelty and incremental nature of the work, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, specifically mentioning the use of a new dataset that is a different train/test split of an existing dataset, SQUALL. It also references another synthetic benchmark paper based on a single question template. However, the comment does not provide specific examples or detailed reasoning to support the claim of lack of novelty, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or references makes the claim 3, as it requires more information to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and that it involves a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. While the comment highlights an important issue, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance the novelty of their work. Without actionable feedback, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it provides insight into a significant weakness but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that more experiments are necessary, indicating a clear action for the authors to take. However, it does not specify which additional experiments should be conducted or how they should be designed. The lack of concrete details on what specific experiments are needed or how to implement them makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more experiments are needed, but it does not specify which part of the paper this pertains to, such as the experimental section or a specific game environment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. However, the comment is specific in its request for additional experiments, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"more experiments are necessary\" but does not provide any reasoning, examples, or references to support this claim. It lacks specific details or evidence to justify why additional experiments are needed or what specific aspects of the current experiments are insufficient. Without further explanation or context, the claim is difficult for the authors to understand and address, making it 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper by noting that the experiments are only conducted on one game environment. It suggests that more experiments are necessary, which is a valid point that could help the authors expand the scope and applicability of their findings. However, the comment lacks specificity and does not provide guidance on which additional environments should be considered or how the experiments should be designed. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, as it provides some direction but lacks depth and detail."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It suggests that this explanation should be supported by solid examples. This feedback provides a clear and direct action for the authors to take, specifying both what needs to be done (explaining the importance of removing these assumptions) and how to do it (using solid examples). The explicit nature of the instruction and the concrete guidance on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the importance of removing these assumptions and the need for solid examples to support this claim. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these assumptions are significant or how their removal impacts the contribution of the paper. Without such support, the claim remains vague and 1, leaving the authors without a clear understanding of what needs to be addressed. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors need to provide more explanation and justification. It highlights the importance of removing certain assumptions, such as bounded variance and bounded gradients, and suggests that this should be supported by solid examples. This feedback is clear and actionable, as it directs the authors to enhance their contribution by providing a rationale for the significance of these assumptions and how their removal impacts the study. However, the comment could be more helpful if it offered suggestions on how to present these examples or provided additional context. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the authors\" claim of implementing ImageNet for the first time, noting that the process is slow and the accuracy is low. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how to address the issues of speed or accuracy, nor are there suggestions for improvement. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" claim of implementing ImageNet for the first time, noting that the process is slow and the accuracy is low. However, it does not specify which part of the paper this claim is based on, such as a specific section or experiment, making it difficult for the authors to pinpoint the exact area needing revision. The comment lacks specificity as it does not detail what aspects of the implementation or accuracy are problematic. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors\" implementation of ImageNet is slow and has low accuracy, citing specific times and accuracy rates. This claim is 3 as it provides quantitative data to support the assertion. However, the comment lacks detailed reasoning or references to specific methods or benchmarks used for comparison, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors\" claim of implementing ImageNet for the first time, noting that the process is slow and the accuracy is low. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address these issues or enhance their implementation. As a result, the comment is 1, as it does not provide the authors with any actionable insights or direction for improving their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but it does not explicitly instruct the authors to conduct this experiment or provide specific guidance on how to implement it. The comment implies an action by questioning the current approach and suggesting a potential improvement, but it lacks concrete details on how to execute this suggestion. Therefore, the comment is 3, as the authors can infer the need for further exploration but are not given explicit instructions on how to proceed.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but it does not specify which part of the paper this suggestion pertains to. The authors can infer that it relates to the methodology or experimental setup sections, but without explicit references, the comment is weakly grounded. However, it is specific in suggesting a potential improvement by using labeled data for consistency training. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, but this claim is not fully supported by the provided references. The references are relevant to graph contrastive learning, but they do not directly address the specific question of using labeled data for consistency training. The comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, which might enhance the model\"s ability to deal with the task of graph anomaly detection. This feedback is 3 as it prompts the authors to consider an alternative approach that could improve their methodology. However, the comment lacks specific guidance or examples on how to implement this suggestion, which would make it more actionable. To be fully helpful, the comment could include detailed suggestions or references to similar studies that have successfully employed labeled data for consistency training. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the classification error of the proposed network compared to the standard softmax network. It suggests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provides a rationale for why this is important. The comment also implies that theoretical justifications would be beneficial for addressing the issue. While the comment explicitly states the need for reporting classification accuracy on ImageNet data, it does not provide specific guidance on how to conduct the analysis or what theoretical justifications might be necessary. The action is explicit but somewhat vague, as it lacks detailed instructions on how to implement the suggested analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the classification error of the proposed network compared to the standard softmax network, suggesting that the authors report the classification accuracy of the proposed classifier on ImageNet data. It also implies that theoretical justifications would be beneficial for addressing the issue. However, the comment does not specify which part of the paper discusses the proposed network or its classification error, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting the need for reporting classification accuracy and theoretical justifications, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the classification error of the proposed network compared to the standard softmax network, suggesting that the authors report the classification accuracy of the proposed classifier on ImageNet data. The comment also implies that theoretical justifications would be beneficial for addressing the issue. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim about the classification error. This makes the claim 3, as it requires additional evidence or detailed reasoning to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the classification error of the proposed network compared to the standard softmax network, suggesting that the authors report the classification accuracy of the proposed classifier on ImageNet data. It also implies that theoretical justifications would be beneficial for addressing the issue. While the comment identifies a potential weakness in the paper and provides a clear suggestion for improvement, it lacks specific guidance on how to conduct the analysis or what theoretical justifications might be necessary. The feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details or examples. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the feasibility of implementing and testing concrete predictions based on the argument that recognition lists are recalled based on items. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their approach. The comment lacks actionable details, such as recommending alternative methods or suggesting ways to test the predictions. As a result, the authors are left without a clear understanding of what steps to take to resolve the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to the argument that recognition lists are recalled based on items. However, it does not specify which part of the paper this argument is discussed in, making it weakly grounded. The comment provides some specificity by questioning the feasibility of implementing and testing concrete predictions based on this argument, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the feasibility of implementing and testing concrete predictions based on the argument that recognition lists are recalled based on items. The reviewer provides a logical reasoning by explaining that in the most common case of recognition, new items comprise the list of all items available in memory (minus the ones seen), and it is challenging to see how such an exhaustive list could be effectively implemented and tested with simulations. This reasoning is based on a logical deduction and common knowledge about memory processes, making the claim 3. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the feasibility of implementing and testing concrete predictions based on the argument that recognition lists are recalled based on items. It provides a logical reasoning by explaining that in the most common case of recognition, new items comprise the list of all items available in memory (minus the ones seen), and it is challenging to see how such an exhaustive list could be effectively implemented and tested with simulations. This feedback highlights a potential limitation in the approach and encourages the authors to consider alternative methods or simulations for testing their predictions. However, the comment could be more helpful if it offered specific suggestions or examples of alternative approaches. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and questions the current form of CD, asking why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment implies that the authors should provide more explanation or examples to clarify these points. While the action is implicit, it is clear and concrete, as it specifies what the authors need to address: describing alternate formulations for CD and clarifying the role of entropy. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and questions the current form of CD, specifically asking why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment references specific lines in the paper (lines 113 and 115), providing full grounding as the authors can accurately identify the parts being addressed. However, the comment lacks specificity as it does not provide detailed guidance on what aspects of CD should be clarified or how alternate formulations could be described. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and questions the current form of CD, asking why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" The comment provides a logical reasoning by questioning the current form of CD and suggesting that it lacks clarity. However, it does not provide specific examples or references to support the claim that entropy is not a suitable measure. This makes the claim 3, as it requires further elaboration or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD). It questions the current form of CD and asks why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" This feedback is clear and actionable, as it prompts the authors to provide more explanation and examples to clarify the concept of CD and its relationship to entropy. However, the comment could be more helpful if it offered specific suggestions or examples of alternate formulations, which would provide even more guidance for the authors. Overall, the comment is 4 as it directs the authors to enhance the clarity and depth of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the assumption for termination states of instructions, noting that it is expensive to label a large number of data manually. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative methods or strategies for labeling data. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption for termination states of instructions, which implies that it relates to the methodology or experimental setup. However, it does not specify which part of the paper discusses these assumptions, making it weakly grounded. The comment is specific in pointing out the issue with the assumption, noting that labeling a large number of data manually is expensive. This provides some guidance on what needs to be addressed, but without explicit references to sections or specific elements, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption for termination states of instructions is strong and that labeling a large number of data manually is expensive. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 2, as it provides some insight but requires more detailed justification to be fully actionable.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption for termination states of instructions, noting that it is expensive to label a large number of data manually. This feedback highlights a limitation in the methodology or experimental setup, which could impact the validity or applicability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing alternative methods for labeling data or discussing potential workarounds. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of clarity in describing the contribution of the paper with respect to ECE_sweep. It explicitly suggests that the paper should be upfront about its contribution and clarifies that the contribution is essentially a way to choose the number of bins using data, which is not fundamentally different from existing estimators. The comment provides a clear and concrete action for the authors to take, which is to clarify the contribution of their work. This makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ECE_sweep,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the contribution, explaining that it is essentially a way to choose the number of bins using data, which is not fundamentally different from existing estimators. The comment suggests that the paper should be upfront about its contribution and clarifies that the reviewer was initially confused about the paper\"s point. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the contribution of the paper with respect to ECE_sweep is not clearly described. The reviewer provides a specific explanation of what the contribution entails, which is a way to choose the number of bins using data, similar to autotuning a hyperparameter in the estimate. The comment suggests that this is not fundamentally different from existing estimators, and it would be more helpful if the paper was upfront about its contribution. While the comment provides a logical reasoning for the claim, it lacks specific references or examples to fully substantiate the critique. Therefore, the claim is 4, as it provides a clear explanation but could benefit from additional evidence or references to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity in describing the contribution with respect to ECE_sweep. It provides a concrete explanation of what the contribution entails, which is essentially a way to choose the number of bins using data, similar to autotuning a hyperparameter in the estimate. The comment suggests that this is not fundamentally different from existing estimators and recommends that the paper should be upfront about its contribution. This feedback is clear and actionable, as it guides the authors on how to improve the clarity and specificity of their contribution. By addressing this feedback, the authors can enhance the comprehensibility and impact of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the related work discusses other methods for training NMT models beyond MLE, such as RL methods, but none of these methods is used as a baseline. However, the comment does not provide any explicit or implicit action for the authors to take. It lacks guidance on whether the authors should include these methods as baselines, compare them to MLE, or address the gap in the literature. Without specific instructions or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work\" and \"other methods for training NMT models beyond MLE,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that none of the discussed methods is used as a baseline, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work discusses other methods for training NMT models beyond MLE, such as RL methods, but none of these methods is used as a baseline. However, the comment does not provide specific examples or references to these other methods, making it difficult for the authors to verify the claim. Without detailed evidence or references, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out a gap in the related work section, noting that while it discusses other methods for training NMT models beyond MLE, none of these methods is used as a baseline. This feedback is 3 as it identifies a potential area for improvement in the paper. However, it lacks specific suggestions or guidance on how the authors might address this gap or incorporate these methods as baselines. Without actionable advice, the authors are left with a general understanding of the issue but without a clear path to improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential ambiguity in the paper regarding the use of the term \"Efficient Proxy.\" The reviewer suggests that the authors clarify whether they are referring to a specific proxy or a family of proxies. While the comment identifies a specific issue with the terminology, it does not provide explicit guidance on how to address this ambiguity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terminology and potentially provide examples or definitions to avoid confusion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of the term \"Efficient Proxy\" in the paper. It suggests that the authors need to clarify whether they are referring to a particular proxy or a family of proxies. However, it does not specify which part of the paper this ambiguity occurs in, making it weakly grounded. The comment is specific in identifying the issue with the terminology but lacks grounding, as the authors cannot confidently determine the exact section or context where this ambiguity arises. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the term \"Efficient Proxy\" in the paper. The reviewer suggests that the use of \"is\" implies a specific proxy, but the absence of a proxy named \"Efficient Proxy\" suggests it refers to a family of proxies. This comment highlights a potential ambiguity in the paper, but it does not provide specific examples or references to support the claim. The reasoning is logical but lacks detailed evidence or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the paper regarding the term \"Efficient Proxy.\" It points out that the use of \"is\" suggests a specific proxy, but the absence of a proxy named \"Efficient Proxy\" implies a family of proxies. This feedback highlights a specific area where the authors need to clarify their terminology to avoid confusion. While the comment effectively identifies a problem, it does not provide detailed guidance on how to resolve the ambiguity or suggest alternative phrasing. Therefore, the comment is 3, as it directs the authors to a specific area for improvement but lacks comprehensive guidance. This aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point describes the methods used in the paper, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, followed by the use of a classical method DBSCAN for clustering. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this stacking is appropriate, if it should be modified, or if additional methods should be considered. Without any actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft based on this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, followed by the use of a classical method DBSCAN for clustering. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the methods being used and the specific issue of stacking them, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point describes the methods used in the paper, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, followed by the use of a classical method DBSCAN for clustering. However, it does not express an opinion, make a claim, or suggest any changes. It is purely descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment provides a factual description of the methods used in the paper, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, followed by the use of a classical method DBSCAN for clustering. However, it does not offer any critique, suggestion, or feedback on the effectiveness or appropriateness of these methods. Without any actionable advice or analysis, the comment lacks helpfulness and does not guide the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. While the comment implies that the authors should explore this aspect, it does not provide explicit instructions on how to conduct this investigation or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore the resilience of the metric and potentially include this in the appendix. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3.a),\" indicating the specific part of the paper being addressed, allowing the authors to accurately identify the section. It is also specific because it raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer further recommends investigating the resilience of the metric to the choice of random projection. While the comment does not specify where this investigation should be included, the authors can infer that it should be in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. The comment provides a logical reasoning for the concern, suggesting that the authors should explore this aspect to ensure the robustness of their results. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further develop the reasoning to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. The reviewer acknowledges that this is unlikely with random projections but still recommends investigating the resilience of the metric to the choice of random projection. This feedback is 3 as it identifies a potential weakness in the methodology and suggests a direction for further exploration. However, the comment could be more helpful if it provided specific guidance on how to conduct this investigation or what aspects to focus on. Overall, the comment offers a valuable insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This feedback is explicit and provides a clear action for the authors to take, which is to include FGT in the evaluation of the proposed method and comparative methods. The comment is also concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the evaluation of FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods. This provides clear guidance on how to improve the draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this evaluation is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of the proposed method, noting that the evaluation of FGT is only used in the ablation study and should be extended to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a direct suggestion for improving the evaluation process. By addressing this point, the authors can enhance the comprehensiveness and validity of their results. However, the comment could be more helpful if it included additional guidance on how to incorporate FGT into the evaluation or why this is important. Overall, the comment is 4, as it directs the authors toward a specific improvement that can strengthen their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the model appears overly simple, describing it as both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the model more complex or what specific aspects need improvement. Without actionable suggestions or details on how to enhance the model, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the model is overly simple, describing it as both a feature and a bug. However, it does not specify which part of the paper discusses the model, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the model are considered overly simple or how this simplicity could be a bug. Without clear guidance on where to focus improvements, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the model is overly simple, describing it as both a feature and a bug. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what aspects of the model are considered overly simple or how this simplicity could be a bug, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the model is overly simple, describing it as both a feature and a bug. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance on how to address the simplicity or what aspects of the model need enhancement, the authors are left without a clear path to improve their draft. Therefore, the comment is 1, as it does not offer any actionable insights or constructive feedback."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the winnertakeall property has been widely used in previous works and questions the novelty of the paper\"s contribution in understanding this behavior with its simplified settings. It also mentions that most of the findings have been reported in previous works. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their contribution. The action is implicit, as the authors can infer that they need to clarify their contribution or provide additional insights, but the comment lacks concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the originality of the paper, specifically questioning the novelty of the paper\"s contribution to the understanding of the winnertakeall property in its simplified settings. It mentions previous works that have used this property and suggests that most of the findings have been reported in previous works. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment provides some specificity by mentioning previous works and the findings reported in Section 5, it does not offer detailed guidance on how the authors might address the issue of originality. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper\"s contribution to understanding the winnertakeall property is not novel, given its simplified settings and the fact that most findings have been reported in previous works. However, the comment does not provide specific references or detailed examples of previous works that have already addressed these findings, making it difficult for the authors to fully understand and address the critique. The lack of explicit references or detailed reasoning makes the claim 3, as the authors would need to invest effort to identify the relevant literature themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the originality of the paper, specifically questioning the novelty of the paper\"s contribution to the understanding of the winnertakeall property in its simplified settings. It points out that this property has been widely used in previous works and that most of the findings have been reported in previous studies. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. While it identifies a potential weakness, it lacks actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should briefly mention the negligible computational cost of CHR, which is currently only in the appendix, in the main paper to help motivate the method. It also recommends providing a rough example of runtimes in the experiments to assist readers who might want to apply the method. While the comment explicitly states the need to include this information, it does not provide specific guidance on how to present the computational cost or runtimes. The action is clear but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should mention the negligible computational cost of CHR, which is currently only in the appendix, in the main paper to help motivate the method. It also recommends providing a rough example of runtimes in the experiments to assist readers who might want to apply the method. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the main paper and the appendix, where the computational cost is discussed. The suggestion is specific in terms of what needs to be addressed, namely, the inclusion of computational cost information and runtime examples. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should mention the negligible computational cost of CHR, which is currently only in the appendix, in the main paper to help motivate the method. It also recommends providing a rough example of runtimes in the experiments to assist readers who might want to apply the method. The comment provides a logical reasoning for why this information should be included, as it can help motivate the method and make it more accessible to readers. However, it lacks specific examples or references to support the claim about the negligible computational cost, which would strengthen the verifiability of the suggestion. Therefore, the comment is 3, as it provides a clear rationale but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment suggests that the authors should include a brief mention of the negligible computational cost of CHR, which is currently only in the appendix, in the main paper to help motivate the method. It also recommends providing a rough example of runtimes in the experiments to assist readers who might want to apply the method. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a concrete suggestion for enhancing the paper. By addressing these points, the authors can better motivate their method and make it more accessible to readers. However, the comment could be more helpful if it included specific guidance on how to present the computational cost or runtime examples. Overall, the comment is 4, as it provides valuable insights for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include additional baselines for code completion tasks. It recommends comparing with existing code completion commercial applications, such as Copilot, and testing them on a smaller subset of RepoEval. This feedback provides a clear and concrete action for the authors to take, specifying both the type of baselines to include and how to test them. The explicit nature of the suggestion and the detailed guidance on implementation make this comment 5.", "grounding_specificity_rationale": "The comment suggests including additional baselines for code completion tasks, specifically mentioning Copilot as a commercial application to compare with. It also recommends testing these baselines on a smaller subset of RepoEval. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental setup or results section. The suggestion is specific in terms of what baselines to include and how to test them, providing clear guidance for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests including additional baselines for code completion tasks, specifically mentioning Copilot as a commercial application to compare with. The reviewer provides a logical reasoning for the suggestion, stating that it is essential to compare with stateoftheart code completion systems. However, the comment lacks specific examples or references to support the claim that Copilot is a relevant baseline or how it should be tested. This makes the claim 3, as it provides a general direction but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors include additional baselines for code completion tasks. It recommends comparing with existing code completion commercial applications, such as Copilot, and testing them on a smaller subset of RepoEval. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance the comprehensiveness and validity of their experimental evaluation. By including these additional baselines, the authors can better position their work in relation to current stateoftheart systems, which is crucial for the credibility and impact of their research. However, the comment could be more helpful if it provided specific guidance on how to implement the comparison or what metrics to use. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. While the comment implies that the authors should provide more information on the selection process and its implications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB), questioning the generalizability of the results. It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. However, the comment does not specify which part of the paper discusses this evaluation, making it weakly grounded. The authors can infer that it relates to the experimental section, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in its request for clarification on the selection criteria and potential implications, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the generalizability of the evaluation by questioning the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that other tasks or datasets might provide different insights. This makes the claim 3, as it provides a logical reasoning but requires further elaboration or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the evaluation by questioning the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and whether other tasks or datasets might yield different insights. This feedback is clear and actionable, as it prompts the authors to provide more context and justification for their evaluation methodology. By addressing this point, the authors can enhance the transparency and robustness of their results. However, the comment could be more helpful if it provided specific suggestions on how to expand the evaluation or included examples of alternative datasets or tasks that could be considered. Overall, the comment is 4, as it directs the authors to a critical area for improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the performance of the shiftedMNIST dataset, specifically why shift=0 performs better than shift~N(0,\u03c32). It also suggests showing the performance of the model and baselines on test samples from the observational (in) distribution. While the comment implies that the authors should provide additional analysis or results to address this question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis to clarify the performance differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"shiftedMNIST,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance difference between shift=0 and shift~N(0,\u03c32) and suggesting the inclusion of performance analysis on test samples from the observational (in) distribution. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the shiftedMNIST dataset, specifically why shift=0 performs better than shift~N(0,\u03c32). It suggests that the authors should show the performance of the model and baselines on test samples from the observational (in) distribution. While the comment questions the reasoning behind the performance difference, it does not provide specific evidence or references to support the claim. The suggestion to show performance on test samples is logical but lacks detailed justification or examples. Therefore, the comment is 3, as it provides a reasonable suggestion but lacks comprehensive evidence or reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a question about the performance of the shiftedMNIST dataset, specifically why shift=0 performs better than shift~N(0,\u03c32). It suggests that the authors should provide more detailed analysis by showing the performance of the model and baselines on test samples from the observational (in) distribution. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a concrete suggestion for additional analysis. By addressing this point, the authors can enhance the comprehensiveness and robustness of their results. However, the comment could be more helpful if it included a rationale or explanation for why this analysis is important or how it might impact the conclusions. Overall, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the description of experimental details is lacking clarity, which makes it difficult for the reader to judge the results. It suggests that the manuscript would benefit from increased clarity in the experimental description. However, it does not provide specific guidance on how to improve the clarity or what aspects of the description need more detail. The action is explicit but vague, as the authors are left to infer the exact changes needed to enhance clarity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking detail and suggests that increased clarity is needed to allow the reader to better judge the results. The comment provides a clear direction for improvement by referencing the \"Questions\" section for further details. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of experimental details lacks clarity, making it difficult for the reader to judge the results. However, it does not provide specific examples or detailed reasoning to support this claim. The reference to \"Questions\" for further details does not fully substantiate the claim, as it does not offer additional context or evidence. Therefore, the comment is 3, as it provides a general critique but lacks specific details or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity in the experimental description, which makes it difficult for the reader to judge the results. It suggests that the manuscript would benefit from increased clarity in the experimental details. However, the comment does not provide specific guidance or examples on how to improve the clarity or what aspects of the description need more detail. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should provide more explanation to clarify the expected results and that the main contribution, the CBR, should be discussed with different optimization strategies and their corresponding results. It also asks for an example of what would happen by minimizing both terms in Eq 3 or only the first term. While the comment explicitly states the need for more explanation and discussion, it does not provide specific guidance on how to implement these suggestions. The authors are given a clear direction but lack detailed instructions on how to execute the actions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing more explanation to clarify the expected results and discussing different optimization strategies and their corresponding results. The comment also includes a specific example of what should be discussed, such as minimizing both terms in Eq 3 or only the first term. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should provide more explanation to clarify the expected results and that the main contribution, the CBR, should be discussed with different optimization strategies and their corresponding results. The reviewer provides a specific example by asking what would happen by minimizing both terms in Eq 3 or only the first term. This level of detail and the inclusion of a concrete example contribute to the claim\"s verifiability. However, the comment could be strengthened by referencing similar works or providing additional context to fully substantiate the claim. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more explanation to clarify the expected results. It also highlights the importance of discussing different optimization strategies and their corresponding results, particularly in relation to the main contribution of the paper, the CBR. The comment includes a concrete example by asking what would happen by minimizing both terms in Eq 3 or only the first term. This level of detail and specificity provides the authors with clear guidance on how to enhance their draft, making the comment 4. However, it could be more comprehensive by suggesting additional aspects to discuss or by offering specific examples of what should be included in the explanation. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. While the comment implies that the authors should provide this definition, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how the definition should be presented or what level of detail is required. However, the authors can infer that they need to add a definition, making the comment 3.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this definition should be included in, such as a specific section or proof. This makes it weakly grounded, as the authors cannot confidently determine where to insert the definition. The comment is specific in suggesting the inclusion of a definition, but without clear grounding, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. This is a request for clarification or additional information, not a claim or opinion that requires verification. It is a factual statement that does not necessitate any justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. This feedback is clear and actionable, as it identifies a specific area where the paper could be improved by providing additional context or clarification for the readers. By addressing this suggestion, the authors can enhance the comprehensibility and accessibility of their work. However, the comment could be more helpful if it provided guidance on how to present the definition or where it should be included in the paper. Overall, the comment is 4 as it directs the authors to a meaningful improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the paper is not selfcontained and requires the supplementary material to understand large parts of the main paper. It also requests the authors to release the source code of their experiments to allow reproducibility. While the comment explicitly states the need for the supplementary material and the release of source code, it does not provide specific guidance on how to improve the selfcontainment of the main paper or how to make the source code available. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper\"s selfcontainment, noting that the supplementary material is necessary to understand large parts of the main paper. It also requests the release of the source code for reproducibility. However, the comment does not specify which parts of the paper are not selfcontained or how the supplementary material is necessary. Additionally, it does not provide specific guidance on how to improve the selfcontainment or release the source code. While the authors can infer that the comment relates to the overall structure and reproducibility of the paper, the lack of detailed guidance makes it 2. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper is not selfcontained and requires the supplementary material to understand large parts of the main paper. It also requests the release of the source code for reproducibility. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is not selfcontained. Without such evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some basis for the request but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s selfcontainment, noting that the supplementary material is necessary to understand large parts of the main paper. It also requests the release of the source code for reproducibility, which is a crucial step in ensuring the paper\"s impact and credibility. While the comment highlights important areas for improvement, it could be more helpful by providing specific suggestions on how to enhance the selfcontainment of the main paper or by offering guidance on how to make the source code available. Despite this, the feedback is 4 as it directs the authors to address critical aspects of their work that can significantly improve its quality and impact. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the importance of the model\"s novel feature, which involves using multiple INs at different speeds in the dynamics predictor. It suggests that the design choice should be ablated to determine its significance. The comment explicitly asks for an evaluation of the added complexity and whether one IN would suffice. This provides a clear and direct action for the authors to take, which is to conduct an ablation study to assess the impact of this feature. The feedback is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment raises a question about the importance of a novel feature in the model, specifically the use of multiple INs at different speeds in the dynamics predictor. However, it does not specify which part of the paper discusses this feature, making it weakly grounded. The comment is specific in its request for an ablation study to determine the added complexity and whether one IN would suffice. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the importance of a novel feature in the model, specifically the use of multiple INs at different speeds in the dynamics predictor. It suggests that this design choice should be ablated to determine its significance. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this ablation is necessary or how it might impact the model\"s performance. Without such evidence or justification, the claim remains 1, as the authors are left without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the importance of a novel feature in the model, specifically the use of multiple INs at different speeds in the dynamics predictor. It suggests that this design choice should be ablated to determine its significance and asks whether one IN would suffice. This feedback is clear and actionable, as it prompts the authors to conduct an ablation study to evaluate the impact of this feature on the model\"s performance. By addressing this point, the authors can gain a better understanding of the model\"s complexity and make informed decisions about its design. However, the comment could be more helpful if it provided additional context or suggestions on how to conduct the ablation study. Overall, the comment is 4, as it directs the authors to a specific area for improvement with actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the opponent in the experiments does not aim to maximize the multiagent payoff proposed by the authors, which is why the opponent is outperformed. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their draft. The comment lacks actionable advice, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experiments, explaining why the opponent is outperformed in terms of the multiagent payoff. The comment provides a clear rationale for this observation, which is that the opponent does not aim to maximize the multiagent payoff but instead focuses on maximizing classical SE and AE. This level of detail helps the authors understand what needs to be addressed in their experiments. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the opponent in the experiments is outperformed because they do not aim to maximize the multiagent payoff proposed by the authors. The reviewer provides a specific example of the opponent maximizing classical SE and AE, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the opponent\"s strategy differs from the authors\" proposed multiagent payoff. Overall, the claim is 4, as it provides a logical explanation but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiments, noting that the opponent is outperformed because they do not aim to maximize the multiagent payoff proposed by the authors. The reviewer provides a clear explanation by pointing out that the opponent focuses on maximizing classical SE and AE, which is different from the authors\" proposed multiagent payoff. This feedback is valuable as it highlights a potential weakness in the experimental setup and suggests that the authors should consider how their opponent\"s strategy aligns with their proposed payoff. However, the comment could be more helpful if it offered suggestions on how to address this issue or improve the experimental design. Overall, the comment is 3 as it provides insight into a specific area for improvement but lacks detailed guidance for action."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide a description of why certain choices were made, such as the use of the REINFORCE algorithm for training instead of PPO. The reviewer implies that this choice might be related to the attention model paper the current paper iterates on, but clarifies that this is only a presumption. While the comment explicitly states that the authors should provide clarification, it does not specify how to do so or what specific aspects of the choice should be explained. The action is explicit but somewhat vague, as the authors know they need to provide clarification but may not be entirely sure of the exact details to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a description of why certain choices were made, such as the use of the REINFORCE algorithm for training instead of PPO. It implies that this choice might be related to the attention model paper the current paper iterates on, but it does not specify which part of the paper this discussion should be included in. The authors can infer that it relates to the methodology or experimental design sections, but the comment lacks full grounding as it does not explicitly mention these sections. However, it is specific in suggesting that the authors should clarify their choice of algorithms. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a rationale for their choice of algorithms, specifically questioning the use of REINFORCE over PPO. The reviewer implies that this choice might be related to the attention model paper the current paper iterates on, but acknowledges that this is only a presumption. The comment lacks specific references or detailed reasoning to support the claim that a justification for the algorithm choice is necessary. This makes the claim 3, as it provides a logical basis for the suggestion but lacks concrete evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should provide a rationale for their choice of algorithms, specifically questioning the use of REINFORCE over PPO. It implies that this choice might be related to the attention model paper the current paper iterates on, but clarifies that this is only a presumption. The comment is clear and actionable, as it directs the authors to explain their reasoning behind specific algorithmic choices, which can help improve the transparency and comprehensiveness of the paper. However, it could be more helpful if it provided specific guidance on what aspects of the choice should be explained or referenced. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify the statement, address the potential disadvantage, or improve the explanation of Theorem 5.1. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clarifies the confusion about the statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. The comment provides a clear indication of what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, the comment does not provide any further explanation, reasoning, or examples to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any further explanation, reasoning, or suggestions on how the authors might clarify or address this potential disadvantage. Without additional context or guidance, the authors are left without actionable feedback to improve their draft. Therefore, the comment is 1, as it does not offer any constructive direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should provide more information on how to use morphologic segmentation across different domains and how it should be conducted differently for different domains. It also questions whether morphologic segmentation is invariant across domains. The comment implies that the paper lacks insight into these aspects and assumes invariance. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions in their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should provide more information on how to use morphologic segmentation across different domains and how it should be conducted differently for different domains. It also questions whether morphologic segmentation is invariant across domains. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections, where morphologic segmentation is likely discussed. The comment is specific in detailing what is missing or unclear, such as the need for insights into domain adaptation and the assumption of invariance. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of information on how to use morphologic segmentation across different domains and whether it should be conducted differently for different domains. The reviewer questions the assumption of invariance and suggests that the paper should provide insights into these aspects. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the paper lacks this information. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the use of morphologic segmentation across different domains and questions whether it should be conducted differently for different domains. It highlights the importance of addressing these questions, given the task domain adaptation, and points out that the paper lacks insight into this aspect. The comment provides a clear direction for the authors to expand their discussion and potentially improve the comprehensiveness of their work. However, it could be more helpful if it offered specific suggestions or examples on how to address these questions. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification regarding the object detection based attention, specifically whether it is performed on the image or on a convolutional feature map. It also suggests that the authors clarify if any rescaling is done based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. This feedback provides clear and explicit actions for the authors to take, ensuring they know exactly what needs to be clarified and how to address it. The comment is 5 as it offers concrete guidance on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"object detection based attention,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified, namely whether the attention is performed on the image or on a convolutional feature map, and whether rescaling is done based on the receptive field. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the object detection based attention, specifically whether it is performed on the image or on a convolutional feature map. It also asks about the rescaling process based on the receptive field. This is a factual request for clarification and does not contain any subjective claims or opinions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of confusion regarding the object detection based attention. It asks for clarification on whether the attention is performed on the image or on a convolutional feature map, and whether rescaling is done based on the receptive field. This feedback prompts the authors to clarify these aspects, which could help improve the clarity and understanding of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address these questions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions the need for a discussion about the Set Transformer and other related works that use summary tokens. This provides a clear action for the authors to take, which is to include a discussion on these topics. However, the comment does not specify how this discussion should be integrated into the paper or what specific aspects should be covered. While the action is explicit, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Set Transformer\" and provides a link to the relevant paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing discussion about the Set Transformer and other related works that use summary tokens. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the paper lacks a discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide any specific reasoning or evidence to support why this discussion is necessary or how it would enhance the paper. The reference to the Set Transformer is a factual statement, but it does not contribute to the claim itself. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, namely the Set Transformer and other related works that use summary tokens. This feedback is clear and actionable, as it directs the authors to include a discussion on these topics, which could enhance the context and relevance of their work. However, the comment could be more helpful if it provided suggestions on how to integrate this discussion or why it is important for the paper. Despite this, the feedback is 4 as it guides the authors toward a meaningful improvement in their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the acceleration of NTK convergence in the highfrequency range using Fourier features. It asks whether the authors overlooked this aspect or if it is not analyzed in the paper. While the comment implies that the authors should address this theoretical support for the merits of Fourier features, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should include this analysis or explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the acceleration of NTK convergence in the highfrequency range using Fourier features. It asks whether this aspect is analyzed in the paper or if it was overlooked. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the theoretical support for the merits of Fourier features, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the acceleration of NTK convergence in the highfrequency range using Fourier features. It asks whether this aspect is analyzed in the paper or if it was overlooked. The comment suggests that this theoretical support is essential for the merits of Fourier features. However, the comment lacks specific evidence, examples, or references to support the claim that Fourier features accelerate NTK convergence. Without detailed justification or examples, the claim remains 3, as the authors would need to infer the importance of this aspect based on the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the acceleration of NTK convergence in the highfrequency range using Fourier features. It asks whether this aspect is analyzed in the paper or if it was overlooked, suggesting that it is an essential theoretical support for the merits of Fourier features. While the comment identifies a potential gap in the analysis, it lacks specific guidance or suggestions on how the authors might address this issue or what additional information could be included. The feedback is 3 as it points out a critical area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of details regarding how the network is made to fit the residual instead of directly learning the inputoutput mapping. While the comment identifies a gap in the explanation, it does not provide explicit guidance on what details should be included or how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more details on this aspect of their methodology. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of details on how the network is made to fit the residual instead of directly learning the inputoutput mapping. This allows the authors to accurately identify the part of the paper being addressed. However, the comment is underspecific because it does not provide detailed guidance on what specific details are missing or how the authors should address this issue. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point questions the lack of details on how the network is made to fit the residual instead of directly learning the inputoutput mapping. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detailed explanation, specifically regarding how the network is made to fit the residual instead of directly learning the inputoutput mapping. This feedback is 3 as it points out a gap in the paper that the authors need to address. However, the comment does not provide specific suggestions or guidance on how to improve the explanation or what additional details should be included. To be more helpful, the comment could offer examples or suggestions on how to clarify this aspect of the methodology. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for details about the experiment setup in Section 3.3, specifically mentioning data augmentation methods, learning rate, etc. This request is clear and direct, providing the authors with a specific action to take. The inclusion of a reference to a relevant paper, \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,\" further supports the need for this information. Therefore, the comment is 5, as it provides a concrete and explicit action for the authors to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely details about the experiment setup, such as data augmentation methods, learning rate, etc. The inclusion of a reference to a relevant paper further supports the need for this information. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual question about the experiment setup in Section 3.3, specifically asking for details on data augmentation methods, learning rate, etc. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by asking for details about the experiment setup in Section 3.3. It requests information on data augmentation methods, learning rate, and other relevant aspects, which could help the authors clarify and enhance their experimental setup. However, the comment lacks depth and does not provide specific guidance or suggestions on how to improve the experiment setup or what specific details are missing. While it points out an area for improvement, it does not offer detailed or actionable feedback, making it 3 but incomplete."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors performed a statistical significance test when comparing the proposed method with baselines. While it implies that the authors should consider conducting such a test, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the test or what parameters to consider. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the statistical significance of the numbers presented in the comparison between the proposed method and baselines. However, it does not specify which part of the paper these numbers are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its request for a statistical significance test, but it lacks grounding as it does not identify the specific part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the statistical significance of the numbers presented in the comparison between the proposed method and baselines. It does not make a claim or express an opinion but rather asks for clarification. The comment is factual and does not require verification, as it is a request for information. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the statistical significance of the numbers presented in the comparison between the proposed method and baselines. It prompts the authors to consider whether they have conducted a statistical significance test, which is a critical aspect of evaluating the effectiveness of their method. This feedback is valuable as it highlights a potential gap in the analysis and encourages the authors to strengthen their methodology. However, the comment could be more helpful if it provided guidance on how to conduct such a test or what specific statistical tests might be appropriate. Overall, the comment is 3 as it identifies an area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It explicitly asks which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This question provides a clear and direct action for the authors to take, as it prompts them to clarify the relationship between the emission distributions and inference tasks. The comment is explicit and provides concrete guidance on what the authors need to address, making it 5.", "grounding_specificity_rationale": "The comment raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM, specifically asking which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. However, it does not specify which part of the paper this question pertains to, leaving the authors to infer that it relates to the sections discussing inference or modeling. While the comment is specific in its inquiry, it lacks grounding as it does not explicitly mention a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It does not present a claim or opinion but rather seeks clarification through a question. As such, it is a normal statement and should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It specifically asks which of the common inference tasks (filtering, smoothing, and marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This question is important as it highlights a potential gap in the paper\"s explanation or demonstration of how these distributions affect inference. By prompting the authors to clarify this aspect, the comment provides a clear and actionable direction for improvement. However, it could be more helpful if it offered suggestions on how to address this issue or provided examples of how similar approaches have been handled in other works. Overall, the comment is 4 as it identifies a critical area for clarification and improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should include an analysis of the reasons behind this outcome, which is an implicit action. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects to focus on. While the action is clear, it lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"analysis of experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the analysis, namely the lack of explanation for the poor performance of the scope prompting method on GPT3.5turbo. The comment provides a clear direction for improvement by suggesting that the authors should analyze the underlying reasons for this outcome. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to provide additional context or analysis to understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it highlights a gap in the paper that the authors can address by conducting a more thorough analysis of the experimental results. By suggesting that the authors should explore the reasons behind the poor performance, the comment provides a concrete direction for improvement. However, it could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to enhance the depth and clarity of their analysis, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation for the lowrank factorization in the introduction is unnecessary, given that the main result is about polytopes. If the result does have implications for lowrank matrix factorization, the reviewer requests that these implications be explicitly discussed. While the comment implies that the authors should address the implications of their result for lowrank matrix factorization, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the implications and determine how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"motivation in the introduction with the lowrank factorization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the motivation, suggesting that it is unnecessary given the main result is about polytopes. If the result has implications for lowrank matrix factorization, the reviewer requests that these implications be explicitly discussed. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the motivation for lowrank factorization in the introduction is unnecessary, given that the main result is about polytopes. The reviewer requests that if the result has implications for lowrank matrix factorization, these implications should be explicitly discussed. However, the comment lacks specific examples or references to support the claim that the motivation is unnecessary or to justify the request for explicit discussion of implications. This makes the claim 3, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the request for additional discussion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation for the lowrank factorization in the introduction, suggesting that it may be unnecessary given the main focus on polytopes. If the result does have implications for lowrank matrix factorization, the reviewer requests that these implications be explicitly discussed. This feedback is clear and actionable, as it directs the authors to reconsider the motivation and potentially expand their discussion to include the implications of their result for lowrank matrix factorization. However, the comment could be more helpful if it provided specific suggestions on how to integrate this discussion or examples of potential implications. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specific method used to solve the minmin problem, but it does not provide any explicit or implicit action for the authors to take. It lacks guidance on whether the authors should clarify the method, provide more details, or address the question in any way. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the specific method used to solve the minmin problem, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine the exact section or context where this method is mentioned, making the comment weakly grounded. However, the comment is specific in its inquiry about the method used, which provides some guidance on what needs to be clarified. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the specific method used to solve the minmin problem. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific method used to solve the minmin problem, which is briefly mentioned in the paper. While it identifies a potential area for clarification, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment is 3 as it points out a gap in the paper, but it does not offer actionable feedback or detailed advice on how to resolve the issue. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the novelty of the paper is limited, as interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any actionable advice or suggestions for the authors to address this issue. It lacks specific guidance on how the authors might enhance the novelty or improve the interpretation of their results. Without concrete steps or suggestions, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically mentioning the interpretation of deep neural network predictions using a linear model. However, it does not specify which part of the paper this critique is based on, such as a particular section or methodology. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment does not provide specific details on what aspects of the novelty are lacking or how the interpretation could be improved. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, as interpreting the prediction of deep neural networks using a linear model is not a new approach. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the novelty of the paper, stating that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not provide any specific suggestions or guidance on how the authors might enhance the novelty or improve the interpretation of their results. Without actionable feedback or constructive advice, the comment lacks helpfulness, leaving the authors without a clear path for improvement. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, it does not provide explicit guidance on how to achieve this or what specific changes should be made to improve the comprehensiveness and generality of the experiments. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand the model size and include more diverse baselines. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, specifically mentioning the limited model size and restrictive baselines for both the language modeling task and image classification task. However, it does not specify which sections of the paper these experiments are discussed in, making it difficult for the authors to pinpoint the exact parts that need improvement. The comment is specific in identifying the issue with the experiments but lacks grounding, as it does not explicitly mention the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments should be more comprehensive and general, specifically mentioning the limited model size and restrictive baselines for both the language modeling task and image classification task. However, the comment lacks specific examples or references to support this claim, such as comparing the model size to industry standards or discussing alternative baselines that could be included. Without detailed justification or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experiments, noting that they should be more comprehensive and general. It points out that the model size is limited and the baselines are restrictive, suggesting that these factors limit the scope and applicability of the results. However, the comment lacks detailed guidance or suggestions on how to address these limitations, such as recommending specific model sizes or baselines to include. While it highlights an important area for improvement, the feedback could be more actionable and helpful by providing concrete steps for the authors to take. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. This is an explicit suggestion that provides a clear action for the authors to take, namely, to incorporate these approaches into their table. The comment is specific and concrete, as it identifies a particular area for improvement and suggests a concrete method to implement it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. However, it does not specify which part of Table1 this suggestion pertains to, nor does it provide details on how these approaches would be integrated or what specific improvements they would bring. While the authors might infer that it relates to the experimental results or methodology sections, the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific in terms of the type of approach to consider, but it is not fully grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. However, the comment does not provide any reasoning, examples, or references to support why this addition would be beneficial or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the significance of this suggestion or how to implement it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach to Table1, specifically mentioning MAML or implicitMAML. This feedback is 3 as it provides a specific suggestion for enhancing the paper by incorporating a particular type of approach. However, the comment lacks depth and does not explain why this addition would be beneficial or how it would improve the paper. It also does not provide guidance on how to integrate these approaches or what specific aspects of the paper could be improved by their inclusion. While the suggestion is actionable, the lack of detailed explanation or context limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper lacks an ablation study to explain why the authors chose the prompt in a specific way, such as using fewshot examples for CoT to improve performance. This feedback implies that the authors should include an ablation study to address this gap in their analysis. While the action is clear, it lacks specific guidance on how to conduct the ablation study or what specific aspects to focus on. The authors know they need to add an ablation study but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an ablation study to explain why the authors chose the prompt in a specific way, such as using fewshot examples for CoT to improve performance. However, it does not specify which part of the paper this critique pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to include an ablation study, but it lacks grounding as it does not point to a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks an ablation study to explain why the authors chose the prompt in a specific way, such as using fewshot examples for CoT to improve performance. This claim is 3 as it highlights a potential gap in the paper\"s analysis and suggests a specific area for improvement. However, the comment does not provide detailed reasoning or examples to fully substantiate the claim, leaving the authors with a general direction but without specific guidance on how to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks an ablation study to explain the choice of prompt, suggesting that using fewshot examples for CoT might improve performance. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by conducting an ablation study. By addressing this gap, the authors can provide a more comprehensive analysis of their approach and its effectiveness. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use the terms \"causal mechanisms\" and \"causality\" carefully, as they are different from the term \"temporal relationship.\" This feedback provides a clear and direct action for the authors to take, ensuring they use the terms correctly. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1\" and the specific term \"causal mechanisms,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"causal mechanisms,\" pointing out that it should be differentiated from \"temporal relationship.\" Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the use of the term \"causal mechanisms\" on page 1. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the use of terminology on page 1, where the term \"causal mechanisms\" is used interchangeably with \"temporal relationship.\" It provides a clear and actionable suggestion to use the terms carefully, ensuring clarity and accuracy in the paper. This feedback is valuable as it helps the authors correct a potential misunderstanding in their work, which could lead to improved clarity and understanding for readers. However, the comment could be more helpful if it provided examples or further explanation of how to differentiate between these terms. Overall, the comment is 4, as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in the reference \"On the Complexity of Learning with Kernels.\" While the comment implies that the authors should add this discussion, it does not provide specific guidance on how to integrate this information or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in a reference. However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the results should be discussed in relation to the reference. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is weakly grounded as it does not specify the part of the paper being addressed, and it is not specific because it lacks detailed guidance on what needs to be discussed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in a reference. However, the comment does not provide specific details or examples from the reference to support the claim, nor does it explain why this discussion is necessary or how it would enhance the paper. Without additional context or reasoning, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered 2, as it provides a general direction but lacks sufficient detail or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should include a discussion on how their results relate to the lower bounds on kernel learning using lowrank approximation, as mentioned in a reference. This feedback is 3 as it points out a potential area for improvement by suggesting a connection to existing literature. However, the comment lacks specificity and does not provide detailed guidance on how to integrate this discussion into the paper or what aspects of the results should be highlighted. While it identifies a relevant area for expansion, the lack of detailed suggestions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. It questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. While the comment implies that the authors should provide more information on the assumptions and their relevance, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the assumptions and their impact on the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. It questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. However, the comment does not specify which part of the paper discusses the use of PCA or where the assumptions are mentioned, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for clarification on the assumptions, but without explicit references to sections or elements of the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. The reviewer questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. The comment references a specific paper by Dombrowski et al. (2022) to support the claim that PCA is a wellknown technique. However, the reference is not directly used to substantiate the claim about the assumptions or the lack of novelty, making the comment 3. The authors would need to further explore the referenced work to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the novelty and significance of using PCA to reduce interaction count, suggesting that it seems intuitive and lacks clarity. It questions the assumptions behind PCA and asks for clarification on how well these assumptions are met. While the comment identifies a potential weakness in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue or enhance the clarity of their work. The feedback is 3 as it prompts the authors to consider the assumptions and their impact on the results, but it lacks actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the fewshot RC models considered in the paper, noting that they are not stateoftheart models. It questions how the performance of these models compares to relation extraction/generation models in fewshot settings. While the comment implies that the authors should provide a comparison or justification for their choice of models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the comparison issue. However, the comment does provide a concrete suggestion by mentioning specific models that could be considered for comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fewshot RC models\" considered in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that these models are not stateoftheart and suggests a comparison with relation extraction/generation models in fewshot settings. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the fewshot RC models considered in the paper are not stateoftheart models, providing specific examples of models that are considered stateoftheart. This claim is supported by references to external works, which provides a clear basis for the assertion. However, the comment could be strengthened by including more detailed comparisons or specific metrics to demonstrate the superiority of the referenced models. Overall, the claim is 4, as it provides a solid foundation for the assertion but lacks comprehensive evidence or detailed analysis. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the fewshot RC models considered in the paper, noting that they are not stateoftheart models. It provides examples of stateoftheart models and suggests a comparison with relation extraction/generation models in fewshot settings. This feedback is clear and actionable, as it directs the authors to consider updating their model selection or providing a comparison to improve the relevance and impact of their work. However, the comment could be more helpful if it included specific suggestions on how to conduct the comparison or what metrics to use. Overall, the comment is 4, as it provides valuable guidance for enhancing the paper, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests the authors to provide results regarding the discussion of using sequential MCB vs a single MCT layers for the decision head. This request is clear and direct, leaving no ambiguity about what the authors need to do to address the feedback. The comment provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB vs a single MCT layers for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests the authors to speak about what was observed regarding this discussion, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information, specifically asking the authors to provide results regarding the discussion of using sequential MCB vs a single MCT layers for the decision head. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that the discussion of using sequential MCB vs a single MCT layers for the decision head is interesting but lacks results. It provides a clear and actionable suggestion for the authors to address by asking them to speak about what was observed in this context. This feedback is specific and offers a direct path for the authors to enhance their draft by providing additional results or analysis. However, the comment could be more helpful if it included suggestions on how to present or interpret these results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment implies that the authors should clarify these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the questions or what information should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. However, it does not specify which part of the paper discusses this choice, making it weakly grounded. The comment is specific in its questions about the choice of distribution sets and the potential impact of selecting fewer sets. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or important. Without additional context or explanation, the authors may find it challenging to understand the basis of the questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises questions about the choice of 20 distribution sets and whether the number of distribution sets for each class can be controlled. It also asks what would happen if only a few distribution sets were selected. While the comment identifies a potential area of concern, it lacks specific guidance or suggestions on how the authors might address these questions or improve their methodology. The feedback is 3 as it prompts the authors to consider these aspects, but it does not provide actionable steps or detailed advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should showcase their approach using transformerbased (masked) language models instead of obsolete language models like ngram HMM and RNN, which are no longer commonly used. This comment explicitly states an action for the authors to take, which is to update their experiments to align with current NLP trends. The suggestion is clear and provides a concrete direction for the authors to follow, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"perplexity experiments\" and the use of \"obsolete language models\" (ngram HMM and RNN), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the language models used and suggests an alternative approach using transformerbased (masked) language models to better align with current NLP trends. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the perplexity experiments are conducted on obsolete language models (ngram HMM and RNN) that are rarely used nowadays. The reviewer suggests that the authors should showcase their approach using transformerbased (masked) language models to better align with current NLP trends. While the claim is based on the observation that these models are outdated, it lacks specific references or detailed reasoning to support why transformerbased models are more relevant or superior. The comment provides a suggestion for improvement but does not fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the perplexity experiments, noting that they are conducted on obsolete language models (ngram HMM and RNN) that are no longer commonly used. It suggests that the authors should showcase their approach using transformerbased (masked) language models to better align with current NLP trends. This feedback is clear and actionable, providing the authors with a concrete suggestion for improvement that can enhance the relevance and impact of their work. By addressing this feedback, the authors can ensure their paper is more aligned with current research practices and trends, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a lack of clarity regarding the estimation of mu, which is the proportion of missing observations. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the clarity of their discussion. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to resolve the problem. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the estimation of mu, which is discussed in the paper. However, it does not specify which part of the paper this discussion occurs in, making it weakly grounded. The comment is specific in pointing out the lack of clarity regarding the estimation of mu, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the discussion on the misestimation of mu is unclear because mu is the proportion of missing observations, and it is not clear how it can be estimated. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this estimation is unclear or how it could be clarified. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the discussion on the misestimation of mu is unclear because mu is the proportion of missing observations. However, it does not provide any suggestions or guidance on how the authors might clarify this issue or improve their explanation. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that only bounds in expectation are provided and asks for highprobability bounds. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment implies that the authors should provide highprobability bounds and consider adding measures of robustness, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that only bounds in expectation are provided and asks for highprobability bounds. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental results or methodology sections. The comment is specific in detailing what needs to be addressed, such as providing highprobability bounds and adding measures of robustness. However, the lack of explicit section references makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that only bounds in expectation are provided and suggests that highprobability bounds would be beneficial. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. The comment provides a logical reasoning for the suggestion, as ensemble methods are known to provide highprobability bounds, and the addition of measures like error bars or standard deviation would enhance the robustness analysis. However, the comment could be strengthened by providing specific examples or references to support the claim about ensemble methods and highprobability bounds. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper, noting that only bounds in expectation are provided and suggests that highprobability bounds would be beneficial. It also recommends using ensemble methods as performed in the experiments and suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, as it provides specific suggestions for improving the paper by enhancing the robustness analysis and providing more comprehensive results. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or provided examples of similar studies that have successfully incorporated highprobability bounds. Overall, the comment is 4 as it directs the authors toward meaningful improvements, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the lack of explicit enforcement of diversity in the model, despite the extensive motivation for diversity in the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to incorporate diversity into the model or suggestions for improvements. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the extensive motivation for diversity and the lack of explicit enforcement of diversity in the model. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper extensively motivates \"diversity\" but does not enforce it explicitly in the model. The reviewer expresses disappointment at the lack of diversity enforcement, suggesting that the authors\" efforts to incorporate diversity were not realized. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains 3, as it provides a general observation but lacks the necessary depth to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of explicit enforcement of diversity in the model, despite the extensive motivation for diversity in the paper. This feedback is valuable as it highlights a potential gap between the theoretical framework and its practical implementation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate diversity into their model. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it provides insight but lacks depth and actionable steps."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This provides a clear and direct action for the authors to take, which is to include these experiments in their study. The comment is explicit and concrete, as it specifies exactly what needs to be added to the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment mentions that \"some experiments are missing,\" specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without clear grounding, the authors may struggle to determine where these experiments should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some experiments are missing,\" specifically mentioning contrastive learning and adversarial learning. However, it does not provide any reasoning, examples, or references to support this claim. Without further explanation or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This feedback is clear and actionable, as it provides the authors with a direct suggestion to enhance their study by including these experiments. However, the comment could be more helpful if it explained why these experiments are important or how they would contribute to the overall understanding of the research. Despite this, the feedback is 4 as it guides the authors toward a clear enhancement of their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results in Table 2, specifically regarding the performance of the complete loss function compared to those with some terms missing. The reviewer questions the logic behind this observation, asking for an explanation. While the comment implies that the authors should provide an explanation for this unexpected result, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question about the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the reported ablation studies, specifically questioning the performance of the complete loss function compared to those with some terms missing. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the results in Table 2, specifically the performance of the complete loss function compared to those with some terms missing. The reviewer points out that the complete loss function performed worse than expected, which is a claim that requires justification. However, the comment does not provide any supporting evidence, reasoning, or references to explain why this observation is unexpected or how it might be addressed. Without additional context or explanation, the claim remains 1, as the authors are left without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the reported ablation studies in Table 2, noting that the complete loss function performed worse than expected for the CUB and SOP datasets. This observation raises a question about the logic behind the results, prompting the authors to provide an explanation. While the comment highlights a potential area of concern, it does not offer specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is 3 as it points out a potential problem, but it lacks depth and actionable advice, making it more suitable for a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests conducting an experiment where the image is occluded, simulating irregularities in neural/behavioral data. It provides a clear rationale for this suggestion, stating that it would allow for inspecting the model\"s longrange inference capacity. The reviewer also implies that these experiments should be included in the final version, unless the authors can provide a convincing reason otherwise. This feedback is explicit and provides concrete guidance on what the authors should do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting an experiment where the image is occluded, simulating irregularities in neural/behavioral data. It provides a clear rationale for this suggestion, stating that it would allow for inspecting the model\"s longrange inference capacity. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors might infer that it relates to the experimental setup or results, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in detailing the suggested experiment and its rationale, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an experiment where the image is occluded to simulate irregularities in neural/behavioral data. The reviewer provides a clear rationale for this suggestion, stating that it would allow for inspecting the model\"s longrange inference capacity. This reasoning is logical and provides a specific suggestion for improving the paper. However, the comment does not include references or examples from existing literature to support the claim that this type of experiment is necessary or beneficial. Therefore, the claim is 4, as it lacks detailed evidence but provides a logical basis for the suggestion.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by recommending an experiment where the image is occluded to simulate irregularities in neural/behavioral data. This suggestion is based on a logical rationale that would allow for inspecting the model\"s longrange inference capacity, which is a valuable addition to the study. The comment also implies that these experiments should be included in the final version, unless the authors can provide a convincing reason otherwise. This feedback is clear and offers a concrete way for the authors to enhance their work, making it 5 for improving the draft. Therefore, the comment deserves a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that a statement in the abstract is unclear and suggests that the abstract should be more highlevel, avoiding technicalities. However, it does not provide specific guidance on how to rephrase the statement or what aspects of it are unclear. The action is implicit, as the authors can infer that they need to clarify the statement, but it lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear in the abstract, namely the statement about ensuring a lowrank feature subspace with a small number of attacked samples and other mild assumptions. The comment provides a clear direction for improvement by suggesting that the abstract should be more highlevel and avoid technicalities. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a statement in the abstract is unclear and suggests that the abstract should be more highlevel, avoiding technicalities. However, the comment does not provide any specific reasoning or examples to support why the statement is unclear or how it could be improved. Without detailed explanation or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a statement in the abstract, noting that it is unclear and should be more highlevel. It provides a clear suggestion to avoid technicalities in the abstract, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it offered specific guidance on how to rephrase the statement or what aspects of it are unclear. Despite this, the feedback is 4 as it directs the authors to improve the clarity and accessibility of their abstract."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding results in other modalities, specifically mentioning languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks, suggesting that other metrics should be considered. While the comment provides a clear direction for expanding the results to include other modalities, it does not specify which modalities or tasks should be included or how to measure performance in those modalities. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests adding results in other modalities, specifically mentioning languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks. However, the comment does not specify which part of the paper should include these additional results or where the current results are presented. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper the comment addresses. The suggestion to include results in other modalities is specific, but the lack of grounding limits the comment\"s effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding results in other modalities, specifically mentioning languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks, suggesting that other metrics should be considered. However, the comment lacks specific examples or references to support the claim that expected test loss is not meaningful in languagerelated tasks. The suggestion to include results in other modalities is logical, but the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests expanding the results to include other modalities, specifically mentioning languagerelated tasks. It also implies that expected test loss might not be as meaningful for languagerelated tasks, suggesting that other metrics should be considered. This feedback is 3 as it provides a clear direction for the authors to consider additional modalities and metrics in their analysis. However, the comment could be more helpful if it offered specific examples of languagerelated tasks or suggested alternative metrics to consider. Overall, the comment is 3 as it guides the authors toward a potential expansion of their results, but it lacks depth and detailed guidance for implementation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the motivation of the work should be further justified, specifically addressing the use of \"fewshot\" in graph link prediction. It highlights the need to explain how the proposed method effectively uses \"fewshot\" and guarantees generalizability to new tasks with 0/few training steps. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or specific steps to take. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation of the work, specifically the use of \"fewshot\" in graph link prediction. It highlights the need for further justification of how the proposed method effectively uses \"fewshot\" and guarantees generalizability to new tasks. However, the comment does not specify which part of the paper discusses the motivation or where the issues with generalizability are presented, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the motivation and generalizability of the work. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified, specifically regarding the use of \"fewshot\" in graph link prediction. The reviewer provides a logical reasoning by explaining that in fewshot learning, the focus is typically on leveraging a few instances to learn a generalizable model. However, the comment lacks specific examples or references to support the claim that the proposed method does not effectively use \"fewshot\" or guarantee generalizability. This makes the claim 3, as it provides a logical framework but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the motivation and justification of the work. It highlights the need to explain how the proposed method effectively uses \"fewshot\" and guarantees generalizability to new tasks with 0/few training steps. This feedback is clear and actionable, as it directs the authors to provide a more thorough explanation of their approach and its benefits. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the use of GP as \"straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their approach. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of GP as \"straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. However, it does not specify which part of the paper this critique pertains to, such as a specific section or methodology, making it difficult for the authors to identify the exact area needing revision. The comment is specific in its critique of the GP approach but lacks grounding as it does not point to a particular part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of GP is \"kind of straightforward and naive\" and suggests that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the GP approach is naive or that dynamical modeling has been extensively explored. Without these elements, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment critiques the use of GP as \"straightforward and naive,\" suggesting that dynamical modeling has been widely investigated in the GP community since the introduction of the Gaussian Process Dynamical Model in NIPS 2005. While the comment highlights a potential weakness in the approach, it lacks specific guidance or suggestions on how the authors might address this critique or improve their methodology. Without actionable feedback or detailed advice, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it identifies a potential issue but does not provide sufficient direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also recommends moving the experimental results from the appendix to the main paper. While the comment implies that the authors should improve their work, it does not provide specific guidance on how to enhance the differential privacy application or what aspects need more clarity. The action is implicit and somewhat vague, as the authors are left to infer the exact changes needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"given2)5)\" and \"the differential privacy application,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. Additionally, it provides a suggestion to move the experimental results from the appendix to the main paper. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the differential privacy application is \"halfbaked\" and suggests that the authors should think through it more clearly. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to justify why the application is considered incomplete or how it could be improved. Without such support, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides some helpful feedback by identifying a potential weakness in the differential privacy application, suggesting that it is \"halfbaked\" and encouraging the authors to think through it more clearly. It also highlights the novelty and interest of the online algorithm and robustness, which is a positive observation. However, the comment could be more helpful if it offered specific suggestions or examples of what aspects need further clarification or improvement in the differential privacy application. Additionally, the suggestion to move the experimental results from the appendix to the main paper is a logical one but lacks detailed guidance on how to present the results effectively. Overall, the comment provides some direction but lacks depth and specificity, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or could be applied more broadly to robotic manipulation. However, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify the scope of their methodology, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or could be more broadly applicable to robotic manipulation. However, it does not specify which part of the paper this issue pertains to, such as a specific section or methodology description. The authors can infer that it relates to the methodology section, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in its critique of the methodology\"s applicability, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point questions the specificity of the proposed methodology, suggesting that it may not be limited to bimanual manipulation and could be more broadly applicable to robotic manipulation. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 2, as it provides some insight but requires more detailed justification.", "helpfulness_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or could be more broadly applicable to robotic manipulation. This feedback is 3 as it prompts the authors to clarify the scope of their methodology and consider its broader applicability. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional experiments or modifications to the methodology. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide the METEOR results, which is also reported in recent works. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the draft. The comment provides concrete guidance on how to implement the action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to provide METEOR results, which are also reported in recent works. This allows the authors to accurately identify the part of the paper that needs attention, such as the results section. The comment is also specific because it clearly specifies what is missing, namely the METEOR results, and references recent works that report these results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide METEOR results, which are also reported in recent works. This is a request for additional information, not a claim or opinion. It does not contain subjective judgments, suggestions, or deductions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, instructing the authors to provide METEOR results, which are also reported in recent works. This feedback is specific and provides a direct suggestion for improvement, allowing the authors to enhance their draft by including additional results. However, the comment could be more helpful if it explained why METEOR results are important or how they would contribute to the paper\"s findings. Despite this, the comment is 4 as it guides the authors toward a concrete improvement, making it a 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a missed opportunity in the paper to discuss the potential benefits of using AutoML approaches beyond improving raw performances. It suggests that the authors should comment on the \"hints\" that can be extracted from the found architecture and what the \"biggest takeaways\" might be. While the comment implies that the authors should address these aspects, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the potential benefits and takeaways of AutoML approaches. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on the potential benefits of using AutoML approaches beyond improving raw performances, specifically mentioning the extraction of \"hints\" that could be used in designing new network architectures. However, it does not specify which part of the paper should include this discussion, making it weakly grounded. The comment is specific in its suggestion to discuss the \"biggest takeaways\" from the found architecture, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where this discussion should be added. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors should discuss the potential benefits of using AutoML approaches beyond improving raw performances, specifically mentioning the extraction of \"hints\" that could be used in designing new network architectures. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of discussing these aspects based on the general idea presented. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by noting that the authors have not discussed the benefits of using AutoML approaches beyond improving raw performances. It suggests that the authors should explore the \"hints\" that can be extracted from the found architecture and what the \"biggest takeaways\" might be. This feedback is clear and actionable, as it directs the authors to consider the broader implications of their work and how it could inform future network architecture design. However, the comment could be more helpful if it provided specific examples or suggestions on how to approach this discussion. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. However, it does not provide specific guidance on how to achieve this conciseness or what specific empirical results should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to make the introduction more concise and include empirical results, but without detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. However, it does not specify which part of the main section or the introduction is problematic or how the empirical results should be integrated. Without explicit references to specific sections or examples, the authors cannot confidently determine which parts need revision. The comment is weakly grounded as it does not pinpoint the exact areas needing attention, and it is not specific in detailing what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. However, it does not provide any specific reasoning, examples, or references to support why the current content is not concise or why empirical results are necessary. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the main part of the paper, particularly the introduction, could be more concise and should include empirical results. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to achieve conciseness or what specific empirical results should be included. The feedback is 3 as it points out a general area for improvement, but it does not offer actionable steps or detailed suggestions, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. However, it does not provide specific guidance on which complex problems to consider or how to conduct these experiments. The action is implicit and somewhat vague, as the authors are left to infer the need for additional experiments without detailed instructions on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or methodology, but the lack of explicit grounding makes it difficult to pinpoint the exact area needing attention. The comment is specific in suggesting the need for more complex experiments, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. However, the comment lacks specific examples or references to support the claim that the current experiments are insufficient or that more complex problems are necessary. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should conduct experiments on more complex problems, particularly those with larger depths that could lead to significant inputs for value and policy functions. This feedback is 3 as it identifies a potential area for improvement by suggesting the need for broader experimentation. However, the comment lacks specificity and does not provide detailed guidance on how to conduct these experiments or what specific complexities should be considered. While it points out a direction for further exploration, it does not offer actionable steps or detailed suggestions, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the novelty and incremental nature of the paper, stating that the improvements on different datasets are trivial and that the topic has been extensively explored in previous works. However, it does not provide any specific guidance or suggestions for improvement. The authors are left without actionable steps to address the critique or enhance the novelty of their work. Without explicit instructions or concrete examples, the comment lacks actionability. Therefore, it is rated as 1.", "grounding_specificity_rationale": "The comment critiques the novelty and incremental nature of the paper, specifically mentioning that the improvements on different datasets are trivial and that the topic has been extensively explored in previous works. However, it does not specify which parts of the paper are being addressed, such as which datasets or sections are discussed. This lack of explicit reference to specific sections or elements of the paper makes it difficult for the authors to pinpoint the exact areas needing revision. Additionally, the comment lacks specificity in terms of what aspects of the paper are considered trivial or incremental. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited, given that many previous works focus on the same topic. However, the comment lacks specific examples or references to support these claims, such as mentioning which previous works are similar or how the improvements are trivial. Without detailed evidence or examples, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 2, as it provides some basis for the critique but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment critiques the novelty and incremental nature of the paper, stating that the improvements on different datasets are trivial and that the topic has been extensively explored in previous works. However, it lacks specificity and does not provide actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of their work need to be revised or how to enhance the novelty of their contributions. Therefore, the comment is rated as 2, as it identifies a potential issue but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. While it identifies an area that needs further exploration, it does not provide explicit guidance on how the authors should address this issue or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a discussion on the theoretical guarantee but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the missing discussion on the theoretical guarantee, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact location for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This feedback is clear and actionable, as it points out a gap in the paper that the authors can address by including a discussion on the theoretical guarantee. However, the comment could be more helpful if it provided suggestions on how to approach this discussion or what aspects to consider. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of quantitative measures to evaluate the generated VCEs, noting that evaluation is primarily based on visual inspection. While the comment identifies a gap in the evaluation process, it does not provide specific guidance on how to address this issue or suggest alternative quantitative measures that could be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to introduce quantitative evaluation methods but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of quantitative measures for evaluating the generated VCEs, noting that evaluation is primarily based on visual inspection. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where evaluation is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for quantitative measures, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation of generated VCEs lacks quantitative measures and is primarily based on visual inspection. This claim is 3 as it highlights a potential gap in the evaluation process, suggesting that a more rigorous approach could be beneficial. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed justification or evidence limits the claim\"s verifiability, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the evaluation process of the generated VCEs, noting that it is primarily based on visual inspection rather than quantitative measures. This feedback is valuable as it highlights a gap in the evaluation methodology, prompting the authors to consider incorporating more rigorous and objective evaluation techniques. However, the comment lacks specific suggestions or examples of quantitative measures that could be employed, which would make it more actionable and helpful. While it points out a critical area for improvement, the feedback could be more comprehensive with additional guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the improvements over baselines are marginal and within the error bar range, questioning the significance of the performance differences. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of marginal improvements or how to improve the method\"s performance. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of the method compared to baselines, specifically mentioning the error range and the claim of better performance. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in detailing the issue with the performance differences, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvements over baselines are marginal and within the error bar range, questioning the significance of the performance differences. However, the comment does not provide specific examples or detailed analysis to support this claim, such as comparing the error ranges or providing data to substantiate the assertion. Without such evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out that the improvements over baselines are marginal and within the error bar range, questioning the significance of the performance differences. This feedback highlights a potential issue with the paper\"s claims of better performance, suggesting that the authors should reconsider their conclusions or provide more detailed analysis to substantiate their claims. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights significant artifacts in the generated videos and notes that only some of the beach videos are convincing. It also mentions that the action recognition performance is below the current stateoftheart on the UCF dataset, which uses more complex architectures. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issues with the generated videos or improve the action recognition performance. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions specific issues with the generated videos, noting significant artifacts and the performance of action recognition on the UCF dataset. However, it does not specify which sections of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact parts that need attention. The comment also includes questions, which could provide some guidance but are not specific enough to be actionable. Therefore, the comment is 2, aligning with category 2.", "verifiability_rationale": "The review point claims that the generated videos have significant artifacts and that the action recognition performance is below the current stateoftheart on the UCF dataset. However, it does not provide specific examples or detailed reasoning to support these claims. The mention of deeper architectures and the use of optic flow is a vague reference that does not fully substantiate the claim. Without more detailed evidence or examples, the authors may find it challenging to address the issues effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies specific issues with the generated videos, noting significant artifacts and the performance of action recognition on the UCF dataset. It also raises questions about the quality of the generated videos and the action recognition performance. However, the comment lacks actionable feedback or suggestions for improvement. It does not provide guidance on how to address the issues with the generated videos or enhance the action recognition performance. Without specific advice or constructive criticism, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding how to make the new proposed evaluation set more diverse and representative compared to the previous method. It also questions the selection of representative images. While the comment identifies a specific area needing clarification, it does not provide explicit guidance or suggestions on how the authors might address these issues. The action is implicit and somewhat vague, as the authors are left to infer what steps to take to improve the clarity and diversity of the evaluation set. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of how the new proposed evaluation set is more diverse and representative compared to the previous method. It also questions the selection of representative images. However, it does not specify which part of the paper discusses the evaluation set or the selection of representative images, making it weakly grounded. The comment is specific in detailing what is unclear, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of how the new proposed evaluation set is more diverse and representative compared to the previous method, and how representative images are selected. However, the comment does not provide any specific reasoning, examples, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the diversity and representativeness of the new proposed evaluation set compared to the previous method. It questions how the new set is more diverse and representative and how representative images are selected. This feedback is clear and actionable, as it prompts the authors to clarify and justify the selection process for the evaluation set. However, the comment could be more helpful if it provided suggestions on how to enhance the diversity or offered examples of how to select representative images. Overall, the comment is 4 as it directs the authors to a critical area needing clarification and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include a background section on the basic RL framework, specifically mentioning elements like the MDP, trajectories, and policy, to clarify the RL context. It also suggests providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. These instructions are clear and provide concrete guidance on what the authors need to do to improve their draft. The feedback is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a background section on the basic RL framework, including elements like the MDP, trajectories, and policy, to clarify the RL context. It also suggests including a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This provides clear guidance on what needs to be addressed, making it easy for the authors to identify the parts of the paper that require revision. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks a background section on the basic RL framework, including elements like the MDP, trajectories, and policy, which would help clarify the RL context. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This feedback is logical and provides a clear rationale for why these additions would improve the paper\"s clarity. However, it does not include specific references or examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid basis for the suggestion but lacks detailed evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of a background section on the basic RL framework, including elements like the MDP, trajectories, and policy. It also suggests including a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This feedback is clear and actionable, providing the authors with specific guidance on how to improve the clarity and comprehensiveness of their draft. By addressing these points, the authors can enhance the reader\"s understanding of the context and the novelty of their contributions. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, specifically mentioning that it may face issues if users continuously add new languages due to limited model capacity. However, the comment does not provide any explicit or implicit actions for the authors to take in response to this limitation. It lacks guidance on how to address this issue, such as suggesting ways to increase model capacity or alternative approaches. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a potential limitation of the proposed method, specifically mentioning that it may face issues if users continuously add new languages due to limited model capacity. However, it does not specify which part of the paper discusses the proposed method or where this limitation is addressed. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how to mitigate this limitation. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests a potential limitation of the proposed method, stating that it may encounter issues if users continuously add new languages due to limited model capacity. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the limitation or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically mentioning that it may face issues if users continuously add new languages due to limited model capacity. This is a relevant observation that could impact the scalability and applicability of the method. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this limitation or improve the method to accommodate additional languages. Without actionable advice or detailed feedback, the authors are left with a general awareness of the issue but no clear path for improvement. Therefore, the comment is 3, as it points out a potential concern but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" in the context of the work described by DoshiVelez and Kim. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should address this question, clarify the relevance, or make any changes to their draft. Without actionable suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the relevance of the term \"interpretable\" in the context of the work of DoshiVelez and Kim. This provides clear guidance on what aspect of the paper needs clarification or further discussion. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the relevance of the term \"interpretable\" in the context of the work described by DoshiVelez and Kim. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" in the context of the work described by DoshiVelez and Kim. While it identifies a potential area for clarification, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with only a vague indication of a possible area for improvement. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the similarity of the proposed method to the approach in reference [10] and suggests that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or whether they should consider incorporating these elements into their method. The comment lacks concrete actions or details on how to implement the suggested changes, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the similarity of the proposed method to the approach in reference [10] and suggests that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, it does not specify which part of the paper this comparison is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not detail what aspects of the proposed method are similar or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the similarity of the proposed method to the approach in reference [10] and suggests that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, the comment does not provide any specific evidence or reasoning to support this claim, such as a detailed comparison of the methods or references to studies that have used similar approaches. Without such support, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the similarity of the proposed method to the approach in reference [10] and suggests that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, it does not provide specific guidance or suggestions on how the authors might address this similarity or how they could differentiate their approach. The comment lacks actionable feedback and does not offer a clear path for improvement, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation in the Atari game results, noting that they are limited to a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the results, what additional games or baselines to include, or how to improve the interpretability of the results. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limitation of the Atari game results, which are limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Atari game result (Section 7.2) is limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the Atari game results, noting that they are limited to a single game and a single baseline, which makes it difficult to interpret. This is a clear and actionable feedback that highlights a weakness in the paper\"s presentation of results. However, the comment does not provide suggestions or guidance on how the authors might address this limitation, such as recommending additional games or baselines to include or suggesting ways to improve the interpretability of the results. While it points out a significant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the evaluation needs experiments on distributed deployment and a larger model. This provides clear guidance on what the authors need to do to improve their draft. The action is direct and concrete, as it specifies the exact experiments that should be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this feedback pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing improvement. While the comment is specific in suggesting the need for experiments on distributed deployment and a larger model, it is 1 because it does not indicate where these changes should be made. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how they would improve the evaluation. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation section of the paper. It suggests that the evaluation should include experiments on distributed deployment and a larger model. This feedback is clear and actionable, providing the authors with a concrete direction to enhance the robustness and applicability of their evaluation. However, the comment could be more helpful if it explained why these experiments are necessary or how they would contribute to the paper\"s findings. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the authors\" claim of superior performance with fewer parameters compared to a baseline. It suggests that the authors should test their model with larger word embedding and LSTM parameters to backup their claim. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct these experiments or what parameters to test. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the model\"s superior performance with fewer parameters compared to a baseline, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the authors\" claim and suggesting that they test their model with larger word embedding and LSTM parameters to backup their claim. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" claim of superior performance with fewer parameters compared to a baseline, suggesting that the authors should test their model with larger word embedding and LSTM parameters to backup their claim. This is a logical request for verification, as it challenges the authors to provide evidence for their claim. However, the comment does not provide specific examples or references to support the claim that the baseline model was tested with standard parameter settings, which would strengthen the argument. Therefore, the comment is 3, as it provides a logical basis for the request but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the authors\" claim of superior performance with fewer parameters compared to a baseline. It suggests that the authors should test their model with larger word embedding and LSTM parameters to backup their claim. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by conducting additional experiments. However, the comment could be more helpful if it included suggestions on how to design these experiments or what parameters to test. Overall, the comment is 4 as it guides the authors toward a potential improvement in their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the introduction of two hyperparameters, k and \u03b7, which require finetuning. It suggests that this finetuning depends on the availability of the environment or a good OPE method. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on what actions the authors should take to resolve the problem or improve the draft. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the introduction of two hyperparameters, k and \u03b7, and their dependence on finetuning, which is contingent on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or where the issue of finetuning is mentioned. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved, such as suggestions for addressing the dependency on finetuning. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the introduction of two hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of two hyperparameters, k and \u03b7, which require finetuning. It highlights the dependency on the availability of the environment or a good OPE method, suggesting that this could be a limitation. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or mitigate its impact. Without actionable advice or further elaboration, the feedback is 3 as it points out a potential concern but does not offer a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the regularization applied to the LN model and the GLM model, suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair. While the comment implies that the authors should consider the regularization methods used in previous models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"LN model\" and \"GLM,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out a discrepancy in the regularization methods used for the LN model and the GLM model, as well as suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the GLM model presented by pillow et al. did not crop the image but used L1 regularization for the filters and a low rank approximation to the spatial filter. This claim is 3 as it references specific regularization methods used in the GLM model, providing some context for the comparison. However, the comment lacks detailed references or examples from pillow et al. to fully substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between the LN model and the GLM model, noting that the authors apply regularization (in the form of a cropped stimulus) to both models, while the GLM model presented by pillow et al. did not crop the image but used L1 regularization for the filters and a low rank approximation to the spatial filter. The comment suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a direction for the authors to enhance their draft. However, it could be more helpful if it included specific suggestions on how to implement these changes or references to similar studies that have successfully made such comparisons. Overall, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. While the comment implies that this is an important aspect to consider, it does not explicitly instruct the authors to conduct this study or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to include a study of inference time but are not given detailed instructions on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting a comparison with previous methods, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. The claim is based on the premise that the current method is direct and does not require detection or keypoint grouping, implying that it should be faster. However, the comment lacks specific examples or references to previous methods, making it difficult for the authors to fully understand the basis of the suggestion. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction but requires more detailed support to be fully actionable.", "helpfulness_rationale": "The review comment suggests that the paper should include a study of inference time, particularly comparing it to previous topdown and bottomup pose estimation methods. This feedback is 3 as it identifies a potential area for improvement by highlighting the importance of evaluating inference speed. However, the comment lacks specific guidance on how to conduct this study or what metrics to use, which would make it more actionable. Additionally, it does not provide any context or explanation for why this comparison is relevant or how it might impact the paper\"s contribution. Therefore, while the comment points out a relevant area for improvement, it does not offer detailed or actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the claim about evolutionary dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. It further mentions that batch normalization standardizes the variance and centers the activation, and recommends discussing these limitations explicitly. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address the limitations or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors are left to infer the exact changes needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim about evolutionary dropout addressing internal covariate shift, suggesting that it is limited in its ability to increase the variance of some lowvariance units. It also mentions batch normalization as a more effective method for standardizing variance and centering activations. However, the comment does not specify which part of the paper discusses this claim, making it weakly grounded. The authors can infer that it relates to the discussion of dropout methods or optimization techniques, but without explicit references, it is challenging to pinpoint the exact section. The comment is specific in detailing the limitations of the claim and suggesting a need for explicit discussion, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claim about evolutionary dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. The reviewer contrasts this with batch normalization, which standardizes the variance and centers the activation. While the comment provides a logical reasoning for the limitation, it lacks specific examples or references to support the claim fully. This makes the comment 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific limitation in the claim about evolutionary dropout addressing internal covariate shift, suggesting that it can only increase the variance of some lowvariance units. It contrasts this with batch normalization, which standardizes the variance and centers the activation. The comment provides a clear and actionable suggestion to discuss these limitations explicitly, which could help the authors refine their understanding and presentation of the dropout method. However, the comment could be more helpful if it offered additional context or examples to further guide the authors in addressing the issue. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be interesting to include not only the retrieved and final attentions but also the tentative attention maps in the qualitative figures. While the comment implies that the authors should add these maps, it does not provide explicit instructions on how to do so or what specific aspects of the tentative attention maps should be included. The action is implicit and somewhat vague, as the authors can infer that they need to add these maps but may not be entirely sure of the exact details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests adding tentative attention maps to the qualitative figures, which implies that the reviewer is referring to the figures where attentions are discussed. However, it does not explicitly mention which figures or sections of the paper this pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of additional attention maps, providing clear guidance on what could be improved. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to include not only the retrieved and final attentions but also the tentative attention maps in the qualitative figures. However, the comment does not provide any reasoning or justification for why this would be beneficial or how it would enhance the understanding of the results. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests an additional element that could be included in the qualitative figures, specifically the tentative attention maps. This feedback is 3 as it provides a specific suggestion for enhancing the visual representation of the results, which could potentially improve the clarity and depth of the analysis. However, the comment lacks detailed guidance on how to incorporate these maps or what specific aspects of the tentative attention maps should be highlighted. While it points out a potential area for improvement, it does not offer comprehensive or actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the author should provide more description about the contribution of the paper. However, it does not specify what aspects of the contribution should be elaborated on or how this description should be incorporated into the paper. The action is explicit but vague, as it lacks concrete guidance on how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the author should provide more description about the contribution of the paper. However, it does not specify which part of the paper lacks this description or what specific aspects of the contribution need elaboration. Without explicit references to sections or examples, the authors cannot confidently determine which parts of the paper need improvement. This makes the comment weakly grounded, as the authors cannot pinpoint the exact areas needing attention. Additionally, the comment lacks specificity because it does not provide detailed guidance on what aspects of the contribution should be expanded upon. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the author should provide more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support why this additional description is necessary or how it would enhance the paper. Without such supporting evidence or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the author should provide more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on what aspects of the contribution should be elaborated upon or how this description should be incorporated into the paper. Without detailed feedback or suggestions, the authors may find it challenging to address the comment effectively. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should include supervised baselines in their experiments, particularly for datasets with a scale of ~100k images. It provides a rationale for why this is important, noting that full annotation is likely available for such datasets and that it would be an informative baseline to compare selfsupervised methods against. The comment is clear and provides concrete guidance on what the authors should do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper should include supervised baselines, particularly for datasets with a scale of ~100k images. It provides a rationale for why this is important, noting that full annotation is likely available for such datasets and that it would be an informative baseline. However, the comment does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. While the authors can infer that it relates to the experimental setup, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in its suggestion but not fully grounded, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper should include supervised baselines, particularly for datasets with a scale of ~100k images. The reviewer provides a logical reasoning by stating that full annotation is likely available for such datasets and that it would be an informative baseline to compare selfsupervised methods against. This reasoning is clear and provides a solid basis for the claim, making it 4. However, the comment could be strengthened by referencing specific examples or studies that support the need for supervised baselines, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines, particularly for datasets with a scale of ~100k images. It provides a rationale for why this is important, noting that full annotation is likely available for such datasets and that it would be an informative baseline to compare selfsupervised methods against. This feedback is clear and actionable, as it directly suggests a specific improvement that the authors can make to enhance the comprehensiveness and validity of their experiments. By addressing this feedback, the authors can significantly strengthen their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the performance differences between methods are minimal across evaluations, with variations less than 1 percentage point. It also mentions that the benchmarks are outdated and likely saturated. However, the comment does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of minimal performance differences or outdated benchmarks. Without actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the performance differences between methods and the minimal variations across evaluations. It also references the outdated nature of the benchmarks, providing a specific reason for the observed results. However, the comment lacks specificity as it does not provide detailed guidance on how to address the issue of minimal performance differences or outdated benchmarks. The authors are informed of the problem but not given clear steps to improve it. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal, with variations less than 1 percentage point, and attributes this to random variation. It also mentions that the benchmarks are outdated and likely saturated. The claim is 3 as it provides a logical explanation for the minimal performance differences, but it lacks specific examples or references to support the assertion about the outdated benchmarks. Including detailed comparisons or references to alternative benchmarks would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s results, noting that the performance differences between methods are minimal and may be attributed to random variation. It also points out that the benchmarks used are outdated and likely saturated. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. Without actionable advice, the authors are left with a general understanding of the problem but without a clear path to resolution. Therefore, the comment is 3, as it provides insight but lacks depth and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and observations about the method\"s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. The comment also points out the absence of BEAR from the baselines and questions the method\"s benefits. While the comment raises important points for consideration, it does not provide explicit instructions or concrete suggestions for the authors to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what steps to take to address the questions and concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and observations about the method\"s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. The comment also points out the absence of BEAR from the baselines and questions the method\"s benefits. However, the comment does not specify which part of the paper these questions and observations are based on, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these issues are discussed, the lack of explicit references makes the comment weakly grounded. The comment is specific in its questions and observations, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point consists of a series of questions and observations, each of which requires verification or further explanation. The first question about the method\"s applicability on Hopper, which has deterministic dynamics, is not supported by evidence or reasoning. The second question about evaluating the method on domains with nondeterministic dynamics is a request for clarification, not a claim. The third question about the absence of BEAR from the baselines is a request for clarification, not a claim. Overall, the comment consists of factual statements and questions, making it \"No\" for the claim extraction step. Therefore, it is classified as \"X.\"", "helpfulness_rationale": "The review comment raises several important questions and observations about the method\"s applicability and benefits. It questions why the method helps on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. This is a valuable suggestion that could help the authors better understand and demonstrate the method\"s effectiveness. Additionally, the comment points out the absence of BEAR from the baselines, which could be a relevant comparison for the authors to consider. However, the comment lacks specific guidance or suggestions on how to address these questions or incorporate BEAR into the analysis. While it identifies areas for improvement, it does not provide detailed actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide a theoretical justification for why cotraining and weight averaging can improve results. While the comment implies that the authors should include this justification, it does not explicitly instruct them to do so. Additionally, it does not provide specific guidance on how to construct this theoretical justification, leaving the authors with a vague understanding of what is expected. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement the suggested action.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging can improve results. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where these methods are discussed. Without explicit references to the paper, the authors may find it challenging to determine where to incorporate this feedback. The comment is specific in its request for a theoretical justification but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a theoretical justification for why cotraining and weight averaging can improve results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide a theoretical justification for why cotraining and weight averaging can improve results. This is a valuable suggestion as it encourages the authors to deepen their understanding of the methods and their impact on performance. However, the comment could be more helpful if it provided specific guidance on what aspects of the theoretical justification should be included or how to approach it. While it identifies a critical area for improvement, the feedback lacks depth and actionable details, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors\" derivation falls into classical learning theorybased bounds, which are not considered realistic unless Bayesian considerations are taken into account. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their derivation. The comment lacks concrete details on what changes or additions should be made to enhance the realism of the bounds. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the authors\" derivation, which is grounded as it pertains to the theoretical aspects of the paper. However, it does not specify which part of the derivation is being discussed, making it weakly grounded. The comment provides a specific critique by suggesting that the bounds are not realistic unless Bayesian considerations are taken into account, but it does not specify where or how these considerations should be integrated into the derivation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" derivation falls into classical learning theorybased bounds, which are not considered realistic unless Bayesian considerations are taken into account. The reviewer provides a specific example of BayesianPAC based bounds, which suggests that the claim is supported by a logical reasoning and a reference to a specific type of bound. However, the comment could be strengthened by providing more detailed reasoning or examples of how the classical bounds are insufficient or how Bayesian considerations would improve the realism of the bounds. Overall, the claim is 4, as it provides a logical basis but lacks comprehensive evidence or detailed examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the authors\" derivation, noting that it falls into classical learning theorybased bounds, which are not considered realistic unless Bayesian considerations are taken into account. This feedback is 3 as it points out a potential limitation in the current approach and suggests a direction for improvement by considering BayesianPAC based bounds. However, the comment lacks detailed guidance or examples on how to incorporate Bayesian considerations into the derivation, which would make it more actionable for the authors. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more details about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that the authors should include these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to present these details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or subsection. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in terms of what details are missing, it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any specific examples, reasoning, or references to support why these details are necessary or how they would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should provide more details about their proposed method. It highlights the need to explain how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. This feedback is clear and actionable, as it directs the authors to enhance their explanation of a critical aspect of their methodology. However, the comment could be more helpful if it provided examples or specific suggestions on how to present these details effectively. Overall, the comment is 4 as it guides the authors toward improving their draft by addressing a key area of uncertainty."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, specifically its difficulty in detecting hallucinations in openended responses. It provides an example scenario where the prompt \"introduce a sports celebrity to me\" could lead to responses about different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. The action is implicit and somewhat vague, as the authors are left to infer that they should consider ways to enhance the method\"s ability to detect hallucinations in openended responses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and provides a specific example scenario where the method might struggle to detect hallucinations in openended responses. It also specifies the issue by discussing the challenge of identifying shared information for consistency checking in responses to the prompt \"introduce a sports celebrity to me.\" This level of detail allows the authors to accurately identify the part of the paper being addressed and what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, specifically in the context of a prompt like \"introduce a sports celebrity to me.\" The reviewer provides a specific example scenario to illustrate the challenge, which is a clear and logical reasoning to support the claim. However, the comment could be strengthened by providing additional examples or references to similar cases where this issue has been observed. Overall, the claim is 4, as it provides a logical basis but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically its difficulty in detecting hallucinations in openended responses. It provides a specific example scenario, \"introduce a sports celebrity to me,\" to illustrate how the sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. This feedback is valuable as it highlights a specific area where the method might struggle, prompting the authors to consider ways to address this issue. However, the comment could be more helpful if it offered suggestions or potential solutions for improving the method\"s ability to detect hallucinations in such scenarios. Overall, the comment is 3 as it provides insight into a potential weakness but lacks actionable guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should verify their conclusion about label noise and model size on MNIST and CNN. This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify how the authors should conduct this verification or what specific aspects of the conclusion need to be verified. While the action is explicit, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of how theoretical findings relate to realworld deep learning models, specifically mentioning the conclusion about label noise and model size on MNIST and CNN. This provides full grounding as it explicitly mentions the theoretical findings and the specific models (MNIST and CNN) being discussed. The comment is also specific because it suggests verifying the conclusion by conducting experiments on these models. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical findings are unclear in their relation to realworld deep learning models, specifically mentioning the conclusion about label noise and model size on MNIST and CNN. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these findings are unclear or how they could be verified. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how theoretical findings relate to realworld deep learning models, particularly in the context of label noise and model size on MNIST and CNN. It suggests that the authors should verify their conclusions by conducting experiments on these models. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and applicability of their findings. However, the comment could be more helpful if it included additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with further details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors should mention that p(y|H_f^(tn)) has to be chosen Gaussian, as otherwise Kalman Filtering and Smoothing and CVI are not possible. It also notes that this assumption is later made in the ELBOs. This feedback provides a clear and direct action for the authors to take, specifying what needs to be mentioned and why. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the issue is addressed, specifically mentioning \"p(y|H_f^(tn))\" and \"ELBOs.\" This allows the authors to accurately identify the sections being addressed. The comment is also specific because it clearly specifies what needs to be addressed: the assumption that p(y|H_f^(tn)) has to be chosen Gaussian to make Kalman Filtering and Smoothing and CVI possible. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"p(y|H_f^(tn)) has to be chosen Gaussian, as otherwise Kalman Filtering and Smoothing and CVI is not possible.\" This claim is supported by logical reasoning, as it explains that the choice of a Gaussian distribution is necessary for specific methods like Kalman Filtering and Smoothing and CVI to be applicable. However, the comment could be strengthened by providing more detailed reasoning or references to specific literature or methods that rely on this assumption. Therefore, the claim is 4, as it provides a logical basis but lacks comprehensive evidence or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improvement by pointing out that the paper should mention that p(y|H_f^(tn)) has to be chosen Gaussian for Kalman Filtering and Smoothing and CVI to be possible. This is an important detail that could be overlooked by the authors, and the comment highlights its significance. By suggesting this addition, the reviewer offers a clear and constructive way for the authors to enhance the clarity and completeness of their draft. However, the comment could be more helpful if it explained why this assumption is necessary or how it impacts the methodology. Overall, the feedback is 4 as it provides a specific direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of weight decay to all layers, suggesting that this could lead to suboptimal training loss and cosine similarities for large weight decay parameters. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analysis. It lacks concrete details on what actions the authors should take to resolve the problem or how they might interpret the results differently. As a result, the comment is vague and does not offer actionable steps for the authors to follow. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weight decay\" and \"cosine similarities,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the plots end at a weight decay strength where cosine similarities are still close to optimal, suggesting that this is a limitation in the analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that weight decay applied to all layers would lead to suboptimal training loss and cosine similarities for large weight decay parameters. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The mention of \"conveniently\" suggests that the absence of reported cosine similarities for large weight decay strengths is a limitation, but this is not substantiated with evidence or examples. As a result, the claim is 3, as it lacks detailed justification or references to support the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of weight decay to all layers, suggesting that it could lead to suboptimal training loss and cosine similarities for large weight decay parameters. It points out that the plots end at a weight decay strength where cosine similarities are still close to optimal, implying that this limitation is not addressed in the paper. While the comment highlights a specific area for improvement, it lacks detailed guidance or suggestions on how the authors might address this issue or what specific changes could be made to improve the analysis. The feedback is 3 as it provides insight into a potential weakness, but it could be more actionable with additional guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the lack of qualitative experiments to demonstrate the validity of the conditional independence model and the need for additional experiments to validate the proposed test metric. The reviewer suggests providing illustrative experimental results, including a toy dataset to demonstrate the separability of inlier features and outlier features, and recommends visualizations or schematic diagrams to aid understanding. These suggestions are explicit and provide concrete guidance on how to address the issues, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"qualitative experiments\" and \"the conditional independence model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as conducting illustrative experiments, using a toy dataset to demonstrate separability, and providing visualizations or schematic diagrams to aid understanding. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model and suggests providing illustrative experimental results. The reviewer also mentions the need for additional experiments to validate the proposed test metric and suggests visualizations or schematic diagrams to aid understanding. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to infer the exact nature of the experiments or visualizations needed to address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it points out the lack of qualitative experiments to demonstrate the validity of the conditional independence model, suggesting that illustrative experimental results could be provided to show the effectiveness of the proposed method. Second, it highlights the need for additional experiments to validate the proposed test metric, recommending the inclusion of visualizations or schematic diagrams to aid understanding. These suggestions are clear and actionable, providing the authors with specific directions to enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered examples of how to conduct these experiments or visualizations. Overall, the feedback is 4 as it guides the authors toward improving their draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that systematically studying the impact of the cost of incentivization on performance would be beneficial. It provides an example of how this could be done, such as analyzing the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how lowering the cost of incentivization might affect the collective return. While the comment implies an action, it does not explicitly instruct the authors to conduct this analysis or provide detailed guidance on how to implement it. The action is somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a specific analysis that would be beneficial, namely studying the impact of the cost of incentivization on performance. It provides an example of how this could be done, such as analyzing the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how lowering the cost of incentivization might affect the collective return. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the analysis or results sections where such an analysis could be included. The suggestion is specific in detailing what kind of analysis would be beneficial. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that systematically studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of how this could be done, such as analyzing the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how lowering the cost of incentivization might affect the collective return. This reasoning is logical and provides a clear direction for further analysis, making the claim 4. However, the comment could be strengthened by referencing similar studies or providing more detailed examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests a valuable analysis that could be conducted to further explore the impact of the cost of incentivization on performance. It provides a specific example of how this analysis could be structured, such as studying the reward incentives for various values of alpha and the collective return. The comment also offers a hypothesis about the roles of \"winners\" and \"cooperators\" and how lowering the cost of incentivization might affect the collective return. This feedback is clear and actionable, as it directs the authors to a specific area for further investigation and improvement. However, it could be more helpful if it included additional guidance on how to conduct this analysis or potential outcomes to expect. Overall, the comment is 4, as it provides a constructive suggestion for enhancing the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the approach description in Section 3 should be revised to make it easier to follow. It also provides a clear action by recommending that the additional page in the cameraready version should be used to extend the approach description rather than adding more experiments. This feedback is direct and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"\u00a7 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the approach description, indicating that it is difficult to follow and suggesting that it should be revised. The comment further provides a clear action by recommending the use of the additional page in the cameraready version to extend the approach description rather than adding more experiments. This level of detail and guidance makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach description in Section 3 is difficult to follow and suggests that it should be revised. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the approach description in Section 3, noting that it is difficult to follow. It provides a clear and actionable suggestion to revise the description, recommending the use of the additional page in the cameraready version to extend the approach description rather than adding more experiments. This feedback is valuable as it directs the authors to focus on improving the clarity and comprehensiveness of their approach description, which is crucial for readers to understand and evaluate the work. However, the comment could be more helpful if it included specific suggestions on how to improve the clarity or examples of what should be added or clarified. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two areas for improvement in the experiments section. First, it suggests that the discussion lacks interpretive insights that would explain why the proposed gyrostructures outperform existing methods. Second, it points out the lack of comparison with other stateoftheart methods that do not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific comparisons or insights should be included. The actions are implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the discussion and comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it details what is missing in the discussion, namely interpretive insights and comparisons with other stateoftheart methods that do not rely on gyrostructures. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights and comparisons with other stateoftheart methods, which could affect the understanding of the proposed gyrostructures\" performance. The comment provides a logical reasoning by suggesting that the lack of comparisons with simpler or more commonly used techniques could impact the evaluation of the proposed approach. However, it does not provide specific examples or references to other stateoftheart methods that could be included for comparison. This makes the claim 3, as it highlights a potential gap in the evaluation but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the experiments section. First, it points out the lack of interpretive insights in the discussion, which could help explain why the proposed gyrostructures outperform existing methods. Second, it notes the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, which could provide a clearer understanding of the proposed approach\"s performance relative to simpler or more commonly used techniques. This feedback is clear and actionable, as it highlights areas where the authors can enhance their experimental analysis and interpretation. However, it could be more helpful if it provided specific suggestions on how to incorporate these comparisons or insights. Overall, the comment is 4, as it directs the authors to important areas for improvement in their experimental discussion."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS over other QFS datasets. While the comment implies that the authors should include additional evidence or analysis, it does not specify what specific evidence or analysis is needed or how to present it. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take without detailed guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS over other QFS datasets. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or analysis. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area that needs improvement. Additionally, while the comment provides a general direction for improvement, it lacks specificity in terms of what evidence or analysis is needed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS over other QFS datasets. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and potential usecases of LMGQS over other QFS datasets. This feedback is clear and actionable, as it directs the authors to provide additional evidence or analysis to strengthen their claims. However, the comment could be more helpful if it offered specific suggestions on what types of evidence or analysis would be most beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the potential impact of regularization effects rather than distillation on the improvements in the teacher\"s performance. It suggests that the authors should conduct proper ablation studies to verify their claims. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on how to design these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and determine the specifics themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the claim that distilling knowledge from the student to the teacher improves the teacher\"s performance. It raises a concern about the potential impact of regularization effects rather than distillation, specifically mentioning the use of finetuning for 10 epochs without earlystopping. This provides clear guidance on what needs to be addressed, such as conducting proper ablation studies to verify the claims. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvements in the teacher\"s performance could be due to regularization effects rather than distillation, as all finetuning is performed for 10 epochs without earlystopping. The reviewer provides a logical reasoning by pointing out that finetuning on GLUE without validation earlystopping often leads to high variances, suggesting the need for proper ablation studies to verify the claims. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim that distilling knowledge from the student to the teacher improves the teacher\"s performance. It suggests that the improvements could be due to regularization effects rather than distillation, as all finetuning is performed for 10 epochs without earlystopping. The reviewer highlights the high variance in finetuning on GLUE without validation earlystopping, which could affect the results. This feedback is clear and actionable, as it prompts the authors to conduct proper ablation studies to verify their claims. However, the comment could be more helpful by suggesting specific experiments or analyses to conduct. Overall, the comment is 4, as it provides valuable insights and guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit suggestions for improving the experiments. First, it recommends adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework\"s robustness and effectiveness. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. These suggestions are clear and provide concrete actions for the authors to take, ensuring they know exactly what improvements to make. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides two distinct suggestions for improvement: (i) adding performance on word similarity and sentence translation tasks, as in the MUSE paper, to enhance credibility, and (ii) including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework. It also recommends including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. These suggestions are supported by logical reasoning, as they align with established practices in the field and would provide a more comprehensive evaluation of the framework. However, the comment could be strengthened by referencing specific examples or studies that have used these tasks or languages, which would make it 5. Therefore, the comment is 4.", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improving the experiments. First, it recommends adding performance on word similarity and sentence translation tasks, as done in the MUSE paper, to enhance the credibility of the framework\"s robustness and effectiveness. This suggestion is clear and provides a concrete way for the authors to strengthen their experimental evaluation. Second, it suggests including morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, in the experiments. This addition would broaden the scope of the experiments and provide a more comprehensive evaluation of the framework. The feedback is detailed and offers valuable insights for the authors to enhance their draft, making it 5. Therefore, the comment deserves a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of node importance in the 1shot scenario and the absence of a 1shot paper setting in the experiments, despite the inclusion of related works like RALE that do have a 1shot setting. While the comment highlights areas of concern, it does not provide explicit or implicit actions for the authors to take. The authors are left without guidance on how to address these issues or improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the use of node importance in the 1shot scenario and the absence of a 1shot paper setting in the experiments, despite the inclusion of related works like RALE that do have a 1shot setting. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the experimental setup and the inclusion of related works, but it lacks grounding as it does not explicitly mention the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the use of node importance in the 1shot scenario and the absence of a 1shot paper setting in the experiments, despite the inclusion of related works like RALE that do have a 1shot setting. The comment provides a logical reasoning by questioning the relevance of node importance in the 1shot scenario and pointing out a discrepancy in the experimental setup. However, it lacks specific examples or detailed references to support the claim fully. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the relevance of node importance in the 1shot scenario and the absence of a 1shot paper setting in the experiments, despite the inclusion of related works like RALE that do have a 1shot setting. This feedback highlights a potential gap in the experimental setup and suggests that the authors should clarify the relevance of their approach in the 1shot scenario. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending additional experiments or modifications to the methodology. While it identifies areas for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. While the comment implies that the authors should expand their discussion on this topic, it does not provide specific guidance on how to do so or what aspects should be included in the expanded discussion. The action is implicit and somewhat vague, as the authors need to infer that they should add more content and determine the specific details themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, it does not specify which part of the paper should include these discussions, making it weakly grounded. The comment is specific in its request for additional discussion on a particular topic, but without clear grounding, the authors may find it challenging to determine where to make these additions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there should be more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that there should be more discussions about why LLMs struggle with finegrained hard constraints and how to address these problems. This feedback is clear and actionable, as it provides a direction for the authors to expand their discussion and potentially enhance the depth and relevance of their work. However, the comment could be more helpful if it offered specific suggestions or examples on how to approach this topic. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of insight into why selfsupervised learning is needed on 360 video data with spatial audio. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should provide more justification or explanation, but it lacks concrete steps or details on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of insight into why selfsupervised learning is needed on 360 video data with spatial audio. However, it does not specify which part of the paper this issue pertains to, such as a specific section or discussion where this insight could be provided. Without explicit references to the paper, the authors cannot confidently determine the exact part of the paper being discussed. Additionally, the comment lacks specificity regarding what kind of insight is needed or how it could be provided. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental results suggest the value of the proposed approach for selfsupervised learning on 360 video data with spatial audio, but it lacks insight into why this type of data requires selfsupervised learning. The comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that selfsupervised learning is necessary for this data. Without additional context or justification, the claim remains 1, as it does not offer the authors a clear path to address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the need for selfsupervised learning on 360 video data with spatial audio. It points out that while the experimental results suggest the value of the proposed approach, there is a lack of insight into why this type of data requires selfsupervised learning. This feedback is 3 as it highlights an area where the authors could provide more justification or explanation. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as what additional insights or explanations could be included. To be more helpful, the comment could suggest potential areas of focus or examples of how other researchers have addressed similar questions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to average their results over multiple runs to determine statistical significance. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete step for the authors to follow, ensuring they know exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests averaging results over multiple runs to determine statistical significance. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or a specific experiment. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to average results, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests averaging results over multiple runs to determine statistical significance. This is a logical suggestion based on common practices in experimental analysis. However, the comment does not provide specific examples or references to support why this is necessary or how it would improve the paper. While the suggestion is reasonable, it lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending that the authors average their results over multiple runs to determine statistical significance. This feedback is specific and offers a concrete step for the authors to take to enhance the robustness and validity of their findings. By addressing this point, the authors can strengthen their results and provide a more comprehensive analysis. However, the comment could be more helpful if it explained why averaging is important or how it would impact the paper\"s conclusions. Overall, the feedback is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the tradeoffs between annotation effort and training performance. While the comment implies that the authors should make these observations and conclusions more prominent, it does not provide specific guidance on how to achieve this, such as suggesting where to place them or what format to use. The action is implicit and somewhat vague, as the authors can infer that they need to make changes but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the tradeoffs between annotation effort and training performance. However, it does not specify which part of the experimental section contains these observations or conclusions, making it difficult for the authors to pinpoint the exact areas needing attention. While the comment provides a general direction for improvement, it lacks specificity and grounding, as it does not identify a specific section or element of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to better understand the tradeoffs between annotation effort and training performance. However, the comment does not provide specific examples or detailed reasoning to support why these observations and conclusions are currently hidden or how they could be better highlighted. Without additional context or evidence, the claim lacks sufficient justification, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of observations and conclusions in the experimental section, suggesting that they are hidden and could be better highlighted to understand the tradeoffs between annotation effort and training performance. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the clarity and impact of their work. However, the comment could be more helpful if it offered suggestions on how to effectively highlight these observations and conclusions, such as through specific formatting or placement within the paper. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the KDE\"s requirement for more data when the classifier space is beyond binary, as mentioned in Remark 1. It also references an alternative approach by Zhang et al. that does not seem to have this issue. The comment suggests showing a comparison of performance on datasets with decision spaces beyond binary. While the comment implies that the authors should include such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Remark 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it is possible to show a comparison of performance on datasets with decision spaces beyond binary. This provides clear guidance on what the authors need to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the KDE\"s requirement for more data when the classifier space is beyond binary, as mentioned in Remark 1. It contrasts this with an alternative approach by Zhang et al. that does not seem to have this issue. The comment suggests comparing the performance on datasets with decision spaces beyond binary. However, the claim lacks specific examples or detailed reasoning to support the assertion that the alternative approach does not face the same issue. The reference to Zhang et al. is not sufficient to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the KDE\"s requirement for more data when the classifier space is beyond binary, as mentioned in Remark 1. It contrasts this with an alternative approach by Zhang et al. that does not seem to have this issue. The comment suggests that the authors should consider showing a comparison of performance on datasets with decision spaces beyond binary. This feedback is 3 as it identifies a potential limitation in the paper and provides a direction for further exploration. However, it lacks specific guidance on how to conduct the comparison or what aspects to focus on, which could be improved to make the comment more actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not provide explicit instructions or suggestions on how the authors should address these questions or investigate the potential issues. The lack of guidance leaves the authors uncertain about what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity as it does not provide details on what aspects of the SR model capacity or the pipelining method are causing the unexpected artifacts. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions: \"How the capacity of the SR model affects the FID\" and \"whether there are unexpected artifacts due to the proposed method being pipelined.\" These are requests for clarification or additional information, not claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. While these questions are relevant and could lead to valuable insights, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address these questions or investigate the potential issues. Without actionable feedback or detailed advice, the authors are left without a clear path for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these additional experiments to enhance the paper. The comment is specific and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. This allows the authors to accurately identify the part of the paper being addressed, which is the experimental section. The comment is also specific because it clearly specifies what is missing in the experiments, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not provide any specific examples, reasoning, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it provides specific areas where the authors can enhance their work by conducting additional experiments. However, the comment could be more helpful if it offered suggestions on which specific comparisons or ablations should be conducted or how to analyze hyperparameters. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the experimental results, noting that the proposed method does not have an advantage over the stateoftheart (SOTA) without prior information. It suggests that the comparison is unfair because the proposed method requires two representation models, VAE/GAN and CL, which adds complexity and cost. While the comment identifies a potential issue with the experimental setup, it does not provide explicit guidance on how the authors should address this concern or improve their methodology. The action is implicit and somewhat vague, as it lacks specific suggestions on how to adjust the experiments or mitigate the complexity issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method lacks an advantage without prior information and that the comparison is unfair due to the additional complexity and cost of using two representation models. The comment provides a clear basis for the authors to understand what needs to be addressed in their experimental setup. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method lacks an advantage over the stateoftheart (SOTA) without prior information, and that the advantage only shows when using prior knowledge. The reviewer provides a logical reasoning by pointing out that the proposed method requires two representation models, VAE/GAN and CL, which adds complexity and cost. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim about the unfairness of the comparison. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, noting that the proposed method lacks an advantage over the stateoftheart (SOTA) without prior information. It points out that the advantage only appears when using prior knowledge, which is considered unfair because it requires two representation models (VAE/GAN and CL) for each dataset. This feedback highlights a critical flaw in the experimental setup and suggests that the complexity and cost of the proposed method should be considered. While the comment effectively identifies a weakness, it could be more helpful by offering suggestions on how to address this issue, such as proposing alternative experimental setups or methods to mitigate the complexity. Overall, the comment is 3 as it provides valuable insights but lacks actionable guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. While the comment implies that the authors should add collaborative games to their experiments, it does not provide specific guidance on which games to choose or how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests adding collaborative games to the experiments to evaluate the methods in both collaborative and competitive settings. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or experiments, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in its request for collaborative games but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this would be interesting or beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the experiments should include collaborative games to evaluate the methods in both collaborative and competitive settings. This feedback is 3 as it identifies a potential area for improvement in the experimental design. However, the comment lacks specificity and does not provide guidance on how to implement collaborative games or what specific benefits might be gained from doing so. While it points out a direction for enhancement, it does not offer detailed actionable steps or reasoning, leaving the authors with a general idea but limited guidance on how to proceed. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. However, it does not provide explicit guidance on what specific information should be included or how the authors should present it. The action is implicit, as the authors can infer that they need to provide experimental settings, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. However, it does not specify which part of the paper discusses these figures, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in identifying the issue of missing experimental settings, but it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental settings for Figures 1 to 9 are missing, which makes the results less convincing. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant issue with the paper, noting the absence of experimental settings for Figures 1 to 9, which makes the results less convincing. This is a critical observation that highlights a gap in the presentation of the experimental results, which is essential for the paper\"s credibility. However, the comment does not provide specific suggestions on how to address this issue or what information should be included in the experimental settings. While it points out a significant weakness, it lacks actionable guidance, making it 3. The authors are given a clear direction to improve their draft but are left without detailed instructions on how to do so. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential ambiguity in the rationale behind the proposed method, specifically questioning how it avoids impeding the learning of new task knowledge. While it identifies a gap in the explanation, it does not provide explicit guidance or suggestions on how the authors might clarify this aspect. The action is implicit and somewhat vague, as it leaves the authors to infer that they need to provide a clearer explanation but does not specify how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the rationale behind the work, which is based on the observation that current parameter isolation methods hinder the acquisition of new task knowledge. It also references the suggestion of pathway protection based on the sparsity exhibited by activation channels in deep networks. However, the comment is underspecific because it does not specify which part of the paper lacks clarity or what specific aspects need to be addressed to clarify the ambiguity regarding the proposed method. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the rationale behind the work is unclear regarding how the proposed method avoids impeding the learning of new task knowledge. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The comment lacks detailed reasoning or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the rationale behind the proposed method, specifically questioning how it avoids impeding the learning of new task knowledge. It highlights a gap in the explanation by pointing out that some parameter isolation methods are specifically tailored to leverage sparsity, which could be relevant to the authors\" work. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this aspect or improve their explanation. While it raises an important point, the feedback lacks actionable details, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment raises concerns about the adhoc nature of the regularization term and suggests that the authors provide theoretical support for it. It also implies that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. While the comment identifies areas for improvement, it does not explicitly instruct the authors to make specific changes or provide detailed guidance on how to address the issues. The action is implicit and somewhat vague, as the authors can infer that they need to provide theoretical justification and consider alternative statistics, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"regularization term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the adhoc nature of the regularization term and suggests alternative statistics, such as the median, that could be used instead of the mean and standard deviation. The comment also raises a question about why these alternatives were not considered, which further specifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the regularization term is adhoc and lacks theoretical support, suggesting that other statistics, such as the median, could be used instead of the mean and standard deviation. The comment provides a logical reasoning by pointing out the potential sensitivity of the mean to outliers, which could affect the regularization. However, it lacks specific examples or references to other statistics that could be used, making the claim 3. The authors would need to explore these alternatives themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the regularization term, noting that it appears adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization, which could provide a more robust and theoretically grounded approach. The comment also raises a question about why these alternatives were not considered, which prompts the authors to reflect on their choice of regularization and potentially explore alternative methods. This feedback is clear and actionable, providing the authors with a specific direction for improvement by suggesting alternative statistics and encouraging a deeper theoretical analysis. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should integrate benchmark comparisons against stateoftheart fairness algorithms in the experimental section. This is a clear and direct action that the authors can take to enhance their paper. The comment provides a concrete suggestion by specifying the need for benchmark comparisons, which would offer tangible evidence of the proposed method\"s performance and position it within the existing FairML research landscape. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by suggesting the inclusion of benchmark comparisons with existing fairness algorithms. This provides clear guidance on what needs to be addressed to enhance the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should include comparisons with existing fairness algorithms in the experimental section. The reviewer provides a logical reasoning by stating that such comparisons would enhance the paper\"s evidence of the proposed method\"s performance and position it within the existing FairML research landscape. However, the comment lacks specific references to existing fairness algorithms or detailed examples of how these comparisons could be conducted, which would strengthen the justification. Therefore, the claim is 3, as it provides a logical basis but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental section by noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would enhance the paper\"s evidence of the proposed method\"s performance and position it within the existing FairML research landscape. This feedback is valuable as it guides the authors on how to strengthen their experimental section and improve the overall impact of their work. However, the comment could be more helpful if it offered specific examples of algorithms to compare against or detailed guidance on how to conduct these comparisons. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential negative transfer of supervised pretraining based on the prediction of homolumo gap, specifically mentioning the poor performance of TransformerM on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. The comment suggests that this finding may contradict the claim of the paper being a \"generalpurpose neural network model.\" While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this contradiction or improve their model. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the negative transfer and its implications for their model\"s generalpurpose claim. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the prediction of the homolumo gap and the performance of TransformerM on QM9 in downstream experiments, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the potential negative transfer and the contradiction with the claim of the paper being a \"generalpurpose neural network model.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that supervised pretraining based on the prediction of homolumo gap may lead to negative transfer, citing the poor performance of TransformerM on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. The comment provides a specific example to support the claim, which is a clear and logical reasoning. However, it could be strengthened by providing more detailed analysis or references to similar cases in the literature. Overall, the claim is 4, as it provides a solid basis for the argument but lacks comprehensive evidence or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the potential negative transfer of supervised pretraining based on the prediction of homolumo gap, specifically mentioning the poor performance of TransformerM on most tasks other than homo, lumo, and gap on QM9 in downstream experiments. This observation is relevant and could be a significant issue for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might investigate or resolve this issue, such as recommending alternative approaches or further analysis. While it identifies a potential problem, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the term \"distributional generalization\" might be too strong to describe the empirical phenomenon presented in the paper. It provides a rationale for this by explaining that the phenomenon is more accurately described as the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero, which might not be the case. However, the comment does not explicitly instruct the authors to change the terminology or provide guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they might need to reconsider the terminology but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"distributional generalization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the terminology used to describe the phenomenon, suggesting that it might be too strong and that the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero might not be the case. The comment offers a specific suggestion for improvement by proposing a more accurate description of the phenomenon. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"distributional generalization\" might be too strong to describe the empirical phenomenon presented in the paper. The reviewer provides a logical reasoning by explaining that the phenomenon is more accurately described as the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero, which might not be the case. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the reasoning and potentially conduct further analysis to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific critique of the terminology used to describe the phenomenon, suggesting that \"distributional generalization\" might be too strong a term to capture the empirical phenomenon presented. It offers a more accurate description of the phenomenon as the ideal of the total variation between the test and train distributions of the network\"s outputs vanishing to zero, which might not be the case. This feedback is clear and actionable, as it guides the authors to reconsider their terminology and provides a more precise description of the phenomenon. However, the comment could be more helpful if it included suggestions on how to rephrase the terminology or offered examples of alternative descriptions. Overall, the comment is 4, as it directs the authors to improve the clarity and accuracy of their terminology, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a critique of the theoretical contribution, stating that it is \"ok but not particularly strong\" and that it is a \"weak, unpractical bound.\" However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how to strengthen the theoretical contribution or improve the practicality of the bound. The comment lacks actionable advice, leaving the authors without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the theoretical contribution, stating that it is \"ok but not particularly strong\" and that it is a \"weak, unpractical bound.\" However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the theoretical contribution are weak or unpractical. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the theoretical contribution, stating that it is \"ok but not particularly strong\" and that it is a \"weak, unpractical bound.\" The reviewer provides a rationale by mentioning that the proof does not offer \"particular mathematical novelty\" and that it is a \"weak, unpractical bound.\" However, the comment lacks specific examples or references to existing results that could substantiate the claim, making it 3. The authors would need to explore the existing literature to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the theoretical contribution, stating that it is \"ok but not particularly strong\" and that it is a \"weak, unpractical bound.\" It also mentions that the proof does not provide \"particular mathematical novelty.\" However, the comment lacks specificity and does not offer any actionable advice or suggestions for improvement. It does not provide guidance on how the authors might strengthen their theoretical contribution or enhance the practicality of the bound. Without actionable feedback or constructive criticism, the comment does not help the authors in making meaningful improvements to their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with the wording in lines 240 and 428, suggesting that the phrase \"is sufficient\" needs clarification. It provides a potential correction, indicating that the authors might want to write that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This feedback is explicit and provides a clear direction for the authors to improve their draft by clarifying the intended meaning. The action is concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L240 and L428), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified: the phrase \"is sufficient\" should be clarified by writing that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This provides clear guidance on how to improve the draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the phrase \"is sufficient\" and suggests a potential correction, providing a logical reasoning for the claim. However, it does not offer specific examples or references to support the suggestion, making it 3. The authors would need to infer the exact correction based on the provided reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in lines 240 and 428, questioning the phrase \"is sufficient\" and suggesting a potential correction. It provides a clear and actionable suggestion for improvement by offering a specific alternative wording that could clarify the intended meaning. This feedback is valuable as it directs the authors to a precise area of their draft that needs revision, offering a concrete step toward enhancing the clarity and accuracy of their work. However, the comment could be more helpful if it explained why the current wording is unclear or how the suggested correction would improve the paper. Overall, the comment is 4, as it provides actionable guidance but could be more comprehensive with additional context or explanation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out that the VAD description is puzzling and suggests that it is not a true VAD because it discards TF bins with a magnitude less than epsilon, which results in a division by zero. The reviewer clarifies that a VAD should look for the presence of speech and is typically defined over time, not frequency. This feedback provides a clear and explicit action for the authors to reconsider their VAD description and ensure it aligns with the correct definition. The comment is 5 as it offers specific guidance on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Your VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is puzzling about the VAD description and provides a detailed explanation of what a VAD should entail. The comment explains that the VAD is not correctly defined and suggests that it should be based on the presence of speech rather than just energy, and should be defined over time rather than frequency. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the VAD description is puzzling and suggests that it is not a true VAD because it discards TF bins with a magnitude less than epsilon, which results in a division by zero. The reviewer provides a clear explanation of what a VAD should entail, emphasizing that it should look for the presence of speech and be defined over time, not frequency. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific examples or literature to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a clear and specific critique of the VAD description in the paper, pointing out that it is puzzling and does not align with the typical definition of a VAD. The reviewer explains that the VAD is described as discarding TF bins with a magnitude less than epsilon, which results in a division by zero, and suggests that this is not a true VAD. The comment also clarifies that a VAD should look for the presence of speech and is typically defined over time, not frequency. This feedback is 5 as it identifies a significant misunderstanding in the paper and offers a clear direction for improvement by aligning the VAD description with its correct definition. The authors are provided with specific guidance on how to revise their VAD description to ensure it accurately reflects the intended concept. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together, resulting in experiments that are difficult to understand. However, it does not provide specific guidance or suggestions on how the authors might improve the clarity or structure of the paper. The comment lacks actionable details, such as recommending specific changes to the presentation or experiments to enhance clarity. As a result, the authors are left without a clear understanding of what steps to take to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general observation about the paper\"s lack of clarity and difficulty in understanding the pieces that fit together. However, it does not specify which parts of the paper are particularly challenging or what specific aspects need improvement. The authors might infer that the experiments are difficult to follow, but the comment lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded as it does not identify a specific part of the paper, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.", "verifiability_rationale": "The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks concrete evidence or references to substantiate the assertion, making it difficult for the authors to understand and address the issue. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is not easy to follow and lacks a clear intuition for how the pieces fit together. This observation is important as it highlights a fundamental weakness in the paper\"s presentation and structure. However, the comment does not provide specific suggestions or guidance on how the authors might improve the clarity or organization of their work. Without actionable feedback, the authors are left without a clear path to address the issues raised. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that this might improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network. While the comment implies that the authors should provide these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the requested metrics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that it might improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network. However, the comment does not specify which part of the paper discusses this training method or where the KID/FID metrics should be included. Without explicit references to sections or figures, the authors cannot confidently determine the exact parts of the paper being addressed. The comment is specific in its request for metrics but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that it might improve the performance of the teacher network. The comment also requests the inclusion of KID/FID metrics for the teacher network. However, the comment lacks specific reasoning or evidence to support the claim that simultaneous training is unfair or how it might impact performance. Without detailed justification or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment raises a question about the fairness of training the student and refinement networks simultaneously, suggesting that this might improve the performance of the teacher network. It also requests the inclusion of KID/FID metrics for the teacher network, which could provide valuable insights into the performance of the teacher network. While the comment identifies a potential issue and provides a specific request for additional metrics, it lacks depth and does not offer detailed guidance on how to address the fairness concern or interpret the KID/FID metrics. The feedback is 3 as it points out an area for improvement but could be more comprehensive with additional suggestions or explanations. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. It also asks whether having a scaling variable before the attention weight would help. While the comment implies that the authors should consider this scaling factor, it does not explicitly instruct them to do so or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they should consider the scaling factor but are not given concrete steps on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the refined region vector, questioning the scaling factor and suggesting a potential improvement by introducing a scaling variable before the attention weight. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. The reviewer provides a logical reasoning by explaining the relationship between the attention weight and the scaling factor. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the implications of this scaling to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific concern about the scaling of the refined region vector, suggesting that it might only scale the most important regions by a factor of two before global pooling. It questions whether having a scaling variable before the attention weight would help. This feedback is 3 as it identifies a potential issue with the scaling of the vector and prompts the authors to consider an alternative approach. However, the comment lacks depth and does not provide detailed guidance or suggestions on how to address this issue, such as proposing specific changes or alternatives. While it points out a potential area for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the LLM\"s performance on the ALFRED benchmark, attributing failures to goal misspecification. It explains that the LLM struggles to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the LLM\"s performance or what specific changes should be made to enhance the recovery of formal goal predicates. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the LLM\"s performance on the ALFRED benchmark, particularly regarding goal misspecification. However, it does not specify which part of the paper discusses the LLM\"s performance or where the issue of goal misspecification is detailed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue of goal misspecification and its impact on the LLM\"s performance, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark are often due to goal misspecification, where the LLM does not accurately recover the formal goal predicate. The comment provides a logical explanation by mentioning the challenges posed by ambiguities in human language. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further investigate the issue to fully understand and address the problem. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the LLM\"s performance on the ALFRED benchmark, attributing failures to goal misspecification. It explains that the LLM struggles to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. This feedback is valuable as it highlights a potential weakness in the LLM\"s performance and provides a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as by recommending specific techniques or approaches to enhance the LLM\"s ability to interpret and recover formal goal predicates. Overall, the comment is 3 as it points out a critical area for improvement but lacks actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the improvement of the method over SOTA methods like IGEV and suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. It also questions whether it is difficult for SamplingGaussian to significantly improve iterative frameworks similar to IGEV. While the comment implies that the authors should conduct additional analysis and provide comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct the suggested analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"this method\" and \"SOTA methods such as IGEV,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the improvement of the method over SOTA methods and suggesting an analysis of the distribution of disparities produced by IGEV compared to other baselines. Additionally, it raises a concern about the difficulty of improving iterative frameworks similar to IGEV. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the small improvement of the method over SOTA methods like IGEV and questions whether this implies a lack of multipeak distribution problems in iterative optimization schemes similar to IGEV. The reviewer suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. Additionally, the reviewer questions the difficulty of improving iterative frameworks similar to IGEV. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the small improvement or the need for further analysis. This makes the claim 3, as it requires additional evidence or examples to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the small improvement of the method over SOTA methods like IGEV, questioning whether this implies a lack of multipeak distribution problems in iterative optimization schemes similar to IGEV. It suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. Additionally, the comment raises a concern about the difficulty of improving iterative frameworks similar to IGEV. While the comment identifies a potential weakness and provides a specific suggestion for analysis, it could be more helpful by offering additional guidance or examples on how to conduct the suggested analysis. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the importance of presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment implies that the authors should conduct this analysis, it does not provide explicit instructions on how to implement it or what specific metrics to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the importance of presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the sections discussing the models and their performance. The suggestion is specific in detailing what additional analysis could be included, making the comment weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It specifically mentions the importance of presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This claim is 3 as it provides a specific suggestion for enhancing the paper\"s analysis, but it lacks detailed reasoning or examples to fully substantiate the need for this additional investigation. The authors would need to infer the potential benefits of this analysis themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should include a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It provides a concrete example of how this could be achieved by presenting differences in false positive rates (FPR) between models with and without ReGuide. This feedback is actionable and offers a clear direction for the authors to enhance their analysis, providing valuable guidance for improving the depth and nuance of their conclusions. However, the comment could be more helpful if it included specific suggestions on how to conduct this analysis or what other metrics might be relevant. Overall, the comment is 4 as it effectively directs the authors to a meaningful area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that when discussing Fourier modes as numbers, the authors should clarify whether they are real or complex. This is an explicit request for clarification, providing a clear action for the authors to take. The comment is specific and concrete, as it directly instructs the authors on what needs to be clarified. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests clarifying whether Fourier modes are real or complex when discussing them as numbers. However, it does not specify which part of the paper this discussion occurs in, making it weakly grounded. The comment is specific in its request for clarification, as it identifies a particular aspect of the paper that needs clarification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that when discussing Fourier modes as numbers, the authors should clarify whether they are real or complex. This is a request for clarification rather than a claim or opinion. It does not contain any subjective statements, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that when discussing Fourier modes as numbers, the authors should clarify whether they are real or complex. This is a specific and actionable piece of feedback that can help the authors improve the clarity and precision of their work. By addressing this suggestion, the authors can enhance the comprehensibility of their paper for readers. However, the comment could be more helpful if it provided additional context or examples of how this clarification might impact the understanding of the paper. Overall, the feedback is 3 as it identifies a clear area for improvement but lacks depth in terms of guidance or examples."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper is missing ablations and suggests that the authors include results using the GCPG model without pretrained initializations. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the draft. The comment is 5 as it gives the authors a direct and specific instruction on how to improve their paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing ablations in the results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely, the performance gain due to the task formulation and the contribution of pretrained language models. The comment provides a clear and actionable suggestion for the authors to include results using the GCPG model without pretrained initializations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are unclear regarding the contribution of the task formulation and pretrained language models. It suggests including results using the GCPG model without pretrained initializations to clarify this. The comment provides a logical reasoning for the claim, suggesting that the current results do not adequately distinguish between the contributions of the task formulation and the pretrained models. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the missing information and how it could be addressed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of ablation studies to distinguish between the contributions of the task formulation and the use of pretrained language models. It provides a clear and actionable suggestion by recommending that the authors include results using the GCPG model without pretrained initializations. This feedback is valuable as it guides the authors to address a critical aspect of their work, helping them clarify the impact of their methodology. However, the comment could be more helpful if it offered additional context or examples on how to conduct these ablations effectively. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with Figure 1, stating that it is difficult to understand what the axes represent. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on how to clarify the axes or what information should be included to make them more understandable. Without any actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the axes of Figure 1. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the difficulty in understanding the axes of Figure 1. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not contain any claims or subjective statements. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. This feedback is 3 as it points out a potential area for improvement in the clarity of the figure. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might clarify the axes or improve the figure\"s readability. Without actionable advice, the authors are left with a general understanding of the issue but without a clear path to address it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that direct runtime comparisons with existing methods are missing, emphasizing the need for such comparisons to demonstrate the efficiency of the proposed approach. The comment provides a clear and concrete action for the authors to take, which is to include direct runtime comparisons with existing methods. This feedback is 5 as it specifies exactly what the authors need to do to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for direct runtime comparisons with existing methods, which allows the authors to identify the specific part of the paper that needs attention. It also specifies the issue by pointing out the absence of such comparisons and the importance of demonstrating the efficiency of the proposed approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. The comment provides a logical reasoning by stating that the proposed approach is based on implicit differentiation, which typically requires additional computational costs. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by referencing specific existing methods or providing examples of how such comparisons would be beneficial. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of direct runtime comparisons with existing methods. It highlights the importance of such comparisons to demonstrate the efficiency of the proposed approach, particularly given the computational costs associated with implicit differentiation. This feedback is clear and actionable, providing the authors with a concrete step to enhance their draft by including direct runtime comparisons. However, the comment could be more helpful if it suggested specific methods to compare against or provided guidance on how to conduct these comparisons. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the proposed framework is a simple combination of metalearning and federated learning, and it does not identify any technical contribution. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this critique. The comment lacks actionable details, leaving the authors without a clear understanding of what changes, if any, are needed to enhance their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed framework as a simple combination of metalearning and federated learning, suggesting that it lacks technical contribution. However, it does not specify which part of the paper this critique is based on, such as a particular section or experiment, making it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment lacks specificity regarding what aspects of the framework are considered simple or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed framework is a simple combination of metalearning and federated learning, suggesting that it lacks technical contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what aspects of the framework are considered simple or how it could be improved, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques the proposed framework as a simple combination of metalearning and federated learning, suggesting that it lacks technical contribution. However, it does not provide any specific feedback or suggestions on how the authors might enhance their work or address the perceived lack of technical contribution. The comment lacks actionable guidance or constructive criticism, leaving the authors without a clear understanding of what improvements could be made to strengthen their draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include case studies and error studies to highlight the effectiveness of each proposed component. It provides an example of how this could be done, mentioning the Elementlevel Graph Pretraining and suggesting a specific reference for a case study. This feedback is explicit and provides concrete guidance on how to improve the draft by including additional examples and studies. The authors know exactly what needs to be done to enhance the clarity and persuasiveness of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests discussing case studies and error studies to highlight the effectiveness of each proposed component, specifically mentioning the Elementlevel Graph Pretraining. It provides an example of how this could be done by referencing a specific paper, \"Graph pretraining for AMR parsing and generation.\" This provides clear guidance on what needs to be addressed and offers a concrete example for improvement. The comment is fully grounded as it explicitly mentions the Elementlevel Graph Pretraining, and it is specific in detailing what needs to be added to enhance the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that discussing case studies and error studies would enhance the paper\"s effectiveness. It provides a specific example of how the Elementlevel Graph Pretraining could be better explained by referencing a case study in \"Graph pretraining for AMR parsing and generation.\" This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by including more detailed examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by recommending the inclusion of case studies and error studies to highlight the effectiveness of each proposed component. It offers a concrete example of how this could be done, referencing the Elementlevel Graph Pretraining and suggesting a specific reference for a case study. This feedback is actionable and provides clear guidance on how the authors can enhance the persuasiveness of their work. However, the comment could be more helpful if it offered additional examples or detailed suggestions on how to conduct these case studies. Overall, the comment is 4 as it directs the authors toward a meaningful improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in the evaluation. It provides an example of how the disentanglement (D) of different representation methods might be evaluated with a fixed capacity of probing (f) and a fixed latent size. The reviewer also points out that DCI and ES may be entangled, as changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest specific actions to improve the evaluation. The feedback is 3 as it highlights an area for clarification, but it lacks concrete steps for the authors to follow. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses the traditional DCI framework, specifically mentioning explicitness (E) and size (S) as potential considerations. It provides an example of how the disentanglement (D) of different representation methods might be evaluated with a fixed capacity of probing (f) and a fixed latent size. The comment also raises a concern about the entanglement between DCI and ES, suggesting that changes in probing capacity or latent size could affect the DCI evaluation. However, the comment does not explicitly mention which part of the paper this discussion is based on, making it weakly grounded. The authors can infer that it relates to the methodology or evaluation sections, but this inference is not as direct as it could be. The comment is specific in detailing the concerns about the evaluation process, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in the evaluation. It provides an example of how the disentanglement (D) of different representation methods might be evaluated with a fixed capacity of probing (f) and a fixed latent size. The reviewer also points out that DCI and ES may be entangled, as changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific references or detailed examples to support the claim that DCI and ES are entangled. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the traditional DCI framework, suggesting that explicitness (E) and size (S) may already be considered in the evaluation. It provides an example of how the disentanglement (D) of different representation methods might be evaluated with a fixed capacity of probing (f) and a fixed latent size. The comment also points out that DCI and ES may be entangled, as changes in probing capacity or latent size could affect the DCI evaluation. While the comment identifies potential issues and provides some insight into the evaluation process, it lacks specific suggestions or detailed guidance on how the authors might address these concerns. The feedback is 3 as it highlights areas for clarification and improvement, but it could be more actionable with additional direction. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the manual disentangling in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that it would be interesting if the paper did not have this type of manual disentangling and everything was learned. While the comment implies that the authors should consider alternative approaches to disentangling, it does not provide explicit guidance on how to achieve this or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative methods for disentangling. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of manual disentangling in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that it would be interesting if the paper did not have this type of manual disentangling and everything was learned. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the exact location is not explicitly mentioned. The comment is specific in detailing the issue with manual disentangling and suggesting an alternative approach, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the manual disentangling in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. The reviewer suggests that it would be interesting if the paper did not have this type of manual disentangling and everything was learned. However, the comment lacks specific reasoning or evidence to support why this manual disentangling is problematic or how it could be improved. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the manual disentangling of the semantic segmentation network as the first module in the pipeline. It questions the rationale behind this choice and suggests that it would be more interesting if the paper did not have this type of manual disentangling and everything was learned. This feedback is 3 as it points out a potential weakness in the methodology and encourages the authors to consider alternative approaches. However, the comment lacks detailed guidance on how to address this issue or what specific changes could be made to improve the paper. While it provides some direction, it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of the connection. The comment implies that the authors should clarify the relationship between the theoretical analysis and the proposed method, but it lacks concrete steps or examples on how to do so. As a result, the comment is 3, as it identifies an area for improvement but does not offer specific guidance on how to address it.", "grounding_specificity_rationale": "The comment addresses the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, it does not specify which part of the paper discusses the theoretical analysis or the proposed method, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the connection between theory and application, but it lacks grounding as it does not identify the specific parts of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the connection between the theoretical analysis and the proposed method is unclear, specifically questioning how the proposed method enhances generalization for distant nodes. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential disconnect between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. It points out that the method seems to be a simple application of the selfattention mechanism from transformers to graphs, without clear explanation of how it improves generalization. This feedback is 3 as it highlights an area where the authors might need to provide more detailed justification or explanation. However, it lacks specific suggestions or guidance on how to address this issue, such as proposing alternative explanations or experiments. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the pieces are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, it does not provide explicit guidance on how the authors should address this issue or improve the clarity of the presentation. The comment implies that the authors should clarify the methods used, but it lacks concrete suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment mentions specific elements, such as \"equation (12)\" and the \"presentation of these methods,\" which allows the authors to identify the parts of the paper being addressed. However, it does not specify what aspects of the presentation are vague or how they could be improved. This lack of specificity makes it difficult for the authors to understand exactly what needs to be addressed. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that some of the pieces are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim 2, as it requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some of the pieces are using existing methods and that the presentation of these methods is vague. This feedback is 3 as it points out a potential area for improvement, specifically the clarity of the presentation of existing methods. However, the comment lacks detailed guidance or suggestions on how the authors might clarify or improve the presentation, leaving the authors with a general idea of what needs attention but without actionable steps to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to compare the effectiveness of their methodology, Contrastive Response Tuning, against existing methods like contrastive decoding. It also mentions that issues mentioned earlier should be addressed and suggests that the work should be considered for a more applicationoriented venue. The comment provides clear and specific actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Contrastive Response Tuning,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a comparison with existing methods, such as contrastive decoding, and addressing the \"notations issues.\" This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should compare its methodology, Contrastive Response Tuning, against existing methods like contrastive decoding. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or references to existing works that have already compared these methods. The mention of \"issues mentioned above\" is vague and does not specify what those issues are, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the paper should compare its methodology, Contrastive Response Tuning, against existing methods like contrastive decoding. This recommendation is clear and could help the authors strengthen their work by demonstrating the novelty and effectiveness of their approach. Additionally, the comment mentions \"issues mentioned above\" that should be addressed, which could refer to other feedback points in the review. However, the comment does not specify what these issues are, which limits its helpfulness. Overall, the feedback is 4 as it guides the authors toward a clear improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns about the algorithm\"s effectiveness and problem, specifically regarding the requirement for access to the entire training dataset. It also questions the comprehensiveness of the related validation experiments and the analysis of the algorithm\"s time complexity and efficiency. Additionally, the reviewer suggests that the authors should further clarify the technical contribution rather than focusing on the form of the attack. While the comment identifies several areas for improvement, it does not provide explicit instructions or concrete steps for the authors to follow. The actions are implicit and somewhat vague, as the authors need to infer what specific changes are needed to address these concerns. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses multiple aspects of the paper, including the effectiveness and problem of the algorithm, the comprehensiveness of related validation experiments, the time complexity of computation, and the efficiency of the algorithm. However, it does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for further analysis of the algorithm\"s time complexity and efficiency, and the expectation for a clearer technical contribution. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including the need for the algorithm to access the entire training dataset, the lack of comprehensive validation experiments, and the absence of a clear analysis of the algorithm\"s time complexity and efficiency. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claims but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It points out the issue of the algorithm requiring access to the entire training dataset, questioning how it would operate effectively when the dataset is not fully perceptible. Additionally, it highlights the need for more comprehensive validation experiments and a clearer analysis of the algorithm\"s time complexity and efficiency. The comment also suggests that the authors should focus on elucidating the technical contribution rather than the form of the attack. While the feedback is clear about the areas needing attention, it could be more helpful by providing specific suggestions or examples on how to address these issues. Overall, the comment is 4 as it directs the authors to important aspects of their work that require further development and clarification."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed method is not wellpositioned in the literature and suggests that the authors conduct a thorough literature review to better position their work. It mentions that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is wellknown and has been used in various works, such as denoising score matching and scoreinterpolation. While the comment implies that the authors should conduct a literature review, it does not provide specific guidance on how to conduct this review or which works to consider. The action is implicit and somewhat vague, as the authors know they need to conduct a literature review but lack detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this idea is wellknown and has been used in various works, such as denoising score matching and scoreinterpolation. The comment further suggests that the authors conduct a thorough literature review to better position their work. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature and suggests that the key idea behind it is wellknown. The reviewer supports this claim by referencing specific works, such as denoising score matching and scoreinterpolation, where this idea has been used. This provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that the proposed method is not wellpositioned in the literature. It highlights that the key idea behind the method, representing the marginal score as the expectation of scores of distributions conditioned on inputs, is wellknown and has been used in various works, such as denoising score matching and scoreinterpolation. The comment suggests that the authors conduct a thorough literature review to better position their work within the existing body of knowledge. While the feedback is clear and actionable, it could be more helpful by providing specific examples or references to guide the authors in their literature review. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It suggests that the authors should provide a gradient comparison between KL and PCC to support this claim. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"matching metric,\" specifically the Pearson correlation coefficient (PCC), which allows the authors to accurately identify the part of the paper being addressed. It also provides a specific critique about the assumption that PCC is a more relaxed constraint compared to KL divergence, offering a detailed explanation of why this assumption is not convincing. The comment suggests that the authors should provide a gradient comparison between KL and PCC to support their claim. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence is not convincing. It provides a logical reasoning by explaining that the constraint strength of a loss function is defined via its gradient distribution and that KL divergence and MSE loss have the same optimal solution but that MSE loss is stricter due to its gradient distribution. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by including specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence. It offers a logical explanation by discussing the gradient distribution of loss functions, such as KL divergence and MSE loss, to illustrate the constraint strength. The comment suggests that the authors should provide a gradient comparison between KL and PCC to support their claim. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a concrete suggestion for addressing the issue. By following this advice, the authors can enhance the rigor and clarity of their argument. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the resolution of a debate that the paper was previously careful to leave open, specifically questioning why the distribution cannot have changed and whether experiments disentangle changes in distribution from the removal of information. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line numbers (L106 and L29), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the resolution of a debate and suggesting that the distribution might have changed. The comment further highlights specific points of confusion, such as the need for experiments to disentangle changes in distribution from the removal of information. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the resolution of a debate that the paper was previously careful to leave open, specifically questioning why the distribution cannot have changed and whether experiments disentangle changes in distribution from the removal of information. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the resolution of a debate that the paper was previously careful to leave open, specifically questioning why the distribution cannot have changed and whether experiments disentangle changes in distribution from the removal of information. It also highlights specific points of confusion, such as the need for experiments to clarify these issues. While the comment identifies a potential weakness in the paper, it lacks detailed guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is 3 as it points out areas for clarification, but it could be more actionable with specific recommendations or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the proposed method uses AdamW with cosine lr for training, while the comparison methods only use Adam with fixed lr. It suggests that directly comparing with the numbers in the paper is unfair and recommends reproducing the results using the same setting, as most recent methods have their code released. This feedback provides a clear and explicit action for the authors to take, which is to reproduce the results using the same setting as the comparison methods. The suggestion is concrete, as it specifies exactly what needs to be done to ensure a fair comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of AdamW with cosine lr for training, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the unfairness of directly comparing with methods that use Adam with fixed lr. The comment provides a clear suggestion to reproduce the results using the same setting as the comparison methods, which is specific and actionable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that directly comparing the proposed method with other methods using different optimization settings is unfair. It suggests that the authors should reproduce the results using the same setting as the comparison methods, as most recent methods have their code released. This claim is 3 as it provides a logical reasoning for the unfairness of the comparison and suggests a specific action to address it. However, the comment could be strengthened by providing examples of recent methods with released code or by explaining why the specific optimization settings matter. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between the proposed method and other methods. It points out that the proposed method uses AdamW with cosine lr for training, while the comparison methods only use Adam with fixed lr. The comment suggests that directly comparing with the numbers in the paper is unfair and recommends reproducing the results using the same setting as the comparison methods, as most recent methods have their code released. This feedback is clear and actionable, providing the authors with a specific direction to improve the fairness and validity of their comparisons. By addressing this issue, the authors can enhance the credibility and robustness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the plots are terrible and provides specific reasons for this assessment, such as their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The reviewer emphasizes that these plots are the main presentation of the experimental results and should be much clearer. This feedback is direct and provides concrete guidance on what needs to be improved, such as increasing plot size, distinguishing colors, labeling axes, and ensuring label clarity. The authors know exactly what changes to make to enhance the clarity of their plots, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the plots,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it details the issues with the plots, such as their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The reviewer provides clear guidance on what needs to be improved, making this comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the plots are \"terrible\" due to their small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels. The reviewer provides specific examples of these issues, such as the difficulty in distinguishing between pink and red colors, and the confusion between \"sdropout(tr)\" and \"edropout(tr)\" labels. This level of detail supports the claim, making it 4. However, the comment could be strengthened by providing suggestions on how to improve the plots, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the quality of the plots presented in the paper. It identifies several issues, such as the small size of the plots, difficulty in distinguishing colors, poorly labeled axes, and visually similar labels. By pointing out these specific problems, the comment offers clear guidance on how to improve the clarity and presentation of the experimental results, which are crucial for the paper\"s impact. This feedback is 5 as it empowers the authors to make significant improvements to their draft, enhancing its readability and effectiveness. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that Table 1 should include standard deviations and that the experiments should be more extensive to strengthen the submission. However, it does not provide specific guidance on how to achieve this or what additional experiments should be conducted. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the inclusion of standard deviations in the table. Additionally, it provides a suggestion for improvement by stating that the experiments should be more extensive, which is a clear and actionable point. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 1 should include standard deviations and that the experiments should be more extensive. However, it does not provide any supporting evidence, reasoning, or examples to justify why these additions would strengthen the submission. The comment lacks specific details or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it lacks standard deviations. It also suggests that the experiments could be more extensive to strengthen the submission. While the comment points out a clear area for improvement, it does not provide detailed guidance on how to address the issue or what specific experiments should be conducted. The feedback is 3 as it highlights a potential weakness, but it lacks depth and actionable suggestions, leaving the authors with a general direction but not a comprehensive plan for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests several actions to improve the paper, including restructuring the sections (introduction>method>experiments) and focusing more on the IEM in Figure 3, which the reviewer considers the main figure. It also recommends improving the visualization of Figures 7 and . While the comment provides explicit actions, it lacks specific guidance on how to implement these changes, such as detailed suggestions for restructuring or improving the visualizations. The authors know what needs to be done but may struggle with the execution, making the comment 3.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the paper, such as restructuring the sections (introduction>method>experiments) and focusing more on the IEM in Figure 3, which the reviewer considers the main figure. It also recommends improving the visualization of Figures 7 and . However, the comment does not explicitly mention which sections are difficult to follow or where the figures are located, making it weakly grounded. The authors can infer that the issues are related to the introduction, method, and experimental sections, but this inference is not as direct as it could be. The comment is specific in its suggestions for improvement, aligning with a score of 3.", "verifiability_rationale": "The review point consists of suggestions for improving the paper, such as restructuring the sections and focusing on specific figures. It does not contain any claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the structure of the sections (introduction>method>experiments) and the focus on the IEM in Figure 3, which the reviewer considers the main figure. It also suggests improving the visualization of Figures 7 and . While the comment provides specific feedback on what needs attention, it lacks detailed guidance or examples on how to implement these changes. The authors are given a general direction but may need to develop their own strategies for improvement. Therefore, the comment is 3, as it points out areas for enhancement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should expand their experiments, it does not provide specific guidance on which architectures or classification tasks to consider or how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in suggesting the need for broader experimentation, but it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This is a request for additional experiments, which is not a claim but rather a suggestion for improvement. The comment does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the experiments should be extended to include other architectures and classification tasks beyond neural networks and image classification. This feedback is 3 as it identifies a potential limitation in the scope of the experiments and encourages the authors to broaden their evaluation. However, the comment lacks specific guidance on which other architectures or classification tasks should be considered, leaving the authors with a general direction but no detailed steps to follow. To be more helpful, the comment could include suggestions or examples of alternative architectures or tasks that might be relevant. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses skepticism about the use of a transformer that is free of localitybias, suggesting that the neighborhood agents should have more impact on each other due to limited information propagation. The reviewer requests an explanation from the authors regarding why the absence of locality should not be a concern. While the comment implies that the authors should provide additional justification or evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment expresses skepticism about the use of a transformer that is free of localitybias and suggests that the neighborhood agents should have more impact on each other due to limited information propagation. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in its request for the authors to explain why the absence of locality should not be a concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses skepticism about the claim that a transformer free of localitybias is the best option, suggesting that the neighborhood agents should have more impact on each other due to limited information propagation. The reviewer questions the validity of this claim by providing a logical reasoning based on the nature of information propagation. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional evidence or explanation to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment expresses skepticism about the claim that a transformer free of localitybias is the best option, suggesting that the neighborhood agents should have more impact on each other due to limited information propagation. The reviewer requests an explanation from the authors regarding why the absence of locality should not be a concern. While the comment identifies a potential weakness in the argument and prompts the authors to provide additional justification, it lacks specific suggestions or detailed guidance on how to address the concern. The feedback is 3 as it points out an area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or evaluate the impact of these strategies. The comment implies that the authors should consider the potential negative effects of these strategies on the model\"s utility, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation strategies on the overall performance of the model, specifically questioning whether these strategies might significantly impair the model\"s utility. However, it does not specify which part of the paper discusses these mitigation strategies or where the authors should focus their attention to address this concern. The comment lacks grounding as it does not mention specific sections, figures, or tables, making it difficult for the authors to pinpoint the exact area needing revision. Additionally, while it raises a specific concern about the tradeoff between reducing a particular behavior and maintaining high performance, it does not provide detailed guidance on how to address this issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. The comment provides a logical reasoning by stating that if these mitigation strategies significantly impair the model\"s utility, it might deter their adoption. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the potential tradeoffs themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the impact of mitigation strategies on the overall performance of the model. It highlights a potential tradeoff between reducing a particular behavior and maintaining high performance, which is an important consideration for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might evaluate or mitigate this tradeoff. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the use of 6fold crossvalidation in the paper, questioning the necessity of this approach given that other papers in the field do not use crossvalidation. While the comment implies that the authors should provide a justification for their choice of crossvalidation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explain the rationale behind their choice. However, the comment does provide some guidance by suggesting that the authors should clarify the reason for using crossvalidation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of 6fold crossvalidation for each dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of crossvalidation, given that other papers in the field do not use it. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the necessity of using 6fold crossvalidation, given that other papers in the field do not use it. The comment provides a logical reasoning by pointing out the inconsistency in methodology across different papers, suggesting that the authors should clarify the rationale behind their choice. However, the comment lacks specific references to the other papers or detailed explanations of why crossvalidation is required in this context. This makes the claim 3, as it provides a basis for questioning but requires further elaboration or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s methodology, specifically questioning the use of 6fold crossvalidation when other papers in the field do not employ this approach. It highlights a lack of clarity regarding the necessity of crossvalidation and suggests that the authors should provide a justification for their choice. This feedback is 3 as it points out a specific area for improvement and prompts the authors to clarify their methodology. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of situations where crossvalidation might be beneficial. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the effectiveness of the proposed engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure and its reliance on a sophisticated filtering template. The comment suggests that the authors clarify the impact of these heuristic components. While the action is explicit, it lacks concrete guidance on how the authors should clarify the impact of these components. The suggestion is 3 as it directs the authors to provide more information, but it does not specify the exact steps or details needed to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"NonAmbiguous Query Generation procedure\" and the \"sophisticated filtering template,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of incorporating heuristic components and suggests that the authors clarify the impact of these components. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents a highly effective engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects. It specifically mentions the NonAmbiguous Query Generation procedure and its reliance on a sophisticated filtering template. The comment suggests that the authors clarify the impact of these heuristic components. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to clarify the impact is logical but requires more elaboration to be 5. Therefore, the comment is 3.", "helpfulness_rationale": "The review comment acknowledges the effectiveness of the proposed engineering method for ReC but points out the incorporation of combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure and its reliance on a sophisticated filtering template. It suggests that the authors clarify the impact of these heuristic components, which is a relevant and actionable feedback. By addressing this point, the authors can provide a clearer understanding of the methodology and its implications, potentially enhancing the comprehensibility and credibility of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify the impact or offered examples of how to address this issue. Overall, the comment is 4 as it identifies a potential area for improvement and guides the authors toward a more comprehensive explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises doubts about the feasibility of training the proposed method without using camera information, specifically questioning how the method can perform ray marching without knowing the viewpoint. The reviewer challenges the logic of the method by asking how the ray\"s origin is determined without camera information. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or address the issue of camera information in their method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the feasibility of training the proposed method without camera information, particularly regarding the determination of ray origins. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the feasibility of the proposed method by challenging the use of camera information. It raises logical concerns about how the method can perform ray marching without knowing the viewpoint and how the ray\"s origin is determined. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claim. While it highlights a potential issue, the lack of supporting evidence or detailed explanation makes it 3. The authors would need to address these concerns themselves, which is why the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the feasibility of the proposed method, specifically questioning how it can be trained without using camera information. It challenges the logic of the method by asking how ray marching can be performed without knowing the viewpoint and how the ray\"s origin is determined. This feedback is valuable as it prompts the authors to clarify a fundamental aspect of their method, which could significantly impact its effectiveness. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or offered examples of alternative approaches. Overall, the comment is 4 as it identifies a significant weakness and prompts the authors to address it, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the method, ODA, has learned a policy to imitate problemsolving but does not clearly explain how it improves performance and computation speed compared to just using ODA. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clearer explanation of the method\"s advantages. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ODA,\" one of the methods for solving the MOIP problem, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the method has learned a policy to imitate problemsolving but does not clearly explain how it improves performance and computation speed compared to just using ODA. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method, ODA, has learned a policy to imitate problemsolving but does not clearly explain how it improves performance and computation speed compared to just using ODA. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the method, ODA, has learned a policy to imitate problemsolving but does not clearly explain how it improves performance and computation speed compared to just using ODA. This feedback is 3 as it points out a potential gap in the explanation of the method\"s advantages. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue, such as providing examples or specific improvements that could be made. To be more helpful, the comment could include actionable advice on how to enhance the explanation or demonstrate the method\"s benefits. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of the lowresource regime. While the comment implies that the authors should expand their experimental evaluation, it does not provide specific guidance on which datasets to use or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of the lowresource regime. However, it does not specify which parts of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental evaluation, but the comment lacks full grounding as it does not explicitly mention specific sections. It is specific in suggesting additional experiments, but the lack of grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of the lowresource regime. While the comment provides a logical reasoning for expanding the experimental evaluation, it lacks specific examples or references to datasets that could be used or to similar studies that have employed multiple datasets. This makes the claim 3, as the authors would need to infer which datasets might be relevant and how to implement the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental evaluation by pointing out the lack of results on more datasets. It provides a clear and actionable suggestion to conduct experiments on more datasets, which would enhance the comprehensiveness of the evaluation. Additionally, it encourages experiments on the full dataset instead of the lowresource regime, offering a specific direction for improvement. This feedback is valuable as it guides the authors on how to strengthen their experimental section, making it 4. However, it could be more helpful if it included suggestions on which additional datasets might be relevant or how to analyze the results across different datasets. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the clarity of how the generic argument task and the random argument task support the authors\" claims. It also criticizes the dataset transformation and experimental setup as cumbersome and unclear. However, the comment does not provide specific guidance on how the authors might clarify these aspects or improve the clarity of their work. The feedback lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of how the generic argument task and the random argument task support the authors\" claims, as well as the complexity of the dataset transformation and experimental setup. However, it does not specify which sections of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact parts that need revision. The comment is specific in its critique of the dataset transformation and experimental setup, but it lacks grounding as it does not identify the specific sections being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity of how the generic argument task and the random argument task support the authors\" claims. It also criticizes the dataset transformation and experimental setup as cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed justification or references to specific sections of the paper makes the claim 3, as the authors would need to infer the exact areas needing improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of clarity in how the generic argument task and the random argument task support the authors\" claims. It also critiques the dataset transformation and experimental setup as cumbersome and unclear. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. Without actionable advice, the authors may struggle to determine the exact steps needed to enhance the clarity and effectiveness of their work. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed guidance for addressing them."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting to see how the model works for tabular data, although it is not necessary. While the comment implies that the authors should consider exploring this aspect, it does not provide explicit guidance on how to do so or what specific steps to take. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the model\"s performance on tabular data but without detailed instructions on how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring the model\"s performance on tabular data, which is a specific area of interest. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the discussion of multimodal data, but this inference is not as direct as it could be. The comment is specific in suggesting an area for exploration, but it lacks full grounding because it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to see how the model works for tabular data, but it does not provide any justification or evidence to support this claim. The comment lacks specific reasoning or examples that would help the authors understand why this exploration is necessary or beneficial. Without such support, the claim remains 1, as it does not provide a clear basis for the authors to address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests exploring the model\"s performance on tabular data, which is a specific area of interest. While the comment acknowledges that this exploration is not necessary, it provides a direction for potential improvement by suggesting an additional application of the model. This feedback is 3 as it offers a clear suggestion for expanding the scope of the paper, but it lacks detailed guidance on how to implement this exploration or what specific aspects to focus on. To be more helpful, the comment could include more detailed instructions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper lacks analysis on the alignment of entity representations, particularly in the context of multilingual alignment. It explicitly recommends adding more analysis and suggests including visualizations or case studies for different language types, such as language families. Additionally, the reviewer expresses interest in whether entities from lowresourced languages are well aligned with highresourced ones. This feedback provides clear and concrete actions for the authors to take, including specific suggestions for additional analysis and visualizations. The explicit nature of the recommendations and the detailed guidance on what to include make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the languageagnostic characters of entity representations,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of analysis on the alignment of entity representations, particularly in the context of multilingual alignment. The comment suggests adding more analysis and provides specific examples, such as visualizations or case studies for different language types, which enhances its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis on the alignment of entity representations, particularly in the context of multilingual alignment. It suggests adding more analysis and provides specific examples, such as visualizations or case studies for different language types. The comment is 4 as it provides a clear suggestion for improvement and offers concrete examples of what could be included. However, it lacks detailed reasoning or references to existing work on multilingual alignment, which would strengthen the justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks analysis, namely the alignment of entity representations across different languages. It suggests that the authors could enhance their analysis by including more discussion on multilingual alignment and providing visualizations or case studies for different language types, such as language families. Additionally, the reviewer expresses interest in whether entities from lowresourced languages are well aligned with highresourced ones, which could be a valuable addition to the paper. This feedback is clear and actionable, providing the authors with specific directions for improving their analysis and potentially expanding their work. However, it could be more helpful if it included examples or references to existing work on multilingual alignment, which would further guide the authors in implementing the suggestions. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two specific issues with the references list: duplicates and missing publication venues and/or years. However, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to check for duplicates and ensure that all references include the correct publication venues and years, but the comment lacks concrete guidance on how to implement these actions. Therefore, the comment is 3, as it highlights the issues but does not provide detailed instructions on how to resolve them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"references list,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the references list, namely duplicates and missing publication venues and/or years. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that the publication venues and/or years of many papers are missing. This is a factual observation that can be verified by checking the references list. However, the comment does not provide specific examples or detailed reasoning to support the claim, making it 3. The authors would need to manually check the references to confirm the issues, which could be timeconsuming. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the references list: duplicates and missing publication venues and/or years. This feedback is clear and actionable, as it directs the authors to review and correct these errors in their references. By addressing these issues, the authors can ensure the accuracy and completeness of their references, which is crucial for the credibility and transparency of their work. However, the comment could be more helpful if it provided examples of duplicate references or suggested ways to verify the publication information. Overall, the comment is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the theoretical analysis in Theorem 1 is unclear and weak, and it suggests that the authors need to analyze and compare the theoretical results to other comparable methods. This provides a clear action for the authors to take, which is to clarify the error bound in Theorem 1 and compare it to other methods. The feedback is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound and the need for comparison with other methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. However, the comment does not provide any further explanation, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and suggesting that the authors should analyze and compare their results with other comparable methods. This feedback is clear and actionable, providing the authors with a direct path to improve their draft by clarifying the theoretical analysis and enhancing its relevance. However, the comment could be more helpful if it offered specific suggestions on how to clarify the error bound or which comparable methods to consider. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about why explicit methods perform better than implicit methods on locomotion tasks and notes the absence of pseudocode for the proposed method. It provides two references, [1] and [2], which could be useful for the authors to explore. However, the comment does not explicitly instruct the authors to include the pseudocode or provide specific guidance on how to address the question about the performance difference. The action is implicit and somewhat vague, as the authors need to infer that they should include the pseudocode and address the performance question. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance difference between explicit and implicit methods on locomotion tasks and notes the absence of pseudocode for the proposed method. It also provides references to relevant literature. However, it does not specify which part of the paper discusses the explicit and implicit methods, making it weakly grounded. The comment is specific in its request for the inclusion of pseudocode and the references to external works, but the lack of explicit grounding limits the authors\" ability to pinpoint the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance difference between explicit and implicit methods on locomotion tasks and notes the absence of pseudocode for the proposed method. It provides references to relevant literature, which is a form of external verification. However, the comment does not provide detailed reasoning or examples to fully substantiate the claim about the performance difference, making it 3. The authors would need to explore the references to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance difference between explicit and implicit methods on locomotion tasks, which is a relevant and important point for the authors to address. It also notes the absence of pseudocode for the proposed method, which is a critical omission that the authors should rectify. The comment provides references to relevant literature, which can help the authors understand the context of their work and potentially guide their analysis. However, the comment could be more helpful if it included specific suggestions on how to address the performance question or how to present the pseudocode. Overall, the comment is 3 as it identifies key areas for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors about the reason for only showing results on images corrupted with Gaussian noise, despite claiming that their model can work well for various types of image noise. This comment implies that the authors should provide an explanation or justification for this choice. However, it does not explicitly instruct the authors to do so or offer guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the authors about the reason for only showing results on images corrupted with Gaussian noise, despite claiming that their model can work well for various types of image noise. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the reason for the limited results, but it lacks grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors about the reason for only showing results on images corrupted with Gaussian noise, despite claiming that their model can work well for various types of image noise. This is a factual observation that does not contain a subjective claim or opinion. It is a request for clarification, which is not a claim requiring verification. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises a pertinent question about the limited scope of the results presented in the paper, specifically questioning why the authors only show results on images corrupted with Gaussian noise, despite claiming that their model can work well for various types of image noise. This feedback is 3 as it prompts the authors to consider expanding their results to include other types of noise, which could enhance the generalizability and applicability of their model. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional noise types to test or suggesting ways to present the results. Therefore, while it identifies a potential area for improvement, it does not provide comprehensive feedback, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should visualize the effect of the existing PU learning methods\" performance decline as the dimensionality of the data increases. This is an explicit request for a specific action, namely, to create a visualization to support the claim. The comment provides clear guidance on what the authors should do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the performance decline of existing PU learning methods as the dimensionality of the data increases. It suggests that the authors should visualize this effect, which is important for the research motivation of the paper. However, the comment does not specify which part of the paper discusses this claim, making it weakly grounded. The suggestion to visualize the effect is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors should visualize the effect of the existing PU learning methods\" performance decline as the dimensionality of the data increases. This claim is based on the authors\" own statement about the research motivation of the paper. However, the comment lacks specific examples, references, or detailed reasoning to support why visualizing this effect is crucial or how it would enhance the paper. The lack of detailed justification makes the claim 3, as it provides a general direction but requires more evidence or explanation to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the performance decline of existing PU learning methods as the dimensionality of the data increases. It suggests that the authors should visualize this effect, which is crucial for the research motivation of the paper. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by illustrating the claim with a visualization. However, the comment could be more helpful if it offered additional guidance on how to create the visualization or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues with the convoluted nature of the results description, providing examples of unnecessarily complex language. It also suggests that the authors should consider related work on speakerlistener communication from a teachability perspective, as well as checking for useful communication in light of a specific reference. The comment includes concrete suggestions for improvement, such as referencing specific papers and checking for meaningful differences in figures. This provides clear and actionable guidance for the authors, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific examples of convoluted language in the results description, allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific suggestions for improvement, such as considering related work on speakerlistener communication and checking for useful communication in light of specific references. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results description is unnecessarily convoluted, providing an example of complex language. It suggests considering related work on speakerlistener communication and checking for useful communication in light of specific references. The comment is 4 as it provides specific examples and references to support the claim, offering a clear direction for the authors to improve their work. However, the comment could be strengthened by providing more detailed reasoning or examples of how the convoluted language affects the clarity of the results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the convoluted nature of the results description, providing an example of unnecessarily complex language. It offers actionable suggestions for improvement by recommending related work on speakerlistener communication and checking for useful communication in light of specific references. This feedback is clear and provides the authors with concrete steps to enhance the clarity and relevance of their results. However, the comment could be more helpful if it included additional guidance on how to simplify the language or integrate the suggested references more effectively. Overall, the comment is 4 as it provides valuable insights and actionable suggestions for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the approximation error is defined as the gap between objective values, which is ambiguous without seeing the values in the table. It recommends providing a mathematical characterization to clarify this point. While the comment implies that the authors should include a mathematical definition, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to mathematically characterize the approximation error. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the definition of approximation error, specifically mentioning the gap between objective values. However, it does not specify which part of the paper discusses this definition, making it weakly grounded. The comment is specific in suggesting that a mathematical characterization would be beneficial, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the definition of approximation error is ambiguous and suggests providing a mathematical characterization. However, the comment does not offer any specific reasoning or examples to support why the current definition is ambiguous or how a mathematical characterization would improve clarity. Without additional context or explanation, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the definition of approximation error, noting that it is unclear without seeing the values in the table. It suggests providing a mathematical characterization to clarify this point. While the comment highlights an area for improvement, it does not offer specific guidance on how to mathematically characterize the approximation error or provide examples of similar approaches. This limits the comment\"s usefulness, as it provides a general direction but lacks detailed actionable advice. Therefore, the comment is 3, as it points out a weakness but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the proposed model: first, that it produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n, which limits the model\"s dynamics; and second, that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their model. The feedback lacks actionable details, such as recommending alternative approaches or suggesting ways to enhance the model\"s complexity. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses specific aspects of the proposed model, such as the reassignment probability and the evolution model, which allows the authors to identify the relevant parts of the paper being discussed. However, it does not specify which sections or figures these aspects are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the model, such as the limited dynamics and the simplistic nature of the evolution model. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n, which limits the model\"s dynamics. It also states that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. While the comment provides a logical explanation for the limitations of the model, it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to further explore and substantiate the reasoning themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the proposed model: first, it notes that the model produces only 1 node changing cluster per time step on average due to the reassignment probability being 1/n, which limits the model\"s dynamics. Second, it points out that the evolution model is simplistic because it only changes edges with the (on average) 1 node changing cluster. While the comment highlights important limitations, it does not provide actionable suggestions or guidance on how the authors might address these issues or improve their model. The feedback lacks depth and specificity, leaving the authors with a general understanding of the problems but without clear steps to take for improvement. Therefore, the comment is 3, as it provides some insight but does not fully support the authors in enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to add details about the division of the dataset into training and test sets, including the numbers and the method used for division (e.g., random or with other considerations). This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what information to include in their draft. The comment is explicit and provides specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing details about the division of the dataset into training and test sets, including the numbers and the method used for division. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what details are missing and should be added, such as whether the division was random or if other considerations were involved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are missing details about the division of the dataset into training and test sets, including the numbers and the method used for division. This is a factual statement that requires no verification or justification. It does not express an opinion, judgment, or suggestion that would necessitate verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks details, namely the division of the dataset into training and test sets. It highlights the importance of including information about the numbers and the method used for division, such as whether it was random or involved other considerations. This feedback is clear and actionable, as it provides the authors with a specific area to address and improve their draft. By adding these details, the authors can enhance the transparency and rigor of their experimental setup, which is crucial for reproducibility and credibility. However, the comment could be more helpful if it suggested specific methods or considerations for division, which would provide even more actionable guidance. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, which varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks specific guidance on how to address these concerns or improve the draft. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, which varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not specify which part of the paper these concerns relate to, making it difficult for the authors to identify the exact sections that need attention. Additionally, while it provides some insight into potential issues, it lacks specificity in terms of what specific changes or improvements are needed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, which varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimal textual format for policy learning, which varies across tasks and models. It also mentions the potential scalability issue with longtext input. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address these concerns or improve their draft. Without detailed guidance or constructive advice, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is rated as 2, as it identifies areas of potential improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the use of a specific loss in a particular setting might be novel, but it does not provide any evidence or reasoning to support this claim. It also states that the work lacks new theoretical results, but again, it does not offer any guidance on how the authors might address this issue or what specific theoretical results are missing. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the use of a specific loss in a particular setting might be novel but lacks theoretical results. However, it does not specify which part of the paper this claim pertains to, such as a specific section or experiment where the loss is discussed. Without explicit references to the paper, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what theoretical results are missing or how they could be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the use of a specific loss in a particular setting might be novel but lacks theoretical results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the use of a specific loss in a particular setting might be novel, but it does not provide any evidence or reasoning to support this claim. It also states that the work lacks new theoretical results, which is a critical aspect of the paper. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or what specific theoretical results are missing. Without actionable feedback or detailed insights, the authors are left without a clear path for improvement. Therefore, the comment is 1, as it does not provide meaningful guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a straightforward hypothesis about the trivial and impossible parts of the dataset, proposing that the trivial part consists of images with highly consistent labels or typical object poses, while the impossible part includes images with ambiguous labels or atypical poses. The reviewer expresses interest in whether the human test results support this hypothesis and asks for more evidence to either prove or disprove it. While the comment implies that the authors should provide additional evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to provide this evidence. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a hypothesis about the trivial and impossible parts of the dataset, proposing that the trivial part consists of images with highly consistent labels or typical object poses, while the impossible part includes images with ambiguous labels or atypical poses. The reviewer expresses interest in whether the human test results support this hypothesis and asks for more evidence to either prove or disprove it. However, the comment does not explicitly mention which part of the paper this hypothesis is based on, making it weakly grounded. The suggestion to provide more evidence is specific, as it directs the authors to either prove or disprove the hypothesis. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a hypothesis about the trivial and impossible parts of the dataset, proposing that the trivial part consists of images with highly consistent labels or typical object poses, while the impossible part includes images with ambiguous labels or atypical poses. The reviewer expresses interest in whether the human test results support this hypothesis and asks for more evidence to either prove or disprove it. However, the comment lacks specific examples or references to support the hypothesis, making it 3. The authors would need to provide additional evidence or analysis to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a hypothesis about the trivial and impossible parts of the dataset, proposing that the trivial part consists of images with highly consistent labels or typical object poses, while the impossible part includes images with ambiguous labels or atypical poses. The reviewer expresses interest in whether the human test results support this hypothesis and asks for more evidence to either prove or disprove it. This feedback is 3 as it provides a potential direction for the authors to explore and offers a specific area for further investigation. However, it lacks detailed guidance on how to conduct this investigation or what specific evidence to provide, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what the authors should do in response to this question, such as suggesting additional testing or analysis on other tasks. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). However, it does not specify which part of the paper discusses this testing, making it weakly grounded. The comment is specific in its inquiry about other tasks, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). This is a factual inquiry that does not contain a claim or opinion requiring verification. It is a request for clarification, which is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the testing of the model on the bAbI dataset, specifically asking if it was only tested on the single supporting fact dataset (Task 1). While this is a valid inquiry, the comment lacks depth and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this issue or expand their testing to other tasks. As a result, the comment is 2, as it identifies a potential area for improvement but does not provide sufficient direction for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 3.2 is difficult to follow and recommends that the author improve it by providing more illustrations and examples. While the comment explicitly states that the author should improve the section, it does not provide specific guidance on how to enhance it or what kind of illustrations or examples would be most beneficial. The action is explicit but vague, as the authors are left to infer the exact changes needed without detailed guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, namely that it is difficult to follow, and suggests improvements by recommending the addition of more illustrations and examples. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 3.2 is difficult to follow and suggests that the author improve it by providing more illustrations and examples. However, the comment does not provide any specific reasoning or examples to support why the section is challenging to follow. Without detailed justification or examples, the authors may find it difficult to understand and address the issue effectively. Therefore, the claim is considered 1, as it lacks sufficient evidence or explanation to substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It provides a clear and actionable suggestion by recommending that the author improve the section by adding more illustrations and examples. This feedback is valuable as it directs the authors to a concrete area for improvement, which can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it included specific examples of what kind of illustrations or examples would be most beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It suggests that this computation could be timeconsuming for problems with many objectives, potentially making LaMOO impractical for such problems. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as it lacks concrete steps or suggestions for improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the time complexity of the proposed algorithm, particularly in relation to the calculation of hypervolume for problems with many objectives. The comment provides a clear question about the practicality of the algorithm for such problems, which gives the authors a clear direction for addressing the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It suggests that this computation could be timeconsuming for problems with many objectives, potentially making LaMOO impractical for such problems. The comment provides a logical reasoning by pointing out the potential issue with the algorithm\"s scalability, which is a valid concern. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the claim themselves to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It points out a potential issue with the algorithm\"s scalability, particularly for problems with many objectives, which could make LaMOO impractical for such problems. This feedback is valuable as it highlights a potential limitation of the algorithm and prompts the authors to consider its practicality in realworld scenarios. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as alternative methods for calculating hypervolume or ways to optimize the algorithm\"s efficiency. Overall, the comment is 4 as it identifies a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges a minor issue with the dataset used in the experiments, noting that they are all small. It suggests that results on a medium or large dataset, such as ImageNet, would be more convincing. However, the comment does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to implement the suggested improvement. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the dataset used in the experiments, noting that they are all small and suggesting that results on a medium or large dataset, such as ImageNet, would be more convincing. However, the comment does not specify which part of the paper discusses the dataset or where the results are presented, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might infer that it relates to the experimental results section, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting the use of a larger dataset, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the dataset used in the experiments is small and suggests that results on a medium or large dataset, such as ImageNet, would be more convincing. However, the comment does not provide any specific reasoning or evidence to support why a larger dataset would be more convincing or how it would impact the results. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges a minor issue with the dataset used in the experiments, noting that they are all small. It suggests that results on a medium or large dataset, such as ImageNet, would be more convincing. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what specific datasets they could consider. Additionally, the comment does not provide any context or explanation as to why a larger dataset would be more convincing or how it might impact the results. As a result, the feedback is 3, as it points out a potential weakness but does not offer actionable advice or depth to guide the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should delve deeper into the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. It also advises being honest and direct in their critique, suggesting that the title is too generic and vague. The comment implies that the authors should clarify what \"brittle convergence properties\" mean and mentions that DeepRL methods are widely adopted. While the comment provides some direction, it lacks specific guidance on how to address these points or what changes to make. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitations of evolutionary methods and the need for deeper discussion on leveraging state, reactiveness, and learning during an episode. It also addresses the title\"s genericity and vagueness, suggesting the authors be more precise in their critique. The comment is specific in its suggestions for improvement, such as clarifying the meaning of \"brittle convergence properties\" and considering the landscape of DeepRL methods 10 years ago. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should delve deeper into the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. The reviewer also critiques the title as being too generic and vague, suggesting that the authors should be more precise in their critique. However, the comment lacks specific examples or references to support the claim that there are deeper issues to address or that the title is too generic. The mention of \"brittle convergence properties\" is not elaborated upon, and the reference to DeepRL methods being widely adopted is a general statement without detailed evidence or context. Therefore, the claim is 3, as it provides some justification but lacks detailed support or examples.", "helpfulness_rationale": "The review comment provides some helpful feedback by suggesting that the authors should delve deeper into the limitations of evolutionary methods, specifically focusing on leveraging state, reactiveness, and learning during an episode. It also advises the authors to be more precise in their critique, noting that the title is too generic and vague. However, the comment lacks specific guidance or examples on how to address these issues, such as suggesting particular aspects to explore or how to improve the title. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the synthesis of the focal stack, the forward model for using a defocus map and an image to synthesize a defocused image, and how edges with depth discontinuities are handled. These questions imply that the authors need to provide more detailed explanations or descriptions in their paper. While the questions are explicit, they lack concrete guidance on how to address these issues, such as specific examples or detailed instructions on what information should be included. The authors can infer that they need to provide additional information, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the synthesis of the focal stack, the forward model for using a defocus map and an image to synthesize a defocused image, and how edges with depth discontinuities are handled. While it does not explicitly mention specific sections or figures, the authors can infer that these questions pertain to the methodology or results sections where these processes are discussed. The comment is specific in detailing what aspects need clarification, such as the synthesis process and handling of depth discontinuities. However, because it does not explicitly mention the sections, it is weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on specific aspects of the methodology, such as the synthesis of the focal stack, the forward model, and the handling of edges with depth discontinuities. These questions are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the methodology and implementation of the focal stack synthesis, specifically asking for clarification on the forward model, the handling of edges with depth discontinuities, and the synthesis process. These questions are relevant and could help the authors improve the clarity and comprehensiveness of their paper. However, the comment lacks specific suggestions or guidance on how to address these questions, which would make it more actionable. While it identifies areas for improvement, it does not provide detailed feedback or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors include a comparison of their approach\"s transferability to other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. This is an explicit suggestion for the authors to expand their analysis and provide additional comparisons. However, the comment does not specify which LLMs should be included in the comparison or how to conduct the analysis, leaving some room for interpretation. While the action is explicit, it lacks concrete details on how to implement the suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GCG,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that a comparison of the approach\"s transferability to other LLMs should be included, particularly regarding the ability to craft adversarial prompts and transfer them to other LLMs. Additionally, it points out a minor issue with the jailbreaking percentage for certain LLMs. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors include a comparison of their approach\"s transferability to other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other LLMs. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to other LLMs that could be included in the comparison. The mention of a \"jailbreaking percentage\" being low for certain LLMs is a factual observation, but it does not directly support the main claim about transferability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear suggestion for improvement by recommending that the authors include a comparison of their approach\"s transferability to other LLMs. It specifically mentions the ability to craft adversarial prompts and transfer them to other LLMs, which could be a valuable addition to the paper. Additionally, the comment points out a minor issue with the jailbreaking percentage for certain LLMs, which could be addressed for completeness. While the comment is actionable and provides specific guidance, it could be more helpful if it offered additional details or examples on how to conduct the comparison or address the jailbreaking issue. Overall, the feedback is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It explicitly requests a more detailed explanation from the authors to understand the difference. This feedback is clear and direct, providing a specific action for the authors to take to improve their draft. The request for a detailed explanation leaves no ambiguity about what the authors need to do, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"unsupervised feature selection from a diffusion perspective,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the difference between similarity and exit times in nature. The comment requests a more detailed explanation, which provides clear guidance on what the authors need to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. The reviewer expresses a lack of understanding and requests a more detailed explanation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the difference is unclear. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It highlights a potential gap in the explanation provided by the authors, which could be addressed by offering a more detailed explanation. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their work. However, the comment could be more helpful if it provided suggestions on how to present the explanation or offered examples to illustrate the difference. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. While the comment implies that the authors should address this limitation, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the framework\"s applicability to various POMDP formulations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the framework\"s applicability to different POMDP formulations, but without clear grounding, the authors may struggle to determine where this question fits within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the limitations of the unified framework. It does not express an opinion, judgment, or suggestion that requires verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the unified framework, specifically asking if it can handle general POMDP formulations with continuous or infinite spaces. This is a relevant and important question that could help the authors expand the applicability of their framework. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or explore the framework\"s applicability to different POMDP formulations. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It notes that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. The comment suggests that the dataset created in the paper could serve as additional data for learning. While the comment implies that the authors should consider using the Kialo dataset instead of creating their own, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to integrate the Kialo dataset or what to do with the existing dataset. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the creation of the dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the dataset, noting that the Kialo dataset, which is wellstudied in the community, provides what the authors need\u2014pairs of short claims and their counters. The comment further specifies that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. Additionally, it suggests that the dataset created in the paper could serve as additional data for learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the creation of the dataset is optional, as the Kialo dataset provides what the authors need. It supports this claim by comparing the Kialo dataset to the one created in the paper, noting that the former is cleaner since it does not rely on automatic processes. The comment also suggests that the dataset created in the paper could serve as additional data for learning. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to the Kialo dataset, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment points out that the creation of the dataset is optional, as the Kialo dataset already provides the necessary pairs of short claims and their counters. It notes that the Kialo dataset is cleaner since it does not rely on automatic processes to construct it. The comment suggests that the dataset created in the paper could serve as additional data for learning. While the comment identifies a potential issue with the dataset and offers a suggestion for improvement, it lacks specific guidance on how to integrate the Kialo dataset or what changes should be made to the existing dataset. The feedback is 3 as it provides insight into the dataset\"s redundancy and suggests a potential direction for improvement, but it could be more actionable with additional details. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the limited number of tasks in the experiments and suggests that the authors should include more tasks (at least 10) and present sequential results in terms of tasks learned rather than epochs. While the comment explicitly states the need for more tasks and sequential results, it does not provide specific guidance on how to achieve this or what specific tasks should be included. The authors are given a clear direction but lack detailed instructions on how to implement the suggested changes. Therefore, the comment is 4, as it provides a concrete action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the experiments, specifically mentioning the limited number of tasks and the desire for sequential results in terms of tasks learned rather than epochs. However, it does not specify which part of the experiments this critique pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what the authors should address, namely the inclusion of more tasks and sequential results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the number of tasks in the experiments is limited and suggests that more tasks (at least 10) should be included. It also requests sequential results in terms of tasks learned rather than epochs. However, the comment lacks specific examples or references to support the claim that 10 tasks are necessary or that sequential results are more informative. Without detailed justification or evidence, the claim remains somewhat vague, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 3, as it provides some justification but lacks specific details or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experiments, noting that the number of tasks is limited and suggests that more tasks (at least 10) should be included. It also recommends presenting sequential results in terms of tasks learned rather than epochs. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting a larger number of tasks and a different presentation of results. However, the comment could be more helpful if it offered examples of how to present the sequential results or suggested specific tasks that could be included. Overall, the comment is 4 as it guides the authors toward enhancing the experimental section of their paper."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a problem with setting the parameter \"S,\" but it does not provide any explicit or implicit guidance on how to address this issue. There is no suggestion or direction on what changes or modifications should be made to improve the setting of this parameter. Without any actionable advice or concrete steps, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a problem with setting the parameter \"S,\" but it does not specify which part of the paper this issue is discussed in, nor does it provide details on what aspect of setting \"S\" is problematic. Without explicit references to sections, figures, or specific discussions, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved regarding the setting of \"S.\" Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"How to set the parameter S remains a problem.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the problem of setting the parameter \"S.\" However, it does not provide any further details, suggestions, or guidance on how to address this problem or improve the setting of the parameter. Without actionable feedback or additional context, the authors are left without a clear understanding of what steps to take to resolve the issue. Therefore, the comment is 1, as it does not offer any direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, it does not provide explicit guidance on how to conduct this human evaluation or what specific aspects should be evaluated. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct a human evaluation but without detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which are considered misleading. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections where caption generation is discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what aspects of the human evaluation would be more convincing or how it should be conducted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which are considered misleading. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why human evaluation would be more effective or how it could address the limitations of automatic metrics. Without such details, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which are considered misleading. This feedback highlights a potential weakness in the current evaluation approach and provides a clear suggestion for improvement. However, the comment lacks specific guidance on how to conduct a human evaluation or what aspects to focus on, which limits its helpfulness. While it identifies a critical area for improvement, it does not offer detailed actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experimental setup borrowed from a reference should be mentioned clearly, as it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This provides a direct action for the authors to take, which is to clarify the experimental setup in their draft. The comment is clear and specific about what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental setup borrowed from [2],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental setup, noting that it is only semireal due to the artificial creation of multinode seed cascades. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental setup is only semireal because it artificially creates multinode seed cascades by merging singlenode seed cascades. This claim is 3 as it provides a logical explanation for why the setup might not be fully realistic. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that it is only semireal because it artificially creates multinode seed cascades by merging singlenode seed cascades. This feedback is clear and actionable, as it directs the authors to clarify the experimental setup in their draft. By addressing this point, the authors can enhance the transparency and realism of their experimental design, which is crucial for the credibility of their results. However, the comment could be more helpful if it provided suggestions on how to improve the realism of the setup or offered examples of how to present this information more clearly. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the limited datasets and models used, and the absence of assessments on stateoftheart generative models like GPT. It also notes that the bias benchmarks only assess gender, race, and religion, suggesting that other important biases and datasets are not measured. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific datasets or models should be considered. The authors are left to infer that they should expand their dataset and model selection to include more diverse biases and stateoftheart generative models. However, the lack of concrete suggestions or examples makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limited datasets and models used in the paper, specifically mentioning the bias benchmarks that only assess gender, race, and religion. It also points out the absence of assessments on stateoftheart generative models like GPT. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing what is missing, such as assessments on other important biases and datasets, and the need for evaluations on stateoftheart generative models. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that the datasets and models used are limited, specifically mentioning that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. Additionally, it notes the absence of assessments on stateoftheart generative models like GPT. While the comment highlights specific areas where the paper could be improved, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the specific biases and datasets that should be included, and the reasoning behind the need for assessments on GPT. Therefore, the comment is 3, as it provides a general direction for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies two key areas for improvement: the limited datasets and models used, and the lack of assessment on stateoftheart generative models like GPT. It also points out that the bias benchmarks only assess gender, race, and religion, suggesting that other important biases are not measured. This feedback is clear and actionable, as it provides specific areas for the authors to expand their work, such as considering more diverse datasets and models. However, the comment could be more helpful if it offered suggestions on which specific datasets or models to include or how to assess these biases. Overall, the comment is 4 as it directs the authors to enhance the scope and depth of their study, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that Figure 3 is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. However, it does not provide explicit guidance or suggestions on how to improve the figure or clarify the issues. The authors are left to infer that they need to revise the figure and its captions, but without concrete instructions on what changes to make, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear workflow and captions, and the confusion regarding the representation of communication modes on the left side. This provides clear guidance on what needs to be addressed to improve the figure\"s clarity. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. However, the comment does not provide any specific examples or detailed reasoning to support why the figure is confusing. Without additional context or explanation, the authors may find it difficult to understand and address the issues raised. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it is challenging to understand due to unclear workflow and captions, as well as confusion regarding the representation of communication modes on the left side. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensibility of their figure. However, the comment could be more helpful if it provided specific suggestions on how to enhance the figure\"s clarity, such as recommending additional labels or explanations. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. While it identifies a specific area of confusion, it does not provide any guidance or suggestions on how the authors might clarify this point in their draft. The comment lacks explicit instructions or concrete steps for the authors to follow, leaving them without a clear understanding of what actions to take to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in identifying the term \"learned [MASK] embedding\" as unclear, but it lacks grounding because it does not provide a clear reference to the part of the paper where this term is used. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to justify why this term is unclear or how it should be clarified. The comment lacks specific details or examples that would help the authors understand the issue or address it effectively. As a result, the claim is considered 1, as it does not provide sufficient information for the authors to make improvements based on the feedback.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the meaning of \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. This is a clear and actionable feedback that prompts the authors to clarify this term in their draft. However, the comment does not provide any suggestions or guidance on how to address this issue, such as proposing alternative explanations or examples. While it highlights a critical area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it points out a specific area for clarification but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the reported results are partially derivative, as they extend to hypernetworks of results already presented in the literature for standard networks. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or improve their draft. There is no suggestion of what specific aspects of the results need to be revised or how the authors might differentiate their work from existing literature. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the reported results are partially derivative, as they extend to hypernetworks of results already presented in the literature for standard networks. However, it does not specify which part of the paper this observation is based on, such as a particular section, table, or figure. Without explicit references, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the results are derivative or how they could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the reported results are partially derivative, as they extend to hypernetworks of results already presented in the literature for standard networks. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or references, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment suggests that the reported results are partially derivative, as they extend to hypernetworks of results already presented in the literature for standard networks. However, it does not provide specific examples or references to support this claim, nor does it offer guidance on how the authors might differentiate their work or address this issue. Without actionable feedback or detailed suggestions, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Figure 3 is difficult to read, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the readability of the figure, such as suggesting ways to enhance the visual clarity or providing specific examples of what needs to be addressed. Without actionable advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in reading the figure. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual statement describing the difficulty in reading Figure 3. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment points out a specific issue with Figure 3, noting that it is difficult to read. However, it lacks any actionable feedback or suggestions on how to improve the figure\"s readability. Without guidance on what aspects of the figure are causing the difficulty or how to address it, the authors are left without a clear path to enhance their draft. This makes the comment 3, as it identifies an issue but does not provide actionable advice, leaving the authors with limited guidance on how to improve their work."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the GAT (Graph Attention Network) is trained with the whole model and that the text needs to be reviewed by an English native speaker for clarity. However, it does not provide specific guidance on how to improve the clarity or what aspects of the text need rewriting. The action is implicit and vague, as the authors are left to infer that they need to make changes to the text but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the GAT (Graph Attention Network) is trained with the whole model and that the text needs to be reviewed by an English native speaker for clarity. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the GAT is discussed. Additionally, while it mentions the need for rewriting, it does not provide specific examples or details on what needs to be rewritten. This lack of grounding and specificity makes it difficult for the authors to identify and address the issues effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the GAT (Graph Attention Network) is trained with the whole model and suggests that the text needs to be reviewed by an English native speaker for clarity. However, the comment lacks specific examples or detailed reasoning to support the claim about the GAT training or the need for rewriting. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two issues: the need for a native English speaker to review the text for clarity and the suggestion that the GAT (Graph Attention Network) is trained with the whole model. While the comment highlights areas for improvement, it lacks specificity and actionable guidance. It does not provide detailed feedback on what aspects of the text need clarification or how to improve the clarity, nor does it offer suggestions on how to address the issue with the GAT training. As a result, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: the replacement of a mathematical expression with an arbitrary parameter and the choice of a specific learning rate for SGD. The first point suggests that the authors should provide a justification for the replacement, which is an explicit action. The second point questions the justification for the learning rate choice, implying that the authors should provide an explanation. Both actions are explicit and provide clear guidance on what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (lines 119121 and line 164), allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issues with the replacement of a mathematical expression with an arbitrary parameter and the choice of a learning rate for SGD, questioning the justification behind these choices. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two claims: the replacement of a mathematical expression with an arbitrary parameter and the choice of a specific learning rate for SGD. The first claim is supported by referencing specific lines in the paper (lines 119121), which provides a clear basis for the critique. The second claim questions the justification for the learning rate choice, suggesting that it is unclear why the Adam default value was not used. While the comment highlights the issues, it does not provide detailed reasoning or references to support the claim fully. Therefore, the comment is 4, as it provides a solid foundation for the critique but lacks comprehensive evidence or references to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper. First, it points out the replacement of a mathematical expression with an arbitrary parameter, which could potentially affect the accuracy or interpretation of the results. Second, it questions the choice of a specific learning rate for SGD, noting that it differs from the default value used in Adam, and suggests that the authors should provide a justification for this choice. These critiques are clear and actionable, as they highlight areas where the authors need to provide additional explanation or justification. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to justify the parameter choices. Overall, the feedback is 4 as it directs the authors to important areas that require clarification or justification."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly encourages the authors to conduct error analysis in their paper and provide detailed explanations of the model\"s performance under different scenarios. This suggestion is clear and direct, giving the authors a specific action to take. The comment also explains the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. The feedback is concrete and provides a clear path for the authors to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting error analysis and providing detailed explanations of the model\"s performance under different scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the evaluation or results sections, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting error analysis and detailed explanations, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting error analysis to evaluate model performance and identify potential issues. It encourages the authors to provide detailed explanations of the model\"s performance under different scenarios, which would aid in guiding subsequent improvements and expansions of the ERC research. However, the comment does not provide specific examples or references to support the claim that error analysis is crucial or how it would benefit the paper. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of error analysis based on the general reasoning provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights the importance of error analysis in evaluating model performance and identifying potential issues. It provides a clear and actionable suggestion for the authors to conduct error analysis and offer detailed explanations of the model\"s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance their draft by providing insights into the model\"s strengths and weaknesses. However, the comment could be more helpful if it offered specific examples or methods for conducting error analysis, which would further assist the authors in implementing this suggestion. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests analyzing the domain gap and discussing the closeness of datasets, which could impact the adaptation of the method. It also mentions that if the method can finetune a pretrained model on synthetic data, the value of the approach would be higher. While the comment implies that the authors should address these points, it does not provide explicit instructions on how to conduct the analysis or discussion. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap and discussing the closeness of datasets, which could impact the adaptation of the method. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment does not specify which part of the paper should address these issues, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact part of the paper. The comment is specific in suggesting what needs to be discussed, such as the domain gap and the value of the approach. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests analyzing the domain gap and discussing the closeness of datasets, which could impact the adaptation of the method. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the domain gap or the potential value of the approach. This makes it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification or evidence to be 5.", "helpfulness_rationale": "The review comment suggests analyzing the domain gap between datasets and discussing the closeness of datasets, which could impact the adaptation of the method. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. While the comment identifies areas for improvement, it lacks specific guidance or examples on how to conduct the analysis or discussion. The feedback is 3 as it points out important considerations, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include at least one NCEbased method for comparison. It provides a specific action by referencing a study that demonstrates the feasibility of learning EBM on natural images with a strong noise distribution. This guidance is clear and concrete, giving the authors a direct and detailed instruction on how to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests including at least one NCEbased method for comparison, referencing a study that demonstrates the feasibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of an NCEbased method and referencing a study, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including at least one NCEbased method for comparison, referencing a study that demonstrates the feasibility of learning EBM on natural images with a strong noise distribution. This claim is 3 as it provides a reference to a specific study that supports the feasibility of the suggestion. However, the comment lacks detailed explanation or examples of how this comparison would benefit the paper, making it difficult for the authors to fully understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests including at least one NCEbased method for comparison, referencing a study that demonstrates the feasibility of learning EBM on natural images with a strong noise distribution. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by including a relevant comparison method. However, the comment could be more helpful if it explained why this comparison is important or how it would enhance the paper\"s contribution. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiment section could be improved by conducting significance tests on the human evaluation results and comparing the proposed method with recent LLMs. While the comment implies that these actions should be taken, it does not explicitly instruct the authors to do so. The suggestion is concrete, as it provides specific actions to enhance the experiment section, but it lacks explicit direction. Therefore, the comment is 3, as the authors can infer the actions but need more guidance on how to implement them.", "grounding_specificity_rationale": "The comment suggests improvements to the experiment section, specifically mentioning the need for significance tests on human evaluation results and comparisons with recent LLMs. However, it does not specify which part of the experiment section this feedback pertains to, such as a particular table or figure. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting improvements, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiment section could be improved by conducting significance tests on human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a logical suggestion for enhancing the experiment, it lacks specific examples or references to recent LLMs that could be used for comparison. This makes the claim 3, as the authors would need to identify suitable LLMs themselves to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas for improvement in the experiment section, suggesting that significance tests should be conducted on the human evaluation results and that the proposed method should be compared with recent LLMs. This feedback is clear and actionable, providing the authors with concrete steps to enhance the rigor and relevance of their experimental analysis. However, the comment could be more helpful if it included specific examples of recent LLMs to consider for comparison or detailed guidance on conducting significance tests. Overall, the comment is 4 as it directs the authors toward meaningful improvements in their experimental section."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to discuss a previous work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" and to illustrate the relationship between that work and their proposed method. It also suggests that the authors should explain why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the lack of research on joint error for UDA, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the problem of arbitrarily increased joint error has already been studied in a previous work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" published in ICML2019. The comment further instructs the authors to discuss this work and illustrate the relationship between it and their proposed method, as well as why their method is better. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors\" assertion about the lack of research on joint error for UDA is incorrect, as this problem has already been studied in a previous work. The reviewer supports this claim by referencing a specific paper, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" published in ICML2019. This reference provides a clear and specific example to substantiate the claim, making it 5. The reviewer also suggests that the authors should discuss this work and illustrate the relationship between it and their proposed method, which further strengthens the verifiability of the comment. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claim that there is no research focusing on the joint error for UDA. It points out that this problem has already been studied in a previous work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" published in ICML2019. The comment provides a specific reference to a relevant work, which is valuable for the authors to consider. It also suggests that the authors should discuss this work and illustrate the relationship between it and their proposed method, as well as explain why their method is better. This feedback is clear and actionable, offering a specific direction for the authors to improve their draft by addressing the gap in their claim and providing a comparative analysis. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods due to the use of a newly collected dataset of 209M samples, while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be attributed to the larger dataset rather than the method itself. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the fairness of the comparison. The action is implicit and vague, as the authors are left to infer that they should consider the impact of dataset size on their results and potentially reevaluate the comparison. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comparison with stateoftheart (SOTA) methods, specifically mentioning the use of a newly collected dataset of 209M samples compared to existing methods using smaller datasets. It provides a specific example of GEM using only 20M unlabeled data. This allows the authors to identify the part of the paper discussing the comparison with SOTA methods, making the comment fully grounded. The comment is also specific because it details the issue of dataset size impacting accuracy and suggests that the superior performance of the proposed method may be due to the larger dataset rather than the method itself. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison with stateoftheart (SOTA) methods may be unfair due to the use of a newly collected dataset of 209M samples, while existing methods use smaller datasets. The reviewer provides a specific example of GEM using only 20M unlabeled data. This comparison highlights the potential impact of dataset size on accuracy, suggesting that the superior performance of the proposed method may be attributed to the larger dataset rather than the method itself. The claim is 4 as it provides a logical reasoning and specific examples to support the argument, but it could be strengthened with additional references or detailed analysis of the dataset sizes. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison with stateoftheart (SOTA) methods due to the use of a newly collected dataset of 209M samples, while existing methods use smaller datasets. The reviewer points out that the superior performance of the proposed method may be attributed to the larger dataset rather than the method itself. This feedback is clear and actionable, as it prompts the authors to consider the impact of dataset size on their results and potentially reevaluate the comparison with SOTA methods. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as proposing alternative comparisons or adjustments to the experimental setup. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to consider."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use powerful pretrained language models like BERT and XLNet as the base encoder for all methods and then compare the efficacy of the transfer parts instead of using ngram features. This comment provides a clear and explicit action for the authors to take, specifying exactly what needs to be done to improve their draft. The suggestion is concrete, as it outlines a specific approach to enhance the paper\"s methodology. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods, rather than using ngram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in suggesting a change in methodology, but without clear grounding, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that powerful pretrained language models like BERT and XLNet can overcome the domainshift problem to some extent. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion or to assess its validity. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a significant change in the methodology by recommending the use of powerful pretrained language models like BERT and XLNet as the base encoder for all methods, rather than relying on ngram features. This feedback is clear and actionable, providing the authors with a specific direction to enhance their approach and potentially improve the efficacy of their work. However, the comment could be more helpful if it explained why this change is beneficial or how it would address the domainshift problem. Despite this, the suggestion is valuable and offers a concrete way for the authors to improve their draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the complexity of the proposed method and its relationship to the baselines. It questions whether the performance gain is due to a specific module or simply from having more parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address it. The action is implicit and somewhat vague, as it lacks specific instructions on how to conduct the ablation study or which modules to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the complexity of the proposed method and its relationship to the baselines, specifically questioning whether the performance gain is due to a particular module or simply from having more parameters. However, it does not specify which part of the paper discusses the ablation study or the modules in question, making it weakly grounded. The comment is specific in detailing the issue with the ablation study and the need for clearer answers regarding the performance gain. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the complexity of the proposed method and its relationship to the baselines, questioning whether the performance gain is due to a specific module or simply from having more parameters. The comment highlights the lack of clarity in the current ablation study, which does not provide definitive answers to these questions. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the problem and how to address it. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, specifically its complexity and the lack of clarity regarding the source of performance gains. It highlights the need for a more detailed ablation study to determine whether the performance improvement is due to a particular module or simply from having more parameters. This feedback is clear and actionable, as it points out a specific area where the authors can improve their draft by conducting a more thorough analysis. However, the comment could be more helpful if it provided suggestions on how to structure the ablation study or which modules to focus on. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific suggestion to improve the draft by requesting more explanation for the difference between two quantities and why it captures the difference in learning settings. This feedback is explicit and provides a clear action for the authors to take, which is to provide additional explanation in the manuscript. The comment also includes a subjective opinion about the acceptance of the paper, but this does not affect the actionability of the feedback. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 196197, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for more explanation regarding the difference between two quantities and why it captures the difference in learning settings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a request for more explanation regarding the difference between two quantities and why it captures the difference in learning settings, and a subjective opinion about the acceptance of the paper. The first part is a request for clarification, which does not contain a claim that requires verification. The second part is a subjective opinion, which does not need to be verified. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out a lack of explanation in the manuscript regarding the difference between two quantities and why it captures the difference in learning settings. This feedback is clear and directs the authors to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included suggestions on how to address this issue or provided examples of what additional explanation might look like. Despite this, the comment is 4 as it effectively guides the authors toward improving their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This request is clear and provides a direct action for the authors to take, which is to include a discussion on the sensitivity of these parameters. The feedback is specific and concrete, leaving no ambiguity about what the authors need to do to address the comment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly asks for a discussion on the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. However, it does not specify which part of the paper this discussion should be included in, such as a specific section or chapter. While the authors can infer that it relates to the methodology or results sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in its request for a discussion on sensitivity, which aligns with the 5 label.", "verifiability_rationale": "The review point is a request for additional discussion, specifically asking the authors to address the sensitivity of fixed tuning parameters in the model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or expansion, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by asking the authors to discuss the sensitivity of fixed tuning parameters in their model. This feedback prompts the authors to consider an important aspect of their methodology that could impact the robustness and performance of their model. However, the comment lacks depth and does not provide specific guidance on how to approach this discussion or what aspects to focus on. While it highlights a relevant area for exploration, the lack of detailed suggestions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. It also asks for clarification on the number of random seeds used for learning the policies (DDPO and IPPG). While the suggestion to explore different policy gradient approaches is explicit, it lacks concrete guidance on how to implement this exploration or which specific approaches to consider. The question about random seeds is explicit and provides a clear action for the authors to take. However, the overall comment is 3 as it provides a direction for further exploration but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. It also asks for clarification on the number of random seeds used for learning the policies (DDPO and IPPG). However, the comment does not specify which part of the paper this suggestion or question pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in suggesting an extension and asking for clarification on random seeds, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. It also asks for clarification on the number of random seeds used for learning the policies (DDPO and IPPG). However, the comment does not provide any supporting evidence, reasoning, or references to justify why exploring different policy gradient approaches would be beneficial or how it might impact the results. The request for clarification on random seeds is a factual question that does not require verification. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting extension to the proposed framework by exploring its compatibility with different policy gradient approaches. This feedback provides a clear direction for the authors to consider, offering a potential avenue for enhancing the applicability and robustness of their work. Additionally, the comment includes a specific question about the number of random seeds used for learning the policies (DDPO and IPPG), which is a relevant detail that could impact the reproducibility and robustness of the results. However, the comment could be more helpful if it provided guidance on how to conduct this exploration or suggested specific policy gradient approaches to consider. Overall, the comment is 4 as it offers actionable suggestions and prompts for further exploration, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper\"s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. This feedback is explicit and provides a clear action for the authors to take, which is to expand the analysis to include multiple datasets and tasks. However, it does not specify which datasets or tasks should be considered or how to implement this expansion. While the action is explicit, the lack of concrete details on how to execute it makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. However, it does not specify which part of the paper this critique is based on, such as a particular section or analysis that could be expanded. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas needing improvement. The comment is specific in suggesting the need for broader analysis, but without clear grounding, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. This claim is 3 as it provides a logical reasoning for why the results could be strengthened by expanding the analysis. However, the comment lacks specific examples or references to datasets or tasks that could be used for comparison, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s analysis, noting that it is based on only one dataset and one task. It suggests that the results and conclusions would be stronger if the analysis were applied to more datasets and tasks. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their analysis to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered suggestions on which additional datasets or tasks might be relevant or provided guidance on how to incorporate them into the analysis. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression. It suggests that the paper could also be presented in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate the suggestion or address the question about applicability. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting the paper in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this question or suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to consider kernel regression and present the paper in a different context, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the paper\"s considerations to kernel (ridge) regression and suggests presenting the paper in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why this should be the case. It lacks specific examples or detailed explanations that would help the authors understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment raises a question about the applicability of the paper\"s considerations to kernel (ridge) regression and suggests presenting the paper in the \"language of kernel interpolation/smoothing.\" While it identifies a potential area for expansion or clarification, the comment lacks specificity and actionable guidance. It does not provide detailed suggestions on how to incorporate kernel regression or what aspects of the paper might benefit from this perspective. As a result, the comment offers limited value to the authors in terms of improving their draft, making it 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that some claims in the paper may be inspired by existing studies and recommends adding supportive references. It provides an example by referencing lines 5564, where it identifies four critical factors affecting chainofthought prompting. The reviewer implies that these factors have been discussed in existing studies, but does not specify which studies or provide detailed guidance on how to incorporate these references. While the comment highlights an area for improvement, it lacks concrete instructions on how to implement the suggested action, such as identifying specific references or studies to include. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 5564,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely the need to add supportive references for claims that may be inspired by existing studies. The comment provides a clear example of the factors discussed in the paper that have been covered in existing studies, which helps the authors understand the specific areas that require further referencing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some claims in the paper may be inspired by existing studies and suggests adding supportive references. It provides an example by referencing lines 5564, where it identifies four critical factors affecting chainofthought prompting. The reviewer implies that these factors have been discussed in existing studies, but does not specify which studies or provide detailed references to support this claim. This lack of specific references or detailed evidence makes the claim 3, as the authors would need to invest time and effort to identify the relevant studies themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that some claims may be inspired by existing studies and suggesting that supportive references should be added. It provides a specific example by referencing lines 5564, where it highlights four critical factors affecting chainofthought prompting. The reviewer implies that these factors have been discussed in existing studies, which is a valuable observation for the authors to consider. However, the comment could be more helpful if it included specific references or examples of existing studies that the authors should consider. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement and provides a clear direction for enhancing the paper by incorporating relevant references. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the tasks used in the paper are somewhat standard and proposes that the authors consider creating unique tasks from the dataset to showcase the diversity of images and plots. It specifically mentions that tasks like Question Answering from images could be considered. While the comment implies that the authors should explore unique tasks, it does not provide explicit instructions on how to implement these suggestions or what specific tasks to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the tasks used in the paper are somewhat standard and proposes the creation of unique tasks to showcase the diversity of images and plots. It mentions specific examples, such as Question Answering from images, which provides some guidance on what could be considered. However, the comment does not explicitly mention which part of the paper discusses the tasks, making it weakly grounded. The authors can infer that it relates to the task description or methodology sections, but this inference is not as direct as it could be. The comment is specific in suggesting unique tasks, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the tasks used in the paper are somewhat standard and proposes the creation of unique tasks to showcase the diversity of images and plots. The reviewer provides a specific example of a task that could be considered, such as Question Answering from images. This suggestion is 3 as it offers a concrete example of how the tasks could be expanded, but it lacks detailed reasoning or references to support the claim that the current tasks are not innovative. The authors would need to consider the suggestion and determine its feasibility, which requires some effort to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that the tasks used are somewhat standard, such as figure captioning and matching figures to captions. It suggests that the authors could enhance their work by creating unique tasks from the dataset to showcase the diversity of images and plots. The comment provides a specific example of a task that could be considered, such as Question Answering from images, which offers a concrete suggestion for improvement. While the comment is clear and actionable, it could be more helpful if it included additional examples or detailed guidance on how to create these unique tasks. Overall, the feedback is 4 as it provides a clear direction for enhancing the paper, but it could be more comprehensive with further elaboration. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the relevance of the framework in relation to nonconvex losses and nonnorm type defenses. It asks whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints would make the algorithm irrelevant or if it could still provide insights into the risk upperbound. Additionally, it poses a question about using the covariance or other statistics to design a better defense if the true mean is known through an oracle. While the comment raises important questions, it does not provide explicit instructions or concrete suggestions for the authors to address these concerns. The actions are implicit and somewhat vague, as the authors need to infer what steps to take to address the questions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the relevance of the framework in relation to nonconvex losses and nonnorm type defenses, specifically mentioning the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints. It also asks about the potential use of covariance or other statistics to design a better defense if the true mean is known through an oracle. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the discussion of the framework and its applicability. The questions are specific, as they address the relevance and potential limitations of the framework. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of a series of questions and suggestions, rather than claims or opinions that require verification. It does not make subjective judgments, express disagreements, or suggest changes to the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the relevance of the framework in relation to nonconvex losses and nonnorm type defenses. It asks whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints would make the algorithm irrelevant or if it could still provide insights into the risk upperbound. Additionally, it poses a question about using the covariance or other statistics to design a better defense if the true mean is known through an oracle. These questions prompt the authors to consider the applicability and limitations of their framework, which is valuable for improving the draft. However, the comment could be more helpful if it provided suggestions or examples on how to address these questions or expand the discussion. Overall, the feedback is 3 as it identifies areas for further exploration but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the baselines in Figure 3, suggesting that the trained models could be sparsified to reduce the number of selected features and compare accuracy to the proposed model. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggestion or what specific features should be considered. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular experiment to conduct, which is to sparsify the trained models and compare accuracy to the proposed model. This provides clear guidance on what the authors could do to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the baselines in Figure 3. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the baselines in Figure 3, suggesting that the trained models could be sparsified to reduce the number of selected features and compare accuracy to the proposed model. This is a 3 comment as it prompts the authors to consider an additional experiment or analysis that could enhance the paper. However, it lacks specific guidance or suggestions on how to implement this idea or what specific features should be considered. While it provides a direction for improvement, it does not offer detailed actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several areas where the paper lacks detail, making it difficult to reproduce the results. It explicitly points out specific aspects that need clarification, such as the sparsification process, the generation of landmarks on the edge, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. Each of these points provides clear guidance on what the authors need to address to improve the clarity and reproducibility of their work. The comment is explicit and provides concrete details on how to implement the suggested improvements, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific areas that need clarification, such as the sparsification process, the generation of landmarks on the edge, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it details what aspects are unclear or missing, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks detail about the techniques, making it difficult to reproduce the results. It provides specific examples of what is unclear, such as the sparsification process, the generation of landmarks on the edge, and the number of landmarks used. These examples are detailed and provide a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific sections of the paper where these details are lacking or by providing examples from similar works that address these issues. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the lack of detail about the techniques used, which makes it difficult to reproduce the results. It provides specific examples of what is unclear, such as the sparsification process, the generation of landmarks on the edge, and the number of landmarks used. This feedback is clear and actionable, as it guides the authors on what aspects of their methodology need further explanation or clarification. By addressing these points, the authors can enhance the reproducibility and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how similar techniques are typically described in the literature. Overall, the comment is 4, as it effectively directs the authors to areas that require attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach used in FIITED for determining chunk significance, suggesting that basing eviction decisions solely on utility scores might introduce biases. It provides an example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their approach. The action is implicit and somewhat vague, as the authors are left to infer that they should consider alternative methods or additional criteria for eviction decisions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FIITED,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the utilitybased approach to determining chunk significance and the potential biases introduced by basing eviction decisions solely on utility scores. The comment provides a specific example of how recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically mentioning the potential for premature evictions of valuable chunks due to recent chunks gaining a temporary high utility. This claim is 3 as it provides a logical reasoning for the potential bias, but it lacks specific examples or references to support the assertion fully. The authors would need to consider this possibility and address it in their work, but the comment could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach used in FIITED for determining chunk significance. It highlights a concern that basing eviction decisions solely on utility scores might introduce biases, such as premature evictions of valuable chunks due to temporary high utility scores of recent chunks. This feedback is 3 as it points out a specific area that could be improved in the paper, prompting the authors to consider alternative methods or additional criteria for eviction decisions. However, the comment could be more helpful if it provided suggestions or examples of how to address this issue or offered a more detailed analysis of the potential biases. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of clarity regarding the performance of different parts of the framework and their contribution to the final result. It suggests that the authors should include quantitative experiments and comparisons between different algorithms, as well as more detailed explanations of the presented algorithms. While the comment implies that these actions should be taken, it does not explicitly instruct the authors to do so. The feedback is 3 as it provides a clear direction for improvement, but it lacks concrete guidance on how to implement the suggested changes. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the lack of clarity regarding the performance of different parts of the framework and their contribution to the final result. It mentions the experimental aspect and the result section, providing some grounding by referencing specific sections of the paper. However, it does not specify which parts of the framework are unclear or which algorithms need more detailed explanations, making it weakly grounded. The comment is specific in suggesting the need for quantitative experiments and comparisons between algorithms, as well as more detailed explanations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance of different parts of the framework and their contribution to the final result are unclear. It supports this claim by noting the lack of quantitative experiments and comparisons between algorithms, as well as a lack of detailed explanations for the presented algorithms. This provides a logical reasoning for the claim, as it highlights specific areas where the paper could be improved to provide more clarity. However, the comment could be strengthened by providing examples of how such experiments or comparisons might be conducted, which would make it 5. Therefore, the comment is rated as 4, as it provides a solid basis for the claim but lacks detailed examples or references that would fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the clarity of the framework\"s performance and contribution to the final result. It points out that while the results section shows promising visual stimuli, there is a lack of quantitative experiments and comparisons between different algorithms, as well as detailed explanations of the presented algorithms. This feedback is clear and actionable, as it provides specific areas for improvement that the authors can address to enhance the comprehensiveness and clarity of their work. By suggesting the inclusion of quantitative experiments and detailed explanations, the comment offers valuable guidance for the authors to strengthen their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps should be taken to clarify the model\"s capabilities. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment lacks specificity as it does not provide details on what aspects of the model or methodology are unclear or how the authors might address this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. However, it does not provide any supporting evidence, reasoning, or examples to justify why this question is relevant or how it relates to the paper\"s content. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses regarding neuron data. While it identifies a potential area of concern, it lacks specificity and does not provide any actionable suggestions or guidance for the authors to address this issue. The comment does not offer insights into how the authors might clarify or demonstrate the model\"s capabilities, leaving the authors without a clear path for improvement. As a result, the feedback is 2, as it points out a potential weakness but does not provide sufficient direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors present a simplified version of Theorem 2 for the general audience, similar to how Theorem 1 is presented. This is an explicit request for the authors to simplify the presentation of Theorem 2, which is a concrete action. The comment provides a clear direction on how to improve the draft by making it more accessible to a general audience. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests simplifying the presentation of Theorem 2 for a general audience, similar to how Theorem 1 is presented. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or subsection where Theorem 2 is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a simplification for a general audience, but without explicit grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that Theorem 2 is difficult to understand and proposes simplifying it for a general audience. However, the comment does not provide any specific reasoning or examples to support why Theorem 2 is challenging or how it could be simplified. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of Theorem 2, suggesting that it may be difficult for a general audience to understand. It proposes a solution by recommending a simplified version of Theorem 2, similar to how Theorem 1 is presented. This feedback is clear and actionable, providing the authors with a specific direction to improve the accessibility and clarity of their work. However, the comment could be more helpful if it included additional suggestions or examples on how to simplify the theorem. Overall, the comment is 4 as it offers a constructive and actionable suggestion for enhancing the paper."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting experiments with a larger image resolution to evaluate performance. While it implies that the authors should consider this change, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion or what specific resolutions to test. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests conducting experiments with a larger image resolution to evaluate performance. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results discussion. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in suggesting a potential improvement, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments with a larger image resolution to evaluate performance. However, it does not provide any supporting evidence, reasoning, or references to justify why this would be interesting or beneficial. The comment lacks specific examples or data to substantiate the claim, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the claim is 1.", "helpfulness_rationale": "The review comment suggests conducting experiments with a larger image resolution to evaluate performance. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct these experiments or what specific resolutions to test. The suggestion is 3 as it points out a possible enhancement, but it does not offer actionable steps or detailed advice, leaving the authors with a general idea of what could be explored. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the keypoint mask averaged feature vector and whether it is obtained by multiplying each feature map elementwise by H_psi. This comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or improve the clarity of the explanation in the paper. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the method used to obtain the keypoint mask averaged feature vector, asking whether it is obtained by multiplying each feature map elementwise by H_psi. This provides clear guidance on what aspect of the paper needs clarification. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the method used to obtain the keypoint mask averaged feature vector. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the method used to obtain the keypoint mask averaged feature vector, specifically asking whether it is obtained by multiplying each feature map elementwise by H_psi. While this question identifies a potential area of confusion or lack of clarity in the paper, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might clarify or improve this aspect of their work. As a result, the comment is 2, as it points out a potential issue but does not assist the authors in addressing it effectively."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is an explicit suggestion that provides a clear action for the authors to take. The comment is specific and provides a concrete direction on what needs to be added to the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular addition to the text, namely mentioning that the algorithms follow the sampled policy for a while. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is a request for clarification or additional information, not a claim or opinion that requires verification. It is a factual statement that does not need justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While this is a specific and actionable suggestion, it is limited in scope and does not provide broader context or guidance on why this information is important or how it fits into the overall narrative of the paper. The feedback is 3 as it directs the authors to a potential enhancement, but it could be more comprehensive by explaining the significance of this addition or suggesting other related improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. It notes that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results follow as an easy corollary of the collaborative ranking results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this observation or improve their draft. As a result, the authors are left without any actionable steps to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the major chunk of work involved in proving results for batched ranking problems, specifically the lower bounds for round complexity. It mentions that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results follow as an easy corollary. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the theoretical analysis or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing the issue with the lower bounds and their relation to collaborative ranking, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. It further states that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results follow as an easy corollary of these collaborative ranking results. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the ease of the reduction or the corollary nature of the lower bound results. This makes the claim 3, as it provides a general idea but lacks the necessary details to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a significant aspect of the paper, namely the major chunk of work involved in proving results for batched ranking problems, which is proving lower bounds for round complexity. It notes that the paper exploits an easy reduction from the problem of collaborative ranking, making the lower bound results follow as an easy corollary. While the comment identifies a key contribution of the paper, it does not provide any suggestions or guidance on how the authors might address this observation or improve their draft. The feedback lacks depth and actionable steps, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the prompting technique used in the study is basic and suggests that carefully curated prompts could lead to better results. However, it does not provide specific guidance on how to curate these prompts or what aspects of the current technique should be improved. The action is implicit and somewhat vague, as the authors are left to infer that they should explore more advanced prompting techniques but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the prompting technique used in the study, suggesting that it is basic and does not fully leverage the potential of LLMs. It implies that carefully curated prompts could lead to better results in generating systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique, making it weakly grounded. Additionally, while it provides a general suggestion for improvement, it lacks specificity in terms of what aspects of the prompting technique need to be addressed or how to curate better prompts. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks evidence or justification for why carefully curated prompts would lead to better results, making it difficult for the authors to understand and address the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the study by pointing out that the prompting technique used is basic and may not fully leverage the potential of LLMs. It suggests that carefully curated prompts could lead to better results in generating systematic reviews. However, the comment lacks specificity and does not provide detailed guidance or examples on how to curate these prompts or what aspects of the current technique should be improved. While it highlights an area for potential enhancement, the feedback is somewhat vague and incomplete, making it 3 for the authors to consider but not fully actionable. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived limitation in the novelty of the proposed video storyboarding approach, specifically noting that the primary method relies on framewise SDSA, which mirrors the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation as mask sources instead of crossattention. While the comment identifies a potential issue with the novelty of the approach, it does not provide explicit guidance or suggestions on how the authors might address this concern or enhance the novelty of their work. The action is implicit and vague, as the authors are left to infer that they should explore ways to differentiate their approach from existing methods. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed video storyboarding approach, specifically mentioning the reliance on framewise SDSA, which mirrors the approach used in ConsiStory. It highlights the use of CLIPseg and OTSU segmentation as mask sources as a potential difference. However, the comment does not specify which part of the paper discusses these methods or their comparison to ConsiStory, making it weakly grounded. The comment is specific in detailing the issue of limited novelty, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the innovation of the proposed video storyboarding approach is limited, primarily due to its reliance on framewise SDSA, which mirrors the approach used in ConsiStory. The comment further notes that the only notable difference is the use of CLIPseg and OTSU segmentation as mask sources instead of crossattention. While the comment provides a logical reasoning for the claim by comparing the approach to existing work, it lacks specific examples or detailed comparisons to fully substantiate the claim. The authors would need to refer to the original ConsiStory paper to fully understand the basis of the comparison. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires additional context for full verification.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the proposed video storyboarding approach, specifically noting that the primary method relies on framewise SDSA, which mirrors the approach used in ConsiStory. The comment highlights the use of CLIPseg and OTSU segmentation as mask sources as a potential difference, but it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. While it points out a weakness, the feedback lacks depth and actionable advice, making it 3. The authors are left with a general understanding of the issue but without clear steps to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point raises questions about the zeroshot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It also provides specific examples to support the claim, such as the difference between the \"walkerrun\" and \"walkerwalk\" tasks and the complexity of the manipulation scenario. The comment explicitly states that the authors need to clarify these points in the paper to avoid misleading readers. The feedback is clear and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment raises questions about the zeroshot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between the \"walkerrun\" and \"walkerwalk\" tasks and the complexity of the manipulation scenario, to support its claims. However, it does not explicitly mention which part of the paper these examples are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the difficulty of policy transfer and the need for clear explanations. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point raises a question about the zeroshot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. The reviewer provides specific examples, such as the difference between the \"walkerrun\" and \"walkerwalk\" tasks and the complexity of the manipulation scenario, to support their claim. This level of detail and specific examples make the claim 4, as it provides a logical basis for the critique. However, the comment could be strengthened by referencing relevant literature or studies that support the idea of limited transferability in similar scenarios. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a critical question about the zeroshot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It provides specific examples, such as the difference between the \"walkerrun\" and \"walkerwalk\" tasks and the complexity of the manipulation scenario, to support its claim. The comment also highlights the need for the authors to clarify these points in the paper to avoid misleading readers. This feedback is clear and actionable, as it identifies a potential weakness in the study and offers specific suggestions for improvement. By addressing these issues, the authors can enhance the clarity and validity of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. It suggests that the authors should consider adding more datasets or providing a repository for reproducing experiments. While the comment implies an action, it does not explicitly instruct the authors to take specific steps, such as identifying additional datasets or creating a repository. The action is somewhat vague, as it lacks concrete guidance on how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the sufficiency of the datasets for a rigorous evaluation, particularly in relation to the number of datasets available for each task. It mentions that having 5, 6, and 4 datasets for the three tasks, respectively, might not be sufficient. However, the comment does not specify which sections or parts of the paper discuss these datasets, making it weakly grounded. The comment is specific in its critique of the dataset selection and its impact on evaluation rigor. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. The reviewer suggests that having fewer datasets for each task might not provide a comprehensive evaluation. However, the comment lacks specific examples or references to support the claim that the datasets are insufficient. Without detailed justification or evidence, the claim remains somewhat vague, making it difficult for the authors to address the concern effectively. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the datasets for a rigorous evaluation, particularly given the large size of some datasets. It suggests that having fewer datasets for each task might not provide a comprehensive evaluation. The comment is 3 as it identifies a potential weakness in the dataset selection and evaluation process. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets or providing insights into how to balance dataset size and comprehensiveness. While it points out a relevant area for improvement, the comment could be more helpful with additional details or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the method\"s ability to address sparse reward problems and compares it to other methods like Qmix. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their method. The comment lacks concrete actions or details on how to implement changes, leaving the authors uncertain about what steps to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the method\"s ability to address sparse reward problems and compares it to other methods like Qmix. However, it does not specify which part of the paper discusses the method or the experiments, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the method\"s effectiveness and the comparison with Qmix, but it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the method\"s ability to address sparse reward problems and compares it to other methods like Qmix. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the method does not address sparse reward problems effectively. The mention of \"minor comments\" suggests that there might be additional points, but without further elaboration, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment raises a critical question about the method\"s ability to address sparse reward problems, specifically questioning whether it offers a better solution compared to other methods like Qmix. It also points out a potential issue with the proposed method requiring subtaskspecific rewards, which could be seen as providing a dense reward signal. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these concerns or improve their method. While it identifies an area for improvement, the feedback is incomplete and does not offer actionable advice, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN had access to this data during training for a fair comparison. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the curated AH36M dataset for training and whether other methods like HMR and SPIN had access to this data during training for a fair comparison. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its inquiry about the use of the dataset and the fairness of comparisons, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of the curated AH36M dataset for training and whether other methods had access to it during training for a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the fairness of the comparison. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises an important question about the use of the curated AH36M dataset for training and whether other methods like HMR and SPIN had access to this data during training. This is a relevant concern for ensuring a fair comparison among different methods. However, the comment lacks specificity and does not provide detailed guidance on how the authors might address this issue or what steps they should take to clarify the use of the dataset. While it identifies a potential area for improvement, the feedback is somewhat vague and could be more helpful with additional direction. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pretrained models. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The authors are left to infer that they need to clarify the motivation and potentially revise the experimental setup, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also mentions the addition of CAT and GAN, which makes the proposed model larger than others. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the concerns about the motivation and experimental fairness, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pretrained models. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 2, as it provides some insight but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment identifies several areas of concern, including the lack of clarity in the motivation for using an adversarial network in the model and questions the fairness of the experimental results. It also points out that the proposed model is larger than others due to the addition of CAT and GAN, even when compared to pretrained models. While the comment highlights important issues, it does not provide specific suggestions or guidance on how the authors might address these concerns. The feedback is 3 as it directs the authors to areas that need clarification or improvement, but it lacks actionable steps or detailed advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a samplebysample basis. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable guidance, such as recommending specific methods for tuning hyperparameters or discussing potential strategies to mitigate the variation. Without concrete advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a samplebysample basis. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about hyperparameter tuning and its implications, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a samplebysample basis. However, it does not provide specific examples, references, or detailed reasoning to support the claim. The comment lacks evidence or detailed justification, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the number of hyperparameters that need to be tuned and the potential variation in optimal hyperparameters due to the optimization being solved on a samplebysample basis. This is a relevant concern that could impact the robustness and generalizability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending methods for hyperparameter tuning or discussing potential strategies to mitigate the variation. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the performance of the proposed method should be compared with more methods and that analysis should be provided for inferior results that violate the motivation. While the comment implies that the authors should expand their comparisons and provide additional analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more comparisons and analysis. However, the comment does provide a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment addresses the comparison of performance with other methods and the consistency of the proposed method\"s superiority. It suggests that analysis should be provided for inferior results that violate the motivation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for additional analysis, but without clear grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that analysis should be provided for inferior results that violate the motivation. However, the comment lacks specific examples or references to support the claim about the limited comparison or the inconsistency in performance. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 2, as it provides some basis for the critique but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s performance evaluation, noting that it is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that analysis should be provided for inferior results that violate the motivation. This feedback is clear and actionable, as it directs the authors to expand their comparisons and provide additional analysis to address the inconsistency in performance. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or which methods to include in the comparison. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of experimental demonstration of the contribution points, specifically noting the absence of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF. The comment implies that the authors should include this comparison to prove the superiority of their method over MVF. While the action is implicit, it is clear and concrete, as the authors know exactly what needs to be done to address the issue: include a comparison with MVF. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of experimental demonstration of the contribution points, specifically referencing the absence of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experimental section, namely the comparison with MVF. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of its contribution points. It specifically points out the absence of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF, which is necessary to prove the superiority of the schema searched by the authors\" method over MVF. This claim is 3 as it provides a clear rationale for the need for additional comparisons to substantiate the claims. However, it lacks specific examples or references to support the assertion that the current experimental setup is insufficient. Providing more detailed evidence or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental demonstration of the contribution points in the paper. It highlights the lack of a comparison between the image classification result of Mid Vision Feedback (MVF) and the baseline without MVF, which is crucial for proving the superiority of the schema searched by the authors\" method over MVF. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to strengthen their experimental results. By suggesting the inclusion of this comparison, the comment offers a concrete step for enhancing the paper\"s experimental validation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests using different notation for \"D\" to avoid confusion between its use as a dimensionality of points and a dilation factor. While the comment identifies a potential issue and provides a clear action for the authors to take, it does not specify which notation should be used or how to implement this change. The action is explicit but somewhat vague, as the authors know they need to make a change but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests using different notation for \"D\" to avoid confusion between its use as a dimensionality of points and a dilation factor. However, it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure where \"D\" is used. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in suggesting a change in notation to avoid confusion, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using different notation for \"D\" to avoid confusion between its use as a dimensionality of points and a dilation factor. However, the comment does not provide any reasoning or examples to support why this confusion exists or how it could be resolved by using different notation. Without specific examples or detailed justification, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper, specifically the use of \"D\" to represent both dimensionality of points and dilation factor. It suggests using different notation to avoid this confusion, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific suggestions on alternative notations or examples of how to implement this change. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement that could enhance the clarity and readability of their work. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the clarity of the concept of \"state\" and suggests that it represents the grid status (e.g., agent position) and is obtained after applying an action of the trace. It questions whether \"elements\" in lines 186187 are equivalent to \"states\" or \"actions\" and recommends further elaboration. While the comment identifies a specific area of confusion and suggests a potential clarification, it does not provide explicit instructions on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the concept of \"state\" and potentially rephrase \"elements\" to align with the intended meaning. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether \"elements\" are equivalent to \"states\" or \"actions\" and suggests that more elaboration is needed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the concept of \"state\" and suggests that it represents the grid status (e.g., agent position) and is obtained after applying an action of the trace. The reviewer questions whether \"elements\" in lines 186187 are equivalent to \"states\" or \"actions\" and recommends further elaboration. While the comment identifies a potential area of confusion, it lacks specific examples or references to support the claim. The suggestion for clarification is logical but requires more detailed explanation or evidence to be 5. Therefore, the comment is 3, as it provides a basis for the claim but requires additional information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the concept of \"state\" in the paper. It questions whether \"elements\" in lines 186187 are equivalent to \"states\" or \"actions,\" suggesting that more elaboration is needed to clarify this point. This feedback is clear and actionable, as it directs the authors to address a particular aspect of their work that may be unclear to readers. By providing a specific line reference, the comment helps the authors pinpoint the exact location where clarification is needed. However, the comment could be more helpful if it offered suggestions on how to clarify the concept or provided examples of how to differentiate between \"states\" and \"elements.\" Overall, the comment is 4 as it effectively guides the authors toward improving the clarity and comprehensibility of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, should be described in more detail. However, it does not provide specific guidance on what aspects of the FRM should be elaborated or how the authors should present this information. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations but without concrete instructions on what to include. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, should be described in more detail. However, it does not specify which part of the paper this description should be added to, making it weakly grounded. The comment is specific in its request for more detailed explanation of the innovative aspects of the FRM. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed FRM, a combination of channel attention and spatial attention, should be described in more detail. However, the comment does not provide any specific reasoning or evidence to support why this description is lacking or how it could be improved. Without additional context or examples, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the proposed FRM, a combination of channel attention and spatial attention, should be described in more detail. This feedback is 3 as it points out a potential weakness in the paper and encourages the authors to provide a more comprehensive explanation of their innovative approach. However, the comment lacks specificity and does not offer detailed guidance on what aspects of the FRM should be elaborated or how to present them. To be more helpful, the comment could include suggestions on what specific details should be included or how to better explain the innovation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a potential restructuring of the paper by moving the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. While the comment implies an action, it does not provide explicit instructions on how to implement this restructuring or why it would improve the paper. The authors can infer that they need to rearrange the sections, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3, as it provides an idea but lacks detailed execution steps.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 and Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a potential restructuring of the sections to reduce redundancy. However, the comment does not provide detailed reasoning or examples of how the sections are redundant or how the suggested restructuring would improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Sections 3 and 4 are slightly redundant and proposes a restructuring to improve clarity. However, the comment does not provide specific examples or detailed reasoning to support why the sections are redundant or how the proposed restructuring would benefit the paper. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with redundancy in Sections 3 and 4 of the paper. It suggests a restructuring of the sections to improve clarity by moving the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This feedback is clear and actionable, providing the authors with a specific suggestion to enhance the organization and flow of their paper. However, the comment could be more helpful if it included additional context or reasoning behind the redundancy, or if it offered more detailed guidance on how the proposed restructuring would benefit the paper. Overall, the comment is 4 as it offers a constructive suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should conduct theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. However, the comment does not provide explicit instructions or concrete steps on how to conduct these analyses or experiments. While the authors can infer that they need to perform additional research, the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct theoretical analyses or extensive experiments to understand the reasons behind the empirical results. It mentions specific aspects that could be explored, such as the performance of simple greedy selection versus more principled acquisition functions and the superiority of deterministic MLP predictors over probabilistic predictors. However, the comment does not specify which part of the paper these analyses or experiments should be conducted in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint the exact areas for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the empirical results of the proposed method are strong and that a more novel contribution would be to explore theoretical analyses or extensive experiments to understand the reasons behind the performance of simple greedy selection and deterministic MLP predictors. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that these analyses are missing or necessary. The suggestion is 3 as it highlights a potential area for improvement, but the lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors conduct theoretical analyses or extensive experiments to understand the reasons behind the empirical results. It specifically mentions the superiority of simple greedy selection over more principled acquisition functions and the performance of deterministic MLP predictors over probabilistic predictors. While the comment highlights an interesting direction for further exploration, it does not provide specific guidance or suggestions on how to conduct these analyses or experiments. The feedback is 3 as it points out a gap in the paper and offers a direction for future work, but it lacks actionable details that would fully support the authors in making improvements. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a citation for the discussion of the \"kmax problem\" elsewhere. This is a clear and direct action that the authors can take to address the comment. The instruction is specific and leaves no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"the kmax problem,\" which allows the authors to identify the specific part of the paper being addressed. It also specifies the need for a citation, providing clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, specifically asking for a citation regarding the discussion of the \"kmax problem\" elsewhere. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and specific in its request for a citation regarding the discussion of the \"kmax problem\" elsewhere. This feedback is actionable and provides a direct way for the authors to improve their draft by addressing a potential gap in their literature review. However, the comment could be more helpful if it provided context or explained why this information is important or relevant to the paper. Despite this, the comment is 4 as it guides the authors toward a specific improvement, making it a 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies two issues: forward referencing and the need for clearer explanations of contributions in the introduction. It also mentions that material supporting the main contributions is in the appendix rather than the main sections. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the contributions in the introduction and ensure that the main contributions are discussed in the main sections, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"the Introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the need for clearer explanations of contributions and the placement of material supporting the main contributions in the appendix rather than the main sections. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, with material being introduced without proper explanation and then explained later. It also mentions that the main contributions are not clearly written in the introduction and that supporting material is in the appendix rather than the main sections. However, the comment lacks specific examples or references to substantiate these claims, making it difficult for the authors to understand the exact issues and address them effectively. The lack of detailed evidence or examples makes the claim 3, as it provides a general direction but requires more detailed justification to be fully actionable.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: forward referencing and the need for clearer explanations of contributions in the introduction. It also points out that material supporting the main contributions is in the appendix rather than the main sections. These observations are valuable as they highlight areas where the paper may be confusing or lacking in clarity. However, the comment could be more helpful if it provided specific suggestions on how to address these issues, such as recommending where to include additional explanations or how to restructure the content. Despite this, the feedback is 4 as it directs the authors to areas that need improvement, offering a clear path for enhancing the clarity and organization of their draft. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the authors have not analyzed the security of their proposed framework, specifically the protection of privacy. This provides a clear and direct action for the authors to take: they should include an analysis of the security aspects of their framework, particularly focusing on privacy protection. The comment is explicit and provides a concrete action for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of analysis on the security (i.e., protection of privacy) of the proposed framework. This allows the authors to accurately identify the part of the paper being addressed, such as the methodology or results sections where security analysis might be expected. The comment is also specific because it clearly specifies what is missing: an analysis of the security aspects, particularly the protection of privacy. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not analyzed the security (i.e., protection of privacy) of the proposed framework. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of an analysis on the security (i.e., protection of privacy) of the proposed framework. This is a critical area that authors should address to ensure the robustness and reliability of their work. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects to focus on, leaving the authors with a general direction but without detailed actionable steps. While the feedback highlights an important area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks but do not provide an explicit explanation or understanding of this concept. The reviewer asks the authors to explicitly explain what type of understanding one reaches by looking at PPP maps. This request is explicit and provides clear guidance on what the authors need to do to improve their draft. The action is concrete, as it specifies the type of explanation needed, making this comment 5.", "grounding_specificity_rationale": "The comment addresses the authors\" statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks. However, it does not specify which part of the paper this statement is made in, making it weakly grounded. The comment is specific in its request for the authors to explicitly explain what type of understanding one reaches by looking at PPP maps. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" statement about the importance of reliable PPP metrics for understanding PPP effects in different tasks. It points out that the article does not provide an explicit explanation or understanding of this concept. The comment is 3 as it highlights a gap in the paper\"s explanation, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to provide additional context or explanation to address the concern, making the comment 4.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the explanation of the importance of reliable PPP metrics for understanding PPP effects in different tasks. It highlights the need for the authors to provide an explicit understanding of what type of insights can be gained from looking at PPP maps. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their work that could enhance the reader\"s understanding. However, the comment could be more helpful if it offered specific suggestions on how to present this explanation or what aspects to focus on. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the training process for RBI, noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors can infer the need for a stronger baseline but are not given concrete steps on how to achieve it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the training process for RBI, specifically noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. However, the comment does not specify which part of the paper discusses RBI or FP, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this discussion is located, the lack of explicit grounding makes it weakly grounded. The comment is specific in identifying the issue with the training process and suggesting a potential improvement, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, specifically noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. However, the comment lacks specific examples or references to support the claim that rewardless actions are ignored, making it 3. The authors would need to further explore and substantiate the claim to fully understand its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the training process for RBI, noting that it only considers rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The comment implies that the authors should provide a stronger baseline than RBI, which is supervised by feedback, to prove the usefulness of FP. While the comment highlights an important issue and suggests a potential improvement, it lacks specific guidance or detailed suggestions on how to address this concern. The authors are left with a general idea of what needs to be improved but without clear steps to take. Therefore, the comment is 3, as it provides some direction but not comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the use of the term \"multiscale\" in the context of the slow and fast RNNs, suggesting that the statement is misleading because the RNNs operate on a logical time scale rather than a physical one. The reviewer provides a rationale for this critique, explaining that the only benefit seems to be the reduction of gradient path by the slow RNN. While the comment identifies a potential issue with the terminology, it does not provide explicit guidance on how the authors should address this issue or suggest alternative wording. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the terminology or provide additional context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of the term \"multiscale\" in the context of the slow and fast RNNs, suggesting that it is misleading because the RNNs operate on a logical time scale rather than a physical one. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this discussion might be, the lack of explicit reference makes it weakly grounded. The comment is specific in detailing the issue with the terminology and the rationale behind it, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the use of the term \"multiscale\" is misleading because the slow and fast RNNs operate on a logical time scale rather than a physical one. The reviewer provides a logical reasoning by explaining that the only benefit seems to be the reduction of gradient path by the slow RNN. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the terminology used in the paper, specifically the term \"multiscale,\" which the reviewer suggests is misleading. The reviewer explains that the slow and fast RNNs operate on a logical time scale rather than a physical one, and that the only benefit seems to be the reduction of gradient path by the slow RNN. This feedback is clear and actionable, as it points out a specific area where the authors might need to clarify their terminology or provide additional context to avoid confusion. However, the comment could be more helpful if it offered suggestions on how to rephrase or clarify the terminology. Overall, the comment is 4 as it provides valuable insight into a potential misunderstanding in the paper, prompting the authors to reconsider their terminology and its implications."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify the distinction between the decisionmaker\"s interest in the true objective function and the noise, which is currently not represented clearly. It implies that the authors should make this distinction clearer upfront in the paper. While the comment explicitly states the need for clarification, it does not provide specific guidance on how to achieve this, such as suggesting changes to the wording or structure of the paper. The action is explicit but somewhat vague, as the authors know they need to clarify the distinction but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need to clarify the distinction between the decisionmaker\"s interest in the true objective function and the noise, and how this distinction is not currently represented. The comment provides a clear direction for improvement by suggesting that the authors make this distinction clearer upfront. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the expected performance under observation noise is typically used for evaluation because the decisionmaker is interested in the true objective function, while the noise is assumed to be noise. It contrasts this with the formulation in the paper, where the decisionmaker does care about the noise and the objective function of interest is the stochastic noisy function. The comment suggests that this distinction should be made clearer upfront. While the claim is based on a logical reasoning about the typical evaluation practice and the paper\"s formulation, it lacks specific examples or references to support the assertion fully. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the decisionmaker\"s interest in the true objective function versus the noise. It points out that the typical approach is to evaluate expected performance under observation noise, assuming the noise is misleading and not representative. However, the comment notes that in the paper\"s formulation, the decisionmaker does care about the noise, and the objective function of interest is the stochastic noisy function. The reviewer suggests that this distinction should be made clearer upfront, which is a valuable observation that could help the authors clarify their work. The feedback is clear and actionable, providing a specific area for improvement that could enhance the paper\"s clarity and understanding. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the longrange modelling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another factor contributing to poor performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The mention of a specific paper provides some context but does not offer actionable steps for the authors. As a result, the comment is vague and lacks concrete details on how to implement any changes, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the longrange modelling ability of DGNs, attributing the issue to oversquashing and vanishing/exploding gradients. It also mentions oversmoothing as a potential factor, referencing a specific paper. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The mention of a specific paper provides some specificity, as it suggests a potential direction for further exploration. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the poor longrange modelling ability of DGNs could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. The reviewer supports this claim by referencing a specific paper, \"Deeper Insights into Graph Convolutional Networks for SemiSupervised Learning, In AAAI\"18,\" which provides a detailed analysis of the issue. This reference offers a robust basis for the claim, making it 5. The inclusion of a specific reference ensures that the authors can easily access the relevant information to understand and address the issue. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modelling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that oversmoothing could be another factor contributing to poor performance, referencing a specific paper for further context. This feedback is 3 as it points out a specific area of concern and provides a reference for the authors to explore. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any explicit or implicit guidance on how to clarify the problem formulation or what specific aspects are unclear. Without additional details or suggestions, the authors are left without a clear understanding of what changes are needed to improve the clarity of the problem formulation. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment indicates that the problem formulation is unclear in the statement and introduction examples. However, it does not specify which parts of the statement or introduction are unclear, nor does it provide details on what aspects need clarification. This lack of specificity and lack of explicit references to sections or examples make it difficult for the authors to pinpoint the exact areas that need improvement. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specificity and does not provide any actionable guidance or suggestions on how to improve the clarity. Without detailed feedback or examples of what needs to be clarified, the authors are left without a clear understanding of what changes are needed to address the issue. This makes the comment 3, as it points out a potential area for improvement but does not offer sufficient direction for the authors to effectively address it. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide valuable insights into the method\"s applicability and generalizability. This feedback is clear and provides a concrete action for the authors to take, which is to conduct additional experiments. The suggestion is specific and actionable, as it outlines exactly what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide insights into the method\"s applicability and generalizability. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional experiments, but without clear grounding, the authors may struggle to determine where these experiments should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide insights into the method\"s applicability and generalizability. The comment does not contain subjective opinions, judgments, or suggestions that require verification. It is a request for additional experiments, which is a factual statement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting the absence of experiments with different LLM families, such as OPT, BLOOM, or other alternatives. It suggests that conducting such experiments could provide valuable insights into the method\"s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it directly points out a specific area for improvement and offers a concrete suggestion for enhancing the paper. By addressing this feedback, the authors can significantly strengthen their draft by demonstrating the method\"s versatility and applicability across different LLM families. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation, whether it should be clarified, or if it should be expanded to include other types of models. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide details on why this limitation exists or how it could be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method only works for generative models that can be finetuned as an in/outpainting model. While this observation highlights a potential limitation of the method, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this limitation or expand the applicability of their method. As a result, the comment is not particularly helpful for the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived disconnect between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. The reviewer suggests that the connection between these two parts is weak and that the initial expectation of the first part was not met. However, the comment does not provide explicit guidance on how to strengthen the connection or improve the clarity of the paper. While it identifies an issue, it lacks actionable advice or suggestions for the authors to address it. The feedback is vague and does not offer concrete steps for improvement, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the connection between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. It suggests that the connection between these two parts is weak and that the initial expectation of the first part was not met. However, the comment does not specify which sections or parts of the paper these expectations are based on, making it difficult for the authors to pinpoint the exact areas needing revision. While the comment provides some insight into the perceived disconnect, it lacks specificity and grounding, as it does not direct the authors to specific sections or elements of the paper that need attention. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the connection between the curve finding (the first part) and FGE (the second part) is weak. However, it does not provide any specific examples, reasoning, or references to support this claim. The comment also mentions an initial expectation that was not met, but again, lacks detailed justification or evidence. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a perceived disconnect between the first part of the paper, which involves curve finding, and the second part, which focuses on FGE. It suggests that the initial expectation of the first part was not met, as the reviewer had expected a specific approach involving random weights and curve learning. However, the comment does not provide detailed feedback or suggestions on how to strengthen the connection between these parts or improve the clarity of the paper. While it highlights an area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not offer comprehensive advice for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should discuss the proposed method in relation to existing methods that capture similar general ideas, such as the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. While the comment implies that the authors should make these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to make these comparisons or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"grounding of the proposed method in neuroscience\" and the \"general ideas\" that are already present in other methods, such as the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, discussing the proposed method in relation to these existing methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some of the general ideas in the proposed method are already present in other methods, specifically mentioning the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. The reviewer provides a detailed explanation of how these existing methods capture similar ideas, such as reasoning topologically and longterm storage through pose graphs. This reasoning is supported by references to specific methods and concepts, making the claim 4. However, the comment could be strengthened by providing more detailed comparisons or examples of how the proposed method differs from these existing approaches. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that some of the general ideas proposed are already present in other methods, such as the generalized Voronoi graph, semantic maps, and pose graphs in SLAM. It suggests that the paper should discuss the proposed method in relation to these existing methods, which could provide a more comprehensive understanding of its novelty and contribution. This feedback is clear and actionable, as it directs the authors to make a comparison with existing work, which can help them strengthen their argument and improve the clarity of their paper. However, the comment could be more helpful if it provided specific examples or references to guide the authors in making these comparisons. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests moving some details from the appendix back into the main text and moving some background from Section 2 to the appendix instead. While the comment provides a clear action for the authors to take, it does not specify which details should be moved back or which background should be moved to the appendix. This lack of concrete guidance makes the action somewhat vague, as the authors may not be entirely sure of the exact changes needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of moving experimental setup, tasks, and other details to the appendix, which makes it difficult to interpret the paper. It suggests moving some of these details back into the main text and moving some background from Section 2 to the appendix instead. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the appendix and possibly Section 2. The suggestion is specific in terms of what needs to be addressed, but the lack of explicit references to sections or figures makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that moving the experimental setup, tasks, and other details to the appendix makes it difficult to interpret the paper. The reviewer suggests moving some of these details back into the main text and moving some background from Section 2 to the appendix instead. However, the comment lacks specific examples or detailed reasoning to support why this change would improve the paper\"s interpretability. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of the paper, noting that moving experimental setup, tasks, and other details to the appendix makes it difficult to interpret the paper. It suggests a potential solution by recommending moving some of these details back into the main text and moving some background from Section 2 to the appendix instead. This feedback is clear and actionable, providing the authors with a specific direction to improve the readability and accessibility of their work. However, the comment could be more helpful if it included more detailed guidance on which specific details should be moved or why the current organization is problematic. Overall, the comment is 4 as it offers a constructive suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point notes that \"Memb\" is apparently the previous stateoftheart but lacks a reference. This implies that the authors should include a reference to support this claim. However, the comment does not explicitly instruct the authors to do so, leaving it as an implicit action. Additionally, while the action is clear, it lacks concrete guidance on which reference to include or how to integrate it into the text. Therefore, the comment is 3, as the authors can infer the action but need more detailed guidance to execute it effectively.", "grounding_specificity_rationale": "The comment mentions \"Memb,\" implying that it is a previous stateoftheart method, but does not specify which part of the paper this claim pertains to. This makes it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity as it does not detail what aspect of \"Memb\" is missing or how it should be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"Memb\" is the previous stateoftheart but lacks a reference. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that \"Memb\" is apparently the previous stateoftheart but lacks a reference, which is a significant omission in the paper. This feedback is important as it highlights a potential gap in the literature review or methodology section, which could impact the credibility and completeness of the paper. However, the comment does not provide specific guidance on how to address this issue, such as suggesting which references to include or how to integrate them into the text. While it identifies a critical area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests studying the impact of the ratio of unseen classes and provides an example of how the performance varies with different ratios of unseen classes. This comment explicitly states an action for the authors to take, which is to investigate the impact of the ratio of unseen classes. The suggestion is clear and provides a concrete example of what the authors should explore, making the comment 5.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes and provides an example of how the performance varies with different ratios of unseen classes. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in suggesting a particular aspect to explore, but it lacks grounding because it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests studying the impact of the ratio of unseen classes, providing an example of how performance varies with different ratios of unseen classes. This suggestion is based on logical reasoning, as it proposes an additional aspect of the study that could provide valuable insights. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the potential benefits of this analysis and how it could impact their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an additional aspect of the study that could be explored, specifically the impact of the ratio of unseen classes on performance. It provides a concrete example of how the performance varies with different ratios of unseen classes, which is a valuable suggestion for the authors to consider. This feedback is clear and actionable, offering a specific direction for the authors to enhance their work. However, it could be more helpful if it included additional guidance on how to conduct this analysis or potential implications of the findings. Overall, the comment is 4 as it provides a meaningful suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"For training we used an epsilongreedy ...\" and asks whether it refers to an epsilongreedy exploration on top of the proposed strategy. This comment is explicit in its request for clarification, as it directly asks for an explanation of the term \"epsilongreedy\" and its relationship to the proposed strategy. The authors are given a clear action to take, which is to provide a detailed explanation of the term and its role in the context of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"For training we used an epsilongreedy ...\" and asks whether it refers to an epsilongreedy exploration on top of the proposed strategy. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of \"For training we used an epsilongreedy ...\" and whether it refers to an epsilongreedy exploration on top of the proposed strategy. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"For training we used an epsilongreedy ...\" and whether it refers to an epsilongreedy exploration on top of the proposed strategy. This feedback is 3 as it prompts the authors to clarify a potentially ambiguous statement in their paper. However, it does not provide specific guidance on how to address the issue or suggest improvements to enhance the clarity of the paper. While it points out a potential area for improvement, the comment lacks depth and actionable advice, making it 3 but not comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed method as a direct combination of GCN and normalizing flow, with the ultimate transformed distribution being replaced by a Gaussian mixture distribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the critique, improve the method, or provide additional context or justification. As a result, the comment lacks actionability and does not offer any direction for the authors to enhance their draft. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment critiques the proposed method as a direct combination of GCN and normalizing flow, with the ultimate transformed distribution being replaced by a Gaussian mixture distribution. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, while the comment provides some insight into the method\"s novelty, it lacks specificity in terms of what aspects need improvement or clarification. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the proposed method as a direct combination of GCN and normalizing flow, with the ultimate transformed distribution being replaced by a Gaussian mixture distribution. The comment suggests that this approach lacks novelty, but it does not provide specific examples or references to support this claim. The reasoning is somewhat vague, as it does not elaborate on why the combination of GCN and normalizing flow is not innovative or how the use of a Gaussian mixture distribution impacts the method\"s novelty. Therefore, the comment is rated as 2, as it provides some basis for the claim but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment critiques the proposed method as a direct combination of GCN and normalizing flow, with the ultimate transformed distribution being replaced by a Gaussian mixture distribution. It suggests that this approach lacks novelty, but it does not provide specific feedback or suggestions on how the authors could improve their work or address the perceived lack of originality. The comment identifies a potential weakness but lacks actionable guidance, making it 3 as it points out an area for improvement but does not offer detailed advice on how to enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the feature selection presented in Section 4.2 could be improved by considering representation learning. However, it does not provide explicit guidance on how to incorporate representation learning or what specific aspects of the feature selection need improvement. The comment implies an action but lacks concrete details on how to implement it, leaving the authors with a general direction but no clear steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, including \"Sec. 4.2\" and \"Line 167174, Sec. 4,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out that the proposed invariant learning module focuses on mask selection and rawlevel features, while the former framework seems not limited to rawlevel selection. Additionally, the comment suggests that the feature selection could be improved by considering representation learning. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the feature selection presented in Section 4.2 could be improved by considering representation learning. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The mention of the \"former framework\" and \"representation learning in the appendix\" adds some context but lacks sufficient detail to fully substantiate the claim. As a result, the comment is 3, as it provides a general direction but lacks the depth needed for a 5 claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed invariant learning module, specifically noting that the feature selection presented in Section 4.2 could be improved by considering representation learning. It points out that the former framework (Line 167174, Sec. 4) seems not limited to rawlevel selection and suggests that the authors should explore representation learning as a means to enhance their feature selection approach. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, it could be more helpful if it offered more detailed guidance on how to incorporate representation learning or examples of how it might be applied. Overall, the comment is 4 as it directs the authors to a meaningful area for enhancement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some details are missing, specifically mentioning the design of rewards. However, it does not provide explicit guidance on what details are missing or how the authors should address this issue. The comment lacks concrete suggestions or examples, leaving the authors uncertain about how to improve their draft. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment mentions that \"some details are missing,\" specifically regarding the design of rewards. However, it does not specify which part of the paper this pertains to, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the missing detail about the design of rewards, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that \"some details are missing,\" specifically mentioning the design of rewards. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand which details are missing or how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area where the paper lacks detail, namely the design of rewards. This is a clear and actionable piece of feedback that can guide the authors in improving their draft by providing more information on this critical aspect. However, the comment could be more helpful if it offered suggestions on what specific details should be included or how the authors might approach the design of rewards. Despite this, the feedback is still 3 as it directs the authors to a specific area needing attention. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications that require computational cheapness. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to discuss the runtime or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the runtime of Prithvi WxC, given its large parameter count, as a potential limitation for applications that require computational cheapness. However, it does not specify which part of the paper should include this discussion, making it weakly grounded. The comment is specific in its suggestion to address the runtime as a limitation, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where this discussion should be included. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the selling point of MLbased emulators is their computational cheapness, and it suggests that the runtime of Prithvi WxC should be discussed due to its large parameter count. The comment provides a logical reasoning for why the runtime is important, as it could be a limitation for applications requiring computational cheapness. However, it lacks specific examples or references to support the claim about the large parameter count or the potential impact on runtime. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the point.", "helpfulness_rationale": "The review comment identifies a potential limitation of the Prithvi WxC model, specifically its large parameter count, which could impact its computational cheapness. It suggests that the authors should discuss the runtime of Prithvi WxC as a limitation for applications that require computational cheapness. This feedback is clear and actionable, as it provides a specific area for improvement and a direction for the authors to address in their draft. However, it could be more helpful if it offered suggestions on how to discuss the runtime or potential solutions to mitigate this limitation. Overall, the comment is 4, as it guides the authors toward enhancing their draft by addressing a critical aspect of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the quality of paraphrases used in the training data, noting that the difference between the paraphrases and the original sentences is unclear. It suggests that this could impact the subsequent steps, as the model relies on the quality of these paraphrases. The comment implies that the authors should ensure the paraphrases are sufficiently different from the originals to maintain the quality of the training data. However, it does not provide explicit guidance on how to achieve this or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue of paraphrase quality but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific concern about the quality of paraphrases used in the training data, questioning how different they are from the original sentences. It highlights the importance of this issue for subsequent steps, as the model relies on the quality of these paraphrases. However, the comment does not specify which part of the paper discusses the generation of paraphrases, making it weakly grounded. The authors can infer that it relates to the methodology or data preparation sections, but this inference is not explicit. The comment is specific in detailing the impact of the paraphrase quality on the training data and subsequent steps. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of paraphrases used in the training data is unclear, which could impact the subsequent steps of the model. The reviewer provides a logical reasoning by suggesting that if the difference between the paraphrases and the original sentences is not significant, the quality of the training data will be compromised. This reasoning is based on a logical chain of events, making the claim 3. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the quality of paraphrases used in the training data, noting that the difference between the paraphrases and the original sentences is unclear. It highlights the importance of this issue, as it directly impacts the subsequent steps of the model, which relies on the quality of these paraphrases. The comment provides a clear and actionable suggestion by emphasizing the need to ensure that the paraphrases are sufficiently different from the originals to maintain the quality of the training data. This feedback is valuable as it directs the authors to a specific area that requires attention and improvement. However, the comment could be more helpful if it offered specific guidance on how to assess or improve the quality of the paraphrases. Overall, the comment is 4, as it effectively points out a critical issue and provides a clear direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it does not provide specific guidance on how to improve the writing or what aspects need attention. The action is implicit and vague, as the authors are left without clear direction on how to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it does not specify which parts of the paper are particularly challenging or what aspects of the writing need improvement. Without explicit references to sections, figures, or specific issues, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what improvements are needed, such as clarity, organization, or coherence. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate why the writing is challenging or how it could be improved. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the writing could be improved, noting that it took effort to understand the main idea and theoretical analysis. However, it does not provide specific suggestions or guidance on how to improve the writing, such as identifying areas of confusion or recommending ways to enhance clarity. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. Therefore, the comment is 2, as it highlights a potential problem but lacks the depth and specificity needed to guide the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the domainspecific model is trained on Pix3D and the experiments are conducted on Pix3D, making comparisons to zeroshot singleimage 3D reconstruction models even more unfair. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their methodology. The comment lacks actionable guidance, such as recommending alternative datasets or methods for comparison, or suggesting ways to mitigate the unfairness. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the domainspecific model being trained on Pix3D and the experiments being conducted on Pix3D. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not provide details on why the comparisons to zeroshot singleimage 3D reconstruction models are unfair or how the authors could address this issue. The comment identifies a potential problem but does not offer guidance on how to resolve it, making it specific but not fully grounded. Therefore, this comment aligns with a score of 4.", "verifiability_rationale": "The review point claims that the domainspecific model is trained on Pix3D and the experiments are conducted on Pix3D, making comparisons to zeroshot singleimage 3D reconstruction models even more unfair. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these comparisons are unfair. Without additional context or explanation, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the experimental setup, noting that the domainspecific model is trained on Pix3D and the experiments are conducted on Pix3D, which could lead to unfair comparisons with zeroshot singleimage 3D reconstruction models. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. Without actionable feedback or specific recommendations, the authors are left without a clear understanding of how to resolve the identified problem. Therefore, the comment is 2, as it highlights a concern but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for C2D. While the comment implies that the authors should perform these experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the exact nature of the experiments or how they should be conducted. However, the authors can infer that they need to perform additional experiments to strengthen their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to support the claims made in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in suggesting additional experiments, but it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for C2D. However, the comment does not provide any specific reasoning, examples, or references to justify why these experiments would be beneficial or how they would enhance the paper\"s support for C2D. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the claims made in the paper regarding C2D. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific type of experiment that could strengthen the paper\"s support for the claims. However, the comment lacks detailed guidance on how to conduct these experiments or what specific aspects should be tested. While it provides a direction for enhancing the paper, it does not offer comprehensive or actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, describing them as unintuitive and overly difficult. It questions the complexity of the tasks, suggesting that simpler ones might be more effective. The reviewer also expresses difficulty in solving the tasks and questions the interpretation of the models\" learning. However, the comment does not provide explicit guidance or suggestions for how the authors might address these concerns or simplify the tasks. The action is implicit and vague, as the authors are left to infer that they should simplify the tasks but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"abstract visual reasoning tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with these tasks, such as their unintuitiveness, difficulty, and potential for confusion due to multiple rows and changing factors. The comment further questions the necessity of these tasks and suggests simpler alternatives. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, describing them as unintuitive and overly difficult. The reviewer expresses difficulty in solving the tasks and questions the interpretation of the models\" learning. However, the comment lacks specific examples or references to support the claim that simpler tasks would be more effective. The absence of detailed reasoning or evidence makes it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises significant concerns about the abstract visual reasoning tasks used in the paper, describing them as unintuitive and overly difficult. It highlights the complexity of the tasks, with multiple rows and changing factors, and questions the interpretation of the models\" learning. The reviewer suggests that simpler visual reasoning tasks might be more effective and asks for proof that the current formulation is the best approach. While the comment identifies a critical issue with the tasks, it lacks specific suggestions or guidance on how to address these concerns or simplify the tasks. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of essential visualizations of intermediate processes and comparisons, suggesting that these are necessary for the paper. However, it does not provide specific guidance on what these visualizations should include or how they should be presented. The action is implicit, as the authors can infer that they need to add visualizations, but it is vague because it lacks concrete details on what exactly should be visualized or compared. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of essential visualizations of intermediate processes and comparisons, but it does not specify which part of the paper lacks these visualizations or where they should be included. This makes it difficult for the authors to pinpoint the exact sections that need improvement. Additionally, the comment lacks specificity regarding what kind of visualizations are needed or how they should be presented. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement by pointing out the lack of essential visualizations of intermediate processes and comparisons. This feedback is 3 as it directs the authors to enhance their paper by including visual representations that could aid in understanding the intermediate steps and comparisons. However, the comment lacks specificity regarding what kind of visualizations are needed or how they should be presented, which limits its usefulness. To be more helpful, the comment could provide examples or suggestions on how to effectively visualize these processes and comparisons. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the importance of the result and suggests that it is not surprising given the findings in [15]. It also points out that the iteration complexity is no longer dimensionfree in Theorem 3. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer that they should clarify the importance of their result or address the iteration complexity issue, but without concrete steps or details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment expresses concern about the importance of the result and suggests that it is not surprising given the findings in [15]. It also mentions a change in iteration complexity in Theorem 3. However, the comment does not specify which part of the paper these concerns relate to, such as a specific section, table, or figure. This makes it difficult for the authors to pinpoint the exact areas needing attention. Additionally, while the comment provides some specific details about the iteration complexity, it lacks specificity regarding the importance of the result or how it relates to the findings in [15]. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point expresses concern about the importance of the result, suggesting that it is not surprising given the findings in [15]. It also mentions a change in iteration complexity in Theorem 3. However, the comment lacks specific examples or detailed reasoning to support the claim that the result is not surprising or to explain the impact of the iteration complexity change. This makes the claim 3, as it provides a general context but requires more detailed justification or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment expresses concern about the importance of the result, suggesting that it is not surprising given the findings in [15]. It also points out a change in iteration complexity in Theorem 3, which is no longer dimensionfree. While the comment identifies potential issues with the result, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is 3 as it highlights areas that need clarification or further explanation, but it does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the grid search of the learning rate is done on the validation set. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what steps to take to clarify this aspect of the methodology. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the validation set, but it lacks grounding as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. This is a factual inquiry that does not contain a claim or opinion requiring verification. It is a request for clarification, which is not considered a claim. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises a question about the grid search of the learning rate, specifically asking if it is done on the validation set. While this is a relevant inquiry, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. Without actionable feedback or additional context, the authors are left without a clear understanding of what needs to be done to enhance their work. Therefore, the comment is 2, as it identifies a potential area of concern but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized groups. While it implies that the authors should consider these aspects, it does not explicitly instruct them to include this information or conduct additional analyses. The action is implicit and somewhat vague, as the authors can infer that they should address these concerns but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized groups. This provides clear guidance on what aspects need to be addressed or considered in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized groups. However, it does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they might impact the results. The comment is more of a suggestion for further exploration rather than a claim that requires verification. Therefore, it is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the racial and economic diversity of the sample and the generalizability of the results to other groups, particularly marginalized groups. This is a relevant concern that could impact the validity and applicability of the study. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or conduct further analysis to ensure inclusivity. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider an important aspect of their study but does not fully guide them in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the small number of images in the VioT dataset, questioning its ability to validate the approach. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether additional images should be included, how the dataset could be expanded, or what specific steps the authors should take to improve the dataset\"s validity. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VioT dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the small number of images in each category, which raises concerns about the dataset\"s validity. However, the comment lacks specificity as it does not provide suggestions or guidance on how to address this issue or what steps the authors could take to improve the dataset\"s validity. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point raises a concern about the small number of images in the VioT dataset, questioning its ability to validate the approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why 20 images per category are insufficient. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the VioT dataset, specifically noting that the number of images provided (20 per category) may be insufficient to validate the approach. This is a relevant observation that could impact the robustness and generalizability of the results. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without additional context or recommendations, the authors are left with a general concern but no clear path to improvement. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including its lack of intuitive explanations for mathematical derivations, insufficient figure captions, and the need for additional explanations and legends. The reviewer also mentions that Figures 1 and 2 did not contribute much to their understanding and required multiple readings. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The actions are implicit and somewhat vague, as the authors are left to infer the necessary steps without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the mathematical derivations and figure captions, allowing the authors to accurately identify the areas being addressed. It also specifies the issues, such as the need for more intuitive explanations and additional explanations and legends for figure captions. The comment provides clear guidance on what needs to be improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests that more intuitive explanations are needed for the mathematical derivations. It also criticizes the figure captions for lacking explanations and legends, specifically mentioning the need to explain the colors in Figure 2. The reviewer further states that Figures 1 and 2 did not contribute much to their understanding and required multiple readings. While the comment provides some reasoning by pointing out specific issues with the figures and derivations, it lacks detailed examples or references to support the claim that the paper is hard to follow. The feedback is 3, as it identifies specific areas for improvement but could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically noting that it is hard to follow due to a lack of intuitive explanations for mathematical derivations and insufficient figure captions. It provides specific suggestions for improvement, such as adding explanations and legends to figure captions, particularly regarding the colors in Figure 2. Additionally, the comment highlights that Figures 1 and 2 did not contribute much to the reviewer\"s understanding and required multiple readings. This feedback is clear and actionable, offering the authors specific guidance on how to enhance the clarity and accessibility of their work. However, it could be more helpful if it included suggestions for improving the mathematical explanations or provided examples of how to enhance the figure captions. Overall, the comment is 4 as it directs the authors toward meaningful improvements, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, emphasizing that wrong choices could negate any improvement gained from the method. The reviewer expresses willingness to reconsider their rating if this issue is addressed. While the comment highlights an important area for consideration, it does not provide explicit guidance on how the authors should investigate or address this sensitivity. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the impact of hyperparameter choices on their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the sensitivity of the empirical results to hyperparameter choices, emphasizing the importance of this issue. However, it does not specify which part of the paper discusses the empirical results or hyperparameter choices, making it weakly grounded. The comment is specific in its request for addressing the sensitivity of results to hyperparameter choices, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, emphasizing the potential impact on the method\"s effectiveness. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the concern.", "helpfulness_rationale": "The review comment raises an important concern about the sensitivity of the empirical results to hyperparameter choices, noting that wrong choices could negate any improvement gained from the method. This is a critical point that the authors should address to ensure the robustness and reliability of their findings. However, the comment lacks specific guidance or suggestions on how the authors might investigate or mitigate this sensitivity. While it identifies a potential issue, it does not provide actionable steps for improvement, leaving the authors with a general direction but no detailed roadmap. Therefore, the comment is 3, as it highlights an important area for consideration but lacks depth and specificity in its feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the motivation behind the crossencoder architecture, specifically addressing the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" The reviewer acknowledges that the architecture may not be as finegrained as claimed. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or improve the motivation, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the motivation behind the crossencoder architecture, specifically challenging the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the motivation but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the motivation behind the crossencoder architecture, specifically challenging the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" The reviewer provides a logical reasoning by explaining that the architecture does not ignore crossentity comparison and attends to all candidates simultaneously. However, the comment lacks specific examples or references to support this reasoning, making it 3. The authors would need to further explore the architecture to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the motivation behind the crossencoder architecture, specifically challenging the claim that it \"ignores crossentity comparison\" and \"attends to all candidates at once.\" The reviewer acknowledges that the architecture may not be as finegrained as claimed. However, the comment does not provide specific suggestions or guidance on how the authors might improve the motivation or clarify the architecture\"s functionality. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point criticizes the use of an \"antiquated\" GNN model and method, stating that it negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not provide any explicit or implicit suggestions for improvement or action. It lacks specific guidance on what the authors should do to address these issues, such as recommending the use of more modern models or methods or suggesting alternative approaches. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment criticizes the use of an \"antiquated\" GNN model and method, which it claims negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not specify which part of the paper discusses these models or methods, making it difficult for the authors to identify the exact sections that need attention. Additionally, while it highlights the issue of antiquated models, it does not provide specific suggestions or examples of modern alternatives that could be considered. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the use of an \"antiquated\" GNN model and method negatively impacts the performance of the framework. However, it does not provide specific examples or references to support this claim, such as comparing the performance with more modern models or methods. The lack of detailed evidence or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the use of an \"antiquated\" GNN model and method, which it claims negatively impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these issues. Without detailed feedback or recommendations, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, the comment is 2, as it highlights a problem but does not offer meaningful direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies several issues with the experiment that estimates the quality of uncertainty estimates. It highlights the use of pseudo feature importance due to the lack of true feature importance, which relies on Proposition 3.2 and a large enough perturbation value. The comment suggests that this makes it difficult to judge the trustworthiness of the experiment, as the difference between the tested method and the pseudo feature importance is only the number of perturbations. The reviewer provides two specific suggestions for strengthening the experiment: first, by using a different method to estimate feature importance, and second, by providing a more detailed analysis of the perturbation value. These suggestions are explicit and provide concrete guidance on how to improve the experiment, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment that estimates the quality of uncertainty estimates, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the experiment, namely the use of pseudo feature importance due to the lack of true feature importance, and the reliance on Proposition 3.2 and a large enough perturbation value. The comment further suggests ways to strengthen the experiment, such as using a different method to estimate feature importance and providing a more detailed analysis of the perturbation value. This level of detail and specificity provides clear guidance for the authors on how to improve their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment using pseudo feature importance is difficult to trust because it relies on Proposition 3.2 and a large enough perturbation value. The reviewer suggests that the experiment could be strengthened by using a different method to estimate feature importance and providing a more detailed analysis of the perturbation value. While the comment identifies potential issues with the experiment, it lacks specific examples or references to support the claim about the reliance on Proposition 3.2 and the perturbation value. This makes the claim 3, as the authors would need to further investigate and substantiate the concerns raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experiment that estimates the quality of uncertainty estimates, specifically the use of pseudo feature importance due to the lack of true feature importance. It highlights the reliance on Proposition 3.2 and a large enough perturbation value, which makes it difficult to judge the trustworthiness of the experiment. The reviewer provides two specific suggestions for improvement: using a different method to estimate feature importance and providing a more detailed analysis of the perturbation value. These suggestions are clear and actionable, offering the authors concrete steps to enhance the robustness and credibility of their experiment. The feedback is comprehensive and constructive, making it 5 for the authors to improve their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of proper mention of the experimental settings and the importance of result reproducibility, noting that the author has not provided the code. While the comment implies that the authors should include more detailed information about the experimental settings and provide the code, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer what needs to be done but may not be entirely sure of the specific details required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental settings\" and \"result reproducibility,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of missing information about the experimental settings and the lack of code provided, which are critical for result reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings are not mentioned properly, which affects result reproducibility. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of the lack of code further highlights the issue but does not fully substantiate the claim. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it provides some support but lacks detailed justification.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental settings, noting that they are not mentioned properly and that result reproducibility is compromised due to the lack of code provided. This feedback is clear and actionable, as it highlights a specific area that needs improvement and suggests that the authors should provide more detailed information about the experimental settings and include the code. By addressing these points, the authors can enhance the transparency and replicability of their work, which is crucial for the credibility of their findings. However, the comment could be more helpful if it provided specific suggestions on how to improve the experimental settings or code documentation. Overall, the comment is 4, as it directs the authors toward a significant improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that it might be autogenerated. It asks whether the authors intend to use human turkers or generate different types of feedback to make it more realistic. While the comment implies that the authors should consider these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the lack of lexical and syntactic diversity in the teacher feedback, implying that it might be autogenerated. However, it does not explicitly mention which part of the paper this feedback is discussed in, making it weakly grounded. The comment is specific in detailing the issue of diversity and suggesting ways to address it, such as using human turkers or generating different types of feedback. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that it might be autogenerated. The reviewer asks whether the authors intend to use human turkers or generate different types of feedback to make it more realistic. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the feedback is autogenerated or how it could be improved. The suggestion for human turkers or diverse feedback is logical but not fully substantiated, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the teacher feedback, noting a lack of lexical and syntactic diversity. It raises a concern about the feedback being autogenerated and suggests that the authors might consider using human turkers or generating different types of feedback to make it more realistic. This feedback is clear and actionable, as it provides a specific area for improvement and offers a potential solution. However, it could be more helpful if it included additional guidance on how to implement these suggestions or examples of diverse feedback types. Overall, the comment is 4, as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the main text should make it more clear that there are additional experiments in the supplement and that their results should be summarized. While the comment implies that the authors should include a summary of the supplementary experiments in the main text, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a summary and where it should be placed. However, the comment does provide a clear direction on what needs to be addressed, making it 3.", "grounding_specificity_rationale": "The comment suggests that the main text should make it more clear that there are additional experiments in the supplement and that their results should be summarized. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where these experiments are mentioned. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, while the comment provides some guidance on what needs to be addressed, it does not specify how the results should be summarized or what specific aspects of the experiments should be highlighted. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the main text should make it more clear that there are additional experiments in the supplement and that their results should be summarized. However, the comment does not provide any specific reasoning or examples to support why this clarification is necessary or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the main text should make it more clear that there are additional experiments in the supplement and that their results should be summarized. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the clarity and comprehensiveness of the paper. By addressing this point, the authors can ensure that readers are aware of the additional experiments and their results, which can help improve the overall understanding and impact of the paper. However, the comment could be more helpful if it provided specific guidance on how to summarize the results or what aspects to highlight. Overall, the comment is 4 as it directs the authors toward a meaningful improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends comparing the performance of the proposed method with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" This provides a clear and direct action for the authors to take, as it specifies which works to compare their method with. The suggestion is concrete, as it outlines a specific task and references two relevant studies. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the recommendation to compare the performance with specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" This allows the authors to accurately identify the part of the paper being addressed, which is the performance evaluation section. The comment is also specific because it clearly specifies what needs to be addressed, namely, the comparison with these two works. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests comparing the performance of the proposed method with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" This recommendation is based on the premise that these works are relevant and could provide a useful comparison. However, the comment does not provide detailed reasoning or evidence to support why these particular works should be included in the comparison. While the suggestion is logical, it lacks specific justification or references to the works, making it 3. The authors would need to independently investigate the relevance of these works to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by recommending a comparison of the proposed method with two existing works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer.\" This recommendation is clear and could help the authors enhance the comprehensiveness and relevance of their performance evaluation. By including these comparisons, the authors can better position their work within the existing literature and demonstrate its advantages or limitations. However, the comment could be more helpful if it provided additional context or rationale for why these specific comparisons are important or how they might impact the paper\"s contribution. Overall, the feedback is 4 as it offers a concrete step for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. While the comment implies that the authors should explore this possibility, it does not provide explicit instructions or concrete steps on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should consider expanding their approach and determine how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for an extension to more general settings, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this extension would be beneficial or how it could be achieved. Without additional context or examples, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the approach to more general settings, suggesting that the authors consider extending their approach to broader scenarios. While it identifies a potential limitation and provides a direction for improvement, it lacks specific guidance or suggestions on how to achieve this extension. The comment is 3 as it prompts the authors to think about the generalizability of their approach, but it does not offer detailed advice or actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the dimensionality of each region and asks which feature extractor is used. While it identifies a specific line in the paper where this issue is discussed, it does not provide any explicit or implicit guidance on how the authors should address this question or what action they should take. The comment lacks actionable advice, such as suggesting ways to clarify or provide additional information about the feature extractor. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of a feature extractor and the dimensionality of each region, providing clear guidance on what needs to be clarified or addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the dimensionality of each region and the feature extractor used. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the dimensionality of each region and the feature extractor used, which is relevant to the understanding of the methodology. However, it does not provide any suggestions or guidance on how the authors might address this question or improve their explanation in the paper. While it identifies a potential area of confusion, it lacks actionable feedback or constructive advice, leaving the authors without a clear path for improvement. Therefore, the comment is 2, as it points out a gap in the paper but does not offer actionable steps for the authors to take."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which parts of the paper these details should be included in or how they should be presented. The action is implicit and somewhat vague, as the authors are left to infer that they need to add these details but without concrete guidance on where or how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in suggesting what kind of details should be added, but without clear grounding, the authors may struggle to determine where these details should be incorporated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not offer any specific reasoning, examples, or references to support why these details are necessary or how they would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. While it identifies a potential area for improvement, it lacks specificity and does not offer guidance on which details should be included or how they should be presented. The feedback is 3 as it points out a general area for enhancement, but it does not provide actionable steps or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two areas for improvement: the lack of analysis on the effectiveness of each data augmentation method and the need to compare the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. It also suggests referencing specific works, such as [1] and [2], to support the analysis. While the comment implies that the authors should conduct additional analysis and comparisons, it does not provide explicit instructions on how to implement these actions. The authors can infer the need for more detailed analysis and comparisons, but the comment lacks concrete guidance on how to execute these steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of analysis on the effectiveness of each data augmentation method, allowing the authors to identify the specific part of the paper being addressed. It also specifies the need for a comparison with other paraphrasing methods, such as EDA or LLMbased paraphrasing, to clarify the unique advantages of their method. The comment provides specific suggestions for improvement, including references to relevant works, which enhances its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, to clarify the unique advantages of the method. The comment supports this claim by referencing specific works, including [1] and [2], which provide examples of relevant literature and methods. This provides a solid basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of the paper, specifically the lack of analysis on the effectiveness of each data augmentation method. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would clarify the unique advantages of the method. The comment also references specific works, such as [1] and [2], which provide examples of relevant literature and methods. This feedback is clear and actionable, as it directs the authors to enhance their analysis and comparison with existing methods, which could significantly improve the comprehensiveness and impact of their work. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting an ablation study to evaluate the net effect of each component in the proposed model. It provides specific examples of experiments that could be conducted, such as learning the model with a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is explicit and provides concrete guidance on how to improve the draft by conducting additional experiments. The authors know exactly what actions to take to address the feedback, making the comment 5.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study to evaluate the net effect of each component in the proposed model, specifically mentioning \"learning with MMD\" and \"typical knowledge distillation loss\" as examples. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting the need for an ablation study and provides examples of experiments to consider, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study to evaluate the net effect of each component in the proposed model. It provides specific examples of experiments that could be conducted, such as learning the model with a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment does not provide any supporting evidence or reasoning to justify why an ablation study is necessary or how it would improve the paper. The suggestion is logical but lacks detailed justification or examples, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment suggests conducting an ablation study to evaluate the net effect of each component in the proposed model. It provides specific examples of experiments that could be conducted, such as learning the model with a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is clear and actionable, offering the authors a concrete way to improve their draft by providing a more comprehensive evaluation of their model. However, the comment could be more helpful if it explained why an ablation study is necessary or how it would enhance the understanding of the model\"s components. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it implies that the authors should consider this scenario, it does not provide explicit guidance on how to address it or what specific aspects of the model\"s performance should be evaluated. The action is implicit and somewhat vague, as the authors can infer that they should explore this scenario but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, experiment, or analysis. Without explicit references or context, the authors cannot confidently determine where this question should be addressed in the paper. Additionally, the comment lacks specificity regarding what aspects of performance should be evaluated or how this scenario relates to the overall study. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the performance of a specific model scenario. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an interesting scenario that the authors might not have considered, it lacks depth and does not provide any guidance or suggestions on how to address this issue or its implications. The comment does not offer actionable feedback or insights that would help the authors improve their draft. Therefore, it is 2, as it prompts the authors to consider a specific scenario but does not provide meaningful direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies the lack of quantitative analysis on computational gains and suggests that specific measurements or comparisons should be included to substantiate the claims. It provides clear guidance by specifying what kind of quantitative analysis would be beneficial, such as GPU hours, memory usage, or training time. This feedback is direct and concrete, giving the authors a clear understanding of what needs to be added to their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely specific measurements or comparisons to substantiate the claimed computational benefits. The comment provides a clear direction for improvement by suggesting the inclusion of quantitative analysis, such as GPU hours, memory usage, or training time. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks specific measurements or comparisons to substantiate the computational gains from replacing the MAE model with a CNNbased data augmentation strategy. The reviewer suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. This claim is 4 as it provides a clear suggestion for what kind of evidence would strengthen the paper\"s claims. However, it lacks specific examples or references to existing literature or benchmarks that could further substantiate the need for such quantitative analysis. Therefore, the comment is categorized as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of quantitative analysis on computational gains. It highlights the importance of specific measurements or comparisons to substantiate the claims made about the efficiency improvements in DQ V2. By suggesting the inclusion of quantitative analysis, such as GPU hours, memory usage, or training time, the comment provides clear and actionable feedback that can help the authors strengthen their claims and improve the rigor of their work. However, the comment could be more helpful if it offered specific examples or methods for conducting such analyses. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the time taken by COLMAP and scenebyscene finetuning should be considered when comparing the method, as it renders the method less efficient for certain scenes. However, the comment does not provide explicit guidance on how the authors should account for this time or how it affects the efficiency comparison. The action is implicit and lacks concrete details on how to address the issue, making it 3.", "grounding_specificity_rationale": "The comment suggests that the time taken by COLMAP and scenebyscene finetuning should be considered when comparing the method, which implies that the efficiency of the method is being discussed. However, the comment does not specify which part of the paper this comparison is made in, nor does it provide details on what specific aspects of efficiency are being addressed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in terms of efficiency. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the time taken by COLMAP and scenebyscene finetuning should be considered when comparing the method, implying that this factor affects the efficiency of the method. However, the comment does not provide any specific data, examples, or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed evidence or reasoning, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the efficiency of the method being evaluated, specifically mentioning the time taken by COLMAP and scenebyscene finetuning. This is a relevant observation that could impact the overall efficiency comparison of the method. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or improve the efficiency comparison. Without detailed suggestions or examples, the feedback is 3 as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and concerns about the \"filter manifold network\" (FMN), which forms the main part of the technique. It asks whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can reasonably scale when the number of filter parameters is large. These questions imply that the authors should provide more discussion and analysis on the FMN, potentially including experiments with different architectures and scaling tests. While the comment does not explicitly instruct the authors to conduct these experiments or analyses, it provides a clear direction for improvement by highlighting areas that need further exploration. The action is implicit but concrete, making this comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by questioning the lack of discussion or analysis on FMN, asking about experiments with other architectures, and inquiring about the scaling of adaptive convolutions with filter parameters. Additionally, it raises a concern about the scalability of FMN with larger numbers of input and output channels. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises several questions and concerns about the \"filter manifold network\" (FMN), which forms the main part of the technique. It questions the lack of discussion or analysis on FMN, asks about experiments with other architectures, and inquires about the scaling of adaptive convolutions with filter parameters. The comment also points out that the number of input and output channels is small in the experiments and wonders if FMN can scale reasonably well with larger numbers of filter parameters. While the comment raises valid points, it lacks specific examples, references, or detailed reasoning to fully substantiate the claims. The authors would need to provide additional information or experiments to address these concerns. Therefore, the comment is 3, as it provides a basis for further exploration but requires more detailed evidence or examples to be 5.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion and analysis of the \"filter manifold network\" (FMN), which forms the main part of the technique. It raises several important questions, such as whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can reasonably scale when the number of filter parameters is large. These questions highlight areas where the paper lacks depth and suggest that the authors should provide more detailed analysis and experimentation to support their claims. The comment is 4 as it offers clear and actionable feedback, prompting the authors to address critical aspects of their work. However, it could be more helpful if it provided specific suggestions on how to conduct these experiments or analyses. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should provide a comparison of the proposed model\"s performance with and without each of the two factors mentioned: noise and keeping an exponential moving average. It also implies that the authors should investigate the contribution of the noisefree exponential moving average to the model\"s performance. While the comment explicitly states the need for a comparison, it does not provide specific guidance on how to conduct this analysis or what metrics to use. The action is explicit but somewhat vague, as the authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed model, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should provide a comparison of the model\"s performance with and without each of the two factors mentioned: noise and keeping an exponential moving average. Additionally, it provides a specific suggestion to investigate the contribution of the noisefree exponential moving average. This level of detail and explicit reference to the model\"s components make the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed model benefits from two factors: noise and keeping an exponential moving average. It proposes a comparison to determine the contribution of each factor individually. The claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim fully. The authors would need to conduct the suggested analysis to fully understand the impact of each factor, which is not explicitly detailed in the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It identifies a potential area of interest by suggesting that the authors should investigate the contribution of each factor\u2014noise and keeping an exponential moving average\u2014to the performance of the proposed model. This feedback is clear and offers a concrete direction for the authors to enhance their analysis and presentation of results. By addressing this point, the authors can provide a more comprehensive understanding of the model\"s performance and its components. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the timing of the results reporting, suggesting that the results are only presented after a significant amount of training has occurred. It speculates that early in training, the model parameters might be \"garbage,\" potentially hindering the performance of the planning component. The reviewer wonders if the CNN could perform reasonably well with less data. While the comment implies that the authors should consider reporting results at different stages of training and potentially explore the performance of the CNN with less data, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the timing of the results reporting, suggesting that the results are only presented after a significant amount of training has occurred. It speculates that early in training, the model parameters might be \"garbage,\" potentially hindering the performance of the planning component. The reviewer wonders if the CNN could perform reasonably well with less data. However, the comment does not explicitly mention which part of the paper this issue pertains to, such as specific sections or figures where results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the timing of results reporting and the potential impact of early training on model performance. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the timing of the results reporting, suggesting that the results are only presented after a significant amount of training has occurred. The reviewer speculates that early in training, the model parameters might be \"garbage,\" potentially hindering the performance of the planning component. This claim is based on logical reasoning and common sense, as it is reasonable to assume that early training might not yield optimal results. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the timing of their results reporting and potentially explore the performance of the CNN with less data to address this concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the timing of the results reporting, suggesting that the results are only presented after a significant amount of training has occurred. It speculates that early in training, the model parameters might be \"garbage,\" potentially hindering the performance of the planning component. The reviewer wonders if the CNN could perform reasonably well with less data. While the comment identifies a potential issue with the timing of results reporting and suggests exploring the performance of the CNN with less data, it lacks specific guidance or actionable steps for the authors to follow. The feedback is 3 as it prompts the authors to consider alternative approaches or data usage, but it could be more beneficial with additional detail or suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the authors handle concepts (multiple entity mentions referring to the same entity) in the context of DocRED, where documents are considered as an entire sentence. The comment explicitly asks for clarification on this aspect, which is a direct request for information. However, it does not provide specific guidance on how the authors should address this issue or what changes they should make to their manuscript. While the action is explicit, it lacks concrete details on how to implement the requested clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about how the authors handle concepts (multiple entity mentions referring to the same entity) in the context of DocRED, where documents are considered as an entire sentence. However, it does not specify which part of the manuscript this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the handling of concepts, but it lacks grounding as it does not explicitly mention a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the methodology used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises a specific question about how the authors handle concepts (multiple entity mentions referring to the same entity) in the context of DocRED, where documents are considered as an entire sentence. This is a relevant inquiry that could help the authors clarify their methodology and potentially improve the clarity of their manuscript. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific changes could be made to enhance their work. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses skepticism about the contribution of the paper, suggesting that the methods used in different stages are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve their contribution. Without actionable suggestions or a clear direction for revision, the authors are left without a path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses skepticism about the contribution of the paper, suggesting that the methods used in different stages are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the contribution are considered marginal. Without explicit references to sections, figures, or specific contributions, the authors cannot confidently determine which parts of the paper are being addressed. This lack of grounding and specificity makes it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution is marginal because the methods used in different stages are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specific examples or references to support this claim, such as comparing the contribution to similar work or discussing the novelty of the methods. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses skepticism about the contribution of the paper, suggesting that the methods used in different stages are welldesigned and demonstrated, and that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specificity and actionable feedback, as it does not provide detailed guidance on how the authors might enhance their contribution or address the reviewer\"s concerns. Without clear suggestions for improvement or areas to focus on, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should focus on improving the clarity or accessibility of the Appendix or whether they should prioritize other aspects of the paper. Without actionable suggestions or feedback, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This provides some specificity regarding the parts of the paper that were not fully reviewed, but it does not specify what needs to be addressed or improved in these sections. The comment is weakly grounded as it does not explicitly mention which part of the paper the additional experiments are located, leaving the authors to infer the relevant sections. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges the comprehensive Appendix and appreciates the additional detail it provides. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This is a factual statement describing the reviewer\"s experience and does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment acknowledges the comprehensive Appendix, which is appreciated for providing additional detail about parts of the paper. However, it also mentions that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This feedback is 3 as it highlights a potential area for improvement, suggesting that the authors might want to prioritize the clarity and accessibility of the Appendix. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending ways to streamline the Appendix or improve its organization. Therefore, while it provides some insight, it does not offer actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is explicit and provides a clear direction for the authors to expand their experiments to include more complex and higherdimensional tasks. The suggestion is concrete, as it specifies the types of tasks that could be used to demonstrate scalability. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the types of tasks that could be used to demonstrate scalability, providing a clear direction for improvement. Therefore, the comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point suggests that continuous control experiments are typically performed on simple and lowdimensional tasks, such as cartpole or mountain car, and recommends demonstrating the scalability of LFF by showing its effectiveness on more challenging tasks with higher input dimensionality, like locomotion of ants or humanoids. This claim is 3 as it provides a logical reasoning for the suggestion, noting the common practice of using simple tasks for experimentation. However, the comment lacks specific examples or references to support the claim that these more complex tasks are necessary for demonstrating scalability. Providing such examples or references would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experiments to include more complex and higherdimensional tasks. By addressing this suggestion, the authors can strengthen their claims about the scalability and applicability of their method. However, the comment could be more helpful if it offered additional guidance on how to approach these more complex tasks or provided examples of similar experiments. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, but it was proposed in 2019 and is considered \"out of fashion.\" However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or whether they should consider other baselines or update their analysis. Without actionable suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper \"MISA: ModalityInvariant and Specific Representations for Multimodal Sentiment Analysis, ACM MM 2020,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, but MULT was proposed in 2019 and is considered \"out of fashion.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, but MULT was proposed in 2019 and is considered \"out of fashion.\" However, the comment does not provide any supporting evidence or references to substantiate the claim that MULT is outdated or that other baselines should be considered. The lack of specific examples or references makes it difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the paper considers MULT as the only deep learningbased baseline that considers crosssensory interaction, but MULT was proposed in 2019 and is considered \"out of fashion.\" This feedback highlights a potential limitation in the paper\"s analysis, suggesting that the authors may need to consider more recent or relevant baselines. However, the comment lacks specific guidance on which baselines to consider or how to incorporate them into the analysis. While it identifies a weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that certain terms, such as W1, W2, W, and V, are not defined in the paper. It suggests that these terms might refer to the Encoder and Decoder networks, but this inference is not explicitly stated. The comment provides a clear indication of what needs to be addressed, which is the definition of these terms. However, it lacks specific guidance on how to define them or where to include the definitions in the paper. While the action is implicit, it is concrete once the authors understand the issue. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper where terms are not defined, such as \"p.3, A4, eq.3.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely the definitions of W1, W2, W, and V. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the absence of definitions for certain terms (W1, W2, W, and V) in the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a significant issue by pointing out that certain terms, such as W1, W2, W, and V, are not defined in the paper. This is a critical oversight that can lead to confusion for readers. The comment provides specific examples of where these terms are used, allowing the authors to easily locate and address the issue. By highlighting the need for definitions, the comment offers clear and actionable feedback that can help the authors improve the clarity and comprehensibility of their draft. However, the comment could be more helpful if it suggested where these definitions should be included or provided examples of how they might be defined. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the process of generating negative chips from a lightweight RPN and whether they are fixed or updated during training. It also asks if alternating between generating negative chips and training the network would improve performance. While the comment highlights an area of uncertainty, it does not provide explicit instructions or suggestions for the authors to address this issue. The authors can infer that they need to clarify the process and potentially conduct experiments to test the impact of alternating between these steps, but the comment lacks concrete guidance on how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the process of generating negative chips from a lightweight RPN, specifically asking if they are fixed or updated during training. It also inquires about the potential impact of alternating between generating negative chips and training the network on performance. However, the comment does not specify which part of the paper this process is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but the lack of explicit reference makes it challenging to pinpoint the exact section. The comment is specific in its inquiry about the process and its potential impact, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification about the process of generating negative chips from a lightweight RPN and whether they are fixed or updated during training. It also asks if alternating between these steps would improve performance. This is a request for clarification and does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the process of generating negative chips from a lightweight RPN, specifically asking whether they are fixed or updated during training. It also inquires about the potential impact of alternating between these steps on performance. This feedback is 3 as it prompts the authors to clarify a critical aspect of their methodology and potentially explore a new approach to improve performance. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending a particular approach or experiment to test the impact. While it identifies a potential area for improvement, it does not provide detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients. While the comment implies that the authors should conduct additional experiments, it does not provide explicit instructions on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments and determine how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in suggesting a particular evaluation scenario, but without grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this evaluation is necessary or how it would impact the study. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the applicability of the proposed approach to patients who are firsttime visitors without historical reports. It suggests that the authors should evaluate the approach on both new and old patients to ensure its effectiveness in different scenarios. This feedback is 3 as it identifies a potential limitation in the study and provides a clear direction for further evaluation. However, the comment could be more helpful if it offered specific suggestions on how to conduct this evaluation or what metrics to consider. Overall, the comment provides a useful insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper lacks an indepth analysis of why inverse scaling occurs over compute. It explicitly states that providing such an analysis would strengthen the paper. However, it does not specify what aspects of the analysis should be included or how the authors should approach it. The action is explicit but vague, as it lacks concrete guidance on how to conduct the analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an indepth analysis of why inverse scaling occurs over compute. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for an analysis explaining the training dynamics, which would enhance the paper\"s solidity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks an indepth analysis of why inverse scaling occurs over compute. It suggests that providing such an analysis would strengthen the paper. However, the comment does not provide any specific reasoning, examples, or references to support why this analysis is necessary or how it would enhance the paper. The lack of detailed justification or evidence makes the claim difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient support.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of an indepth analysis to explain why inverse scaling occurs over compute. It suggests that providing such an analysis would strengthen the paper\"s solidity. While the comment highlights an important area for improvement, it does not offer specific guidance or suggestions on how the authors might conduct this analysis or what aspects to focus on. The feedback is 3 as it points out a critical area for enhancement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point consists of two questions: the first asks for additional insights into modest performance gains on Clothing1M, and the second inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. These questions are explicit and seek specific information from the authors. However, they do not provide any guidance or suggestions on how the authors should address these questions or improve their draft. The lack of actionable advice makes it difficult for the authors to know what steps to take in response to the questions. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment consists of two questions, each of which seeks additional information or clarification. The first question asks for insights into modest performance gains on Clothing1M, while the second inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. However, the comment does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. Additionally, while the questions are specific in nature, they lack detailed guidance on how to address them. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point consists of two questions seeking additional insights and performance evaluations. It does not contain any claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment consists of two questions seeking additional insights and performance evaluations. While it prompts the authors to provide more information, it does not offer any specific suggestions or guidance on how to improve the draft or address the issues raised. The questions are relevant and could lead to valuable additions to the paper, but without actionable feedback or constructive advice, the comment is not particularly helpful. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the paper should describe the hyperparameters used by each defense and how they are derived. It also suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and showing the amount of clean data needed to remove the attack. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be added to their draft. The comment is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of description regarding hyperparameters used by each defense and how they are derived. This allows the authors to accurately identify the part of the paper that needs attention. The comment is also specific because it clearly specifies what is missing, namely the description of hyperparameters and their derivation, as well as the suggestion to optimize hyperparameters against the attack and show the amount of clean data required. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks information on hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and showing the amount of clean data needed to remove the attack. While the comment provides a logical reasoning for why this information is important, it does not include specific examples or references to support the claim. The lack of detailed evidence or examples makes the claim 3, as the authors would need to infer the importance of this information based on the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the description of hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation would involve optimizing hyperparameters against the attack and showing the amount of clean data needed to remove the attack. This feedback is clear and actionable, providing the authors with specific guidance on what information is missing and how to improve their analysis. By addressing these points, the authors can enhance the comprehensiveness and rigor of their defense evaluation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the theoretical results\" lack of immediate practical implications, noting that this is understandable given the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide explicit guidance on how to incorporate these takeaway points or whether this observation is indeed novel. The action is implicit and somewhat vague, as the authors are left to infer that they should include more practical implications and clarify the novelty of their findings. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and their practical implications, acknowledging the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not specify which part of the paper discusses these theoretical results or where the authors should include more practical implications. While the authors might infer that it relates to the theoretical sections, the comment lacks full grounding as it does not explicitly mention specific sections or figures. The suggestion is specific in terms of what the authors should consider, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the theoretical nature of the results and their lack of immediate practical implications, noting that this is understandable given the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide specific examples or references to support the claim that this observation is novel or lacks practical implications. The reasoning is somewhat logical but lacks detailed evidence or references, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the theoretical nature of the results and their lack of immediate practical implications, which is understandable given the novelty of the work. It suggests that the paper should include more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size. However, the comment does not provide specific guidance on how to incorporate these takeaway points or how to make them more practical. While it identifies a potential area for improvement, the feedback lacks depth and actionable suggestions, making it 3. The authors gain some insight into the need for more practical implications but are left without detailed guidance on how to achieve this. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the necessity of introducing separators in section 4 and asks for clarification on what additional information they convey beyond T/I/O. While the comment implies that the authors should provide a justification for the introduction of separators, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question of why separators are needed and what additional information they provide. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for introducing separators and asks for clarification on what additional information they convey beyond T/I/O. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of introducing separators in section 4 and asks for clarification on what additional information they convey beyond T/I/O. However, the comment does not provide any reasoning, examples, or references to support why the introduction of separators is questionable. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the rationale behind the introduction of separators in section 4, asking for clarification on what additional information they convey beyond T/I/O. This feedback is 3 as it prompts the authors to reconsider the necessity and purpose of the separators, encouraging them to provide a clearer explanation or justification. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing alternative explanations or examples. While it identifies a potential area for improvement, it does not provide detailed actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of mean pooling for tokens and suggests considering other pooling strategies. While it implies that the authors should explore alternative pooling methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to explore or evaluate other pooling strategies. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of mean pooling for tokens and suggests considering other pooling strategies. The comment provides a clear direction for the authors to explore alternative approaches, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the choice of mean pooling for tokens and suggests considering other pooling strategies. However, it does not provide any specific reasoning, examples, or references to support why mean pooling might not be the best choice or how other pooling strategies could be beneficial. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of mean pooling for tokens, suggesting that other pooling strategies could be considered. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or examples of alternative pooling strategies that could be explored. The comment is 3 as it prompts the authors to consider other options, but it does not offer detailed suggestions or actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training details of the VQGAN, specifically whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. While the comment implies that the authors should provide these details, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information. However, the comment does provide a clear direction on what details are missing, which makes it 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the training details of the VQGAN, specifically whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. However, it does not specify which part of the paper this question pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. While the comment is specific in its inquiry, it is 1 because it does not indicate where in the paper this information should be included. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the training details of the VQGAN, specifically whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This is a factual inquiry that does not contain a claim or opinion requiring verification. It is a request for clarification, which is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, asking whether it is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This is a relevant inquiry that could help clarify the methodology and provide important context for the reader. However, the comment does not offer any suggestions or guidance on how the authors might address this question or improve their draft. While it identifies a potential area of concern, it lacks actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include works such as Li et al. (2017) and He et al. (2015) in their discussion, as these works are relevant to the taskoriented recommendation perspective. It also recommends discussing how the current work differs from other chatbox research works. While the comment implies that the authors should include these references and discussions, it does not provide explicit instructions on how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the perspective of taskoriented recommendation, allowing the authors to identify the relevant part of the paper. It also specifies what needs to be addressed, which is the inclusion of relevant works such as Li et al. (2017) and He et al. (2015), as well as a discussion on how the current work differs from other chatbox research works. This provides clear guidance on what the authors need to do to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that works such as Li et al. (2017) and He et al. (2015) are important to include and compare to, as they relate to the taskoriented recommendation perspective. The comment provides specific references to external works, which is a clear and direct way to support the claim. This makes the claim 4, as it provides a solid basis for the authors to consider these references in their work. However, the comment could be strengthened by providing more detailed reasoning or examples of how these works relate to the current study, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the inclusion of relevant works, such as Li et al. (2017) and He et al. (2015), which are important for the taskoriented recommendation perspective. It also recommends discussing how the current work differs from other chatbox research works, which would help the authors contextualize their contribution. This feedback is clear and provides a concrete direction for the authors to enhance their draft by incorporating relevant literature and comparisons. However, the comment could be more helpful if it offered specific suggestions on how to integrate these references or discuss the differences. Overall, the comment is 4 as it guides the authors toward improving their draft by providing relevant references and a clear direction for comparison."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed methods, DualIS and DualDIS, noting that they do not perform well on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3). However, the comment does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this issue. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DualIS and DualDIS\" and \"MSVD (Table 3),\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed methods, namely that they do not perform well on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3). Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some crossmodel retrieval tasks, citing the performance in MSVD (Table 3) as evidence. However, the comment does not provide detailed reasoning or specific examples to support this claim, such as comparing the performance with other methods or discussing the limitations of the proposed methods in this context. The lack of detailed justification or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some evidence but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out a specific issue with the proposed methods, DualIS and DualDIS, noting that they do not perform well on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3). This feedback is 3 as it identifies a potential weakness in the paper, allowing the authors to consider whether these methods are suitable for the intended applications. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the performance of their methods. To be more helpful, the comment could include recommendations for further analysis, alternative approaches, or ways to enhance the generality of the methods. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the experimental strengths of the proposed approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. While the comment implies that the authors should consider this alternative method, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested alternative. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental strengths of the proposed approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. However, the comment does not explicitly mention which part of the paper discusses the experimental setup or results, making it weakly grounded. The authors can infer that it relates to the experimental methodology or results section, but this inference is not direct. The comment is specific in detailing the issue with the experimental approach and suggesting an alternative, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point questions the experimental strengths of the proposed approach by suggesting an alternative method that could potentially reach the global minimum. The reviewer provides a logical reasoning by comparing the proposed descent procedure for 40 different networks to running vanilla Adam on the final network with 40 random initial points. This comparison highlights a potential inefficiency in the proposed method. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to consider the logic and implications of the suggestion to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the proposed approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could potentially reach the global minimum. This feedback is 3 as it provides a different perspective on the experimental methodology and suggests a potential improvement. However, the comment lacks specific guidance on how to implement the suggested alternative or how to address the issue raised, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the performance of FedSP is not the best in Table 1 and Table 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to improve the performance of FedSP or explaining why this is relevant to the theme of the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1 and Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out that the performance of FedSP is not the best on some datasets, providing a clear indication of what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of FedSP is not the best in Table 1 and Table 2 on some datasets. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific data or comparisons to other methods, the claim remains vague and difficult for the authors to verify or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the performance of FedSP, as it is not the best performer on some datasets, as shown in Tables 1 and 2. However, the comment lacks specificity and does not provide any actionable advice or suggestions for improvement. It does not offer guidance on how the authors might address this issue or why it is relevant to the theme of the paper. Without actionable feedback or detailed insights, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any explicit or implicit guidance on how the authors should explore this dataset further. There is no indication of what specific aspects of the dataset should be discussed, analyzed, or compared. Without concrete suggestions or examples, the authors are left without a clear understanding of how to address this feedback. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper this exploration should have been included in, such as a specific section or analysis. This lack of explicit reference to a particular part of the paper makes it weakly grounded. The comment is specific in suggesting that the dataset could have been explored more, but without grounding, the authors cannot confidently determine where this exploration should have been included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, the comment lacks any supporting evidence, reasoning, or examples to justify why this exploration is necessary or how it could enhance the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it lacks specificity and does not provide any guidance on how the authors might explore this dataset further or what aspects of it could be discussed. Without actionable suggestions or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that, like most work on pruning, it is not yet possible to realize efficiency gains on GPU. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or improve their work to achieve efficiency gains on GPU. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"most work on pruning\" without specifying which part of the paper it addresses, making it difficult for the authors to identify the exact section being referred to. Additionally, it does not provide specific details or examples of what needs to be addressed regarding the realization of efficiency gains on GPU. This lack of grounding and specificity makes it challenging for the authors to understand the basis of the comment and how to address it. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"it is not yet possible to realize efficiency gains on GPU,\" which is a subjective opinion based on the current state of work on pruning. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential limitation in the work, noting that, like most work on pruning, it may not yet be possible to realize efficiency gains on GPU. However, the comment lacks specificity and does not provide any actionable advice or suggestions for the authors to address this issue. Without guidance on how to improve the work or what steps to take to achieve efficiency gains on GPU, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the impact of the method on insurance costs for men and women. However, it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this question or what specific information should be included in the paper to answer it. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the impact of the method on insurance costs for men and women. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the method or results should be considered in relation to insurance costs. Without clear grounding or specificity, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on a specific aspect of the paper, specifically the impact of the method on insurance costs for men and women. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the impact of the method on insurance costs for men and women. While it identifies a potential area of interest, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or incorporate it into their paper. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is 2, as it points out a potential area of interest but does not provide enough detail or direction for the authors to effectively address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the difference between the meta solvers and the centralized RL where agents share weights. It provides a specific example from Foester et al. (2016) to guide the authors in making this distinction. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"meta solvers\" and \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by asking for clarification on the difference between meta solvers and centralized RL, where agents share weights. The comment provides a specific example from Foester et al. (2016) to guide the authors in making this distinction. This level of detail and explicit reference to a specific part of the paper make the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the meta solvers are centralized controllers and suggests that the authors clarify the difference between these solvers and centralized RL where agents share weights. The reviewer supports this claim by referencing a specific paper, \"Foester et al., Learning to communicate with deep multiagent reinforcement learning, NIPS 2016,\" which provides a concrete example of a related work. This external reference enhances the verifiability of the claim, as it offers a clear context and comparison for the authors to consider. Therefore, the comment is 4, as it provides a logical basis for the claim with a specific reference, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the distinction between meta solvers and centralized RL, where agents share weights. It suggests that the authors clarify this difference, providing a specific example from Foester et al. (2016) to guide the clarification process. This feedback is clear and actionable, offering a concrete suggestion for improvement that can help the authors enhance the clarity and accuracy of their work. By addressing this point, the authors can better communicate their contributions and differentiate their approach from existing literature. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the paper\"s methodology, specifically the use of publication years from the ACL anthology to categorize papers. It points out that many papers are available on arXiv much earlier than their publication in the ACL anthology, using the example of the BERT paper. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative methods for categorization. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their categorization method but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the paper\"s categorization method, which is based on publication years from the ACL anthology. It provides a specific example of the BERT paper being available on arXiv earlier than its publication in the ACL anthology. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly points out the issue with the categorization method and provides a concrete example, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s categorization method, based on publication years from the ACL anthology, is problematic because many papers are available on arXiv much earlier. It provides a specific example with the BERT paper, which is available on arXiv from October. This claim is 4 as it is supported by a concrete example and a logical reasoning that many papers are available on arXiv before their publication in the ACL anthology. However, the comment could be strengthened by providing more examples or references to substantiate the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s categorization method, which is based on publication years from the ACL anthology. It points out that many papers are available on arXiv much earlier than their publication in the ACL anthology, using the example of the BERT paper. This feedback is valuable as it highlights a potential flaw in the categorization method and suggests that the authors may need to reconsider their approach. However, the comment could be more helpful if it provided suggestions on alternative categorization methods or how the authors might address this issue. Despite this, the comment is 4 as it directs the authors\" attention to a critical aspect of their methodology that requires revision. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two main issues. First, it questions the authors\" choice of using a relaxation of rejection sampling instead of directly using Importance sampling. This implies that the authors should provide a justification for their approach. Second, it points out a lack of clarity in Algorithm 1, specifically regarding the difference between QRS and RS. The reviewer suggests that the authors should demonstrate a scenario where these methods behave differently. While the comment implies that the authors should provide additional explanations or examples, it does not explicitly instruct them on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific information to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the algorithm, namely the lack of clarity between QRS and RS and the need to demonstrate a scenario where they behave differently. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the authors\" choice of using a relaxation of rejection sampling instead of directly using Importance sampling, suggesting that the authors should provide a justification for their approach. This is a claim that requires justification, as it implies a potential flaw in the methodology. However, the comment does not provide any specific reasoning or evidence to support this claim, making it difficult for the authors to understand the basis of the critique. The second part of the comment questions the difference between QRS and RS in Algorithm 1 and suggests that the authors should demonstrate a scenario where these methods behave differently. This part is more factual and does not contain a claim. Therefore, the overall comment is 4, as the first part lacks sufficient justification, while the second part is factual.", "helpfulness_rationale": "The review comment raises two distinct points. First, it questions the authors\" choice of using a relaxation of rejection sampling instead of directly using Importance sampling, suggesting that the authors should provide a justification for their approach. This feedback is 3 as it prompts the authors to clarify their methodology and potentially reconsider their approach. Second, the comment points out a lack of clarity in Algorithm 1, specifically regarding the difference between QRS and RS. The reviewer suggests that the authors should demonstrate a scenario where these methods behave differently, which could help clarify the algorithm\"s logic. This feedback is more actionable, as it provides a specific direction for improvement. Overall, the comment offers some guidance but could be more comprehensive by providing additional context or examples. Therefore, it is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the experimental results on the last two datasets, suggesting that the performance is similar to IRM and questioning whether this is due to the issues mentioned earlier. However, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the experimental validation. The comment lacks actionable details, such as recommending additional experiments, modifications to the methodology, or alternative analyses to validate the proposed method. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments\" and \"the last two datasets,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, noting that they are not convincing enough to validate the effectiveness of the proposed method due to similarities with IRM. The comment further questions whether this similarity is caused by the issues mentioned earlier. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method, as the performance is similar to IRM. The reviewer questions whether this similarity is due to the issues mentioned earlier. However, the comment lacks specific examples or detailed reasoning to support the claim that the performance is not convincing. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 2, as it provides some basis for the critique but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the performance on the last two datasets is not convincing enough to validate the effectiveness of the proposed method. It further questions whether this similarity to IRM is due to the issues mentioned earlier. While the comment highlights a potential weakness in the experimental validation, it lacks actionable suggestions or guidance on how the authors might address this issue or improve their experimental setup. Without specific recommendations or detailed feedback, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it points out a concern but does not provide sufficient detail or direction for the authors to effectively address it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of detecting both entities in Figure 2, suggesting that knowing the long entity might be sufficient. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should address this question, modify their approach, or provide additional explanation. The comment lacks actionable details, leaving the authors uncertain about how to respond. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of detecting both entities in the example and asks for clarification on the difference between detecting both entities and just knowing the long one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of detecting both entities in Figure 2, suggesting that knowing the long entity might be sufficient. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is the case. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in Figure 2, suggesting that knowing the long entity might be sufficient. This is a valid point that prompts the authors to reconsider the relevance and importance of detecting both entities in their analysis. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a potential area for improvement, the feedback is incomplete and does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the phrase \"nonsequential information such as chunks,\" asking whether \"chunk\" is still considered sequential information. This comment is explicit in its request for clarification, as it directly asks for an explanation of the phrase. However, it does not provide any guidance on how the authors should address this confusion or clarify the terminology. The action is explicit but lacks concrete details on how to implement the clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the phrase \"nonsequential information such as chunks,\" seeking clarification on whether \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the phrase \"nonsequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the phrase \"nonsequential information such as chunks,\" specifically asking whether \"chunk\" is still considered sequential information. This is a clear and direct question that prompts the authors to clarify a potential ambiguity in their work. By addressing this question, the authors can ensure that their terminology is consistent and understandable to readers. However, the comment does not provide any additional context or suggestions for improvement beyond the clarification request. While it is a useful prompt for the authors to clarify their terminology, it lacks depth and does not offer broader guidance on how to enhance the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out an exception that is not true. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue or clarify the exception. The action is implicit, as the authors need to infer that they should provide an explanation for this exception, but it is vague because it lacks concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the correctness of the theorem when there is a separate node with 0 neighbors, and it raises a concern about the upper bound being 0. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the correctness of Theorem 1 by pointing out an exception where the upper bound is 0 when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but raises a logical contradiction. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence makes the claim 3, as it provides a logical basis but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment raises a question about the correctness of Theorem 1, specifically regarding the upper bound when there is a separate node with 0 neighbors. The reviewer acknowledges that the theorem seems correct but points out a potential exception that is not true. This feedback is 3 as it identifies a potential issue with the theorem and prompts the authors to consider and address this exception. However, the comment lacks specific guidance or suggestions on how to resolve this issue, such as proposing alternative explanations or modifications to the theorem. While it highlights an area for improvement, the lack of detailed feedback limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a gap in the analysis regarding the detection of rumors generated by GPT, suggesting that further analysis or solutions should be proposed. It questions why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this analysis or propose solutions. The action is implicit and somewhat vague, as the authors are left to infer what kind of analysis or solutions are needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the handling of rumors generated by GPT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by questioning the analysis of why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. The comment suggests that further analysis or solutions should be proposed to address this gap. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis or solutions regarding the detection of rumors generated by GPT, specifically questioning why GPTgenerated rumors are as difficult to detect as natural rumors. The reviewer provides a logical reasoning by pointing out that both GPTgenerated and natural rumors are written by humans, and therefore, the difficulty in detection should be similar. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to further explore the reasoning and evidence themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks analysis or solutions regarding the detection of rumors generated by GPT. It questions why GPTgenerated rumors are as difficult to detect as natural rumors, given that both are written by humans. This feedback is clear and actionable, as it prompts the authors to further explore and analyze this aspect of their work. By addressing this gap, the authors can enhance the comprehensiveness and depth of their analysis, which is crucial for improving the draft. However, the comment could be more helpful if it provided specific suggestions or examples of how to approach this analysis. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the technical contribution of the paper, specifically noting that Section 4 is more about heuristics than a formal and principled solution. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this issue. The comment lacks actionable details, leaving the authors without a clear understanding of what changes or additions are needed to enhance the technical contribution. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, specifically mentioning that Section 4 is more about heuristics than a formal and principled solution. However, it does not specify which part of Section 4 is being referred to, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique of the technical contribution but lacks grounding as it does not identify the specific sections or elements being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical contribution is limited, specifically mentioning that Section 4 is more about heuristics than a formal and principled solution. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or references to what constitutes a formal and principled solution, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment critiques the technical contribution of the paper, specifically noting that Section 4 is more about heuristics than a formal and principled solution. While it identifies a potential weakness in the paper, it lacks actionable feedback or suggestions for improvement. The comment does not provide guidance on how the authors might enhance the technical contribution or address the critique, leaving the authors without a clear path for improvement. As a result, the comment is not particularly helpful, as it does not offer actionable insights or constructive feedback to assist the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses regret that the probability mass function is not fully exploited in the paper, specifically mentioning the use of a quasiuniform distribution in MixBoost. The reviewer suggests that considering various probability mass functions could add depth to the experimental setting. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific probability mass functions should be considered. The action is implicit and somewhat vague, as the authors are left to infer that they should explore different probability mass functions but without concrete steps or examples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"probability mass function\" and \"MixBoost,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the probability mass function is not fully exploited and suggests considering various distributions to add depth to the experimental setting. However, the comment lacks specific examples or detailed guidance on how to implement this suggestion, making it somewhat specific. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses regret that the probability mass function is not fully exploited in the paper, specifically mentioning the use of a quasiuniform distribution in MixBoost. The reviewer suggests that considering various probability mass functions could add depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that considering different distributions would be beneficial. The suggestion is based on intuition and logical reasoning, but without detailed evidence or examples, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the probability mass function is not fully exploited in the paper. It points out that the quasiuniform distribution used in MixBoost is based on a single parameter, which could be expanded upon by considering different probability mass functions. The comment provides a logical rationale for why this exploration could add depth to the experimental setting, and it even hints at a possible reason why the quasiuniform distribution might be suitable. However, the comment could be more helpful if it offered specific examples of alternative probability mass functions or detailed guidance on how to implement this suggestion. Overall, the feedback is 3 as it highlights a potential area for enhancement but lacks comprehensive guidance for execution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of fairness in the comparison or what steps to take to improve the draft. The comment lacks actionable advice, leaving the authors without a clear understanding of what needs to be done to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. However, it does not specify which part of the paper this comparison is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not detail what aspect of the comparison is unfair or how it should be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. However, it does not provide any supporting evidence, reasoning, or references to justify why the comparison might be unfair. The comment lacks specific examples or detailed analysis to substantiate the claim, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of comparing the accuracies of different models, specifically mentioning ChatGPT and other models. While it identifies a potential issue with the comparison, it does not provide any actionable feedback or suggestions on how the authors might address this concern. The comment lacks depth and does not offer guidance on how to improve the draft or clarify the comparison. As a result, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include references, specifically mentioning [a], which is relevant to their topic. It also suggests discussing connections with [a], which uses supervised learning in QBF solving, where QBF generalizes SMT. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what references to include and how to discuss them. The comment is explicit and provides detailed guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the references that are missing, allowing the authors to accurately identify the part of the paper that needs attention. It also specifies what is missing by suggesting the inclusion of references and a discussion of connections with [a], which uses supervised learning in QBF solving. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that certain references are relevant to the topic and suggests discussing connections with a specific reference, [a]. However, it does not provide detailed reasoning or examples to support why these references are relevant or how they should be integrated into the discussion. The mention of [a] and its use of supervised learning in QBF solving is a vague reference that lacks specific details or context. Without further explanation or examples, the claim is difficult for the authors to understand and act upon, making it barely verifiable. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the absence of relevant references. It suggests including references, particularly [a], which uses supervised learning in QBF solving, where QBF generalizes SMT. This feedback is clear and actionable, as it provides a concrete reference and a specific area for the authors to explore and discuss. By addressing this gap, the authors can enhance the context and relevance of their work. However, the comment could be more helpful if it provided additional context or explanation on why these references are important or how they relate to the paper\"s topic. Overall, the comment is 4 as it directs the authors to a specific improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It suggests that explaining this point may be beneficial. While the comment implies that the authors should explore alternative relationships, it does not provide explicit guidance on how to do so or what specific alternatives to consider. The action is implicit and somewhat vague, as the authors need to infer that they should investigate other relationships and explain their findings. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the context of \"training\" and the \"mono tonic relationship\" between the degree of a singletask predictor participation and the weight of the corresponding task loss. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises a question about whether the mono tonic relationship can be replaced by other relationships and suggests that explaining this point may be beneficial. The reference to [1] provides additional context and support for the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that this relationship could be replaced by other relationships and asks for an explanation. The comment references a specific paper, \"Learning the Pareto Front with Hypernetworks,\" which provides some context and direction for the authors to explore alternative relationships. However, the comment lacks detailed reasoning or examples of how other relationships might be explored or why the mono tonic relationship is problematic. This makes the claim 3, as it provides a starting point but requires further elaboration from the authors to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that this relationship could be replaced by other relationships and encourages the authors to explain this point further. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might explore alternative relationships or what specific aspects of the explanation could be improved. The reference to a related work provides some context but does not fully support the claim or offer actionable advice. Therefore, the comment is 3, as it prompts the authors to consider an area for further exploration but does not provide comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the comparison of computation cost or running time, implying that the authors should include this information in their draft. However, it does not provide explicit guidance on how to address this issue or what specific aspects of computation cost or running time should be considered. The action is implicit and somewhat vague, as the authors can infer that they need to include this information but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the comparison of computation cost or running time, but it does not specify which part of the paper this comparison should be included in. The authors cannot confidently determine the exact section being addressed, making the comment weakly grounded. However, it is specific in suggesting a particular aspect of the paper that needs attention, namely the comparison of computation cost or running time. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification on the comparison of computation cost or running time. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the comparison of computation cost or running time, suggesting that this aspect should be included in the paper. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how the authors should address this issue. The comment does not offer actionable suggestions or examples, leaving the authors with a general idea of what might be missing but without clear steps to enhance their draft. Therefore, the comment is 2, as it provides limited value for improving the paper."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using traffic signal control as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the questions or improve the draft, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using traffic signal control as an example. However, it does not specify which part of the paper discusses these issues, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its critique but lacks grounding, as it does not explicitly mention the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions and critiques, such as questioning the privacy preservation of the approach and the relevance of using traffic signal control as an example. These are not claims that require verification, as they are factual questions or observations. The comment does not make subjective opinions, judgments, or suggestions that need to be supported by evidence or reasoning. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the privacy preservation of the approach compared to other federated learning methods and questions the relevance of using traffic signal control as an example. It challenges the authors to justify their choice of application and provides a critical perspective on the potential limitations of their work. However, the comment does not offer specific suggestions or guidance on how the authors might address these concerns or improve their draft. While it highlights areas that need clarification or justification, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the neural network in Section 528 is hard to understand and recommends starting the section with the final paragraph, which is clearer. This feedback provides a clear and explicit action for the authors to take, which is to restructure the section to improve clarity. The suggestion is concrete, as it specifies exactly what needs to be done to enhance the readability of the section. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 528,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the description of the neural network is hard to understand and suggests starting the section with the final paragraph, which is clearer. This provides clear guidance on what needs to be addressed to improve the clarity of the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network in Section 528 is hard to understand. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description of the neural network in Section 528, noting that it is hard to understand. It suggests starting the section with the final paragraph, which is clearer, as a way to improve the readability. This feedback is clear and actionable, providing the authors with a direct suggestion to enhance the clarity of their work. However, it could be more helpful if it included additional guidance on how to restructure the section or what specific aspects of the description need clarification. Overall, the comment is 4 as it directs the authors toward a meaningful improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. While the comment implies that the authors should consider this possibility, it does not provide explicit guidance or suggestions on how to implement this change or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility and determine how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in its suggestion to explore attentionbased training, but without clear grounding, it is challenging for the authors to determine where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or how it might impact the model\"s performance. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of the model, specifically whether it is possible to train it towards attentionbased encoderdecoder training. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or suggestions on how the authors might explore this possibility or what specific changes could be made to the model. The comment is 3 as it prompts the authors to consider an alternative approach, but it does not offer actionable steps or detailed feedback to enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the division of tables into three types in Section 3, specifically questioning whether one type (the column header) should suffice. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes, if any, are needed. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 (line 247252),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the division of tables into three types and suggests that one type (the column header) might suffice. This provides clear guidance on what aspect of the paper needs clarification or revision. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the division of tables into three types, specifically questioning whether one type (the column header) should suffice. However, it does not provide any supporting evidence, reasoning, or examples to justify why the division into three types is unnecessary or how the column header alone could be sufficient. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the division of tables into three types in Section 3, specifically questioning whether one type (the column header) should suffice. While it identifies a potential area of confusion or unnecessary complexity, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their presentation. The comment is 3 as it prompts the authors to reconsider their table structure, but it does not offer actionable advice or detailed feedback. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the attack methods used in the paper are considered naive and suggests that other classical attack methods in NLP should be considered. However, it does not provide specific guidance on which classical attack methods should be used or how to incorporate them into the paper. The comment implies that the authors should explore additional attack methods, but it lacks concrete details on how to implement this suggestion. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the attack methods used in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the attack methods are considered naive and suggests that other classical attack methods in NLP should be considered. The comment provides specific examples of papers that could be referenced for alternative attack methods, which adds further clarity and specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. The reviewer provides a specific example by mentioning the use of universal adversarial suffixes and references two papers that could be consulted for alternative methods. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current methods are inadequate. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a weakness in the paper by pointing out that the attack methods used are considered naive. It suggests that other classical attack methods in NLP should be considered, particularly in the context of the toy setting with classification tasks. The comment provides specific examples of papers that could be referenced for alternative attack methods, which is a valuable suggestion for the authors to consider. However, the comment could be more helpful if it offered a more detailed analysis of why the current methods are inadequate or how the suggested methods might improve the paper. Overall, the feedback is 4 as it provides clear guidance on areas for improvement, but it could be more comprehensive with additional context and analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest specific actions to mitigate the potential issues. The feedback is implicit and lacks concrete details on how to implement changes, making it 3.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. However, it does not specify which part of the paper discusses this issue or where the prior knowledge is incorporated, making it weakly grounded. The comment is specific in detailing the potential issue of unfairness due to the leakage of additional information from the pretrained visual model and target dataset. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The lack of concrete evidence or detailed explanation makes it difficult for the authors to understand and address the concern fully. Therefore, the comment is considered 2, as it provides a general concern but lacks sufficient detail for verification.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential issue of unfairness resulting from the leakage of additional information from the pretrained visual model and target dataset. This feedback is 3 as it identifies a critical area that could impact the validity of the results and suggests a potential source of bias. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or mitigate the potential unfairness. To be more helpful, the comment could include recommendations for controlling or accounting for this bias, such as proposing specific methods or analyses to ensure fairness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no suggestion for further analysis, clarification, or improvement. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps, if any, they should take in response to this observation. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by expressing surprise at the dominance of function words over content words in a Japanese sentence. However, the comment does not provide further details or suggestions on how to address this observation, making it specific but not fully grounded. Therefore, this comment aligns with a score of 4.", "verifiability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this observation. The comment lacks specific examples or explanations that would help the authors understand the basis of the surprise or how this observation relates to the paper\"s content. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue or improve their work. Therefore, it is rated as 1.", "helpfulness_rationale": "The comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any further context, analysis, or suggestions for improvement. It lacks depth and does not offer actionable feedback or guidance for the authors to address this observation or its implications. As a result, the comment is 1, as it does not provide any value to the authors in terms of improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should use the minimal kmeans objective over multiple seeds as a baseline instead of the average of kmeans objectives with multiple seeds. The comment provides specific references to support this suggestion, which is a concrete action for the authors to take. The references offer a clear direction on how to implement the suggested change, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of the average of kmeans objectives with multiple seeds as a baseline, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests using the minimal kmeans objective over multiple seeds as a more reasonable baseline, providing a clear and actionable suggestion. The comment further supports this suggestion with references to relevant literature, which enhances its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the average of kmeans objectives with multiple seeds is not a suitable baseline and proposes using the minimal kmeans objective instead. This claim is supported by references to two external works that provide evidence and reasoning for the suggestion. The references offer specific examples and arguments, making the claim 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It points out that the average of kmeans objectives with multiple seeds is used as a baseline, and it proposes using the minimal kmeans objective over multiple seeds as a more reasonable baseline. This suggestion is supported by references to relevant literature, which adds credibility to the feedback. The comment is clear and provides a concrete direction for the authors to enhance their work, making it 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the importance of including a reference to the idea of unrolling, which was first proposed in \"Lista\" by Yann LeCun. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista, and place itself in an appropriate context. While the comment implies that the authors should include this reference and discussion, it does not provide explicit instructions on how to do so or what specific aspects should be highlighted. The action is implicit and somewhat vague, as the authors can infer the need for inclusion but may not be entirely sure of the exact details or context required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the idea of unrolling, which was first proposed in \"Lista\" by Yann LeCun. This allows the authors to accurately identify the part of the paper being addressed, as it relates to the concept of unrolling. The comment is also specific because it highlights the importance of discussing the similarities and differences between the proposed work and Lista, and suggests that the paper should place itself in an appropriate context. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that an important reference is missing, specifically mentioning the idea of unrolling, which was first proposed in \"Lista\" by Yann LeCun. The reviewer provides a direct link to the reference, which is a clear and specific piece of evidence supporting the claim. This makes the claim 5, as it is supported by a concrete reference that can be easily verified by the authors. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, namely the lack of reference to the idea of unrolling, which was first proposed in \"Lista\" by Yann LeCun. It highlights the importance of discussing the similarities and differences between the proposed work and Lista, and suggests that the paper should place itself in an appropriate context. This feedback is clear and actionable, as it directs the authors to include a reference and discussion that can enhance the paper\"s context and relevance. However, the comment could be more helpful if it provided specific guidance on how to integrate this reference or what aspects to focus on in the discussion. Overall, the comment is 4, as it identifies a critical gap and offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point raises two main concerns: the lack of clarity in the specific definition of the sparsity of the residual term and the need for evidence supporting the sparsity assumption across various noisy cases. It also suggests that the authors should demonstrate the advantages of their assumptions compared to existing methods. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the definition of sparsity and provide evidence or examples to support the sparsity assumption, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3, as it highlights areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"specific definition of the sparsity of the residual term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of clarity in the definition and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. Additionally, it requests a comparison of the proposed method\"s assumptions with existing methods. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises a claim about the lack of clarity in the specific definition of the sparsity of the residual term and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. However, the comment does not provide any specific reasoning, examples, or references to support the claim or suggest how the authors might address the issue. This lack of detailed justification or evidence makes the claim difficult for the authors to understand and address, rendering it 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the definition of the sparsity of the residual term and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. It also recommends demonstrating the advantages of the proposed method\"s assumptions compared to existing methods. This feedback is clear and actionable, as it highlights a critical aspect of the paper that needs clarification and provides a direction for improvement. By addressing these points, the authors can enhance the comprehensiveness and robustness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the term \"connectivity\" is misleading because it does not refer to structural connections between the brain and body. However, it does not provide any guidance on how the authors should address this issue or suggest alternative terminology. The action is explicit but lacks concrete details on how to implement the change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term \"connectivity,\" explaining that it does not refer to structural connections between the brain and body. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not refer to structural connections between the brain and body. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is the case. Without additional context or explanation, the claim remains 1, as the authors may not fully understand the basis of the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the term \"connectivity\" used in the paper, pointing out that it does not accurately reflect the structural connections between the brain and body. This feedback is 3 as it highlights a potential misinterpretation or misunderstanding in the paper. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or clarify the terminology. To be more helpful, the comment could suggest alternative terms or provide examples of how to accurately describe the connections. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific guidance on what details are missing or how the authors should address these issues. The comment refers to another section for more details, but without explicit instructions or concrete suggestions, the authors are left without a clear path forward. This lack of specificity and actionable advice makes the comment 1.", "grounding_specificity_rationale": "The comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which parts of the paper are lacking in detail or what specific aspects need improvement. Additionally, it does not provide any references or examples to support the claim, making it difficult for the authors to pinpoint the exact areas needing attention. The comment is 1 as it does not identify specific sections or elements of the paper, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or evidence to support this claim, such as mentioning which aspects of the related work, experiments, or writing are lacking. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or guidance on what details are missing or how the authors can improve these areas. Without actionable feedback or suggestions for improvement, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of studying the \"essentialness of using orthogonal matrix rather than just following the form that connects local and connects beyond local windows.\" It suggests that this aspect should be further explored to validate the significance of using orthogonal matrices. However, the comment does not provide explicit instructions on how to conduct this study or what specific steps should be taken. While the authors can infer that they need to investigate this aspect further, the feedback lacks concrete guidance on how to implement this action. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Step 2\" and \"Step 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the \"essentialness of using orthogonal matrix rather than just following the form that connects local and connects beyond local windows\" should be studied. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Step 3 is the vital part that only orthogonal matrix weight can perform,\" suggesting that the essentialness of using orthogonal matrices should be studied. However, the comment lacks specific evidence or references to support this claim. It does not provide detailed reasoning or examples to justify why Step 3 is unique to orthogonal matrices, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the use of orthogonal matrices in the paper. It highlights the importance of studying the \"essentialness of using orthogonal matrix rather than just following the form that connects local and connects beyond local windows,\" suggesting that this aspect should be further explored. While the comment points out a potential gap in the paper, it does not provide detailed guidance or suggestions on how to address this issue or conduct the study. The feedback is 3 as it directs the authors\" attention to an area that requires further investigation, but it lacks actionable steps or detailed advice, leaving the authors with a general direction to follow. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the models and datasets used are too toylike and proposes specific alternatives, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small, to improve the complexity and difficulty of the experiments. It also asks whether there is a foreseeable challenge to experiment on language tasks. While the comment provides explicit suggestions for improvement, it does not specify how the authors should address these suggestions or what specific changes should be made to the experiments. The action is explicit but somewhat vague, as the authors know what needs to be done but may not be entirely clear on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the models and datasets, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improving the complexity and difficulty of the experiments by recommending specific models and datasets, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small. Additionally, it raises a question about the feasibility of experimenting on language tasks, which further specifies the areas needing attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the models and datasets are too toylike and suggests specific alternatives, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small. The reviewer provides a logical reasoning by stating that CIFAR100 is of similar size to CIFAR10 but more difficult, and that ResNet 34 or 50 would require more compute but are manageable by the authors\" machines. The suggestion to include ViTtiny or small is also logical, as they are similar in compute to ResNet 18. However, the comment lacks specific references or detailed explanations of why these alternatives are necessary or how they would improve the paper. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the models and datasets used are too toylike and proposes alternative, more challenging datasets and models, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also raises a question about the feasibility of experimenting on language tasks, which could be an interesting direction for the authors to explore. The comment is clear and offers concrete suggestions for improvement, making it 5 for the authors to enhance the rigor and relevance of their work. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that some natural ablation studies are missing, specifically questioning how scratchGAN would perform if pretraining was included. It also highlights the importance of this baseline, given the central argument against pretraining. While the comment implies that the authors should include these ablation studies, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to conduct these ablation studies or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that some natural ablation studies are missing, specifically questioning how scratchGAN would perform if pretraining was included. It also highlights the importance of this baseline, given the central argument against pretraining. However, the comment does not specify which part of the paper these ablation studies should be included in, making it weakly grounded. The comment is specific in its suggestion to include these ablation studies, but without clear grounding, the authors may struggle to identify the exact section where this feedback is relevant. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that some natural ablation studies are missing, specifically questioning how scratchGAN would perform if pretraining was included. The comment highlights the importance of this baseline, given the central argument against pretraining. However, the comment lacks specific examples or detailed reasoning to support why these ablation studies are crucial or how they would contribute to the paper. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3, as it provides some justification but lacks detailed support.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that natural ablation studies are missing, particularly questioning how scratchGAN would perform if pretraining was included. This feedback is actionable as it highlights a crucial baseline that could strengthen the paper\"s argument against pretraining. The comment also includes minor comments and questions, which provide additional context and direction for the authors. However, the comment could be more helpful if it offered specific suggestions on how to conduct these ablation studies or what aspects to focus on. Overall, the feedback is 4 as it directs the authors to a significant area for enhancement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of a comparison against baselines in the study, specifically noting that the reported accuracy across optimization levels of binaries lacks baseline comparisons. The reviewer suggests that this is a widelyunderstood binary analysis application and that many papers have developed architectureagnostic similarity comparisons or reported them as code search, which is a similar task. While the comment implies that the authors should include baseline comparisons, it does not explicitly instruct them to do so or provide specific guidance on which baselines to consider. The action is implicit and somewhat vague, as the authors need to infer that they should include baseline comparisons and may not be entirely sure of the specific baselines to consider. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study\" and the \"accuracy across optimization levels of binaries,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking baseline comparisons and references similar work in the field. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison against baselines, specifically noting the absence of baseline comparisons in the functionality similarity comparison study. The reviewer supports this claim by stating that many papers have developed architectureagnostic similarity comparisons or reported them as code search, which is a similar task. This provides a logical reasoning and reference to common practices in the field, making the claim 4. However, the comment could be strengthened by providing specific examples of papers that have included baseline comparisons or by elaborating on the importance of such comparisons in the context of the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of baseline comparisons in the functionality similarity comparison study. It highlights that the reported accuracy across optimization levels of binaries lacks a comparison against established baselines, which is a common practice in the field. The comment also references similar work in the area, suggesting that many papers have developed architectureagnostic similarity comparisons or reported them as code search, which is a similar task. This feedback is clear and actionable, as it directs the authors to include baseline comparisons to strengthen the validity and relevance of their findings. However, it could be more helpful if it provided specific suggestions on which baselines to consider or how to integrate them into the study. Overall, the comment is 4, as it effectively guides the authors toward improving the comprehensiveness and rigor of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to mention a specific detail regarding the preprocessing and evaluation in SI 6.5. It provides clear guidance on what needs to be added to the draft, making the action concrete and direct. The authors know exactly what needs to be done to address the comment, ensuring a high level of actionability. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be mentioned regarding the preprocessing and evaluation, which is different from Mnih et al. [7]. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should mention a specific difference in preprocessing and evaluation compared to Mnih et al. [7]. This is a factual statement that does not require verification or justification. It is a request for clarification or additional information, not an opinion or claim that needs to be substantiated. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to include a mention of a difference in preprocessing and evaluation compared to Mnih et al. [7]. By pointing out this detail, the comment helps the authors enhance the clarity and completeness of their paper. However, while it identifies a particular area for improvement, it does not offer additional insights or suggestions beyond this specific point. Therefore, the comment is 4, as it provides clear guidance but could be more comprehensive with further elaboration. This aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper regarding the lack of reported metrics that demonstrate the efficiency of the proposed method compared to previous work. While the comment identifies a specific area for improvement, it does not provide explicit guidance on what metrics should be included or how to measure efficiency. The action is implicit and somewhat vague, as the authors need to infer that they should include metrics to demonstrate efficiency. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of reported metrics that demonstrate the efficiency of the proposed method compared to previous work. However, it does not specify which part of the paper discusses the advantages over previous work, making it weakly grounded. The comment is specific in pointing out the absence of efficiency metrics, which is a clear indication of what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks metrics to demonstrate the efficiency of the proposed method compared to previous work. However, it does not provide specific examples of what metrics should be included or how the current metrics are insufficient. This lack of detailed justification or references makes the claim 3, as the authors would need to infer the specific metrics needed to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that while the authors discuss the advantages of their method over previous work in terms of efficiency, they do not provide any metrics to substantiate these claims. This feedback is valuable as it highlights a critical area for improvement, specifically the need to include efficiency metrics to support the claims made in the paper. However, the comment could be more helpful if it suggested specific metrics or methods for measuring efficiency, which would provide the authors with more actionable guidance. Overall, the comment is 3 as it points out a key weakness but lacks depth in suggesting how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the contribution of the paper, stating that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might enhance their contribution or address the perceived limitations. Without actionable suggestions or specific feedback, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the contribution of the paper, specifically addressing the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. However, it does not specify which part of the paper discusses these contributions, making it weakly grounded. The comment is specific in its critique of the contribution, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the contribution of the paper, stating that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment lacks specific examples or detailed reasoning to support why the contribution is insufficient or limited. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment critiques the contribution of the paper, stating that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment does not provide specific feedback or suggestions on how the authors might enhance their contribution or address the perceived limitations. It lacks actionable guidance or detailed critique, leaving the authors without a clear understanding of what needs to be improved or how to improve it. As a result, the comment is 1, as it does not offer any constructive feedback for the authors to consider."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests more details on the statespace, actions, and the space in which theta lies. It suggests that the authors should be precise in their descriptions rather than leaving the reader to guess. This feedback provides a clear and direct action for the authors to take, which is to provide more detailed information in the draft. The comment is explicit and concrete, giving the authors a specific task to complete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for more details about the statespace, actions, and the space in which theta lies. The comment provides a clear direction for improvement by suggesting that the authors should be precise in their descriptions rather than leaving the reader to guess. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the nature of the statespace, actions, and the space in which theta lies. The reviewer suggests that these details should be provided for clarity. However, the comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely the details about the statespace, actions, and the space in which theta lies. It suggests that the authors should provide more precise information to avoid leaving the reader to guess. This feedback is clear and actionable, as it directs the authors to enhance the clarity and precision of their descriptions. However, the comment could be more helpful if it provided specific suggestions on how to present these details or why they are important. Overall, the comment is 4 as it guides the authors toward improving the clarity and precision of their work."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that the authors have already addressed this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. However, the comment does not provide any explicit guidance or suggestions on how the authors might address this issue or improve their proof technique. The action is implicit and vague, as the authors are left without clear direction on how to resolve the problem. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the proof technique, noting the reliance on a special case where a contradiction arises as matrix norms approach infinity. The comment further specifies that this issue is acknowledged by the authors in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. This level of detail provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proof technique in Appendix A relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that the authors have addressed this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. The comment provides a logical explanation of the issue and references the authors\" acknowledgment of it, which is a clear and specific justification. However, it could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It acknowledges that the authors have already addressed this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment highlights a potential weakness in the proof technique, it does not provide any suggestions or guidance on how the authors might address this issue or improve their proof. The feedback is 3 as it points out a specific area for improvement, but it lacks actionable advice, making it incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. While the comment implies a change in the choice of downstream task, it does not provide explicit guidance on how to implement this change or why LiDARbased segmentation is the preferred choice. The authors can infer that they should reconsider their choice of downstream task, but the comment lacks concrete details on how to make this change or what specific aspects of LiDARbased segmentation make it a better fit. Therefore, the comment is 3, as it provides an implicit suggestion but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. However, it does not specify which part of the paper discusses the choice of downstream task, making it weakly grounded. The comment is specific in its suggestion to use LiDARbased segmentation and provides a rationale for the choice, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that LiDARbased segmentation is a better choice for the downstream task than object detection, citing the need for accurate locations and poses in benchmark metrics like KITTI and Waymo. The claim is 3 as it provides a logical reasoning for the preference of LiDARbased segmentation, particularly in the context of benchmark metrics. However, the comment lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should reconsider their choice of downstream task, specifically recommending LiDARbased segmentation over object detection. It provides a rationale for this suggestion, noting that object detection requires accurate locations and poses, which are crucial for benchmark metrics like KITTI and Waymo. While the comment identifies a potential area for improvement, it lacks specific guidance on how to implement the suggested change or why LiDARbased segmentation is the preferred choice. The feedback is 3 as it points out a potential issue and offers a direction for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential contradiction between the objective of Eq (12) and the IPO (Infinite Product Optimization). However, it does not provide any explicit or implicit guidance on how the authors should address this contradiction or what specific changes are needed to resolve it. The comment lacks actionable details, such as suggesting ways to reconcile the objectives or explaining how the authors might clarify the contradiction. Without concrete instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"Eq (12)\" and \"IPO,\" which allows the authors to identify the specific part of the paper being addressed, providing full grounding. However, the comment does not specify what aspect of Eq (12) is in contradiction with IPO or how this contradiction affects the paper. This lack of specificity makes it difficult for the authors to understand the exact issue and how to address it. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that there is a contradiction between the objective of Eq (12) and the Infinite Product Optimization (IPO). However, the comment does not provide any further explanation, examples, or references to support this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the contradiction or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential contradiction between the objective of Eq (12) and the Infinite Product Optimization (IPO). This is a relevant observation that could impact the validity of the paper\"s claims or the interpretation of the results. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this contradiction or clarify the issue. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it points out a potential issue but does not offer sufficient guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts effectively. The reviewer provides a rationale for this concern, suggesting that while DINO representations may contain rich geometric information, the adaptation capacity might be limited for concepts where class labels correlate more with semantics rather than geometry. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the adaptation capacity. The action is implicit and somewhat vague, as the authors are left to infer that they should explore or address the issue of adapting to new concepts, but without concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts effectively. It provides a rationale for this concern by discussing the potential limitations for concepts where class labels correlate more with semantics rather than geometry. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the discussion of the visual memory or adaptation capacity, but without explicit references, it is challenging to pinpoint the exact section. The comment is specific in detailing the concern about adaptation capacity and the potential limitations, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can accommodate new concepts effectively. The reviewer provides a logical reasoning by suggesting that while DINO representations may contain rich geometric information, the adaptation capacity might be limited for concepts where class labels correlate more with semantics rather than geometry. This reasoning is based on a logical inference and common knowledge about the nature of DINO representations. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment raises a valid concern about the adaptation capacity of the proposed visual memory, specifically questioning whether it can effectively accommodate new concepts. The reviewer provides a logical reasoning by suggesting that while DINO representations may contain rich geometric information, the adaptation capacity might be limited for concepts where class labels correlate more with semantics rather than geometry. This feedback is 3 as it highlights a potential limitation in the paper and prompts the authors to consider this aspect further. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this concern or improve the adaptation capacity. Overall, the comment provides a valuable insight but lacks actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the paper should include a comparison against stateoftheart loss functions widely used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This provides a clear and direct action for the authors to take, as it specifies the type of comparison that should be added to the paper. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding a comparison against stateoftheart loss functions widely used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting the types of loss functions to consider, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a comparison against stateoftheart loss functions widely used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples of how these comparisons would enhance the paper. The authors would need to infer the importance of these comparisons and how they relate to the paper\"s focus on biometric verification learning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should include a comparison against stateoftheart loss functions widely used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This feedback is clear and actionable, as it provides specific examples of loss functions that could be included in the comparison. By suggesting this addition, the comment offers a concrete way for the authors to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it explained why these comparisons are important or how they would contribute to the paper\"s findings. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point questions the intent of Section 5.2, implying that the authors should clarify the purpose of this section. However, it does not provide any guidance on how to address this issue or what specific aspects of the section need clarification. The action is implicit and vague, as the authors are left to infer that they need to provide more context or explanation for the section. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the intent of Section 5.2, indicating that the authors should clarify the purpose of this section. However, it does not specify what aspect of the section is unclear or what specific information is missing. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. The comment is 1 as it does not identify a specific section, table, or figure, and it is not specific because it lacks detailed guidance on what needs to be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the intent of Section 5.2. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment questions the intent of Section 5.2, indicating that the authors should clarify the purpose of this section. While it identifies a potential area of confusion, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The feedback is vague and does not offer actionable steps for improvement, leaving the authors without a clear path forward. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify the threat model by defining the assumed threat model more explicitly, specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. It also suggests including this information in a dedicated section to enhance clarity, particularly regarding the assumed whitebox access to the victim model. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"threat model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the assumed threat model, including the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it suggests including this information in a dedicated section to enhance clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly. It provides a clear and logical reasoning for this suggestion, as it highlights the importance of specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. This feedback is wellsupported by the need for clarity in the threat model, making it 4. However, the comment could be strengthened by providing examples or references to similar threat models for comparison, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for further clarification of the threat model. It provides a clear and actionable suggestion by asking the authors to define the assumed threat model more explicitly, specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. This feedback is valuable as it guides the authors on how to enhance the clarity and comprehensiveness of their threat model, which is crucial for understanding the context and limitations of their work. However, the comment could be more helpful if it included examples or references to similar threat models for comparison. Overall, the comment is 4 as it provides clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the chatgpt baseline is rudimentary and suggests testing a fewshot approach. It also recommends including discourse relation information in the prompts, which the reviewer believes could yield good results. However, the comment does not provide explicit instructions on how to implement these suggestions or test the fewshot approach. While the authors can infer that they should explore these options, the feedback lacks concrete guidance on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"chatgpt baseline\" and \"fewshot approach,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as testing the fewshot approach and including discourse relation information in the prompts. The comment specifies what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the chatgpt baseline is rudimentary and suggests testing a fewshot approach. It also recommends including discourse relation information in the prompts, which the reviewer believes could yield good results. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The suggestion to include discourse relation information is not fully substantiated, making it difficult for the authors to understand the basis of the recommendation. Therefore, the claim is 3, as it provides some justification but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a weakness in the chatgpt baseline, noting that it is rudimentary and lacks testing of a fewshot approach. It suggests that including discourse relation information in the prompts, possibly through a ChainofThought style approach, could yield better results. This feedback is 3 as it points out a potential area for improvement and offers a specific suggestion for enhancing the evaluation. However, the comment could be more helpful if it provided additional guidance on how to implement the suggested approach or why it might be beneficial. Overall, the comment provides some direction but lacks depth and actionable details, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to present the results comparing standard vs. evolutional dropout on shallow models as a mean over many runs (at least 10), ideally with errorbars. It also notes that the plotted curves are from single runs and might be subject to significant fluctuations, suggesting that the models are small and should not be an excuse for not providing statistics. This feedback is clear and provides concrete steps for the authors to take, ensuring they know exactly what changes to make to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results comparing standard vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting the results as a mean over many runs (at least 10) with errorbars, and explaining why the current presentation might be subject to significant fluctuations. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs, ideally with errorbars, to account for potential fluctuations. The reviewer provides a logical reasoning by noting that the plotted curves are from single runs, which could lead to significant fluctuations due to the small size of the models. This reasoning is clear and provides a basis for the suggestion, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim about the need for statistical analysis. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs, ideally with errorbars, to account for potential fluctuations. The reviewer points out that the current presentation is from single runs, which could lead to significant fluctuations due to the small size of the models. This feedback is specific and provides a concrete suggestion for improving the presentation of the results, which is valuable for the authors. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or why it is important for the paper. Overall, the comment is 4 as it directs the authors toward a significant improvement in the presentation of their results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This is a clear and direct action that the authors can take to improve their draft. The comment also provides a rationale for why this information is important, explaining that different versions of the experimental environment can affect training and inference speeds. This level of detail and guidance makes the action concrete and easy for the authors to follow, ensuring that the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. This allows the authors to accurately identify the part of the paper that needs revision. The comment is also specific because it clearly specifies what needs to be addressed, namely the detailed description of the experimental environment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. The claim is based on the assumption that different versions of these tools can impact training and inference speeds. While the reviewer provides a logical reasoning for why this information is important, the comment lacks specific examples or references to substantiate the claim. This makes the claim 3, as it requires further elaboration or evidence to fully support the suggestion.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should include more detailed information about the experimental environment, such as the CUDA and PyTorch versions. This information is crucial for reproducibility and understanding the impact of different versions on training and inference speeds. By addressing this feedback, the authors can enhance the transparency and robustness of their experimental setup, which is a significant improvement for the draft. However, the comment could be more helpful if it also suggested how this information should be presented or integrated into the paper. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the evaluation metric should be mentioned in the text to better understand the scale of the improvement and for comparability with the results reported in the paper. It also points out the specific expression used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to clarify the evaluation metric. This feedback is explicit and provides concrete guidance on what needs to be done, making it 5. The authors know exactly what needs to be added to their draft to improve clarity and comparability. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lines (078079 / Line 08) where the issue is located, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the evaluation metric should be mentioned to better understand the scale of the improvement and for comparability with the results reported in the paper. Additionally, it provides a specific example of the expression used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to clarify the evaluation metric. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation metric should be mentioned to better understand the scale of the improvement and for comparability with the results reported in the paper. It references a specific expression used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to clarify the evaluation metric. This provides a clear and specific reference to support the claim, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the evaluation metric impacts the results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the evaluation metric should be mentioned in the text to better understand the scale of the improvement and for comparability with the results reported in the paper. It references a specific expression used in Fern\u00e1ndezGonz\u00e1lez and G\u00f3mezRodr\u00edguez (2020) to clarify the evaluation metric, which is a concrete example that can guide the authors in improving their draft. This feedback is clear and detailed, offering the authors a direct path to enhance the clarity and comprehensibility of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. However, it does not provide specific guidance on how the authors should address this issue or what steps they should take to improve the applicability of their approach. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to respond to this feedback. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the bounds and their improvement over previously known results for arbitrarily long inputs. However, it does not specify which part of the paper discusses these bounds or where the authors should focus their attention to address this issue. The comment lacks grounding as it does not mention specific sections, figures, or tables, making it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while it raises a concern about the applicability of the approach, it does not provide specific guidance on how to address this limitation. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. However, it does not provide specific examples or references to support this claim, nor does it explain how these improvements would limit the applications of the approach. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the bounds having o(1) terms and improving over previously known results for arbitrarily long inputs. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the applicability of their approach. The comment lacks actionable feedback or detailed insights, leaving the authors without a clear understanding of what steps to take to enhance their work. As a result, the comment is 1, as it does not offer any constructive direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that a clear clarification is not provided until the conclusion. However, it does not explicitly instruct the authors to clarify this point or suggest how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the target of their study but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that a clear clarification is not provided until the conclusion. However, it does not specify which part of the paper lacks this clarification, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of clarity regarding the target of the study but lacks grounding as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses confusion about whether the paper targets singletoken or multitoken cloze queries and notes that a clear clarification is not provided until the conclusion. However, the comment does not provide any specific reasoning, examples, or references to support the claim of confusion or the need for clarification. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the target of the paper, whether it focuses on singletoken or multitoken cloze queries. It notes that a clear clarification is not provided until the conclusion, which is a relevant observation. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this point or improve the clarity of their paper. While it highlights an area for improvement, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the major contributions of the paper are unclear and that analyzing previous work does not constitute a contribution. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or clarify their contributions. There is no suggestion on what specific aspects of the paper should be highlighted as contributions or how the authors might reframe their work to better articulate its contributions. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the lack of clarity regarding the paper\"s major contributions, specifically questioning whether analyzing previous work constitutes a contribution. However, it does not specify which part of the paper this issue pertains to, such as a particular section or discussion, making it weakly grounded. The comment is specific in its critique of the contributions, but without clear grounding, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the major contributions of the paper are unclear and that analyzing previous work does not constitute a contribution. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the lack of clarity regarding its major contributions. It points out that analyzing previous work alone does not constitute a contribution, which is a valid critique. However, the comment does not provide specific suggestions or guidance on how the authors might clarify or enhance their contributions. Without actionable advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it highlights an important area for improvement but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, it does not provide explicit guidance on how to implement this suggestion or what specific attributes should be included in the vector form. The action is implicit and somewhat vague, as the authors are left to infer the details of the proposed change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where the protected feature is discussed. Without explicit references or context, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the protected feature should be included in the vector form or how this extension would benefit the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension would be beneficial or how it might improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests extending the protected feature \"A\" to a vector form, implying that it currently represents a single attribute. This feedback provides a potential direction for improvement by suggesting a more comprehensive representation of the protected feature. However, the comment lacks specificity and does not offer detailed guidance on how to implement this suggestion or what specific attributes should be included in the vector form. While it identifies a potential area for enhancement, the lack of detailed advice limits its helpfulness. Therefore, the comment is 3, as it provides a general direction for improvement but lacks depth and actionable steps."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that $kNNECD$ is very similar to $kNNMT$, implying that the technical contribution of the paper is limited. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this concern or improve the paper\"s contribution. Without any actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that $kNNECD$ is very similar to $kNNMT$, implying that the technical contribution of the paper is limited. However, it does not specify which part of the paper discusses $kNNECD$ or $kNNMT$, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the paper are similar or how the similarity affects the technical contribution. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that $kNNECD$ is very similar to $kNNMT$, suggesting that the technical contribution of the paper is limited. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or comparisons, it is difficult for the authors to understand the basis of the comparison or how the similarity affects the paper\"s contribution. As a result, the claim is 1, as it lacks the necessary justification or evidence to support the assertion.", "helpfulness_rationale": "The review comment suggests that $kNNECD$ is very similar to $kNNMT$, implying that the technical contribution of the paper is limited. However, it does not provide any specific examples or details to support this claim, nor does it offer suggestions on how the authors might address this issue or enhance the paper\"s contribution. Without actionable feedback or guidance, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that including an example and a figure would be beneficial for explaining the definition of uniform shattering. While the comment implies that the authors should add these elements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to create the example or figure. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where this definition is discussed. Without explicit references, the authors may find it challenging to determine where to incorporate these suggestions. The comment is specific in suggesting the inclusion of an example and a figure, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any specific reasoning or evidence to support why this would be beneficial or how it would improve the clarity of the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that including an example and a figure would be beneficial for explaining the definition of uniform shattering. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the clarity and comprehensibility of the paper. By offering a concrete way to improve the draft, the comment is 5 for the authors, as it guides them on how to enhance the reader\"s understanding of a critical concept. However, the comment could be more helpful if it provided additional context or explanation about why this example and figure are necessary. Overall, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a belief that the proposed transductive method is not very novel, suggesting that it is related to a common way to incorporate unlabeled data in semisupervised methods. However, the comment does not provide any specific guidance or suggestions on how the authors might address this concern or improve the novelty of their method. It lacks explicit instructions or concrete details on what the authors should do to enhance the novelty of their approach. As a result, the comment is vague and does not offer actionable steps for the authors to take. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the proposed transductive method is not very novel, as it is related to a common way to incorporate unlabeled data in semisupervised methods. However, it does not specify which part of the paper this claim pertains to, such as a specific section or methodology discussion. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. Additionally, while the comment provides some insight into the potential lack of novelty, it does not specify what aspects of the method are not novel or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed transductive method is not very novel, suggesting that it is related to a common way to incorporate unlabeled data in semisupervised methods. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the reviewer\"s assertion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment expresses a belief that the proposed transductive method is not very novel, suggesting that it is related to a common way to incorporate unlabeled data in semisupervised methods. However, the comment lacks specificity and does not provide any detailed reasoning or examples to support this claim. It does not offer actionable feedback or suggestions for the authors to address the perceived lack of novelty. Without additional context or guidance, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the assumption among classes is not a common practice but notes that the formulation or definition in the manuscript is somewhat trivial. It suggests that the highlight lies in the optimization and theoretical property analysis, from which conclusions or insights can be gained. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the manuscript or what specific aspects of the optimization or theoretical property analysis should be emphasized. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption among classes, which is not a common practice, and mentions the formulation or definition in the manuscript. However, it does not specify which part of the paper discusses this assumption or formulation, making it weakly grounded. The comment is specific in noting that the highlight lies in optimization and theoretical property analysis, suggesting that insights can be gained from these aspects. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption among classes is not a common practice, but it acknowledges that the formulation or definition in the manuscript is somewhat trivial. The comment suggests that the highlight lies in the optimization and theoretical property analysis, from which conclusions or insights can be gained. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the optimization and theoretical property analysis are significant. Without these elements, the claim remains 3, as the authors may need to infer the importance of these aspects based on the comment alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the assumption among classes is not a common practice but notes that the formulation or definition in the manuscript is somewhat trivial. It suggests that the highlight lies in the optimization and theoretical property analysis, from which some conclusions or insights can be gained. While the comment identifies a potential area of interest, it lacks specific guidance or suggestions on how the authors might enhance their analysis or presentation of these aspects. The feedback is 3 as it points out a potential area of interest, but it does not provide actionable advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment raises a concern about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of the other views when the paraphrase similarity view consistently outperforms them. The reviewer suggests that a more detailed analysis of the differences and similarities between these views is needed to draw solid conclusions. While the comment implies that the authors should conduct a more comprehensive analysis, it does not provide explicit instructions on how to achieve this or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to conduct a more detailed analysis but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"multiview clustering approach\" and the \"paraphrase similarity view,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the effectiveness of the other views and suggesting that a more detailed analysis is needed to understand the differences and similarities between these views. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the effectiveness of the multiview clustering approach, specifically the usefulness of the other views when the paraphrase similarity view consistently outperforms them. The reviewer provides a specific example of how the different views help in clustering paraphrases of the word \"slip,\" but notes that there is no further analysis of how these views differ. This suggests that the claim is based on a lack of detailed analysis, which is a valid observation. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to conduct additional analysis to address the concern, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the effectiveness of the multiview clustering approach, particularly questioning the usefulness of the other views when the paraphrase similarity view consistently outperforms them. It highlights the need for a more detailed analysis of the differences and similarities between these views to draw solid conclusions about their usefulness. The comment provides a clear direction for improvement by suggesting that the authors should conduct a more comprehensive analysis to better understand the role of each view in the clustering process. This feedback is actionable and constructive, offering the authors a clear path to enhance their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide detailed experimental results on Wikipedia regarding the impact of model size on performance, as recent work by Ni et al. has shown that the scaling law applies to dense retrieval models. This feedback is explicit in its request for additional experimental results, which provides a clear action for the authors to take. However, it does not specify how the authors should present these results or what specific aspects of the scaling law should be explored. While the action is explicit, the lack of detailed guidance makes it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide detailed experimental results on Wikipedia regarding the impact of model size on performance, as recent work by Ni et al. has shown that the scaling law applies to dense retrieval models. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit grounding makes it difficult for the authors to identify the exact area needing revision. The comment is specific in its request for additional experimental results and references to Ni et al., but without clear grounding, it aligns with a score of 1.", "verifiability_rationale": "The review point claims that increasing the model size should not hurt performance, as recent work by Ni et al. has shown that the scaling law applies to dense retrieval models. The reviewer provides a reference to Ni et al., which supports the claim by suggesting that the scaling law is applicable. However, the comment could be strengthened by providing more detailed information about the specific findings of Ni et al. or how they relate to the authors\" work. Overall, the claim is 4, as it provides a reference but lacks full details, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claim that increasing the model size can hurt performance, suggesting that this is contrary to recent findings by Ni et al. regarding the scaling law in dense retrieval models. The comment provides a specific reference to Ni et al., which could help the authors understand the context of their findings and potentially revise their conclusions. However, the comment could be more helpful if it included a more detailed explanation of how the scaling law applies to dense retrieval models or how the authors might incorporate this information into their work. Overall, the comment is 4 as it points out a potential inconsistency and provides a reference for further exploration, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include related experiments that demonstrate the effectiveness of the \"information axis\" tool. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on what kind of experiments should be conducted or how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include related experiments to demonstrate the effectiveness of the \"information axis\" tool. However, it does not specify which part of the paper this suggestion pertains to, such as the conclusion or a specific section where the tool is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of related experiments, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper uses much analysis to justify the effectiveness of the \"information axis\" tool but lacks related experiments to demonstrate its practical application. The reviewer expresses curiosity about such experiments. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the paper lacks experimental evidence. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that the authors should include related experiments to demonstrate the effectiveness of the \"information axis\" tool. This feedback is 3 as it points out an area where the paper could be strengthened by providing practical applications or examples of the tool\"s utility. However, the comment lacks specificity and does not provide detailed guidance on what kind of experiments should be conducted or how to integrate them into the paper. While it highlights a meaningful area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point expresses interest in whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific steps to consider. The comment lacks actionable details, leaving the authors uncertain about how to respond or improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses interest in whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, nor does it provide details on what aspect of Greek is problematic or how it relates to the paper\"s content. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine the exact part being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a request for information, asking if other multilingual pretraining setups also struggle with Greek. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a question seeking clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment expresses interest in whether other multilingual pretraining setups also struggle with Greek. While it raises an intriguing question, it lacks specificity and does not provide any actionable feedback or suggestions for the authors to address this issue. The comment does not offer guidance on how the authors might investigate or resolve this potential problem, leaving the authors without a clear path for improvement. As a result, the comment is 1, as it does not provide any actionable insights or direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the text in lines 293295 makes the above point unclear and difficult for readers to understand. It suggests that the results are acceptable, but it does not provide specific guidance on how to clarify the text or improve its clarity. The action is implicit, as the authors need to infer that they should revise the text to make it clearer. Additionally, the comment lacks concrete details on how to achieve this clarity, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines (293295) where the issue is identified, allowing the authors to accurately pinpoint the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in the text and the difficulty for readers to understand and evaluate the results. The comment provides a clear direction for improvement by suggesting that the text should be clarified to make the point more understandable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 makes the point unclear and difficult for readers to understand. However, it does not provide any specific examples or detailed reasoning to support this claim. The comment lacks evidence or explanation, making it difficult for the authors to understand the basis of the critique. Without additional context or examples, the claim is not verifiable, as it does not provide sufficient information for the authors to address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text in lines 293295, suggesting that it makes the point unclear and difficult for readers to understand. This feedback is 3 as it points out a potential area for improvement, allowing the authors to revise their draft to enhance clarity. However, the comment lacks detailed guidance or suggestions on how to improve the clarity, such as proposing alternative phrasing or additional explanations. While it provides some direction, it could be more helpful with more specific feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant issue with the organization and clarity of the proofs, noting that they are difficult to follow and rigorously check for correctness. It specifically mentions Lemma 3 and questions whether the result holds for any polynomial function. This feedback provides a clear and explicit action for the authors to improve the organization and clarity of their proofs, as well as to address the specific concern about Lemma 3. The comment is 5 as it identifies a specific area for improvement and provides a concrete question to consider, giving the authors clear guidance on how to enhance their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of poor organization and clarity in the proofs, providing a concrete example with the question about Lemma 3. This level of detail helps the authors understand what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the proof is not well organized and difficult to follow, providing a specific example with Lemma 3. The reviewer questions whether the result holds for any polynomial function, which is a logical and relevant concern. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the overall organization and clarity of the proofs. While it provides a specific question, it does not offer a comprehensive analysis or evidence to support the broader claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or examples to be 5.", "helpfulness_rationale": "The review comment identifies a significant issue with the organization and clarity of the proofs, noting that they are difficult to follow and rigorously check for correctness. It provides a specific example by questioning whether the result in Lemma 3 holds for any polynomial function, which is a concrete and actionable suggestion for the authors to address. This feedback is clear and provides a clear direction for improvement, making it 4. However, it could be more helpful if it offered additional guidance on how to improve the organization or clarity of the proofs. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This is an explicit suggestion that provides a clear action for the authors to take. However, the comment does not specify which realworld datasets should be used or how to conduct the experiments, leaving some room for ambiguity. While the action is explicit, the lack of concrete details makes it 3.", "grounding_specificity_rationale": "The comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the use of realworld datasets, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This claim is based on the premise that the paper claims to address realistic scenarios, which is a logical reasoning. However, the comment lacks specific examples or references to support the claim that realworld datasets are more appropriate for the outofdistribution setting. This makes the claim 3, as it provides a logical basis but requires more detailed justification or evidence to be fully convincing.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This feedback is clear and actionable, as it provides a specific direction for improving the experimental setup to better align with the paper\"s claim of addressing realistic scenarios. However, the comment could be more helpful if it included suggestions on which realworld datasets to use or how to adapt the experiments to these datasets. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their experimental design."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. While the suggestion is explicit, it lacks concrete details on how to implement this change, such as whether the smoothed GT shapes should be added as an overlay or as a separate figure. The comment also mentions a \"minor concern,\" but this is not elaborated upon, leaving the authors uncertain about its significance. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in suggesting a particular change to improve the clarity of the figures, but without explicit references to the figures, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to improve the understanding of the reconstruction quality. This is a request for clarification or enhancement, not a claim or opinion that requires verification. It is a factual statement that does not need justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests a specific improvement to the figures by recommending the inclusion of smoothed GT shapes in Figures 3 and 5. This suggestion is clear and actionable, as it provides a concrete way for the authors to enhance the clarity and understanding of their results. By showing the smoothed GT shapes, the authors can better demonstrate the quality of the reconstruction, which is a valuable addition to the figures. However, the comment does not elaborate on why this suggestion is important or how it would impact the overall understanding of the paper. While it offers a specific improvement, it could be more helpful with additional context or explanation. Therefore, the comment is rated as 4, as it provides actionable feedback but lacks full comprehensiveness."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include important references for domain adaptation and to discuss them in the revised manuscript. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks important references for domain adaptation and instructs the authors to include them in the revised manuscript. However, it does not specify which references are missing or where in the paper these references should be included. This makes it difficult for the authors to pinpoint the exact parts of the paper that need revision. The comment is specific in its request for references but lacks grounding as it does not identify a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation and suggests that the authors should include them. However, the comment does not provide specific examples of the missing references or explain why they are crucial. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of important references for domain adaptation. It provides a clear and actionable suggestion for the authors to include these references and discuss them in the revised manuscript. This feedback is valuable as it directs the authors to a specific area for improvement, ensuring that their work is more comprehensive and aligned with current literature. However, the comment could be more helpful if it specified which references are missing or why they are important. Overall, the comment is 4 as it guides the authors toward enhancing the depth and relevance of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range and that the distance to the next best model is suspiciously large. However, it does not provide explicit guidance on how the authors should address these concerns or improve their draft. The comment implies that the authors should investigate the hyperparameter tuning process and the distance to the next best model, but it lacks concrete steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range and that the distance to the next best model is suspiciously large. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does provide some specificity by suggesting that the authors should investigate the hyperparameter tuning process and the distance to the next best model. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range and that the distance to the next best model is suspiciously large. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some basis for concern but requires more detailed justification.", "helpfulness_rationale": "The review comment raises a concern about the SCNN getting \"lucky\" on domain pricing, suggesting that the chosen hyperparameters might be at the end of the searched range and that the distance to the next best model is suspiciously large. This feedback is 3 as it points out a potential issue with the hyperparameter tuning process, which could impact the reliability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve their methodology. To be more helpful, the comment could include recommendations on how to validate the hyperparameter choices or suggest alternative approaches to ensure the results are not biased. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide explicit guidance on what needs to be clarified or improved. The authors can infer that they need to provide more detailed information about the corpora and datasets used in the experiments, but the comment lacks concrete suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment mentions \"some aspects of the experimental setup\" as being unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not specify which part of the paper these aspects are discussed in, making it weakly grounded. The comment is specific in identifying the issue with corpora and datasets, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks concrete evidence or references to substantiate the assertion, making it difficult for the authors to understand and address the issue. As a result, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the experimental setup, noting that some aspects are unclear or poorly motivated, particularly regarding corpora and datasets. This feedback is 3 as it points out a potential area for improvement, prompting the authors to clarify and motivate their experimental choices. However, the comment lacks detailed guidance or suggestions on how to address these issues, such as specific questions to consider or examples of how to improve the clarity. While it provides some direction, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It also points out that the authors mention the use of 4 hourglass modules but do not specify the size of each module. This feedback implies that the authors should provide more detailed information about the model\"s size and structure, which is an implicit action. However, the comment does not explicitly instruct the authors to include this information, and it lacks concrete guidance on how to present this data. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It also points out that the authors mention the use of 4 hourglass modules but do not specify the size of each module. This provides a clear indication of what needs to be addressed, namely the size and structure of the model. However, the comment does not explicitly mention which part of the paper this issue pertains to, such as a specific section or table. While the authors can infer that it relates to the methodology or results sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what is missing, making it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises a question about the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It points out that the authors mention the use of 4 hourglass modules but do not specify the size of each module. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the size of the model, specifically its depth or number of parameters, in comparison to competing approaches. It points out that the authors mention the use of 4 hourglass modules but do not specify the size of each module. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about the model\"s size and structure, which is crucial for understanding its performance and comparison with other models. By addressing this feedback, the authors can enhance the comprehensiveness and clarity of their draft. However, the comment could be more helpful if it suggested specific ways to present this information or provided examples of how other papers have done so. Overall, the comment is 4, as it directs the authors to an important area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this critique or improve their work. The comment lacks actionable advice, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It also mentions that the metric perspective analysis does not seem to work based on the existing content of the paper. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact sections that need attention. While the authors might infer that it relates to the theoretical sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in its critique of the metric learning theory, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper does not provide better results compared to previous theoretical results. It also suggests that the metric perspective analysis does not seem to work based on the existing content of the paper. However, the comment lacks specific references or detailed reasoning to support these claims. Without explicit evidence or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment critiques the metric learning theory in the paper, suggesting that it does not provide better results compared to previous theoretical results. It also claims that the metric perspective analysis does not seem to work based on the existing content of the paper. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address the critique or enhance their work. As a result, the comment is 1, as it does not provide the authors with any actionable insights or direction for improving their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential confusion in the use of the symbol \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. However, it does not provide any explicit guidance or suggestions on how to address this confusion. The authors are left to infer that they should clarify the usage of \"r\" in their paper, but without specific instructions on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of confusion regarding the use of the symbol \"r\" in both contexts. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to explain why this usage is confusing or how it could be improved. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper, specifically the use of the symbol \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and specific observation that could help the authors clarify their notation and improve the readability of their work. However, the comment does not provide any suggestions or guidance on how to resolve this issue, such as recommending alternative notations or explaining the potential impact of the confusion. While it highlights a problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. However, the comment does not provide explicit guidance or suggestions on how to address this issue or what actions the authors should take to improve their draft. The question is posed in a way that requires the authors to infer the need for additional analysis or clarification, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or figure where this discussion is relevant. Additionally, while it raises a concern, it does not provide specific guidance on how to address this issue or what changes might be necessary. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the potential impact of not knowing that a test example is crucially different, such as the patient in Figure 8 being British. It suggests that using the American corpus to explain this example might be problematic. This is a relevant concern that could affect the validity and generalizability of the results. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their methodology to account for such differences. While it highlights a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider a critical aspect of their work but does not fully support them in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. While the comment implies that the authors should consider using a different dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the choice of dataset, specifically the WebQuestionsSP dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear rationale for why the authors should consider using the more popular WebQuestions benchmark set instead, explaining that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, facilitating direct comparison with mainstream QA research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. The reviewer provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. This reasoning is logical and provides a clear basis for the suggestion, making the claim 4. However, the comment could be strengthened by referencing specific studies or examples that support the claim about the advantages of using WebQuestions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment questions the choice of the WebQuestionsSP dataset as the testbed and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, stating that NSM only requires weak supervision and that using WebQuestions would be more intuitive and straightforward, allowing for direct comparison with mainstream QA research. This feedback is clear and actionable, as it offers a specific alternative dataset that could enhance the paper\"s relevance and comparability. By suggesting a change in the dataset, the comment provides the authors with a concrete step to improve their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of making claims about the desirability of sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. While the comment implies that the authors should provide evidence for their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to demonstrate the benefits or what evidence is needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the need for certain claims regarding sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. However, it does not specify which part of the paper these claims are made in, making it weakly grounded. The comment is specific in its critique of the claims and suggests that the authors should provide evidence for their assertions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of making claims about the desirability of sparsity in training and suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated. The reviewer provides a logical reasoning by pointing out that in the age of parallelized computation, the reduction in FLOPs may not necessarily lead to cost savings unless it can be shown to impact practical implementations. However, the comment lacks specific examples or references to support the claim that sparsity is not desirable or that the benefits are not evident. This makes the claim 3, as it provides a logical argument but requires more detailed evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the necessity of certain claims made in the paper regarding the desirability of sparsity in training. It suggests that any potential benefits, such as improved training speed or reduced FLOPs, need to be demonstrated or substantiated with evidence. While the comment identifies a potential weakness in the paper, it lacks specific guidance or suggestions on how the authors might address this issue or provide the necessary evidence. The feedback is 3 as it prompts the authors to consider the validity of their claims, but it does not offer actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a lack of clarity in the model design, specifically mentioning the fragmentation or absence of model architecture and learning details. It suggests that the authors could provide a plot of the model illustration, pseudocode table, or code repository to improve clarity. Additionally, the comment emphasizes the importance of demonstrating integrated details, especially since Neurochaos Learning is not a wellknown method. This feedback is explicit and provides concrete suggestions on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"model design\" and \"learning details,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the fragmentation or absence of model architecture and learning details, suggesting that the authors provide a plot of the model illustration, pseudocode table, or code repository. Additionally, the comment highlights the importance of demonstrating integrated details, especially since Neurochaos Learning is not a wellknown method. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the model design is unclear due to fragmented or missing details, suggesting that the authors provide a plot of the model illustration, pseudocode table, or code repository. The comment also emphasizes the importance of demonstrating integrated details, especially since Neurochaos Learning is not a wellknown method. This claim is 3 as it provides a logical reasoning for the need to clarify the model design, but it lacks specific examples or references to support the assertion that the current design is unclear. The suggestion to provide additional details is reasonable, but the comment could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the model design, noting that the architecture and learning details are fragmented or missing. It provides specific suggestions for improvement, such as including a plot of the model illustration, pseudocode table, or code repository. This feedback is actionable and constructive, as it guides the authors on how to enhance the transparency and reproducibility of their work, particularly given the unfamiliarity of the Neurochaos Learning method. By addressing these points, the authors can significantly improve the comprehensibility and utility of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for clearer clarification of the advantages of DIMES, specifically its ability to overcome generalization gaps in the finetuning step. It also suggests comparing DIMES with other methods on TSP100, both with and without metalearning. While the comment implies that the authors should provide more detailed explanations and comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer what needs to be done but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"generalization to the specific TSP instances (the finetuning step in DIMES),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified, namely the advantages of DIMES in overcoming generalization gaps and the need for a comparison with other methods on TSP100. This provides clear guidance on what the authors should address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should clarify the advantages of DIMES in overcoming generalization gaps and provides a specific suggestion for comparison with other methods on TSP100. However, the comment lacks detailed reasoning or evidence to support the claim that DIMES has unique advantages or that a comparison with other methods is necessary. The suggestion is 3 as it highlights a potential area for improvement, but it requires more detailed justification or examples to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should clarify the advantages of DIMES in overcoming generalization gaps, particularly in the finetuning step. It also proposes a comparison of DIMES with other methods on TSP100, both with and without metalearning, to further demonstrate the paper\"s contributions. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the clarity and depth of the paper. However, it could be more helpful if it included specific examples or references to guide the authors in making these comparisons. Overall, the comment is 4, as it directs the authors to enhance the paper\"s clarity and comparative analysis, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim that the readability of RC datasets does not directly affect question difficulty. It suggests that this claim depends on the method or features used for answer detection, such as POS/dependency parse features. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific changes to their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the impact of different methods or features on their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim made in the paper regarding the relationship between dataset readability and question difficulty. It suggests that this claim depends on the method or features used for answer detection, such as POS/dependency parse features. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the dataset analysis or methodology sections, but this inference is not direct. The comment is specific in detailing the issue with the claim, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point challenges the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this depends on the method or features used for answer detection, such as POS/dependency parse features. The comment provides a logical reasoning by pointing out a potential dependency on the method used, which is a valid critique. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore this aspect to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim that the readability of RC datasets does not directly affect question difficulty. It suggests that this claim may depend on the method or features used for answer detection, such as POS/dependency parse features. This feedback is 3 as it points out a specific area where the authors might need to clarify or expand their analysis. However, the comment does not provide detailed guidance on how to address this issue or suggest specific experiments or analyses to conduct. While it highlights a potential weakness, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a question about the geometry of the vector space used in the morphfitting results and suggests that the authors provide evidence that the space is meaningful. It also implies that the authors should analyze whether the morphfitting results lead to a more meaningful space. While the comment does not explicitly instruct the authors to perform these analyses, it does provide a clear direction for what the authors should focus on. The action is implicit but concrete, as the authors know exactly what kind of analysis is needed to address the concern. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"geometry of the space\" and \"morphfitting results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for analysis, asking whether the geometry of the space is meaningful and whether specific semantics can be assigned to different inflections. The comment also suggests analyzing whether \"looking\"  \"look\" + \"walk\" = \"walking,\" which adds further detail to the specific analysis required. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the geometry of the vector space used in the morphfitting results, suggesting that the authors provide evidence that the space is meaningful. It also implies that the authors should analyze whether the morphfitting results lead to a more meaningful space. However, the comment lacks specific examples or references to support the claim that the geometry of the space is not meaningful. While it provides a logical reasoning for the suggestion, it does not fully substantiate the claim with detailed evidence or examples. Therefore, the comment is 3, as it requires additional information to fully support the claim.", "helpfulness_rationale": "The review comment raises a critical question about the geometry of the vector space used in the morphfitting results, suggesting that the authors should provide evidence that the space is meaningful. It also implies that the authors should analyze whether the morphfitting results lead to a more meaningful space, not just better embeddings. This feedback is clear and actionable, as it prompts the authors to consider the semantic implications of their work and provides a specific example (\"looking\"  \"look\" + \"walk\" = \"walking\") to guide their analysis. By addressing these points, the authors can enhance the interpretability and significance of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. However, the comment does not provide explicit guidance on how to improve the writing quality or what specific changes should be made to address the issues with the related work section. The action is implicit and somewhat vague, as the authors are left to infer what specific improvements are needed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment provides a general observation about the writing quality, specifically mentioning that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. However, the comment does not specify which sections of the paper these issues pertain to, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, while it identifies a lack of coverage in the related work section, it does not provide specific examples or references to guide the authors on what should be included. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the writing quality of the paper should be improved, specifically mentioning that the authors spend the same space on explaining basic memory networks and then the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement: the writing quality and the related work section. It points out that the authors spend the same space on explaining basic memory networks and then the forward model, suggesting that this could be improved by focusing on more relevant content. Additionally, it notes that the related work section lacks coverage of more reinforcement learning tasks in the literature, which is an important area for the paper to address. However, the comment does not provide detailed suggestions or examples on how to enhance the writing quality or what specific tasks should be included in the related work section. While it highlights important areas for improvement, the feedback could be more actionable and comprehensive. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be present in a simulation. However, it does not provide any explicit or implicit actions for the authors to take. The question is not phrased as a suggestion or a request for clarification, leaving the authors without any guidance on how to address the issue. As a result, the comment lacks actionability, as it does not offer any direction for improvement or change in the draft. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be present in a simulation. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references to the paper, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity as it does not provide guidance on what aspects of the simulation are being questioned or how to address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the number of different kinds of physical interactions that can be present in a simulation. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the number of different kinds of physical interactions that can be present in a simulation. While it highlights an area of potential interest or complexity, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this question or what implications it might have for their work. As a result, the comment is not helpful, as it does not offer any actionable insights or direction for the authors to enhance their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights specific issues with the model comparison, noting that the chosen datasets are not adequate for a thorough comparison due to the absence of categorical features and the use of onehot encoding. The comment provides a clear and explicit action for the authors to take, which is to expand the dataset selection to include more diverse features and consider using onehot encoding for categorical features. The feedback is concrete and directly guides the authors on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"key contribution\" of the paper, which is the \"thorough comparison of models on a wide range of datasets.\" It also specifies the issue with the dataset selection, noting that only one dataset has categorical features, while all others have exclusively numerical features. This is a clear indication of where the issue lies. The comment is also specific because it details the reasons for the inadequacy of the dataset selection, such as the omission of categorical features and the potential impact on conclusions due to the lack of onehot encoding. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the chosen dataset selection is inadequate for a thorough comparison due to the absence of categorical features and the use of onehot encoding. The reviewer provides a logical reasoning by explaining that categorical features are generally more challenging for deep learning models, which could affect the conclusions drawn from the comparison. However, the comment lacks specific examples or references to support the claim that the chosen datasets are insufficient. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment provides a detailed critique of the model comparison section, highlighting specific issues with the dataset selection. It points out that the chosen datasets are inadequate for a thorough comparison due to the absence of categorical features, which are generally more challenging for deep learning models. The comment also notes that the authors do not employ onehot encoding for the dataset with categorical features, which could negatively impact performance for some models. This feedback is clear and actionable, as it identifies specific areas for improvement and suggests ways to enhance the dataset selection and analysis. By addressing these issues, the authors can significantly strengthen their model comparison and contribute to a more comprehensive evaluation of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the authors\" approach to pruning, noting that it primarily works with large networks trained in distributed settings. It suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this aspect of their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"pruning\" and \"large networks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential need to find global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that pruning primarily works with large networks trained in distributed settings and suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that finding global top Q values is necessary or how it would impact acceleration techniques. The lack of detailed justification makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some insight but requires more detailed evidence or explanation to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" approach to pruning, noting that it primarily works with large networks trained in distributed settings. It suggests that the authors should consider finding global top Q values of the metric over the average of gradients to avoid breaking acceleration techniques like quantization and sparsification. This feedback is 3 as it points out a specific area where the authors might need to address potential limitations or tradeoffs in their approach. However, the comment could be more helpful if it provided additional context or examples on how to implement this suggestion or why it is important. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the potential swapping of subfigures in Figures 1 and 2. While it implies that the authors should check for this mistake, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to verify or correct the issue. The authors can infer that they need to check the figures for consistency, but the comment does not provide detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it raises a question about the potential swapping of subfigures, which provides clear guidance on what needs to be checked for accuracy. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question asking about the potential swapping of subfigures in Figures 1 and 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual inquiry, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the potential swapping of subfigures in Figures 1 and 2. While it identifies a potential issue, it lacks depth and does not provide any guidance or suggestions on how the authors might address this concern. The comment does not offer actionable feedback or insights into how the authors might verify or correct the issue, leaving the authors with only a vague indication of a possible problem. Therefore, the comment is 2, as it points out a potential issue but does not provide sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the positive impact of the dropout probe, noting that it improves sensitivity and identifies a causal role for syntactic representations. However, it also raises a concern about the potential increase in false positives. The reviewer suggests that this should be a substantial part of the discussion, implying that the authors should address this issue in their paper. While the comment highlights an important consideration, it does not provide explicit guidance on how to incorporate this discussion into the paper or what specific aspects should be addressed. The action is implicit and somewhat vague, as the authors know they need to discuss the potential risks but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"dropout probe,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the positive impact of the dropout probe in improving sensitivity and identifying a causal role for syntactic representations, while also raising a concern about the potential increase in false positives. The comment suggests that this issue should be a substantial part of the discussion, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the positive impact of the dropout probe in improving sensitivity and identifying a causal role for syntactic representations. It also raises a concern about the potential increase in false positives, suggesting that this should be a substantial part of the discussion. The comment provides a logical reasoning by pointing out the potential tradeoff between sensitivity and false positives, which is a common consideration in experimental design. However, it lacks specific examples or references to support the claim about the risk of false positives, making it 3. The authors would need to further explore and substantiate this point themselves to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the positive impact of the dropout probe in improving sensitivity and identifying a causal role for syntactic representations. It also raises a concern about the potential increase in false positives, suggesting that this should be a substantial part of the discussion. This feedback is 3 as it highlights an important consideration that the authors should address in their paper. However, it lacks specific guidance on how to incorporate this discussion or what aspects to focus on, which limits its usefulness. The comment provides a direction for the authors to consider but does not offer detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the authors\" claim and the actual content of the paper. It points out that the regret bound for the proposed minibatch method is claimed to be in the appendix, but the reviewer could not find it in the supplementary material. The comment references an external work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which could provide a basis for the authors to address the issue. However, the comment does not explicitly instruct the authors to include the regret bound or provide specific guidance on how to address the discrepancy. The action is implicit and somewhat vague, as the authors need to infer that they should either clarify the claim or provide the missing information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the regret bound for the proposed minibatch method being in the appendix, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the reviewer could not find the regret bound in the supplementary material, providing clear guidance on what needs to be addressed. Additionally, the comment references an external work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which could help the authors understand the context of the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have stated that the regret bound for the proposed minibatch method is in the appendix, but the reviewer could not find it in the supplementary material. The comment references an external work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which could provide a basis for the claim. However, the comment does not provide specific details or examples from the external work to substantiate the claim, making it 3. The authors would need to investigate the referenced work to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the authors\" claim and the actual content of the paper. It points out that the regret bound for the proposed minibatch method is claimed to be in the appendix, but the reviewer could not find it in the supplementary material. This feedback is valuable as it highlights a potential error or omission in the paper, prompting the authors to verify and correct their claims. However, the comment could be more helpful if it provided specific guidance on how to address the issue, such as suggesting where the regret bound should be included or offering examples of similar approaches. Overall, the comment is 3 as it directs the authors\" attention to a critical area that needs clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the paper for not discussing and comparing various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific methods for comparison. The action is implicit, as the authors can infer that they need to include a discussion and comparison of these methods, but the comment lacks concrete details on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the paper for not discussing and comparing various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper this critique pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in detailing the missing discussion and comparison, but it lacks grounding as it does not explicitly mention a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of these methods and their potential impact on the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not discuss and compare various exploration methods in RL literature, such as countbased methods and intrinsic motivations like RND and ICM. This feedback is valuable as it highlights an important area for improvement that could enhance the comprehensiveness and depth of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular methods to include or ways to structure the comparison. While it points out a critical area for enhancement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While the comment identifies areas that need clarification or improvement, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors can infer that they need to provide more detailed explanations and potentially conduct additional analyses, but the feedback lacks specificity and actionable steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the coefficient in line 307 and the lack of hyperparameter details, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact parts of the paper that need revision. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While the comment identifies specific areas that need clarification or improvement, it does not provide detailed reasoning or evidence to support these claims. The lack of specific examples or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the paper, including the impact of inference slowdown, the coefficient in line 307, the lack of hyperparameter details, and the clarity of the writing. While it identifies specific areas that need clarification or improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The comment highlights potential weaknesses but lacks actionable advice, making it 3. The authors are given some direction but are left to figure out the specifics of how to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific weakness of the proposed method, namely that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to mitigate this weakness. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper discusses this method or where the comparison with PQ is made. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in this context. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, which is presented as a main weakness of the method. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or data to support the assertion, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed method, noting that it performs worse than PQ when a small code length is allowed. This is presented as a main weakness of the method, which is a valuable observation for the authors to consider. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their method. Without actionable feedback or specific recommendations, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it highlights a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data that includes various languages and nationalities. The reviewer expresses curiosity about potential biases and interesting observations that could be made by comparing these different languages/nationalities. While the comment implies that the authors should expand their analysis to include more detailed comparisons, it does not provide explicit instructions on how to achieve this or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more detailed analyses and comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data and the potential for interesting observations by comparing different languages/nationalities. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or analysis. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting a potential area for improvement, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the analyses could be more detailed, specifically mentioning the \"language/nationality\" data and the potential for interesting observations by comparing different languages/nationalities. The reviewer provides a specific example of the data, which includes Japanese, Chinese, English, Arabic, and German, indicating that there are approximately 20 different types. This provides some context and a basis for the claim that biases might exist. However, the comment lacks detailed reasoning or specific examples of how these biases could be analyzed or what observations could be made. While the suggestion is logical, it requires more elaboration to be 5. Therefore, the comment is 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the analyses could be more detailed. It provides a concrete example by mentioning the \"language/nationality\" data, which includes various languages and nationalities, and points out that biases might exist among these different groups. The reviewer expresses curiosity about potential observations that could be made by comparing these different languages/nationalities. This feedback is clear and actionable, as it directs the authors to consider expanding their analysis to include more detailed comparisons and potentially uncover interesting insights. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it provides a clear direction for enhancing the paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper should include tasks beyond link prediction where PE (position encoding) is important. However, it does not provide any explicit or implicit guidance on how to identify or implement these additional tasks. The comment lacks concrete details or suggestions on what specific tasks should be included or how to incorporate them into the paper. As a result, the authors are left without a clear understanding of what actions to take to address this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper should include tasks beyond link prediction where position encoding (PE) is important. However, it does not specify which part of the paper this suggestion pertains to, nor does it provide details on what specific tasks should be included or how they should be integrated. Without explicit references to sections or examples, the authors cannot confidently determine which part of the paper needs revision. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that it is expected to see a variety of tasks beyond link prediction where position encoding (PE) is important. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this expectation. Without specific references or detailed explanations, the claim remains vague and difficult for the authors to understand or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should include tasks beyond link prediction where position encoding (PE) is important. While it identifies a potential area for expansion, the comment lacks specificity and does not provide any guidance on how to incorporate these additional tasks or what specific tasks might be relevant. Without actionable suggestions or examples, the authors are left with a general idea of what could be improved but without a clear path to implementation. Therefore, the comment is 2, as it provides some insight but lacks depth and direction."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that footnotes are used excessively in the paper, which is distracting and should be moved into the main body of the paper. It provides a specific example of where this could be done, suggesting that details around parameter settings could be moved to the appendix. This feedback is clear and provides concrete guidance on how to improve the draft by reducing the use of footnotes and reorganizing content. The authors know exactly what action to take and how to implement it, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of footnotes, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the excessive use of footnotes and suggests moving content from the footnotes to the main body of the paper. Additionally, it provides a concrete example of where this could be done, such as moving details about parameter settings to the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that footnotes are used excessively in the paper, which is distracting and should be moved into the main body of the paper. The reviewer provides a specific example by suggesting that details around parameter settings could be moved to the appendix. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more examples or specific instances of excessive footnotes, which would further support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the excessive use of footnotes in the paper, which is distracting and should be addressed. It provides a clear and actionable suggestion to move content from the footnotes into the main body of the paper, particularly mentioning details around parameter settings that could be moved to the appendix. This feedback is valuable as it offers a concrete way for the authors to improve the readability and organization of their paper. However, the comment could be more helpful if it provided additional context or examples of other content that could be moved to the main body. Overall, the comment is 4 as it directs the authors toward a specific improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a set of fewshot demonstrations should be included, with the help of domain experts, and that a discussion about this would be appreciated. It also questions the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks relevance. However, the comment does not provide explicit guidance on how to implement the suggestion for fewshot demonstrations or how to address the concern about zeroshot generation results. The actions are implicit and somewhat vague, as the authors are left to infer what specific steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the inclusion of zeroshot generation results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks relevance. The comment further suggests that a set of fewshot demonstrations should be included, with the help of domain experts, and that a discussion about this would be appreciated. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point raises a claim about the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks relevance. The reviewer provides a logical reasoning by questioning the relevance of zeroshot results in the context of the paper, which is a valid point. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the reviewer\"s point and provide additional justification or context to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks relevance in the context of the paper. It also suggests that a set of fewshot demonstrations should be included, with the help of domain experts, and that a discussion about this would be appreciated. This feedback is 3 as it points out a specific area for improvement and provides a suggestion for enhancing the paper. However, the comment could be more helpful if it offered more detailed guidance on how to incorporate the fewshot demonstrations or why they are more relevant. Overall, the comment provides some direction but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should acknowledge older works in the related works section, specifically mentioning that there is a long line of work using supervised, multilingual systems. While the comment implies that the authors should include references to older works, it does not provide specific examples or guidance on which older works should be acknowledged. The action is implicit and somewhat vague, as the authors need to infer which older works are relevant and how to incorporate them into the related works section. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works in the context of multilingual systems, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works in the related works section, specifically mentioning the use of supervised, multilingual systems. However, the comment does not provide specific examples or references to older works that should be acknowledged, making it difficult for the authors to understand which works are being referred to. This lack of detailed support or examples makes the claim 3, as the authors need to infer which works are relevant and how to incorporate them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works in the related works section, specifically mentioning the use of supervised, multilingual systems. This feedback is 3 as it points out a potential gap in the literature review, encouraging the authors to be more comprehensive in their coverage. However, the comment lacks specific examples or references to older works that should be included, which would make it more actionable and helpful. By suggesting a direction for improvement but not providing detailed guidance, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights concerns about the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve the time complexity. The comment lacks actionable details, such as recommending optimizations or alternative approaches, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the concerns about time complexity, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity seems high, providing three reasons: the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. However, the comment lacks specific examples, detailed explanations, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the large number of hidden units. This feedback is 3 as it points out areas that could be improved to enhance the efficiency of the method. However, the comment lacks specific suggestions or guidance on how the authors might address these issues, such as recommending optimizations or alternative approaches. While it highlights a concern, it does not provide actionable steps for improvement, making it 3 but incomplete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback provides a clear and explicit action for the authors to take, which is to modify the figures to include this information. The suggestion is concrete, as it specifies exactly what needs to be changed to improve the clarity of the figures. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figures,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending that the figures should specify \"pretrained solution encoders & solution decoders\" to enhance clarity. This level of detail guides the authors on what changes to make to improve the figures. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This claim is based on a logical reasoning that the current labeling is unclear and could be improved by specifying the types of encoders and decoders used. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the exact changes needed to improve clarity, which could be challenging without further guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the figures by recommending that they specify \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback is clear and actionable, offering a concrete way for the authors to enhance the clarity and comprehensibility of their figures. By addressing this suggestion, the authors can improve the readability and understanding of their work for both reviewers and readers. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment implies that the authors should make these comparisons, it does not provide explicit instructions on how to implement them or why these comparisons are important. The action is implicit and somewhat vague, as the authors need to infer the need for these comparisons and the reasoning behind them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental results or methodology sections. The suggestion to include comparisons with specific methods is specific, but the comment lacks grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment provides some context by mentioning specific methods, it lacks detailed reasoning or evidence to support why these comparisons are necessary or how they would enhance the paper. The claim is 3, as it highlights potential areas for improvement but lacks specific justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper. It suggests that the authors should include comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe,\" which could provide a more comprehensive evaluation of the method. Additionally, it questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment highlights important areas for improvement, it lacks specific guidance on how to implement these comparisons or why the occlusion experiment is not relevant. The feedback is 3 as it points out potential weaknesses and areas for enhancement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the extraction of parts of sentences and documents and the potential impact of extraction rules on the experiment. It explicitly requests a more detailed analysis. While the comment does not provide specific instructions on how to conduct this analysis, it clearly identifies the areas that need further exploration. The authors know that they need to provide a more detailed analysis of the extraction process and its effects on the experiment. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment raises questions about the extraction of parts of sentences and documents and the potential impact of extraction rules on the experiment. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for a more detailed analysis, but without clear references to specific sections or examples, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the extraction process and its potential impact on the experiment. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the extraction process and its potential impact on the experiment. It specifically asks how the parts of sentences and documents are extracted and whether the extraction rules have any effect on the experiment. This feedback is clear and actionable, as it prompts the authors to provide a more detailed analysis of their extraction process. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects to focus on. Despite this, the comment provides valuable guidance for improving the clarity and depth of the paper, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises a question about the application of the meta sampler, specifically whether it is used in a decoupled manner and when it is applied. It explicitly asks for more discussion on this aspect and when the meta sampler is started. This provides clear and direct actions for the authors to take, such as providing additional discussion and specifying the epoch at which the meta sampler is applied. The feedback is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the meta sampler,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for more discussion on the application of the meta sampler and when it is started, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on the application of the meta sampler. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the application of the meta sampler, inquiring whether it is used in a decoupled manner and when it is applied. It explicitly asks for more discussion on this aspect and requests information about the epoch at which the meta sampler is started. This feedback is clear and actionable, providing the authors with a direct request for additional information and discussion that could enhance the clarity and comprehensiveness of their paper. By addressing these points, the authors can improve the transparency and depth of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use fairnessaware metrics like Equality odds (EO) and conduct more experiments on datasets like COMPAS and Drug Consumption. It also encourages the authors to follow a specific AAAI paper that they have cited. While the comment implies that the authors should incorporate these suggestions, it does not provide explicit instructions on how to implement them or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of a \"vanilla metric\" and the lack of related fairnessaware metrics like Equality odds (EO). It also suggests conducting more experiments on datasets like COMPAS and Drug Consumption, referencing a specific AAAI paper. This provides clear guidance on what needs to be addressed and where, making it easy for the authors to identify the relevant parts of the paper. The comment is also specific because it provides a clear suggestion for improvement and references a relevant paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors use their own defined \"vanilla metric\" and lack related fairnessaware metrics like Equality odds (EO). It suggests conducting more experiments on datasets like COMPAS and Drug Consumption and references a specific AAAI paper. The claim is 3 as it provides a specific suggestion for improvement and references a relevant paper, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to explore the referenced paper to understand the context fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the use of a \"vanilla metric\" without considering related fairnessaware metrics like Equality odds (EO). It suggests that the authors conduct more experiments on datasets like COMPAS and Drug Consumption, referencing a specific AAAI paper for guidance. This feedback is clear and actionable, providing the authors with a concrete direction for improving their work by incorporating fairnessaware metrics and expanding their dataset analysis. However, the comment could be more helpful if it included a more detailed explanation of why these metrics are important or how they might impact the results. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to rephrase a section of the paper (lines 107114) as a remark, an aside in the Discussion section, or to remove it entirely. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 107114, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the content is speculative or overly opinionated and suggests that it should be rephrased as a remark or an aside in the Discussion section or removed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that lines 107114 are speculative or overly opinionated, suggesting that they should be rephrased as a remark or an aside in the Discussion section or removed. However, the comment does not provide any specific reasoning or examples to support why these lines are considered speculative or overly opinionated. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (lines 107114) as being speculative or overly opinionated. It provides a clear and actionable suggestion to rephrase this section as a remark or an aside in the Discussion section or to remove it entirely. This feedback is valuable as it guides the authors on how to improve the clarity and focus of their work by either rephrasing or removing content that may be perceived as subjective or unnecessary. However, the comment could be more helpful if it provided additional context or examples to further clarify the issue. Overall, the comment is 4, as it offers a clear direction for improvement but lacks depth in its explanation."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement resulting from the changes proposed in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to incorporate these baselines or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes proposed in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results discussion. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of these baselines, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes proposed in the paper. However, the comment does not provide any reasoning or evidence to support why these specific baselines are relevant or how they would contribute to the verification process. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests considering additional baselines, specifically Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes proposed in the paper. This feedback is 3 as it provides a specific suggestion for enhancing the experimental validation of the paper. However, the comment could be more helpful if it explained why these particular baselines are relevant or how they would contribute to the verification process. Additionally, it does not offer guidance on how to incorporate these baselines or what specific aspects to focus on. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies two missing elements in the paper: the value of neighborhood size h and an analysis of its influence on the model\"s performance, as well as the use of different hyperparameter sets per dataset. It suggests that the authors provide insights into how performance varies with a constant set of parameters. These actions are clear and concrete, giving the authors specific directions on what to include in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"value of neighborhood size h\" and the \"analysis of its influence over the model\"s performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what is missing, namely an analysis of the influence of h on performance and the use of different hyperparameter sets per dataset. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an analysis of the value of neighborhood size h and its influence on the model\"s performance, which is considered a key parameter of the proposed strategy. It also notes the use of different hyperparameter sets per dataset, suggesting that this is not ideal. The comment provides a logical reasoning for the importance of analyzing the neighborhood size and its impact on performance, as well as the need for consistency in hyperparameter sets. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the importance of these elements based on the provided reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two important areas for improvement in the paper. First, it points out the absence of an analysis of the value of neighborhood size h and its influence on the model\"s performance, which is a key parameter of the proposed strategy. This feedback is actionable as it suggests that the authors should include an analysis of the impact of h on the model\"s performance, providing readers with valuable insights. Second, the comment highlights the use of different hyperparameter sets per dataset, which is not ideal, and asks for insights into how performance varies with a constant set of parameters. This feedback is clear and actionable, offering the authors specific directions for enhancing their draft. Therefore, the comment is 4, as it provides detailed and constructive suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. While it does not explicitly instruct the authors to address this issue, it implies that the authors should consider and discuss this aspect in their paper. The question is somewhat vague, as it does not provide specific guidance on how to address the issue or what kind of analysis or discussion would be most beneficial. However, the authors can infer that they need to explore and report on the effects of missing data on the model. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the effects of missing data and how the model handles it, providing a clear direction for the authors to consider. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. The comment does not present a claim or opinion but rather poses a question seeking clarification. It does not require verification as it is a request for information or clarification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically addressing the effects of missing modalities on the construction of polynomial tensors. It prompts the authors to consider the potential compounding effects of missing data and how the model might handle such situations. This feedback is 3 as it encourages the authors to explore a critical aspect of their work that could impact the model\"s performance and robustness. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of similar approaches in the literature. Overall, the comment is 3, as it directs the authors\" attention to an important area for further exploration and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the SST dataset, specifically asking for statistics on the times negation or intensity words take effect. It suggests showing the frequency of words like \"nothing\" and how often they change the polarity of the context. While the comment implies that the authors should provide these statistics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to analyze the dataset further but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the SST dataset, suggesting that the authors should provide statistics on the times negation or intensity words take effect. The comment provides a clear and actionable suggestion, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question and a suggestion regarding the SST dataset. It asks for statistics on the times negation or intensity words take effect, specifically mentioning the word \"nothing\" and its impact on polarity. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the SST dataset, suggesting that the authors should provide statistics on the times negation or intensity words take effect. It specifically mentions the word \"nothing\" and its impact on polarity, which is a clear and actionable suggestion for improving the paper. By addressing this point, the authors can enhance the clarity and depth of their analysis, providing readers with a more comprehensive understanding of the dataset. However, the comment could be more helpful if it included additional suggestions or examples of how these statistics might be presented or analyzed. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the stability of the OGEAug on OOD benchmarks, specifically mentioning the DrugOOD dataset and the SPE method. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should verify the stability of their method on these benchmarks, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, leaving the authors uncertain about the specific steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific concern about the stability of the OGEAug method on OOD benchmarks, particularly mentioning the DrugOOD dataset and the SPE method. However, it does not specify which part of the paper discusses these benchmarks or methods, making it weakly grounded. The comment is specific in detailing the issue of stability verification on these datasets, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not verified the stability of the OGEAug method on OOD benchmarks, specifically mentioning the DrugOOD dataset and the SPE method. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific concern about the stability of the OGEAug method on OOD benchmarks, particularly mentioning the DrugOOD dataset and the SPE method. This feedback is 3 as it points out a potential gap in the evaluation of the method\"s performance on outofdistribution data. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their evaluation methodology. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors consider alternative methods, such as freezing layers of the model or using parameterefficient methods like LoRA, for experimental comparison. While the comment implies that the authors should explore these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to implement these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests considering alternative methods for experimental comparison, such as freezing layers of the model or using parameterefficient methods like LoRA. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative methods for comparison, but without clear grounding, the authors may struggle to determine where these suggestions should be implemented. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering alternative methods for experimental comparison, such as freezing layers of the model or using parameterefficient methods like LoRA. The comment provides a logical reasoning by suggesting that these methods are natural to think about and could provide a valuable basis for comparison. However, it lacks specific examples or references to support the claim that these methods are relevant or beneficial in the context of the paper. While the suggestion is reasonable, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests considering alternative methods for experimental comparison, such as freezing layers of the model or using parameterefficient methods like LoRA. It provides a logical reasoning for why these methods could be valuable additions to the study, offering a clear and actionable suggestion for the authors to explore. By recommending specific approaches, the comment empowers the authors to enhance their experimental design and potentially improve the comprehensiveness of their results. However, the comment could be more helpful if it included additional context or examples of how these methods might be applied. Overall, the feedback is 4 as it provides a constructive direction for the authors to consider, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to expand the related work section by comparing their work to strong baselines that use coordinates. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment explicitly instructs the authors to expand the related work section by comparing their work to strong baselines that use coordinates. This provides clear guidance on what needs to be addressed, making the comment fully grounded. However, it does not specify which part of the related work section needs expansion or which baselines should be compared, leaving some room for ambiguity. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests expanding the related work section by comparing the work to strong baselines that use coordinates. However, it does not provide any specific examples, references, or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. The lack of supporting evidence or detailed justification makes the claim difficult for the authors to understand and address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to expand the related work section by comparing the work to strong baselines that use coordinates. This feedback is valuable as it directs the authors to enhance the context and relevance of their work by highlighting its relationship to existing strong baselines. However, the comment could be more helpful if it specified which baselines should be considered or provided examples of how to make these comparisons. Despite this, the feedback is 4 as it guides the authors toward a specific improvement that can strengthen their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This feedback is clear and provides a direct action for the authors to take, which is to conduct additional experiments with multiple seeds. The suggestion is concrete, as it specifies exactly what needs to be done to improve the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of singleseed experiments, which limits the assessment of performance differences and the impact of the proposed cycle consistency loss. However, it does not specify which part of the paper discusses these experiments, making it weakly grounded. The comment is specific in suggesting the need for multiple seed experiments to provide a more robust evaluation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This claim is 3 as it provides a logical reasoning for the need for multiple seed experiments to ensure the robustness of the results. However, the comment lacks specific examples or references to support the claim that singleseed experiments are insufficient. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper\"s experimental setup, specifically the use of a single seed for training. It highlights the difficulty in assessing the significance of performance differences and the impact of the proposed cycle consistency loss on convergence due to this limitation. The reviewer suggests conducting multiple seed experiments to provide a more robust evaluation. This feedback is clear and actionable, offering a specific improvement that the authors can implement to enhance the credibility and robustness of their results. However, the comment could be more helpful if it provided additional guidance on how to conduct these multiple seed experiments or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors toward a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. While the comment implies that the authors should provide a clearer explanation for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify their rationale but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, it does not specify which part of the paper discusses these distributions or where the authors should provide clarification. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in questioning the motivation behind the choice of distributions, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. The comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. The comment highlights a gap in the paper but lacks actionable feedback, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed method, noting that it requires an entire multiGPU setup for optimizations, which may limit its accessibility to potential users. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the accessibility of their method. Without guidance on potential solutions or modifications, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the proposed method, specifically mentioning that it requires an entire multiGPU setup for optimizations, which may limit its accessibility to potential users. However, it does not specify which part of the paper discusses this requirement or where the authors should address this issue. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of accessibility need to be improved or how the authors might address this limitation. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method requires an entire multiGPU setup for optimizations, which limits its accessibility to potential users. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, noting that it requires an entire multiGPU setup for optimizations, which may limit its accessibility to potential users. This is a relevant observation that could impact the practicality and applicability of the method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the accessibility of their method. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it highlights a concern but lacks depth and actionable advice."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that the authors should consider Ref[2] as a strong baseline for comparison. While the comment provides a clear action to compare the current system with another system that captures semantics, it does not specify which aspects of the current system should be compared or how to implement the comparison. The suggestion to use Ref[2] as a baseline is also vague, as it does not provide specific guidance on how to incorporate this reference into the comparison. Therefore, the comment is 4, as it identifies a clear action but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that the authors should consider Ref[2] as a strong baseline for comparison. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in suggesting a comparison with Ref[2] and the need to capture semantics, but without explicit references to the paper, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that Ref[2] could be a strong baseline for comparison. However, the comment lacks specific reasoning or evidence to support why Ref[2] is a suitable baseline or how it would provide a meaningful comparison. Without detailed justification or examples, the claim remains 3, as the authors would need to infer the relevance of Ref[2] themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It implies that this comparison could provide valuable insights into the performance of the current system. Additionally, the comment suggests using Ref[2] as a strong baseline for comparison, which could help the authors benchmark their work effectively. While the comment identifies a potential area for improvement and provides a specific suggestion, it lacks detailed guidance on how to implement the comparison or what specific aspects to focus on. This limits the comment\"s helpfulness, as it provides a general direction but not a comprehensive plan for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset. It questions whether one of the assumptions is not satisfied or if there are learning difficulties. However, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve the model\"s performance. The comment implies that the authors should investigate these possibilities, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the model\"s performance in identifying true sources in the triangle dataset, but it does not specify which part of the paper discusses this issue. The authors cannot confidently determine which section or subsection this comment pertains to, making it weakly grounded. However, the comment is specific in questioning whether one of the assumptions is not satisfied or if there are learning difficulties. This provides some guidance on what the authors might need to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the model\"s performance in identifying true sources in the triangle dataset, questioning whether one of the assumptions is not satisfied or if there are learning difficulties. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the model\"s performance in identifying true sources in the triangle dataset. It raises questions about whether one of the assumptions is not satisfied or if there are learning difficulties, which is a clear indication of a potential weakness in the model\"s design or implementation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these issues or improve the model\"s performance. While it points out a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the metrics used for evaluating continual learning, specifically the loss after switch and recovery time after switch. It suggests that these metrics might not be applicable in settings where task boundaries are unknown or not clearly defined. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative metrics that could be more suitable. The action is implicit and somewhat vague, as the authors are left to infer that they should consider alternative metrics or adapt their evaluation approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the metrics used for evaluating continual learning, specifically mentioning \"loss after switch\" and \"recovery time after switch.\" However, it does not specify which part of the paper discusses these metrics, making it weakly grounded. The comment is specific in detailing the limitations of these metrics in certain settings, such as when task boundaries are unknown or not clearly defined. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metrics used for evaluating continual learning, such as loss after switch and recovery time after switch, are not applicable in settings where task boundaries are unknown or not clearly defined. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the metrics used for evaluating continual learning, specifically the loss after switch and recovery time after switch. It points out that these metrics might not be applicable in settings where task boundaries are unknown or not clearly defined. This feedback is 3 as it highlights a specific area where the evaluation methodology could be improved or adapted to better suit different scenarios. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or explore alternative metrics. To be more helpful, the comment could include recommendations or examples of alternative metrics that could be more suitable in various settings. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and not from all time steps. While the comment implies that the authors should clarify this aspect, it does not provide explicit guidance on how to address the issue or suggest specific changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation or clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and not from all time steps. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the use of information, but without clear grounding, the authors may struggle to identify the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and not from all time steps. This is a request for clarification rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and not from all time steps. This is a relevant question that could help the authors clarify their methodology and potentially improve the clarity of their paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific changes could be made to improve the explanation. While it identifies a potential area for improvement, it lacks depth and actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the \"location\" of these heads within the model. It implies that a controlled baseline should be included, which ablates heads at different locations in the model. While the comment identifies a potential confounding factor and suggests a way to address it, it does not provide specific guidance on how to implement this controlled baseline or what specific locations should be tested. The action is explicit but somewhat vague, as the authors know they need to include a controlled baseline but may not be entirely clear on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"induction heads and FV heads,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the \"location\" of these heads within the model could be a confounding factor affecting the ICL performance. The comment further suggests a controlled baseline that ablates heads at different locations in the model. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the \"location\" of these heads within the model. The reviewer provides a logical reasoning by pointing out that induction heads and FV heads are located at different layers, which could be a confounding factor. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider this reasoning and potentially conduct additional experiments to verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confounding factor in the analysis of induction heads and FV heads, suggesting that the \"location\" of these heads within the model could influence the ICL performance. It provides a clear and actionable suggestion by recommending a controlled baseline that ablates heads at different locations in the model. This feedback is valuable as it directs the authors to consider a more comprehensive approach to their analysis, which could lead to a deeper understanding of the factors affecting ICL performance. However, the comment could be more helpful if it included specific examples or guidance on how to implement this controlled baseline. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that a section on synonym identification is missing under similarity measurement, suggesting that the authors should include this section to describe how the multiplechoice task is approached. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to their draft. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions a missing section on synonym identification under similarity measurement, providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies what is missing, namely a description of how the multiplechoice task is approached, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this section is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this section or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks a section on synonym identification under similarity measurement, which would describe how the multiplechoice task is approached. This feedback is clear and actionable, as it provides a direct suggestion for improving the paper by adding a section that could enhance the understanding of the methodology. However, the comment could be more helpful if it offered additional guidance on what aspects should be included in this section or how it would contribute to the overall understanding of the paper. Despite this, the comment is 4 as it directs the authors to a clear area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not provide explicit guidance on how to create this overview or what specific elements should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide an overview but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not specify which part of the paper lacks this overview or where it should be included. The authors might infer that it pertains to the introduction or the methodology section, but this inference is not explicit. The comment is specific in suggesting what is needed, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. However, it does not provide any specific reasoning, examples, or references to support why this overview is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that an overview of the workflow and the model would be beneficial for understanding the work as a whole. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a more comprehensive introduction to the methodology. However, the comment lacks specificity and does not provide detailed guidance on how to structure this overview or what specific elements should be included. While it points out a general area for enhancement, it does not offer actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential bias in the sketch due to the need to compute the statistical dimension d_lambda of the design matrix A. It suggests that this computation requires the same runtime as solving the ridge regression problem, which could defeat the purpose of the approach. The comment implies that the authors should address this issue by discussing it in the paper, but it does not provide explicit instructions on how to do so. While the action is implicit, it is 3 as it points out a potential issue that the authors should consider. However, the lack of concrete guidance on how to address the issue limits its actionability.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the computation of the statistical dimension d_lambda of the design matrix A, which is crucial for debiasing the sketch. It also mentions a similar issue when computing the surrogate sketch. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue and its potential impact on the approach, but the lack of explicit grounding limits the score to 3.", "verifiability_rationale": "The review point claims that the statistical dimension d_lambda of the design matrix A is necessary for debiasing the sketch, but this computation requires the same runtime as solving the ridge regression problem, potentially defeating the purpose of the approach. The reviewer supports this claim by explaining the computational complexity involved and the potential impact on the approach. However, the comment lacks specific references or detailed examples to fully substantiate the claim. While the reasoning is logical, the lack of additional evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing of the sketch, specifically the need to compute the statistical dimension d_lambda of the design matrix A. It points out that this computation requires the same runtime as solving the ridge regression problem, which could defeat the purpose of the approach. The comment also mentions a similar issue when computing the surrogate sketch. While the comment highlights a critical concern, it does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the potential bias. The feedback is 3 as it alerts the authors to a potential problem, but it lacks actionable advice, making it more beneficial for the authors to understand the issue rather than directly improving their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific guidance on how to improve the setup or what questions need to be addressed. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not specify which part of the paper discusses these ablations or what specific questions arise regarding the setup. Without explicit references to sections or examples, the authors cannot confidently determine which part of the paper is being addressed. The comment is vague and lacks specificity, making it difficult for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific examples or detailed reasoning to support why the current setup is inadequate. The comment lacks concrete evidence or references to justify the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment identifies a potential issue with the ablation experiments, suggesting that they deserve a better experiment setup. However, it does not provide specific guidance or suggestions on how to improve the setup or what questions need to be addressed. The comment raises a concern but lacks actionable feedback, leaving the authors with a general idea of an area for improvement without detailed guidance on how to address it. This makes the comment 3, as it points out a potential issue but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed models are useful for learning representations for lowfrequency words but lacks empirical evidence to support this claim. It suggests that the authors should explore this aspect further by providing empirical evidence. While the comment implies that the authors should conduct additional analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the analysis or what metrics to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the aspect of the paper being addressed, namely the proposed models\" usefulness for learning representations for lowfrequency words. It also specifies the issue by pointing out the lack of empirical evidence to test the hypothesis and the need for deeper exploration. However, it does not provide specific guidance on how to address these issues or what additional evidence or analysis would be beneficial. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed models are useful for learning representations for lowfrequency words but lacks empirical evidence to support this claim. The reviewer suggests that the authors should explore this aspect further, which is a reasonable request. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the reasoning behind the suggestion and potentially conduct additional research to address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks empirical evidence to support its claim about the usefulness of the proposed models for learning representations of lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it offered specific suggestions on how to conduct this empirical analysis or what metrics to use. Despite this, the feedback provides a valuable direction for the authors to enhance their draft, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the error analysis on the movie dataset is missing, and it highlights the importance of understanding the cases where the model fails. This provides a clear action for the authors to take: conducting an error analysis on the movie dataset to identify the cases where the model fails. The comment is explicit and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment addresses the absence of an error analysis on the movie dataset, which is a specific aspect of the paper. However, it does not specify which part of the paper discusses the movie dataset, making it weakly grounded. The comment is specific in its request for an error analysis to understand the model\"s failures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a critical aspect for other researchers to continue working on the task. The comment highlights the importance of understanding the cases where the model fails, providing a logical reasoning for why this analysis is necessary. However, it does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the importance of this analysis based on the provided reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the absence of an error analysis on the movie dataset. It highlights the importance of understanding the cases where the model fails, which is crucial for other researchers to continue working on the task. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the comprehensiveness and utility of their work. However, the comment could be more helpful if it offered suggestions on how to conduct the error analysis or what aspects to focus on. Overall, the comment is 4, as it directs the authors to a critical area that needs attention, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which details are missing or how the authors should address this issue. The comment lacks explicit guidance or concrete suggestions on what needs to be added or clarified, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment indicates that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which part of the paper these questions are from, nor does it provide details on what specific details are missing. This lack of explicit reference to a specific section or element of the paper makes it difficult for the authors to pinpoint the exact areas needing attention. Additionally, the comment lacks specificity regarding the missing details, leaving the authors uncertain about what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"some details of the proposed method are missing,\" but it does not provide any specific examples or reasoning to support this claim. Without detailed explanation or references to what details are missing, the authors may find it challenging to understand and address the issue. The comment lacks sufficient evidence or justification, making it difficult for the authors to verify the claim. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment indicates that some details of the proposed method are missing, as noted in the questions section. However, it does not specify which details are missing or provide any guidance on how the authors might address this issue. Without specific feedback or suggestions, the authors are left without actionable steps to improve their draft. The comment lacks clarity and depth, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of an ablation analysis in the main paper, which makes it challenging to identify the source of a small performance gain. While the comment implies that an ablation analysis should be included, it does not explicitly instruct the authors to conduct one. The action is implicit and somewhat vague, as the authors can infer that they need to add an ablation analysis but are not provided with specific guidance on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of ablation analysis in the main paper, which makes it difficult to identify the source of a small performance gain. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or methodology sections, but this inference is not explicit. The comment is specific in pointing out the need for an ablation analysis, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis makes it difficult to identify the source of a small performance gain. This is a subjective opinion based on the reviewer\"s expectation of what should be included in the paper. However, the comment does not provide specific examples or detailed reasoning to support why an ablation analysis is necessary or how it would improve the paper. Without additional context or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of an ablation analysis, which would help pinpoint the source of a small performance gain. This feedback is valuable as it highlights a critical area for improvement that could enhance the paper\"s clarity and understanding of the results. However, the comment does not provide specific suggestions or guidance on how to conduct the ablation analysis or what components to focus on. While it directs the authors to a necessary step, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a finding from Figure 2, stating that when the number of classes is large, the noise rate of similarity labels is less than that of class labels. It also mentions the use of \"Th.\" However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how this finding should be addressed, whether it requires further explanation, or if it has any implications for the paper. Without any actionable advice or suggestions, the authors are left without a clear understanding of what steps to take in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to Figure 2, which allows the authors to identify the specific part of the paper being addressed. It specifies that when the number of classes is large, the noise rate of similarity labels is less than that of class labels. However, it does not provide any further details or suggestions on how this finding should be addressed or what implications it has for the paper. The comment lacks specificity regarding what needs to be done to improve the paper based on this observation. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point makes a factual observation about the noise rate of similarity labels compared to class labels, as shown in Figure 2. It does not express an opinion, judgment, or suggestion that requires verification. The statement is purely descriptive and does not contain any claims or requests for changes. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a specific observation from Figure 2, noting that when the number of classes is large, the noise rate of similarity labels is less than that of class labels. However, it does not provide any context, explanation, or suggestions for how this finding might impact the paper or what implications it has for the authors\" work. Without additional guidance or analysis, the comment lacks depth and does not offer actionable feedback for the authors to improve their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the CNN experiments are not fully convincing, but it does not provide any specific details or suggestions on how to improve them. There is no explicit or implicit action for the authors to take, nor are there any concrete steps outlined for enhancing the experiments. Without any guidance or direction, the authors are left without a clear understanding of what needs to be done to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the CNN experiments are not fully convincing, but it does not specify which part of the paper these experiments are discussed in, nor does it provide details on what aspects of the experiments are not convincing. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas that need attention or improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the CNN experiments are not fully convincing, but it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment indicates that the CNN experiments are not fully convincing, but it does not provide any specific details or examples to support this claim. Without additional context or suggestions for improvement, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be strengthened. This lack of specificity and actionable feedback makes the comment 2, as it does not guide the authors in addressing the issue effectively. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should place more emphasis on prompt design, as different prompts can lead to varying performance outcomes. However, it does not provide specific guidance on how to effectively design prompts or what aspects of prompt design should be discussed. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss prompt design but without concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more emphasis should be placed on prompt design, specifically mentioning the introduction of several prompting methods to address issues in MenatQA. However, it does not specify which part of the paper discusses these prompting methods or where the authors should focus on prompt design. While the authors might infer that this relates to the methodology or results sections, the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in suggesting that prompt design should be discussed, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that more emphasis should be placed on prompt design, as different prompts can lead to varying performance outcomes. However, the comment does not provide specific examples or detailed reasoning to support why this emphasis is necessary or how it would impact the paper. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should place more emphasis on prompt design. It acknowledges the introduction of several prompting methods to address issues in MenatQA and highlights the importance of discussing how to design prompts effectively. This feedback is clear and actionable, as it directs the authors to a particular aspect of their work that could be expanded upon. However, the comment could be more helpful if it provided specific suggestions or examples on how to effectively design prompts. Overall, the comment is 4, as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. While it implies that the authors should provide a clearer explanation for their choice of freezing, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what additional information should be included. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. However, it does not specify which part of the paper discusses the freezing method or where the MLS selection process is described. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the freezing method and suggests an alternative, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why freezing is not a suitable choice or why an adaptive method would be better. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the rationale behind using freezing in the MLS selection process and suggests using an adaptive method instead. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or suggestions on how the authors might address this issue. The comment points out a potential weakness but does not offer actionable advice or examples to help the authors improve their draft. Therefore, the feedback is 3, as it prompts the authors to reconsider their approach but does not fully support them in making those changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the issue addressed in the existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the issue addressed in existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in suggesting a particular analysis that could be conducted, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the issue addressed in existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. The comment references an existing work (https://arxiv.org/abs/2104.06378) that has done closelyrelated analyses, providing some support for the suggestion. However, the comment lacks specific examples or detailed reasoning on how the proposed knowledgeCLIP model might address these issues, making it 3. The authors would need to infer the exact steps or analyses required to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises an interesting question about whether the issue addressed in existing work is also solved in the proposed knowledgeCLIP model. It suggests that the authors perform a similar analysis, such as adding negation or changing entities in text, to see if the KGaugmented method can robustly handle these changes. This feedback is 3 as it provides a specific suggestion for further analysis that could enhance the paper. However, the comment lacks detailed guidance on how to conduct this analysis or what specific aspects to focus on, which limits its usefulness. The authors gain some insight into a potential area for exploration, but the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more explanation about how novel values in the test set are handled. This is an explicit request for additional clarification, which is clear and actionable. The authors know exactly what needs to be done to improve their draft by adding more explanation on this topic. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 97, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should provide more explanation about how novel values in the test set are handled. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more explanation about how novel values in the test set are handled. This is a request for clarification rather than a claim or opinion. It does not contain any subjective statements, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors should provide more explanation about how novel values in the test set are handled. This is a specific and actionable piece of feedback that can help the authors clarify an aspect of their methodology that may be unclear to readers. By addressing this suggestion, the authors can enhance the clarity and comprehensibility of their paper. However, the comment could be more helpful if it provided additional context or examples of what specific information should be included. Overall, the feedback is 4 as it directs the authors to a clear area for improvement, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point mentions that similar methods for multitask learning have already been proposed and have not been discussed in the paper. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should address this issue, discuss the existing methods, or incorporate them into their work. Without any actionable steps or suggestions, the comment lacks direction for the authors, making it 1.", "grounding_specificity_rationale": "The comment mentions that similar methods for multitask learning have already been proposed and have not been discussed in the paper. However, it does not specify which part of the paper this issue pertains to, such as a specific section or discussion where these methods should be addressed. Additionally, the comment lacks specificity regarding which methods are being referred to or how they relate to the current work. Without explicit references or detailed guidance, the authors cannot confidently determine which part of the paper needs revision or improvement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that similar methods for multitask learning have already been proposed and have not been discussed in the paper. However, it does not provide any references or examples of these existing methods, making it difficult for the authors to verify the claim. Without specific references or detailed explanations, the authors may find it challenging to address the issue or understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that similar methods for multitask learning have already been proposed and have not been discussed in the paper. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or incorporate these existing methods into their work. Without actionable feedback or detailed advice, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises an expectation that the amount of computation for FedMITR is higher than other methods and asks whether this has been compared. While the comment implies that the authors should compare the computation of FedMITR with other methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to compare computation but are not given specific guidance on how to conduct the comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the computational complexity of FedMITR compared to other methods, but it does not specify which part of the paper this comparison should be made in. The authors can infer that it relates to the experimental results or methodology sections, but without explicit references, the comment is weakly grounded. It is specific in its request for a comparison, but the lack of grounding makes it difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the computational complexity of FedMITR compared to other methods, suggesting that the authors should compare this aspect. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is expected or necessary. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the computational complexity of FedMITR compared to other methods, suggesting that the authors should compare this aspect. While the comment identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to conduct the comparison or what specific aspects of computation should be considered. The feedback is 3 as it prompts the authors to consider an important aspect of their work, but it could be more actionable with additional details or suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the methodology used to select 0.6 for glove embedding similarity and suggests exploring alternative loss functions, such as replacing the min with a mean or NDCG. While the comment implies that the authors should provide more details on their methodology and consider alternative loss functions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the methodology used to select 0.6 for glove embedding similarity and suggests exploring alternative loss functions. However, it does not specify which part of the paper discusses this methodology or where the authors should address these questions. The comment lacks grounding as it does not refer to a specific section, figure, or table, making it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while it provides some specific suggestions for improvement, it does not specify what needs to be addressed in detail. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises questions about the methodology used to select 0.6 for glove embedding similarity and suggests exploring alternative loss functions. However, it does not provide any specific reasoning, examples, or references to support these questions or suggestions. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions about the methodology used in the paper, specifically regarding the selection of 0.6 for glove embedding similarity and the potential impact of using alternative loss functions. It also suggests exploring other influential loss functions, such as replacing the min with a mean or NDCG. While the comment identifies areas for improvement and provides some direction, it lacks specific guidance on how to address these questions or suggestions. The authors are left with a general understanding of what needs to be explored but without detailed instructions on how to implement these changes. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests several specific actions for the authors to take, including training on labeled data, incorporating input mask explanation annotations for a few examples, and using modern backbone baselines for feature extraction. The reviewer also provides a concrete suggestion to increase the number of convolutional layers to ensure robustness. While the comment is explicit in its actions, it does not provide detailed guidance on how to implement these suggestions, such as which specific annotations to use or how to integrate the modern backbone baselines. Therefore, the comment is 4, as it provides clear directions but lacks detailed execution steps.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific aspects of the paper, such as the \"new method of training on the labeled data\" and the suggestion to use modern backbone baselines like Resnet50 or DenseNet121. It also specifies what needs to be addressed, such as incorporating input mask explanation annotations and increasing the number of convolutional layers. This provides clear guidance on what the authors need to revise. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed method of training on labeled data and incorporating input mask explanation annotations might not be effective, citing the failure of similar robustness/domain invariance interventions in the past. However, the comment lacks specific examples or references to these failed interventions, making it difficult for the authors to fully understand and address the critique. The claim is 3 as it provides a general rationale but lacks detailed evidence or examples to substantiate the skepticism. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback, suggesting improvements to the methodology and experimental setup. It recommends incorporating input mask explanation annotations for a few examples and using modern backbone baselines for feature extraction, which could enhance the robustness and effectiveness of the proposed method. The comment also addresses a potential concern about the feasibility of the approach, acknowledging that similar interventions have failed in the past. While the comment does not provide detailed guidance on how to implement these suggestions, it offers clear directions for improvement, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method to ensure a fair comparison. This is an explicit action, as it directly instructs the authors to address a specific issue related to the hyperparameter tuning of the baseline. However, the comment does not provide detailed guidance on how to implement this action, such as which hyperparameters to focus on or how to conduct the tuning. While the action is clear, the lack of concrete details makes it 3.", "grounding_specificity_rationale": "The comment addresses the introduction of multiple hyperparameters and the extensive hyperparameter search, specifically mentioning \"temperature, penalty, and threshold.\" However, it does not specify which part of the paper discusses these hyperparameters or the hyperparameter search, making it weakly grounded. The comment is specific in suggesting that the baseline should be fully tuned with similar resources as the proposed method for a fair comparison. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper introduces multiple hyperparameters and conducts an extensive hyperparameter search, which could impact the fairness of the comparison with the proposed method. The reviewer recommends ensuring that the baseline is fully tuned with similar resources as the proposed method. However, the comment lacks specific examples or references to support the claim about the impact of hyperparameters on the comparison. Without detailed evidence or examples, the claim is 3, as it provides a logical suggestion but lacks sufficient justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between the proposed method and the baseline due to the extensive hyperparameter search. It suggests that ensuring the baseline is fully tuned with similar resources as the proposed method could be important for a fair comparison. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a concrete suggestion for addressing it. However, the comment could be more helpful if it offered guidance on how to conduct the tuning or which hyperparameters to focus on. Overall, the comment is 4, as it directs the authors to a critical aspect of their work that requires attention, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a mistake in the definition of perplexity and provides a correction. It also points out that the equation presented does not look like perplexity but rather like crossentropy. This feedback is clear and provides direct actions for the authors to take, such as correcting the definition of perplexity and ensuring that the equation is correctly labeled. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific line number (\"L259\") and the equation (\"Eq1\"), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly points out the incorrect definition of perplexity and provides a correction, as well as noting that the equation does not look like perplexity but rather like crossentropy. This level of detail guides the authors on what needs to be corrected or clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definition of perplexity at line 259 is incorrect and that the equation (Eq1) does not look like perplexity but rather like crossentropy. This claim is verifiable as it provides a clear and specific correction to the definition of perplexity, which is a wellestablished concept in natural language processing. The comment also references the equation, which allows the authors to verify the claim and make the necessary corrections. Therefore, the comment is 5.", "helpfulness_rationale": "The review comment identifies a specific error in the definition of perplexity, pointing out that the explanation provided in the paper is incorrect. It also notes that the equation presented does not look like perplexity but rather like crossentropy. This feedback is clear and actionable, as it directly points out a mistake in the paper and provides a correction. By addressing this issue, the authors can ensure that their definition and equation are accurate, which is crucial for the understanding and credibility of their work. Therefore, the comment is 5, as it provides specific and actionable guidance that can significantly improve the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the evaluation of the proposed strategies, specifically the consideration that purifying the input image before passing it to the model and using an adaptive attack against the edge map defense strategies could result in structural damage to the edge map. The reviewer suggests evaluating the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map while misleading model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct this evaluation to strengthen their defense strategies. The suggestion is concrete, as it specifies the type of evaluation needed to address the concern. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation of the proposed strategies, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need to evaluate the proposed defense against an adversarial attack that minimally alters the edge map while misleading model predictions. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the evaluation of the proposed strategies, specifically the consideration that purifying the input image before passing it to the model and using an adaptive attack against the edge map defense strategies could result in structural damage to the edge map. The reviewer suggests evaluating the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map while misleading model predictions. This claim is 3 as it provides a logical reasoning for the need to evaluate the defense against a specific type of adversarial attack. However, it lacks specific examples or references to support the claim fully, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the evaluation of the proposed strategies. It highlights the need to assess the defense against an adversarial attack that minimally alters the edge map while misleading model predictions. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their evaluation process. By suggesting a more robust evaluation against a specific type of attack, the comment offers valuable guidance that can significantly strengthen the defense strategies presented in the paper. However, the comment could be more helpful if it included examples or additional details on how to implement this evaluation. Overall, the comment is 4, as it effectively directs the authors toward a meaningful improvement in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to assess the significance of the results. This comment provides a clear and explicit action for the authors to take: they should include standard deviations in their experimental results to improve the clarity and interpretability of their findings. The feedback is direct and provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, namely the absence of standard deviations, which makes it difficult to judge the significance of the results. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results lack standard deviations, which makes it difficult to judge the significance of the results. This is a factual statement that does not require verification or justification. It is a request for clarification or improvement, not an opinion or suggestion that needs to be substantiated. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the lack of standard deviations makes it difficult to judge the significance of the results. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the inclusion of standard deviations. By addressing this point, the authors can enhance the clarity and interpretability of their results, which is crucial for the credibility and impact of their work. However, the comment could be more helpful if it provided additional context or examples on how standard deviations can be incorporated or why they are important. Overall, the comment is 4, as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks specific suggestions or guidance on how to improve the quality of the generated images or what aspects of the realism need to be enhanced. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of the generated images by the proposed method, specifically mentioning the limited realism of the results shown in the paper and supplemental material. However, it does not specify which part of the paper or supplemental material this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the realism of the generated results, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of the generated images by the proposed method is limited, specifically mentioning the lack of realism in the results shown in the paper and supplemental material. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the quality of the generated images by the proposed method, noting that while good continuous control is achieved, the realism of the generated results is limited. This feedback is 3 as it points out a potential weakness in the paper, prompting the authors to consider ways to enhance the realism of their generated images. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending particular techniques or methods to improve realism. Without actionable advice, the authors may find it challenging to know where to focus their efforts for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the statement in lines 559560 is not entirely true and provides a correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This feedback is clear and provides a direct action for the authors to correct the misrepresentation in their draft. The comment is explicit and concrete, giving the authors precise guidance on how to improve their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 559560, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it corrects a statement by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This provides clear guidance on what needs to be corrected in the draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in lines 559560 is not entirely true. It provides a specific correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This detailed explanation supports the claim, making it 4. However, the comment could be strengthened by referencing specific literature or examples to further substantiate the correction. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific error in the paper, pointing out that the statement in lines 559560 is not entirely true. It provides a clear and actionable correction by explaining that in Cycle Consistency loss, iterations can be performed between two phases of reconstructions with separate standard backpropagation processes. This feedback is valuable as it helps the authors correct a misrepresentation in their draft, ensuring accuracy and clarity in their work. However, the comment could be more helpful if it also suggested how this correction might impact the overall understanding or methodology of the paper. Overall, the comment is 4, as it provides clear guidance for improvement but could be more comprehensive with additional context or suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that some details of the models are missing, specifically the grammar over kernels, which is not explained in detail. It also raises questions about the probabilities associated with the grammar and how inference is performed. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors can infer that they need to provide more detailed explanations, but the comment lacks specific guidance on what aspects to focus on or how to present the information. Therefore, the comment is 3, as it highlights areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the grammar over kernels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing, namely the explanation of how the approach is applied in practice and the probabilities associated with the grammar. The comment raises questions about inference and provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some details of the models are missing, specifically the grammar over kernels, which is not explained in detail. It questions how inference is performed and whether probabilities are associated with the grammar. While the comment identifies specific areas of concern, it lacks detailed reasoning or examples to support the claim. The authors may need to provide more information to fully understand the issue, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the explanation of the grammar over kernels and the associated probabilities. It highlights the importance of understanding how this approach is applied in practice and raises questions about inference. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations in the relevant sections of the paper. By addressing these points, the authors can enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of similar approaches for comparison. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include qualitative results, particularly for cases where previous methods failed but the proposed method was successful. It also recommends showing failure cases and analyzing the limitations. While the comment provides a clear direction for what the authors should do, it does not specify how to present these results or analyze the limitations. The action is explicit but somewhat vague, as it lacks detailed guidance on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including qualitative results, particularly for cases where previous methods failed but the proposed method was successful. It also recommends showing failure cases and analyzing limitations. However, it does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what additional results or analyses could be included, but without clear references to specific sections, the authors may find it challenging to pinpoint where these changes should be made. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including qualitative results, particularly for cases where previous methods failed but the proposed method was successful. It also recommends showing failure cases and analyzing limitations. However, the comment lacks specific examples or references to support the claim that such results would be beneficial or necessary. Without detailed justification or evidence, the authors may find it challenging to understand the importance of these suggestions. Therefore, the comment is considered 2, as it provides a general idea but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of qualitative results, particularly for cases where previous methods failed but the proposed method was successful. It also suggests showing failure cases and analyzing limitations, which can help the authors better understand and communicate the strengths and weaknesses of their approach. However, the comment could be more helpful if it offered specific guidance on how to present these results or analyze the limitations. Despite this, the feedback is 4 as it directs the authors toward enhancing the comprehensiveness and clarity of their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests clarifying the title to specify that it refers to machine comprehension of text rather than human reading comprehension. This is an explicit action that the authors can take to improve the clarity of their work. The comment provides a clear direction on what needs to be changed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the title, suggesting that it is ambiguous and should clarify that it refers to machine comprehension of text rather than human reading comprehension. This provides clear guidance on what needs to be addressed to improve the clarity of the title. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous and recommends clarifying that it refers to machine comprehension of text rather than human reading comprehension. The comment provides a logical reasoning by explaining that \"reading comprehension\" and \"readability\" are often associated with human understanding, which is different from the context of machine comprehension. This reasoning is clear and provides a basis for the suggestion, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the distinction between machine and human comprehension. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the title, suggesting that it could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This feedback is clear and actionable, as it provides a specific suggestion for improving the clarity and accuracy of the title. By addressing this issue, the authors can enhance the clarity and precision of their work, which is beneficial for both readers and reviewers. However, the comment could be more helpful if it provided additional context or examples to further clarify the distinction between machine and human comprehension. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. It suggests that this choice weakens the convincingness of the human evaluation. While the comment highlights a potential issue, it does not provide explicit guidance on what the authors should do to address this concern. The action is implicit, as the authors need to infer that they should reconsider their choice of metric for human evaluation. Additionally, the comment lacks concrete details on how to implement this change or what specific human metric should be used. Therefore, the comment is 3, as it identifies an issue but does not provide clear steps for resolution.", "grounding_specificity_rationale": "The comment questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. However, it does not specify which part of the paper discusses the human evaluation or where the use of TSS is mentioned. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the choice of metric but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. The reviewer claims that this choice weakens the convincingness of the human evaluation. However, the comment lacks specific reasoning or examples to support why a human metric would be more appropriate or how the use of TSS affects the evaluation. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment questions the choice of using an automatic metric (TSS) instead of a human metric for evaluating style control in the human evaluation. It highlights a potential weakness in the methodology, suggesting that the use of an automatic metric may weaken the convincingness of the human evaluation. While the comment identifies a critical issue, it lacks specific suggestions or guidance on how the authors might address this concern or what alternative human metrics could be considered. The feedback is 3 as it points out a potential flaw, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including experiments across more diverse domains would strengthen the paper. While it implies that the authors should expand their experiments, it does not provide specific guidance on which domains to consider or how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and determine the specific domains themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that including experiments across more diverse domains would strengthen the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or a specific table or figure. Additionally, it does not provide details on which domains should be considered or why they would strengthen the paper. This lack of specificity and grounding makes it difficult for the authors to identify the exact areas needing improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experiments \"succinctly prove the point that the authors try to make\" and suggests that including experiments across more diverse domains would strengthen the paper. However, the comment lacks specific examples or references to support the claim that the current experiments are insufficient or that additional domains would provide valuable insights. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the experiments successfully prove the authors\" point but suggests that including experiments across more diverse domains would strengthen the paper. This feedback is 3 as it identifies a potential area for improvement by suggesting a broader scope of experiments. However, the comment lacks specific guidance on which domains to consider or how to implement this suggestion, leaving the authors with a general direction but not a detailed plan for enhancement. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in making significant improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of confidence intervals for the results, which makes it unclear whether the performance gains are statistically significant. It also notes that the evaluation is limited to only two datasets, which are standard in the RNP community. The comment provides a list of references that could be relevant for addressing these issues. While the comment implies that the authors should include confidence intervals and evaluate on more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these points. However, the references provided offer some guidance on how to improve the evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the absence of confidence intervals for results, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of statistical significance and the limited evaluation on only two datasets. Additionally, the comment provides references to relevant literature, which further grounds the feedback. However, the comment could be more specific by suggesting how the authors might address these issues or what specific datasets they should consider. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absence of confidence intervals makes it unclear whether performance gains are statistically significant and that the evaluation is limited to only two datasets. The comment is supported by references to relevant literature, which provides a basis for the claim. However, the references are not directly cited within the text, which could make it less accessible for the authors. Overall, the claim is 4, as it provides a logical reasoning and references to external works, but the lack of direct citations within the text could make it slightly more challenging for the authors to fully understand and address the feedback. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the limited evaluation on only two datasets, which may not adequately represent the diversity of the RNP community. The comment provides a list of relevant references that could help the authors address these issues, such as [1] DiversitySensitive Conditional Generative Adversarial Networks, [2] Controlling Selection Bias in Causal Inference, [3] An empirical study on robustness to spurious correlations using pretrained language models, and [4] On Feature Learning in the Presence of Spurious Correlations. This feedback is clear and actionable, as it not only points out the weaknesses but also suggests potential solutions by referencing relevant literature. However, the comment could be more helpful if it provided specific guidance on how to incorporate these references or address the issues. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the LUQ is straightforward to design once the goal is clear and that the approaches in Section 5 are standard and explored in previous literature. The reviewer suggests that the main contribution of the paper is demonstrating that a simple combination of existing techniques can achieve surprisingly good accuracy. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the paper or what specific aspects need attention. Without actionable suggestions or feedback, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the design of the LUQ and the approaches in Section 5, suggesting that they are straightforward and standard. However, it does not specify which part of the paper discusses the LUQ or the approaches in Section 5, making it weakly grounded. The comment is specific in its critique of the paper\"s contribution, suggesting that the main contribution is showing the effectiveness of existing techniques rather than proposing novel ones. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. The reviewer suggests that the main contribution of the paper is demonstrating the effectiveness of existing techniques rather than proposing novel ones. However, the comment lacks specific references or examples to support the claim that the approaches are standard or explored in previous literature. This makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some justification but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment acknowledges that the LUQ is straightforward to design once the goal is clear and that the approaches in Section 5 are standard and explored in previous literature. It suggests that the main contribution of the paper is demonstrating the effectiveness of existing techniques rather than proposing novel ones. While the comment provides some insight into the paper\"s contribution, it lacks specific suggestions or guidance on how the authors might enhance their work or address the reviewer\"s concerns. The feedback is 3 as it highlights the paper\"s focus on existing techniques, but it does not offer actionable advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. While the comment implies that the authors should include training losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to present the training losses or what specific metrics to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method and suggests including training losses. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where this method is discussed. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. The comment is specific in its request for training losses but lacks grounding, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. However, the comment does not provide any supporting evidence, reasoning, or references to justify why training losses are necessary or how they would demonstrate stability. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the stability of training the deep localization network with the differentiable Sinkhorn method. It suggests that the authors should include training losses to provide evidence of stability. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to address the issue or what specific training losses should be included. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the training of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the training process. The action is implicit and somewhat vague, as the authors are left to infer that they need to ensure a fair comparison by adjusting the training process. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the training process seeing 2x samples per iteration, which could lead to unfair comparisons with other methods. The comment provides a clear explanation of the problem, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to unfair comparisons with other methods. However, the comment does not provide any supporting evidence, such as specific examples or references to other methods, to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the training process of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to unfair comparisons with other methods. This is a relevant observation that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or ensure a fair comparison. While it highlights a potential problem, it lacks actionable feedback, making it 3. The authors are left to infer that they need to adjust their training process or provide additional context to ensure a fair comparison. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. While it implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to investigate and report on the scalability of their method. However, the comment does not specify what aspects of scalability should be considered or how to conduct the analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to determine where to address the issue. The comment is specific in its inquiry about scalability, but without clear grounding, it is challenging for the authors to know exactly what part of the paper needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the scalability of the method as the corpus size or hidden dimension size increases. This is an important consideration for the authors to address, as it can impact the practical applicability and efficiency of their approach. However, the comment does not provide specific guidance or suggestions on how the authors might investigate or address this scalability issue. While it highlights a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider an important aspect of their work but does not fully support them in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about relaxing the need to visit all ballaction pairs with each iteration, suggesting that the authors consider making minimal assumptions or partially covering them. While the comment implies that the authors should explore these possibilities, it does not provide explicit instructions or concrete steps on how to implement these ideas. The action is implicit and somewhat vague, as the authors need to infer that they should consider these options and determine how to address them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it directly addresses the previous remark about relaxing the need to visit all ballaction pairs with each iteration. This allows the authors to accurately identify the part of the paper being discussed. However, the comment is specific in suggesting what could be done to relax this requirement, such as making minimal assumptions or partially covering the ballaction pairs. This provides clear guidance on what the authors should consider to improve their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on how to relax the need to visit all ballaction pairs with each iteration. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment builds upon a previous remark by asking for clarification on how to relax the need to visit all ballaction pairs with each iteration. It suggests exploring minimal assumptions or partial coverage of these pairs. While the comment provides a direction for further exploration, it lacks specific guidance or examples on how to implement these suggestions. The authors are given a general idea of what could be done but are not provided with detailed steps or examples to follow. This limits the comment\"s usefulness, as it does not fully empower the authors to make significant improvements to their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should test this hypothesis, make changes to their encoder, or address this point in their discussion. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not detail what improvements are expected or how the encoder choice might impact the results. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change might be beneficial or necessary. The comment lacks specific details or references that would help the authors understand the basis of the suggestion, making it difficult for them to address the claim effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether improvements could be observed with a different encoder, such as RoBERTabase, instead of BERT. While it identifies a potential area for exploration, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or conduct further experiments. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is 2, as it points out a possible direction but does not provide enough detail or direction for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without severely damaging the performance of the predictive model. This is an explicit request for the authors to provide additional evidence or examples to support their claims. However, the comment does not specify how the authors should present this information or what specific aspects of the method should be highlighted. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without severely damaging the performance of the predictive model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, while the comment provides a clear suggestion for improvement, it does not specify what aspects of the method should be highlighted or how to present the evidence. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without severely damaging the performance of the predictive model. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it could be achieved. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without severely damaging the performance of the predictive model. This is a clear and actionable suggestion that could help the authors improve their draft by providing additional evidence or examples to support their claims. However, the comment could be more helpful if it offered specific guidance on how to present this information or what aspects of the method should be highlighted. Overall, the feedback is 3 as it identifies a potential area for improvement but lacks depth and detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the biggest concern during reading is the lack of implementation details of the proposed methods, which should have been described in Section 4.1. This provides a clear and direct action for the authors to take, which is to include the implementation details in the specified section. The comment is explicit and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of implementation details of the proposed methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the biggest concern during reading is the lack of implementation details of the proposed methods. It suggests that these details should have been included in Section 4.1. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details. Without detailed justification or examples, the claim is 3, as it lacks sufficient evidence to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of implementation details of the proposed methods. It suggests that these details should have been included in Section 4.1, which is dedicated to implementation details. This feedback is clear and actionable, providing the authors with a direct path to improve their draft by addressing the missing information. However, the comment could be more helpful if it offered suggestions on what specific implementation details should be included or how to present them effectively. Overall, the comment is 4 as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of empirical evaluation and comparison with other methods, which is a significant concern for a paper submitted to NeurIPS. It also notes the lack of practical value and theoretical argumentation, suggesting that the paper is not suitable for publication in its current form. While the comment identifies the need for empirical evaluation and comparison, it does not provide specific guidance on how to address these issues or what kind of evaluation or comparison would be appropriate. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of empirical evaluation, comparison with other methods, and the absence of a theoretical argument for the practical value of the contribution. However, it does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what is missing, such as empirical evaluation and comparison with other methods, as well as the need for a theoretical argument for practical value. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation, comparison with other methods, and a theoretical argument for practical value. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The comment suggests that the theoretical contributions may be significant but does not elaborate on how this could be demonstrated. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to address the feedback effectively. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies several critical weaknesses in the paper, specifically the lack of empirical evaluation, comparison with other methods, and a theoretical argument for the practical value of the contribution. It highlights that even a theoretical paper should attempt to argue for its significance, which is not the case with the current submission. While the comment effectively points out the deficiencies, it does not provide specific suggestions or guidance on how to address these issues or improve the paper. The feedback is clear in its critique but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method discussed in the paper can be applied to general MDPs but is limited to navigation problems. It also mentions that combining RL and planning has already been discussed in PRMRL~[1] and suggests exploring the application of such algorithms in more general tasks. However, the comment does not provide explicit guidance on how the authors should address these limitations or suggestions. While it implies that the authors should consider expanding the applicability of their method, it lacks concrete steps or detailed instructions on how to do so. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the applicability of the method discussed in the paper, specifically mentioning that it is limited to navigation problems. It also references PRMRL~[1] as an example of combining RL and planning, suggesting that such algorithms could be applied to more general tasks. However, the comment does not specify which part of the paper discusses the method or where the limitations are mentioned, making it weakly grounded. The comment is specific in suggesting a potential direction for expansion, but without explicit references to the paper, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method discussed in the paper is limited to navigation problems and suggests exploring its application in more general tasks. The comment references PRMRL~[1] as an example of combining RL and planning, which provides some context for the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that the method is limited to navigation problems. While it provides a reference, it does not fully explain why this limitation exists or how it could be addressed. Therefore, the claim is 3, as it requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that the method discussed is primarily applicable to navigation problems and suggests exploring its application in more general tasks. It references PRMRL~[1] as an example of combining RL and planning, which could provide a basis for further exploration. While the comment highlights a potential area for expansion, it lacks specific guidance or suggestions on how the authors might address this limitation or conduct such an exploration. The feedback is 3 as it points out a direction for future work, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of a clear definition for the \"contrastive gap,\" which is a central concept in the paper. It acknowledges that an intuitive example was provided but notes that the setting of this example is less convincing. The comment suggests that a formal definition for the contrastive gap is still needed. While the action is explicit, the comment does not provide specific guidance on how to define the concept or what aspects of the definition should be clarified. The authors know they need to define the contrastive gap more formally, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is a central concept in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of a clear definition for the contrastive gap, even after providing an intuitive example. The comment further details the problem by noting that the setting of the example is less convincing and that a formal definition is still needed. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the \"contrastive gap\" is a central concept in the paper but has not been defined clearly. It acknowledges that an intuitive example was provided but notes that the setting of this example is less convincing. The comment suggests that a formal definition is still lacking. While the reviewer provides a logical reasoning for the claim by pointing out the lack of clarity, it does not include specific examples or references to support the assertion. This makes the claim 3, as it highlights the issue but lacks detailed evidence or references to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the lack of a clear definition for the \"contrastive gap,\" which is a central concept. It acknowledges that an intuitive example was provided but notes that the setting of this example is less convincing. The comment highlights the need for a formal definition of the contrastive gap, which is crucial for understanding and evaluating the work. By pointing out this gap, the comment provides clear and actionable feedback that can guide the authors in improving the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered specific suggestions on how to define the concept or what aspects of the definition should be clarified. Overall, the comment is 4 as it directs the authors to a critical area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that other baselines, such as those discussed in related work [29, 5, 6], should also be included. It implies that the authors should consider adding these baselines to their study. However, the comment does not provide explicit guidance on which specific baselines to include or how to integrate them into the paper. While the action is implicit, it is somewhat vague as it lacks concrete details on how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including other baselines, such as those discussed in related work [29, 5, 6], and implies that this would enhance the paper. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of additional baselines, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that other baselines should be included, referencing specific works from the related work section. The reviewer acknowledges that the authors have addressed their concerns in the response, which is a positive step. However, the comment lacks specific reasoning or examples to support why these additional baselines are necessary or how they would enhance the paper. This makes the claim 3, as it provides some justification but lacks detailed evidence or references to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including other baselines, such as those discussed in related work, would enhance the paper. It acknowledges that the authors have addressed the reviewer\"s concerns in their response, which is a positive step. However, the comment could be more helpful if it provided specific examples of which baselines should be included or why they are relevant to the study. Additionally, the suggestion to add an explanation for the chosen baseline in the final version of the paper is a constructive feedback. Overall, the comment offers some guidance but lacks depth and specificity, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the use of the phrase \"to meet\" in the paper, specifically on line 280, where it is unclear what is meant by \"a response candidate can meet each utterance.\" However, the comment does not provide any guidance or suggestions on how to address this issue or improve the clarity of the text. The action is implicit and vague, as the authors are left without clear instructions on how to resolve the confusion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 280,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the phrase \"to meet\" and how it is difficult to understand. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of \"to meet\" in the phrase \"a response candidate can meet each utterance\" is difficult to understand. However, the comment does not provide any further explanation, reasoning, or examples to support why this phrase is unclear or how it could be improved. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the phrase \"to meet\" in the paper, specifically on line 280, where it is unclear what is meant by \"a response candidate can meet each utterance.\" This feedback is 3 as it points out a potential source of confusion in the text, prompting the authors to reconsider the phrasing or provide additional clarification. However, the comment lacks depth and does not offer suggestions on how to improve the clarity or rephrase the sentence. To be more helpful, the comment could include examples of clearer phrasing or guidance on how to address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about other limitations of the method, specifically asking if the network is shallow in the graph case. This implies that the authors should consider discussing additional limitations or providing more details about the depth of the network. However, the comment does not explicitly instruct the authors to address these points or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address limitations but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about other limitations of the method, specifically asking if the network is shallow in the graph case. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for additional information about limitations, particularly regarding the depth of the network. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on other limitations of the method, specifically asking if the network is shallow in the graph case. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about other limitations of the method, specifically asking if the network is shallow in the graph case. This prompts the authors to consider additional limitations or provide more details about the depth of the network. While the comment identifies a potential area for improvement, it lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it encourages the authors to expand their discussion on limitations, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the dropout process, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment does not explicitly instruct the authors to provide this information, it implies that the authors should address these questions by including the requested details in their response. The action is implicit but concrete, as the authors know exactly what information is needed to clarify the dropout process. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the dropout\" and \"the reading of the response letter,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the dropping rate and the number of masks generated. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dropout process, specifically asking for the dropping rate and the number of masks generated. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises specific questions about the dropout process, seeking clarification on the dropping rate and the number of masks generated. While it identifies a gap in the explanation of the dropout method, it does not provide suggestions or guidance on how the authors might address these questions or improve their explanation. The comment is 3 as it points out a lack of clarity, but it lacks actionable advice or detailed feedback that could help the authors enhance their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the effectiveness of the proposed twostage optimization approach needs further justification. It suggests that showing the performance drop on fusion models is not sufficient and that comparisons with other singlestage attacks are needed to demonstrate effectiveness. The comment also highlights the importance of proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms to justify the technical contributions. This feedback provides clear and concrete actions for the authors to take, such as conducting additional comparisons and benchmarks, which makes the comment 5.", "grounding_specificity_rationale": "The comment addresses the effectiveness of the proposed twostage optimization approach, specifically mentioning the need for further justification and comparisons with other singlestage attacks. However, it does not specify which part of the paper discusses the twostage optimization approach, making it weakly grounded. The comment is specific in detailing what is missing, such as comparisons with other SOTA algorithms and benchmarks, which would help justify the effectiveness of the technical contributions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed twostage optimization approach needs further justification. It argues that showing the performance drop on fusion models is not sufficient and suggests that comparisons with other singlestage attacks are needed. The comment also highlights the importance of proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms to justify the technical contributions. While the comment provides a logical reasoning for the need for additional comparisons, it lacks specific examples or references to other SOTA algorithms or benchmarks, which would strengthen the argument. Therefore, the claim is 3, as it provides a clear direction for improvement but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the need for further justification of the effectiveness of the proposed twostage optimization approach. It points out that merely showing the performance drop on fusion models is insufficient and suggests that comparisons with other singlestage attacks are necessary to demonstrate the approach\"s effectiveness. Additionally, the comment highlights the importance of proper benchmarks and comparisons with other stateoftheart (SOTA) algorithms to justify the technical contributions. This feedback is clear and actionable, providing the authors with specific directions to enhance their draft by conducting additional comparisons and justifications. However, it could be more helpful if it offered suggestions on how to conduct these comparisons or what specific benchmarks to use. Overall, the comment is 4 as it guides the authors toward improving the clarity and justification of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the Perceptual Metric in Figure 2, suggesting that the Second Inpainted Images should be connected to the Inpainted Image rather than the Images Masked by Second Masks. This feedback is explicit and provides a clear action for the authors to take, which is to correct the connection in the figure. The comment is also concrete, as it specifies exactly what needs to be changed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Perceptual Metric, indicating that the Second Inpainted Images should be connected to the Inpainted Image rather than the Images Masked by Second Masks. This provides clear guidance on what needs to be corrected in the figure. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the connection between the Second Inpainted Images and the Inpainted Image in Figure 2. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the Perceptual Metric in Figure 2, pointing out that the Second Inpainted Images should be connected to the Inpainted Image rather than the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a precise direction for correcting an error in their figure. By addressing this issue, the authors can improve the clarity and accuracy of their presentation, which is crucial for the understanding of their results. However, the comment could be more helpful if it included an explanation of why this connection is important or how it affects the interpretation of the results. Overall, the comment is 4 as it directs the authors to a specific improvement that can enhance the quality of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, suggesting that it may only attend to neighboring nodes based on the description of N_l^(s) in equation 2. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this question or clarify the issue, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in equation 2. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its question about the attention mechanism, but without explicit references to sections or equations, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) in equation 2. This is a claim that requires verification, as it suggests a limitation or misunderstanding in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the attention mechanism in the paper, specifically whether each node can attend to its own lowerlevel representation. It references equation 2 and the description of N_l^(s) to suggest that only neighboring nodes are attended to. This feedback is 3 as it points out a potential limitation or misunderstanding in the paper, prompting the authors to clarify or address this issue. However, the comment lacks specific suggestions or guidance on how to resolve this concern, which would make it more actionable. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the lack of clarity in the main contribution and the unclear explanation of how the proposed method copes with dynamic largescale multitasking. It also points out that the automation aspect is unclear. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what specific changes are needed to clarify the main contribution and the automation aspect. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, which is unclear, and points out that the proposed method\"s ability or applicability is either overstated or not wellsupported. It also mentions that the main idea of how the proposed method copes with dynamic largescale multitasking is unclear and that the automation aspect is unclear. However, the comment does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what is unclear about the main contribution and the automation aspect. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear and that the proposed method\"s ability or applicability is either overstated or not wellsupported. It also mentions that the main idea of how the proposed method copes with dynamic largescale multitasking is unclear and that the automation aspect is unclear. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or references makes the claim 3, as the authors would need to invest effort to determine the exact issues and address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, specifically the lack of clarity in the main contribution and the unclear explanation of how the proposed method copes with dynamic largescale multitasking. It also points out that the automation aspect is unclear. These are important areas that the authors need to address to improve the clarity and impact of their work. However, the comment does not provide specific suggestions or guidance on how to clarify these aspects, such as what additional information or examples could be included to enhance the explanation. While it highlights key areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extractthengenerate methodologies and questioning the lack of a Related Work section. While the comment implies that the authors should address these issues, it does not provide explicit instructions or concrete suggestions on how to do so. The authors are left to infer that they need to include a Related Work section and compare their methodology with existing ones, but the comment lacks detailed guidance on how to execute these actions. Therefore, the comment is 3, as it identifies areas for improvement but does not provide clear steps for the authors to follow.", "grounding_specificity_rationale": "The comment raises questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extractthengenerate methodologies and questioning the lack of a Related Work section. However, it does not specify which part of the paper these concerns relate to, such as a particular section or experiment. The authors can infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique of the lack of related work and comparisons, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extractthengenerate methodologies and questioning the lack of a Related Work section. The comment suggests that the paper lacks context and comparison with existing work, which is a valid concern. However, it does not provide specific examples or references to existing work that could be used for comparison, making the claim 3. The authors would need to conduct additional research to address these concerns, which is a reasonable expectation but requires effort beyond the scope of the review comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the novelty and originality of the proposed methodology, specifically asking for comparisons with other extractthengenerate methodologies and questioning the lack of a Related Work section. It also points out the absence of experiments with other extractthengenerate methods using the proposed model, which is a critical gap in the paper. While the comment identifies significant weaknesses and areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it highlights important gaps in the paper, but it could be more actionable with additional guidance or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the need to train multiple models to test the approach and suggests exploring unlabelled data or applying constraints to improve model stability. While the comment implies that the authors should consider these alternatives, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the need to train multiple models to test the approach and suggests exploring unlabelled data or applying constraints to improve model stability. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting alternative approaches to address the issue, but without clear references to the paper, the authors may find it challenging to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a subjective opinion about the need to train multiple models to test the approach, describing it as \"not particularly appealing.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. It lacks specific details or references that would help the authors understand the basis of this opinion or how it could be addressed. As a result, the claim is 1, as it does not provide sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the need to train multiple models to test the approach, describing it as \"not particularly appealing.\" It suggests exploring alternative methods, such as using unlabeled data or applying constraints, to improve model stability. While the comment identifies a potential issue and offers a direction for improvement, it lacks specific guidance or detailed suggestions on how to implement these alternatives. The authors are given a general idea of what could be explored but are not provided with actionable steps or examples to follow. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of quantitative measurement regarding the extent of occupation bias relative to real distributions in society. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific measurements could be used. The comment lacks actionable guidance, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of quantitative measurement of occupation bias relative to real distributions in society. However, it does not specify which part of the paper this critique pertains to, such as a particular section or analysis. Without explicit references or context, the authors may find it challenging to pinpoint the exact area needing revision. The comment is specific in identifying the absence of quantitative measurement but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point claims that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. This claim is based on the absence of such measurements in the paper, which is a factual observation. However, the comment does not provide any specific examples or references to support the claim, making it difficult for the authors to understand the full context or implications of the critique. Therefore, the comment is considered 2, as it lacks detailed justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks quantitative measurement to assess the extent of occupation bias relative to real distributions in society. This is a valuable observation that highlights a gap in the analysis, which could be addressed to enhance the paper\"s contribution. However, the comment does not provide suggestions or guidance on how the authors might incorporate such measurements or what specific metrics could be used. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends using a real DICOM image instead of a PNG image for the experiment data and suggests using the FastMRI challenge dataset. It also advises comparing inference speed between different methods. These suggestions are clear and provide concrete actions for the authors to take, making the comment 5. The authors know exactly what changes to make to improve their draft, ensuring a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of a real DICOM image instead of a PNG image, which allows the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions, such as recommending the FastMRI challenge dataset and comparing inference speed between different methods. This level of detail and explicit guidance makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests using a real DICOM image instead of a PNG image for the experiment data and recommends using the FastMRI challenge dataset. It also advises comparing inference speed between different methods. However, the comment lacks specific reasoning or evidence to support why using a real DICOM image is preferable or how the FastMRI dataset would be beneficial. Without detailed justification or examples, the claim is 3, as it provides a suggestion but lacks the necessary support to fully substantiate the recommendation.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by recommending the use of a real DICOM image instead of a PNG image for the experiment data. It also suggests using the FastMRI challenge dataset and comparing inference speed between different methods. This feedback is clear and offers concrete steps for the authors to improve their experimental setup and analysis, making it 4. However, the comment could be more comprehensive by explaining why using a real DICOM image is important or how the FastMRI dataset would benefit the study. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that further optimization and validation are needed for the binder design provided by ProtPainter. However, it does not specify what aspects of the design need optimization or how to validate it. The comment lacks concrete guidance on how the authors should proceed with these actions, leaving them with a vague understanding of what needs to be done. As a result, the comment is barely actionable, as the authors are not provided with clear steps to improve their draft.", "grounding_specificity_rationale": "The comment addresses the binder design provided by ProtPainter, suggesting that further optimization and validation are required. However, it does not specify which part of the paper discusses this design, making it weakly grounded. The comment is specific in its request for further optimization and validation, but without clear references to the paper, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that ProtPainter provides only an empirical conformation estimation for binder design and suggests that further optimization and validation are required. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion for further optimization and validation. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the binder design provided by ProtPainter, noting that it is limited to an empirical conformation estimation and suggests that further optimization and validation are needed. This feedback is 3 as it points out a potential weakness in the paper and provides a direction for improvement. However, the comment lacks specific suggestions or guidance on how to optimize or validate the binder design, which would make it more actionable for the authors. To be more helpful, the comment could include examples of potential optimization techniques or validation methods that could be applied. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about what would happen if the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. The question is not phrased as a suggestion or a request for clarification, leaving the authors without any guidance on how to address this issue. As a result, the comment lacks actionability, as it does not offer any direction for improvement or change in the draft. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment poses a question about a specific scenario involving the original CAD model and SV BRDF maps. However, it does not specify which part of the paper this scenario is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry, but it lacks grounding as it does not reference a particular section or context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about a specific scenario involving the original CAD model and SV BRDF maps. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about a specific scenario involving the original CAD model and SV BRDF maps. While it highlights a potential area of interest, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this scenario or its implications for their work. Without specific advice or direction, the comment does not offer much value in helping the authors enhance their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the statement about initialization should be more carefully stated, as initialization plays a role in the context of NGD, which is a discretization of NGF. The reviewer references a specific paper by Kunstner et al. (2019) to support this claim. While the comment implies that the authors should revise their statement on initialization, it does not provide explicit guidance on how to make the statement more accurate or detailed. The reference to the external work is a helpful starting point, but the authors still need to determine how to apply this information to their draft. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete instructions on how to implement the suggested changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Initialization,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the statement about initialization should be more carefully stated, particularly in the context of NGD being a discretization of NGF and the role of initialization as an initial value problem (IVP). The comment provides a reference to a specific paper by Kunstner et al. (2019), which supports the claim and offers a potential direction for further exploration. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that initialization plays a role in the context of NGD, which is a discretization of NGF, and that solving NGF is an initial value problem (IVP). The reviewer suggests that the statement about initialization should be more carefully stated, referencing a specific paper by Kunstner et al. (2019). This provides a logical basis for the claim, as the reference supports the assertion that initialization is relevant in this context. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper. Overall, the claim is 4, as it is supported by a reference but could benefit from additional explanation or examples.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the statement about initialization. It provides a logical reasoning by connecting the role of initialization in the context of NGD, which is a discretization of NGF, and the fact that solving NGF is an initial value problem (IVP). The comment suggests that the statement about initialization should be more carefully stated, offering a reference to a relevant paper by Kunstner et al. (2019) for further exploration. This feedback is clear and actionable, as it directs the authors to reconsider their statement on initialization and provides a potential direction for improvement. However, it could be more helpful if it included specific suggestions on how to rephrase or expand the statement. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the extraction of named entities from the datasets is unclear and recommends an Englishproofreading to improve the readability of the paper. While the comment implies that the authors should clarify the extraction process, it does not provide specific guidance on how to do so or what aspects of the extraction need clarification. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve the clarity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of named entity extraction from datasets and suggests an Englishproofreading to improve readability. However, it does not specify which part of the paper discusses the extraction process, making it weakly grounded. The comment is specific in suggesting an Englishproofreading, but it lacks detailed guidance on what aspects of the extraction process need clarification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the extraction of named entities from datasets is unclear and suggests an Englishproofreading to improve readability. However, it does not provide any specific examples, reasoning, or references to support the claim about the clarity of the extraction process. The suggestion for an Englishproofreading is a general recommendation without detailed justification or evidence of how it would improve the paper. Therefore, the comment is considered 1, as it lacks sufficient support for the claims made.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of named entity extraction from datasets. It suggests that an Englishproofreading could improve the readability of the paper. While the comment highlights a potential issue, it lacks depth and does not provide detailed guidance or suggestions on how to improve the extraction process or enhance the clarity of the paper. The feedback is 3 as it points out a specific area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the inversion of matrix determination or the division of the number of samples is being referred to. It also mentions a mistake in equations, but it does not specify which equations or what the mistake is. The comment lacks explicit guidance or concrete suggestions on how to address the issue, leaving the authors uncertain about the exact action needed. The action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment mentions \"W4 \u2013 Mistakes in Eqs,\" which provides some grounding as it implies that the issue is related to equations in the paper. However, it does not specify which equations are incorrect or what the specific mistake is, making it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment is specific in identifying a potential issue with equations but lacks full grounding because it does not explicitly mention the section or page where the equations are located. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the interpretation of a specific equation, specifically whether it refers to the inversion of a matrix or the division of the number of samples. This is a factual question that does not contain an opinion, claim, or suggestion requiring verification. It is purely descriptive and does not fit the criteria for a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the interpretation of a specific equation, specifically whether it refers to the inversion of a matrix or the division of the number of samples. This is a clear and specific observation that could help the authors clarify a potential misunderstanding in their work. However, the comment does not provide any guidance on how to address this issue or suggest ways to improve the clarity of the equation. While it identifies a potential area of confusion, it lacks actionable feedback or suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the clarity of the motivation for the task and the potential downstream applications or benefits of amodal tracking. It also questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The authors can infer that they need to provide more detailed explanations and examples, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it highlights important areas for improvement but does not offer detailed steps for execution.", "grounding_specificity_rationale": "The comment addresses the motivation of the task, specifically questioning the clarity of the motivation and the potential downstream applications or benefits of amodal tracking. It also raises concerns about the quality of annotations due to uncertainty in amodal predictions. However, the comment does not specify which part of the paper discusses the motivation or where the authors should address these concerns. While the authors might infer that it relates to the introduction or motivation sections, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in detailing what needs to be clarified, but it is not fully grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the unclear motivation of the task and questions the potential downstream applications or benefits of amodal tracking. It also questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The absence of concrete evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment raises important questions about the motivation and potential applications of the task, specifically regarding the difficulty of predicting the state of objects when they are totally occluded. It also questions the quality of annotations and the handling of uncertainty in amodal predictions. While the comment identifies critical areas for clarification and improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it highlights key areas for improvement, but it lacks actionable advice, making it difficult for the authors to fully understand and implement the necessary changes. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. While the suggestion is explicit, it lacks concrete details on how to implement this change, such as specific experimental setups or parameters to use. The authors are given a clear direction but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in suggesting the inclusion of GPT3.5 experiments, but without clear grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests including experiments with GPT3.5 to provide a more comprehensive evaluation, given the expense of GPT4. The comment is based on a logical reasoning that GPT3.5 is a more affordable option, which could enhance the evaluation of the proposed approach. However, the comment lacks specific examples or references to support the claim that GPT3.5 is a suitable alternative or that it would provide a more comprehensive evaluation. This makes the claim 3, as it provides a logical basis but lacks detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests including experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of the proposed approach. This feedback is clear and actionable, as it offers a specific suggestion for improving the experimental setup. By including GPT3.5, the authors can demonstrate the effectiveness of their approach across different models, which could enhance the robustness and applicability of their findings. However, the comment could be more helpful if it provided additional context or rationale for why GPT3.5 is a suitable alternative or how it might impact the results. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a slight confusion regarding the use of the word \"confident\" in the context of ceterus paribus convexity. It suggests that the author might be referring to human interpretability rather than model confidence, and recommends a slight rephrasing to clarify this point. While the comment identifies a potential issue and suggests a specific action (rephrasing), it does not provide detailed guidance on how to rephrase the sentence. The action is explicit but somewhat vague, as the authors know what needs to be addressed but may not be entirely sure of the exact wording. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"We have found it easier to be confident about applying ceterus paribus convexity,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of the word \"confident\" and suggesting that it might refer to human interpretability rather than model confidence. The comment provides a clear suggestion for rephrasing to clarify this point. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of the word \"confident\" in the context of ceterus paribus convexity, suggesting that it might refer to human interpretability rather than model confidence. The reviewer provides a logical reasoning by questioning the clarity of the statement and suggesting a potential interpretation. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to consider the context and make an inference to address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confusion in the use of the word \"confident\" in the context of ceterus paribus convexity, suggesting that it might refer to human interpretability rather than model confidence. The reviewer provides a clear suggestion for rephrasing to clarify this point, which is a valuable contribution to the authors. However, the comment could be more helpful if it offered additional context or examples to further guide the authors in making the necessary changes. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, providing actionable advice. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the presentation of empirical findings, including missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two smallscale datasets and a single architecture type for core findings. While the comment identifies specific areas that need improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should add axis labels, clarify the masking of curves, conduct multiple seed experiments, and expand the dataset and architecture types for core findings. However, the lack of concrete guidance on how to implement these changes makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the figures and empirical results, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two smallscale datasets and a single architecture type for core findings. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details what is lacking in the figures and empirical results, providing clear guidance on how to improve them. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity and confidence in its empirical findings due to issues with the presentation of figures and results. It mentions specific problems, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two smallscale datasets and a single architecture type for core findings. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the exact nature of the issues and how they impact the confidence in the empirical results. Therefore, the comment is 3, as it provides a general direction but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies several specific issues with the presentation of empirical findings, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of only two smallscale datasets and a single architecture type for core findings. These points are clear and actionable, providing the authors with concrete areas to address in order to improve the clarity and confidence in their empirical results. However, the comment could be more helpful by suggesting specific ways to address these issues, such as recommending the inclusion of multiple seeds or additional datasets. Overall, the feedback is 4 as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of the number of weight updates as a metric instead of the number of network updates, given that the brain operates in parallel. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their paper. The comment lacks concrete details on what additional feedback or improvements are needed, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of metric, specifically questioning the use of the number of weight updates instead of the number of network updates, given that the brain operates in parallel. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its critique of the metric choice but lacks grounding, as the authors cannot confidently determine which section or part of the paper this critique relates to. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of the number of weight updates as a metric, suggesting that the number of network updates might be a better metric given the parallel nature of the brain. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the number of network updates would be a more appropriate metric. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a valid question about the choice of metric, specifically questioning the use of the number of weight updates instead of the number of network updates, given that the brain operates in parallel. This is a relevant point that could lead to a deeper discussion or clarification in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their paper. While it identifies a potential area for improvement, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. However, it does not provide any explicit or implicit actions for the authors to take. The question is more of a request for clarification, leaving the authors without a clear direction on how to address the issue. Without specific guidance or suggestions, the authors are not provided with a concrete path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment lacks specificity as it does not provide details on what aspects of the adversarial prediction accuracy are unclear or how it differs from classical prediction accuracy. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. It does not present a claim or opinion but rather seeks clarification. Therefore, it is a normal statement and should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the real scenarios where the objective given by the adversarial prediction accuracy, as proposed by the authors, differs from classical prediction accuracy. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the distinction. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 2, as it identifies a potential area of concern but does not offer meaningful guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the contrastive learning framework is the same as SimCLR, but it does not provide any explicit or implicit actions for the authors to take. It lacks any guidance or suggestions on how the authors might address this issue or improve their draft. Without any actionable steps or recommendations, the authors are left without a clear understanding of what needs to be done to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the contrastive learning framework is the same as SimCLR, but it does not specify which part of the paper this claim pertains to, such as a specific section, figure, or experiment. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the framework are identical to SimCLR, making it difficult for the authors to understand the exact issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contrastive learning framework is the same as SimCLR, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comparison or how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment claims that the contrastive learning framework used in the paper is the same as SimCLR, without providing any context, explanation, or justification for this assertion. This lack of detail and specificity makes the comment unhelpful, as it does not offer any actionable feedback or guidance for the authors to improve their work. Without additional information or suggestions, the authors are left without a clear understanding of what needs to be addressed or how to enhance their draft. Therefore, the comment is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors could improve their paper by making the comparisons between the present work and the related work of Zemel et al. (2013) more systematic. It specifically recommends comparing the best performance of each method to provide a more comprehensive analysis. While the comment implies an action\u2014making the comparisons more systematic\u2014it does not provide explicit guidance on how to achieve this, such as suggesting specific metrics or analysis techniques to use. The action is concrete in terms of the desired outcome but lacks detailed instructions on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the related work of Zemel et al. (2013) and the present paper, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, namely making the comparisons more systematic with respect to the tuning of each method. This provides clear guidance on what the authors need to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons more systematic with respect to the tuning of each method. It references the work of Zemel et al. (2013) as a related work and suggests that the present paper explains how it is different and provides comparisons in simulations. However, the comment does not provide specific examples or detailed reasoning on how the comparisons could be improved or what aspects are lacking in the current analysis. This makes the claim 3, as it highlights an area for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that the comparisons between the present work and the related work of Zemel et al. (2013) could be made more systematic. It provides a clear and actionable suggestion to compare the best performance of each method, which would enhance the comprehensiveness and rigor of the analysis. This feedback is valuable as it directs the authors to a concrete step that could significantly improve the clarity and depth of their comparisons. However, the comment could be more helpful if it included specific suggestions on how to conduct these systematic comparisons or which metrics to focus on. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to estimate the time complexity of the learning algorithm to prove its scalability properties. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific task that needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"time complexity of the learning algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the estimation of the time complexity to prove scalability properties. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. This is a claim that requires justification, as it implies that the current presentation lacks sufficient evidence or analysis of the algorithm\"s scalability. However, the comment does not provide specific reasoning or examples to support why this estimation is necessary or how it would impact the paper\"s claims about scalability. Without additional context or evidence, the claim remains 3, as it highlights an area for improvement but lacks detailed justification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s analysis and presentation. By addressing this point, the authors can strengthen their argument regarding the scalability of their algorithm, which is crucial for its practical application. However, the comment could be more helpful if it included additional guidance on how to estimate the time complexity or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider connecting the third point of definition one to the properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. While the comment implies that the authors should explore this connection, it does not provide explicit instructions on how to make this connection or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition one\" and \"chapter 4 of Steinwart and Christmann,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a connection to the properties of universal kernels and provides a reference to support this suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a connection between the third point of definition one and the properties of universal kernels, referencing chapter 4 of Steinwart and Christmann. This provides a specific reference and logical reasoning to support the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced chapter to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests a potential connection between the third point of definition one and the properties of universal kernels, as discussed in chapter 4 of Steinwart and Christmann. This feedback is 3 as it points out a possible area for further exploration or elaboration in the paper. However, the comment lacks specific guidance on how to make this connection or what aspects of the universal kernels should be considered. While it provides a reference for further reading, it does not offer detailed suggestions for improvement, leaving the authors with a general direction but not a clear path forward. Therefore, the comment is rated as 3, aligning with a score of 3."}
