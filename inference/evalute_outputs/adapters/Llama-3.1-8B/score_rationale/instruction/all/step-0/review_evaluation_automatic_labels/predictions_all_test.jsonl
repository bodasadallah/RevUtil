{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper would benefit from a revision due to the authors\" use of minmax optimization, which is typically challenging to train and get right, especially for PDEs with advective terms. The comment acknowledges that the methodology provided by the authors appears to outperform the baselines but notes the lack of clarity in the presentation and the precise steps involved. While the comment implies that a revision is necessary, it does not provide specific guidance on what aspects of the paper need revision or how to improve the clarity. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of minmax optimization, which is typically challenging to train and get right, especially for PDEs with advective terms. It acknowledges that the methodology provided by the authors seems to outperform the baselines but notes the lack of clarity in the presentation and the precise steps involved. However, the comment does not specify which part of the paper discusses the minmax optimization or where the lack of clarity is present. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in identifying the issue with the methodology and its presentation, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that minmax optimization is \"usually hard to train and get right,\" especially for PDEs with advective terms. The reviewer acknowledges that the methodology provided by the authors seems to outperform the baselines but notes the lack of clarity in the presentation and the precise steps involved. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim about the difficulty of minmax optimization for PDEs with advective terms. This lack of detailed justification makes the claim 3, as the authors may need to further explore the challenges and potential improvements in their methodology. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the methodology provided by the authors seems to outperform the baselines but notes the lack of clarity in the presentation and the precise steps involved. It suggests that the paper would benefit from a revision, implying that the authors should clarify their methodology and presentation. However, the comment does not provide specific guidance on how to improve the clarity or what aspects of the methodology need further explanation. While it identifies a potential area for improvement, the feedback is somewhat vague and lacks actionable suggestions, making it 3. The authors are given some direction but are left to infer the exact changes needed, which limits the comment\"s usefulness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the practicality of using the modified TD learning algorithm defined in Definition 5.1 over the original proposal (Algorithm 1). While it does not explicitly instruct the authors to make a change, it implies that the authors should provide a justification for their choice or consider the practical implications of using the modified algorithm. The action is implicit but clear, as the authors can infer that they need to address the question of practicality. However, the comment lacks concrete guidance on how to address this issue, such as suggesting specific aspects to consider or potential benefits of the modified algorithm. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Definition 5.1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the practicality of using the modified TD learning algorithm over the original proposal. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the practicality of using the modified TD learning algorithm over the original proposal, suggesting that the authors should provide a justification for their choice. However, the comment does not offer any specific reasoning, examples, or references to support why the original proposal should be preferred over the modified algorithm. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the basis of the question themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the practicality of using the modified TD learning algorithm defined in Definition 5.1 over the original proposal (Algorithm 1). This is a valuable point that prompts the authors to consider the practical implications of their theoretical analysis and to provide a justification for their choice. However, the comment does not offer specific suggestions or guidance on how the authors might address this question or improve their draft. While it identifies an area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the practical utility of the data quality metric proposed in the paper, specifically the diversity coefficient. It points out that the claim is not empirically validated, which is a significant concern given the emphasis on Task2Vec and model diversity. However, the comment does not provide explicit guidance on how the authors should address this concern or suggest specific steps to validate the claim. The action is implicit and somewhat vague, as the authors are left to infer that they need to empirically validate the claim but are not given concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"data quality metric\" and the \"diversity coefficient,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of empirical validation of the claim regarding the practical utility of the data quality metric, particularly in relation to Task2Vec and model diversity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper suggests a data quality metric, the diversity coefficient, but does not empirically validate this claim. This is a significant concern, especially given the emphasis on Task2Vec and model diversity in the paper. The comment highlights a gap in the paper\"s validation process, which is a valid point. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional evidence or explanation to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the practical utility of the data quality metric proposed in the paper, specifically the diversity coefficient. It points out that the claim is not empirically validated, which is a critical issue given the emphasis on Task2Vec and model diversity. This feedback is clear and actionable, as it highlights a specific area that needs further validation and empirical evidence. By addressing this concern, the authors can strengthen the credibility and practical relevance of their work. However, the comment could be more helpful if it provided suggestions on how to empirically validate the claim or examples of similar approaches. Overall, the comment is 4, as it directs the authors to a crucial area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that using canary clients might be less efficient compared to using canary examples, implying that more resources might be needed. However, the comment does not provide explicit guidance on how to address this issue or suggest alternative methods. The action is implicit and vague, as the authors are left to infer that they should reconsider their approach but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that using canary clients might be less efficient compared to using canary examples, implying that more resources might be needed. However, it does not specify which part of the paper discusses canary clients or examples, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of efficiency or resource allocation are being considered. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that using canary clients might be less efficient compared to using canary examples, implying that more resources might be needed. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or data to substantiate the assertion, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that using canary clients might be less efficient compared to using canary examples, implying that more resources might be needed. While it identifies a potential issue with the approach, it lacks specificity and does not provide actionable advice or suggestions on how the authors might address this inefficiency. The comment does not offer guidance on alternative methods, optimizations, or ways to improve resource allocation. As a result, the feedback is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed approach, noting that it is computeintensive due to the need for pretraining the GAA model on the same dataset as the QA model. It also questions the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could lead to longer annotation times. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the approach. The action is implicit and vague, as the authors are left to infer that they should address the computeintensive nature of the approach and the assumption about the GAA model\"s performance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the proposed approach, namely its computeintensive nature due to the pretraining of the GAA model on the same dataset as the QA model. It also questions the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could impact annotation times. However, the comment does not explicitly mention which part of the paper discusses this approach, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in detailing the issue with the approach, providing a clear critique of the assumption and its potential impact. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the computeintensive nature of the proposed approach, specifically mentioning the pretraining of the GAA model on the same dataset as the QA model. It questions the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could lead to longer annotation times. While the comment highlights a potential issue, it lacks specific examples or references to support the claim. The reasoning is logical but requires more detailed evidence or examples to be 5. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed approach, specifically its computeintensive nature due to the pretraining of the GAA model on the same dataset as the QA model. It questions the assumption that the resultant GAA model is performant enough to provide meaningful prompts to annotators, which could lead to longer annotation times. This feedback highlights a critical aspect of the methodology that could impact the efficiency and effectiveness of the approach. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the approach. While it points out a significant concern, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, noting its high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks specific suggestions or guidance on how to mitigate the dependence on the server dataset or improve the method\"s generality. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a potential limitation of the proposed method, specifically its high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, it does not specify which part of the paper discusses the proposed method or where this dependence is mentioned. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what needs to be addressed or how to mitigate this dependence. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method has a high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically its high dependence on the server dataset, which limits its potential use cases and reduces its generality. This feedback is relevant and could prompt the authors to consider ways to mitigate this dependence or expand the method\"s applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative datasets or methods to reduce dependence. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks why only a single downstream search method (EA) is provided and suggests adding other methods like BO and LS. This provides a clear and direct action for the authors to take, which is to include additional methods in their analysis. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Why only a single downstream search method (EA) is provided?\" This allows the authors to accurately identify the part of the paper being addressed, specifically the section discussing downstream search methods. The comment is also specific because it suggests adding other methods like BO and LS, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of using only a single downstream search method (EA) and suggests adding others like BO and LS. However, it does not provide any reasoning or evidence to support why these additional methods should be included or how they would enhance the study. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the choice of using only a single downstream search method (EA) and suggesting the inclusion of other methods like BO and LS. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the study by diversifying the methods used. However, the comment could be more helpful if it explained why these additional methods are important or how they might contribute to the study. Despite this, the comment still offers valuable guidance for the authors to consider, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper regarding the comparison of FLOPs and FPS in sparse network research. It notes that while FLOPs for pDETR are listed in Table 7, a direct comparison with other sparse models is missing. This feedback provides a clear and explicit action for the authors to take, which is to include a direct comparison of FLOPs and FPS with other sparse models. The comment is specific and provides a concrete suggestion on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a direct comparison of FLOPs and FPS with other sparse models. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not sufficiently highlight the comparison of FLOPs and FPS in sparse network research, despite listing FLOPs for pDETR in Table 7. The comment suggests that a direct comparison with other sparse models is missing. This claim is 3 as it points out a specific area where the paper could be improved, but it lacks detailed reasoning or examples of how the comparison should be made. The authors would need to infer the exact nature of the comparison that is missing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the comparison of FLOPs and FPS in sparse network research. It points out that while FLOPs for pDETR are listed in Table 7, a direct comparison with other sparse models is missing. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the paper by including a direct comparison with other sparse models. By addressing this point, the authors can strengthen the paper\"s contribution and relevance to the field. Therefore, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive by suggesting how to conduct the comparison or what specific aspects to focus on."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the metrics used in the paper, noting that they are hard to understand and that the results in the tables are unclear. It provides a concrete example of how the accuracy for binary boolean questions in Table 5 could be misleading, suggesting that simply reversing the prediction of DollyV27B would yield an accuracy of 97%, which is clearly wrong. This feedback is explicit and provides a clear action for the authors to take, which is to clarify the metrics and ensure they are accurately represented in the results. The comment is 5 as it offers a specific example of how the metrics could be misinterpreted and provides a clear direction for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the metrics, explaining that they are hard to understand and that the results in the tables are unclear. The comment provides a concrete example of how the accuracy for binary boolean questions could be misleading, suggesting that simply reversing the prediction of DollyV27B would yield an accuracy of 97%, which is clearly wrong. This level of detail helps the authors understand what needs to be clarified or improved in their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the metrics are hard to understand, which affects the clarity of the results in the tables. It provides a specific example by explaining that if the accuracy for binary boolean questions in Table 5 is measured by the number of correct answers divided by the total number of questions, simply reversing the prediction of DollyV27B would yield an accuracy of 97%, which is clearly wrong. This example provides a clear and logical reasoning to support the claim, making the comment 4. However, the comment could be strengthened by referencing specific sections of the paper where these metrics are discussed, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the metrics used in the paper, noting that they are hard to understand and that the results in the tables are unclear. It provides a concrete example by explaining that if the accuracy for binary boolean questions in Table 5 is measured by the number of correct answers divided by the total number of questions, simply reversing the prediction of DollyV27B would yield an accuracy of 97%, which is clearly wrong. This feedback is actionable as it highlights a potential misunderstanding in the results and suggests that the authors clarify the metrics to ensure they are accurately represented. By addressing this issue, the authors can improve the clarity and transparency of their work. Therefore, the comment is rated as 4, as it provides clear guidance for improvement but could be more comprehensive by suggesting specific ways to clarify the metrics."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the Gaussian assumption and its applicability in practice. It asks whether the assumption is typical in practice, whether it is always possible to compute the \"effective\" variance for nonGaussian outputs, and whether there is a finiteN expansion that characterizes the departure from Gaussianity in the nonideal case. While these questions imply that the authors should address these points, they do not provide explicit instructions on how to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide additional analysis or discussion on these topics. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the Gaussian assumption and its applicability in practice, specifically asking whether it is typical in practice and whether there is a finiteN expansion that characterizes the departure from Gaussianity in the nonideal case. However, it does not explicitly mention a specific section of the paper where these questions are relevant, making it weakly grounded. The comment is specific in its questions about the Gaussian assumption and its applicability, but without clear references to specific sections, the authors may find it challenging to pinpoint the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification and additional information about the Gaussian assumption and its applicability in practice. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek to understand the limitations and applicability of the Gaussian assumption, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the Gaussian assumption and its applicability in practice. It asks whether the assumption is typical in practice, whether it is always possible to compute the \"effective\" variance for nonGaussian outputs, and whether there is a finiteN expansion that characterizes the departure from Gaussianity in the nonideal case. These questions are relevant and provide the authors with a clear direction for further exploration and clarification. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of similar situations in the literature. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the approach to the math and science categories, suggesting that there is an open vocabulary problem that is not clearly addressed. It also notes that other categories are tackled using Wikipedia and a popularity metric. However, the comment does not provide specific guidance on how the authors should address this issue or improve their approach. It lacks concrete suggestions or actions for the authors to take, leaving them without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the approach to the math and science categories, suggesting an open vocabulary problem that is not clearly tackled. It also mentions that other categories are tackled using Wikipedia and a popularity metric. However, the comment does not specify which part of the paper discusses these categories, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the issue with the math and science categories and how it differs from other categories, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the approach to the math and science categories suggests an open vocabulary problem that is not clearly tackled. It contrasts this with the approach to other categories, which are tackled using Wikipedia and a popularity metric. However, the comment lacks specific examples or detailed reasoning to support the claim about the open vocabulary problem in the math and science categories. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential issue with the approach to the math and science categories, suggesting that there is an open vocabulary problem that is not clearly addressed. It contrasts this with the approach to other categories, which are tackled using Wikipedia and a popularity metric. While the comment highlights a specific area for improvement, it lacks detailed guidance or suggestions on how the authors might address the open vocabulary problem or improve their methodology. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional guidance or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the similarity between the current work and stochastic routing warrants a more thorough discussion. However, it does not provide explicit guidance on how to conduct this discussion or what specific aspects should be included. The action is implicit and somewhat vague, as the authors can infer that they need to expand the discussion but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the similarity between the current work and stochastic routing warrants a more thorough discussion. However, it does not specify which part of the paper this comparison is currently lacking in, nor does it provide details on what aspects of the discussion should be expanded. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the discussion should be expanded. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the similarity between the current work and stochastic routing warrants a more thorough discussion. However, it does not provide any specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples that would help the authors understand why a more thorough discussion is necessary. Without such support, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the similarity between the current work and stochastic routing warrants a more thorough discussion. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct this discussion or what aspects should be included. The comment points out a potential gap in the paper but does not offer actionable advice or suggestions for improvement. As a result, the feedback is 3, as it highlights an area for expansion but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that convergence in direction should be considered as convergence, given that the CE loss can never be minimized due to the exponential. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or address the issue of convergence in their paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that convergence in direction should be considered as convergence, given that the CE loss can never be minimized due to the exponential. However, it does not specify which part of the paper this issue pertains to, such as a specific section, figure, or table. Without explicit references, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what changes or clarifications are needed to address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that convergence in direction should be considered as convergence, given that the CE loss can never be minimized due to the exponential. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is the case. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that convergence in direction should be considered as convergence, given that the CE loss can never be minimized due to the exponential. While the comment identifies a potential issue with the interpretation of convergence, it lacks specificity and does not provide actionable guidance on how the authors should address this concern. Without detailed suggestions or examples, the authors may struggle to understand how to incorporate this feedback into their draft. Therefore, the comment is 2, as it points out a potential issue but does not offer clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should try replacing components with other models to prove the robustness of their proposed framework. However, it does not provide specific guidance on which components to replace, what alternative models to use, or how to conduct the evaluation. The action is implicit and lacks concrete details, making it 3. The authors can infer that they need to conduct experiments with different components and models, but the lack of specific guidance makes it challenging to implement effectively.", "grounding_specificity_rationale": "The comment addresses the issue of the authors\" claim about the flexibility of their framework, specifically questioning whether they have tested the robustness of their framework by replacing components with other models. However, it does not specify which part of the paper discusses this claim or where the authors should make these replacements. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in its critique of the lack of testing for robustness, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the authors have stated the flexibility of their framework but have not tested it by replacing components with other models to prove the robustness of the proposed framework. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed reasoning or evidence makes the claim 2, as it provides a general critique but does not fully substantiate it. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that while the authors claim the framework\"s flexibility, they have not tested this by replacing components with other models to prove the robustness of the proposed framework. This feedback is 3 as it points out a gap in the evaluation process that could be addressed to strengthen the paper. However, the comment lacks specific suggestions or guidance on how the authors might conduct these tests or which components could be replaced. To be more helpful, the comment could provide examples or detailed instructions on how to proceed. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of 30 disentangled factors for the Atari game experiments. It implies that specifying this number might be challenging for an arbitrary domain. However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue or suggest alternative methods for determining the number of disentangled factors. The lack of actionable advice leaves the authors without a clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Atari game experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of 30 disentangled factors and suggests that it might be challenging to specify for an arbitrary domain. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the choice of 30 disentangled factors for the Atari game experiments, suggesting that it might be challenging to specify for an arbitrary domain. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or how it could be improved. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the choice of 30 disentangled factors for the Atari game experiments, suggesting that it might be challenging to specify for an arbitrary domain. While it identifies a potential issue, it lacks depth and does not provide any suggestions or guidance on how the authors might address this concern. The comment points out a specific area that could be improved but does not offer actionable advice or insights into how the authors might resolve the issue. Therefore, the comment is 3, as it prompts the authors to consider this aspect of their work but does not fully support them in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with the use of colloquial expressions, such as \"By the way,\" which are considered unprofessional. The reviewer provides a concrete example of the issue, allowing the authors to directly identify and address the problem. This feedback is clear and actionable, as it specifies what needs to be corrected, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of colloquial expressions, specifically referencing the phrase \"By the way,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of colloquial expressions, which are considered unprofessional. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that colloquial expressions are unprofessional, specifically mentioning the phrase \"By the way.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this expression is unprofessional or how it affects the paper\"s professionalism. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of colloquial expressions, such as \"By the way,\" which are considered unprofessional. This feedback is clear and actionable, as it provides a concrete example of the issue and suggests that such expressions should be avoided for professional writing. By pointing out this specific issue, the comment offers the authors a clear direction for improving the professionalism and clarity of their writing. However, it could be more helpful if it provided additional context or suggestions on how to replace these expressions with more appropriate language. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the abbreviations \"LLH\" and \"ECE\" are not defined in the paper, despite the abbreviation \"OOD\" being explicitly defined. It highlights the importance of these abbreviations in the context of the work. While the comment identifies a clear issue with the lack of definitions, it does not provide explicit guidance on how to address this problem. The authors are left to infer that they need to define these abbreviations, but without specific instructions on where or how to do so, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abbreviations \"LLH\" and \"ECE,\" allowing the authors to accurately identify the parts of the paper where these abbreviations are used. It is also specific because it clearly specifies the issue of undefined abbreviations and the importance of these abbreviations in the context of the work. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abbreviations \"LLH\" and \"ECE\" are not defined in the paper, despite the abbreviation \"OOD\" being explicitly defined. This is a factual statement that does not require verification or justification. The comment is purely descriptive and does not contain any subjective opinions, suggestions, or claims that need to be verified. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the lack of definitions for important abbreviations like \"LLH\" and \"ECE,\" despite the explicit definition of \"OOD.\" This is a critical oversight that can lead to confusion for readers and hinder the understanding of the paper. By pointing out this issue, the comment provides clear and actionable feedback that the authors need to address to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it suggested specific ways to define these abbreviations or provided examples of how to integrate them into the text. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, as the probability of failure in stochastic/random projection increases. It explicitly asks the authors to justify the stability of their method and inquire about the impact of stacking more layers. The comment provides clear and specific actions for the authors to take, such as justifying the stability and addressing the potential issues with stacking layers. The feedback is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses a concern about the stability of the proposed method when stacking multiple layers of WLS units, specifically related to the probability of failure in stochastic/random projection. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the stability of the method and the potential impact of stacking layers, but it lacks explicit references to specific sections or elements of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, as the probability of failure in stochastic/random projection increases. The reviewer provides a logical reasoning by explaining how the probability of failure could impact the method\"s stability. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the claim to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the stability of the proposed method when stacking multiple layers of WLS units, as the probability of failure in stochastic/random projection increases. It highlights a potential issue that could hinder the formation of deeper GNNs, which is an important consideration for the authors to address. The comment is clear and actionable, as it prompts the authors to justify the stability of their method and inquire about the impact of stacking more layers. This feedback provides the authors with a specific area to focus on and offers a clear path for improvement. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity in the computation of the Bottleneck Distance in Definition 4.1. However, it does not provide specific guidance on how to improve this clarity or what aspects of the computation need to be clarified. The action is implicit, as the authors can infer that they need to make the computation more transparent, but it lacks concrete details on how to achieve this. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment identifies a specific issue with the clarity of the computation of the Bottleneck Distance in Definition 4.1. This provides full grounding as it explicitly mentions a section of the paper where the issue is located, allowing the authors to accurately pinpoint the part that needs attention. The comment is also specific because it clearly specifies the issue of clarity in the computation, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some sections of the paper lack clarity, specifically mentioning the computation of the Bottleneck Distance in Definition 4.1. However, the comment does not provide any further explanation or examples to support this claim, nor does it offer suggestions on how to improve the clarity. Without additional context or details, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a specific area where the paper lacks clarity, specifically in the computation of the Bottleneck Distance in Definition 4.1. This feedback is valuable as it directs the authors to a particular section that needs improvement. However, the comment does not provide detailed guidance on how to enhance the clarity or suggest specific changes that could be made to improve the explanation. While it highlights an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a specific area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper\"s visualization (Figure 5) is weaker compared to Balikas COLING16\"s work, which raises doubts about the actual segmenting and assigning results of the document. The reviewer recommends providing a longer exemplar and making the color assignment consistent with the topics listed in Figure 4. While the comment implies that the authors should improve their visualization, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to enhance the visualization or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the visualization, noting that it is weaker compared to Balikas COLING16\"s work and suggesting improvements, such as providing a longer exemplar and making color assignment consistent with the topics listed in Figure 4. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper\"s visualization (Figure 5) is weaker compared to Balikas COLING16\"s work, which raises doubts about the actual segmenting and assigning results of the document. The reviewer suggests that providing a longer exemplar and making color assignment consistent with the topics listed in Figure 4 would make the visualization more convincing. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to Balikas COLING16\"s work to fully substantiate the comparison. This makes the claim 3, as it requires additional context or evidence to fully support the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s visualization, particularly Figure 5, which is compared to Balikas COLING16\"s work. It points out that the visualization is weaker, raising doubts about the actual segmenting and assigning results of the document. The reviewer suggests that providing a longer exemplar and making color assignment consistent with the topics listed in Figure 4 would improve the visualization\"s effectiveness. This feedback is clear and actionable, as it provides a specific direction for enhancing the paper\"s visual presentation. However, it could be more helpful if it included examples or detailed suggestions on how to achieve the recommended improvements. Overall, the comment is 4, as it guides the authors toward improving the clarity and persuasiveness of their visualizations."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment questions the use of P5small as the backbone model and the need for parameterefficient training. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable guidance, such as recommending a different model or explaining why parameterefficient training is necessary. Without specific advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the use of P5small as the backbone model and the need for parameterefficient training. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in questioning the rationale behind using a small model and parameterefficient training, but it lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of P5small as the backbone model and the need for parameterefficient training. However, it does not provide any supporting evidence, reasoning, or references to justify why this choice is questionable or why parameterefficient training is unnecessary. Without additional context or explanation, the claim remains 1, as the authors are left without a clear understanding of the basis for the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the choice of using P5small as the backbone model and the need for parameterefficient training. However, it does not provide any context, reasoning, or suggestions for alternative approaches or improvements. Without additional information or guidance, the authors are left without a clear understanding of why this choice might be problematic or how they could address it. The comment lacks depth and actionable feedback, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors seem to be proposing a way to create a challenging set, but the description provided is specific and not scalable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the proposal more general or scalable, nor are there suggestions for alternative approaches or improvements. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general observation about the authors\" proposal to create a challenging set, noting that it seems specific and not scalable. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the proposal are specific or how it could be made more scalable. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors\" proposal to create a challenging set is specific and not scalable. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to what makes the proposal specific or unscalable, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" proposal, noting that it seems specific and not scalable. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or make their proposal more generalizable. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a concern but lacks depth and specificity in its feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the proposed method\"s reliance on an optimal value function corresponding to a reward function. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or suggestions for improvement. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to enhance their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the proposed method\"s reliance on an optimal value function corresponding to a reward function. However, it does not specify which part of the paper this reliance is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspect of this reliance is problematic or how it could be improved. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a concern about the proposed method\"s reliance on an optimal value function corresponding to a reward function. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this reliance is a strong one. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the proposed method\"s reliance on an optimal value function corresponding to a reward function. However, it does not provide any specific details or suggestions on how this reliance might be problematic or how it could be addressed. Without actionable feedback or guidance, the authors are left without a clear understanding of what needs to be improved or how to enhance their work. Therefore, the comment is 1, as it does not offer any constructive direction for the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that the approach is derivative, combining two existing approaches, but it does not provide any explicit or implicit actions for the authors to take. It does not suggest ways to improve the approach, address concerns about its derivative nature, or offer guidance on how to differentiate it from other similar works. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the approach taken in the paper, specifically noting that it is derivative, combining two existing approaches. However, it does not specify which parts of the paper discuss these approaches or how they are combined. The comment lacks grounding as it does not identify a specific section or aspect of the paper being addressed, making it difficult for the authors to pinpoint where improvements are needed. Additionally, it does not provide specific details on what aspects of the derivative approach need improvement or how it could be differentiated from other similar works. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the approach is derivative, combining two existing approaches. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it affects the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges that the approach is derivative, combining two existing approaches, but it does not provide any constructive feedback or suggestions for improvement. It lacks depth and does not offer any actionable advice or guidance on how the authors might differentiate their work or enhance its originality. Without specific suggestions or critiques, the comment does not help the authors in improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of comparisons against other potential baseline approaches in the evaluation, specifically mentioning a simple photographic style transfer method as a potential alternative. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so or provide specific guidance on how to conduct these comparisons. The action is implicit and somewhat vague, as the authors can infer that they need to add comparisons but are not given detailed instructions on how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the absence of comparisons against other potential baseline approaches in the evaluation, specifically mentioning a simple photographic style transfer method as a potential alternative. However, it does not specify which part of the paper this issue pertains to, such as the results section or the discussion. The authors can infer that it relates to the evaluation or results sections, but this inference is not explicit. The comment is specific in identifying the lack of comparisons and suggesting a potential alternative, but it lacks grounding as it does not explicitly mention the sections being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks comparisons against other potential baseline approaches, specifically mentioning a simple photographic style transfer method as a potential alternative. The reviewer provides a logical reasoning by stating that the results shown in the paper and supplementary material suggest that such a method could achieve similar or better effects. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the suggestion and potentially conduct additional comparisons to fully address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, namely the absence of comparisons against other potential baseline approaches in the evaluation. It specifically mentions a simple photographic style transfer method as a potential alternative that could achieve similar or better results. This feedback is clear and actionable, as it highlights a critical area for improvement and suggests a specific direction for the authors to consider. By including comparisons with other methods, the authors can provide a more comprehensive evaluation of their approach and enhance the robustness of their findings. However, the comment could be more helpful if it provided additional guidance on how to conduct these comparisons or suggested specific methods to consider. Overall, the comment is 4 as it directs the authors to a key area for enhancement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a specific issue with the clarity of the symbols used in Figure 2 and their relationship to the equations and the main context. It explicitly points out the lack of explanation for symbols like C_i, Q_i, R_i, and A_i in Figure 2 and the confusion regarding S_i and S_j. The comment provides a clear action for the authors to take, which is to clarify the meaning of these symbols and their relationship to the equations and the main context. This feedback is explicit and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the symbols in Figure 2, particularly the lack of explanation for C_i, Q_i, R_i, and A_i, and the confusion between S_i and S_j. The comment provides clear guidance on what needs to be clarified, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the difficulty in mapping symbols in Figure 2 to those in the equations makes it challenging to understand the proposed method. It provides specific examples of symbols (C_i, Q_i, R_i, and A_i) that are not explained in the main context, which supports the claim. Additionally, the comment points out a discrepancy between S_i in Figure 2 and S_j in the text, suggesting that the authors should clarify how to compute S_i. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by referencing specific sections or equations where these symbols are used, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the symbols used in Figure 2 and their relationship to the equations and the main context. It points out the lack of explanation for symbols like C_i, Q_i, R_i, and A_i in Figure 2, which makes it difficult for readers to understand the details of the proposed method. Additionally, the comment highlights a discrepancy between S_i in Figure 2 and S_j in the text, suggesting that the authors should clarify how to compute S_i. This feedback is clear and actionable, as it provides specific examples of what needs to be clarified and improved in the paper. By addressing these issues, the authors can enhance the comprehensibility and clarity of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should study additional hyperparameters, specifically the number of backtracking steps and the acceptance rate, and investigate how much tuning was required to achieve good results. While the comment implies that the authors should conduct further analysis, it does not provide explicit instructions on how to implement this suggestion. The action is implicit and somewhat vague, as it lacks concrete details on what specific analyses or experiments should be conducted. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests studying additional hyperparameters, specifically the number of backtracking steps and the acceptance rate, and inquires about the tuning required to achieve good results. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in detailing what additional analyses could be conducted, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should study additional hyperparameters, specifically the number of backtracking steps and the acceptance rate, and inquire about the tuning required to achieve good results. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these parameters are important or how they might impact the results. Without such support, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should study additional hyperparameters, specifically the number of backtracking steps and the acceptance rate, and inquire about the tuning required to achieve good results. This feedback is 3 as it identifies a potential area for further exploration and analysis, which could enhance the understanding of the methodology and its effectiveness. However, the comment lacks specific guidance on how to conduct this analysis or what specific questions to address regarding the tuning process. While it provides a direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for clarification regarding the objective function for GSdyn and FABOLAS. It questions whether the accuracy mentioned in Section 5.1 refers to the validation dataset or the test dataset. This feedback provides a clear and direct action for the authors to take, which is to clarify the objective function and specify which accuracy is being referred to. The comment is explicit and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the objective function for GSdyn and FABOLAS and asking which accuracy is being referred to (validation or test). This provides clear guidance on what needs to be clarified, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual question seeking clarification about the objective function for GSdyn and FABOLAS. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area of confusion in the paper regarding the objective function for GSdyn and FABOLAS. It questions whether the accuracy mentioned in Section 5.1 refers to the validation dataset or the test dataset, which is a critical point for clarity. By asking for clarification, the comment provides the authors with a clear direction for improvement, ensuring that the objective function and its evaluation are accurately described in the paper. This feedback is actionable and constructive, making it 5 for the authors to enhance the clarity and comprehensiveness of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests rearranging the sections of the paper, specifically proposing that section 3.1 should be moved to the related work section and section 3.2 should become the new section 3. This provides a clear and explicit action for the authors to take, as it specifies exactly what needs to be done to reorganize the sections. The comment is also concrete, as it provides a specific suggestion for how to improve the structure of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests rearranging the sections of the paper, specifically proposing that section 3.1 should be moved to the related work section and section 3.2 should become the new section 3. However, it does not specify which part of the paper this suggestion pertains to, such as mentioning the specific sections or subsections. This makes it difficult for the authors to pinpoint the exact parts of the paper being addressed. Additionally, while the comment provides a suggestion for reorganizing the sections, it lacks specificity in terms of why this rearrangement would be beneficial or how it would improve the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests rearranging the sections of the paper, specifically proposing that section 3.1 should be moved to the related work section and section 3.2 should become the new section 3. However, the comment does not provide any reasoning or justification for why this rearrangement would be beneficial or how it would improve the paper. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests rearranging the sections of the paper, specifically proposing that section 3.1 should be moved to the related work section and section 3.2 should become the new section 3. This feedback provides a clear and actionable suggestion for improving the organization of the paper, which could enhance its readability and flow. However, the comment lacks further explanation or justification for why this rearrangement would be beneficial, such as how it would better align with the paper\"s structure or improve the reader\"s understanding. While the suggestion is 3 in guiding the authors to reorganize their sections, it could be more comprehensive with additional context or rationale. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should perform additional evaluation on the VOT dataset to compare the methods in terms of different metrics like Accuracy, Robustness, and EAO. This is an explicit suggestion that provides a clear action for the authors to take. The comment also specifies the metrics to consider, which makes the action concrete. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the datasets (OTB50, OTB100, OTB2015, and LASOT) and the metrics (AUC and precision) used for evaluation. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests an additional evaluation on the VOT dataset, specifying the metrics (Accuracy, Robustness, and EAO) that should be considered. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should perform additional evaluation on the VOT dataset to compare the methods in terms of different metrics like Accuracy, Robustness, and EAO. The comment provides a logical reasoning by noting that the current evaluation on OTB50, OTB100, OTB2015, and LASOT datasets uses only AUC and precision metrics, which may not fully capture the performance of the proposed framework. This reasoning is clear and provides a rationale for the suggestion, making the claim 4. However, the comment could be strengthened by referencing specific studies or benchmarks that use these additional metrics, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential limitation in the evaluation of the proposed framework, noting that the current benchmarks focus on AUC and precision metrics. It suggests that the authors should perform additional evaluation on the VOT dataset to compare the methods in terms of different metrics like Accuracy, Robustness, and EAO. This feedback is clear and actionable, providing a specific suggestion for enhancing the evaluation of the framework. By addressing this point, the authors can provide a more comprehensive assessment of their method\"s performance. However, the comment could be more helpful if it included examples or references to studies that use these additional metrics, which would further guide the authors in implementing the suggestion. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of comparison of the proposed method to stateoftheart unsupervised semantic segmentation techniques. It notes that the paper claims the method\"s performance is comparable to supervised semantic segmentation but does not report the performance of any stateoftheart methods, supervised or unsupervised. This feedback is explicit in its request for a comparison to stateoftheart methods, providing a clear action for the authors to take. However, it does not specify which specific methods should be compared or how to conduct the comparison, leaving some room for interpretation. Therefore, the comment is 4, as it clearly identifies the need for comparison but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of not comparing the proposed method to stateoftheart unsupervised semantic segmentation techniques. This allows the authors to accurately identify the part of the paper being addressed, specifically the comparison section. The comment is also specific because it clearly specifies the issue of not reporting the performance of stateoftheart methods, both supervised and unsupervised, which is crucial for evaluating the proposed method\"s performance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method is not compared to any stateoftheart unsupervised semantic segmentation technique, despite the paper claiming its performance is comparable to supervised semantic segmentation. The reviewer points out that the paper does not report the performance of stateoftheart methods, either supervised or unsupervised. This claim is 3 as it highlights a gap in the paper\"s comparison to existing methods, but it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to address this gap to improve the paper, but the comment could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of comparison to stateoftheart unsupervised semantic segmentation techniques. It points out that the paper claims the proposed method\"s performance is comparable to supervised semantic segmentation but does not report the performance of any stateoftheart methods, supervised or unsupervised. This feedback is clear and actionable, as it highlights a critical area for improvement that could strengthen the paper\"s claims and contributions. By suggesting the inclusion of such comparisons, the comment provides the authors with a specific direction for enhancing the draft. However, it could be more helpful if it offered examples of relevant stateoftheart methods or guidance on how to conduct the comparison. Overall, the comment is 4, as it effectively directs the authors to a key area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses uncertainty about the first curvefinding part and questions its explanation of the FGE work. It suggests that the cyclical learning rate scheduling may not guarantee that the weight is changing along the curve described. However, the comment does not provide explicit guidance or suggestions on how the authors might improve this part of the paper. It lacks concrete details on what specific changes or clarifications are needed to address the issue. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment expresses uncertainty about the first curvefinding part and questions its explanation of the FGE work. However, it does not specify which part of the paper this issue pertains to, such as a specific section, figure, or table. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment raises a concern about the explanation of the FGE work, it does not provide specific details or suggestions on how to improve the explanation. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses uncertainty about the first curvefinding part and questions its explanation of the FGE work. The reviewer suggests that the cyclical learning rate scheduling may not guarantee that the weight is changing along the curve described. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses uncertainty about the first curvefinding part and questions its explanation of the FGE work. It suggests that the cyclical learning rate scheduling may not guarantee that the weight is changing along the curve described. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might improve the explanation or address the issue. Without detailed feedback or examples, the authors are left without a clear understanding of what changes are needed to enhance the clarity of their work. Therefore, the comment is 2, as it identifies a potential issue but does not offer sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should present a case study, ideally with synthetic datasets, to demonstrate the advantages of a distillation strategy. It also implies that the authors should investigate the reason behind the performance differences in Table 3, such as why LFADSHard performs better than LFADSSoft and why NDTCorrelation performs better than NDT. The comment provides a clear and explicit action for the authors to take, which is to conduct additional analysis and present it in the paper. However, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. While the action is explicit, the lack of detailed instructions makes it 3.", "grounding_specificity_rationale": "The comment suggests that the authors present a case study, ideally with synthetic datasets, to demonstrate the advantages of a distillation strategy. It also questions the performance differences in Table 3, specifically between LFADSHard and LFADSSoft, and between NDTCorrelation and NDT. The comment provides specific suggestions for improvement, such as investigating the reasons behind these performance differences and offering more reasoning or hypotheses based on the performance. However, it does not explicitly mention which part of the paper these suggestions pertain to, making it weakly grounded. The authors can infer that it relates to the results section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should present a case study, ideally with synthetic datasets, to demonstrate the advantages of a distillation strategy. It also questions the performance differences in Table 3, specifically between LFADSHard and LFADSSoft, and between NDTCorrelation and NDT. The comment implies that the authors should investigate the reasons behind these performance differences and provide more reasoning or hypotheses based on the performance. While the comment identifies areas for improvement, it lacks specific examples or detailed reasoning to fully support the claim. The suggestion for a case study with synthetic datasets is a logical one, but the comment does not provide a clear path for the authors to follow. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to improve their paper. It recommends presenting a case study, ideally with synthetic datasets, to demonstrate the advantages of a distillation strategy. This suggestion is specific and offers a concrete way for the authors to enhance their work by providing a practical example of when and why a distillation strategy might be beneficial. Additionally, the comment questions the performance differences in Table 3, specifically between LFADSHard and LFADSSoft, and between NDTCorrelation and NDT, suggesting that the authors should investigate the reasons behind these differences. This feedback encourages the authors to provide more reasoning or hypotheses based on the performance, which can help clarify the results and enhance the paper\"s comprehensiveness. Overall, the comment is 5 as it offers specific and actionable suggestions for improvement, making it a valuable resource for the authors."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors focus on evaluating LM loss throughout the paper, which is fine for style and topics but not clean enough for factual knowledge. It implies that the authors could create clozestyle or question answering evaluation sets to focus exclusively on generating factual knowledge. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors to implement these changes. The action is concrete but implicit, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on evaluating LM loss throughout the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests creating clozestyle or question answering evaluation sets to focus on generating factual knowledge, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of LM loss is not clean enough for factual knowledge because only a few tokens in a sentence are related to facts. The reviewer suggests creating clozestyle or question answering evaluation sets to focus on generating factual knowledge. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that LM loss evaluation is insufficient for factual knowledge. This makes the claim 3, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the evaluation of LM loss, suggesting that it may not be sufficient for factual knowledge generation. It provides a clear and actionable suggestion by recommending the creation of clozestyle or question answering evaluation sets to focus on generating factual knowledge. This feedback is valuable as it offers a concrete way for the authors to enhance their evaluation methodology, which could significantly improve the paper. However, the comment could be more helpful if it included additional details or examples on how to implement these suggestions effectively. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with further guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the sensitivity of the RTD score to clusters and asks for an explanation of the theoretical or topological aspects of this sensitivity. It also questions why the proposed RTD is specifically designed for network representation. While the comment implies that the authors should provide a theoretical or topological explanation for the sensitivity of the RTD score, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the theoretical aspects and provide a rationale for the specific application to network representation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"key contribution\" of the paper, which is the sensitivity of the RTD score to clusters, and it refers to the experiments where this sensitivity is verified. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises questions about the theoretical or topological aspects of the sensitivity of the RTD score and questions why it is specifically designed for network representation. This provides clear guidance on what aspects need further explanation or justification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the sensitivity of the RTD score to clusters and questions the theoretical or topological aspects of this sensitivity. It also questions why the proposed RTD is specifically designed for network representation. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The absence of supporting evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the key contribution of the paper, specifically the sensitivity of the RTD score to clusters. It questions the theoretical or topological aspects of this sensitivity and suggests that the authors should provide an explanation. Additionally, it questions why the proposed RTD is specifically designed for network representation, suggesting that it could potentially be applied to measure any vectors with the same size. This feedback is clear and actionable, as it identifies specific areas where the authors need to provide more theoretical or topological justification for their claims. By addressing these points, the authors can enhance the comprehensiveness and clarity of their work. Therefore, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises concerns about the claim that ROCK has similar complexity to the original model, questioning the validity of this assertion due to the additional layers added by ROCK. It explicitly requests that inference timings be provided to substantiate this claim. Additionally, the comment suggests conducting ablation experiments to evaluate the contribution of each auxiliary task on object detection performance in ROCK and in standard MTL. This feedback provides clear and explicit actions for the authors to take, including providing inference timings and conducting ablation experiments. The instructions are concrete and direct, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 8889, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim about ROCK\"s complexity, questioning its validity due to the additional layers added by ROCK. The comment further suggests providing inference timings to substantiate the claim and proposes conducting ablation experiments to evaluate the contribution of each auxiliary task on object detection performance. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises a claim about the complexity of ROCK compared to the original model, questioning the validity of the claim due to the additional layers added by ROCK. The reviewer suggests that inference timings should be provided to substantiate this claim. This request is logical and provides a clear direction for the authors to address the concern. However, the comment lacks specific examples or references to support the claim about the complexity increase, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a logical basis for the claim but requires more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by questioning the claim that ROCK has similar complexity to the original model due to the additional layers it introduces. It explicitly requests that inference timings be provided to substantiate this claim, which is a specific and concrete suggestion for improvement. Additionally, the comment identifies a weakness in the experiments, suggesting the need for ablation studies to evaluate the contribution of each auxiliary task on object detection performance in ROCK and in standard MTL. This feedback is detailed and provides the authors with a clear path to enhance the robustness and clarity of their experimental results. Therefore, the comment is 5, as it offers valuable insights and actionable suggestions for improving the draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations. It also raises concerns about how the model might perform on noisy or imbalanced realworld medical datasets, where labels may be incomplete, inaccurate, or skewed. While the comment identifies areas that need further exploration, it does not provide explicit guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors are left to infer that they should expand their discussion on dataset diversity and quality, as well as consider the model\"s performance in realworld scenarios. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations. It also raises concerns about the model\"s performance on noisy or imbalanced realworld medical datasets, where labels may be incomplete, inaccurate, or skewed. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in detailing what aspects of the dataset and model performance need further discussion, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions or imaging variations. It also questions how the model might perform on noisy or imbalanced realworld medical datasets, where labels may be incomplete, inaccurate, or skewed. While the comment identifies areas that could be improved, it does not provide specific examples, references, or detailed reasoning to support the claim. The lack of concrete evidence or detailed justification makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered 2, as it provides a general direction for improvement but lacks the necessary details for full verification.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion regarding the diversity and quality of the dataset, particularly in terms of rare conditions or imaging variations. It also raises concerns about the model\"s performance on realworld medical datasets, where labels may be incomplete, inaccurate, or skewed. This feedback is valuable as it highlights areas that need further exploration and clarification, which could significantly impact the robustness and generalizability of the model. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of how to improve the dataset quality. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the reproducibility of the results due to the lack of promised code and detailed training information. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should include more detailed training information, but it lacks concrete suggestions on what specific details should be provided. This makes the action somewhat vague, as the authors are left to infer what additional information is needed to ensure reproducibility. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the reproducibility of the results, specifically mentioning the lack of promised code and detailed training information. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the reproducibility issue, but without clear grounding, it is difficult for the authors to know where to focus their efforts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of promised code and detailed training information makes the results nonreproducible. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to similar cases where such issues have led to nonreproducibility or suggestions on how to address the problem. Without these elements, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the reproducibility of the results due to the lack of promised code and detailed training information. This is an important concern that the authors need to address to ensure the credibility and reliability of their work. However, the comment does not provide specific suggestions or guidance on how the authors might improve the reproducibility of their results. While it highlights a significant weakness, it lacks actionable feedback that could help the authors make the necessary improvements. Therefore, the comment is 3, as it points out a crucial area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing piece of critical setup information, specifically the total number of agents available in Flow\"s default configuration. This provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"critical setup information\" that is missing, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the total number of agents available in Flow\"s default configuration. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"critical setup information is missing,\" specifically mentioning the total number of agents available in Flow\"s default configuration. However, the comment does not provide any reasoning or evidence to support why this information is critical or how its absence affects the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting the absence of critical setup information, such as the total number of agents available in Flow\"s default configuration. This feedback is clear and actionable, as it directs the authors to include this information, which is essential for understanding the setup and context of the experiments. By addressing this point, the authors can enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or explained why this information is crucial. Overall, the feedback is 4 as it guides the authors toward a specific improvement, but it could be more comprehensive with further elaboration."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim that the model is the \"first deep generative model for unsupervised scenegraph discovery,\" arguing that there are many works that infer structures in an unsupervised way. The comment suggests that the definition of \"scene graph\" is too narrow and that the claim is not accurate. However, it does not provide specific suggestions or guidance on how the authors should address this issue or improve their claim. The action is implicit and vague, as the authors are left without clear direction on how to revise their claim or broaden their definition. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the claim that the model is the \"first deep generative model for unsupervised scenegraph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. However, it does not specify which part of the paper this claim is made in, nor does it provide details on which works are being referenced or how they relate to the claim. This lack of specificity and grounding makes it difficult for the authors to identify the exact part of the paper being addressed and what needs to be revised. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper\"s assertion of being the \"first deep generative model for unsupervised scenegraph discovery\" is not accurate, as there are many works that infer structures in an unsupervised way. However, the comment does not provide specific examples or references to these works, making it difficult for the authors to understand the basis of the claim or to address it effectively. The lack of detailed evidence or references makes the claim 3, as the authors would need to invest time and effort to identify and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment challenges the claim that the model is the \"first deep generative model for unsupervised scenegraph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. This feedback is 3 as it points out a potential weakness in the paper\"s claim, prompting the authors to reconsider their assertion and potentially revise it. However, the comment lacks specific examples or references to these other works, which would provide more detailed guidance for the authors to address the issue. While it identifies a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the ablation study, noting that it does not provide information on the effect of different numbers of projectors on distillation when the feature dimensions are different. This feedback implies that the authors should include this information in their ablation study to enhance its comprehensiveness. However, the comment does not explicitly instruct the authors to add this information or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to expand their ablation study but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ablation study, namely that it does not provide information on the effect of different numbers of projectors on distillation when the feature dimensions are different. This provides clear guidance on what needs to be addressed in the study. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the ablation study lacks information on the effect of different numbers of projectors on distillation when the feature dimensions are different. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the ablation study, noting that it does not provide information on the effect of different numbers of projectors on distillation when the feature dimensions are different. This feedback is clear and actionable, as it highlights a missing aspect of the study that could be valuable for understanding the impact of the projectors. However, the comment could be more helpful if it suggested ways to address this gap or provided examples of how such information could be included. Despite this, the comment is 4 as it directs the authors to an area that needs further exploration and improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting more experiments on diverse datasets to demonstrate the generalization capabilities of the model beyond the current focus on three categories (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to demonstrate the core idea of the proposed method. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on which datasets or shapes to use or how to implement these experiments. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting more experiments on diverse datasets to demonstrate the generalization capabilities of the model beyond the current focus on three categories (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to demonstrate the core idea of the proposed method. However, the comment does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. Without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. The comment is specific in suggesting additional experiments but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting more experiments on diverse datasets to demonstrate the generalization capabilities of the model. It recommends evaluating more complex shapes with various topologies to demonstrate the core idea of the proposed method. While the comment provides a logical suggestion for further experimentation, it lacks specific examples or references to support the claim that the current dataset is insufficient. This makes the claim 3, as it provides a direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting more experiments on diverse datasets to demonstrate the generalization capabilities of the model beyond the current focus on three categories (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to demonstrate the core idea of the proposed method. This feedback is clear and actionable, as it provides a specific direction for expanding the experimental scope to better validate the model\"s capabilities. However, the comment could be more helpful if it included suggestions on which specific datasets or shapes to consider or how to implement these additional experiments. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include a comparison against methods that require more training time. It provides a specific reason for this comparison, noting that the neural networks proposed by Park & Van Hentenryck (2023) and others do not necessitate extensive training time. The comment also explains the implications of low computational requirements, emphasizing the need to understand the implications of fewer models needing to be trained. While the action is explicit, the comment does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. Therefore, the comment is 4, as it clearly identifies the action but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests a comparison against methods that require more training time, specifically mentioning the work of Park & Van Hentenryck (2023) and others. This provides a clear basis for the suggestion, allowing the authors to identify the relevant part of the paper that needs to be addressed. However, the comment does not explicitly mention which section or part of the paper this comparison should be included in, making it weakly grounded. The suggestion is specific in terms of the comparison needed, but without explicit grounding, the authors may find it challenging to pinpoint the exact location for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a comparison against methods requiring more training time is necessary, particularly in light of the neural networks proposed by Park & Van Hentenryck (2023) and others that do not necessitate extensive training time. The comment provides a logical reasoning by highlighting the implications of low computational requirements during test time, which may render restrictions like a hard limit of 10 minutes of training time on a single CPU core unnecessary. However, the comment lacks specific references or detailed examples of these methods or their computational requirements, which would strengthen the justification. Therefore, the claim is 3, as it provides a logical basis but requires more detailed evidence to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include a comparison against methods that require more training time. It highlights the importance of understanding the implications of low computational requirements, particularly in the context of neural networks proposed by Park & Van Hentenryck (2023) and others. The comment explains the rationale behind this comparison, noting that fewer models needing to be trained may render restrictions like a hard limit of 10 minutes of training time on a single CPU core unnecessary. This feedback is valuable as it directs the authors to a specific area for improvement, offering a clear path for enhancing their draft. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is 4, as it effectively guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the comparison between DetNAS and ResNet is unfair because the ShuffleNetv2 block is more efficient than the Residual block in ResNet. It provides a specific action for the authors to take, which is to include more comparisons with other networks constructed using efficient blocks, such as a 3.8G FLOPs ShuffleNetv2 in Table 2. This feedback is clear and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison between DetNAS and ResNet, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the comparison is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. The comment further suggests including more comparisons with other networks constructed using efficient blocks, such as a 3.8G FLOPs ShuffleNetv2 in Table 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparison between DetNAS and ResNet is unfair because the ShuffleNetv2 block is more efficient than the Residual block in ResNet. The reviewer suggests including more comparisons with other networks constructed using efficient blocks, such as a 3.8G FLOPs ShuffleNetv2. This claim is 3 as it provides a logical reasoning for the unfairness of the comparison and suggests a specific example for improvement. However, the comment could be strengthened by providing additional references or data to support the claim about the efficiency of ShuffleNetv2. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison between DetNAS and ResNet, pointing out that the comparison is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. It suggests that the authors should provide more comparisons with other networks constructed using efficient blocks, such as a 3.8G FLOPs ShuffleNetv2 in Table 2. This feedback is clear and actionable, offering a concrete suggestion for improving the draft by expanding the comparisons to include more efficient networks. The comment is 5 as it provides specific guidance on how to enhance the paper\"s content and analysis, empowering the authors to make significant improvements."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived limitation in the input and output spaces/representations, suggesting that they are restricted to specific cases. However, it does not provide explicit guidance or suggestions on how the authors might address this limitation or expand their work to include more general representations. The comment implies that the authors should consider broader representations, but it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a perceived limitation in the input and output spaces/representations, suggesting that they are restricted to specific cases. However, it does not specify which part of the paper this issue pertains to, such as a particular section or methodology. The mention of \"e.g. the two papers I mention in point (3)\" implies that the authors might be aware of these references, but it does not provide explicit guidance on where to find them in the paper. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment is specific in identifying the limitation but lacks grounding, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the input and output spaces/representations are restricted to specific cases, such as the group itself under the regular or trivial representation, or a homogeneous space of the group. The reviewer contrasts this with other papers mentioned in point (3), which can work with any finitedimensional representation. However, the comment does not provide specific references or detailed examples from the mentioned papers to support the claim. This lack of detailed evidence or references makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a perceived limitation in the input and output spaces/representations, suggesting that they are restricted to specific cases. It contrasts this with other papers mentioned in point (3), which can work with any finitedimensional representation. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this limitation or expand their work to include more general representations. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential complexity in the practical applications of the system, specifically mentioning the need to specify a source prompt, blend word, and various conditions. However, it does not provide explicit guidance or suggestions on how the authors might address this complexity or improve the usability for typical users. The comment identifies an issue but lacks actionable advice, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the complexity of practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the complexity and potential limitations of the system, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point highlights a potential complexity in the practical applications of the system, specifically mentioning the need to specify a source prompt, blend word, and various conditions. This claim is 3 as it identifies a specific challenge in the usability of the system for typical users. However, the comment lacks detailed examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Providing more context or evidence would enhance the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential complexity in the practical applications of the system, specifically noting the need to specify a source prompt, blend word, and various conditions. It highlights a limitation that may restrict the usability of the system for typical users seeking simpler image adjustments. However, the comment does not provide specific suggestions or guidance on how the authors might address this complexity or improve the system\"s usability. While it points out an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential limitation but lacks detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the contributions of the paper are not very significant and that there is a lack of effort in contrasting the technique with traditional classification or manifold learning literature. However, it does not provide explicit guidance on how the authors should address these issues or improve their contributions. The comment implies that the authors should enhance their contributions and provide a more comprehensive comparison, but it lacks concrete steps or suggestions on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment critiques the significance of the paper\"s contributions and the lack of effort in contrasting the technique with traditional classification or manifold learning literature. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the contributions and the lack of comparison, but it lacks grounding as it does not reference any particular section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contributions of the paper are not significant and that there is a lack of effort in contrasting the technique with traditional classification or manifold learning literature. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the reasoning behind the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out that the contributions of the paper are not very significant and lacks effort in contrasting the technique with traditional classification or manifold learning literature. This feedback identifies a potential weakness in the paper, specifically the lack of novelty or originality in the contributions. However, the comment does not provide specific suggestions or guidance on how the authors might enhance their contributions or improve the comparison with existing literature. Without actionable advice, the authors are left with a general understanding of the issue but without a clear path to improvement. Therefore, the comment is 3, as it highlights an area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should include a discussion on the impact of the fewshot dataset for the sparsity ratio. It acknowledges that larger datasets could provide more accurate estimates but would require more time to compute. The comment provides a clear action for the authors to take, which is to discuss the tradeoff between dataset size and computational time. Additionally, it references two relevant works that could help inform this discussion. This feedback is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment suggests that a discussion on the impact of the fewshot dataset for the sparsity ratio is necessary. It acknowledges that larger datasets could provide more accurate estimates but would require more time to compute. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, namely the impact of dataset size on sparsity ratio and computational time. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a discussion on the impact of the fewshot dataset for the sparsity ratio is necessary. It acknowledges that larger datasets could provide more accurate estimates but would require more time to compute. The comment references two external works, 1 and 2, which provide additional context and support for the claim. However, the references are not directly integrated into the argument, and the comment could benefit from a more detailed explanation of how these works relate to the issue at hand. Overall, the claim is 4, as it provides some support but lacks a comprehensive integration of the references into the argument. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should include a discussion on the impact of the fewshot dataset for the sparsity ratio. It acknowledges the tradeoff between dataset size and computational time, which is an important consideration in the context of the paper. The comment provides a clear and actionable suggestion for the authors to address, which is to discuss the implications of dataset size on the sparsity ratio and computational efficiency. Additionally, it references two relevant works that could help inform this discussion. This feedback is detailed and constructive, offering the authors a clear path to enhance their draft. Therefore, it is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of explanation and experimental verification regarding the decision to keep representations in the same hidden space. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should provide an explanation and experimental verification. However, the comment lacks concrete details on how to implement these actions, such as what specific aspects of the explanation or verification are needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the lack of explanation and experimental verification regarding the decision to keep representations in the same hidden space. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely the explanation and experimental verification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not illustrated why it is better to keep representations in the same hidden space and that this has not been experimentally verified. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of explanation and experimental verification regarding the decision to keep representations in the same hidden space. This is a critical area that the authors need to address to strengthen their argument and provide a clear rationale for their approach. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as proposing potential experiments or providing examples of how to explain the benefits of keeping representations in the same hidden space. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the paper for lacking sufficient novelty in its methodologies, specifically noting that the proposed approach does not offer a significant advancement beyond existing methods. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the novelty of their work. Without guidance on potential enhancements or alternative approaches, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Longitudinal Representation Learning\" and \"Karwande et al. (2022),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of sufficient novelty in the methodologies, particularly in relation to Faster RCNN (Ren et al., 2015). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient novelty in its methodologies, specifically noting that the proposed approach does not offer a significant advancement beyond existing methods. The reviewer supports this claim by referencing Karwande et al. (2022) and Faster RCNN (Ren et al., 2015), which are cited as the basis for the paper\"s methodology. This provides a clear basis for the claim, as it highlights the lack of originality in the approach. However, the comment could be strengthened by providing more detailed comparisons or examples of how the proposed method differs from existing ones. Overall, the claim is 4 due to the references provided, but it could be more robust with additional context or examples. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of novelty in the methodologies proposed. It points out that the paper introduces Longitudinal Representation Learning as an extension of Karwande et al. (2022) by using Faster RCNN (Ren et al., 2015), which does not seem to offer a substantial advancement beyond existing methods. This feedback is valuable as it highlights a potential weakness in the paper\"s contribution to the field. However, the comment could be more helpful if it provided suggestions on how the authors might enhance the novelty of their approach or offered examples of potential improvements. Despite this, the comment is 4 as it directs the authors\" attention to a critical area that needs further development. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues with the paper, including the presentation of 3 as the underlying data generating mechanism, the use of causal graphs instead of the label inference process, and the difficulty in understanding definition 4. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how to clarify the presentation of 3, how to incorporate causal graphs, or how to improve the readability of definition 4. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses multiple issues, including the presentation of 3 as the underlying data generating mechanism, the use of causal graphs instead of the label inference process, and the difficulty in understanding definition 4. However, it does not specify which sections of the paper these issues pertain to, making it difficult for the authors to pinpoint the exact parts that need revision. The comment is specific in detailing what is unclear or incorrect, but it lacks grounding as it does not explicitly mention sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including that 3 is not the underlying data generating mechanism and that causal graphs should be used instead of the label inference process. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The mention of \"definition 4\" being hard to read is also not substantiated with further explanation. Without additional context or evidence, the claims remain vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the presentation of 3 as the underlying data generating mechanism, the use of causal graphs instead of the label inference process, and the difficulty in understanding definition 4. However, it does not provide specific suggestions or guidance on how to address these issues, such as clarifying the presentation of 3, explaining the use of causal graphs, or improving the readability of definition 4. The comment highlights areas that need attention but lacks actionable feedback, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the conditions under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate the dualfree approach. While the comment implies that the authors should provide more examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate these examples or what kind of examples would be most beneficial. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the conditions under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate the dualfree approach. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in suggesting the inclusion of more examples to motivate the dualfree approach, but without grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the conditions under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate the dualfree approach. However, the comment lacks specific examples or detailed reasoning to support the claim that evaluating the gradient is expensive or infeasible. Without such evidence or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a question about the conditions under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests that including more examples in machine learning could motivate the dualfree approach. While the comment identifies a potential area for improvement by suggesting the inclusion of examples, it lacks specificity and actionable guidance on how to incorporate these examples or what specific aspects of the dualfree approach should be highlighted. The feedback is 3 as it points out a potential gap in the paper, but it could be more beneficial with additional details or suggestions on how to address the issue. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the explanation for selecting a probability from the range 0, Pcj(0) in the data approximation technique (step 3 of Algorithm 1). While it does not explicitly instruct the authors to provide an explanation, it implies that the authors should address this gap in their explanation. The action is implicit but clear, as the authors can infer that they need to provide an explanation. The comment is 3 because it specifies the area of concern but does not provide detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the data approximation technique (step 3 of the Algorithm 1),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the lack of explanation for selecting a probability from the range 0, Pcj(0) and requests clarification. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the explanation for selecting a probability from the range 0, Pcj(0) in the data approximation technique. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the explanation for selecting a probability from the range 0, Pcj(0) in the data approximation technique. It highlights a lack of clarity in the paper and prompts the authors to provide an explanation for this choice. This feedback is clear and actionable, as it directs the authors to address a specific gap in their explanation, which can help improve the comprehensibility of their work. However, the comment could be more helpful if it provided additional context or suggested potential explanations for the selection process. Overall, the comment is 4 as it guides the authors toward enhancing the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a precise definition or informal description of the notion of the spectrum of distributions and their characteristic functions. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how the authors should define or describe these concepts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (128 and 168) where the authors refer to the spectrum of distributions and their characteristic functions. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing, namely, a precise definition or informal description of these notions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper would benefit from a precise definition or informal description of the spectrum of distributions and their characteristic functions. However, the comment does not provide any specific reasoning or examples to support why this is necessary or how it would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide a precise definition or informal description of the spectrum of distributions and their characteristic functions. This feedback is clear and actionable, as it directs the authors to enhance the clarity and comprehensibility of their work by defining key concepts. However, the comment could be more helpful if it provided examples or references to guide the authors in defining these concepts. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the AIGgeneration task, questioning its convincingness and suggesting that more background information should be provided for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance the task\"s credibility. While the comment implies that the authors should provide more context and benchmark their method, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more background information and benchmark their method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the AIGgeneration task, questioning its convincingness and suggesting that more background information should be provided for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a). While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections where the AIGgeneration task is discussed. The comment is specific in suggesting the need for more background information and benchmarking on existing datasets. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the AIGgeneration task is not convincing and suggests that more background information should be provided. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a). The comment provides a logical reasoning by questioning the task\"s convincingness and suggesting that more context and benchmarking would enhance its credibility. However, it lacks specific examples or detailed reasoning about why the current approach is not convincing, making the claim 3. The reference to LayerDAG (Li et al., 2024a) provides some context but does not fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the AIGgeneration task, questioning its convincingness and suggesting that more background information is needed for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance the task\"s credibility. This feedback is clear and actionable, as it provides specific suggestions for improving the paper\"s clarity and robustness. By addressing these points, the authors can enhance the comprehensibility and validity of their work. However, the comment could be more helpful if it included additional guidance on how to provide the necessary background information or benchmark the method effectively. Overall, the comment is 4, as it directs the authors toward meaningful improvements but could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that some statements in the paper lack detail and analysis, but it does not provide specific examples or suggest how the authors might address this issue. The feedback is vague and lacks actionable guidance, leaving the authors uncertain about what aspects of their statements need more detail or analysis. Without concrete suggestions or examples, the authors are not provided with a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that some statements in the paper lack detail and analysis, but it does not specify which statements or sections are being referred to. This makes it difficult for the authors to identify the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what kind of detail or analysis is missing, leaving the authors without clear guidance on how to address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"some statements in this paper lack detail and analysis,\" but it does not provide specific examples or evidence to support this claim. Without detailed examples or references to particular statements, the authors may find it challenging to understand and address the issue. The lack of specificity and supporting evidence makes the claim difficult to verify, aligning with a score of 1.", "helpfulness_rationale": "The comment identifies a general issue with the paper, noting that some statements lack detail and analysis. However, it does not specify which statements are problematic or provide guidance on how to address this issue. Without specific examples or suggestions for improvement, the authors are left without actionable feedback to enhance their draft. The comment is vague and lacks depth, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include a comparison with other generative models, such as VAE, to provide more informative insights. It specifically mentions the unique features of diffusion models, such as the diffusion timesteps, and suggests analyzing how these differences affect feature learning. While the comment implies that the authors should conduct this analysis, it does not provide explicit instructions on how to implement it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a comparison with other generative models, such as VAE, could be more informative. It specifically mentions the unique features of diffusion models, such as the diffusion timesteps, and suggests analyzing how these differences affect feature learning. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the discussion or results sections where comparisons with other models are typically presented. The comment is specific in suggesting a particular analysis to enhance the paper, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that a comparison with other generative models, such as VAE, could be more informative. It provides a specific reason for this suggestion by highlighting the unique features of diffusion models, such as the diffusion timesteps, and how these differences could affect feature learning. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific studies or examples that demonstrate the impact of these differences. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from a more informative comparison with other generative models, such as VAE. It highlights the unique features of diffusion models, such as the diffusion timesteps, and suggests analyzing how these differences affect feature learning. This feedback is clear and actionable, as it provides a specific direction for enhancing the paper by exploring the unique aspects of diffusion models. However, the comment could be more helpful if it offered examples of how to conduct this analysis or suggested specific features to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the combination of selfsupervised tasks in Table 4, specifically the lack of complementarity between ICT and DaPI. It also questions the significance of the DaPI task, noting that its effectiveness is not substantial despite doubling GPU memory usage. Additionally, the comment suggests that ICoL is proposed to address insufficient memory on a single GPU and improve performance by increasing negative instances, but lacks corresponding experiments to demonstrate the influence of negative instances. The reviewer provides a reference to TASB, suggesting that the quality of negatives is more important than the quantity. While the comment identifies specific issues and provides some guidance, it lacks explicit instructions or detailed suggestions on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer what changes are needed and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the combination of selfsupervised tasks, the effectiveness of the DaPI task, and the lack of corresponding experiments to demonstrate the influence of negative instances. The comment also references TASB to support the claim about the importance of negative instance quality. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the effectiveness of the combination of selfsupervised tasks in Table 4, specifically the DaPI task. It notes that the effectiveness of DaPI is not significant despite doubling GPU memory usage. The reviewer also questions the lack of experiments to demonstrate the influence of negative instances on ICoL, suggesting that the quality of negatives is more important than the quantity. While the comment provides some reasoning, it lacks specific examples or references to support the claims fully. The mention of TASB is a general reference, not a detailed comparison or analysis. Therefore, the comment is 3, as it provides a basis for the claims but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper, providing actionable feedback that can help the authors improve their draft. It points out a potential lack of complementarity between selfsupervised tasks in Table 4, questioning the significance of the DaPI task despite doubling GPU memory usage. The comment also highlights the need for experiments to demonstrate the influence of negative instances on ICoL, suggesting that the quality of negatives is more important than the quantity. This feedback is clear and actionable, as it directs the authors to address these specific concerns by conducting additional experiments or analyses. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what metrics to focus on. Overall, the comment is 4, as it effectively guides the authors toward improving their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the authors should add a caption to emphasize the differences between the three plots on the same row in Figure 3. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in the differences between the three plots on the same row. The suggestion to add a caption to emphasize these differences provides clear guidance on how to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the differences between the three plots in Figure 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it is unclear what the differences are between the three plots on the same row. It suggests that adding a caption could help clarify this. While the comment highlights a potential area for improvement, it does not provide detailed guidance on how to enhance the clarity of the figure or what specific information should be included in the caption. The feedback is 3 as it points out a weakness and offers a general suggestion, but it lacks depth and actionable details. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper could benefit from a deeper dive into the computational complexity of GPSE, particularly when compared to handcrafted PSEs and other encoding strategies. While the comment implies that the authors should provide more detailed analysis on computational complexity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct this analysis or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of computational complexity, specifically mentioning the high complexity of handcrafted PSEs and suggesting a deeper dive into GPSE\"s computational complexity. However, it does not specify which part of the paper should include this analysis, making it weakly grounded. The comment is specific in its request for a deeper dive into computational complexity, particularly when compared to other encoding strategies. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that most handcrafted PSEs have high computational complexity on large graphs and suggests that the paper could benefit from a deeper dive into GPSE\"s computational complexity. However, the comment lacks specific examples or references to support the claim about the high complexity of handcrafted PSEs or the need for a deeper dive into GPSE\"s complexity. This makes the claim 3, as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the paper, specifically the high computational complexity of handcrafted PSEs, and suggests that the paper could benefit from a deeper dive into the computational complexity of GPSE. This feedback is 3 as it points out an area for improvement and provides a direction for further analysis. However, the comment lacks specific guidance on how to conduct this analysis or what aspects to focus on, which limits its usefulness. To be more helpful, the comment could include suggestions on what metrics or methods to use for the analysis or how to compare GPSE\"s complexity to other encoding strategies. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to report results on the teststandard split instead of the testdev split, as mentioned in the guidelines from the VQA dataset authors. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete step, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reported results, namely that they are based on the testdev split instead of the teststandard split, as per the guidelines from the VQA dataset authors. This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results on the VQA dataset should be reported on the teststandard split rather than the testdev split, as mentioned in the guidelines from the VQA dataset authors. The reviewer provides a direct reference to the guidelines, which is a clear and specific source of verification. This makes the claim 5, as it is supported by an external reference that provides a clear rationale for the recommendation. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the reporting of results in Table 1, noting that the results on the VQA dataset are reported on the testdev split rather than the teststandard split, as per the guidelines from the VQA dataset authors. This feedback is clear and actionable, as it provides a direct suggestion for improvement by specifying the correct split to use for reporting results. By addressing this issue, the authors can ensure their results are presented accurately and in line with the guidelines, which is crucial for the credibility of their work. Therefore, the comment is 4, as it provides a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the limited applicability of the methods presented in the paper to more structured layers like convolutions. It acknowledges that applying LBEN to convnets without much modification is a strength, but it questions the readiness of the methods to be extended to nonfully connected architectures due to their performance trailing that of MON. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the applicability of their methods. The action is implicit and vague, as the authors are left to infer that they should explore ways to enhance the applicability of their methods to more structured layers. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the limited applicability of the methods presented in the paper to more structured layers like convolutions. It acknowledges that applying LBEN to convnets without much modification is a strength, but questions the readiness of the methods to be extended to nonfully connected architectures due to their performance trailing that of MON. However, the comment does not specify which part of the paper discusses the application to convnets or the comparison with MON, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique but lacks grounding, as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the limited applicability of the methods presented in the paper to more structured layers like convolutions. It acknowledges that applying LBEN to convnets without much modification is a strength, but questions the readiness of the methods to be extended to nonfully connected architectures due to their performance trailing that of MON. The comment provides a logical reasoning by comparing the performance of LBEN to MON, suggesting that the methods may not be ready for broader application. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the limited applicability of the methods presented in the paper to more structured layers like convolutions. It acknowledges that applying LBEN to convnets without much modification is a strength, but questions the readiness of the methods to be extended to nonfully connected architectures due to their performance trailing that of MON. This feedback is 3 as it highlights a potential limitation of the paper and prompts the authors to consider the broader applicability of their methods. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the applicability of their methods to more structured layers. To be more helpful, the comment could include actionable advice or examples of how to enhance the applicability of the methods. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the evaluation of the refactoring process and suggests that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that could be considered for evaluation, such as code coverage, test suite size, and test suite complexity. While the comment implies that the authors should consider these metrics, it does not explicitly instruct them to use any specific metric or provide detailed guidance on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer that they should consider these metrics and decide which ones to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation of the refactoring process, specifically questioning the use of a pass rate for unit tests as insufficient. It provides a list of potential metrics that could be considered, such as code coverage, test suite size, and test suite complexity. However, the comment does not specify which part of the paper discusses the refactoring process, making it weakly grounded. The comment is specific in suggesting alternative metrics for evaluation, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the evaluation of the refactoring process and suggests that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that could be considered, such as code coverage, test suite size, and test suite complexity. While the comment offers some suggestions, it lacks specific examples or detailed reasoning to fully substantiate the claim that the current evaluation method is inadequate. The authors would need to infer the necessity of these additional metrics based on the provided list. Therefore, the comment is 3, as it provides some guidance but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of the refactoring process, noting that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that could be considered for evaluation, such as code coverage, test suite size, and test suite complexity. This feedback is clear and actionable, as it offers concrete suggestions for improving the evaluation methodology. However, the comment could be more helpful if it included additional context or examples on how these metrics might be applied or integrated into the evaluation process. Overall, the comment is 4 as it provides valuable guidance for enhancing the evaluation of the refactoring process."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the main contribution of the paper is not sufficient because the Wiener deconvolution has already been proposed. However, it does not provide any specific guidance or suggestions on how the authors could enhance their contribution or address the issue. The comment lacks actionable details, such as recommending additional contributions or suggesting ways to differentiate the work from existing literature. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the main contribution of the paper, specifically mentioning the Wiener deconvolution, which has already been proposed. However, it does not specify which part of the paper discusses this contribution, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide details on what aspects of the contribution are insufficient or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the main contribution of the paper is not sufficient because the Wiener deconvolution has already been proposed. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the main contribution of the paper, the Wiener deconvolution, has already been proposed, suggesting that the contribution is not sufficient. However, the comment lacks specificity and does not provide any actionable feedback or suggestions on how the authors could enhance their contribution or differentiate their work from existing literature. Without detailed guidance or constructive criticism, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, the comment is 1, as it does not offer any meaningful direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several areas where the connection between the spin glass theory and the regularization term in the paper is considered weak. It points out specific aspects that need further explanation, such as how the regularization helps escape local minima, the effect on Parisi\"s order parameter, and the role of temperature in the proposed scheme. While the comment highlights areas that require clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations, but they are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing in the connection to spin glasses, namely the explanation of how the regularization helps escape local minima, the effect on Parisi\"s order parameter, and the role of temperature in the proposed scheme. This provides clear guidance on what needs to be addressed to strengthen the connection. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the connection to spin glasses is weak, specifically questioning how the regularization term helps escape local minima, the effect on Parisi\"s order parameter, and the role of temperature in the proposed scheme. While the comment raises valid points, it lacks specific examples or references to support the claim. The authors would need to infer the reasoning behind the critique, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the connection between the spin glass theory and the regularization term in the paper is considered weak. It highlights three key aspects that need further explanation: how the regularization helps escape local minima, the effect on Parisi\"s order parameter, and the role of temperature in the proposed scheme. This feedback is clear and actionable, as it provides specific areas for the authors to address in order to strengthen the connection and improve the comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address these points or provided examples of how similar connections have been made in other works. Overall, the comment is 4, as it directs the authors to important areas for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment acknowledges the authors\" exploration of a selftraining scheme but notes that the contribution is limited. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to enhance the contribution or what specific aspects of the selftraining scheme could be further explored or developed. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the selftraining scheme, which is a specific aspect of the paper. However, it does not specify which part of the paper discusses this scheme, making it weakly grounded. The comment provides some specificity by noting that the contribution is limited, but it lacks detailed guidance on how to enhance the contribution or what specific aspects need improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the selftraining scheme is a direct application and that the contribution is limited. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific details or references to compare the contribution with other works, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the authors\" exploration of a selftraining scheme but notes that the contribution is limited. However, it does not provide any specific feedback or suggestions on how the authors could enhance their contribution or improve the paper. Without actionable guidance or detailed critique, the comment lacks helpfulness, leaving the authors without a clear understanding of what needs to be addressed or how to improve their work. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include zoomedin regions of the rendered focal stack or allinfocus images to inspect the quality of the results. This is an explicit request for additional content, providing a clear action for the authors to take. The comment is also concrete, as it specifies exactly what needs to be added to the paper to improve its quality. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that the results shown in the paper are lowresolution and recommends including zoomedin regions of the rendered focal stack or allinfocus images to inspect the quality. However, it does not specify which part of the paper these results are presented in, making it weakly grounded. The comment is specific in suggesting what additional content could be included to improve the paper, such as zoomedin regions or allinfocus images. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results shown in the paper are lowresolution and suggests including zoomedin regions or allinfocus images to inspect the quality. However, the comment does not provide any specific examples or references to support this claim, nor does it explain why the current resolution is insufficient. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the resolution of the results presented in the paper, suggesting that including zoomedin regions or allinfocus images would help inspect the quality. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper by enhancing the visual representation of the results. However, the comment could be more helpful if it explained why the current resolution is insufficient or how the additional images would benefit the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or reasoning."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two concerns regarding the comparative inference method: the significant increase in inference cost due to multiple forward passes and the requirement for validation data for posthoc calibration, which may limit its applicability in openended generation tasks. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the method. The authors are left to infer that they should consider ways to reduce inference cost or explore alternative methods for calibration, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comparative inference method and its impact on inference cost and posthoc calibration, which are specific concerns related to the methodology. However, it does not explicitly mention which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the issues with the method, such as the increased inference cost and the need for validation data, which limits its applicability in certain scenarios. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparative inference method increases inference cost significantly due to multiple forward passes and that posthoc calibration requires validation data, which may limit its applicability in openended generation tasks. The comment provides a logical reasoning for the claim, noting the potential impact on computational resources and the need for validation data. However, it lacks specific examples or references to support the claim fully, making it 3. The authors would need to further explore and substantiate the claim themselves to fully understand its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two potential issues with the comparative inference method: the significant increase in inference cost due to multiple forward passes and the requirement for validation data for posthoc calibration, which may limit its applicability in openended generation tasks. While the comment highlights important considerations, it does not provide specific suggestions or guidance on how the authors might address these concerns or explore alternative methods. The feedback is 3 as it points out areas for improvement, but it lacks actionable advice, making it difficult for the authors to fully understand and address the issues. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly questions the authors\" choice to reinitialize the model to address exploding gradients, suggesting an alternative approach of gradient clipping with a high value for the gradient norm. This provides a clear and direct action for the authors to consider, offering a specific suggestion for improvement. The comment is explicit and concrete, as it specifies exactly what the authors should do to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 265, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current approach of reinitializing the model to address exploding gradients and suggests an alternative method of gradient clipping with a high value for the gradient norm. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" choice to reinitialize the model to address exploding gradients, suggesting an alternative approach of gradient clipping with a high value for the gradient norm. This is a logical suggestion based on common practices in gradient clipping to prevent exploding gradients. However, the comment does not provide specific examples or references to support why gradient clipping is a better approach, making it 3. The authors would need to consider the suggestion and determine its validity themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It questions the authors\" choice to reinitialize the model to address exploding gradients and suggests an alternative approach of gradient clipping with a high value for the gradient norm. This feedback is clear and offers a concrete way for the authors to enhance their methodology, making it 5. By suggesting a more robust and standard approach to gradient clipping, the comment empowers the authors to make a significant improvement in their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for a more detailed explanation of the term \"common pattern,\" indicating that the authors should provide a clearer definition or elaboration. This feedback is direct and provides a clear action for the authors to take, which is to clarify the meaning of the term. The comment is explicit and concrete, giving the authors a specific task to address, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the term \"common pattern,\" allowing the authors to identify the part of the paper where this term is used. This provides full grounding. However, the comment lacks specificity as it does not specify what aspect of the explanation is needed or how it should be improved. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point questions the exact meaning of the term \"common pattern\" and requests a more detailed explanation. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification, which is factual and does not fit the criteria for a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific term, \"common pattern,\" and requests a more detailed explanation. This feedback is clear and actionable, as it directs the authors to clarify a term that may be unclear to readers. By addressing this point, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to elaborate on the term or what aspects of the explanation might be missing. Overall, the comment is 4 as it guides the authors toward improving the clarity of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the generalizability of the pretrained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern, such as conducting additional experiments or analyses to test generalizability, or suggesting ways to improve the model\"s performance on diverse datasets. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the generalizability of the pretrained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, it does not specify which part of the paper discusses the downstream datasets or the pretrained model, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its concern about generalizability but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the generalizability of the pretrained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the generalizability of the pretrained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. This is a relevant point that could impact the applicability and robustness of the model. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or recommendations, the authors are left with a general observation but no clear path for improvement. Therefore, the comment is 3, as it identifies a potential limitation but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the quality of the generated dataset, given that LLMs are known to hallucinate. However, it does not provide any explicit or implicit actions for the authors to take in response to this concern. There is no guidance on how to address the issue of hallucination or how to quality check the generated dataset. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the quality of the generated dataset, specifically questioning how the authors quality check it, given that LLMs are known to hallucinate. However, it does not specify which part of the paper discusses the generation of the dataset or how the authors address the issue of hallucination. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its concern about quality checking but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the quality of the generated dataset, given that LLMs are known to hallucinate. However, it does not provide any specific examples, reasoning, or references to support the claim that the dataset is affected by hallucination. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the quality of the generated dataset, given that LLMs are known to hallucinate. This is an important issue that the authors should address to ensure the reliability and validity of their dataset. However, the comment does not provide any specific guidance or suggestions on how the authors might quality check the dataset or mitigate the risk of hallucination. Without actionable advice or detailed feedback, the authors are left with a general awareness of the issue but no clear path to improvement. Therefore, the comment is 3, as it identifies a critical area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the comparison across the four models might not be meaningful because the wav2vec model is finetuned, while the other three models are trained from scratch. The reviewer implies that the finetuned model is likely to perform better, which could affect the interpretation of the results. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the comparison or provide additional context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the comparison across four models might not be meaningful due to the finetuning of the wav2vec model, while the other three models are trained from scratch. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the potential issue with the comparison, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison across four models might not be meaningful due to the finetuning of the wav2vec model, while the other three models are trained from scratch. The reviewer provides a logical reasoning that the finetuned model is likely to perform better, which could affect the interpretation of the results. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the reasoning and potentially provide additional context or analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a potential issue with the comparison across four models, suggesting that the finetuning of the wav2vec model might affect the interpretation of the results. This feedback is 3 as it highlights a potential weakness in the experimental setup, prompting the authors to consider whether the comparison is fair and meaningful. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative comparisons or analyses. To be more helpful, the comment could provide actionable advice or examples of how to improve the comparison. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges that the paper is wellwritten but notes that it feels dense compared to other puremath ML papers. It suggests that including more examples, such as Figure 2, would be helpful. While the comment implies that the authors should consider adding more examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on what kind of examples to include or how to integrate them into the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges that the paper is wellwritten but notes that it feels dense compared to other puremath ML papers. It suggests that including more examples, such as Figure 2, would be helpful. However, the comment does not specify which part of the paper is dense or where more examples could be added. This makes it weakly grounded, as the authors cannot confidently determine which sections are being referred to. The comment is specific in suggesting the inclusion of more examples, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that the paper is wellwritten but notes that it feels dense compared to other puremath ML papers. It suggests that including more examples, such as Figure 2, would be helpful. However, the comment does not provide specific examples of what aspects of the paper are dense or how the inclusion of more examples would improve the paper. Without detailed reasoning or examples, the claim lacks sufficient support, making it 2. The authors would need to infer the specific areas that could benefit from additional examples, which adds complexity to the feedback. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment acknowledges that the paper is wellwritten but notes that it feels dense compared to other puremath ML papers. It suggests that including more examples, such as Figure 2, would be helpful. While the comment identifies a potential issue with the paper\"s density, it lacks specific guidance on how to address this issue or what types of examples would be most beneficial. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a difference between the introduction of 4.1 and 4.2, noting that 4.2 provides highlevel intuition while 4.1 does not. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this issue. Without actionable advice or specific recommendations, the authors are left without a clear understanding of what changes, if any, are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"4.2\" and \"4.1,\" allowing the authors to identify the specific sections being addressed. However, it does not specify what aspect of these sections is being critiqued or how the highlevel intuition in 4.2 differs from 4.1. This lack of specificity makes it difficult for the authors to understand the exact issue and how to address it. Therefore, the comment is 2, aligning with category 2.", "verifiability_rationale": "The review point claims that \"4.2 starts by providing highlevel intuition while 4.1 does not.\" However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comparison or how it affects the overall structure of the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a difference in the introduction of sections 4.1 and 4.2, noting that 4.2 provides highlevel intuition while 4.1 does not. This observation highlights a potential inconsistency in the paper\"s structure, suggesting that the authors may need to ensure a consistent level of introduction across all sections. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending a particular approach or structure for introducing sections. Without actionable advice, the feedback is 3 as it identifies a potential area for improvement but does not provide detailed guidance on how to enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should introduce more discussions about the obtained permutation matrices in Figure 3, specifically mentioning (e)(j)(o). However, it does not provide explicit guidance on what specific aspects of these matrices should be discussed or how to structure these discussions. The action is implicit and somewhat vague, as the authors can infer that they need to add more content but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the introduction of more discussions about the obtained permutation matrices in Figure 3, specifically mentioning (e)(j)(o). This provides clear guidance on what the authors need to focus on, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that more discussions should be introduced regarding the obtained permutation matrices in Figure 3, specifically mentioning (e)(j)(o). However, the comment does not provide any reasoning or evidence to support why these discussions are necessary or how they would enhance the paper. Without additional context or justification, the authors may find it challenging to understand the importance of these discussions or how to incorporate them effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should introduce more discussions about the obtained permutation matrices in Figure 3, specifically mentioning (e)(j)(o). This feedback is 3 as it identifies a potential area for improvement by suggesting additional content that could enhance the paper. However, the comment lacks specificity and does not provide detailed guidance on what aspects of these matrices should be discussed or how to structure these discussions. While it points out a direction for improvement, it does not offer comprehensive or actionable advice, leaving the authors with a general idea of what to focus on but without clear steps to take. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the crowd workers, specifically asking about their recruitment and training. While it implies that the authors should provide more information on these aspects, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address these questions, but they are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the crowd workers, specifically asking about their recruitment and training. However, it does not specify which part of the paper this information is missing from, making it difficult for the authors to pinpoint the exact section that needs revision. The authors can infer that it might be related to the methodology or experimental setup, but without explicit grounding, it remains weakly grounded. The comment is specific in its request for information about the crowd workers, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point consists of a question seeking clarification about the crowd workers, their recruitment, and training. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the crowd workers, specifically asking for information on their recruitment and training. While this is a relevant inquiry that could help clarify the methodology and ensure the validity of the results, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue. It does not offer actionable feedback or insights into how the authors might improve their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics used may not fully capture the quality of the simplifications. The reviewer emphasizes the importance of human evaluations for assessing the validity and robustness of conclusions. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the evaluation process. The action is implicit and somewhat vague, as it leaves the authors to infer that they should focus more on human evaluations but does not specify how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the validity and robustness of conclusions due to the weak correlation, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the correlation between automatic metrics and human evaluations is weak, suggesting that automatic metrics may not fully capture the quality of simplifications. The comment provides a logical reasoning by stating that human evaluations are more important, which is a common understanding in the field. However, it lacks specific examples or references to support the claim about the weak correlation, making it 3. The authors would need to further explore the issue to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights a potential issue with the weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. It raises a valid concern about the validity and robustness of the conclusions drawn from the automatic metrics alone. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their evaluation process. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to be more specific in the \"Chain of Reasoning\" section, particularly in line 276. This provides a clear and direct action for the authors to take, which is to enhance the specificity of their reasoning in that section. The comment is explicit and provides concrete guidance on what needs to be improved, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Chain of Reasoning\" section and a specific line number (276), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it instructs the authors to be more specific in this section, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, specifically asking for more specificity in the \"Chain of Reasoning\" section, particularly in line 276. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of the paper that needs improvement, namely the \"Chain of Reasoning\" section, particularly line 276. By pointing out the need for more specificity in this section, the comment provides the authors with a clear direction for enhancing their draft. However, it lacks detailed guidance or suggestions on how to achieve this specificity, which would make the feedback more actionable. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the assumptions made in the paper, specifically regarding the presence of constraints and discriminators. However, it does not provide any explicit or implicit actions for the authors to take. The question lacks guidance on how the authors should address this assumption or whether it is a concern that needs to be addressed. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the assumptions made in the paper regarding constraints and discriminators. However, it does not specify which part of the paper this assumption is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not detail what aspect of the constraints or discriminators is being questioned. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the assumptions made in the paper regarding constraints and discriminators. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the assumptions made in the paper regarding the presence of constraints and discriminators. While it identifies a potential area of confusion or uncertainty, it does not provide any actionable feedback or suggestions for the authors to address this issue. The comment lacks depth and does not offer guidance on how the authors might clarify or improve their assumptions. As a result, the comment is 2, as it points out a potential area of concern but does not assist the authors in resolving it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss the Wasserstein GAN (WGAN) paper by Arjovsky et al. (2017) or even add WGAN as a baseline method. This feedback is explicit and provides a clear action for the authors to take, which is to include a discussion or comparison of WGAN in their work. The suggestion is concrete, as it specifies the exact paper and method to consider, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Optimal Transport (OT),\" \"Wasserstein Distance,\" and \"Wasserstein GAN (WGAN),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need to discuss WGAN or add it as a baseline method, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using Optimal Transport (OT) or the Wasserstein Distance in GANs is first seen in the Wasserstein GAN (WGAN) paper by Arjovsky et al. (2017). This claim is supported by a specific reference to the WGAN paper, which provides a clear and verifiable source for the claim. The suggestion to discuss WGAN or add it as a baseline method is also logical and wellsupported by the reference. Therefore, the comment is 5.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors discuss or include the Wasserstein GAN (WGAN) paper by Arjovsky et al. (2017) as a baseline method. This feedback is actionable and offers a clear direction for the authors to enhance their work by incorporating relevant literature and methods. By addressing this suggestion, the authors can provide a more comprehensive context for their research and potentially improve the quality of their draft. However, the comment could be more helpful if it explained why discussing or including WGAN is beneficial or how it relates to the authors\" work. Overall, the comment is 4 as it provides a constructive and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that important related work on MCMC in discrete spaces is absent and suggests that several methods have applied Langevin MCMC to sample discrete sequences, which should be discussed. It also provides specific references to papers that should be included. This feedback is clear and provides concrete guidance on what needs to be addressed, making it 5. The authors know exactly what work to include and where to find it, allowing them to make specific additions to their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the absence of important related work on MCMC in discrete spaces, which allows the authors to identify the specific area needing attention. It also specifies what is missing by suggesting the inclusion of several methods that have applied Langevin MCMC to sample discrete sequences, providing specific references to papers that should be discussed. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important related work on MCMC in discrete spaces is absent and suggests that several methods have applied Langevin MCMC to sample discrete sequences, which should be discussed. The reviewer supports this claim by providing specific references to papers that should be included, such as 1 and 2. This detailed reference to external works provides a clear basis for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of important related work on MCMC in discrete spaces. It provides specific references to papers that have applied Langevin MCMC to sample discrete sequences, which the authors should consider including in their discussion. This feedback is clear and actionable, as it directs the authors to a specific area for improvement by suggesting relevant literature that could enhance the paper\"s context and contribution. Additionally, the comment offers a broader perspective by suggesting that the paper may be more suitable for presentation at a workshop due to its preliminary results and issues with clarity and organization. This additional insight provides the authors with a clearer understanding of the paper\"s current status and potential trajectory. Overall, the comment is 5 as it offers specific guidance and constructive feedback that can significantly improve the draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions why DSFedDRO and FedDRO use different methods to estimate $g$, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether this difference is a concern or how it should be addressed. Without any suggestions or instructions, the authors are left without a clear understanding of what needs to be done in response to this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment questions the choice of methods used to estimate $g$ in DSFedDRO and FedDRO. However, it does not specify which part of the paper discusses these methods or where the authors should address this issue. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the methods is being questioned or how it should be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the choice of methods used to estimate $g$ in DSFedDRO and FedDRO. However, it does not provide any reasoning, examples, or references to support why this choice is problematic or how it affects the paper. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of methods used to estimate $g$ in DSFedDRO and FedDRO. While it identifies a potential area of confusion or inconsistency, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is 2, as it points out a potential problem but does not assist the authors in resolving it."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the authors should include a discussion about the difference between \"(6)\" in Nicekl Kiela and \"l.\" However, it does not provide any specific guidance on what aspects of the difference should be discussed or how to incorporate this discussion into the paper. The action is implicit and vague, as the authors are left to infer what specific aspects need to be addressed and how to integrate this discussion into their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests a discussion about the difference between \"(6)\" in Nicekl Kiela and \"l.\" However, it does not specify which part of the paper this discussion should be included in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the difference should be discussed or how it relates to the paper. Without clear guidance on where to incorporate this discussion or what specific points to address, the authors are left without a clear understanding of what needs to be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests a discussion about the difference between \"(6)\" in Nicekl Kiela and \"l.\" However, it does not provide any context, reasoning, or examples to support why this discussion is necessary or how it would enhance the paper. Without additional information or justification, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include a discussion about the difference between \"(6)\" in Nicekl Kiela and \"l.\" However, it does not provide any context, reasoning, or specific guidance on why this discussion is important or how it would enhance the paper. Without additional information or examples, the authors are left without a clear understanding of what aspects of the difference should be discussed or how it relates to their work. This lack of specificity and actionable feedback makes the comment 2, as it does not offer meaningful guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the lack of multiple experiments and variance analysis for the results. While it identifies an issue, it does not provide explicit guidance on how the authors should address this concern. The comment lacks specific suggestions or instructions on what steps to take to improve the experimental setup or analysis. As a result, the authors are left without a clear understanding of how to implement the necessary changes. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the lack of multiple experiments and variance analysis for the results. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in identifying the lack of multiple experiments and variance analysis, but it lacks grounding as it does not mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments were not conducted multiple times and lacks variance analysis for the results. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to justify the assertion, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental setup, noting that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. This feedback is important as it highlights a potential weakness in the study\"s methodology and analysis, which could impact the reliability and validity of the findings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending the use of statistical tests or suggesting alternative methods for variance analysis. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point acknowledges the inherent gaps between the experiments conducted in the paper and the goal of achieving label efficiency with a human in the loop. It highlights specific factors like differing dataset qualities and temporal drifts in data distributions, which are not accounted for in the experiments. However, the comment does not provide explicit guidance or suggestions on how the authors might address these gaps or account for these factors in their experiments. The action is implicit and somewhat vague, as the authors are left to infer that they should consider these factors but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the gap between the experiments conducted in the paper and the goal of achieving label efficiency with a human in the loop. It specifically mentions factors like differing dataset qualities and temporal drifts in data distributions, which are not accounted for in the experiments. However, the comment does not explicitly mention which part of the paper this issue pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental setup or results, but this inference is not as direct as it could be. The comment is specific in detailing the issue of gaps with realworld datasets, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the inherent gaps between the experiments conducted in the paper and the goal of achieving label efficiency with a human in the loop. It highlights specific factors like differing dataset qualities and temporal drifts in data distributions, which are not accounted for in the experiments. The comment provides a logical reasoning by identifying the limitations of the experiments in terms of their applicability to realworld scenarios. However, it does not provide specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is 3, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the applicability of the experiments to realworld datasets. It acknowledges the inherent differences between the experiments conducted and the goal of achieving label efficiency with a human in the loop. The comment highlights specific factors such as differing dataset qualities and temporal drifts in data distributions, which are not accounted for in the experiments. This feedback is valuable as it points out a limitation in the paper and suggests areas for improvement, such as considering these factors in future experiments. However, the comment could be more helpful if it provided specific suggestions on how to address these gaps or examples of how to account for these factors. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the communication cost provided in the paper, suggesting that it is not particularly low or noteworthy compared to other federated Qlearning algorithms. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or improve the communication cost, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the communication cost provided in the paper, suggesting that it is not particularly low or noteworthy compared to other federated Qlearning algorithms. However, it does not specify which part of the paper discusses the communication cost, making it weakly grounded. The comment is specific in its critique of the communication cost, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the communication cost provided in the paper is not particularly low or noteworthy, given that other federated Qlearning algorithms have demonstrated that O(H) communication rounds are sufficient. However, the comment does not provide specific examples or references to these other algorithms, making it difficult for the authors to verify the claim. The lack of detailed evidence or references limits the verifiability of the claim, as the authors may struggle to understand the basis of the comparison. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment critiques the communication cost provided in the paper, suggesting that it is not particularly low or noteworthy compared to other federated Qlearning algorithms. However, it does not provide specific examples or references to these other algorithms, nor does it offer suggestions on how the authors might improve their communication cost analysis. The feedback is 3 as it identifies a potential area for improvement, but it lacks depth and actionable guidance, leaving the authors with limited insight into how to address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the paper for using a common approach in machine learning literature, specifically the ensemble of neural networks, and notes that it lacks specific adaptations to the homomorphic encryption domain. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this critique or improve their work. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment critiques the paper for using a common approach in machine learning literature, specifically the ensemble of neural networks, and notes that it lacks specific adaptations to the homomorphic encryption domain. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its critique of the lack of specific adaptations but lacks grounding as it does not point to a particular part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main idea of using an ensemble of neural networks is trivial and common in machine learning literature, and that the paper lacks specific adaptations to the homomorphic encryption domain. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without specific examples or detailed reasoning, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the paper for using a common approach in machine learning literature, specifically the ensemble of neural networks, and notes that it lacks specific adaptations to the homomorphic encryption domain. While it identifies a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper presents a new model for detecting overlapping entities in text and that it improves the previous stateoftheart, MH, in experiments on benchmark datasets. However, it questions the clarity of why and how the new model works better. While the comment identifies a lack of clarity, it does not provide explicit guidance or suggestions on how the authors might address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations about the model\"s improvements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the general discussion section of the paper, where the new model for detecting overlapping entities is presented. It mentions that the new model improves the previous stateoftheart, MH, in experiments on benchmark datasets. However, the comment questions the clarity of why and how the new model works better. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the general discussion or results sections. The comment is specific in pointing out the lack of clarity regarding the model\"s improvements, but it lacks full grounding as it does not explicitly mention a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of why and how the new model works better than the previous stateoftheart, MH. However, it does not provide any specific reasoning, examples, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the paper\"s discussion on the new model\"s improvements over the previous stateoftheart, MH. It points out that while the paper presents the new model and its performance on benchmark datasets, it lacks an explanation of why and how the new model works better. This feedback is clear and actionable, as it prompts the authors to provide a more detailed explanation of the model\"s advantages and how they contribute to improved performance. However, the comment could be more helpful if it offered specific suggestions on how to enhance the explanation or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point critiques the formula used in the Adjective Projection part, suggesting that it is not reasonable. It provides a clear explanation of how the formula should be calculated, which involves first calculating the similarity between \"large\" and the object, then \"small\" and the object, and finally calculating the difference between the two similarities. This feedback is explicit and provides concrete guidance on how to improve the formula, making it 5. The authors know exactly what changes to make to address the issue, ensuring a clear path for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Adjective Projection part,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the formula, providing a detailed explanation of how it should be calculated. This feedback is clear and actionable, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point critiques the formula used in the Adjective Projection part, suggesting that it is not reasonable. The reviewer provides a detailed explanation of how the formula should be calculated, which involves calculating the similarity between \"large\" and the object, then \"small\" and the object, and finally calculating the difference between the two similarities. This reasoning is clear and logical, providing a solid basis for the claim. However, the comment could be strengthened by referencing similar approaches or studies that support the proposed calculation method. Overall, the claim is 4, as it provides a logical argument but lacks specific references or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment provides a detailed critique of the formula used in the Adjective Projection part, suggesting that it is not reasonable. It offers a clear explanation of how the formula should be calculated, which involves first calculating the similarity between \"large\" and the object, then \"small\" and the object, and finally calculating the difference between the two similarities. This feedback is 5, as it not only identifies a specific issue but also provides a concrete suggestion for improvement. By offering a clear and detailed explanation, the comment empowers the authors to make a significant enhancement to their draft. Therefore, it is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of a mathematical expression in line 121, specifically regarding the use of sigma_k on both sides of the equation. While it does not explicitly instruct the authors to clarify this point, it implies that they should provide an explanation. The comment also suggests that the authors elaborate on the issues mentioned, which are not specified. The action is implicit and somewhat vague, as it does not provide specific guidance on how to address the issues or clarify the expression. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 121,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of a mathematical expression and suggests that the authors elaborate on the issues mentioned. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point consists of a question about the meaning of a mathematical expression and a suggestion to elaborate on the issues mentioned. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of a mathematical expression in line 121, specifically regarding the use of sigma_k on both sides of the equation. This is a clear and specific point that the authors need to address to ensure clarity in their work. Additionally, the comment suggests that the authors elaborate on the issues mentioned, which could include providing more context or explanation about the proposed method and its ability to capture longrange context information. While the comment identifies a specific area for improvement, it could be more helpful if it offered suggestions on how to elaborate on these issues. Overall, the feedback is 3 as it directs the authors to clarify a mathematical expression and provides a general direction for elaboration, but it lacks detailed guidance on how to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should discuss and compare their work to more recent studies that focus on anyresolution image generation, specifically mentioning two examples: 1 Anyresolution training for highresolution image synthesis, ECCV 2022, and 2 Image Neural Field Diffusion Models, CVPR 2024. This feedback is explicit and provides concrete examples of works that the authors should consider for comparison. The action is clear and actionable, as the authors know exactly what they need to do to improve their draft by including these comparisons. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss and compare their work to more recent studies that focus on anyresolution image generation. It mentions two specific examples, 1 and 2, which are fully grounded as they provide explicit references to the works being compared. However, the comment does not specify which part of the paper should include this discussion or comparison, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but the lack of explicit grounding limits the comment\"s clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should discuss and compare their work to more recent studies that focus on anyresolution image generation. It provides specific examples of works that the authors should consider, namely 1 and 2. This level of detail and reference to external sources supports the claim, making it 4. However, the comment could be strengthened by providing a more detailed explanation of why these comparisons are necessary or how they would enhance the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the authors should discuss and compare their work to more recent studies that focus on anyresolution image generation. It provides specific examples of works that the authors should consider, such as 1 and 2, which are relevant to the topic. This feedback is clear and actionable, as it directs the authors to expand their discussion and comparison to include recent advancements in the field. By following this advice, the authors can enhance the context and relevance of their work, making the comment 5. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the overfitting risk due to the small sample size in the CT experiment and suggests that Section 6 does not sufficiently discuss limitations of the work. It explicitly asks the authors to discuss limitations, such as theoretical assumptions and implementation considerations, and to compare the training time of ODER with RED (Unfold) and RED (Denoising). These requests are clear and provide concrete guidance on what the authors need to address. The comment is explicit and provides specific actions, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sections \"84: 1763\u2013 1780\" and \"Section 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of overfitting due to the small sample size in the CT experiment and suggests discussing limitations, such as theoretical assumptions and implementation considerations. Additionally, it raises questions about the relative improvement of ODER over RED (Unfold) and RED (Denoising) and the training time comparison. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point raises concerns about the overfitting risk due to the small sample size in the CT experiment and suggests that Section 6 does not sufficiently discuss limitations of the work. It provides a specific reference to a DOI link, which supports the claim about the small sample size. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the limitations of the work or the comparison of ODER with RED (Unfold) and RED (Denoising). While the reference to the DOI link provides some support, the overall justification is somewhat incomplete, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the small sample size in the CT experiment, which could lead to overfitting. It suggests that Section 6 does not sufficiently discuss limitations of the work, prompting the authors to consider discussing theoretical assumptions, implementation considerations, and the relative improvement of ODER over RED (Unfold) and RED (Denoising). Additionally, it raises a question about the training time comparison between these alternatives. This feedback is clear and actionable, providing the authors with specific areas to address and improve their draft. However, it could be more helpful if it included suggestions on how to address these limitations or improve the discussion. Overall, the comment is 4, as it guides the authors toward enhancing the comprehensiveness and robustness of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a specific error in the paper, noting that the bound on the 2Wasserstein is stated incorrectly. It points out that the bound should be on the 2Wasserstein squared, rather than the 2Wasserstein itself. This feedback is explicit and provides clear guidance on what needs to be corrected, making it 5. The authors know exactly what part of the paper needs to be revised and how to make the correction. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines (216 and 217) where the error is found, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error, which is the incorrect statement of the bound on the 2Wasserstein. The comment provides a clear and direct correction, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point identifies a specific error in the paper, noting that the bound on the 2Wasserstein is stated incorrectly. It points out that the bound should be on the 2Wasserstein squared, rather than the 2Wasserstein itself. This claim is verifiable as it provides a clear and specific correction, allowing the authors to easily identify and address the error. The comment is wellsupported by the logical reasoning of the incorrect statement, making it 5.", "helpfulness_rationale": "The review comment identifies a specific error in the paper, noting that the bound on the 2Wasserstein is stated incorrectly. It points out that the bound should be on the 2Wasserstein squared, rather than the 2Wasserstein itself. This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. By addressing this error, the authors can ensure the accuracy and clarity of their work. Therefore, the comment is 5, as it offers a direct and constructive suggestion that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the difference between the proposed multiscale hierarchical predictor and existing methods that use pooling layers to reduce the number of nodes and learn different scale representations. It explicitly asks for clarification on this point, which is a direct action for the authors to take. However, the comment does not provide specific guidance on how to address this question or what aspects of the proposed method should be highlighted to differentiate it from the existing methods. While the action is explicit, the lack of concrete details makes it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Comparison to other methods,\" allowing the authors to identify the part of the paper being addressed. It also specifies the issue by questioning the difference between the proposed multiscale hierarchical predictor and existing methods that use pooling layers. The comment provides references to relevant literature, which further grounds the discussion. However, it does not specify what aspects of the proposed method need to be clarified or how it differs from the existing methods, making it specific but not fully specific. Therefore, this comment is categorized as 4, aligning with a score of 4.", "verifiability_rationale": "The review point raises a question about the difference between the proposed multiscale hierarchical predictor and existing methods that use pooling layers. It does so by referencing several external works, which provides some support for the claim. However, the comment lacks detailed reasoning or specific comparisons to fully substantiate the claim. The references are listed but not integrated into the discussion, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the novelty and differentiation of the proposed multiscale hierarchical predictor compared to existing methods that use pooling layers. It references several relevant works, which provides a context for the authors to consider. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or differentiate their work. While it highlights an important area for clarification, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the paper needs more careful proofreading, indicating that the authors should improve the readability of their draft. However, it does not provide specific guidance on what aspects of the paper are unclear or how to improve the proofreading. The action is implicit and vague, as the authors are left to infer what needs to be addressed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment indicates that the paper as a whole needs more careful proofreading to improve its readability. However, it does not specify which parts of the paper are problematic or what specific issues need attention, such as grammatical errors, unclear sentences, or logical inconsistencies. Without detailed guidance, the authors cannot effectively address the feedback. The comment is 1 as it does not identify a specific section or aspect of the paper, and it is also not specific in detailing what needs to be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not read well and requires more careful proofreading. However, it lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the paper is unclear or needs improvement, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the paper as a whole needs more careful proofreading to improve its readability. However, it lacks specificity and does not provide any actionable feedback or suggestions on how to address the issue. Without detailed guidance or examples of what needs to be improved, the authors are left without a clear understanding of where to focus their efforts. This makes the comment 2, as it identifies a general problem but does not offer meaningful guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests several actions for the authors to take. First, it recommends analyzing the distribution of addressing coefficients (Betas) with and without the bias towards sequential addressing, noting that this difference is important for the synthetic task. Second, it questions the value of the tradeoff parameter (Theta) and asks how it was selected. Third, it proposes a baseline comparison by using the attention from the previous question instead of a soft attention mechanism. These suggestions are explicit and provide concrete guidance on what the authors should explore or address in their draft. The feedback is clear and actionable, making it 5.", "grounding_specificity_rationale": "The comment suggests analyzing the distribution of addressing coefficients (Betas) with and without the bias towards sequential addressing, noting its importance for the synthetic task. It also questions the value of the tradeoff parameter (Theta) and asks how it was selected. Additionally, the reviewer proposes a baseline comparison by using the attention from the previous question instead of a soft attention mechanism. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the analysis or results sections where these topics might be discussed. The comment is specific in detailing what needs to be addressed, such as the distribution analysis and the tradeoff parameter. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the distribution of addressing coefficients (Betas) with and without the bias towards sequential addressing should be analyzed, noting that this difference is important for the synthetic task. It also questions the value of the tradeoff parameter (Theta) and asks how it was selected. Additionally, the reviewer proposes a baseline comparison by using the attention from the previous question instead of a soft attention mechanism. These suggestions are based on logical reasoning and common knowledge about the importance of analyzing distributions and the potential impact of the tradeoff parameter. However, the comment lacks specific references or detailed examples to fully substantiate the claims, making it 3. The authors would need to provide additional context or evidence to fully understand and address the points raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors analyze the distribution of addressing coefficients (Betas) with and without the bias towards sequential addressing. This is an important point, as it highlights a potential area for improvement in understanding the impact of the sequential addressing bias on the synthetic task. Additionally, the comment questions the value of the tradeoff parameter (Theta) and asks how it was selected, which could help clarify the methodology. The reviewer also proposes a baseline comparison by using the attention from the previous question instead of a soft attention mechanism, offering a concrete suggestion for further analysis. This level of detail and specificity makes the comment 5, as it guides the authors on how to enhance their draft by addressing specific areas of concern and providing actionable suggestions for improvement. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the necessity of proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is obvious. The reviewer also expresses a personal opinion that the proposition is unnecessary and does not contribute to making NC a complexity measure in the context of statistical learning. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should remove or revise proposition 1, or how they might address the reviewer\"s concerns. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the necessity of proposition 1 and suggests that it is a standard regression problem, implying that the application of a standard concentration inequality is obvious. However, it does not specify which part of the paper discusses proposition 1, making it weakly grounded. The comment is specific in its critique of the proposition, questioning its relevance and contribution to the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is obvious. The reviewer also expresses a personal opinion that the proposition is unnecessary and does not contribute to making NC a complexity measure in the context of statistical learning. However, the comment lacks specific reasoning or references to support the claim that proposition 1 is unnecessary or decorative. Without detailed justification or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient evidence or explanation.", "helpfulness_rationale": "The review comment questions the necessity of proposition 1, suggesting that it is a standard regression problem and that the application of a standard concentration inequality is obvious. The reviewer also expresses a personal opinion that the proposition is unnecessary and does not contribute to making NC a complexity measure in the context of statistical learning. While the comment identifies a potential area of concern, it lacks specific guidance or suggestions on how the authors might address this issue or improve their draft. The feedback is 3 as it prompts the authors to reconsider the relevance of proposition 1, but it does not provide actionable advice or detailed insights into how to enhance the paper. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the limited evaluation of defense techniques in the context of backdooring classification. It suggests that the evaluation of proposed methods against input perturbationbased defenses is crucial for a comprehensive understanding of attacks. The reviewer provides specific references to relevant works by Doan et al. that could be used for comparison. While the comment implies that the authors should include these evaluations, it does not explicitly instruct them to do so. The action is implicit and somewhat concrete, as the authors can infer the need to include these evaluations but may not be entirely sure of the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"defense techniques\" and \"backdooring classification,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of limited evaluation of defense techniques and suggests that the evaluation of proposed methods against input perturbationbased defenses is essential for a comprehensive understanding of attacks. The comment provides specific references to relevant works by Doan et al. that could be used for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of defense techniques is limited, specifically mentioning input perturbationbased defenses. The reviewer supports this claim by referencing two recent works by Doan et al. that address similar issues. This provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation of defense techniques, particularly in the context of backdooring classification. It highlights the importance of evaluating the proposed method against input perturbationbased defenses, which is a relevant and actionable suggestion. The comment provides specific references to relevant works by Doan et al., which can guide the authors in expanding their evaluation. This feedback is clear and actionable, offering a concrete direction for enhancing the comprehensiveness of the paper. However, it could be more helpful if it included a more detailed explanation of how these defenses work or how they might be applied to the proposed method. Overall, the comment is 4, as it provides valuable insights and direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the related work section should be more focused and should include descriptions of similar datasets for nonEnglish or underrepresented languages. It also points out that the context and evidencebased methods are presented shallowly in the related work. While the comment implies that the authors should expand the related work section to include more detailed descriptions and examples, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer what specific changes are needed and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section should be more focused and should include descriptions of similar datasets for nonEnglish or underrepresented languages. It also critiques the presentation of context and evidencebased methods in the related work. However, the comment does not specify which part of the related work section is lacking in focus or depth, making it difficult for the authors to pinpoint the exact areas needing improvement. While the authors might have an idea of where these issues could be addressed, the comment lacks full grounding. It is specific in suggesting what should be included, but without explicit references to sections or parts of the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the related work section should be more focused and should include descriptions of similar datasets for nonEnglish or underrepresented languages. It also critiques the presentation of context and evidencebased methods in the related work. However, the comment lacks specific examples or references to support the claim that the related work is shallow or that it should be more focused. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the related work section. It suggests that the section should be more focused and should include descriptions of similar datasets for nonEnglish or underrepresented languages. Additionally, it points out that the context and evidencebased methods are presented shallowly in the related work. While the comment highlights important areas for expansion and depth, it could be more helpful if it provided specific examples or references to guide the authors in making these improvements. Overall, the feedback is clear and actionable, making it 4 for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" argument regarding the placement of Batch Normalization (BN) layers in the network. It suggests that BN can be folded into the next convolutional operation if it follows a ReLU layer, as all activations in the same convolutional feature map share the same mean, variance, scale, and offset in the BN implementation. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their argument. The action is implicit and vague, as it lacks concrete steps for the authors to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"same paragraph\" and \"experiment (Table 2),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the authors\" argument about the placement of Batch Normalization (BN) layers and suggesting an alternative placement strategy. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the placement of Batch Normalization (BN) layers in the network, specifically questioning the authors\" argument that BN can be folded into the next convolutional operation. The comment provides a logical reasoning by suggesting that all activations in the same convolutional feature map share the same mean, variance, scale, and offset in the BN implementation, which could support the claim that BN can be folded into the next convolutional operation. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to further explore and justify the reasoning themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the placement of Batch Normalization (BN) layers in the network, specifically questioning the authors\" argument that BN can be folded into the next convolutional operation. It provides a logical reasoning by suggesting that all activations in the same convolutional feature map share the same mean, variance, scale, and offset in the BN implementation, which could support the claim that BN can be folded into the next convolutional operation. This feedback is 3 as it prompts the authors to reconsider their argument and potentially revise their explanation. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this issue or improve the clarity of the argument. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct largescale experiments to validate the results from their smallscale experiments. It explicitly states that the models used in the experiments are small and recommends varying the network size to determine if the results extend to larger scales. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be done to improve their draft. The suggestion is explicit and offers detailed guidance on how to implement the action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section\" and the specific models used in the MNIST and SVHN experiments, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of lacking largescale experiments and suggests conducting experiments that vary the network size to determine the scalability of the results. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the models used in the experiments are small and suggests conducting largerscale experiments to validate the results. However, the comment does not provide specific reasoning or evidence to support why largerscale experiments are necessary or how they would impact the results. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, specifically the lack of largescale experiments. It points out that the models used in the experiments are quite small, which raises questions about the scalability of the results. The comment provides a clear and actionable suggestion by recommending that the authors conduct experiments with varying network sizes to determine if the results from smallscale experiments extend to larger scales. This feedback is valuable as it highlights a critical area for improvement and offers a specific direction for the authors to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it provided additional context or examples of how to conduct these largerscale experiments. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about what happens when the matrix W is an identity matrix, suggesting that this would reduce the problem to a spherical case and asking for a comparison with prior work. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and report on the results of this scenario. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about what happens when the matrix W is an identity matrix, suggesting that this would reduce the problem to a spherical case and asking for a comparison with prior work. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in its request for comparison with prior work, but without clear grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises a question about what happens when the matrix W is an identity matrix and suggests that this would reduce the problem to a spherical case. It also asks for a comparison with prior work. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this scenario is relevant or how it relates to the prior work. Without additional context or explanation, the authors may find it challenging to understand the significance of this question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about what happens when the matrix W is an identity matrix, suggesting that this would reduce the problem to a spherical case and asking for a comparison with prior work. While the comment identifies a potential area for exploration, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or incorporate it into their analysis. The feedback is 3 as it prompts the authors to consider a specific scenario, but it does not offer actionable steps or detailed advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the work primarily focuses on CO problems on graphs, rather than general MILP or QUBO problems, which limits the application scope. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this limitation or expand the application scope. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the scope of the work, specifically that it focuses on CO problems on graphs rather than general MILP or QUBO problems. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, while the comment identifies a specific issue with the scope, it does not provide detailed guidance on how to address this limitation or expand the application scope. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the work primarily focuses on CO problems on graphs, limiting its application scope to general MILP or QUBO problems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the limitation or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a limitation in the scope of the work, noting that it primarily focuses on CO problems on graphs rather than general MILP or QUBO problems. This observation is relevant and could be helpful for the authors to consider expanding their application scope. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this limitation or broaden their focus. Without detailed feedback or suggestions for improvement, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that learning both low and highfrequency information in balance is not novel, as there have been many works promoting uniformly learning various frequency domains by randomly masking frequency segments. The reviewer suggests that the authors should analyze or compare their work to these related works, but does not provide specific guidance on how to conduct this analysis or comparison. The comment implies an action (to analyze or compare the work to related studies) but lacks concrete details on how to execute it, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the aspect of learning low and highfrequency information in balance, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the lack of analysis or comparison to related works, such as those mentioned in the references, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that learning both low and highfrequency information in balance is not novel, as there have been many works promoting uniformly learning various frequency domains by randomly masking frequency segments. The reviewer supports this claim by referencing several related works, including 1 Stochastic Frequency Masking to Improve SuperResolution and Denoising Networks, ECCV 2020, 2 FSDR: Frequency Space Domain Randomization for Domain Generalization, CVPR 2021, 3 Spectrum Random Masking for Generalization in Imagebased Reinforcement Learning, NeurIPS 2022, and 4 MASKED FREQUENCY MODELING FOR SELFSUPERVISED VISUAL PRETRAINING, ICLR 2023. This provides a robust basis for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that learning both low and highfrequency information in balance is not novel, as there have been many works promoting uniformly learning various frequency domains by randomly masking frequency segments. The reviewer provides specific references to related works, which is helpful for the authors to understand the context of their work and potentially identify gaps in their analysis or comparison. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or integrate these related works into their discussion. Overall, the comment is 3 as it provides valuable information but lacks detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the compression bandwidth of PC+IDF should be compared with IDF in Section 5. However, it does not provide any explicit instructions or guidance on how to conduct this comparison or what specific aspects of the compression bandwidth should be evaluated. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly what steps to take to address the suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the compression bandwidth of PC+IDF compared with IDF. This provides clear guidance on what the authors should focus on improving. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the compression bandwidth of PC+IDF should be compared with IDF in Section 5. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or beneficial. The comment lacks specific details or examples that would help the authors understand the importance of this comparison or how it might impact their work. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the suggestion effectively.", "helpfulness_rationale": "The review comment suggests a specific comparison that could be made in Section 5, namely the compression bandwidth of PC+IDF compared with IDF. This feedback is 3 as it provides a clear direction for the authors to consider when improving their draft. However, the comment lacks depth and does not offer any additional context or rationale for why this comparison is important or how it might impact the paper. To be more helpful, the comment could include a justification for the suggested comparison or suggest other aspects that could be explored in this context. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the model names T5ind and T5seq are misleading and proposes alternative names, such as Descind/seq, Egind, and Demoind/seq. This provides a clear and direct action for the authors to take, specifying exactly what needs to be changed in the model naming. The comment is 5 as it offers concrete suggestions that the authors can follow to improve the clarity and accuracy of their model names.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the model names \"T5ind\" and \"T5seq,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the model names, namely that they are misleading, and provides alternative suggestions for more appropriate names. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model names \"T5ind\" and \"T5seq\" are misleading and suggests alternative names. However, the comment does not provide any reasoning or evidence to support why these names are misleading or how the suggested alternatives would be more appropriate. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the model names \"T5ind\" and \"T5seq,\" suggesting that they are misleading. It provides a clear and actionable suggestion by proposing alternative names, such as \"Descind/seq,\" \"Egind,\" and \"Demoind/seq,\" which could help clarify the models\" purpose. This feedback is valuable as it directly addresses a potential source of confusion and offers concrete steps for improvement. However, the comment could be more helpful if it explained why the current names are misleading or how the suggested alternatives would be more appropriate. Overall, the comment is 4, as it provides actionable guidance but could be enhanced with additional context or reasoning."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the choice of the acronym \"AR\" for \"artificial intelligence\" and notes its use in line 055. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the acronym should be changed, clarified, or if there is a specific reason for its use. The comment lacks actionable advice, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the choice of the acronym \"AR\" for \"artificial intelligence\" and mentions its use in line 055. This provides full grounding as it explicitly references a specific line number, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly questions the choice of the acronym and its use, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of the acronym \"AR\" for \"artificial intelligence\" and notes its use in line 055. However, it does not provide any reasoning or justification for why this choice is problematic or how it could be improved. The comment lacks supporting evidence or examples, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the choice of the acronym \"AR\" for \"artificial intelligence\" and notes its use in line 055. While it identifies a potential issue with the consistency and clarity of the acronym, it does not provide any suggestions or guidance on how the authors might address this issue. The comment lacks depth and actionable feedback, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the paper\"s core idea and the motivation behind the gating design for MTL, suggesting that the gating mechanism is not a new story in MTL. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the clarity of the motivation or how to address the critique regarding the novelty of the gating mechanism. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the core idea of the paper, specifically the motivation behind the gating design for MTL and its novelty. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in its critique of the gating mechanism\"s novelty, but without clear references to specific sections, the authors may struggle to identify the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the paper\"s core idea and the motivation behind the gating design for MTL, suggesting that the gating mechanism is not a new story in MTL. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the gating mechanism is not novel. Without such evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment critiques the paper\"s core idea, specifically the motivation behind the gating design for MTL, suggesting that it is not a new story in MTL. However, it does not provide specific suggestions or guidance on how the authors might improve the clarity or novelty of their approach. Without actionable feedback or constructive criticism, the authors are left without a clear path for improvement. Therefore, the comment is rated as 2, as it identifies a potential weakness but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the practicality of the proposed method, noting that it relies on strong assumptions such as the availability of ground truth and DM\"s decisions for each DM of interest. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the practicality of their method. The comment identifies a concern but lacks actionable advice, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the practicality of the proposed method, specifically mentioning the strong assumptions required for training, such as the availability of ground truth and DM\"s decisions for each DM of interest. However, it does not specify which part of the paper discusses these practical scenarios or assumptions, making it weakly grounded. The comment is specific in detailing the issue with the assumptions, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the practicality of the proposed method is impaired by strong assumptions, such as the availability of ground truth and DM\"s decisions for each DM of interest. However, the comment does not provide specific examples or detailed reasoning to support this claim. The mention of biases, uncertainties, and behaviors during training is vague and lacks concrete evidence or references to substantiate the critique. Without additional context or examples, the claim remains 3, as the authors would need to infer the specific issues and their impact on practicality. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the practicality of the proposed method, noting that it relies on strong assumptions such as the availability of ground truth and DM\"s decisions for each DM of interest. This feedback highlights a critical area that could impact the applicability of the method in realworld scenarios. However, the comment does not provide specific suggestions or guidance on how the authors might address these assumptions or improve the practicality of their approach. While it points out a significant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential weakness but lacks depth and specificity in suggesting improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the experimental part, specifically mentioning that the LR and SVM baselines are too weak compared to deep learning approaches. However, it does not provide any explicit or implicit suggestions for improvement. There is no guidance on how the authors might strengthen their experimental section or address the issue of weak baselines. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the experimental part, specifically mentioning that the LR and SVM baselines are too weak compared to deep learning approaches. However, it does not specify which part of the experimental section is being addressed, such as a particular experiment, table, or figure. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. Additionally, the comment does not provide specific details on what aspects of the baselines are weak or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental part is less convincing due to the weak performance of the LR and SVM baselines compared to deep learning approaches. However, the comment lacks specific examples, detailed comparisons, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental part of the paper, noting that the LR and SVM baselines are too weak compared to deep learning approaches. This feedback is 3 as it points out a potential weakness in the experimental design or results, prompting the authors to consider whether their baselines are appropriate or if additional comparisons are needed. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative baselines or methods for comparison. Therefore, while it highlights an area for improvement, it does not offer detailed actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of discussion on communication cost in both the theorem and the experiment, which undermines the contribution of the paper. While the comment identifies an area that needs attention, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should include a discussion on communication cost, and it is somewhat vague because it lacks specific instructions on how to incorporate this discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation of the GLASU algorithm, which is to save communication, and points out that neither the theorem nor the experiment discuss the communication cost. This implies that the authors should include a discussion on communication cost to support the contribution of the paper. However, the comment does not specify which part of the paper should include this discussion, such as the methodology or results sections. While the authors can infer that it relates to the theoretical or experimental sections, the comment lacks full grounding as it does not explicitly mention these sections. It is specific in identifying the issue of lacking communication cost discussion, but not fully grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks discussion on communication cost, which undermines the contribution of the paper. However, the comment does not provide specific examples or references to support this claim. It lacks detailed reasoning or evidence to substantiate why the absence of communication cost discussion is problematic. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides a general claim but lacks sufficient detail for verification.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the discussion of communication cost, which is a key aspect of the GLASU algorithm\"s motivation. By pointing out the lack of discussion on communication cost in both the theorem and the experiment, the comment highlights a critical area that needs attention to fully substantiate the paper\"s contribution. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of specific metrics or analyses. While it points out a crucial weakness, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, as it provides insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly instructs the authors to explicitly state the contributions of their paper. This is a clear and direct action that the authors can take to improve their draft. The feedback provides a specific and concrete step for the authors to follow, ensuring they know exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the contributions of the paper should be explicitly stated, but it does not specify which part of the paper this should be addressed in. The authors can infer that it relates to the introduction or conclusion sections, where contributions are typically discussed, but this inference is not explicit. The comment is specific in its request for explicit contribution statements, but it lacks grounding as it does not pinpoint a specific section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the contributions of the paper should be explicitly stated. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment identifies a critical area for improvement by suggesting that the paper should explicitly state its contributions. This is an important aspect of any research paper, as it helps readers understand the novelty and significance of the work. However, the comment lacks specificity and does not provide guidance on how to effectively communicate the contributions or what specific aspects should be highlighted. While it points out an essential area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it provides a general direction but lacks depth and actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in the motivation and explanation of the work. It specifically points out that the claim about \"different densities directly causing semantic conflicts\" should be justified experimentally or theoretically. While the comment identifies a specific area needing improvement, it does not provide explicit guidance on how to address this issue or what specific experiments or theoretical justifications should be included. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without detailed instructions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of the motivation and explanation in the paper, specifically mentioning the claim about \"different densities directly causing semantic conflicts.\" However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its request for experimental or theoretical justification of this claim. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation and explanation of the work are not clear, specifically mentioning the statement about \"different densities directly causing semantic conflicts.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this claim is valid. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of clarity in the motivation and explanation of the work. It points out a specific claim about \"different densities directly causing semantic conflicts\" and suggests that this claim should be justified experimentally or theoretically. This feedback is clear and actionable, as it directs the authors to provide a stronger rationale for their claims. However, the comment could be more helpful if it offered specific suggestions on how to improve the explanation or provided examples of how similar claims have been justified in other works. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the training method for the three transformer modules in the proposed approach. It also critiques the inclusion of another three cases in Figure 5, suggesting that it is unnecessary if no new points are demonstrated. While the comment implies that the authors should clarify the training method and potentially remove the redundant visualization, it does not provide explicit instructions on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the training method and potentially revise the figure. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"another three cases,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the repetition of visualization and suggests that it is unnecessary if no new points are demonstrated. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the training method for the three transformer modules in the proposed approach, asking whether they are trained iteratively or in an endtoend manner. It also critiques the inclusion of another three cases in Figure 5, suggesting that it is unnecessary if no new points are demonstrated. The comment provides a logical reasoning for the critique, questioning the necessity of repeating the visualization without new insights. However, it lacks specific examples or references to support the claim about the training method or the redundancy of the visualization. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises a question about the training method for the three transformer modules in the proposed approach, asking whether they are trained iteratively or in an endtoend manner. This is a relevant and important point that could clarify the methodology and potentially impact the understanding of the approach. Additionally, the comment critiques the inclusion of another three cases in Figure 5, suggesting that it is unnecessary if no new points are demonstrated. This feedback is clear and actionable, as it prompts the authors to clarify the training method and potentially revise the figure to avoid redundancy. However, the comment could be more helpful if it provided specific suggestions on how to address the issues or offered examples of how to improve the clarity of the figure. Overall, the comment is 4, as it identifies areas for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific suggestions for improving the clarity and precision of the writing, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFNproduced distributions.\" It also highlights the need for the authors to explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that are not due to BFNs. These suggestions are explicit and provide concrete guidance on how to enhance the clarity and originality of the paper. The authors know exactly what changes to make to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the clarity and precision of the writing, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFNproduced distributions.\" It also highlights the need for the authors to explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that are not due to BFNs. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these distinctions are discussed. The comment is specific in detailing what needs to be addressed, making it weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the writing could benefit from greater precision and clarity, providing specific examples such as the distinction between \"parameters of BFNs\" and \"parameters of BFNproduced distributions.\" It also claims that the proposed method is closely related to infoDiffusion, with the main adaptation being its application to BFNs. The comment suggests that the authors should explicitly outline the unique contributions of ParamReL to distinguish it from infoDiffusion. While the comment provides some reasoning and examples, it lacks detailed justification or references to specific aspects of infoDiffusion or BFNs that would strengthen the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on improving the clarity and precision of the writing, suggesting that the authors distinguish between \"parameters of BFNs\" and \"parameters of BFNproduced distributions.\" It also highlights the need for the authors to explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that are not due to BFNs. This feedback is clear and offers concrete suggestions for enhancing the clarity and originality of the paper, making it 4. However, it could be more comprehensive by providing additional guidance on how to present these distinctions or innovations. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential misunderstanding in the text regarding the focus of the discussion in Section 2. It suggests that the authors should clarify their intention to discuss a situation where the gradient of the sum is not the sum of the individual gradients. The comment also implies that the authors should discuss this situation in less space, as it is shared in all ERM approaches. While the comment identifies a specific issue and provides a suggestion for improvement, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as it lacks detailed guidance on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines (6074) and section (Sect. 2) of the paper being addressed, allowing the authors to accurately identify the part of the paper being discussed. It also specifies the issue by pointing out a potential misunderstanding regarding the focus of the discussion and suggesting that the authors clarify their intention to discuss a situation where the gradient of the sum is not the sum of the individual gradients. Additionally, the comment provides a specific suggestion to discuss this situation in less space, as it is shared in all ERM approaches. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors want to focus on a situation where the gradient of the sum is not the sum of the individual gradients, but this is not communicated in the text. The reviewer provides a specific reference to lines 6074 in Section 2, which supports the claim by allowing the authors to verify the context. However, the comment lacks additional evidence or examples to fully substantiate the claim, making it 3. The authors would need to consider the reviewer\"s suggestion to clarify their focus in the text, but the comment could be strengthened with more detailed reasoning or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential misunderstanding in the paper regarding the focus of the discussion in Section 2. It points out that the authors may intend to discuss a situation where the gradient of the sum is not the sum of the individual gradients, but this is not clearly communicated in the text. The comment suggests that this situation is shared in all ERM approaches and could be discussed in less space. While the feedback highlights a specific area for clarification, it does not provide detailed guidance on how to rephrase or restructure the text to address the issue. The suggestion to discuss the situation in less space is somewhat vague, as it does not specify what aspects could be omitted or how to streamline the discussion. Therefore, the comment is 3, as it points out a potential misunderstanding but lacks depth and actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the proposed questionrewrite strategy, specifically questioning its effectiveness in covering a sufficiently large number of questions. The reviewer provides detailed analysis, noting that out of 100 passages, 23% become invalid, with 44% of those invalid questions attributed to unresolved coreference. The comment also points out that the proposed method rewrites only 12% of the questions for all models, which the reviewer considers insignificant. While the comment highlights a potential issue with the method, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their strategy. The action is implicit and somewhat vague, as the authors are left to infer that they should either revise their method or provide additional justification for its effectiveness. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed questionrewrite strategy\" and references specific data from Table 4 in the appendix, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of the method in covering a sufficiently large number of questions, particularly highlighting the high number of invalid questions and the attribution of those invalid questions to unresolved coreference. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed questionrewrite strategy, specifically questioning its effectiveness in covering a sufficiently large number of questions. The reviewer provides detailed analysis, noting that out of 100 passages, 23% become invalid, with 44% of those invalid questions attributed to unresolved coreference. The comment also references specific data from Table 4 in the appendix and reports that the proposed method rewrites only 12% of the questions for all models, which the reviewer considers insignificant. This level of detail and specific references provide a robust basis for the claim, making it 5. The reviewer\"s reasoning is clear and supported by factual data, allowing the authors to understand and address the concern effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment raises a significant concern about the proposed questionrewrite strategy, questioning its effectiveness in covering a sufficiently large number of questions. It provides detailed analysis, noting that out of 100 passages, 23% become invalid, with 44% of those invalid questions attributed to unresolved coreference. The comment also points out that the proposed method rewrites only 12% of the questions for all models, which the reviewer considers insignificant. This feedback is clear and actionable, as it highlights a potential weakness in the method and suggests that the authors should address this issue to improve the effectiveness of their strategy. However, the comment could be more helpful if it offered specific suggestions or examples on how to enhance the coverage or effectiveness of the questionrewrite strategy. Overall, the comment is 4, as it provides valuable insights and prompts the authors to consider a critical aspect of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the use of L2 distance in equation (4) and suggests that earth mover\"s distance is more common in OT. It explicitly asks for the benefit of using L2 distance, which is a direct and concrete action for the authors to address. The comment provides a clear and specific question that the authors need to answer, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (4),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of L2 distance and asks for the benefit of using it instead of the more common earth mover\"s distance in OT. This provides clear guidance on what aspect of the paper needs clarification or justification. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of L2 distance in equation (4) and suggests that earth mover\"s distance is more common in OT. It asks for the benefit of using L2 distance, which is a logical question that requires justification. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate the claim that earth mover\"s distance is more common or why L2 distance might be beneficial. This lack of supporting information makes the claim 3, as the authors would need to provide their own reasoning or evidence to address the question. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the use of L2 distance in equation (4) and suggests that earth mover\"s distance is more common in OT. It asks for the benefit of using L2 distance, which is a relevant and important point for the authors to address. By prompting the authors to justify their choice of distance metric, the comment provides a clear and actionable suggestion for improvement. However, it could be more helpful if it offered additional context or examples to guide the authors in their response. Overall, the comment is 4 as it directs the authors to clarify an important aspect of their methodology, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the description of related work is scattered throughout the paper and recommends a broader discussion of how the algorithm compares to other offline RL algorithms. While the comment implies that the authors should consolidate the related work discussion and provide a more comprehensive comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to structure the comparison or which aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the related work being scattered throughout the paper, specifically mentioning papers 14,15. It also suggests a broader discussion of how the algorithm compares to other offline RL algorithms. However, it does not specify which sections of the paper are affected by this scattering or where the authors should include the broader discussion. While the authors can infer that the comment relates to the related work section, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting a broader discussion, but without detailed guidance on how to implement this, it remains somewhat vague. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the related work is scattered throughout the paper and suggests a broader discussion of how the algorithm compares to other offline RL algorithms. However, the comment lacks specific examples or references to support the claim about the scattering of related work or the need for a broader discussion. Without detailed evidence or examples, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2, as it provides some basis for the claim but requires more detailed justification or examples to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of the related work section, noting that it is scattered throughout the paper. It suggests that a broader discussion of how the algorithm compares to other offline RL algorithms would be beneficial. While the comment highlights a potential area for improvement, it lacks detailed guidance or suggestions on how to structure this broader discussion or which specific aspects of the comparison should be included. The feedback is 3 as it points out a weakness and provides a general direction for improvement, but it could be more actionable with additional details. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the final solution if all increments are available simultaneously. While it implies that the authors should address this question, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide an explanation or analysis regarding the impact of simultaneous availability of increments on the final solution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment poses a question about the final solution if all increments are available simultaneously. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or experiment. Without explicit references or context, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspect of the final solution is being questioned or how it should be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the final solution if all increments are available simultaneously. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the final solution if all increments are available simultaneously. While it highlights an area that could be explored or clarified, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this question. The comment identifies a potential area for improvement but does not offer actionable advice or detailed feedback, leaving the authors with a general direction but no clear steps to take. Therefore, the comment is 3, as it prompts the authors to consider an aspect of their work but does not fully support them in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the technique of using multiple different feature spaces, describing it as convoluted and potentially circular. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this issue. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to simplify the technique. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technique of using multiple different feature spaces, specifically mentioning the 25 feature space of Mitchell et al. and the full/pruned GloVe model. This provides full grounding as it explicitly references specific aspects of the paper, allowing the authors to accurately identify the part being addressed. The comment is also specific because it clearly specifies the issue with the technique, describing it as convoluted and potentially circular. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the technique of using multiple different feature spaces, describing it as convoluted and potentially circular. However, the comment does not provide specific examples or detailed reasoning to support why this approach is problematic. Without additional context or explanation, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 2, as it lacks sufficient evidence or justification to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a potential issue with the technique used in the paper, specifically the use of multiple different feature spaces. It describes the approach as convoluted and potentially circular, which could be confusing for readers. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their technique. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it highlights a concern but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include comparisons with other works that use the MobileNetV3 search space, specifically mentioning AtomNAS, and to provide FLOPs and parameter sizes. It also questions the absence of results from OFA with progressive shrink in the table. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The explicit nature of the instructions and the detailed guidance on what to include make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the table, namely comparisons with other works using the MobileNetV3 search space (e.g., AtomNAS) and the inclusion of FLOPs and parameter sizes. Additionally, it questions the absence of results from OFA with progressive shrink in the table. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the absence of comparisons with other works using the MobileNetV3 search space, specifically mentioning AtomNAS, and asks for the inclusion of FLOPs and parameter sizes. It also questions the absence of results from OFA with progressive shrink in the table. While the comment raises valid points, it lacks specific references or detailed reasoning to support the claim that these comparisons are necessary or how they would enhance the paper. The authors may need to infer the importance of these comparisons based on the context of the paper. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or examples to be 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying a gap in the comparison of results with other works using the MobileNetV3 search space, such as AtomNAS. It also questions the absence of results from OFA with progressive shrink in the table, which could be relevant for comparison. This feedback is clear and directs the authors to enhance their analysis by including additional comparisons and data, which could significantly improve the comprehensiveness and depth of their results. However, the comment could be more helpful if it suggested specific works to compare with or provided guidance on how to present the additional data. Overall, the comment is 4 as it effectively guides the authors toward improving their draft by addressing a critical gap in their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a brief discussion on why fixing hallucinations is necessary, beyond merely pointing to existing work. While the comment implies that the authors should provide additional context or justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify the exact content or depth of the discussion that should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a brief discussion on why fixing hallucinations is necessary, beyond merely pointing to existing work. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in suggesting the need for additional context on the importance of addressing hallucinations. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including a brief discussion on why fixing hallucinations is necessary would be beneficial. However, it does not provide any specific reasoning, examples, or references to support why this discussion is important or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include a brief discussion on why fixing hallucinations is necessary, beyond merely pointing to existing work. This feedback is 3 as it identifies a potential gap in the paper and provides a direction for improvement. However, the comment lacks specificity on what aspects of the discussion should be included or how it should be structured, which limits its usefulness. To be more helpful, the comment could offer more detailed guidance or examples of what the authors might discuss. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the order of the terms mentioned in the paper, noting that terms like \"Type1 error,\" \"Type2 error,\" and \"false positive rate\" are mentioned before the null hypothesis is clearly stated. However, the comment does not provide any explicit or implicit action for the authors to take. It lacks guidance on how to address this issue, such as suggesting a reordering of the terms or providing a clearer explanation of the null hypothesis. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (5054) where the terms \"Type1 error,\" \"Type2 error,\" and \"false positive rate\" are mentioned before the null hypothesis is clearly stated. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the order of the terms and the need for a clearer statement of the null hypothesis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the order of terms mentioned in the paper, specifically noting that \"Type1 error,\" \"Type2 error,\" and \"false positive rate\" are mentioned before the null hypothesis is clearly stated. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a specific issue with the order of terms mentioned in the paper, noting that \"Type1 error,\" \"Type2 error,\" and \"false positive rate\" are mentioned before the null hypothesis is clearly stated. This feedback is 3 as it identifies a potential confusion or lack of clarity in the presentation of the material. However, the comment does not provide actionable suggestions or guidance on how to address this issue, such as recommending a reordering of the terms or a clearer explanation of the null hypothesis. While it highlights an area for improvement, the lack of detailed advice limits its usefulness to the authors. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential uncertainty inherent in estimating a continuous importance weight function, which could affect the model\"s reliability. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue. The comment poses a question but lacks actionable guidance or concrete steps for the authors to follow. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the potential uncertainty in estimating a continuous importance weight function, which could affect the model\"s reliability. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the potential issue but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the potential uncertainty in estimating a continuous importance weight function, which could affect the model\"s reliability. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. It merely poses a question without offering a detailed explanation or justification for why this issue might arise. Without additional context or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the estimation of a continuous importance weight function, which could introduce uncertainty and affect the model\"s reliability. It raises a valid concern about the impact of this uncertainty on the model\"s performance. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or mitigate the potential effects. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential problem but does not offer detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the performance of the SFAM scorers, which are fundamental components of the LISA embedding, and their correlation with human judgments on more linguisticsrelevant styles. The comment suggests that this discrepancy might make the LISA more contentfocused rather than stylefocused. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve the performance of the SFAM scorers. The action is implicit and vague, as the authors are left to infer that they should investigate and potentially improve the performance of the SFAM scorers to enhance the stylefocused aspect of the LISA. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the SFAM scorers, which are fundamental components of the LISA embedding, and the correlation with human judgments on more linguisticsrelevant styles. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issue of the SFAM scorers not correlating well with human judgments on linguisticsrelevant styles, suggesting that this might make the LISA more contentfocused rather than stylefocused. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the SFAM scorers, which are fundamental components of the LISA embedding, do not correlate well with human judgments on more linguisticsrelevant styles, such as simplification and linguistic acceptability. The comment provides a logical reasoning by contrasting the performance on semanticsrelevant styles (e.g., sentiment, emotion) with the less favorable results on linguisticsrelevant styles. This reasoning is based on a clear understanding of the LISA embedding and its components, which provides a solid foundation for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Overall, the claim is 4, as it provides a logical basis but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of the SFAM scorers, which are fundamental components of the LISA embedding. It highlights that these scorers do not correlate well with human judgments on more linguisticsrelevant styles, such as simplification and linguistic acceptability, while performing well on semanticsrelevant styles like sentiment and emotion. This observation suggests that the LISA might be more contentfocused rather than stylefocused. While the comment points out a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the performance of the SFAM scorers. The feedback is 3 as it directs the authors\" attention to a specific area for improvement, but it lacks actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiments should be evaluated on other realworld datasets, specifically mentioning DexYCB and more recent handobject pose estimation pipelines. This feedback provides a clear and explicit action for the authors to take, which is to include additional datasets and evaluation methods in their experiments. The suggestion is concrete, as it specifies the datasets and evaluation methods to consider, making it 5.", "grounding_specificity_rationale": "The comment suggests evaluating the experiments on other realworld datasets, specifically mentioning DexYCB and more recent handobject pose estimation pipelines. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results discussion. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of additional datasets and evaluation methods, which provides clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests evaluating the experiments on other realworld datasets, specifically mentioning DexYCB and more recent handobject pose estimation pipelines. This suggestion is based on a logical reasoning that additional datasets and evaluation methods could provide a more comprehensive assessment of the paper\"s findings. However, the comment lacks specific references or detailed justification for why these datasets or pipelines are particularly relevant or how they would enhance the evaluation. While the suggestion is reasonable, the lack of supporting evidence or detailed reasoning makes it 3, as the authors may need to further explore the rationale behind the suggestion.", "helpfulness_rationale": "The review comment suggests that the experiments should be evaluated on other realworld datasets, specifically mentioning DexYCB and more recent handobject pose estimation pipelines. This feedback is clear and actionable, as it provides a specific suggestion for improving the experimental evaluation of the paper. By including additional datasets and evaluation methods, the authors can enhance the robustness and generalizability of their results. However, the comment could be more helpful if it explained why these specific datasets or pipelines are relevant or how they would contribute to the study. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional context or rationale."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of explicit explanation regarding important components of the paper, such as the design of sequential models and how the attention model is updated. This feedback implies that the authors should provide more detailed explanations to enhance the reader\"s understanding of the proposed work. However, the comment does not specify which parts of the paper need these explanations or how to present them, leaving the authors with a vague idea of what needs to be addressed. While the action is implicit, it lacks concrete guidance on how to implement the suggested changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of explicit explanation regarding important components of the paper, such as the design of sequential models and how the attention model is updated. However, it does not specify which sections of the paper these components are discussed in, making it difficult for the authors to pinpoint the exact parts that need clarification. The comment is specific in identifying the areas that need more explanation, but it lacks grounding as it does not direct the authors to a particular section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks explicit explanation on important components, such as the design of sequential models and how the attention model is updated. This claim is 3 as it highlights a specific area where the paper could be improved by providing more detailed explanations. However, the comment does not provide specific examples or references to support the claim, which would strengthen the justification. The authors are left to infer the exact nature of the missing explanations, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting the lack of explicit explanation regarding important components such as the design of sequential models and how the attention model is updated. This feedback is valuable as it highlights a critical area that needs clarification to enhance the reader\"s understanding of the proposed work. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional explanations or examples. While it points out a key area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the entire code should be made accessible if the paper is accepted. This is an explicit action that provides clear guidance on what the authors should do to improve their draft. The comment is concrete because it specifies exactly what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment suggests that the entire code should be made accessible if the paper is accepted. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements of the paper, the authors may find it challenging to determine where this suggestion should be implemented. The comment is specific in its request for code accessibility but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the entire code should be made accessible if the paper is accepted. This is a request for additional information or resources, but it does not contain a claim or opinion that requires verification. It is a factual statement about the potential benefits of code accessibility, which does not need to be substantiated. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment suggests that the entire code should be made accessible if the paper is accepted. This is a clear and actionable piece of feedback that can significantly benefit the authors by providing a way to enhance the transparency and reproducibility of their work. By making the code accessible, the authors can address potential concerns about the methodology and allow others to replicate and build upon their findings. However, the comment could be more helpful if it provided additional context or rationale for why code accessibility is important or how it could enhance the paper. Overall, the suggestion is 4 as it offers a concrete step for improvement, but it could be more comprehensive with further explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the explanations of specific processes, such as spikedriven token selection and intra and interstage feature fusion, could be clearer. It implies that including pseudocode or flow diagrams might enhance the reader\"s understanding of the model\"s operation. While the comment provides a clear action to improve the clarity of the explanations, it does not specify how to implement this suggestion, such as which processes should be explained in more detail or how to incorporate pseudocode or flow diagrams. The action is explicit but somewhat vague, as the authors know they need to improve the clarity but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific processes, such as \"spikedriven token selection\" and \"intra and interstage feature fusion,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, namely the clarity of these processes, and suggests including pseudocode or flow diagrams to enhance understanding. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the explanations of specific processes, such as spikedriven token selection and intra and interstage feature fusion, could be clearer. The reviewer implies that including pseudocode or flow diagrams might enhance the reader\"s understanding of the model\"s operation. However, the comment lacks specific examples or detailed reasoning to support why these explanations are unclear or how the suggested improvements would benefit the reader\"s understanding. Without concrete evidence or examples, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the clarity of explanations for certain processes within the hybrid architecture. It suggests that including pseudocode or flow diagrams might enhance the reader\"s understanding of the model\"s operation. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and accessibility of the paper. However, the comment could be more helpful if it specified which processes need more detailed explanations or provided examples of how pseudocode or flow diagrams could be incorporated. Overall, the comment is 4 as it guides the authors toward enhancing the clarity and comprehensibility of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed method as an incremental improvement over AutoAugment, noting that the performance gains are not significant compared to recent methods. It also mentions that the standard deviation is large, which raises doubts about generalizability. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the concerns about performance or generalizability, or how to improve the method. Without actionable suggestions or specific directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed method as an incremental improvement over AutoAugment, noting that the performance gains are not significant compared to recent methods. It also mentions that the standard deviation is large, which raises doubts about generalizability. However, the comment does not specify which part of the paper discusses the proposed method or the comparison to recent methods, making it weakly grounded. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in its critique of the performance and generalizability, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the proposed method is an incremental improvement over AutoAugment and that the performance gains are not significant compared to recent methods. It supports this claim by providing specific numerical data, such as the 0.3 improvement over 18 on ImageNet using resnet50. Additionally, it mentions the large standard deviation, which raises doubts about generalizability. This level of detail and specific references provide a robust basis for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a critical evaluation of the proposed method, noting that it is an incremental improvement over AutoAugment and that the performance gains are not significant compared to recent methods. It specifically mentions that the standard deviation is large, which raises doubts about the method\"s generalizability. While the comment identifies a potential weakness in the method\"s performance and raises concerns about its applicability, it lacks actionable suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas for improvement, but it could be more beneficial with specific recommendations or examples of how to enhance the method\"s performance or generalizability. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the weakness of the comparison without referencing existing prior arts or mentioning significant performance gaps between the proposed method and latest methods. While it implies that the authors should include references to prior arts and address the performance gaps, the comment does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include references and address the performance gaps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the weakness of the comparison without referencing existing prior arts or mentioning significant performance gaps between the proposed method and latest methods. However, it does not specify which part of the paper this critique pertains to, such as a specific section or experiment. The authors can infer that it relates to the comparison or results sections, but this inference is not explicit. The comment is specific in pointing out the lack of references to prior arts and the performance gaps, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison is weak without referencing existing prior arts and highlights a significant performance gap between the proposed method and latest methods. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or references makes the claim 3, as the authors would need to invest effort to identify the gaps and references themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of comparison to existing prior arts and the absence of references to the latest methods. This feedback is important as it highlights the need for the authors to provide a more comprehensive context for their work by including references to relevant literature. However, the comment does not offer specific suggestions on how to address this issue or which prior arts or methods should be included. While it points out a critical area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should provide quantification of the diversity of the data gathered, noting that this is not difficult to do. It specifically recommends a \"shallow types vs. token statistic\" as a useful way to quantify diversity. This feedback is clear and provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of quantifying the diversity of the data gathered, suggesting that even a simple \"types vs. token statistic\" would be useful. However, it does not specify which part of the paper discusses the diversity of the data, making it weakly grounded. The comment is specific in suggesting a particular method for quantifying diversity, which is a clear indication of what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors argue for the diversity of the data but do not provide quantification, suggesting that even a simple \"types vs. token statistic\" would be useful. This claim is 3 as it highlights a potential gap in the paper regarding quantification of diversity. However, the comment lacks specific examples or references to support the claim that quantification is necessary or how it would enhance the paper. Providing more detailed reasoning or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of quantification of the diversity of the data gathered. It suggests that even a simple \"types vs. token statistic\" would be useful for quantifying this diversity. This feedback is clear and actionable, providing the authors with a concrete step to enhance their draft. However, the comment could be more helpful if it explained why quantification is important or how it would benefit the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or rationale."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of sufficient evidence to support the claim that the paper has created a more diverse set of positive (similar) instance pairs. It points out that there is no suggested measure of diversity and no comparison with earlier works regarding the diversity of examples. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue or suggest specific measures to include. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a measure of diversity and compare their work with earlier studies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a claim made in the paper regarding the creation of a more diverse set of positive (similar) instance pairs. It points out that this claim is not sufficiently backed up, as there is no suggested measure of diversity and no comparison with earlier works regarding the diversity of examples. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. It is specific in detailing what is missing, such as a measure of diversity and comparison with earlier works. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s assertion about creating a more diverse set of positive (similar) instance pairs is not sufficiently backed up. It points out the lack of a suggested measure of diversity and a comparison with earlier works regarding the diversity of examples. This critique is 3 as it highlights a gap in the paper\"s justification of its claim. However, it lacks specific examples or references to earlier works that could provide a more detailed basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper\"s claim about creating a more diverse set of positive (similar) instance pairs. It points out that the claim is not sufficiently backed up, as there is no suggested measure of diversity and no comparison with earlier works regarding the diversity of examples. This feedback is clear and actionable, as it highlights a specific area where the authors need to provide more detailed justification and evidence to support their claim. However, the comment could be more helpful if it suggested specific metrics or methods for measuring diversity or provided examples of how earlier works have addressed this issue. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the authors\" approach would compare to or work in line with other inputs, such as structured information, and mentions that AUCROC seems high in other models in literature. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should address this comparison, conduct additional experiments, or provide further context. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about how the authors\" approach would compare to or work in line with other inputs, such as structured information, and mentions that AUCROC seems high in other models in literature. However, it does not specify which part of the paper this question pertains to, nor does it provide specific guidance on how the authors should address this comparison. Without explicit references to sections or examples, the authors cannot confidently determine which part of the paper needs attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about how the authors\" approach would compare to or work in line with other inputs, such as structured information, and mentions that AUCROC seems high in other models in literature. However, the comment does not provide specific examples or references to support the claim about AUCROC being high in other models, nor does it offer a detailed explanation of how the authors\" approach might differ or align with these inputs. This lack of supporting evidence or detailed reasoning makes the claim 3, as the authors would need to infer the basis of the comparison and seek additional information to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about how the authors\" approach would compare to or work in line with other inputs, such as structured information, and mentions that AUCROC seems high in other models in literature. While it identifies a potential area for comparison or improvement, the comment lacks specificity and does not provide actionable guidance or suggestions for the authors to address this issue. It does not offer insights into how the authors might conduct such a comparison or what specific aspects of their approach could be improved to align with other inputs. As a result, the comment is 3, as it prompts the authors to consider a relevant comparison but does not fully support them in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take. It suggests stating the objective function in experiments, clarifying the inequality sign in Eq. 7, and improving the explanation of the training procedure in Section 4. These suggestions are clear and provide concrete steps for the authors to follow. The comment also offers a rationale for each suggestion, which further enhances its actionability. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 7\" and \"section 3 (mainly sec. 3.2)\" and \"section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as stating the objective function in experiments and clarifying the inequality sign in Eq. 7. The comment also suggests leaving more space in Section 4 to explain the training procedure, which is a specific and actionable recommendation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions, each requiring verification. The first claim about the objective function in experiments is supported by a request for clarification, which is a logical step to improve the paper. The second claim about the inequality sign in Eq. 7 is also supported by a suggestion for clarification. The third claim about the technical nature of Section 3 and the suggestion to focus on explaining the training procedure in Section 4 is a subjective opinion that lacks specific evidence or references. Overall, the comment provides a mix of verifiable and 1 claims, making it 3. Therefore, the score is 3.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper. It explicitly requests the authors to state the objective function in experiments, which would help clarify the methodology. It also points out a potential error in Eq. 7 regarding the inequality sign and suggests clarifying the gap definition. Additionally, the comment highlights a perceived issue with the technical nature of Section 3, suggesting that more space in Section 4 could be dedicated to explaining the training procedure. While the comment offers valuable insights, it could be more helpful by providing specific examples or further elaboration on how to improve the clarity of Section 3. Overall, the feedback is 4 as it guides the authors toward enhancing the clarity and accessibility of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly questions the reason for the decrease in the Disc. reward for SPACE and fPCPO in the Grid (Fig. 3, top right plot). It clearly states that this should be explained, providing a direct action for the authors to take. The comment is specific and leaves no ambiguity about what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 3, top right plot,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it questions the reason for the decrease in the Disc. reward for SPACE and fPCPO in the Grid, and it clearly specifies that this should be explained. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the decrease in the Disc. reward for SPACE and fPCPO in the Grid (Fig. 3, top right plot) and requests an explanation. However, it does not provide any supporting evidence, reasoning, or references to justify why this decrease should be explained. The comment lacks specific details or examples that would help the authors understand the basis of the question or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, questioning the decrease in the Disc. reward for SPACE and fPCPO in the Grid (Fig. 3, top right plot). It explicitly requests an explanation for this observation, which is a clear and actionable piece of feedback. By addressing this point, the authors can enhance the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to explain the decrease. Overall, the feedback is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing aspect in the paper, specifically the resolutions at which images successfully achieve adversarial effects. While it identifies a gap in the information provided, it does not explicitly instruct the authors to include this detail or provide guidance on how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to add this information but may not be entirely sure of the exact format or level of detail required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the missing implementation details, specifically the resolutions at which images successfully achieve adversarial effects. However, it does not specify which part of the paper this information should be included in, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the missing information, which is the resolutions at which adversarial effects are achieved. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that key implementation details are missing, specifically the resolutions at which images successfully achieve adversarial effects. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these details are crucial or how their absence impacts the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting the absence of key implementation details regarding the resolutions at which images successfully achieve adversarial effects. This feedback is clear and actionable, as it directs the authors to include this information, which is crucial for understanding the experimental setup and results. However, the comment could be more helpful if it provided suggestions on how to present or discuss these details effectively. Overall, the comment is 4 as it points out a critical omission and guides the authors toward improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that while the current approach using DDIM Inversion for data preprocessing is effective in reducing training time, it does not significantly simplify the overall complexity. The reviewer recommends exploring improvements to the motion guidance strategy itself to enhance training efficiency. This feedback is explicit in suggesting a specific area for improvement, namely the motion guidance strategy, and provides a clear direction for the authors to consider. However, it does not offer concrete steps or detailed guidance on how to implement these improvements. While the action is explicit, the lack of detailed instructions makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"section on data preprocessing,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the current approach, which involves using DDIM Inversion to obtain motion guidance, and suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that while the approach using DDIM Inversion for data preprocessing is effective in reducing training time, it does not significantly simplify the overall complexity. The reviewer suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the current approach does not simplify complexity. Without these elements, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the data preprocessing approach, noting that while it effectively reduces training time, it does not significantly simplify the overall complexity. The reviewer suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. This feedback is clear and actionable, providing the authors with a specific area for improvement and a direction to enhance their work. However, the comment could be more helpful if it offered specific suggestions or examples of how to improve the motion guidance strategy. Overall, the comment is 4 as it directs the authors to a critical area for enhancement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the statistics of relation phrases and the frequency of predicting rarer relation phrases in sentences. It also mentions a potential disadvantage of chunking things into relation phrases, which could lead to the problem of heavy tails in relations. However, the comment does not provide explicit instructions or suggestions for how the authors should address these issues or improve their draft. The questions are implicit and lack concrete guidance on what actions the authors should take to resolve the concerns. As a result, the comment is barely actionable, as it highlights areas for improvement but does not offer specific steps for the authors to follow.", "grounding_specificity_rationale": "The comment raises questions about the statistics of relation phrases and the frequency of predicting rarer relation phrases in sentences. It also mentions a potential disadvantage of chunking things into relation phrases, which could lead to the problem of heavy tails in relations. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing the concerns about relation phrases and their potential disadvantages, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises questions about the statistics of relation phrases and the frequency of predicting rarer relation phrases in sentences. It also mentions a potential disadvantage of chunking things into relation phrases, which could lead to the problem of heavy tails in relations. However, the comment does not provide specific examples, data, or references to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed evidence or reasoning makes the claim 3, as it requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment raises important questions about the statistics of relation phrases and the frequency of predicting rarer relation phrases in sentences. It also points out a potential disadvantage of chunking things into relation phrases, which could lead to the problem of heavy tails in relations. While the comment identifies areas for improvement and potential issues, it lacks specific suggestions or guidance on how the authors might address these concerns. The feedback is 3 as it prompts the authors to consider these aspects, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment acknowledges that the statement about robustness in dynamic regions is generally true but points out that there are edge cases that require more robust approaches. It provides a specific example from the Bonn dataset, where moving objects like humans can occupy over 50% of the image. The comment suggests potential solutions, such as masking out dynamic regions using segmentation masks or rerunning relative pose estimation after identifying dynamic regions. This feedback is explicit and provides concrete suggestions for addressing the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement \"For most scenes, where most pixels are static, random samples of points will place more emphasis on the static elements,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of edge cases requiring more robust approaches and provides a concrete example from the Bonn dataset, where moving objects like humans can occupy over 50% of the image. The comment further suggests potential solutions, such as masking out dynamic regions or rerunning relative pose estimation. This level of detail and specificity provides clear guidance for the authors on how to address the issue, making the comment 5.", "verifiability_rationale": "The review point acknowledges that the statement about robustness in dynamic regions is generally true but points out that there are edge cases that require more robust approaches. It provides a specific example from the Bonn dataset, where moving objects like humans can occupy over 50% of the image. The comment suggests potential solutions, such as masking out dynamic regions or rerunning relative pose estimation after identifying dynamic regions. This level of detail and specific examples provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by referencing additional literature or studies that support the need for more robust approaches in dynamic regions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges that the statement about robustness in dynamic regions is generally true but points out that there are edge cases that require more robust approaches. It provides a specific example from the Bonn dataset, where moving objects like humans can occupy over 50% of the image. The comment suggests potential solutions, such as masking out dynamic regions using segmentation masks or rerunning relative pose estimation after identifying dynamic regions. This feedback is actionable and provides clear guidance on how to address the issue, making it 5 for the authors. The comment is specific and offers concrete suggestions for improvement, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparison between the authors\" models and other methods in the experiments. While it identifies a specific area for improvement, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete details on which other methods should be included in the comparison or how to incorporate them into the experiments. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue with the experiments, noting that they only focus on comparing various models proposed by the authors and lack comparison with other methods. However, it does not specify which part of the paper this issue pertains to, such as which sections or experiments are affected. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the lack of comparison with other methods, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments only focus on comparing various models proposed by the authors and lack comparison with other methods. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without specific references or detailed explanations, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiments, noting that they only focus on comparing various models proposed by the authors and lack comparison with other methods. This feedback is 3 as it points out a limitation in the experimental design, prompting the authors to consider including comparisons with other methods to enhance the validity and comprehensiveness of their results. However, the comment lacks depth and does not provide specific suggestions or examples of alternative methods that could be included in the comparison. To be more helpful, the comment could offer guidance on how to incorporate these comparisons or suggest relevant methods to consider. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a minor inconsistency in the labeling of models in Tables 3 and 4, noting that the models considered math specialists are marked with an asterisk, but the MAVIS models are not. The reviewer suggests that the MAVIS models should also be considered math specialists and should be marked accordingly. While the comment identifies a specific issue and provides a clear suggestion for improvement, it does not explicitly instruct the authors to make the change. The action is implicit but concrete, as the authors can infer that they need to add the asterisk to the MAVIS models. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a particular inconsistency in the labeling of models, suggesting that the MAVIS models should also be considered math specialists and should be marked accordingly. This provides clear guidance on what needs to be addressed in the tables. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the labeling of models in Tables 3 and 4, noting that the models considered math specialists are marked with an asterisk, but the MAVIS models are not. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a minor inconsistency in the labeling of models in Tables 3 and 4, noting that the models considered math specialists are marked with an asterisk, but the MAVIS models are not. The reviewer suggests that the MAVIS models should also be considered math specialists and should be marked accordingly. While this feedback is specific and identifies a clear area for improvement, it does not provide any additional context or suggestions on why this inconsistency matters or how it might impact the interpretation of the results. The comment is 3 as it directs the authors to a specific issue that needs attention, but it could be more helpful with further elaboration or guidance on the significance of this labeling inconsistency. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the technical novelty of the work, stating that the KNNbased methods are widely studied in LM and MT. It suggests that the work provides few insights into nonparametric methods for text classification. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might enhance the novelty or provide more insights, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical novelty of the work, specifically mentioning the use of KNNbased methods in LM and MT. However, it does not specify which part of the paper discusses these methods or where the lack of novelty is evident. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the lack of novelty but lacks grounding as it does not explicitly mention a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical novelty is limited, specifically mentioning that KNNbased methods are widely studied in LM and MT. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the assertion. Without additional context or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment critiques the technical novelty of the work, specifically noting that KNNbased methods are widely studied in LM and MT. It suggests that the work provides few insights into nonparametric methods for text classification. However, the comment lacks specificity and actionable feedback, as it does not provide guidance on how the authors might enhance the novelty or provide more insights. Without detailed suggestions or examples, the authors are left without a clear understanding of what changes or additions could be made to improve the draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential overstatement in the paper regarding the enhancement of the IM for most existing RL algorithms. It suggests that the paper lacks a comparison with the latest work, particularly nonpixelbased approaches to solving data efficiency. While the comment implies that the authors should update their comparison to include more recent work, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should update their comparison and identify the latest work to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"extensive enhancement of the IM for most existing RL algorithms\" and the \"most recent description of the mainstream RL algorithms in related work,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper lacks a comparison with the latest work, particularly nonpixelbased approaches to solving data efficiency. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper overstates the enhancement of the IM for most existing RL algorithms, noting that the most recent description of mainstream RL algorithms in related work is SAC from 2018. The comment suggests that the paper lacks a comparison with the latest work, particularly nonpixelbased approaches to solving data efficiency. While the claim highlights a potential issue, it lacks specific examples or references to recent work that could support the assertion. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential overstatement in the paper regarding the enhancement of the IM for most existing RL algorithms. It points out that the most recent description of mainstream RL algorithms in related work is SAC from 2018, suggesting that the paper lacks a comparison with the latest work, particularly nonpixelbased approaches to solving data efficiency. This feedback is 3 as it highlights a specific area where the paper may be overstating its claims and provides a direction for improvement by suggesting a comparison with more recent work. However, the comment could be more helpful if it offered specific examples of recent work or detailed guidance on how to incorporate these comparisons into the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should expand the background discussion in Section 2 by including further background knowledge on adversarial examples and threat models. It also recommends referencing relevant surveys to clarify the threat model and position at the stateoftheart (SoA). This feedback provides clear and concrete actions for the authors to take, such as expanding the background discussion and referencing specific surveys. The guidance is explicit and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2\" and \"the background discussion,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely expanding the background discussion with further knowledge on adversarial examples and threat models, and referencing relevant surveys to clarify the threat model and position at the stateoftheart. This level of detail helps the authors understand exactly what changes are needed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests expanding the background discussion on adversarial examples and threat models, specifically mentioning whitebox, greybox, and blackbox threat models. The comment provides a clear direction for improvement by recommending references to relevant surveys that could help clarify the threat model and position at the stateoftheart. This guidance is logical and provides a specific suggestion for enhancing the paper, making the claim 4. However, the comment could be strengthened by including specific references to the surveys or examples of how these references would enhance the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors expand the background discussion in Section 2 to include further knowledge on adversarial examples and threat models, particularly whitebox, greybox, and blackbox threat models. It also recommends referencing relevant surveys to clarify the threat model and position at the stateoftheart, which would help nonexpert readers understand these distinctions. This feedback is clear and offers concrete steps for the authors to enhance the comprehensiveness and clarity of their paper. By following this advice, the authors can improve the depth and accessibility of their work, making the comment 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of how the proposed multiplespan answer setting is essential in realworld applications. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify or demonstrate the importance of this setting in realworld applications, leaving the authors without a clear path for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of how the proposed multiplespan answer setting is essential in realworld applications. However, it does not specify which part of the paper this issue pertains to, such as a specific section or discussion where this aspect is addressed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what aspects of the multiplespan answer setting are unclear or how they could be clarified. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a lack of clarity regarding the importance of the proposed multiplespan answer setting in realworld applications. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the reviewer\"s concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how the proposed multiplespan answer setting is essential in realworld applications. This is a relevant observation that could help the authors improve their draft by clarifying the practical significance of their approach. However, the comment lacks depth and does not provide specific suggestions or examples on how the authors might address this issue. While it points out a potential weakness, it does not offer actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the use of \"Testsets\" and suggests mixing in train set examples with hypernyms and nonhypernyms. However, it does not provide any explicit instructions or suggestions on how the authors should address this issue. The comment lacks concrete details on what changes should be made or how the mixing should be implemented. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sections \"558\" and \"574ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the use of \"Testsets\" and suggesting a potential improvement by mixing in train set examples with hypernyms and nonhypernyms. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the use of \"Testsets\" and suggests mixing in train set examples with hypernyms and nonhypernyms. However, it does not provide any supporting evidence, reasoning, or references to justify why this suggestion would be beneficial or necessary. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the use of \"Testsets\" and suggests mixing in train set examples with hypernyms and nonhypernyms. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or reasoning on why this suggestion would enhance the paper. The comment does not offer actionable advice or detailed explanations, leaving the authors with only a vague idea of what could be improved. Therefore, the comment is 2, as it provides limited value for the authors in terms of improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the authors to provide results for the AdpCLR_full approach for the ResNet50 (1x, 2x, 4x) architecture, similar to the results provided for AdpCLR_pre in Table 1. This request is clear and direct, leaving no ambiguity about what the authors need to do to address the comment. The action is concrete, as it specifies the exact results to be included, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 1\" and \"AdpCLR_pre,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is missing, namely the results for the AdpCLR_full approach for the ResNet50 (1x, 2x, 4x) architecture. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional results to be included in the paper, specifically asking for the results of the AdpCLR_full approach for the ResNet50 (1x, 2x, 4x) architecture. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is clear and specific, requesting the authors to provide results for the AdpCLR_full approach for the ResNet50 (1x, 2x, 4x) architecture, similar to the results provided for AdpCLR_pre in Table 1. This feedback is actionable and provides a clear direction for the authors to enhance their draft by including additional results. However, the comment could be more helpful if it explained why these results are important or how they might impact the paper\"s conclusions. Overall, the comment is 4 as it guides the authors to improve their draft by addressing a specific gap in the presented results."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the similarity between N trajectories and the concept of replay in the Dyna model. However, it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this question or what implications it might have for their work. Without any actionable steps or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the similarity between N trajectories and the concept of replay in the Dyna model. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion where this concept is introduced. Without explicit references or context, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspect of the similarity needs clarification or why it is relevant to the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the similarity between N trajectories and the concept of replay in the Dyna model. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the similarity between N trajectories and the concept of replay in the Dyna model. While it highlights a potential area of confusion or misunderstanding, it does not provide any actionable feedback or suggestions for the authors to address this issue. The comment lacks depth and does not offer guidance on how the authors might clarify or resolve this point in their paper. As a result, it provides minimal value to the authors in terms of improving their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the suspicious nature of some experiment results, specifically mentioning that Tables 16 and 17 share the same result despite changing the 2hop EG into 3hop EG. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific actions they should take to resolve the concern. The comment lacks actionable details, such as suggesting ways to verify or explain the results, or recommending alternative analyses. As a result, the authors are left without a clear understanding of how to proceed, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 16 and 17,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It also specifies the issue by pointing out that the results in these tables are suspicious, particularly regarding the shared result despite changing the 2hop EG into 3hop EG. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some experiment results are suspicious, specifically mentioning that Tables 16 and 17 share the same result despite changing the 2hop EG into 3hop EG. However, the comment does not provide any further explanation, reasoning, or examples to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suspicion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the suspicious nature of some experiment results, specifically pointing out that Tables 16 and 17 share the same result despite changing the 2hop EG into 3hop EG. This observation is relevant and could indicate a potential issue with the experimental setup or analysis. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might investigate or address this concern. Without actionable feedback or additional context, the authors are left with a vague indication of a problem but without a clear path to resolution. Therefore, the comment is 3, as it identifies an area of concern but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that the experimental results show some advantages of the proposed algorithms but notes that these advantages are not very significant. It also mentions that the proposed algorithms are still competitive with stateoftheart algorithms. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to enhance the significance of the results or improve the competitiveness with stateoftheart algorithms. Without actionable suggestions or specific feedback, the authors are left without a clear understanding of what steps to take to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to the experimental results, suggesting that they show some advantages of the proposed algorithms but that these advantages are not very significant. It also mentions that the proposed algorithms are still competitive with stateoftheart algorithms. However, the comment does not specify which experimental results or sections of the paper are being discussed, making it difficult for the authors to pinpoint the exact parts that need attention. Additionally, while it provides some insight into the perceived significance of the results, it lacks specificity in terms of what aspects of the results need improvement or how to address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental results show some advantages of the proposed algorithms, but these advantages are not very significant. It also mentions that the proposed algorithms are still competitive with stateoftheart algorithms. However, the comment lacks specific examples or detailed reasoning to support the claim about the lack of significance. Without concrete evidence or references to compare the results with other algorithms, the claim remains somewhat vague. Therefore, the comment is classified as 3, as it provides some justification but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges that the experimental results show some advantages of the proposed algorithms but notes that these advantages are not very significant. It also mentions that the proposed algorithms are still competitive with stateoftheart algorithms. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance on how to enhance the significance of the results or make the algorithms more competitive, the authors are left without a clear understanding of what steps to take to address the issues raised. Therefore, the comment is 1, as it does not offer any actionable insights or constructive feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the persentence assessment protocol, suggesting that it may be prone to overconfidence in the LLM\"s predictions. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address or mitigate the issue of overconfidence, nor are there suggestions for alternative methods or improvements. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the \"persentence assessment protocol\" and mentions a potential issue with overconfidence in the LLM\"s predictions. However, it does not specify which part of the paper discusses this protocol, making it weakly grounded. The comment is specific in detailing the issue of overconfidence, but without explicit references to sections or examples, the authors may find it challenging to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the persentence assessment protocol may be prone to overconfidence in the LLM\"s predictions, suggesting that the LLM prefers its predictions even if they are incorrect. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the persentence assessment protocol, suggesting that it may be prone to overconfidence in the LLM\"s predictions. This is a relevant observation that could impact the reliability and accuracy of the protocol. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or improve the protocol. Without detailed feedback or recommendations, the authors are left with a general understanding of the problem but without a clear path to resolution. Therefore, the comment is 3, as it highlights a potential concern but does not fully support the authors in making improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the significance of the experimental results, asking whether they are due to the superiority of the method or an accidental result from a specific kernel function and feature map. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to investigate or address this question, nor are there suggestions for further analysis or experimentation. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a question about the significance of the experimental results, specifically whether they are due to the superiority of the method or an accidental result from a specific kernel function and feature map. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. Without explicit references to specific sections or experiments, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors might investigate this question. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the significance of the experimental results, asking whether they are due to the superiority of the method or an accidental result from a specific kernel function and feature map. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or analysis, the authors may find it challenging to address the question effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the significance of the experimental results, questioning whether they are due to the superiority of the method or an accidental result from a specific kernel function and feature map. This is an important point that the authors need to address to ensure the validity and robustness of their findings. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might investigate or address this question. Without actionable feedback or detailed advice, the authors are left with a vague understanding of what needs to be clarified or improved. Therefore, the comment is 3, as it identifies a potential issue but does not fully support the authors in resolving it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed method is complex, involving modified GromovHausdorff distances and hypergraph structures, which likely increases time complexity. It acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B. However, the comment suggests that a discussion of the computational costs associated with training would be beneficial. While the comment implies that the authors should include a discussion on training costs, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the complexity of the method, involving modified GromovHausdorff distances and hypergraph structures, and the potential increase in time complexity. The comment further suggests that a discussion of the computational costs associated with training would be beneficial. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method is complex, involving modified GromovHausdorff distances and hypergraph structures, which likely increases time complexity. The reviewer acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B. However, the comment suggests that a discussion of the computational costs associated with training would be beneficial. This claim is 3 as it provides a logical reasoning for the complexity and references the theoretical analysis in Appendix B. However, it lacks specific examples or detailed calculations to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the complexity of the proposed method, noting that it involves modified GromovHausdorff distances and hypergraph structures, which could increase time complexity. It acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B. However, the comment suggests that a discussion of the computational costs associated with training would be beneficial. This feedback is clear and actionable, as it points out an area for improvement and provides a specific suggestion for enhancing the paper. By addressing the computational costs, the authors can provide a more comprehensive analysis of the method\"s efficiency, which is valuable for readers and reviewers. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed method may not represent a groundbreaking innovation within the field and lacks distinction from existing contrastive decoding techniques. However, it does not provide specific guidance on how the authors could address this issue or improve the clarity of their contributions. The comment implies that the authors should better articulate the uniqueness and advantages of their approach, but it does not offer concrete steps or suggestions on how to achieve this. As a result, the action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s contribution to the field of LLMs, specifically questioning the groundbreaking nature of the proposed method and its distinction from existing contrastive decoding techniques. However, it does not specify which part of the paper discusses the proposed method or where the lack of distinction is evident. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some insight into the critique, it lacks specificity and grounding, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method may not represent a groundbreaking innovation within the field and lacks distinction from existing contrastive decoding techniques. However, the comment does not provide specific examples or references to existing work that the proposed method builds upon or fails to distinguish itself from. This lack of detailed evidence or comparison makes it difficult for the authors to understand the basis of the critique and address it effectively. As a result, the claim is considered 2, as it provides some insight but lacks sufficient support for the authors to fully understand and respond to the critique.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the proposed method may not represent a groundbreaking innovation within the field of LLMs. It points out that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, leaving readers without a clear understanding of the unique contributions and advantages of the new approach. This feedback is 3 as it highlights an area where the paper could be improved by better articulating its originality and differentiation from existing work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing ways to highlight the novelty or providing examples of how the method differs from existing techniques. Therefore, while it points out a relevant concern, it does not offer detailed actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the tabular representation of node agent interactions in Figure 4 is not intuitive. However, it does not provide any explicit or implicit suggestions on how to improve the figure or make it more intuitive. The authors are left without guidance on what changes to make or how to enhance the figure\"s clarity. Without actionable advice or concrete steps, the comment lacks utility for the authors in improving their draft. Therefore, it is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the tabular representation of node agent interactions, indicating that it is not intuitive. This provides clear guidance on what needs to be addressed to improve the figure\"s clarity. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the tabular representation of node agent interactions in Figure 4 is not intuitive. However, it does not provide any supporting evidence, reasoning, or examples to justify why this representation is problematic or how it could be improved. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment identifies a specific issue with the tabular representation of node agent interactions in Figure 4, noting that it is not intuitive. However, it does not provide any suggestions or guidance on how to improve the figure\"s clarity or make it more intuitive. Without actionable feedback or examples of how to enhance the figure, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the appropriateness of using PU (Positive Unlabeled) frameworks as baselines and suggests considering noiseaware losses. It also inquires about the impact of the PU loss on calibration and uncertainty estimation for downstream use cases of AI text detectors. While the comment implies that the authors should consider alternative frameworks and explore the impact of the PU loss, it does not provide explicit instructions or concrete steps on how to address these questions or conduct the necessary analyses. The actions are implicit and somewhat vague, leaving the authors with a general direction but without detailed guidance on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the appropriateness of using PU frameworks as baselines and suggests considering noiseaware losses. It also inquires about the impact of the PU loss on calibration and uncertainty estimation for downstream use cases of AI text detectors. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in its questions and suggestions, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises questions about the appropriateness of using PU frameworks as baselines and suggests considering noiseaware losses. It also inquires about the impact of the PU loss on calibration and uncertainty estimation for downstream use cases of AI text detectors. While the comment provides some logical reasoning by questioning the choice of baselines and the impact on calibration, it lacks specific examples or references to support these claims. The lack of detailed evidence or references makes the claims 3, as the authors would need to further explore and substantiate the points themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the appropriateness of using PU frameworks as baselines and suggests considering noiseaware losses as alternatives. It also inquires about the impact of the PU loss on calibration and uncertainty estimation, which are crucial for downstream use cases of AI text detectors. While the comment identifies potential areas for improvement and provides some direction, it lacks specific suggestions or detailed guidance on how to address these questions or conduct the necessary analyses. The feedback is 3 as it prompts the authors to consider alternative frameworks and explore the impact of their choice on calibration and uncertainty estimation, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a disagreement with the characterization of Transfer Learning (TL) and Finetuning (FT) as sequential MTL. It clarifies that TL is a broader term for the phenomenon of learning from one task benefiting another task, while finetuning is a sequential way of doing it. The comment also mentions that standard MTL is a parallel means to the same end. However, it does not provide any explicit or implicit actions for the authors to take, such as suggesting a recharacterization or clarification in the paper. The comment lacks actionable guidance, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the characterization of Transfer Learning (TL) and Finetuning (FT) as sequential MTL in the introduction. It provides a clear explanation of the difference between TL and FT, which helps the authors understand the issue. However, the comment does not explicitly mention which part of the introduction this characterization is found in, making it weakly grounded. The comment is specific in detailing the issue with the characterization, but without explicit references to the introduction, the authors may find it challenging to pinpoint the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction describes Transfer Learning (TL) and Finetuning (FT) as sequential MTL, but the reviewer does not agree with this characterization. The comment provides a clear explanation of the difference between TL and FT, stating that TL is a broader term for the phenomenon of learning from one task benefiting another task, while finetuning is a sequential way of doing it. This reasoning is logical and provides a clear distinction, making the claim 4. However, the comment could be strengthened by referencing specific sections of the paper where this characterization is made, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential mischaracterization in the introduction, where Transfer Learning (TL) and Finetuning (FT) are described as sequential MultiTask Learning (MTL). The reviewer clarifies that TL is a broader term for the phenomenon of learning from one task benefiting another task, while finetuning is a sequential way of doing it. Additionally, the comment points out that standard MTL is a parallel means to the same end. This feedback is valuable as it corrects a misunderstanding and provides a more accurate understanding of the concepts, which could help the authors improve the clarity and accuracy of their introduction. However, the comment could be more helpful if it suggested how to rephrase or clarify the description in the paper. Overall, the comment is 3 as it identifies a critical issue but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the paper lacks a Limitation section, which is considered important. However, it does not provide any guidance or suggestions on how the authors should address this issue or what specific limitations should be included. The action is explicit but lacks concrete details on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment indicates that the paper lacks a Limitation section, which is considered important. However, it does not specify which part of the paper this absence is noticed in, nor does it provide details on what specific limitations should be included. Without explicit references to sections or examples, the authors cannot confidently determine where to address this issue. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks a Limitation section, which is considered important. However, the comment does not provide any reasoning, examples, or references to support why this section is crucial or how its absence affects the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment identifies a significant omission in the paper, namely the absence of a Limitation section. This is an important aspect of any research paper, as it helps readers understand the limitations of the work and its applicability. However, the comment does not provide any guidance or suggestions on what specific limitations should be included or how the authors might address this issue. While it highlights a critical area for improvement, the lack of actionable advice makes the feedback 3, as it points out a significant gap but does not fully support the authors in addressing it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point provides a list of specific sections that need improvement, including more detailed explanations in Section 2.1, a better explanation of CLIP guidance in Section 2.2, and a clearer explanation of the works of Choi et al. (2021) and Meng et al. (2021) in Section 3.2. It also mentions that captions of figures are often not explanatory, specifically mentioning Figures 3, 4, 7, and 8. While the comment identifies areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific details should be included. The authors can infer that they need to provide more detailed explanations, but the comment lacks concrete suggestions on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, including Section 2.1, 2.2, and 3.2, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the need for more detailed explanations in Section 2.1, the lack of explanation for CLIP guidance in Section 2.2, and the need to explain the works of Choi et al. (2021) and Meng et al. (2021) in Section 3.2. Additionally, it points out that captions of figures are often not explanatory, specifically mentioning Figures 3, 4, 7, and 8. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions, each of which requires verification. The first claim about Section 2.1 suggests that the theory behind diffusion models needs more detailed explanations, but it does not provide specific examples or reasoning to support this claim. The second claim about Section 2.2 mentions the need for better explanation of CLIP guidance, but again lacks detailed justification. The third claim about Section 3.2 points out the lack of explanation for the works of Choi et al. (2021) and Meng et al. (2021), but does not elaborate on why this is important or how it affects the paper. The final claim about figure captions is a suggestion for improvement, but it does not provide specific examples or reasoning to support the need for more explanatory captions. Overall, the review point contains multiple claims and suggestions that are not fully supported, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying several areas that need improvement in the paper. It highlights the need for more detailed explanations in Section 2.1 regarding the theory behind diffusion models, suggests better explanations of CLIP guidance in Section 2.2, and points out the lack of explanation for the works of Choi et al. (2021) and Meng et al. (2021) in Section 3.2. Additionally, it notes that captions of figures are often not explanatory, specifically mentioning Figures 3, 4, 7, and 8. This feedback is clear and provides the authors with concrete areas to address, making it 4. However, the comment could be more comprehensive by offering specific suggestions on how to improve the explanations or by providing examples of what would constitute a better explanation. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include the term \"tensor completion\" in the title, as it is the only application of the new model presented in the paper. This is a clear and direct action, providing the authors with a specific and concrete step to take. The comment leaves no ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the title, namely the term \"tensor completion,\" which is the only application of the new model presented in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the title should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. This claim is based on a logical reasoning that the title should accurately reflect the content of the paper. However, the comment lacks specific examples or references to support why \"tensor completion\" is the only relevant application, making it 3. The authors would need to infer the importance of this application and its relevance to the title. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the title of the paper. It identifies a specific aspect that could be included to better reflect the content of the paper, namely the term \"tensor completion,\" which is the only application of the new model presented. This feedback is valuable as it directly guides the authors on how to enhance the clarity and relevance of their title. However, the comment could be more helpful if it explained why including \"tensor completion\" is important or how it aligns with the paper\"s contributions. Overall, the comment is 4 as it offers a concrete improvement that the authors can implement to enhance the title\"s accuracy and relevance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should implement a simple baseline and compare it to their proposed method to make the paper more persuasive. While the comment explicitly states the need for a comparison, it does not provide specific guidance on how to implement this comparison or what specific baseline to use. The action is explicit but somewhat vague, as the authors know they need to compare their method to a baseline but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of comparison to other prior methods and suggests implementing a simple baseline for comparison. However, it does not specify which part of the paper this critique pertains to, such as a specific section or analysis, making it weakly grounded. The comment is specific in suggesting the need for a comparison and proposing a simple baseline, but without clear grounding, the authors may find it challenging to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to other prior methods, which is considered a subjective opinion. The reviewer suggests that implementing a simple baseline and comparing it to the proposed method would make the paper more persuasive. However, the comment does not provide specific examples of prior methods or baselines that could be used for comparison, nor does it offer detailed reasoning or references to support the claim that such comparisons are necessary. This lack of detailed justification or examples makes the claim 3, as the authors would need to infer the importance of comparisons based on the general suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, namely the lack of comparison to other prior methods. It suggests that the authors should implement a simple baseline and compare it to their proposed method to make the paper more persuasive. This feedback is clear and actionable, providing the authors with a specific direction for improving the empirical evaluation of their work. By addressing this critique, the authors can enhance the robustness and persuasiveness of their findings. However, the comment could be more helpful if it offered examples of potential baselines or comparisons to guide the authors further. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a clear path forward."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method in reducing computational load in real applications. It suggests that the method may face challenges due to the activation of different channels for different tokens, which could make it difficult to apply a uniform activation pattern across all tokens. The comment also notes that the reliance on precomputed PPL and activation patterns may not generalize well to other tokens, potentially requiring all tokens to activate all channels. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the method\"s practicality. The action is implicit and somewhat vague, as the authors are left to infer what steps might be taken to resolve the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a potential limitation of the proposed method in reducing computational load in real applications. It highlights a specific issue related to the activation of different channels for different tokens, which could make it difficult to apply a uniform activation pattern across all tokens. The comment also mentions the reliance on precomputed PPL and activation patterns, suggesting that these patterns may not generalize well to other tokens. However, the comment does not explicitly mention which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in detailing the issue with the method\"s practicality, but the lack of explicit grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method may face challenges in reducing computational load in real applications due to the activation of different channels for different tokens. It provides a logical reasoning by explaining that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens. The comment also suggests that in extreme cases, all tokens might need to activate all channels to achieve their unique activation pattern, negating the intended efficiency gains. While the reasoning is logical, it lacks specific examples or references to support the claim fully. Therefore, the comment is 3, as it provides a logical basis for the claim but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method in reducing computational load in real applications. It highlights a specific issue related to the activation of different channels for different tokens, which could make it difficult to apply a uniform activation pattern across all tokens. The comment also notes that the reliance on precomputed PPL and activation patterns may not generalize well to other tokens, potentially requiring all tokens to activate all channels. While the comment effectively points out a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this limitation or enhance the method\"s practicality. Providing such guidance would make the feedback more actionable and helpful. Therefore, the comment is 3, as it highlights an important issue but does not fully support the authors in resolving it."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the core motivation of the paper is not clear, specifically mentioning the abstract\"s statement about \"it is hard to demarcate task boundaries in actual tasks\" and the proposal of a new benchmark, metrics, and gating technique. However, the comment does not provide explicit guidance on how to clarify the core motivation or improve the clarity of the paper. While it identifies an issue, it lacks actionable advice on how to address it, leaving the authors uncertain about what steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the core motivation of the paper, specifically mentioning the abstract\"s statement about \"it is hard to demarcate task boundaries in actual tasks\" and the proposal of a new benchmark, metrics, and gating technique. This provides full grounding as it explicitly references the abstract, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the clarity of the core motivation and the need for more concise statements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the core motivation of the paper is not clear, specifically critiquing the abstract for making \"stacked statements\" that do not effectively capture the main problem. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed justification or examples makes the claim 3, as it requires more information to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s core motivation, noting that the abstract makes \"stacked statements\" that do not effectively capture the main problem. This feedback is valuable as it highlights a fundamental weakness in the paper\"s clarity and structure. However, the comment does not provide specific suggestions or guidance on how to improve the clarity of the core motivation or restructure the abstract to better convey the paper\"s focus. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the sequence inference classifier used to filter data and questions the type of data that passes this filter. It suggests that the task of filtering data using the task description is different from the original MNLI distribution and recommends providing examples of the filtered data to clarify this issue. While the comment implies that the authors should provide examples of the filtered data, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer what needs to be done but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"sequence inference classifier\" and the \"task of filtering data using the task description,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the type of data that passes the filter and suggesting that examples of the filtered data would be helpful. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the sequence inference classifier used to filter data, questioning the type of data that passes this filter. The reviewer suggests that the task of filtering data using the task description is different from the original MNLI distribution and recommends providing examples of the filtered data. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to provide examples is a logical step, but the comment itself is somewhat vague in its current form. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment raises a specific concern about the sequence inference classifier used to filter data, questioning the type of data that passes this filter. It suggests that the task of filtering data using the task description is different from the original MNLI distribution and recommends providing examples of the filtered data to clarify this issue. This feedback is clear and actionable, as it identifies a potential gap in the paper and offers a concrete suggestion for improvement. By addressing this concern, the authors can enhance the clarity and transparency of their work. Therefore, the comment is rated as 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights potential biases in the application experiments due to the use of a single model (DALLE) and a small dataset consisting of only 30 famous paintings and 30 generated paintings. It suggests that the experiment results are not convincing and that the effectiveness of the proposed methods cannot be validly verified without comprehensive experiments. The comment also recommends examining the structure, argumentation, and language clarity to ensure the paper meets highquality standards. Additionally, it points out specific issues with equation numbering and the format of Algorithm 1. While the comment provides explicit actions for the authors to take, such as conducting more comprehensive experiments and improving the clarity of the paper, it lacks detailed guidance on how to address these issues. The authors know what needs to be done but may need more specific instructions on how to implement the changes. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the application experiments and the use of a single model (DALLE) and a small dataset, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the potential biases in the experiments and suggests that the results are not convincing due to the limited dataset. The comment further recommends examining the structure, argumentation, and language clarity to ensure the paper meets highquality standards. Additionally, it points out specific issues with equation numbering and the format of Algorithm 1. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the application experiments may have biases due to the use of a single model (DALLE) and a small dataset, which makes the results difficult to be convincing. The reviewer suggests that without comprehensive experiments, the effectiveness of the proposed methods cannot be validly verified. This claim is 3 as it provides a logical reasoning for the potential bias in the experiments, but it lacks specific examples or references to support the assertion. The suggestion to examine structure, argumentation, and language clarity is also 3, as it highlights areas for improvement but does not provide detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the application experiments, noting that the use of a single model (DALLE) and a small dataset (30 famous paintings and 30 generated paintings) may introduce biases, making the results less convincing. It suggests that the paper requires more comprehensive experiments to validate the effectiveness of the proposed methods. Additionally, the comment provides specific feedback on the structure, argumentation, and language clarity of the paper, recommending improvements in these areas. The mention of issues with equation numbering and the format of Algorithm 1 adds further detail to the feedback. Overall, the comment is 4 as it provides clear and actionable suggestions for improving the paper, offering a comprehensive roadmap for the authors to enhance the quality and validity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of practical applications for the experiments in the paper, noting that the datasets are made up from standard benchmarks. It suggests that the authors should comment on whether there are real tasks with available data that could benefit from the model. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to address the concern or what kind of comment would be appropriate. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the lack of practical applications for the experiments in the paper, specifically noting that the datasets are made up from standard benchmarks. It suggests that the authors should comment on whether there are real tasks with available data that could benefit from the model. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for the authors to comment on practical applications, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of practical applications for the experiments in the paper, noting that the datasets are made up from standard benchmarks. The reviewer suggests that there might be real tasks with available data that could benefit from the model. However, the comment does not provide specific examples or references to support the claim that such tasks exist or that the model could be applied to them. The lack of detailed evidence or examples makes the claim 3, as the authors would need to explore and substantiate the suggestion themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of practical applications for the experiments in the paper, noting that the datasets are made up from standard benchmarks. It suggests that the authors should comment on whether there are real tasks with available data that could benefit from the model. This feedback is 3 as it prompts the authors to consider the practical relevance of their work and potentially expand their discussion to include realworld applications. However, the comment could be more helpful if it provided specific examples or suggestions for how the authors might address this issue. Overall, the feedback is 3, as it identifies a potential gap in the paper and encourages the authors to consider practical implications, but it lacks detailed guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider including other backdoor detection methods that are input datafree, such as those using weight matrix statistics or matrix factorization. While the comment implies that the authors should expand their analysis to include these methods, it does not provide specific guidance on how to integrate them into the \"Robustness\" section or what aspects of these methods should be considered. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and may not be entirely sure of the exact changes needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Robustness\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should consider other backdoor detection methods that are input datafree, such as those using weight matrix statistics or matrix factorization. This provides clear guidance on what needs to be addressed in the \"Robustness\" section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that other backdoor detection methods, such as those using weight matrix statistics or matrix factorization, should be considered in the analysis of algorithm performance. However, the comment does not provide specific examples or references to these methods, making it difficult for the authors to fully understand and address the suggestion. The lack of detailed information or references limits the verifiability of the claim, as the authors may struggle to determine which methods are being referred to and how they should be integrated into their analysis. Therefore, the comment is rated as 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the \"Robustness\" section of the paper. It suggests that the authors should consider other backdoor detection methods that are input datafree, such as those using weight matrix statistics or matrix factorization. This feedback is clear and actionable, as it provides a concrete suggestion for expanding the analysis to include additional methods, which could enhance the robustness evaluation of the algorithm. However, the comment could be more helpful if it included specific examples or references to these alternative methods, which would provide the authors with more detailed guidance on how to incorporate them into their analysis. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the \"relation works\" section is incomplete and suggests that the authors should describe which view of the knowledge graph is part of the assumption, such as instanceview, ontologyview, or twoview KG. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the section. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"relation works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a description of which view of the knowledge graph is part of the assumption (instanceview, ontologyview, or twoview KG). This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"relation works\" section is incomplete and suggests that the authors should describe which view of the knowledge graph is part of the assumption. However, the comment does not provide any specific reasoning or examples to support why the section is incomplete or what aspects are missing. Without detailed justification or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of incompleteness in the paper, namely the \"relation works\" section. It provides a clear and actionable suggestion by specifying that the authors should describe which view of the knowledge graph is part of the assumption, such as instanceview, ontologyview, or twoview KG. This feedback is valuable as it directs the authors to a particular aspect of their work that needs further elaboration, helping them improve the clarity and completeness of their draft. However, the comment could be more helpful if it included additional suggestions or examples on how to address this issue. Overall, the comment is 4, as it provides clear guidance on a specific area for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of theoretical support for the technical design and questions the update derivation for the intrinsic reward parameters. It suggests that even if the design is accepted, it needs more justification, referencing Sorg et al. 2010. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the theoretical support. The action is implicit and somewhat vague, as it points out a problem but does not offer concrete steps for resolution. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of theoretical support for the technical design and questions the update derivation for the intrinsic reward parameters. It references specific equations (Eq.710) and mentions Sorg et al. 2010, which provides some grounding by indicating the specific parts of the paper being discussed. However, the comment does not specify what aspects of the theoretical support are lacking or how the update derivation could be improved, making it specific but not fully grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical design lacks theoretical support and questions the update derivation for the intrinsic reward parameters. It references Sorg et al. 2010 as a source for the design choice but does not provide detailed reasoning or examples to support the claim that the update derivation is not convincing. The reference to Sorg et al. 2010 provides some context but lacks specific evidence or analysis to substantiate the critique. Therefore, the claim is 3, as it provides a starting point for further exploration but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of theoretical support for the technical design. It questions the update derivation for the intrinsic reward parameters, suggesting that even if the design is accepted, it needs more justification. The comment references Sorg et al. 2010, which provides some context but does not fully address the issue. While it highlights a critical area for improvement, the comment could be more helpful if it offered specific suggestions or examples of how to enhance the theoretical foundation. Therefore, the comment is 3, as it points out a significant issue but lacks detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the adaptive variance reduction property claimed by the authors, suggesting that it is equivalent to selecting a \"small enough\" \u03b2 parameter, which the reviewer believes undermines the adaptivity claim. The comment also mentions that this is not the case in adaptive methods like AdaGrad. While the comment identifies a potential issue with the adaptivity claim, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or substantiate their claim regarding adaptivity. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the adaptive variance reduction property claimed by the authors, specifically questioning the adaptivity claim and suggesting that it is equivalent to selecting a \"small enough\" \u03b2 parameter. However, it does not specify which part of the paper discusses this property, making it weakly grounded. The comment is specific in its critique of the adaptivity claim and provides a comparison with adaptive methods like AdaGrad, which helps the authors understand the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the adaptive variance reduction property is equivalent to selecting a \"small enough\" \u03b2 parameter, which the reviewer believes undermines the adaptivity claim. The comment provides a specific example of adaptive methods like AdaGrad, suggesting that the claim is not valid in such cases. This reasoning is 3 as it provides a logical comparison with another method, but it lacks detailed evidence or references to fully substantiate the claim. The authors would need to further explore the comparison to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the adaptive variance reduction property claimed by the authors, suggesting that it is equivalent to selecting a \"small enough\" \u03b2 parameter, which the reviewer believes undermines the adaptivity claim. The comment provides a specific example of adaptive methods like AdaGrad, which the reviewer claims is not the case in the authors\" approach. This feedback is 3 as it identifies a potential issue with the adaptivity claim and offers a comparison with another method, prompting the authors to reconsider their approach. However, the comment could be more helpful if it provided additional guidance on how the authors might address this issue or improve their claim. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding the value of different augmentation techniques and suggests that DINOv2 seems to be the bestperforming model most of the time. It implies that the authors should investigate why this is the case and how to further improve the bestperforming model. While the comment identifies an area for further investigation, it does not provide explicit instructions or concrete steps on how to conduct this investigation. The action is implicit and somewhat vague, as the authors need to infer the specific actions needed to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the value of different augmentation techniques and the performance of DINOv2, suggesting further investigation into why it is the bestperforming model most of the time. However, it does not specify which part of the paper discusses these techniques or their performance, making it weakly grounded. The comment is specific in suggesting further investigation into the bestperforming model, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the value of different augmentation techniques is unclear and suggests that DINOv2 seems to be the bestperforming model most of the time. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the superiority of DINOv2. Without additional evidence or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the value of different augmentation techniques and the performance of DINOv2. It suggests that while DINOv2 seems to be the bestperforming model most of the time, further investigation is needed to understand why and how to improve it. This feedback is clear and actionable, as it directs the authors to explore the reasons behind the performance of DINOv2 and suggests a potential area for improvement. However, the comment could be more helpful if it provided specific suggestions or examples of how to conduct this investigation. Overall, the comment is 4 as it guides the authors toward a meaningful area for further exploration and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the acronym \"FTL\" for \"follow the top perturbed leader\" is unfortunate because it is commonly associated with \"Follow the Leader\" in literature. The reviewer implies that the acronym should be changed to avoid confusion. While the comment explicitly states the need for a change, it does not provide specific guidance on what alternative acronym to use or how to implement the change. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the acronym \"FTL\" for \"follow the top perturbed leader,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the potential confusion with the term \"Follow the Leader\" in literature and suggests a change in the acronym to avoid this confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the acronym \"FTL\" for \"follow the top perturbed leader\" is unfortunate because it is commonly associated with \"Follow the Leader\" in literature. The comment implies that this confusion could lead to misunderstandings and suggests changing the acronym. However, the comment does not provide specific examples or references to support the claim that \"FTL\" is commonly associated with \"Follow the Leader\" in literature. This lack of detailed evidence or references makes the claim 3, as the authors would need to independently verify the claim or seek additional information to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the acronym \"FTL\" for \"follow the top perturbed leader,\" noting that it could be confused with \"Follow the Leader\" in literature. This feedback is 3 as it points out a possible source of confusion and suggests a change in the acronym to avoid it. However, the comment lacks specific guidance on what alternative acronym to use or how to implement the change, which would make it more actionable. While it provides some insight into a potential improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out that the selection of attacks in Table 1 seems arbitrary and suggests that there are better stateoftheart attacks, such as MIDIFGSM. It also requests additional information about the hyperparameters and the number of iterations the attacks are run for. This feedback provides clear and concrete actions for the authors to take, such as updating the selection of attacks and including specific details about the hyperparameters and iterations. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the selection of attacks, noting that they are not stateoftheart and suggesting specific attacks like MIDIFGSM. Additionally, it requests additional information about the hyperparameters and the number of iterations the attacks are run for. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the selection of attacks in Table 1 is arbitrary and suggests that there are better stateoftheart attacks, such as MIDIFGSM. The reviewer supports this claim by referencing a survey paper that provides an extensive analysis of attacks. This external reference is a robust source of evidence, making the claim 5. The inclusion of specific examples, like MIDIFGSM, and the reference to the survey paper provide a clear and detailed justification for the claim, ensuring that the authors can understand and address the feedback effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with the selection of attacks in Table 1, noting that they are not stateoftheart and suggesting better alternatives like MIDIFGSM. It also provides a reference to an extensive survey on attacks, which can guide the authors in making more informed choices. Additionally, the comment requests additional information about the hyperparameters and the number of iterations the attacks are run for, which is a concrete suggestion for improvement. This feedback is actionable and comprehensive, empowering the authors to enhance the quality and rigor of their work. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the method, specifically that it is primarily effective for encoders pretrained with contrastive learning and may not perform well with other selfsupervised learning pretraining methods like Masked Image Modeling (MIM). However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this limitation, such as suggesting alternative methods or experiments to test the method\"s effectiveness with different pretraining approaches. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"limitations and conclusion\" sections of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the limitation of the method\"s effectiveness for encoders pretrained with contrastive learning and its potential lack of performance with other selfsupervised learning pretraining methods like Masked Image Modeling (MIM). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method is primarily effective for encoders pretrained with contrastive learning and may not perform well with other selfsupervised learning pretraining methods like Masked Image Modeling (MIM). However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional evidence or context, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment highlights a limitation of the method, specifically that it is primarily effective for encoders pretrained with contrastive learning and may not perform well with other selfsupervised learning pretraining methods like Masked Image Modeling (MIM). This feedback is 3 as it points out a potential weakness in the paper\"s scope or applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or explore alternative pretraining methods. Without actionable advice, the authors are left with a general understanding of the issue but without a clear path to improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the qualitative analysis in Section 4.5.5 and Figure 1. It asks how the input sentences for the qualitative analysis were determined, whether they occurred during the finetuning process, and whether the attribution values in Figure 1 were normalized. Additionally, it inquires about the attribution map for input examples that failed to be classified. These questions are explicit and provide clear guidance on what the authors need to address to improve their draft. The feedback is concrete, as it specifies the exact aspects that need clarification or additional information. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.5.5\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what is missing in the description of the qualitative analysis, such as the determination of input sentences and the normalization of attribution values. The comment also raises questions about the attribution maps for input examples that failed to be classified, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and requests for clarification regarding the qualitative analysis in Section 4.5.5 and Figure 1. It asks about the determination of input sentences for the qualitative analysis, whether they occurred during the finetuning process, and whether the attribution values in Figure 1 were normalized. Additionally, it inquires about the attribution map for input examples that failed to be classified. These questions are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the qualitative analysis section of the paper. It raises important questions about the selection of input sentences for the qualitative analysis, whether they occurred during the finetuning process, and the normalization of attribution values in Figure 1. Additionally, it asks about the attribution map for input examples that failed to be classified, which could be valuable for understanding the model\"s performance. By addressing these points, the authors can enhance the clarity and comprehensiveness of their qualitative analysis, which is crucial for readers to fully understand the results. The comment is detailed and provides clear guidance on how to improve the draft, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. This feedback is explicit and provides a clear action for the authors to take, which is to provide examples and clarify the practical benefits of equivariant tensor functions. The suggestion is concrete, as it specifies what kind of examples and clarifications are needed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for examples and clarification, providing clear guidance on what the authors should address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, it does not provide any specific examples or references to support the claim that such examples are necessary or beneficial. The suggestion is based on logical reasoning, but without concrete evidence or examples, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends including examples of practical applications where specific types of tensors need to be equivariant, which would help clarify the advantages of using equivariant tensor functions. This feedback is clear and offers a concrete way for the authors to enhance the practical relevance and understanding of their work. By addressing this suggestion, the authors can provide a more comprehensive and compelling argument for the benefits of their approach. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the tables, particularly Table 2, where it is unclear what methods like ERM, cRT, and LWS represent. It also points out a misalignment between Section 3.2.3 and the table. While the comment highlights the problems, it does not provide explicit instructions on how to address them, such as suggesting ways to clarify the methods or align the section with the table. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the methods and align the section, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Section 3.2.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the tables, such as the lack of proper references for methods like ERM, cRT, and LWS, and the misalignment between Section 3.2.3 and the table. This provides clear guidance on what needs to be addressed to improve the clarity and accuracy of the paper. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that there are issues with the tables, specifically Table 2, where it is unclear what methods like ERM, cRT, and LWS represent, as they are not referenced properly. Additionally, it notes a misalignment between Section 3.2.3 and the table. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the exact nature of the issues and how to address them. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed explanation or examples to be 5.", "helpfulness_rationale": "The review comment identifies specific issues with the tables, particularly Table 2, where it is unclear what methods like ERM, cRT, and LWS represent. It also points out a misalignment between Section 3.2.3 and the table. This feedback is clear and actionable, as it directs the authors to clarify the methods used in the table and ensure that the section aligns with the table content. However, the comment could be more helpful if it provided suggestions on how to clarify the methods or align the section, which would make it fully actionable. Overall, the comment is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two specific suggestions for improvement. First, it questions the suitability of the model for sarcastic/nonsarcastic utterances and suggests that the authors should provide more details for further analysis. Second, it asks for an explanation of why eyemovement data would be useful for sarcastic/nonsarcastic sentiment classification beyond textual features. Both suggestions are explicit and provide clear guidance on what the authors need to address. The feedback is concrete, as it specifies the areas where additional details or explanations are needed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as questioning the suitability of the model for sarcastic/nonsarcastic utterances and asking for more details and explanations regarding the use of eyemovement data. This level of detail helps the authors understand what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two claims: (1) questioning the suitability of the model for sarcastic/nonsarcastic utterances and (2) questioning the usefulness of eyemovement data for sentiment classification beyond textual features. Both claims are supported by logical reasoning, as they prompt the authors to provide more details and explanations. However, the comment lacks specific references or examples to fully substantiate the claims, making it 3. The authors would need to provide additional context or evidence to fully address these points. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a balanced assessment of the paper, noting its overall quality and organization while offering specific suggestions for improvement. It questions the suitability of the model for sarcastic/nonsarcastic utterances and asks for more details on this aspect. Additionally, it inquires about the usefulness of eyemovement data for sentiment classification beyond textual features and requests more explanations. These questions and suggestions are clear and actionable, offering the authors specific areas to address and expand upon in their draft. The feedback is constructive and provides valuable guidance for enhancing the paper, making it 4. However, it could be more comprehensive if it included additional suggestions or examples. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the experimental results: the limited number of datasets used and the inprofessional presentation of the tables. However, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should expand the number of datasets used and improve the presentation of the tables, but without concrete suggestions on how to do so. The action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table1 and table2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the issue of using DDIM as a sampler method instead of a model, which is a clear and actionable point for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are limited due to the use of only two smallscale/resolution datasets. It also criticizes the presentation of tables 1 and 2, stating that DDIM is used as a sampler method instead of a model. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the specific problems and their significance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the experimental results: the limited number of datasets used and the inprofessional presentation of tables 1 and 2. It points out that DDIM is used as a sampler method instead of a model, which is a critical error in the presentation of the results. However, the comment does not provide suggestions on how to address these issues or expand the dataset selection. While it highlights important areas for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more clarification about why their proposed method is important. It implies that the method is an adjustment to DPSGD, which should influence utility but may also impact privacy levels. However, the comment does not explicitly instruct the authors to address these points or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the importance of their method and its potential impact on utility and privacy levels, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more clarification about the importance of their proposed method. It implies that the method is an adjustment to DPSGD and should influence utility but may also impact privacy levels. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its request for clarification about the method\"s importance and potential impact on utility and privacy levels. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed method is important but lacks clarity on why it is significant. The reviewer implies that the method is an adjustment to DPSGD and should influence utility but may also impact privacy levels. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide more clarification about the importance of their proposed method. It implies that the method is an adjustment to DPSGD and should influence utility but may also impact privacy levels. This feedback is clear and actionable, as it directs the authors to address the potential tradeoffs between utility and privacy in their method. However, the comment could be more helpful if it provided specific suggestions on how to present this information or examples of similar tradeoffs in other methods. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a biggerscale experiment with a longerhorizon example. The reviewer explicitly states that the results should be presented in a tabular format. This feedback provides a clear and concrete action for the authors to take, specifying both the type of experiment and the format in which the results should be presented. The explicit nature of the suggestion and the detailed guidance on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a biggerscale experiment with a longerhorizon example. It explicitly mentions the need for a tabular presentation of the results. While the comment does not specify which part of the paper discusses the empirical results, the authors can infer that it relates to the results section. The suggestion for a longerhorizon example and the request for a tabular presentation provide clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the empirical results are \"illustrative, more than demonstrative\" and suggests that a biggerscale experiment with a longerhorizon example would be beneficial. However, the comment lacks specific examples or references to support this claim, such as comparing the current results to those from a largerscale experiment or discussing the limitations of the current setup. Without detailed justification or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the empirical results, noting that they are illustrative rather than demonstrative. It suggests that a biggerscale experiment with a longerhorizon example would be more beneficial. The comment is clear and actionable, providing a specific recommendation for improvement by suggesting a longerhorizon example and specifying that it should be presented in a tabular format. This feedback is valuable as it directs the authors to enhance the robustness and applicability of their results, which can significantly impact the paper\"s credibility and usefulness. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that Equation (13) does not have a closedform solution in general and suggests that details about how it is solved in the experiments and on computational complexity would be helpful. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly what details should be included or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (13),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely details about how Equation (13) is solved in the experiments and its computational complexity. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that Equation (13) does not have a closedform solution in general and suggests that details about how it is solved in the experiments and on computational complexity would be helpful. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Equation (13), noting that it does not have a closedform solution in general. It suggests that providing details about how the equation is solved in the experiments and its computational complexity would be helpful. This feedback is clear and actionable, as it directs the authors to address a particular aspect of their work that could benefit from further explanation. However, the comment could be more helpful if it included specific suggestions on how to present the details or examples of similar cases where such information was provided. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the paper should discuss the choice of \"proximity\" and the nature of the task, particularly in relation to the proposed tasks. It highlights that the correlation between proximity in Cartesian positions and the solution space does not hold for certain tasks, such as complicated mazes or robotic tasks with obstacles. The reviewer recommends analyzing which tasks have reasonable proximity metrics and demonstrating failures on those that do not. This feedback provides clear and concrete actions for the authors to take, including analyzing specific tasks and demonstrating failures. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion on the choice of \"proximity\" and the nature of the task, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the correlation between proximity in Cartesian positions and the solution space, and provides examples of tasks where this relationship does not hold, such as complicated mazes and robotic tasks with obstacles. The comment further suggests that the paper should analyze which tasks have reasonable proximity metrics and demonstrate failures on those that do not. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the choice of \"proximity\" and its relationship to the nature of the task. It provides a logical reasoning by explaining that the correlation between proximity in Cartesian positions and the solution space does not hold for certain tasks, such as complicated mazes or robotic tasks with obstacles. The reviewer suggests that the paper should analyze which tasks have reasonable proximity metrics and demonstrate failures on those that do not. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the discussion of the choice of \"proximity\" and its relationship to the nature of the task. It highlights that the correlation between proximity in Cartesian positions and the solution space does not hold for certain tasks, such as complicated mazes or robotic tasks with obstacles. The reviewer suggests that the paper should analyze which tasks have reasonable proximity metrics and demonstrate failures on those that do not. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by addressing a critical aspect of their work. The comment is 5 as it offers a detailed and constructive suggestion that can significantly enhance the paper\"s quality and clarity. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of implementation details in the experiments, which is necessary for readers to fully understand and reproduce the results. However, it does not provide specific guidance on what implementation details are missing or how the authors should address this issue. The comment refers to \"Questions for details,\" but these questions are not provided in the review, leaving the authors without concrete steps to take. As a result, the comment is vague and lacks actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of implementation details in the experiments, which is necessary for readers to fully understand and reproduce the results. However, it does not specify which experiments are lacking these details or what specific implementation details are missing. This makes it difficult for the authors to pinpoint the exact parts of the paper that need revision. Additionally, the comment refers to \"Questions for details,\" but these questions are not provided, further complicating the authors\" ability to address the issue. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experiments lack implementation details necessary for readers to fully understand or reproduce the results. However, it does not provide specific examples or details of what implementation details are missing, making it difficult for the authors to address the issue effectively. The reference to \"Questions for details\" is vague and does not offer sufficient context or justification for the claim. As a result, the comment is considered 1, as it lacks the necessary evidence or reasoning to support the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the experiments, noting that they lack implementation details necessary for readers to fully understand or reproduce the results. This is a critical observation that could impact the paper\"s reproducibility and credibility. However, the comment does not provide specific examples of what implementation details are missing or suggestions on how to address this issue. Without detailed guidance, the authors may struggle to determine which aspects of their experiments need more explanation or detail. While the comment highlights an important area for improvement, it lacks actionable feedback, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the potential unfairness in the comparison between SSUL and the offtheshelf saliencymap detector due to the use of Mask2Former. It suggests that SSUL should adopt Mask2Former to detect unseen classes or explore generating object proposals without additional data or a heavy model. While the comment implies that these changes could improve the fairness of the comparison, it does not explicitly instruct the authors to make these modifications. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SSUL\" and \"Mask2Former,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the potential unfairness in the comparison due to the use of different models and data. The comment suggests alternative approaches, such as using Mask2Former or generating object proposals without additional data or a heavy model, which provides specific guidance for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the potential unfairness in the comparison between SSUL and the offtheshelf saliencymap detector due to the use of different models and data. It suggests that Mask2Former, which is used in the paper, is trained on COCO and has larger parameters than the offtheshelf detector. The comment also proposes alternative approaches, such as using Mask2Former to detect unseen classes or generating object proposals without additional data or a heavy model. While the comment provides a logical reasoning for the potential unfairness, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the concern but could be strengthened with more detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between SSUL and the offtheshelf saliencymap detector, noting that the use of different models and data could introduce unfairness. It suggests alternative approaches, such as using Mask2Former to detect unseen classes or generating object proposals without additional data or a heavy model, which could improve the fairness of the comparison. This feedback is clear and actionable, providing the authors with specific suggestions for enhancing their work. However, it could be more helpful if it included additional context or examples to further guide the authors in implementing these suggestions. Overall, the comment is 4 as it offers constructive feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the metrics used in the experiments, suggesting that they may not adequately validate the performance of the proposed approach. It provides specific examples, such as the style accuracy being based on a style classifier that might not capture the styleness of the proposed algorithm, and the difficulty in verifying the transfer result based on a styled motion input. However, the comment does not explicitly instruct the authors to change or improve the metrics or provide guidance on how to address these concerns. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their metrics but are not given concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the metrics used in the experiments, specifically questioning their ability to validate the performance of the proposed approach. It provides examples of potential issues, such as the style accuracy being based on a style classifier that might not capture the styleness of the proposed algorithm, and the difficulty in verifying the transfer result based on a styled motion input. However, the comment does not specify which sections of the paper discuss these metrics or experiments, making it weakly grounded. The authors can infer that it relates to the experimental results or methodology sections, but the lack of explicit references makes it challenging to pinpoint the exact parts of the paper being addressed. The comment is specific in detailing the issues with the metrics, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metrics used in the experiments may not adequately validate the performance of the proposed approach. It provides specific examples, such as the style accuracy being based on a style classifier that might not capture the styleness of the proposed algorithm, and the difficulty in verifying the transfer result based on a styled motion input. These examples provide a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the metrics used in the experiments, suggesting that they may not adequately validate the performance of the proposed approach. It provides specific examples, such as the style accuracy being based on a style classifier that might not capture the styleness of the proposed algorithm, and the difficulty in verifying the transfer result based on a styled motion input. This feedback is clear and actionable, as it highlights a specific area for improvement in the experimental design and suggests that the authors reconsider their choice of metrics. However, the comment could be more helpful if it offered alternative metrics or methods to address these concerns. Overall, the comment is 4 as it provides valuable insights into improving the experimental validation of the proposed approach."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of clarity regarding how individual preferences are generated in the proposed method. It suggests that the authors clarify whether these preferences are based on rules or policies learned from experiences. While the comment implies that the authors should provide more details on this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the mechanism for generating individual preferences. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the argument about taking individual preferences into account when simulating agents, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how individual preferences are generated and suggesting that the authors clarify whether these preferences are based on rules or policies learned from experiences. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of how individual preferences are generated in the proposed method. It questions whether these preferences are based on rules or policies learned from experiences and suggests that this needs to be clarified. The comment provides a logical reasoning by pointing out a potential gap in the explanation of how individual preferences are incorporated, which is a valid concern. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional details or evidence to fully address the issue, hence the score of 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how individual preferences are generated in the proposed method. It questions whether these preferences are based on rules or policies learned from experiences, and it suggests that this needs to be clarified. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations or examples to clarify how individual preferences are incorporated into the simulation. By addressing this point, the authors can enhance the comprehensibility and robustness of their work. Therefore, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises questions about the clarity of Figure 4, specifically regarding the meaning of \"1200 frames\" and how the values are computed. It also questions the relationship between precision and recall and the trajectory length, as well as the meaning of \"action repeat.\" These questions imply that the authors should clarify these aspects in their draft. However, the comment does not provide explicit instructions on how to address these questions or improve the clarity of the figure. While the authors can infer that they need to provide explanations for these terms and concepts, the action is implicit and somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear about the figure, namely the meaning of \"1200 frames,\" how the values are computed, the relationship between precision and recall and trajectory length, and the meaning of \"action repeat.\" This provides clear guidance on what needs to be clarified or explained in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about specific aspects of Figure 4, such as the meaning of \"1200 frames,\" the computation of values, the relationship between precision and recall and trajectory length, and the meaning of \"action repeat.\" These questions are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas of confusion in Figure 4, such as the meaning of \"1200 frames,\" the computation of values, the relationship between precision and recall and trajectory length, and the term \"action repeat.\" By pointing out these unclear aspects, the comment provides the authors with clear guidance on what needs to be clarified or explained in their draft. This feedback is actionable and constructive, as it directs the authors to enhance the clarity and comprehensibility of their figures, which is crucial for the understanding of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to clarify these terms. Overall, the comment is 4, as it effectively points out areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the arbitrariness of certain design decisions, such as the number of initial ground truth examples and the number of labeled examples. It suggests that the authors should provide justification for these decisions, particularly in light of the paper\"s focus on costeffectiveness. The comment implies that the authors should conduct a comparison between LLaMAA and finetuning, using a number of samples equivalent in cost to the additional samples from the LLM. While the comment does not explicitly instruct the authors to perform this comparison, it provides a clear direction for how to address the issue. The action is concrete, as it specifies what kind of comparison would be beneficial, but it is not explicitly stated. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses specific design decisions related to the number of initial ground truth examples and the number of labeled examples, questioning their arbitrariness. It suggests that the authors should provide justification for these decisions, particularly in light of the paper\"s focus on costeffectiveness. However, the comment does not specify which sections of the paper these decisions are discussed in, making it weakly grounded. The comment is specific in its request for justification and comparison with LLaMAA and finetuning, but without explicit references to sections, it is challenging for the authors to pinpoint the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some design decisions, such as the number of initial ground truth examples and the number of labeled examples, seem arbitrary. It suggests that the authors should provide justification for these decisions, particularly in light of the paper\"s focus on costeffectiveness. The comment implies that a comparison between LLaMAA and finetuning, using a number of samples equivalent in cost to the additional samples from the LLM, would be more satisfying. However, the comment lacks specific examples or references to support the claim that these design decisions are arbitrary or that the suggested comparison would be beneficial. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the design decisions in the paper, specifically questioning the arbitrariness of the number of initial ground truth examples and the number of labeled examples. It suggests that the authors should provide justification for these decisions, particularly in light of the paper\"s focus on costeffectiveness. The comment also proposes a specific comparison between LLaMAA and finetuning, using a number of samples equivalent in cost to the additional samples from the LLM, which could provide valuable insights into the costeffectiveness of the approach. While the comment is clear in its critique and offers a constructive suggestion for improvement, it could be more helpful by providing additional context or examples to further guide the authors. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides a concrete suggestion for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the motivation for investigating a graph structured model, questioning the need for such an approach when the encoder and decoder are based on the Transformer, which can already capture global dependencies. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this confusion or improve their approach. Without actionable suggestions or a clear direction for revision, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the motivation for investigating a graph structured model, specifically questioning the need for such an approach when the encoder and decoder are based on the Transformer, which can already capture global dependencies. However, the comment does not specify which part of the paper discusses the motivation or the complexity of the approach, making it weakly grounded. The authors can infer that it relates to the introduction or motivation section, but this inference is not explicit. The comment is specific in questioning the need for a complex approach, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the motivation for investigating a graph structured model, questioning its necessity given that the encoder and decoder are based on the Transformer, which can already capture global dependencies. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the motivation for investigating a graph structured model when the encoder and decoder are based on the Transformer, which can already capture global dependencies. However, the comment does not provide any specific suggestions or guidance on how the authors might address this concern or improve their approach. It lacks depth and actionable feedback, leaving the authors without a clear understanding of what steps to take to enhance their work. As a result, the comment is 2, as it identifies a potential issue but does not offer meaningful guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide videos showing different policies controlling cars on different tracks to better understand how different methods work. This is an explicit request for additional content that would enhance the paper\"s reproducibility. Additionally, the comment highlights a lack of implementation details in the main paper, which makes reproducing the results difficult. The reviewer also questions the policy gradient approach used. While the first suggestion is explicit and provides a clear action, the second part is more implicit, as it points out a problem but does not explicitly instruct the authors on how to address it. Overall, the comment is 4, as it provides concrete guidance for one aspect and a more general direction for the other.", "grounding_specificity_rationale": "The comment suggests providing videos to demonstrate different policies controlling cars on different tracks, which would help understand how different methods work. It also mentions a lack of implementation details in the main paper, making it difficult to reproduce the results. The comment is fully grounded as it explicitly mentions the need for videos and the lack of implementation details, allowing the authors to accurately identify the parts of the paper being addressed. However, it is specific only in terms of the need for videos and the lack of implementation details, as it does not provide detailed guidance on what specific implementation details are missing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that providing videos showing different policies controlling cars on different tracks would enhance understanding of how different methods work. This is a subjective claim that lacks specific reasoning or examples to support why videos would be beneficial. Additionally, the comment mentions a lack of implementation details, which is a factual statement requiring no verification. Therefore, the claim about videos is 1, while the statement about implementation details is factual, resulting in a score of \"1\".", "helpfulness_rationale": "The review comment provides two distinct points. First, it suggests that the authors should include videos showing different policies controlling cars on different tracks to better understand how different methods work. This is a clear and actionable suggestion that could enhance the paper\"s clarity and reproducibility. Second, it highlights a lack of implementation details in the main paper, which makes reproducing the results difficult. This feedback is also actionable, as it points out a specific area for improvement. However, the comment could be more helpful if it provided more detailed guidance on what specific implementation details are missing or how to address them. Overall, the comment is 4 as it offers actionable feedback that can guide the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the approximation in Equation 11 and suggests that the authors should conduct more experiments and theoretical analyses to explore the impact of the order of layers with the same parameters. While the comment implies that the authors should conduct additional work, it does not provide explicit instructions on how to proceed or what specific experiments or analyses should be conducted. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without detailed guidance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 11\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the approximation in Equation 11 and the lack of clarity in Figure 1 regarding the representation of layers. The comment provides clear guidance on what needs to be addressed, such as conducting more experiments and theoretical analyses to explore the impact of layer order. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the approximation in Equation 11, suggesting that it only considers the impact of parameters in each layer and does not account for the effect of the order of layers with the same parameters. The reviewer provides a logical reasoning by pointing out that Figure 1 does not indicate which specific layer each color represents, suggesting that more experiments and theoretical analyses are needed to explore this aspect. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to conduct additional research to fully understand and address the issue, which is a reasonable expectation but not fully supported by the current comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the approximation in Equation 11, suggesting that it only considers the impact of parameters in each layer and does not account for the effect of the order of layers with the same parameters. It also points out a lack of clarity in Figure 1, where the colors do not indicate which specific layer they represent. The comment provides a clear and actionable suggestion for the authors to conduct more experiments and theoretical analyses to explore this aspect. By addressing these issues, the authors can enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered specific guidance on how to conduct these experiments or analyses. Overall, the feedback is 4 as it identifies important areas for improvement and provides a clear direction for further exploration."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the approach to offlinetoonline learning adaptation is incremental, as most previous offline RL benchmarks are based on simulation environments and rulebased reward functions. It implies that implementing online finetuning on top of existing benchmarks is feasible. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The action is implicit and vague, as the authors are left to infer that they should consider alternative approaches or provide more detailed justification for their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of offlinetoonline learning adaptation, suggesting that the approach is incremental due to the reliance on simulation environments and rulebased reward functions in previous offline RL benchmarks. However, it does not specify which part of the paper this observation is based on, making it weakly grounded. The comment is specific in its critique of the approach, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the approach to offlinetoonline learning adaptation is incremental, as most previous offline RL benchmarks are based on simulation environments and rulebased reward functions. The comment suggests that implementing online finetuning on top of existing benchmarks is feasible. However, the claim lacks specific examples or references to support the assertion that the approach is incremental or that online finetuning is feasible. Without detailed evidence or examples, the claim remains 3, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the approach to offlinetoonline learning adaptation, suggesting that it is incremental due to the reliance on simulation environments and rulebased reward functions in previous offline RL benchmarks. It implies that implementing online finetuning on top of existing benchmarks is feasible. While the comment highlights a specific area for improvement, it lacks detailed guidance or suggestions on how the authors might address this issue or explore alternative approaches. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional insights or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a contradiction in the results presented in Table 6, specifically noting that AT, which finetunes the detection model with emotion classification data, achieves a worse F1 score compared to BERTsynth, which does not use emotionawareness. It also points out that GAS, which finetunes the model with multiple emotion classification datasets, achieves the lowest F1 score. The comment suggests that these results do not support the claim that emotionawareness could be useful for synthetic text detection. While the comment identifies a potential issue with the results, it does not provide explicit guidance on how the authors should address this contradiction or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconcile the results or provide additional analysis to support their claim. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the contradiction in the results, particularly the F1 scores of AT and BERTsynth, and the performance of GAS. The comment provides specific examples and reasoning, making it clear what needs to be addressed regarding the claim that emotionawareness could be useful for synthetic text detection. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 6 provides contradicting evidence, specifically noting that AT, which finetunes the detection model with emotion classification data, achieves a worse F1 score than BERTsynth, which does not use emotionawareness. It also points out that GAS, which finetunes the model with multiple emotion classification datasets, achieves the lowest F1 score. The reviewer suggests that these results do not support the claim that emotionawareness could be useful for synthetic text detection. The comment provides specific examples and reasoning to support the claim, making it 4. However, it could be strengthened by providing more detailed analysis or references to similar studies that support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 6, pointing out a contradiction in the evidence provided. It highlights that AT, which finetunes the detection model with emotion classification data, achieves a worse F1 score compared to BERTsynth, which does not use emotionawareness. Additionally, it notes that GAS, which finetunes the model with multiple emotion classification datasets, achieves the lowest F1 score. This feedback is valuable as it helps the authors recognize a potential flaw in their argument that emotionawareness could be useful for synthetic text detection. However, the comment could be more helpful if it provided suggestions on how to address this contradiction or improve the analysis. Overall, the comment is 4 as it directs the authors\" attention to a critical issue in their results, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests conducting more experiments to address the research question and test the method\"s generalizability with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models. These suggestions are explicit and provide concrete guidance on how to expand the experimental scope and improve the evaluation. The authors know exactly what actions to take to enhance their draft, making this comment 5.", "grounding_specificity_rationale": "The comment suggests conducting more experiments to address the research question and test the method\"s generalizability with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section or results. The suggestion is specific in terms of what additional experiments or models should be considered. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting more experiments to address the research question and test the method\"s generalizability with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models. The suggestion is supported by references to specific works, such as \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\" and \"Learning Transferable Visual Models From Natural Language Supervision,\" which provide context and justification for the proposed experiments. This level of detail and reference to external sources makes the claim 4, as it provides a clear path for the authors to enhance their work. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors conduct more experiments to address the research question and test the method\"s generalizability with various models, such as Vision Transformers (ViT). It also recommends including results under more complex input noise models, such as those involving multiplicative distortions, to provide a more comprehensive evaluation. This feedback is clear and detailed, offering concrete steps for the authors to enhance their experimental setup and analysis. By following these suggestions, the authors can significantly improve the robustness and comprehensiveness of their study. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the number of human annotators mentioned in the D.2 appendix should be four, based on the author responses. This provides a clear and direct action for the authors to take, ensuring that the number of annotators is corrected in the appendix. The comment is explicit and concrete, as it specifies exactly what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"D.2 appendix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the number of human annotators mentioned in the appendix. The comment provides a clear and direct instruction to correct the number of annotators, ensuring that the authors know exactly what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement that corrects the number of human annotators mentioned in the D.2 appendix, based on the author responses. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is highly specific and actionable, as it identifies a clear error in the number of human annotators mentioned in the D.2 appendix. By pointing out this discrepancy, the comment provides the authors with a direct and concrete step to take in correcting their draft. This level of detail and specificity is valuable for the authors, as it ensures they can make a precise and effective revision. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a better motivation for the encoder and decoder structure would have helped in understanding the value of the proposed approach. However, it does not provide explicit guidance on how to improve the motivation or what specific aspects of the structure need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations or examples to better motivate the structure. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a better motivation for the encoder and decoder structure would help in understanding the value of the proposed approach. However, it does not specify which part of the paper discusses the encoder and decoder structure, making it difficult for the authors to pinpoint the exact section that needs improvement. Additionally, the comment lacks specificity regarding what aspects of the motivation are lacking or how they could be improved. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a better motivation for the encoder and decoder structure would help in understanding the value of the proposed approach. However, the comment does not provide any specific examples, reasoning, or references to support why the current motivation is insufficient or how it could be improved. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that a better motivation for the encoder and decoder structure would help in understanding the value of the proposed approach. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how to enhance the motivation or what specific aspects of the structure need clarification. The feedback is 3 as it points out a weakness, but it does not offer detailed suggestions or examples to assist the authors in making improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the novelty of the explored loss functions, noting that they are not new and are a \"simple \"plug and play\" of loss functions.\" It also points out the limitation of conducting only whitebox attacks and suggests extending the analysis to include targeted attacks. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or specific actions to take. The authors can infer that they need to enhance the novelty of their work and consider blackbox and targeted attacks, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"explored loss functions\" and the \"conducted attacks,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the concerns about the novelty of the loss functions, the absence of blackbox evaluation, and the limitation of only considering untargeted attacks. The comment provides clear guidance on what needs to be addressed, such as extending the analysis to targeted attacks and considering blackbox evaluations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the novelty of the explored loss functions, noting that they are not new and are a \"simple \"plug and play\" of loss functions.\" It also critiques the lack of blackbox evaluation and the focus on untargeted attacks. While the comment provides a logical reasoning for the claim about the lack of novelty, it lacks specific examples or references to support the assertion. This makes the claim 3, as it provides a basis for the critique but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas of concern that could be addressed to improve the paper. It highlights the limited novelty of the explored loss functions, noting that they are not new and are a \"simple \"plug and play\" of loss functions.\" It also points out the lack of blackbox evaluation and the focus on untargeted attacks, suggesting that extending the analysis to targeted attacks would showcase the strength of the proposed attack method. While the comment provides clear insights into areas for improvement, it could be more helpful by offering specific suggestions on how to enhance the novelty or by providing examples of how to conduct blackbox evaluations. Overall, the feedback is 4 as it directs the authors\" attention to important aspects of their work that need further development."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point highlights that the results for CIFAR10 are not impressive and suggests that a direct comparison with the approaches mentioned is mandatory. It also requests results for CIFAR100. While the comment explicitly states the need for a direct comparison and additional results, it does not provide specific guidance on how to conduct these comparisons or what metrics to focus on. The action is explicit but somewhat vague, as the authors know they need to improve the results but may not be entirely clear on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results for CIFAR10, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, noting that they are not impressive and suggesting a direct comparison with the approaches mentioned. Additionally, it requests results for CIFAR100. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the results for CIFAR10 are not impressive and suggests that a direct comparison with the approaches mentioned is necessary. However, the comment does not provide any specific examples or references to support this claim, nor does it explain why the results are not impressive. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the results for CIFAR10, noting that they are not impressive compared to the approaches mentioned. It explicitly requests a direct comparison with these approaches and suggests including results for CIFAR100. This feedback is clear and actionable, providing the authors with a specific area for improvement and a concrete suggestion for enhancing their draft. By addressing these points, the authors can strengthen their results section and provide a more comprehensive evaluation of their approach. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of evidence demonstrating the suitability of hyperbolic space for hierarchical datasets in the experiments. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should include experiments or analyses to demonstrate this suitability, but it does not specify what kind of experiments or analyses would be appropriate. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"hyperbolic space\" and \"hierarchical dataset,\" which provides some context. However, it does not specify which experiments are being referred to, making it difficult for the authors to pinpoint the exact sections that need attention. The comment also lacks specificity regarding what aspects of the experiments should demonstrate the suitability of hyperbolic space for hierarchical datasets. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that \"hyperbolic space is well suited for hierarchical dataset\" but notes that the experiments do not clearly demonstrate this. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim about the suitability of hyperbolic space for hierarchical datasets. Without additional context or justification, the claim remains 1, as it lacks the necessary evidence or explanation to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out a potential gap in the paper, noting that while it is known that hyperbolic space is wellsuited for hierarchical datasets, the experiments do not clearly demonstrate this. This feedback identifies a specific area where the paper could be strengthened by providing evidence or analysis to support the claim. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue, such as recommending specific experiments or analyses to include. While it highlights a relevant area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the main strength of MixBoost, asking whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific aspects of their draft need improvement. Without actionable suggestions or a clear direction for revision, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the main strength of MixBoost, asking whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion where these strengths are mentioned. Without explicit references to sections or elements of the paper, the authors cannot confidently determine the exact part being addressed. Additionally, while the comment identifies the areas of interest, it does not provide specific guidance on how to address these questions or improve the clarity of the paper. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the main strength of MixBoost, asking whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. It lacks specific examples or detailed analysis to justify why these aspects might be the main strengths of MixBoost. Without such support, the claim remains 1, as the authors are left without a clear understanding of the basis for the question. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the main strength of MixBoost, asking whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. While this question identifies a potential area of confusion or lack of clarity in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue. The comment lacks actionable feedback or detailed insights that could help the authors improve their draft. As a result, the comment is 2, as it points out a potential weakness but does not offer a clear path for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the wording in the paper, specifically regarding the statement that \"Unlike previous works which use the test set for hyperparameter tuning.\" The reviewer suggests that proper hyperparameter tuning is essential in ML but finds the wording to be challenging. Additionally, the comment implies that the use of a \"smaller training set\" could be avoided by training the network with optimal parameters on the complete train+val. While the comment identifies issues with the wording and suggests an alternative approach, it does not provide explicit instructions on how to revise the wording or implement the suggested training method. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line numbers 243 and 245, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the wording regarding hyperparameter tuning and suggests an alternative approach to avoid using a smaller training set. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the wording in the paper, specifically regarding the statement that \"Unlike previous works which use the test set for hyperparameter tuning.\" The reviewer suggests that proper hyperparameter tuning is essential in ML but finds the wording to be challenging. Additionally, the comment implies that the use of a \"smaller training set\" could be avoided by training the network with optimal parameters on the complete train+val. While the comment provides some reasoning, it lacks specific examples or references to support the claim about the challenging wording or the alternative approach suggested. This makes the claim 3, as it requires more detailed justification or evidence to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the paper, particularly regarding the statement that \"Unlike previous works which use the test set for hyperparameter tuning.\" The reviewer acknowledges the importance of proper hyperparameter tuning but finds the wording to be challenging. Additionally, the comment suggests an alternative approach to avoid using a smaller training set by training the network with optimal parameters on the complete train+val. This feedback is clear and actionable, providing the authors with a specific area for improvement and a potential solution. However, the comment could be more helpful if it included additional guidance on how to rephrase the challenging wording or how to implement the suggested alternative approach. Overall, the comment is 4 as it directs the authors to enhance the clarity and accuracy of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the writing of the paper needs improvement, specifically mentioning that the introduction is obscure and highlevel, lacking detailed elaboration on the actual implementation. The reviewer recommends hinting at how parameters are tokenized and how DDPM is used to predict actual parameters, which could help the authors gain clearer insights. While the comment identifies areas for improvement, it does not provide specific guidance on how to implement these suggestions or what aspects of the introduction need more detail. The action is explicit but somewhat vague, as the authors know they need to improve the introduction but may not be entirely sure of the exact changes needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment provides specific feedback on the writing of the paper, particularly the introduction, which is described as obscure and highlevel. It suggests that the authors should elaborate on the actual implementation, such as how parameters are tokenized and how DDPM is used to predict actual parameters. This feedback is specific in identifying what needs to be addressed, but it does not explicitly mention which part of the introduction is being referred to, making it weakly grounded. However, the authors can infer that it relates to the introduction section. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the writing of the paper needs improvement, specifically mentioning that the introduction is obscure and lacks detailed elaboration on the actual implementation. The reviewer suggests that the authors should provide more details on how parameters are tokenized and how DDPM is used to predict actual parameters. However, the comment does not provide specific examples or references to support the claim that the introduction is obscure or lacks detail. Without detailed justification or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s writing, noting that the introduction is obscure and lacks detailed elaboration on the actual implementation. It suggests that the authors should provide more details on how parameters are tokenized and how DDPM is used to predict actual parameters, which could help clarify the methodology. This feedback is clear and actionable, as it points out a particular area for improvement and offers a concrete suggestion for enhancing the paper\"s clarity. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to incorporate these suggestions. Overall, the comment is 4 as it directs the authors toward improving the clarity and depth of their introduction."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the presentation is not good and suggests that the authors name a few examples. However, it does not provide any specific guidance on what aspects of the presentation are lacking or how the authors might improve it. The action is implicit and vague, as the authors are left to infer that they need to enhance the presentation but without concrete suggestions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the presentation is considered \"not good.\" It lacks specificity because it does not provide details on what aspects of the presentation are problematic or how they could be improved. Without clear guidance, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the presentation is not good, but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples of what aspects of the presentation are lacking, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment states that the presentation is not good but does not provide any specific details or examples to support this claim. It lacks actionable feedback or suggestions for improvement, leaving the authors without a clear understanding of what aspects of the presentation need attention. Without detailed guidance, the authors are unable to effectively address the issue, making the comment 1. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing reference in the related work section, specifically mentioning the work by Rieck et al. 2. This provides a clear and direct action for the authors to take, which is to include the missing reference. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the work by Rieck et al. 2, which should be included in the discussion of the correlation between topological complexity and generalization ability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have missed a relevant work by Rieck et al. 2 in their discussion of the correlation between topological complexity and generalization ability. This claim is verifiable as it provides a specific reference to an external work that should be included in the related work section. The mention of a specific reference adds credibility to the claim, making it 4. However, the comment could be strengthened by providing more context or explanation about why this work is relevant or how it relates to the authors\" work. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific omission in the related work section, pointing out that the authors have missed the work by Rieck et al. 2 in their discussion of the correlation between topological complexity and generalization ability. This feedback is clear and actionable, as it provides a direct suggestion for the authors to include a relevant reference in their work. By addressing this oversight, the authors can enhance the comprehensiveness and accuracy of their literature review. However, the comment could be more helpful if it provided additional context or explanation about why this reference is important or how it relates to the authors\" work. Overall, the comment is 4 as it guides the authors toward a specific improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the usefulness of the exploration parameter gamma in Algorithm 1 and Theorem 3.1, given that only upperbounds on the pseudoregret are provided. It suggests that the choice gamma=0 might be optimal and proposes a remark on highprobability upperbounds and the role of gamma. Additionally, it asks whether the analysis, which is based on expectations, can be extended to highprobability bounds on the regret. While the comment implies that the authors should address these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested remarks or extensions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Alg 1\" and \"Thm 3.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the usefulness of the exploration parameter gamma, suggesting that the choice gamma=0 might be optimal, and proposing a remark on highprobability upperbounds and the role of gamma. Additionally, it asks whether the analysis can be extended to highprobability bounds on the regret. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point raises a concern about the usefulness of the exploration parameter gamma in Algorithm 1 and Theorem 3.1, given that only upperbounds on the pseudoregret are provided. The reviewer suggests that the choice gamma=0 might be optimal and proposes a remark on highprobability upperbounds and the role of gamma. Additionally, the comment asks whether the analysis, which is based on expectations, can be extended to highprobability bounds on the regret. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the suggestion that gamma=0 is optimal. This makes the claim 3, as it requires further elaboration or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the analysis provided in the paper, specifically regarding the exploration parameter gamma in Algorithm 1 and Theorem 3.1. It points out that only upperbounds on the pseudoregret are provided, questioning the usefulness of gamma and suggesting that the choice gamma=0 might be optimal. The comment also proposes a remark on highprobability upperbounds and the role of gamma, which could be an interesting addition to the paper. Additionally, it asks whether the analysis, which is based on expectations, can be extended to highprobability bounds on the regret. This feedback is clear and actionable, as it highlights a specific area for improvement and suggests potential directions for further analysis. However, it could be more helpful if it provided more detailed guidance on how to address these issues or included specific examples. Overall, the comment is 4, as it provides valuable insights and prompts the authors to consider additional aspects of their analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to add a restatement of the definition of LCA relaxation from Wang et al. in the body of the paper or to provide a description in the appendix. This feedback is clear and provides a direct action for the authors to take, ensuring they know exactly what needs to be done to address the comment. The action is concrete, as it specifies where the definition should be added, either in the main text or the appendix. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 150,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a direct definition of LCA relaxation, and provides a clear action for the authors to take, either by restating the definition from Wang et al. in the body of the paper or by adding a description in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the LCA relaxation is referenced but not directly defined in the paper. It suggests that the authors should either restatement the definition from Wang et al. in the body of the paper or provide a description in the appendix. This claim is 3 as it highlights a potential gap in the paper, but it lacks specific examples or references to the work of Wang et al. to fully substantiate the need for clarification. The authors would need to refer to the original source to fully understand the issue and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the LCA relaxation is referenced but not directly defined. It provides a clear and actionable suggestion for the authors to either restatement the definition from Wang et al. in the body of the paper or to add a description in the appendix. This feedback is valuable as it directs the authors to a precise area for improvement, ensuring that the paper is more accessible and comprehensible to readers. However, the comment could be more helpful if it included a brief explanation of what LCA relaxation is or why it is important, which would further enhance the authors\" understanding of the issue. Overall, the comment is 4, as it provides clear guidance for improvement but could be more comprehensive with additional context."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that providing more information on how validation and test splits influence model training could strengthen reproducibility. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly what information should be included or how it should be presented. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more information on how validation and test splits influence model training could strengthen reproducibility. However, it does not specify which part of the paper this issue pertains to, such as a specific section or methodology discussion. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Additionally, while the comment identifies a potential area for improvement, it does not provide specific guidance on what additional information should be included or how it would strengthen reproducibility. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that providing more information on how validation and test splits influence model training could strengthen reproducibility. However, the comment does not provide specific examples or detailed reasoning to support why this information is crucial or how it would enhance reproducibility. The lack of detailed justification or examples makes it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered 2, as it provides a general idea but lacks the necessary depth to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that more information on how validation and test splits influence model training could strengthen reproducibility. This feedback is 3 as it points out a specific aspect that could enhance the robustness and transparency of the paper. However, the comment lacks detailed guidance or examples on what specific information should be included or how it would impact reproducibility. To be more helpful, the comment could provide suggestions or examples of what additional information would be beneficial. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scope of the paper, specifically questioning why the authors have limited their focus to dropout as a solution for overfitting. It suggests considering other regularization techniques, such as L2 regularization, data augmentation, and adding noise, and asks what would happen if ZeroLiers were used in combination with these techniques. While the comment implies that the authors should consider a broader range of regularization techniques, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate these additional techniques or what the expected outcome might be. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the scope of the paper, specifically questioning why the authors have limited their focus to dropout as a solution for overfitting. It suggests considering other regularization techniques, such as L2 regularization, data augmentation, and adding noise, and asks what would happen if ZeroLiers were used in combination with these techniques. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the discussion of regularization techniques or the methodology section, but this inference is not explicit. The comment is specific in its suggestion to consider other regularization techniques, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the scope of the paper, specifically questioning why the authors have limited their focus to dropout as a solution for overfitting. It suggests considering other regularization techniques, such as L2 regularization, data augmentation, and adding noise, and asks what would happen if ZeroLiers were used in combination with these techniques. While the comment raises a valid point about the scope of the paper, it lacks specific examples or references to support the suggestion of considering other regularization techniques. The claim is 3, as it provides a logical reasoning for expanding the scope, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid question about the scope of the paper, specifically questioning why the authors have limited their focus to dropout as a solution for overfitting. It suggests considering other regularization techniques, such as L2 regularization, data augmentation, and adding noise, and asks what would happen if ZeroLiers were used in combination with these techniques. This feedback is 3 as it prompts the authors to consider a broader range of regularization techniques and their potential impact on the results. However, the comment could be more helpful if it provided specific examples or references to support the suggestion of considering these additional techniques. Overall, the comment offers a valuable direction for expanding the scope of the paper, but it lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the generalizability of Assumption A (overlap) from a tabular setting to a function approximation setting. It suggests that since the authors mention this assumption in the section about consistency, it would be beneficial to discuss it. While the comment implies that the authors should address the generalizability issue, it does not explicitly instruct them to do so or provide specific guidance on how to discuss it. The action is implicit and somewhat vague, as the authors can infer that they need to address the generalizability issue but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Assumption A (overlap)\" and the section about consistency, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the generalizability of the assumption from a tabular setting to a function approximation setting and suggests discussing this issue. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of Assumption A (overlap) from a tabular setting to a function approximation setting. The reviewer suggests that since the authors mention this assumption in the section about consistency, it would be beneficial to discuss it. However, the comment does not provide any specific reasoning or evidence to support why this generalization might be challenging or how it could impact the paper. The suggestion is logical but lacks detailed justification or examples, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a question about the generalizability of Assumption A (overlap) from a tabular setting to a function approximation setting. It suggests that since the authors mention this assumption in the section about consistency, it would be beneficial to discuss this generalization. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address the issue or what aspects of the generalization should be discussed. This limits the helpfulness of the feedback, as it provides insight but does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a twocolumn width. It also mentions that the paper was not easy to understand during the first read and suggests that major improvements could be achieved by straightening up the content. While the comment provides explicit suggestions for layout changes, it does not offer specific guidance on how to straighten up the content or what aspects need improvement. The action is explicit but somewhat vague, as the authors know they need to make layout changes but may not be entirely sure how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"figures 3, 5, and 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that Table 1 should be one column wide and that the figures would benefit from a twocolumn width. Additionally, it provides feedback on the overall readability of the paper, suggesting that major improvements could be achieved by straightening up the content. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper could be improved by making layout changes, specifically recommending that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a twocolumn width. However, the comment does not provide any reasoning or evidence to support why these layout changes would enhance the paper\"s readability or understanding. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the layout of the paper, suggesting that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a twocolumn width. This feedback is clear and direct, offering the authors a concrete way to improve the readability and presentation of their work. Additionally, the comment mentions that the paper was not easy to understand during the first read, suggesting that major improvements could be achieved by straightening up the content. While the comment does not elaborate on what specific aspects of the content need improvement, it still offers valuable guidance on layout and readability. Therefore, the comment is 4, as it provides actionable suggestions that can significantly enhance the paper\"s presentation and clarity."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should repeat the TextDPO baseline but with the generated images used for DPO as images for additional imagequestionanswer triplets. It implies that the authors should create new triplet pairs using perturbed images to test the hypothesis that the additional performance benefit comes from training with perturbed images rather than the specific DPO objective. While the action is implicit, it is concrete because it provides a clear direction on how to test the hypothesis. The authors know exactly what needs to be done to address the concern. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests repeating the TextDPO baseline but with perturbed images used for additional imagequestionanswer triplets. It provides a specific suggestion for how to test the hypothesis that the additional performance benefit comes from training with perturbed images rather than the specific DPO objective. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the experimental setup or results section, but this inference is not as direct as it could be. The comment is specific in detailing the proposed modification, which aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the additional performance benefit comes from training with perturbed images rather than the specific DPO objective. The reviewer provides a specific suggestion for testing this hypothesis by creating new triplet pairs using perturbed images. This reasoning is logical and provides a clear direction for the authors to explore, making the claim 4. However, the comment could be strengthened by referencing similar studies or experiments that support this hypothesis, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the experimental setup by repeating the TextDPO baseline with perturbed images used for additional imagequestionanswer triplets. This feedback is actionable and offers a clear direction for the authors to test their hypothesis that the additional performance benefit comes from training with perturbed images rather than the specific DPO objective. By suggesting a concrete experiment, the comment empowers the authors to refine their methodology and potentially uncover valuable insights. However, the comment could be more helpful if it included additional context or explanation on why this approach might be beneficial or how it could impact the overall results. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential assumption in the paper regarding the expertise of Alice and Bob, suggesting that there could be nonlinear interactions between successrate and speedup due to different levels of expertise. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The comment implies that the authors should consider this assumption and its implications, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific assumption in the paper regarding the expertise of Alice and Bob, suggesting that there could be nonlinear interactions between successrate and speedup due to different levels of expertise. However, it does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the assumption and providing a potential area for improvement, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about a final assumption in the paper regarding the expertise of Alice and Bob, suggesting that there could be nonlinear interactions between successrate and speedup due to different levels of expertise. The comment provides a logical reasoning by pointing out that this assumption may not hold in realworld tasks involving humanAI collaboration. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider the implications of this assumption and potentially address it in their work, but the comment could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential assumption in the paper regarding the expertise of Alice and Bob, suggesting that there could be nonlinear interactions between successrate and speedup due to different levels of expertise. This is a valuable observation that highlights a critical area for consideration in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or explore the implications of different levels of expertise. While it points out a potential weakness, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the mitigation strategies, such as data sanitization, which are specific to the dataset and may not be applicable more generally. It also notes that the framework, while demonstrating the possibility of data leakage, is not very generalizable and may have limited applicability to other LLMs or datasets. However, the comment does not provide explicit guidance or suggestions on how the authors might address these limitations or improve the generalizability of their framework. The action is implicit and vague, as the authors are left to infer that they should explore more generalizable mitigation strategies or expand the applicability of their framework. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the mitigation strategies, specifically mentioning \"sanitizing the data,\" which provides some grounding as it implies a specific part of the paper discussing data handling. However, it does not explicitly mention the section or part of the paper where these strategies are discussed, making it weakly grounded. The comment is specific in detailing the limitations of the mitigation strategies, noting their datasetspecific nature and potential lack of generalizability. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the mitigation strategies, such as data sanitization, are datasetspecific and may not be applicable more generally. The reviewer provides a logical reasoning by stating that the framework demonstrates the possibility of data leakage but lacks generalizability. However, the comment does not provide specific examples or references to support the claim about the limitations of the mitigation strategies. This lack of detailed evidence or examples makes the claim 3, as the authors would need to further explore and substantiate the generalizability concerns themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the mitigation strategies proposed by the authors, specifically noting that they are datasetspecific and may not be applicable more generally. It points out that while the framework demonstrates the possibility of data leakage, it lacks generalizability and may have limited applicability to other LLMs or datasets. This feedback is 3 as it highlights a critical area for improvement, prompting the authors to consider more generalizable mitigation strategies. However, the comment could be more helpful if it provided specific suggestions or examples of how to enhance the generalizability of the framework. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the paper is not clear in some aspects and provides a list of questions to clarify. However, it does not specify which parts of the paper are unclear or how the authors should address these issues. The comment suggests that the weaknesses could be fixed before the final submission, but it lacks concrete guidance on how to improve the clarity. The action is implicit and vague, as the authors are left to infer what needs to be done without specific instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment indicates that the paper is not clear in some aspects and provides a list of questions to clarify. However, it does not specify which parts of the paper are unclear or which questions are being asked, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment also lacks specific suggestions or examples of what needs to be clarified. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not sufficiently clear in some aspects, but it does not provide specific examples or detailed reasoning to support this claim. The comment mentions a list of questions but does not elaborate on them, making it difficult for the authors to understand the basis of the critique. Without specific examples or detailed justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the paper, suggesting that it is not sufficiently clear in some aspects. It provides a list of questions to clarify, which could help the authors identify specific areas needing improvement. However, the comment lacks detailed guidance or suggestions on how to address these issues, such as recommending specific changes or improvements. While it points out a potential weakness, it does not provide actionable feedback to help the authors enhance their draft. Therefore, the comment is 3, as it highlights a problem but does not offer comprehensive guidance for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: whether the natural and synthetic audio signals are related to the task conditions referenced in Figure 2, and what task participants are performing. These questions imply that the authors should clarify these aspects in their draft. However, the comment does not provide explicit instructions on how to address these questions or what specific information should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide additional information but are not given concrete guidance on what to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2, as well as the task participants are performing. However, it does not specify which part of the paper these questions pertain to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its questions, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point consists of questions seeking clarification about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2, as well as the task participants are performing. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions about the paper: whether the natural and synthetic audio signals are related to the task conditions referenced in Figure 2, and what task participants are performing. These questions are relevant and could help the authors clarify important aspects of their work. However, the comment does not provide any suggestions or guidance on how to address these questions or improve the clarity of the paper. While it identifies areas that need clarification, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper did not address several other problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. However, it does not provide any explicit or implicit suggestions for how the authors might address these issues or improve their work. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a gap in the paper by noting that it did not address several other problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. However, it does not specify which part of the paper this critique pertains to, making it weakly grounded. The comment is specific in detailing the issues that were not addressed, providing a clear understanding of what the authors could consider for future work. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper did not address several problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides a general observation but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that it did not address several important problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense and facts. This feedback is valuable as it highlights areas where the paper could be expanded or improved, providing the authors with a clear direction for enhancing their work. However, the comment lacks specific suggestions or guidance on how to address these issues, which would make it more actionable. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the statistical distribution of paper venues, specifically questioning the inclusion of Arxiv papers. It suggests that Arxiv papers are not peerreviewed and are not considered formal publications, which could impact the significance of the results presented. The reviewer also expresses reservations about including Arxiv papers in the study due to the perceived quality of these papers. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer that they should provide statistical distributions and consider the implications of including Arxiv papers. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the statistical distribution of paper venues, specifically questioning the inclusion of Arxiv papers. It suggests that Arxiv papers are not peerreviewed and are not considered formal publications, which could impact the significance of the results presented. However, the comment does not specify which part of the paper discusses these venues or where the statistical distribution is presented. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in its critique of Arxiv papers but lacks grounding, aligning with a score of 1.", "verifiability_rationale": "The review point raises a claim about the statistical distribution of paper venues, specifically questioning the inclusion of Arxiv papers. The reviewer suggests that Arxiv papers are not peerreviewed and are not considered formal publications, which could impact the significance of the results presented. The comment also expresses reservations about including Arxiv papers in the study due to the perceived quality of these papers. However, the claim lacks specific evidence or references to support the assertion that Arxiv papers are not peerreviewed or that they are of low quality. The reasoning is based on the reviewer\"s intuition, which is not sufficient to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some justification but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the statistical distribution of paper venues, specifically questioning the inclusion of Arxiv papers. It suggests that Arxiv papers are not peerreviewed and are not considered formal publications, which could impact the significance of the results presented. The reviewer also expresses reservations about including Arxiv papers in the study due to the perceived quality of these papers. While the comment identifies a potential issue with the methodology and raises a valid point about the significance of the results, it lacks specific suggestions or guidance on how the authors might address these concerns. The feedback is 3 as it prompts the authors to consider the implications of their methodology and the potential impact on the results, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should focus more on the proposed problem and framework rather than devoting significant space to applications. While the comment implies that the authors should restructure their paper to prioritize the problem and framework, it does not provide specific guidance on how to achieve this or what changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the necessary adjustments without detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should focus more on the proposed problem and framework rather than spending much space on applications. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or chapter. Without explicit references to specific sections or examples, the authors cannot confidently determine where to make these changes. The comment is weakly grounded because it does not identify a specific part of the paper, and it is not specific because it lacks detailed guidance on what aspects of the problem or framework should be emphasized. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should focus more on the proposed problem and framework rather than spending much space on applications. However, the comment does not provide any reasoning, examples, or references to support why this shift in focus would be beneficial or necessary. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the authors should prioritize the discussion of the proposed problem and framework over the applications, indicating that the current focus on applications may be excessive. This feedback is 3 as it points out an area where the authors might be able to streamline their paper, potentially improving its clarity and focus. However, the comment lacks specific guidance on how to achieve this balance or what aspects of the problem and framework should be emphasized. While it provides a general direction for improvement, it does not offer detailed suggestions or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point provides a brief assessment of the paper, stating that it is \"marginally above acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it does not offer any specific guidance or suggestions for improvement. There is no explicit or implicit action for the authors to take, leaving them without a clear understanding of what needs to be done to enhance their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment does not specify which part of the paper is being addressed, making it difficult for the authors to identify the exact section or aspect that needs attention. It also lacks specificity regarding the limitations or potential negative societal impact that have been addressed, leaving the authors without clear guidance on what needs to be improved or clarified. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a subjective assessment of the paper, stating that it is \"marginally above acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it does not provide any supporting evidence, reasoning, or examples to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the assessment or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a brief assessment of the paper, stating that it is \"marginally above acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it lacks specificity and does not offer any actionable feedback or suggestions for improvement. Without detailed guidance or constructive criticism, the authors are left without a clear understanding of what aspects of their work need further attention or revision. Therefore, the comment is 1, as it does not provide any value to the authors in terms of improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the simplicity of the current dataset could be solved by an agent translating natural language into <source, path, destination> triples, then using code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their work. There is no actionable advice on how to enhance the dataset or the research impact of the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the simplicity of the current dataset, suggesting that it could be solved by an agent translating natural language into <source, path, destination> triples and using code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. However, the comment does not specify which part of the paper discusses the dataset or its simplicity, making it weakly grounded. The comment is specific in detailing the potential issues with the dataset and its implications for research impact, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the simplicity of the current dataset could be solved by an agent translating natural language into <source, path, destination> triples, then using code or search libraries. It also suggests that the natural language is generated by patterns, making natural language understanding easy. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The mention of future studies using methods like PAL or LLMs with code interpreters is a logical inference but does not provide direct evidence or detailed justification for the claim about the limited research impact. Therefore, the comment is 3, as it provides a logical basis but lacks sufficient evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies a potential limitation in the simplicity of the current dataset, suggesting that it could be solved by an agent translating natural language into <source, path, destination> triples and using code or search libraries. It also mentions that the natural language is generated by patterns, making natural language understanding easy. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the dataset\"s complexity. While it highlights a potential weakness, it lacks actionable feedback or detailed advice, leaving the authors with a general understanding of the issue but without a clear path for improvement. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests revising a statement about the maximum likelihood estimation, noting that the limitations of the proposed measure are not fairly discussed. It points out that the proposed measure does not provide a stronger theoretical connection to generalization than competing measures and is not shown to outperform them experimentally. While the comment implies that the authors should revise the statement to address these limitations, it does not provide specific guidance on how to revise it or what additional information should be included. The action is implicit and somewhat vague, as the authors know they need to revise the statement but may not be entirely sure of the exact changes needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"25: masures 242,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be revised, namely, the statement about the maximum likelihood estimation and the limitations of the proposed measure. The comment provides detailed reasoning, pointing out that the limitations of the proposed measure are not fairly discussed and that it lacks a stronger theoretical connection to generalization compared to competing measures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the limitations of the proposed measure are not fairly discussed, specifically regarding its theoretical connection to generalization and its experimental performance compared to competing measures. The reviewer provides a detailed explanation of why these limitations are not adequately addressed, which supports the claim. However, the comment could be strengthened by referencing specific sections or experiments where these limitations are not discussed, or by providing examples of competing measures for comparison. Overall, the claim is 4, as it provides a logical reasoning but lacks detailed references or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the limitations of the proposed measure are not fairly discussed. It points out that the measure does not provide a stronger theoretical connection to generalization than competing measures and is not shown to outperform them experimentally. This feedback is clear and actionable, as it directs the authors to revise their statement and provide a more comprehensive discussion of the limitations. However, the comment could be more helpful if it offered suggestions on how to address these limitations or provided examples of how other measures have been evaluated. Overall, the comment is 4 as it highlights a critical area for improvement and guides the authors toward enhancing their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of results for finetuned opensource LLMs, which the reviewer considers important for a domainspecific benchmark. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to include these results. The lack of concrete instructions or suggestions leaves the authors uncertain about how to implement the suggested change. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of results for finetuned opensource LLMs, which the reviewer considers important for a domainspecific benchmark. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment. Without explicit references, the authors may find it challenging to identify the exact area needing attention. The comment is specific in its critique of the lack of results but lacks grounding, as it does not clearly indicate where in the paper this issue should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of results for finetuned opensource LLMs is important for a domainspecific benchmark. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these results are crucial or how they would impact the benchmark. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of results for finetuned opensource LLMs, which the reviewer considers important for a domainspecific benchmark. This feedback is clear and actionable, as it highlights a gap in the paper that the authors can address by including these results. However, the comment could be more helpful if it provided suggestions on how to incorporate these results or why they are crucial for the benchmark. Despite this, the comment still offers valuable guidance for the authors to enhance their draft. Therefore, it is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the regression model, including how it is trained, what the input and output are, and how the parameter space differs for models with different feature sizes. It also asks whether the model performance is affected by the number of parameters. These questions are explicit and provide clear guidance on what the authors need to address in their draft. The feedback is concrete, as it specifies the exact information that needs to be included or clarified. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises questions about the regression model, specifically asking about its training, input, output, parameter space, and the impact of parameter number on model performance. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in detailing what aspects of the regression model need clarification, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the regression model, such as how it is trained, what the input and output are, and how the parameter space differs for models with different feature sizes. It also asks whether the model performance is affected by the number of parameters. These questions are factual and do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the regression model, including how it is trained, what the input and output are, and how the parameter space differs for models with different feature sizes. It also asks whether the model performance is affected by the number of parameters. These questions are specific and actionable, as they prompt the authors to clarify and provide detailed information about their regression model. By addressing these questions, the authors can enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it provided suggestions on how to address these questions or offered guidance on potential improvements to the model. Overall, the feedback is 4 as it directs the authors to important areas that need clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to add more ablation experiments to demonstrate the effectiveness of their proposed model. It specifies the areas that need further exploration, such as the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This feedback provides clear and concrete guidance on what the authors need to do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model, specifically mentioning the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. However, it does not specify which part of the paper these experiments should be added to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the role of different updating methods and reweighting after selection. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model. It provides specific examples of what these experiments should focus on, such as the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This level of detail and specificity in suggesting additional experiments makes the claim 4, as it provides a clear direction for the authors to enhance their work. However, the comment could be strengthened by referencing similar experiments or studies that support the need for these ablation tests. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should conduct additional ablation experiments to demonstrate the effectiveness of their proposed model. It identifies two key areas for exploration: the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This feedback is clear and detailed, offering the authors a concrete path to enhance their draft by providing more evidence and insights into the performance of their model. However, the comment could be more helpful if it included suggestions on how to design these ablation experiments or what specific metrics to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experimental results can be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also mentions adaptive mechanisms from Phan et al. (2017, 2019, 2020) and other related works as potential baselines for comparison. While the comment implies that the authors should consider using more complex datasets and adaptive mechanisms, it does not provide explicit instructions on how to implement these suggestions or which specific datasets or adaptive mechanisms to use. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the datasets used in the experiments, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the limited number of dimensions in the datasets and suggests using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. Additionally, it provides references to adaptive mechanisms and related works that could be considered as baseline approaches for comparison. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results can be improved by using more complex datasets and learning tasks. It provides specific examples of datasets with limited dimensions, such as dim=24 in power consumption, dim=6 in real estate valuation, and dim=30 in breast cancer detection. The suggestion to use image datasets with thousands of dimensions and deep learning tasks is supported by logical reasoning, as it implies that the current datasets are insufficiently challenging. The mention of adaptive mechanisms from Phan et al. (2017, 2019, 2020) and other related works provides a basis for comparison, making the claim 4. However, the comment could be strengthened by providing more detailed examples or references to specific image datasets or deep learning tasks. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental results by pointing out the limited number of dimensions in the datasets used. It suggests that the work could be extended to more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. Additionally, it mentions adaptive mechanisms from Phan et al. (2017, 2019, 2020) and other related works as potential baselines for comparison. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their experimental setup and potentially expanding the scope of their work. However, the comment could be more helpful if it included suggestions on how to select or access more complex datasets or detailed guidance on implementing the adaptive mechanisms. Overall, the comment is 4 as it offers valuable insights and direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the experiment results, specifically questioning the effectiveness of PRESENCE and the relationship between temperature $\tau$ and downstream performance. It suggests that using a positive or negative $\tau$ could yield improvement over no reweighting, which makes the reviewer curious about the importance of reweighting. Additionally, the comment points out that the results from Table 4 do not show an advantage of using PRESENCE. While the comment identifies areas of concern and raises questions, it does not provide explicit guidance on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer what changes might be necessary to address the concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Table 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experiment results, particularly the relationship between temperature $\tau$ and downstream performance, and the lack of advantage shown in Table 4. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the experiment results, specifically questioning the effectiveness of PRESENCE and the relationship between temperature $\tau$ and downstream performance. The reviewer suggests that using a positive or negative $\tau$ could yield improvement over no reweighting, which makes them curious about the importance of reweighting. Additionally, the comment points out that the results from Table 4 do not show an advantage of using PRESENCE. While the comment provides a logical reasoning and raises valid questions, it lacks specific examples or references to support the claims fully. The authors would need to investigate these points further to address the concerns. Therefore, the comment is 3, as it provides a basis for further exploration but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment raises concerns about the experiment results, specifically questioning the effectiveness of PRESENCE and the relationship between temperature $\tau$ and downstream performance. It points out that the results do not seem to justify the twostage pretraining and suggests that using a positive or negative $\tau$ could yield improvement over no reweighting. This makes the reviewer curious about the importance of reweighting. Additionally, the comment notes that the results from Table 4 do not show an advantage of using PRESENCE. While the comment identifies specific areas of concern and raises questions, it does not provide detailed guidance or suggestions on how the authors might address these issues or improve their draft. The feedback is 3 as it highlights potential weaknesses but lacks actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific observation from Table 2, noting that the results for k=1 are already better than the baselines. It suggests that the performance gain might be due to a reason other than applying Eq.10. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this observation or what changes, if any, should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular observation regarding the results for k=1 being better than the baselines, and it suggests a potential reason for this, hinting at a different performance gain than expected. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the results for k=1 in Table 2 are already better than the baselines, suggesting that the performance gain might be due to a reason other than applying Eq.10. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment points out a specific observation from Table 2, noting that the results for k=1 are already better than the baselines. It suggests that this might indicate a performance gain for a reason other than applying Eq.10. While the comment identifies a potential issue, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this observation or improve their analysis. The feedback is 3 as it highlights a potential area of concern, but it does not offer detailed advice or specific steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed method lacks solid grounding and that the choice of mixedinteger programming is not fully justified. It also notes that the advantages of this approach over alternative methods are unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or suggest specific actions to take. The feedback is implicit, as it highlights areas that need improvement but does not offer concrete steps for the authors to follow. As a result, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on how to implement those improvements.", "grounding_specificity_rationale": "The comment addresses the lack of solid grounding for the proposed method, specifically mentioning the choice of mixedinteger programming and its advantages over alternative approaches. However, it does not specify which part of the paper this critique pertains to, such as a particular section or subsection where the method is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what is lacking, namely the justification for the choice of mixedinteger programming and the comparison with alternative approaches. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks solid grounding and that the choice of mixedinteger programming is not fully justified. It also notes that the advantages of this approach over alternative methods are unclear. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 2, as it lacks sufficient support to be fully actionable.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of solid grounding for the proposed method. It points out that the choice of mixedinteger programming is not fully justified and that its advantages over alternative approaches are unclear. This feedback is valuable as it highlights a critical area that needs further explanation or justification. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these issues, such as recommending a comparison with other methods or suggesting additional experiments to demonstrate the advantages. Overall, the comment is 3 as it directs the authors\" attention to a crucial aspect of their work that requires clarification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment consists of two separate points. The first point identifies a confusion in the notation used in Equation 1, specifically the use of \"c\" instead of \"o.\" This is an explicit statement that provides clear guidance on what needs to be corrected. The second point notes the absence of a reference to Pedersen et al 2007 in the reference section. This is also an explicit action, as it instructs the authors to include the missing reference. Both points are concrete, as they specify exactly what needs to be corrected or added. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1\" and \"Line 361,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the notation in Equation 1 and the missing reference to Pedersen et al 2007 in the reference section. This level of detail provides clear guidance on what needs to be corrected, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two separate claims: the first is about the confusion in notation in Equation 1, and the second is about the missing reference to Pedersen et al 2007. The claim regarding the notation is straightforward and logical, as it points out a potential source of confusion for readers. The claim about the missing reference is also clear and verifiable, as it directly identifies a specific omission in the reference section. Both claims are supported by clear and specific observations, making them 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides two specific and actionable pieces of feedback. First, it points out a confusion in the notation used in Equation 1, suggesting that \"c\" is used instead of \"o,\" which could lead to confusion for readers. This feedback is clear and actionable, as it directs the authors to correct the notation to improve clarity. Second, it notes the absence of a reference to Pedersen et al 2007 in the reference section, which is a straightforward and important correction to make. Both points are specific and provide clear guidance on how to improve the draft, making the comment 5 for the authors. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the second contribution of the paper, combining SSMs with Attention, is not new and has been proposed before in MEGA and Blockstate Transformer. It suggests that the similarities and differences between S++ and this work should be discussed thoroughly and ablated. This feedback provides a clear and explicit action for the authors to take, which is to discuss and ablate the similarities and differences between their work and existing literature. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second contribution of the paper, the proposal to combine SSMs with Attention, and references specific works like MEGA and Blockstate Transformer. It also mentions Figure 5, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific in detailing what needs to be discussed and ablated, namely the similarities and differences between S++ and existing work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second contribution of the paper, combining SSMs with Attention, is not new and has been proposed before in MEGA and Blockstate Transformer. The reviewer supports this claim by referencing specific works, including MEGA and Blockstate Transformer, and provides a link to the latter. This level of detail and specific references make the claim 5, as it provides clear evidence and sources for the reviewer\"s assertion. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the second contribution of the paper, which is the proposal to combine SSMs with Attention. It points out that this idea is not new and has been proposed before in MEGA and Blockstate Transformer, referencing specific works. The comment also notes that the architecture in Figure 5 appears similar to the proposed architecture in Mega, suggesting that the similarities and differences between S++ and this work should be discussed thoroughly and ablated. This feedback is clear and actionable, providing the authors with specific guidance on how to address the issue of novelty and differentiate their work from existing literature. By suggesting a thorough discussion and ablation, the comment offers a constructive path for improvement, making it 5. Therefore, the comment deserves a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the rationale behind reporting results on knowledge transfer in only a few select environments. While it implies that the authors should provide a justification for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide a justification but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind reporting results on knowledge transfer in only a few select environments, specifically mentioning section 4.3. This provides full grounding as it explicitly references a specific section of the paper, allowing the authors to accurately identify the part being addressed. The comment is also specific because it clearly specifies what needs to be addressed: the reason for reporting results on a limited number of environments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the rationale behind reporting results on knowledge transfer in only a few select environments. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind reporting results on knowledge transfer in only a few select environments. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their reporting. The comment lacks actionable feedback, leaving the authors with only a vague understanding of what needs to be clarified or improved. Therefore, it is rated as 2, as it provides minimal value for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of specific ablation experiments and suggests that the performance improvement could be attributed to pretrained weights rather than the method proposed in the manuscript. It also notes that the absence of detailed ablation comparisons may lead to confusion. While the comment implies that the authors should conduct specific ablation experiments to clarify the contribution of their method, it does not provide explicit guidance on how to conduct these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and determine the specifics themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of specific ablation experiments and the potential attribution of performance improvement to pretrained weights rather than the method proposed in the manuscript. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in identifying the need for detailed ablation comparisons to avoid confusion, but it lacks grounding as it does not pinpoint the exact part of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of specific ablation experiments could lead to confusion about the contribution of the proposed method. However, it does not provide specific examples or detailed reasoning to support this claim. The comment suggests that the performance improvement could be attributed to pretrained weights, but this is not substantiated with evidence or references. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of specific ablation experiments. It suggests that the performance improvement could be attributed to pretrained weights rather than the method proposed in the manuscript, which could lead to confusion. This feedback is clear and actionable, as it highlights an important area for improvement that could significantly enhance the paper\"s clarity and contribution. By recommending detailed ablation comparisons, the comment provides the authors with a specific direction for enhancing their draft. However, it could be more helpful if it offered suggestions on how to conduct these ablation experiments or what specific aspects to focus on. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and robustness of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the lemmatizer stripping suffixes from words that are already lemmas but end with a suffix substring. However, it does not provide any explicit or implicit actions for the authors to take in response to this concern. There is no guidance on how to address this issue or improve the lemmatizer\"s performance in realworld texts with evolving vocabularies. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific limitation of the lemmatizer, namely its behavior when stripping suffixes from words that are already lemmas but end with a suffix substring. However, it does not specify which part of the paper discusses this limitation, making it weakly grounded. The comment is specific in detailing the concern about the lemmatizer\"s behavior in realworld texts with evolving vocabularies. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the described limitation of the lemmatizer, which strips suffixes from words that are already lemmas but end with a suffix substring, is a major concern for realworld texts with evolving vocabularies. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the significance of this limitation or how it affects their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation of the lemmatizer, which is its behavior when stripping suffixes from words that are already lemmas but end with a suffix substring. This is a critical issue that could impact the accuracy and effectiveness of the lemmatizer in realworld texts with evolving vocabularies. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or improve the lemmatizer\"s performance. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their work. Therefore, the comment is 3, as it highlights an important issue but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the use of pretrained DGCNN for semantic segmentation in Table 2, suggesting that the comparison of segmentation metrics is not meaningful under this condition. The reviewer implies that the comparison is only showing that the segmentation of the methods combined with DGCNN is worse than the proposed method. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and vague, as the authors are left to infer that they should reconsider the comparison or provide additional context. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the comparison of segmentation metrics using pretrained DGCNN is not meaningful, as it only shows that the segmentation of the methods combined with DGCNN is worse than the proposed method. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison of segmentation metrics using pretrained DGCNN in Table 2 is not meaningful, as it only shows that the segmentation of the methods combined with DGCNN is worse than the proposed method. The comment provides a logical reasoning for why the comparison is not meaningful, which is based on the assumption that the pretrained DGCNN is not a fair comparison. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the reasoning and potentially provide additional context or evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison of segmentation metrics in Table 2, where pretrained DGCNN is used for semantic segmentation. It points out that the comparison is not meaningful, as it only shows that the segmentation of the methods combined with DGCNN is worse than the proposed method. This feedback is clear and actionable, as it highlights a potential flaw in the experimental setup and suggests that the authors should reconsider the comparison or provide additional context to make it more meaningful. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative comparisons that might be more informative. Overall, the comment is 4, as it directs the authors to a specific area that needs improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that it is challenging to obtain rules in realworld applications and proposes that statistical rules learned from data may be feasible. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the difficulty in obtaining rules or how to implement statistical rules in their work. The comment lacks actionable advice, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment does not specify which part of the paper it addresses, making it difficult for the authors to identify the exact section that needs attention. It also lacks specificity regarding what aspect of \"rules\" is being discussed or how the suggestion of using statistical rules might improve the paper. Without clear grounding or specificity, the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that it is challenging to obtain rules in realworld applications and proposes that statistical rules learned from data may be feasible. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that statistical rules are a viable alternative. Without additional context or evidence, the authors may find it difficult to understand the basis of the suggestion or how to implement it in their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the difficulty in obtaining rules in realworld applications and suggests that statistical rules learned from data may be feasible. However, it lacks specificity and does not provide any actionable advice or suggestions for the authors to consider. Without detailed guidance or examples, the comment does not offer much value in helping the authors improve their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a comparison with dynamic sparse trainingbased and other sparsitybased methods. While the comment implies that this comparison is missing, it does not explicitly instruct the authors to add it. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct the comparison or which methods to include. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the comparison with dynamic sparse trainingbased and other sparsitybased methods is missing. However, it does not specify which part of the paper this comparison should be included in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in suggesting the type of comparison that should be added, but it lacks grounding as it does not mention any specific sections or parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a comparison with dynamic sparse trainingbased and other sparsitybased methods is missing. However, it does not provide any specific reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the importance of this comparison. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that a comparison with dynamic sparse trainingbased and other sparsitybased methods is missing. This feedback is 3 as it points out an area where the authors could enhance their work by providing additional context and comparison. However, the comment lacks specificity and does not offer detailed guidance on how to conduct this comparison or which specific methods to include. While it highlights an area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the reasoning presented in the paper regarding the intractability of $p_\u03b8(y|x)$ in a latent variable model. The reviewer suggests that while $p_\u03b8(y|x, z)$ may be tractable, the intractability of $p_\u03b8(y|x)$ could still be due to other factors, such as a Bernoulli likelihood with a Gaussian posterior. This comment provides a specific example to illustrate the point, offering a concrete suggestion for the authors to consider. However, it does not explicitly instruct the authors to revise their reasoning or make specific changes to the draft. The action is implicit but concrete, as the authors can infer that they need to reconsider their explanation of intractability. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific part of the paper, \"The intractability of $p_\u03b8(y|x)$ in a latent variable model is due to the intractability of $p_\u03b8(z|x)$, since $p_\u03b8(y|x, z)$ is tractable,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly points out the issue with the reasoning presented in the paper, suggesting that the intractability of $p_\u03b8(y|x)$ could be due to factors other than $p_\u03b8(z|x)$, such as a Bernoulli likelihood with a Gaussian posterior. This provides a clear direction for the authors to reconsider their explanation. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point critiques the reasoning in the paper regarding the intractability of $p_\u03b8(y|x)$ in a latent variable model. The reviewer provides a counterexample, suggesting that both the posterior and the likelihood can be tractable but $p_\u03b8(y|x)$ may still be intractable, as in the case of a Bernoulli likelihood with a Gaussian posterior. This reasoning is logical and provides a clear example to support the claim, making the comment 4. However, the comment could be strengthened by referencing specific literature or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the reasoning presented in the paper regarding the intractability of $p_\u03b8(y|x)$ in a latent variable model. It points out that the current explanation suggests that $p_\u03b8(y|x)$ is intractable because $p_\u03b8(z|x)$ is intractable, which may not be the case. The reviewer provides a specific example of a Bernoulli likelihood with a Gaussian posterior to illustrate that both the posterior and the likelihood can be tractable but $p_\u03b8(y|x)$ may still be intractable. This feedback is clear and actionable, as it prompts the authors to reconsider their explanation and potentially revise their reasoning. However, the comment could be more helpful if it offered additional suggestions or examples on how to address this issue. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the collected datasets are inaccessible outside of the associated groups, making the results irreproducible. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the datasets more accessible or how to improve reproducibility. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the collected datasets are inaccessible outside of the associated groups, making the results irreproducible. However, it does not specify which part of the paper this issue pertains to, such as a specific section or methodology where the datasets are discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how to make the datasets more accessible. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the collected datasets are inaccessible outside of the associated groups, making the results irreproducible. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to the inaccessible datasets or their impact on reproducibility, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the collected datasets are inaccessible outside of the associated groups, which makes the results irreproducible. This is a critical concern that the authors need to address to ensure the validity and reproducibility of their work. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might make the datasets more accessible or address the reproducibility issue. Without detailed feedback or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a critical problem but does not offer actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly questions whether there is a missing equation before \"where p is the firing rate\" in section 3.4.1. This is a direct and clear action for the authors to take, as it prompts them to verify the presence of the equation and, if necessary, to add it. The comment provides a specific and concrete instruction, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"sec 3.4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the presence of a missing equation before a specific phrase, \"where p is the firing rate.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual question about the presence of an equation in a specific section of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it questions the presence of a missing equation in a particular section of the paper. By pointing out this potential omission, the reviewer provides clear guidance for the authors to verify and, if necessary, correct the draft. This feedback is valuable as it directs the authors to a specific area that may need attention, helping them improve the clarity and completeness of their manuscript. However, the comment could be more helpful if it included a suggestion on how to address the issue or why the equation is important. Overall, the comment is 4, as it effectively guides the authors toward a specific improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should conduct experiments to evaluate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This is a clear and direct action for the authors to take, providing specific guidance on what needs to be done to improve their draft. The comment is concrete in its instructions, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"sentiment word detection and correction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the evaluation of the effects of the sentiment word position detection module and the predicted sentiment word candidates. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation of sentiment word detection and correction is lacking, as these are key ideas in the SWRM framework. The reviewer provides a logical reasoning by stating that the detection and correction of sentiment words are crucial components of the framework, implying that their evaluation is necessary. However, the comment does not provide specific examples or references to support the claim, which would strengthen the justification. Therefore, the claim is 3, as it lacks detailed evidence or examples to fully substantiate the need for evaluation.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks evaluation, namely the detection and correction of sentiment words. It suggests that since these are key ideas in the SWRM framework, experiments should be conducted to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by conducting additional experiments. However, the comment could be more helpful if it offered suggestions on how to design these experiments or what specific metrics to consider. Overall, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the performance of incontext learning baselines, such as static fewshot and chainofthought, which underperform the backbone in many items. It suggests that this could be due to the large variance of results or the uncareful design of the baselines. The comment implies that the authors should provide more explanations to support the reliability of their claims. While the action is implicit, it is clear that the authors need to address the issue of unreliable results by providing additional explanations. The feedback is 3 as it identifies a specific area for improvement but lacks detailed guidance on how to provide these explanations.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the performance of incontext learning baselines, such as static fewshot and chainofthought, which underperform the backbone in many items. It suggests that this could be due to the large variance of results or the uncareful design of the baselines. The comment implies that more explanations are needed to support the reliability of the claims. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the need for more explanations, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are mysterious results where incontext learning baselines, such as static fewshot and chainofthought, underperform the backbone in many items. The reviewer suggests that this could be due to the large variance of results or the uncareful design of the baselines. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand the basis of the critique. The suggestion for more explanations is valid, but without additional context or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the performance of incontext learning baselines, such as static fewshot and chainofthought, which underperform the backbone in many items. It suggests that this could be due to the large variance of results or the uncareful design of the baselines. The comment implies that the authors should provide more explanations to support the reliability of their claims. While the feedback highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative explanations or methods to reduce variance. This limits the comment\"s usefulness, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of clarity regarding the key innovation driving the improvements in GFNSeqEditor. It suggests that the paper should better articulate what novel techniques or insights lead to the claimed improvements, which would enhance the reader\"s understanding of the method\"s unique value. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations but are not given specific guidance on what aspects to focus on. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of the key innovation in GFNSeqEditor, specifically the claim that it can produce novel sequences with improved properties. It suggests that the paper should better articulate what novel techniques or insights lead to these improvements, which would enhance the reader\"s understanding of the method\"s unique value. However, the comment does not explicitly mention which part of the paper this issue pertains to, such as a particular section or subsection. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what needs to be addressed, namely, the need for better articulation of the key innovation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding the key innovation driving the improvements in GFNSeqEditor. It suggests that the paper should better articulate what novel techniques or insights lead to the claimed improvements. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the ambiguity or how to address it. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the specific areas that need clarification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of ambiguity in the paper regarding the key innovation driving the improvements in GFNSeqEditor. It suggests that the paper should better articulate what novel techniques or insights lead to the claimed improvements, which would enhance the reader\"s understanding of the method\"s unique value. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by clarifying the key innovation. However, the comment could be more helpful if it offered examples or specific suggestions on how to articulate these improvements. Overall, the comment is 4, as it guides the authors toward enhancing the clarity and impact of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should demonstrate the faithfulness of their proposed approach by conducting a simple experiment to show that it is less susceptible to biases compared to other methods. While the comment implies that the authors should conduct an experiment, it does not provide specific guidance on how to design or execute this experiment. The action is explicit but somewhat vague, as the authors know they need to conduct an experiment but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the faithfulness of their proposed approach by conducting a simple experiment to show that it is less susceptible to biases compared to other methods. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its request for a demonstration of faithfulness and a comparison with other methods, but it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate the faithfulness of their proposed approach by conducting a simple experiment to show that it is less susceptible to biases compared to other methods. However, the comment does not provide any specific reasoning, examples, or references to support why this demonstration is necessary or how it would be beneficial. Without additional context or evidence, the claim remains vague and 1, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should demonstrate the faithfulness of their proposed approach through a simple experiment. It highlights the need to show that the method is less susceptible to biases compared to other methods, which is a critical aspect of the paper\"s claims. While the comment provides a clear direction for improvement, it lacks detailed guidance on how to conduct the experiment or what specific biases should be tested. This limits the comment\"s usefulness, as the authors may still need to invest time and effort to determine the exact steps needed to address the feedback. Therefore, the comment is 3, as it points out a significant area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that most realworld applications are continuous and difficult to discretize, questioning the suitability of the proposed method that operates with stateaction spaces. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their motivation. The comment implies that the authors should reconsider their approach or provide additional justification, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the motivation for the proposed method, specifically questioning its applicability to realworld applications due to its reliance on stateaction spaces. However, it does not specify which part of the paper this critique is based on, such as a particular section or figure where the motivation is discussed. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. The comment is specific in its critique of the method\"s applicability, but without clear grounding, it is 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that most realworld applications are continuous and difficult to discretize, questioning the suitability of the proposed method that operates with stateaction spaces. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the justification themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the manuscript by pointing out that most realworld applications are continuous and difficult to discretize, questioning the suitability of the proposed method that operates with stateaction spaces. This feedback highlights a critical issue that the authors need to address, specifically the applicability of their method to realworld scenarios. However, the comment does not provide specific suggestions or guidance on how the authors might overcome this limitation or improve their method\"s applicability. While it raises an important concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the experiment results are not very competitive compared to the stateoftheart (SOTA) methods, with only minor improvements. It also notes that the presentation of the main results in Table 1 is unclear due to differences in backbones compared to prior methods. The reviewer suggests moving the baseline to the ablation study and showing only the proposed method. While the comment identifies specific issues with the results and presentation, it does not provide explicit guidance on how to address these issues or improve the draft. The actions are implicit and somewhat vague, as the authors need to infer that they should focus on improving the competitiveness of their results and clarifying the presentation of Table 1. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiment results, specifically noting that they are not very competitive compared to the stateoftheart (SOTA) methods and that the presentation of the main results in Table 1 is unclear due to differences in backbones compared to prior methods. It also suggests moving the baseline to the ablation study and showing only the proposed method. While the comment does not explicitly mention specific sections or tables, the authors can infer that it relates to the results and tables discussed in the paper. The comment is specific in detailing what needs to be addressed, such as the competitiveness of the results and the clarity of the presentation. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiment results are not very competitive compared to the stateoftheart (SOTA) methods, with only minor improvements. It also critiques the presentation of the main results in Table 1, noting that the different backbones compared to prior methods make the results unclear. The reviewer suggests moving the baseline to the ablation study and showing only the proposed method. While the comment provides some reasoning by comparing the results to SOTA methods, it lacks specific examples or references to support the claim about the minor improvements. The suggestion to move the baseline to the ablation study is logical but not fully substantiated. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the lack of competitiveness of the experiment results compared to stateoftheart (SOTA) methods and the unclear presentation of the main results in Table 1 due to differences in backbones compared to prior methods. It suggests moving the baseline to the ablation study and showing only the proposed method, which is a clear and actionable suggestion to improve the clarity and focus of the results. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to enhance the competitiveness of the results or improve the presentation of Table 1. Overall, the feedback is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the endusers who utilize the model. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions on how to achieve this clarification. The action is implicit and somewhat vague, as the authors need to infer that they should specify the copyright protection mechanisms\" purpose. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the endusers who utilize the model. However, it does not specify which part of the manuscript this issue pertains to, such as a specific section or discussion. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in suggesting what needs to be clarified, it is 1 because it does not indicate where in the manuscript this issue arises. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the endusers who utilize the model. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the manuscript, suggesting that the copyright scenario could be clarified. It highlights the need to specify whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the endusers who utilize the model. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by clarifying the copyright scenario. However, the comment could be more helpful if it offered examples or further guidance on how to achieve this clarification. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of theoretical justification or intuitive explanation for why the lowrank adapter acquires domainagnostic information, while the highrank adapter collects domainspecific knowledge. However, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should provide a theoretical or intuitive explanation, but it lacks concrete steps or examples on how to achieve this. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper regarding the theoretical justification and intuitive explanation for why the lowrank adapter acquires domainagnostic information, while the highrank adapter collects domainspecific knowledge. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this discussion is located, the comment lacks full grounding. It is specific in detailing what is missing, namely a theoretical or intuitive explanation, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no theoretical justification or intuitive explanation for why the lowrank adapter acquires domainagnostic information, while the highrank adapter collects domainspecific knowledge. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of theoretical justification or intuitive explanation for why the lowrank adapter acquires domainagnostic information, while the highrank adapter collects domainspecific knowledge. This is a critical observation that highlights a fundamental weakness in the paper\"s theoretical foundation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing potential theoretical frameworks or methods for explaining the observed behavior. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the statement on local explanations in line 154, asking why it is true that local models will only be nontrivial if the data point is near a decision boundary. It also suggests an alternative approach, such as measuring differences in probabilities based on feature changes. While the comment implies that the authors should provide a justification for their statement or consider an alternative approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the statement about local explanations and suggests an alternative approach, such as measuring differences in probabilities based on feature changes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the statement on local explanations, asking why it is true that local models will only be nontrivial if the data point is near a decision boundary. It suggests an alternative approach, such as measuring differences in probabilities based on feature changes. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the current approach is insufficient or why the suggested alternative is more effective. Without additional context or explanation, the claim remains 1, as the authors are left without clear guidance on how to address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the statement on local explanations, specifically questioning why local models would only be nontrivial if the data point is near a decision boundary. It suggests an alternative approach, such as measuring differences in probabilities based on feature changes. This feedback is 3 as it prompts the authors to reconsider their explanation and potentially explore an alternative method for local explanations. However, the comment could be more helpful if it provided additional context or examples to support the suggested alternative approach. Overall, the comment offers a direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experiments only report results on ImageNet and suggests that results on classic datasets like CIFAR10 and CIFAR100 should also be included. This provides a clear and direct action for the authors to take, which is to expand their experimental results to include these additional datasets. The comment is explicit and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments and the datasets being addressed, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies what is missing, namely the inclusion of results on classic datasets like CIFAR10 and CIFAR100. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments only report results on ImageNet and suggests that results on classic datasets like CIFAR10 and CIFAR100 should also be included. This is a factual statement that does not require verification or justification. It is a request for additional information or data, which is not a claim that needs to be substantiated. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper, noting that the experiments only report results on ImageNet and suggesting that results on classic datasets like CIFAR10 and CIFAR100 should also be included. This feedback is clear and actionable, as it provides a direct suggestion for expanding the experimental scope to include additional datasets. By addressing this point, the authors can enhance the comprehensiveness and robustness of their experimental results, which is a valuable contribution to the paper. However, the comment could be more helpful if it provided additional context or rationale for why including these datasets is important. Overall, the feedback is 4, as it guides the authors toward a specific improvement that can enhance the quality of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a confusion regarding the DinoSR part in Figure 1, specifically noting that the softmax layer is not clearly shown despite the encoder not including that layer. The comment contrasts this with the clarity of the figure in the original DinoSR paper. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this confusion or improve the clarity of the figure. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the figure or its description. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the confusion regarding the DinoSR part, noting that the softmax layer is not clearly shown despite the encoder not including it. The comment contrasts this with the clarity of the figure in the original DinoSR paper. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the DinoSR part in Figure 1 is confusing because the softmax layer is not clearly shown, despite the encoder not including that layer. The comment contrasts this with the clarity of the figure in the original DinoSR paper. While the comment provides a logical reasoning for the confusion, it lacks specific examples or references to the original DinoSR paper to fully substantiate the claim. This makes the comment 3, as it requires additional context or references to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 1, specifically regarding the DinoSR part and the absence of the softmax layer in the encoder, as described in the text. It contrasts this with the clarity of the figure in the original DinoSR paper, providing a clear and actionable suggestion for improvement. By pointing out the discrepancy between the text description and the figure, the comment offers a concrete way for the authors to enhance the clarity and accuracy of their presentation. This feedback is valuable as it directly addresses a potential source of confusion for readers, making it 4. However, it could be more helpful if it included suggestions on how to resolve the issue or provided examples of how to improve the figure. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should review related work on causal inference and discuss more works related to the paper. However, it does not specify which aspects of the related work should be reviewed or how these works relate to the paper. The action is implicit and somewhat vague, as the authors are left to infer what specific aspects of the related work need to be discussed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests reviewing related work on causal inference and mentions specific references (1, 2, 3). However, it does not specify which part of the paper should include this review or how it relates to the current content. The authors can infer that it pertains to the literature review or discussion sections, but the comment lacks full grounding as it does not explicitly mention these sections. The suggestion to review more related work is specific, but the lack of grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more related work on causal inference should be reviewed, specifically mentioning references 1, 2, and 3. However, the comment does not provide any reasoning or justification for why these specific works should be included or how they relate to the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of these references or how they fit into the discussion. Therefore, the claim is considered 2, as it lacks sufficient support to fully substantiate the need for additional related work.", "helpfulness_rationale": "The comment suggests that the authors should review more related work on causal inference, specifically mentioning references 1, 2, and 3. While it identifies a potential area for improvement by pointing out the need for a broader discussion of related work, the comment lacks specificity and does not provide guidance on how to integrate these references into the paper or what aspects of the existing work should be compared or contrasted. The feedback is 3 as it highlights a gap in the literature review, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that sections 3.1 and 3.2 could have been avoided by using the LLM2Vec encoder, which is already cited in the paper. It implies that the authors should provide a justification for not adopting this approach and suggests conducting ablation studies to validate the decision. While the comment explicitly states the need for a justification and suggests an action (conducting ablation studies), it does not provide specific guidance on how to conduct these studies or what aspects to focus on. The action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the potential avoidance of these sections by using the LLM2Vec encoder, and suggests that the reasoning for not adopting this approach should be validated with ablation studies. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that sections 3.1 and 3.2 could have been avoided by using the LLM2Vec encoder, which is already cited in the paper. It suggests that the reasoning for not adopting this approach is unclear and should be validated with ablation studies. While the comment provides a logical reasoning for the claim, it lacks specific examples or detailed justification for why the LLM2Vec encoder should have been used. This makes the claim 3, as it provides a basis for the suggestion but requires more detailed evidence or explanation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the structure of the paper, specifically suggesting that sections 3.1 and 3.2 could have been avoided by using the LLM2Vec encoder, which is already cited in the paper. It raises a valid point about the need for a clear justification for not adopting this approach and suggests conducting ablation studies to validate the decision. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by either justifying their choice or conducting the suggested studies. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation studies or what specific aspects to focus on. Overall, the comment is 4, as it effectively guides the authors toward improving their draft by addressing a structural issue and providing a clear path forward."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and lack realworld problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should include realworld problems, how they should go about it, or what specific changes are needed to address this issue. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments that compare the proposed Batch BORE method with existing baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the absence of realworld problems in the experiments, providing clear guidance on what is missing. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and lack realworld problems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a significant limitation in the experimental setup, noting that the comparison of the proposed Batch BORE method with existing baselines only uses synthetic objective functions and lacks realworld problems. This is a critical observation that highlights a potential weakness in the paper\"s evaluation and generalizability. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their experimental setup. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it identifies a significant issue but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential challenge in distinguishing roles using explanationfocused cues, suggesting that LLMs may rely more on language style than informational depth. It implies that a detailed analysis of benchmark sentence differences between explanation and listenerfocused parts could clarify these findings. While the comment identifies an area for further analysis, it does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to proceed. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the challenge of distinguishing roles using explanationfocused cues, suggesting that LLMs may rely more on language style than informational depth. It implies that a detailed analysis of benchmark sentence differences between explanation and listenerfocused parts could clarify these findings. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit reference makes it challenging to pinpoint the exact location. The comment is specific in suggesting a detailed analysis to clarify the findings, but without grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that distinguishing roles using explanationfocused cues is challenging, suggesting that LLMs may rely more on language style than informational depth. The comment provides a logical reasoning by proposing a detailed analysis of benchmark sentence differences between explanation and listenerfocused parts to clarify these findings. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the challenge and how the proposed analysis could address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential challenge in distinguishing roles using explanationfocused cues, suggesting that LLMs may rely more on language style than informational depth. It proposes a detailed analysis of benchmark sentence differences between explanation and listenerfocused parts as a way to clarify these findings. This feedback is 3 as it points out a specific area for further investigation and provides a suggestion for how to address it. However, the comment lacks detailed guidance on how to conduct this analysis or what specific aspects to focus on, which limits its usefulness. To be more helpful, the comment could include more detailed instructions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper uses acronyms heavily, which affects readability, and specifically mentions that the acronym \"DU\" is not clearly defined. This feedback provides a clear and explicit action for the authors to take: define the acronym \"DU\" to improve readability. The comment is direct and provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of heavy use of acronyms, which affects readability, and specifically points out the lack of a clear definition for the acronym \"DU.\" This allows the authors to accurately identify the part of the paper being addressed, namely the sections where acronyms are used. The comment is also specific because it highlights a particular acronym that needs clarification, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s heavy use of acronyms affects readability and specifically mentions the acronym \"DU\" as an example. This claim is 3 as it highlights a potential issue with the paper\"s readability and provides a specific example of an acronym that needs clarification. However, the comment lacks detailed reasoning or examples of how the acronyms impact readability, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s readability, noting the heavy use of acronyms and the lack of a clear definition for the acronym \"DU.\" This feedback is clear and actionable, as it directs the authors to address the issue by defining the acronym to improve the paper\"s readability. However, the comment could be more helpful if it provided suggestions on how to effectively introduce and define acronyms or offered examples of best practices in this regard. Despite this, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the estimation of variance in section 2.3, specifically asking how the variance of the distribution p(q|s) is estimated and whether it is determined using the sample variance of the quality values in the training data. It also inquires about the assumption of a diagonal covariance matrix, suggesting that it might not be reasonable for the problem at hand. While the comment implies that the authors should provide more details on the estimation method and assumptions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the questions raised. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the estimation of variance and the assumptions made regarding the distribution p(q|s), including whether the complete covariance matrix is approximated or a diagonal covariance matrix is assumed. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point raises a question about the estimation of variance in section 2.3, specifically asking how the variance of the distribution p(q|s) is estimated and whether it is determined using the sample variance of the quality values in the training data. The reviewer also inquires about the assumption of a diagonal covariance matrix, suggesting that it might not be reasonable for the problem at hand. While the comment poses questions and seeks clarification, it does not contain any subjective claims or opinions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the estimation of variance in section 2.3, specifically asking how the variance of the distribution p(q|s) is estimated and whether it is determined using the sample variance of the quality values in the training data. It also inquires about the assumption of a diagonal covariance matrix, suggesting that it might not be reasonable for the problem at hand. This feedback is clear and actionable, as it prompts the authors to provide more detailed information on the estimation method and assumptions, which could help clarify the methodology and enhance the paper\"s transparency. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of alternative approaches. Overall, the comment is 4, as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the initial accuracy of the MILbased baseline model being higher than the converged models, particularly for the NSCLC dataset. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this observation or what steps they should take to improve their draft. Without any actionable suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the initial accuracy of the MILbased baseline model being higher than the converged models, particularly for the NSCLC dataset. This provides clear guidance on what aspect of the figure needs further explanation or investigation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the initial accuracy of the MILbased baseline model being higher than the converged models, particularly for the NSCLC dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the initial accuracy of the MILbased baseline model being higher than the converged models, particularly for the NSCLC dataset. This is a relevant observation that could point to a potential issue or inconsistency in the results. However, the comment does not provide any suggestions or guidance on how the authors might investigate or address this observation. Without actionable feedback or suggestions for improvement, the comment is 3 as it highlights an area of concern but does not offer a clear path for the authors to enhance their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider other datasets to explore the generalization of their proposed method. While the comment implies that the authors should expand their dataset analysis, it does not provide specific guidance on which datasets to consider or how to incorporate them into the study. The action is implicit and somewhat vague, as the authors need to infer that they should explore additional datasets and determine how to integrate them into their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should consider other datasets to explore the generalization of the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology, results, or discussion sections. Additionally, it lacks specificity regarding which other datasets should be considered or how they might impact the generalization of the method. Without explicit references to specific sections or detailed guidance, the authors cannot confidently determine where to make these changes or what exactly is being suggested. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should consider other datasets to explore the generalization of the proposed method. However, it does not provide specific examples of alternative datasets or detailed reasoning why considering them is beneficial. The comment lacks supporting evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should consider other datasets to explore the generalization of the proposed method. This feedback is 3 as it points out a potential limitation in the paper\"s scope and encourages the authors to broaden their analysis. However, the comment lacks specificity regarding which other datasets should be considered or how they might impact the generalization of the method. Without detailed guidance or examples, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and actionable details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the expectation that the systems investigated in the paper are not Bayesoptimal on relatively straightforward problems. It suggests that more work is needed at the start of the paper to establish alternative hypotheses and gear the analyses and results towards ruling out those alternatives. The comment implies that the current analysis is mostly confirmatory and lacks experiments that would truly test the hypothesis. While the comment identifies a need for more detailed analysis and experimentation, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors are left to infer what specific experiments or analyses are needed to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the expectation that the systems investigated in the paper are not Bayesoptimal on relatively straightforward problems. It suggests that more work is needed at the start of the paper to establish alternative hypotheses and gear the analyses and results towards ruling out those alternatives. The comment implies that the current analysis is mostly confirmatory and lacks experiments that would truly test the hypothesis. However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment. While the authors might infer that it relates to the introduction or methodology sections, the comment lacks full grounding. It is specific in suggesting the need for more detailed analysis and experimentation to test the hypothesis, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the expectation that the systems investigated in the paper are not Bayesoptimal on relatively straightforward problems. It suggests that more work is needed to establish alternative hypotheses and gear the analyses and results towards ruling out those alternatives. The comment implies that the current analysis is mostly confirmatory and lacks experiments that would truly test the hypothesis. However, it does not provide specific examples or references to support the claim that the systems are not Bayesoptimal or that the analysis lacks rigor. The reasoning is logical but lacks detailed evidence or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the expectation that the systems investigated in the paper are not Bayesoptimal on relatively straightforward problems. It suggests that more work is needed at the start of the paper to establish alternative hypotheses and gear the analyses and results towards ruling out those alternatives. The comment implies that the current analysis is mostly confirmatory and lacks experiments that would truly test the hypothesis. By highlighting the need for a more rigorous approach, the comment provides valuable feedback that could guide the authors in refining their methodology and experimental design. However, the comment could be more helpful if it offered specific suggestions or examples of experiments that would address the issue. Overall, the feedback is 4 as it identifies a critical area for improvement and encourages a more robust approach to testing hypotheses, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the authors to add confidence intervals to Table 1, which provides results for the performance of different fairness improvement techniques. This request is clear and provides a direct action for the authors to take, making it 5. The comment specifies exactly what needs to be done to improve the draft, ensuring that the authors know how to apply the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reported values in Table 1, noting that they are too close to draw meaningful conclusions. The comment further requests the addition of confidence intervals, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the reported values in Table 1 are too close to draw meaningful conclusions and suggests adding confidence intervals. However, the comment does not provide any reasoning or evidence to support why the reported values are insufficient or how confidence intervals would improve the analysis. Without additional context or explanation, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Table 1, noting that the reported values are too close to draw meaningful conclusions. It provides a clear and actionable suggestion by requesting the addition of confidence intervals, which would help the authors present their results more effectively. This feedback is valuable as it directly addresses a weakness in the paper and offers a concrete step for improvement. However, the comment could be more helpful if it explained why confidence intervals are important or how they would enhance the analysis. Overall, the comment is 4, as it provides a clear direction for improvement but lacks some depth in its explanation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point indicates that some choices are not justified or clear, but it does not specify which choices or provide any guidance on how to address this issue. The comment includes a list of questions for the authors, but these questions are not directly actionable as they do not provide clear instructions on what the authors should do to improve their draft. The lack of specific guidance and concrete actions makes the comment 1.", "grounding_specificity_rationale": "The comment mentions that \"some choices are not justified/not clear,\" but it does not specify which choices or parts of the paper are being referred to. Additionally, it does not provide any details on what is unclear or not justified, leaving the authors without a clear understanding of what needs to be addressed. Without specific references or examples, the authors cannot confidently determine which parts of the paper are affected or how to improve them. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"some choices are not justified/not clear\" but does not provide any specific examples or reasoning to support this claim. Without detailed explanation or references, the authors may find it challenging to understand and address the issue. The lack of supporting evidence or justification makes the claim 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that some choices are not justified or clear. However, it does not specify which choices are problematic or provide any guidance on how to address this issue. The comment includes a list of questions for the authors, but these questions are not actionable in themselves. Without specific feedback or suggestions, the authors are left without a clear understanding of what needs to be improved or how to proceed. Therefore, the comment is 1, as it does not provide actionable insights or guidance for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about hyperparameter tuning, specifically regarding the polarization regularizer and its two hyperparameters. It notes that these hyperparameters affect both FLOPs and accuracy, making the tuning process challenging. The reviewer suggests that the paper should provide more detailed discussions on this issue for reproducibility. While the comment implies that the authors should include more information on hyperparameter tuning, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"hyperparameter tuning\" and \"polarization regularizer,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the challenges of tuning due to the impact of hyperparameters on FLOPs and accuracy, and the need for detailed discussions on this topic for reproducibility. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about hyperparameter tuning, specifically regarding the polarization regularizer and its impact on FLOPs and accuracy. The reviewer suggests that the tuning process is challenging due to the multiple solutions that can hit the same FLOPs, making it difficult to navigate based on a simple objective. The comment provides a logical reasoning for the claim, noting the complexity of the tuning process due to the interplay of hyperparameters and their effects on performance. However, it lacks specific examples or references to support the claim fully. Therefore, the comment is 3, as it provides a logical basis but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific concern regarding hyperparameter tuning, particularly in the context of the polarization regularizer. It highlights the challenge of navigating the tuning process due to the interplay of hyperparameters affecting both FLOPs and accuracy. The reviewer suggests that the paper should provide more detailed discussions on this issue for reproducibility. While the comment points out a relevant area for improvement, it could be more helpful by offering specific suggestions or examples on how to address the issue. Overall, the feedback is 3 as it directs the authors to a critical area that needs further clarification, but it lacks detailed guidance on how to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing element in Figure 1, specifically the accuracies of the target model using different defenses against the FGSM attack. It points out that this omission makes it unclear how the known attacks differ from the unknown attacks. While the comment identifies a specific gap in the figure, it does not provide explicit instructions on how to address this issue or suggest what information should be included. The action is implicit and somewhat vague, as the authors can infer that they need to add the missing information but may not be entirely sure of the exact details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of accuracies of the target model using different defenses against the FGSM attack. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, making it unclear how the known attacks differ from the unknown attacks. This claim is 3 as it highlights a specific omission in the figure, which could be addressed by including the requested information. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it difficult for the authors to understand the exact impact of this omission. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the presentation of results, noting that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1. This omission makes it unclear how the known attacks differ from the unknown attacks. By pointing out this missing information, the comment provides clear and actionable feedback that can help the authors improve the clarity and completeness of their results presentation. However, the comment could be more helpful if it suggested how the authors might present this information or why it is important for the reader to understand. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that some figures are hard to read and recommends using a logscale for the yaxis. While the action is explicit, it lacks concrete details on which figures are problematic or how to implement the suggestion of using a logscale. The authors are given a clear direction but may need to infer which figures need attention and how to apply the logscale. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some figures,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it provides a clear suggestion to consider using a logscale for the yaxis, which would improve the readability of the figures. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some figures are hard to read and suggests using a logscale for the yaxis. However, it does not provide specific examples or detailed reasoning to support why the figures are difficult to read or how a logscale would improve readability. The comment lacks sufficient evidence or explanation to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the readability of some figures in the paper, suggesting that a logscale for the yaxis could improve their clarity. This feedback is actionable and provides a clear direction for the authors to enhance the visual presentation of their data. However, the comment could be more helpful if it specified which figures are problematic or provided examples of how a logscale might improve readability. Despite this, the suggestion is valuable and could lead to a significant improvement in the paper\"s visual representation, making the comment 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the proposed method was motivated by the claim that augmentation information is useful, as evidenced by examples like flowers and birds. However, the comment notes that this claim was not validated in the experiment. It suggests that finegrained datasets like the Oxford 102 flowers dataset and the CaltechUCSD Birds200 dataset should have been used to validate the claims. While the comment implies that the authors should include these datasets in their experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these datasets to validate their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method was motivated by the claim that augmentation information is useful, as evidenced by examples like flowers and birds, but this claim was not validated in the experiment. The comment suggests using finegrained datasets like the Oxford 102 flowers dataset and the CaltechUCSD Birds200 dataset to validate the claims. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method was motivated by the claim that augmentation information is useful, as evidenced by examples like flowers and birds. However, it notes that this claim was not validated in the experiment. The reviewer suggests using finegrained datasets like the Oxford 102 flowers dataset and the CaltechUCSD Birds200 dataset to validate the claims. This provides a logical reasoning for the claim and suggests specific datasets that could be used for validation. The comment is 4 as it offers a clear rationale and specific references, but it could be strengthened by providing more detailed reasoning or examples. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the proposed method was motivated by the claim that augmentation information is useful, as evidenced by examples like flowers and birds. However, the comment points out that this claim was not validated in the experiment. It suggests that finegrained datasets like the Oxford 102 flowers dataset and the CaltechUCSD Birds200 dataset should have been used to validate the claims. This feedback is clear and actionable, providing the authors with a specific direction for improving their experimental validation. By addressing this feedback, the authors can strengthen the credibility and validity of their claims. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of theoretical analysis and empirical evidence supporting the claim that GEMS converges to the Nash equilibrium. While it identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or suggest specific actions for improvement. The authors are left to infer that they need to include theoretical analyses and empirical evaluations to support their claim, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is 3, as it points out an area for improvement but does not offer detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement about \"Over time, those opponents will evolve toward the Nash equilibrium,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of theoretical analyses and empirical evaluations supporting the claim that GEMS converges to the Nash equilibrium. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks theoretical analyses and empirical evidence to support the claim that GEMS converges to the Nash equilibrium. However, the comment does not provide specific examples or references to substantiate this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to invest effort to determine the specific gaps in the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it claims \"Over time, those opponents will evolve toward the Nash equilibrium\" but lacks theoretical analyses and empirical evidence to support this claim. This feedback is clear and actionable, as it highlights a critical gap in the paper that needs to be addressed. By pointing out the lack of theoretical and empirical support, the comment provides the authors with a clear direction for improvement, such as conducting additional analyses or experiments to substantiate their claims. However, the comment could be more helpful if it offered suggestions on how to conduct these analyses or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out several issues with Equation (1), including its unclear purpose, the definition of the optimization variable, and the unusual constraints notation. It provides specific questions and suggestions for clarification, such as whether the equation defines a loss function or an optimization problem, and whether the optimization variable should be in R^k instead of R^n. These explicit and concrete actions guide the authors on how to improve the clarity and accuracy of their equation, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the equation, including its unclear purpose, the definition of the optimization variable, and the unusual constraints notation. The comment provides clear guidance on what needs to be clarified or corrected, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point critiques Equation (1) for being unclear, specifically questioning its purpose (loss function or optimization problem), the definition of the optimization variable, and the unusual constraints notation. While the comment identifies specific areas of confusion, it does not provide detailed reasoning or examples to support why these aspects are unclear or how they could be clarified. This makes the claim 3, as the authors would need to further investigate and clarify these points themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the clarity of Equation (1), which is crucial for understanding the paper\"s methodology. It raises questions about the purpose of the equation, the definition of the optimization variable, and the unusual constraints notation. By addressing these points, the authors can improve the clarity and accuracy of their work. The comment is clear and detailed, offering a direct path for the authors to enhance their draft. Therefore, it is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to provide more discussions or explanations regarding the observation that including the collected LIVEN parallel data for finetuning makes the NMT system perform worse. This request is clear and direct, giving the authors a specific action to take. The comment provides a concrete suggestion on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 257,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the NMT system performing worse after including the collected LIVEN parallel data for finetuning and requests additional discussions or explanations. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the observation that including the collected LIVEN parallel data for finetuning makes the NMT system perform worse. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual question seeking clarification or explanation, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific observation in the paper, namely that including the collected LIVEN parallel data for finetuning makes the NMT system perform worse. It requests additional discussions or explanations on this observation, which is a clear and actionable suggestion for the authors to address. By prompting the authors to provide more context and analysis, the comment offers a constructive way to enhance the clarity and depth of the paper. However, it could be more helpful if it provided specific suggestions on how to approach this discussion or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area needing further elaboration."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper includes unsubstantiated conjectures about finetuning as exposure of existing capabilities in LMs, noting that the reasoning or references are lacking. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors need to provide more detailed reasoning or references to substantiate their claims, but it does not specify what kind of reasoning or references are needed. As a result, the action is implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding unsubstantiated conjectures about \"finetuning as exposure of existing capabilities in LMs.\" However, it does not specify which part of the paper these conjectures are made in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment provides some context by mentioning \"adequate reasoning or references,\" but it lacks specificity in terms of what reasoning or references are needed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper includes unsubstantiated conjectures about \"finetuning as exposure of existing capabilities in LMs.\" However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes it challenging for the authors to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it includes unsubstantiated conjectures about \"finetuning as exposure of existing capabilities in LMs.\" It points out that the reasoning or references supporting these conjectures are lacking, which makes it difficult for the reader to comprehend the claims. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their reasoning. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a weakness but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. While the comment implies that the authors should consider adding this baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to integrate NaturalSpeech 3 or why it would be beneficial. The authors can infer that they should consider adding this baseline, but the lack of explicit instructions and detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where FACodec is discussed. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in suggesting a particular baseline to include, but without clear grounding, it is 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. However, it does not provide any reasoning, evidence, or references to support why NaturalSpeech 3 is a relevant or beneficial baseline. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the suggestion effectively.", "helpfulness_rationale": "The review comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. While it identifies a potential area for improvement by recommending a specific baseline, it lacks depth and does not provide a rationale or explanation for why NaturalSpeech 3 would be beneficial. The comment does not offer guidance on how to integrate this baseline or address any specific concerns related to voice cloning tasks. As a result, the feedback is 3, as it points out a potential enhancement but does not fully support the authors in making the necessary improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the experiments, suggesting that if the proposed method uses data from the first four weeks for inference, other methods should also use this data for training. The reviewer implies that the proposed method cannot train with this data, which is why the experiments are considered unfair. However, the comment does not provide explicit instructions or concrete suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the experimental setting or make adjustments to ensure fairness. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the experimental setting, namely the use of data from the first four weeks for inference. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification on the experimental setting, particularly regarding the fairness of the experiments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the fairness of the experiments, suggesting that if the proposed method uses data from the first four weeks for inference, other methods should also use this data for training. The reviewer claims that the proposed method cannot train with this data, which makes the experiments unfair. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the concern fully. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed justification.", "helpfulness_rationale": "The review comment raises a concern about the fairness of the experiments, specifically questioning why the proposed method uses data from the first four weeks for inference but other methods do not. The reviewer suggests that if the proposed method uses this data for inference, other methods should also use it for training, as it would be unfair otherwise. This feedback is 3 as it identifies a potential issue with the experimental design and prompts the authors to consider whether their approach is fair. However, the comment lacks specific suggestions or guidance on how to address this concern, such as proposing alternative experimental setups or providing examples of how to ensure fairness. Therefore, while it highlights an important area for consideration, it does not fully support the authors in improving their draft. Overall, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. This is a clear and direct action, providing specific details on what needs to be included in the results section. The authors know exactly what to do to address this feedback, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category (50%, 2:4, 4:8). This provides clear guidance on what specific results should be included in the paper. However, it does not specify why these results are important or how they relate to the current content, which could provide more context for the authors. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. This is a request for additional information, not a claim or opinion. It does not contain subjective judgments, suggestions, or deductions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include additional results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. This feedback is specific and offers a concrete way for the authors to enhance their paper by providing more comprehensive results. By addressing this suggestion, the authors can improve the depth and breadth of their analysis, which is valuable for readers interested in the performance of their model. However, the comment could be more helpful if it explained why these results are important or how they would contribute to the paper\"s overall impact. Overall, the comment is 4 as it provides clear guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the extent to which sequential bias affects the VisDial results. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific steps should be taken to investigate or mitigate the impact of sequential bias. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the extent to which sequential bias affects the VisDial results. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide details on what aspects of the VisDial results are affected by sequential bias or how this bias should be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the extent to which sequential bias affects the VisDial results. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the extent to which sequential bias affects the VisDial results. While it identifies a potential area of concern, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable feedback or insights into how the authors might investigate or mitigate the impact of sequential bias. As a result, the comment is 2, as it points out a potential area for improvement but does not provide the authors with a clear path forward."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a contradiction between the experimental results and the stated goal of LTAP, which is to strengthen parameter protection for tail classes. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the contradiction or improve the draft to align with the stated goal. As a result, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results on the ImageNetLT dataset\" and the comparison with ATO and RReg, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of the performance improvement for head classes versus tail classes, and how this contradicts the stated goal of strengthening parameter protection for tail classes in LTAP. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results on the ImageNetLT dataset show a larger performance improvement for head classes compared to tail classes, which contradicts the stated goal of strengthening parameter protection for tail classes in LTAP. However, the comment does not provide any specific examples, detailed analysis, or references to support this claim. Without additional evidence or explanation, the authors may find it challenging to understand the basis of the contradiction or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential contradiction between the experimental results and the stated goal of LTAP, which is to strengthen parameter protection for tail classes. By pointing out this discrepancy, the comment highlights an area where the authors may need to clarify or revise their claims. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it raises an important point, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the reliability of the search process due to its dependency on LLMbased evaluation by prompting. It suggests that this reliance on LLMs may introduce biases or inconsistencies in the quality assessment of generated documentations. However, the comment does not provide specific guidance on how to address these concerns or improve the reliability of the search process. While it identifies an issue, it lacks actionable advice or concrete steps for the authors to take. Therefore, the comment is 3, as it highlights a potential problem but does not offer detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment addresses the reliability of the reward computation, specifically mentioning the dependency on LLMbased evaluation by prompting. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the concern about biases and inconsistencies introduced by LLMs in the quality assessment of generated documentations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the reward computation relies on LLMbased evaluation by prompting, which may introduce biases or inconsistencies in the quality assessment of generated documentations. However, the comment lacks specific examples or references to support this claim, such as detailed comparisons or studies that demonstrate the potential biases or inconsistencies. Without such evidence, the claim remains 3, as it provides a logical concern but lacks concrete support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the reward computation, specifically the reliance on LLMbased evaluation by prompting. It raises concerns about the reliability of the search process and suggests that this dependency on LLMs may introduce biases or inconsistencies in the quality assessment of generated documentations. While the comment highlights an important area for consideration, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the reliability of their approach. The feedback is 3 as it points out a critical issue, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more empirical examples and compare their results to the stateoftheart (SOTA) performance from referenced papers. It also mentions that Equation 12 might address this issue but is unclear. While the comment implies that the authors should include more empirical evidence and comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq 12,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the argument for the process\"s effectiveness is unclear and suggests that more empirical examples and comparisons to SOTA performance from referenced papers are needed. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the argument for the process\"s effectiveness is unclear and suggests that more empirical examples and comparisons to stateoftheart (SOTA) performance from referenced papers are needed. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the necessary steps to improve the clarity and empirical support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity in the argument for the process\"s effectiveness. It suggests that more empirical examples and comparisons to stateoftheart (SOTA) performance from referenced papers are needed to support this claim. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the clarity and robustness of their argument. However, the comment could be more helpful if it included examples of how to incorporate these empirical examples or comparisons, which would make it fully actionable. Overall, the comment is 4, as it guides the authors toward improving the clarity and empirical support of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the difficulty of the problem and provides a detailed explanation of why the problem is challenging. It explicitly states that the adversary cannot pick arbitrary S but only those that satisfy a specific condition, which is enforced by Assumption 1. The reviewer further explains that even after removal, the remaining samples are sufficient for accurate recovery, provided that the number of samples is proportional to the logarithm of the number of observations. This comment provides a clear and explicit action for the authors to address, namely, to clarify the difficulty of the problem and its assumptions. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Assumption 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the difficulty of the problem and provides a logical explanation of why the problem is challenging, specifically related to Assumption 1. The comment explains that the adversary cannot pick arbitrary S but only those that satisfy a specific condition, and it provides a mathematical reasoning for why this still allows for accurate recovery. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the difficulty of the problem, specifically related to Assumption 1. It provides a detailed explanation of why the problem is challenging, including a logical reasoning that the adversary cannot pick arbitrary S but only those that satisfy a specific condition. The comment also includes a mathematical argument that even after removal, the remaining samples are sufficient for accurate recovery, provided that the number of samples is proportional to the logarithm of the number of observations. This level of detail and logical reasoning makes the claim 5, as it provides a clear and robust explanation for the reviewer\"s concern. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment raises a significant concern about the difficulty of the problem, specifically related to Assumption 1. It provides a detailed explanation of why the problem is challenging, noting that the adversary cannot pick arbitrary S but only those that satisfy a specific condition. The reviewer further explains that even after removal, the remaining samples are sufficient for accurate recovery, provided that the number of samples is proportional to the logarithm of the number of observations. This comment is 5 as it identifies a critical issue with the problem formulation and provides a clear rationale for why it is challenging. By offering this detailed analysis, the comment empowers the authors to address this concern and potentially improve their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a contradiction between Figure 1 and the last two columns of Table 1, indicating that the number of selected knearest neighbors affects NNGS. However, it does not provide any explicit or implicit guidance on how the authors should address this contradiction or what specific changes are needed to resolve it. The comment lacks actionable details, such as suggesting ways to reconcile the findings or explaining the implications of this contradiction. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out a contradiction between the figure and the table, indicating that the number of selected knearest neighbors affects NNGS. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 1 illustrates a relationship between NNGS and the number of selected knearest neighbors, contradicting the comparison in the last two columns of Table 1. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the contradiction or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential contradiction between Figure 1 and the last two columns of Table 1, specifically regarding the relationship between NNGS and the number of selected knearest neighbors. This feedback highlights a specific area where the authors may need to clarify or reconcile their findings. However, the comment does not provide detailed guidance on how to address this contradiction or suggest ways to resolve it. While it points out an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity in its suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the extensibility of the proposed method to a large number of tasks, similar to the challenges posed in multitask learning. It asks for an explanation of the impact of a large number of tasks on the set of shared parameters and requests that the authors address this question in their response. While the comment explicitly states the need for an explanation, it does not provide specific guidance on how to address the issue or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to provide an explanation but may not be entirely sure of the exact details to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the extensibility of the proposed method to a large number of tasks, similar to the challenges posed in multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and requests clarification on this aspect. However, the comment does not specify which part of the paper discusses the proposed method or the experiments, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in its request for clarification on the impact of a large number of tasks, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the extensibility of the proposed method to a large number of tasks, similar to the challenges posed in multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and requests clarification on this aspect. The comment provides a logical reasoning by comparing the proposed method to multitask learning, which is a wellknown challenge in machine learning. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional evidence or analysis to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the extensibility of the proposed method to a large number of tasks, similar to the challenges posed in multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and requests clarification on this aspect. This feedback is 3 as it identifies a potential limitation of the proposed method and prompts the authors to address it. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or improve the method\"s scalability. Overall, the comment is 3 as it directs the authors\" attention to an important area for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a perceived issue with the eyetracking data selection and filtering, noting that it appears that everything is analyzed, including regressions to earlier parts of the sentence, with some exclusions. However, the comment does not provide specific guidance on what aspects of the data selection or filtering are problematic or how the authors might address these issues. The feedback lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the comment is vague and 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to eyetracking data selection and filtering, noting that it appears that everything is analyzed, including regressions to earlier parts of the sentence, with some exclusions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the data selection and filtering process, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location of the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the eyetracking data selection and filtering are perplexing, noting that everything is analyzed, including regressions to earlier parts of the sentence, with some exclusions. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment identifies a specific issue with the eyetracking data selection and filtering process, noting that it appears that everything is analyzed, including regressions to earlier parts of the sentence, with some exclusions. This feedback highlights a potential area of concern that the authors should address to improve the clarity and comprehensiveness of their analysis. However, the comment lacks specific suggestions or guidance on how to resolve this issue, such as recommending a more systematic approach to data selection or providing examples of what exclusions might be problematic. While it points out a relevant area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the credibility of the results in the appendix for InitNO, specifically regarding textimage alignment. It points out that despite InitNO reporting improved alignment on StableDiffusionv14, the results in Table 6 show that InitNO\"s alignment is lower than that of StableDiffusionv14. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what steps they should consider to improve the credibility of the results. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix results for InitNO\" and \"Table 6,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies the issue with the results, questioning the credibility of the textimage alignment results for InitNO. The comment points out a discrepancy between the reported improvement in alignment and the actual results in Table 6. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the credibility of the results in the appendix for InitNO, specifically regarding textimage alignment. It points out a discrepancy between the reported improvement in alignment and the actual results in Table 6. This claim is 3 as it highlights a potential issue with the results, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to investigate the discrepancy themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the credibility of the results in the appendix for InitNO, specifically regarding textimage alignment. It points out a discrepancy between the reported improvement in alignment and the actual results in Table 6, suggesting that the results may not be as favorable as claimed. This feedback is 3 as it highlights a specific area of concern that the authors need to address. However, the comment lacks detailed guidance or suggestions on how the authors might investigate or resolve this issue, such as recommending additional experiments or analyses. While it provides some insight into a potential problem, it does not offer comprehensive or actionable advice for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit suggestions for improving the paper, specifically mentioning the need for additional editing to improve language usage and notation in the equations. It suggests considering dropping some sub/superscripts for convenience, while noting that this change should be acknowledged. These actions are clear and provide concrete guidance on how to enhance the draft. The authors know exactly what needs to be done to address the issues raised, making the comment 5.", "grounding_specificity_rationale": "The comment provides specific feedback on the writing style, noting that it is occasionally uneven and could benefit from additional editing. It also addresses the notation in the equations, suggesting that some sub/superscripts could be dropped for convenience. However, the comment does not specify which parts of the paper are uneven or where the notation becomes unwieldy, making it weakly grounded. The suggestion to drop sub/superscripts is specific, but without explicit references to sections or equations, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the writing is occasionally uneven and could benefit from additional editing, particularly in terms of language usage and notation. It also suggests considering dropping some sub/superscripts for convenience in the equations. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The suggestion to drop sub/superscripts is a logical one, but without further explanation or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the writing style, noting that it is occasionally uneven and could benefit from additional editing, particularly in terms of language usage and notation. It also suggests considering dropping some sub/superscripts in the equations for convenience, while acknowledging that this change should be noted. This feedback is clear and actionable, offering the authors concrete steps to improve the readability and clarity of their draft. However, the comment could be more helpful if it included examples or specific sections where the uneven writing or notation issues occur. Overall, the comment is 4 as it guides the authors toward enhancing the readability and clarity of their manuscript."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns and questions about the dataset, including the cost of image acquisition and the type of manual collection used. It also points out a grammatical error in the text and requests clarification on the content of \"regulatory requirements\" and what is considered \"politically sensitive.\" While the comment identifies specific areas that need clarification or correction, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to provide additional information or clarification, but the feedback lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it highlights areas for improvement but does not provide detailed instructions on how to address them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines of the paper (79 and 263), allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear requests for clarification, such as explaining the image acquisition cost and the type of manual collection used, and asking for clarification on the content of \"regulatory requirements\" and what is considered \"politically sensitive.\" This level of detail guides the authors on what specific aspects of their paper need further elaboration. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several claims and questions, including the cost of image acquisition and the type of manual collection used, as well as grammatical errors and the content of \"regulatory requirements.\" While the comment identifies specific areas for clarification, it lacks detailed reasoning or evidence to support these claims. The authors are left to infer the basis of the questions and suggestions, making the claims 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several specific and actionable points for improvement. It questions the dataset\"s size relative to the development cost, prompting the authors to explain the image acquisition cost and the type of manual collection used. This request for clarification is important for transparency and understanding the dataset\"s limitations. Additionally, the comment points out a grammatical error in the text, suggesting that it should be corrected. It also requests clarification on the content of \"regulatory requirements\" and what is considered \"politically sensitive,\" which could be relevant to the study\"s context. These detailed suggestions and requests for clarification offer valuable guidance to the authors, making the comment 4. However, it could be more comprehensive by addressing other aspects of the paper, such as the methodology or results. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses curiosity about how the third column of Fig. 7 is generated, noting that the visualizations do not seem to be normalized. While the comment raises a question, it does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit, as the authors can infer that they need to clarify or normalize the visualizations, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the generation of the third column of Fig. 7, noting that the visualizations do not seem to be normalized. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point expresses curiosity about how the third column of Fig. 7 is generated, noting that the visualizations do not seem to be normalized. However, the comment does not provide any supporting evidence, reasoning, or references to justify why normalization is necessary or how it would impact the visualizations. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the generation of the third column in Figure 7, noting that the visualizations do not seem to be normalized. This feedback is 3 as it points out a potential issue with the presentation of the data, prompting the authors to clarify or normalize the visualizations. However, the comment lacks depth and does not provide specific guidance on how to address the issue or why normalization might be necessary. While it identifies a potential area for improvement, it does not offer detailed suggestions or explanations, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take. It suggests that the advantages of using assignment entropy maximization should be evaluated in the ablation experiment, which is a direct and concrete instruction. Additionally, it points out that the authors should discuss potential negative societal impacts of their work, which is another explicit and concrete action. Both suggestions are clear and provide specific guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"section of benefit of assignment entropy maximization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the evaluation of the advantages of using assignment entropy maximization in the ablation experiment. Additionally, it points out the lack of discussion on potential negative societal impacts of the work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the investigation of assignment entropy maximization is rather heuristic and suggests that the advantages of using this method should be evaluated. However, the comment does not provide specific examples or detailed reasoning to support why the investigation is considered heuristic or how the advantages should be evaluated. This lack of detailed justification makes the claim 3, as the authors would need to infer the basis of the critique and develop their own reasoning to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback, identifying two areas for improvement. First, it points out that the investigation of assignment entropy maximization is rather heuristic and suggests that the advantages of using this method should be evaluated in the ablation experiment. This feedback is clear and directs the authors to a specific aspect of their work that requires further analysis. Second, the comment notes that the authors have described the limitations of their work but have not discussed potential negative societal impacts. This is a valuable suggestion that encourages the authors to consider broader implications of their research. Overall, the comment is 4 as it offers detailed guidance on how to enhance the draft, making it a valuable resource for the authors to improve their manuscript."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point notes that there is only one baseline model in the experimental section, implying that the authors should include additional baseline models for comparison. However, it does not provide specific guidance on which models to include or how to implement them. The action is implicit and somewhat vague, as the authors are left to infer the need for additional models but without concrete details on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of multiple baseline models in the experimental section. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that there is only one baseline model in the experimental section. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it affects the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out a specific issue with the experimental section, noting that there is only one baseline model included. This feedback is 3 as it identifies a potential weakness in the paper\"s experimental setup, suggesting that the authors should consider including additional baseline models for comparison. However, the comment lacks depth and does not provide specific guidance on which additional models might be appropriate or how to incorporate them effectively. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a gap in the results section, noting the absence of certain baselines and literature comparisons. It specifically mentions traditional QAT (LSQ, LSQ+), other LLMbased QAT work (e.g. LLMQAT 1), and more recent PTQ baselines such as SpinQuant 2. The comment provides a clear action for the authors to include these comparisons, which is explicit and concrete. By specifying the specific baselines and literature to consider, the authors know exactly what needs to be added to their results section. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"results\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the results section, namely the inclusion of certain baselines and literature comparisons. The comment provides specific examples of what is missing, such as traditional QAT (LSQ, LSQ+), other LLMbased QAT work (e.g. LLMQAT 1), and more recent PTQ baselines like SpinQuant 2. This level of detail provides clear guidance on what the authors need to address in their results section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that certain baselines and literature comparisons are missing in the results section, specifically mentioning traditional QAT (LSQ, LSQ+), other LLMbased QAT work (e.g. LLMQAT 1), and more recent PTQ baselines such as SpinQuant 2. The reviewer provides specific examples of what is missing, which helps to substantiate the claim. However, the comment could be strengthened by providing more detailed reasoning or evidence on why these comparisons are important or how they would enhance the understanding of the results. Overall, the claim is 4, as it provides a clear direction for improvement but lacks comprehensive justification. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the results section by pointing out the absence of certain baselines and literature comparisons. It specifically mentions traditional QAT (LSQ, LSQ+), other LLMbased QAT work (e.g. LLMQAT 1), and more recent PTQ baselines such as SpinQuant 2. This feedback is clear and actionable, as it provides specific examples of what the authors should include in their results section to enhance the comprehensiveness and validity of their analysis. By addressing these gaps, the authors can provide a more robust and thorough evaluation of their work. However, the comment could be more helpful if it offered suggestions on how to integrate these comparisons or explained their importance in the context of the paper. Overall, the comment is 4, as it effectively guides the authors toward improving their draft by highlighting a critical area for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how to define attributes and what the difference between attributes is. It also suggests that more detailed instructions should be provided. While the comment implies that the authors should clarify these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to define attributes or what additional information should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the definition of attributes and the difference between them, suggesting that more detailed instructions should be provided. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for more detailed instructions, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a request for clarification regarding the definition of attributes and the difference between them. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for additional information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of attributes and the difference between them, suggesting that more detailed instructions should be provided. While it identifies a potential area for clarification, it lacks specific guidance or suggestions on how the authors might address this issue. The comment points out a gap in the paper but does not provide actionable advice on how to improve it. As a result, the feedback is 3, as it prompts the authors to consider clarifying their definitions but does not fully support them in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a concern about the theory\"s ability to predict robustness to adversarial perturbations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern, such as suggesting ways to improve the theory or conduct additional experiments to validate its effectiveness. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the theory\"s ability to predict robustness to adversarial perturbations. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the theory are problematic or how it could be improved. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a claim that the theory in the paper is ineffective in predicting robustness to adversarial perturbations. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to justify the assertion, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the theory\"s ability to predict robustness to adversarial perturbations. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their theory. Without actionable feedback or detailed insights, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is 1, as it does not offer any constructive direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the terminology used in the paper, specifically asking for clarification on what is meant by \"scenario\" and where the \"agnostic\" part is coming in. While the comment identifies areas of confusion, it does not provide explicit instructions or suggestions on how the authors should address these issues. The action is implicit and somewhat vague, as the authors can infer that they need to clarify these terms but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the terminology used in the paper, specifically asking for clarification on what is meant by \"scenario\" and where the \"agnostic\" part is coming in. However, it does not specify which part of the paper these terms are used in, making it difficult for the authors to pinpoint the exact sections that need clarification. The comment is specific in its request for clarification but lacks grounding as it does not identify the specific parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on the terminology used in the paper, specifically asking for clarification on what is meant by \"scenario\" and where the \"agnostic\" part is coming in. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a valid concern about the clarity of terminology used in the paper, specifically questioning what is meant by \"scenario\" and where the \"agnostic\" part is coming in. This feedback is 3 as it identifies a potential area of confusion that the authors need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how to clarify these terms or improve the paper\"s clarity. While it points out an issue, it does not offer actionable steps for the authors to take, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the choice of naming the method \"Maestro\" and expresses confusion about its introduction. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion to clarify the naming choice, introduce the method, or provide context for its use. The comment lacks actionable advice, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the choice of naming the method \"Maestro\" and expresses confusion about its introduction. However, it does not specify which part of the paper discusses this method, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide details on what aspect of the method is unclear or why the name is considered \"weird.\" Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the choice of naming the method \"Maestro\" and expresses confusion about its introduction. However, it does not provide any supporting evidence, reasoning, or references to justify why the name is problematic or why it should be clarified. The comment lacks specific details or examples that would help the authors understand the issue or address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to make improvements based on the feedback.", "helpfulness_rationale": "The review comment questions the choice of naming the method \"Maestro\" and expresses confusion about its introduction. While it identifies a potential issue with the naming convention, it lacks depth and does not provide any suggestions or guidance on how the authors might address this concern. The comment does not offer actionable feedback or insights into how the authors might clarify the method\"s introduction or rationale for its naming. As a result, the comment is 2, as it points out a potential issue but does not assist the authors in resolving it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify the meaning of \"best\" when referring to a candidate on page 5. It suggests that the authors should define what \"best\" means within the context of the paper, specifying whether it refers to candidates that are most relevant for prediction, those with the highest confidence scores, or some other criteria. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the definition of \"best\" within the context of the paper. The comment suggests clarifying whether \"best\" refers to candidates that are most relevant for prediction, those with the highest confidence scores, or some other criteria. This level of detail provides clear guidance on what needs to be improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the term \"best\" should be explicitly defined in the context of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification, which is factual and does not necessitate additional evidence or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the term \"best\" should be explicitly defined within the context of the paper. It provides clear guidance on what needs to be clarified, such as whether \"best\" refers to candidates that are most relevant for prediction, those with the highest confidence scores, or some other criteria. This feedback is actionable and constructive, as it empowers the authors to enhance the clarity and precision of their work. However, it could be more helpful if it included examples or further elaboration on how to define \"best\" within the context of the paper. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claims made in the paper, specifically that the proposed method does not consider feedforward layers but is described as if it does. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to clarify the claims. The action is implicit, as the authors can infer that they need to revise their claims, but it lacks concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue with the claims made in the paper, noting that the proposed method does not consider feedforward layers but is described as if it does. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in identifying the issue with the claims but lacks grounding, as it does not indicate where in the paper these claims are made. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some points are overclaimed, specifically that the proposed method does not consider feedforward layers but is described as if it does. This claim is 3 as it highlights a potential discrepancy between the claims and the actual capabilities of the proposed method. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Providing more detailed evidence or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the claims made in the paper, noting that the proposed method does not consider feedforward layers but is described as if it does. This feedback is 3 as it points out a potential overclaim in the paper, which could lead to confusion or misinterpretation among readers. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify their claims. To be more helpful, the comment could include recommendations on how to accurately represent the method\"s capabilities or suggest ways to improve the clarity of the claims. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experiments are not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or improve the clarity of the experiments. The comment lacks concrete details on what changes should be made or how the authors might better motivate their experimental design. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments design,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of clarity in the motivation for the \"no variations\" and \"Up to 18 games\" finetuning methods, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these aspects are unclear or how they could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiments, noting that the design is not clearly motivated. It highlights two aspects, \"no variations\" and \"Up to 18 games\" finetuning methods, which are not well explained. This feedback is 3 as it points out a potential area for improvement, but it lacks detailed guidance or suggestions on how the authors might clarify or motivate these aspects of the experiments. To be more helpful, the comment could include specific questions or suggestions for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to evaluate the method performance under missing modality cases, such as testing with different missing ratios. It also references specific works, \"On unimodal feature learning in supervised multimodal learning\" and \"Audiovisual SlowFast Networks for Video Recognition,\" which could provide guidance on how to approach this evaluation. The comment is explicit and provides concrete details on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1/2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: evaluating the method performance under missing modality cases, such as testing with different missing ratios. The comment also references specific works, which provides additional context and guidance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in Table 1/2 is incomplete because it only shows results for MissV and MissA, and suggests that the method performance should be evaluated under different missing modality cases. The comment references specific works, \"On unimodal feature learning in supervised multimodal learning\" and \"Audiovisual SlowFast Networks for Video Recognition,\" which provide some context and support for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how these works address the issue. Overall, the claim is 4, as it provides some support but lacks comprehensive evidence or detailed reasoning. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of the method performance in Tables 1/2, noting that only MissV and MissA results are shown. It suggests that the method performance should be evaluated under different missing modality cases, such as testing with different missing ratios. This feedback is clear and actionable, as it provides a specific direction for improving the evaluation of the method\"s performance. Additionally, the comment references relevant works, which could offer guidance on how to approach this evaluation. However, the comment could be more helpful if it included more detailed suggestions or examples of how to implement these evaluations. Overall, the comment is 4, as it effectively guides the authors toward improving their evaluation methodology."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that an ablation study on the effect of using image features should be included, even if the conditions are not changed during web browsing. While the comment implies that the authors should conduct an ablation study, it does not provide specific guidance on how to implement this suggestion or what aspects of the study should be focused on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including an ablation study on the effect of using image features, even if the conditions are not changed during web browsing. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Without explicit references to the paper, the authors may find it challenging to determine where this feedback should be addressed. The comment is specific in suggesting the need for an ablation study, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an ablation study on the effect of using image features should be included, even if the conditions are not changed during web browsing. This claim is 3 as it provides a logical reasoning for the need of an ablation study to evaluate the impact of image features. However, the comment lacks specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that an ablation study on the effect of using image features should be included, even if the conditions are not changed during web browsing. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the study by exploring the impact of image features. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Despite this, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big\" and \"deep Transformers.\" However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should conduct additional experiments, modify their approach, or address this concern in the paper. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big\" and \"deep Transformers.\" However, it does not specify which part of the paper this question pertains to, such as the experimental section or the results discussion. Without explicit references to sections or figures, the authors cannot confidently determine where to address this concern. The comment is specific in its inquiry about challenging settings but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point consists of a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big\" and \"deep Transformers.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual inquiry, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big\" and \"deep Transformers.\" While it identifies a potential area for further exploration, it lacks actionable feedback or suggestions for the authors to address this concern. The comment does not provide guidance on how the authors might test the approach in these challenging settings or what specific modifications or experiments could be conducted to evaluate its performance. As a result, the comment is 3, as it points out a potential area for improvement but does not offer detailed guidance on how to proceed. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point corrects the authors\" understanding of identifiability, clarifying that it is a property of a model assuming infinite data can be observed. It explicitly states that insufficient data cannot be the reason for a model being nonidentifiable. This feedback is clear and provides a direct correction to the authors\" understanding, making it 5. The authors know exactly what needs to be corrected in their draft, ensuring a clear path for improvement.", "grounding_specificity_rationale": "The comment addresses the authors\" understanding of identifiability, specifically correcting the notion that insufficient data can make a model nonidentifiable. However, it does not specify which part of the paper discusses identifiability or where the incorrect understanding is presented. This lack of grounding makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its correction of the concept of identifiability, but without clear grounding, it aligns with a score of 1.", "verifiability_rationale": "The review point claims that the authors\" understanding of identifiability is incorrect, specifically stating that identifiability is a property of a model assuming infinite data can be observed. The reviewer provides a clear and logical explanation of what identifiability entails, which helps the authors understand the basis of the claim. However, the comment could be strengthened by providing examples or references to support the claim further. Overall, the claim is 4, as it provides a logical reasoning but lacks specific examples or references, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides a clear and specific correction to the authors\" understanding of identifiability, which is a crucial concept in their work. It clarifies that identifiability is a property of a model assuming infinite data can be observed, and it cannot be attributed to insufficient data. This feedback is valuable as it corrects a fundamental misunderstanding that could impact the validity of the authors\" analysis. However, the comment could be more helpful if it offered suggestions on how to address this misunderstanding or how it might affect the authors\" methodology. Despite this, the comment is 4 as it provides a critical correction that the authors need to address."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the results show no particular benefit with respect to the simple baseline the authors compare with. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to improve the results or provide a more detailed comparison. Without any actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the results and the simple baseline the authors compare with, but it does not specify which part of the paper these results are discussed in. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the results are lacking or how they could be improved. Without explicit references to sections or detailed feedback, the comment is 1 and lacks specificity. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results show no particular benefit with respect to the simple baseline the authors compare with. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or analysis, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the results do not show any particular benefit compared to the simple baseline the authors have used. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address this issue or improve their results. Without detailed guidance or examples, the authors are left without a clear understanding of what needs to be done to enhance their work. Therefore, the comment is 1, as it does not offer any actionable insights for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues related to efficiency: the time cost of pretraining the WaveFiT vocoder and the slower inference speed due to the diffusionbased vocoder. However, it does not provide explicit guidance on how the authors should address these issues. The comment lacks actionable details, such as suggesting ways to optimize the pretraining process or improve inference speed. As a result, the authors are left without clear direction on how to implement the necessary changes. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"training process\" and \"inference process,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues related to efficiency, such as the time cost of pretraining the WaveFiT vocoder and the slower inference speed due to the diffusionbased vocoder. The comment provides clear and actionable feedback on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the efficiency of the method, specifically regarding the time cost of pretraining the WaveFiT vocoder and the slower inference speed due to the diffusionbased vocoder. However, it does not provide specific details or references to support these claims, such as the exact time costs or comparisons with other methods. The lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies two areas of concern related to efficiency: the time cost of pretraining the WaveFiT vocoder and the slower inference speed due to the diffusionbased vocoder. It highlights the lack of information about the time cost of the pretraining process, which is an important detail for readers to understand the method\"s efficiency. Additionally, it points out the slower inference speed compared to DSP and WarpNet, which is relevant for practical applications. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues, such as recommending optimization techniques or providing examples of how to improve efficiency. While it highlights important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper mentions the generalizability of the scoring function s(\u00b7; G) but does not explore this generalization, which calls into question the framework\"s generalizability. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on what specific aspects of the generalization should be explored or how the authors might demonstrate the framework\"s generalizability. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the generalization of the scoring function s(\u00b7; G) and questions the framework\"s generalizability. However, it does not specify which part of the paper discusses this generalization or where the authors should explore it further. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the generalization should be explored or how the authors might demonstrate the framework\"s generalizability. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the generalizability of the framework by noting that the paper mentions the potential for generalization but does not explore it. However, the comment lacks specific examples or detailed reasoning to support the claim that the generalization is questionable. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that the generalization of the scoring function s(\u00b7; G) is not explored, which calls into question the framework\"s generalizability. This feedback is 3 as it highlights an area where the authors could expand their work to demonstrate the framework\"s broader applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing potential areas for exploration or suggesting specific experiments to conduct. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach\"s performance. It implies that this data could offer insights into the framework\"s comparative performance throughout the recommendation process. While the comment does not explicitly instruct the authors to include this information, it provides a clear direction on what additional data could be beneficial for the paper. The action is implicit but concrete, as the authors know exactly what kind of data to include to enhance their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach\"s performance. It references a specific paper by Yiming Zhang et al. (2022) to support the suggestion. However, the comment does not explicitly mention which part of the paper this information should be included in, such as a specific section or table. While the authors might infer that it relates to the results or discussion sections, the lack of explicit grounding makes it weakly grounded. The suggestion is specific, as it clearly outlines what additional data would be beneficial for the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including information on the success rate at each conversation turn to enhance the understanding of the proposed approach\"s performance. The comment references a specific paper by Yiming Zhang et al. (2022) to support the suggestion, providing a clear and specific reference that can help the authors understand the importance of this data. This makes the claim 4, as it is supported by an external reference that provides context and justification for the suggestion. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach\"s performance. This feedback is clear and actionable, as it identifies a specific data point that could enhance the paper\"s analysis and help readers assess the framework\"s effectiveness. By referencing a specific paper, the comment provides a concrete example of how this information could be beneficial. However, the comment could be more helpful if it offered guidance on how to present this data or suggested additional metrics that could be included. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper is dense and difficult to read, suggesting that numbered lists in paragraphs might be easier to read as actual lists. However, it does not provide explicit guidance on which parts of the paper should be revised or how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer which sections need to be revised and how to make the changes. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment provides a general observation about the paper being dense and difficult to read, and it suggests that numbered lists in paragraphs might be easier to read as actual lists. However, it does not specify which parts of the paper are particularly dense or which numbered lists are problematic. The authors can infer that the comment relates to the overall structure and readability of the paper, but without explicit references to specific sections or examples, it is weakly grounded. The comment is specific in suggesting a potential improvement in the presentation of numbered lists, but it lacks detailed guidance on how to implement this change. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is dense and difficult to read, suggesting that numbered lists in paragraphs might be easier to read as actual lists. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of concrete evidence or examples makes the claim 3, as the authors would need to infer the specific problems and how to resolve them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s readability, noting that it is dense and difficult to read due to the inclusion of numbered lists within paragraphs. It suggests that these lists might be more easily understood if presented as actual lists rather than embedded in the text. This feedback is 3 as it points out a potential improvement in the paper\"s presentation, which could enhance readability. However, the comment lacks detailed guidance on how to implement this suggestion or which sections of the paper might benefit from this change. To be more helpful, the comment could provide examples or specific instructions on how to restructure the lists. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fundamental basis of \"fake image detectors,\" suggesting that they might be using similar spectral cues as the simple classifier discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to investigate this question further, what specific aspects of the spectral cues should be examined, or how to address the issue in the paper. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment raises a question about the fundamental basis of \"fake image detectors,\" suggesting that they might be using similar spectral cues as the simple classifier discussed in the paper. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not detail what aspects of the spectral cues should be examined or how this question relates to the paper\"s content. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the fundamental basis of \"fake image detectors,\" suggesting that they might be using similar spectral cues as the simple classifier discussed in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. It lacks specific examples or detailed explanations that would help the authors understand the basis of the question or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to make improvements based on the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises an interesting question about the fundamental basis of \"fake image detectors,\" suggesting that they might be using similar spectral cues as the simple classifier discussed in the paper. This question prompts the authors to consider whether their approach is unique or if it shares commonalities with other methods. However, the comment lacks specificity and does not provide actionable guidance or suggestions for the authors to explore this question further. Without detailed advice on how to investigate or address this issue, the feedback remains somewhat vague, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the visualization results are terrible compared to the ground truth and suggests that the authors should provide analysis of satisfied and terrible cases. This is a clear and direct action for the authors to take. Additionally, the comment references a specific work, \"Classincremental learning for semantic segmentation reusing neither old data nor old labels,\" which provides a concrete example of a related study. This additional information enhances the actionability of the comment by guiding the authors on how to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the visualization results, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the visualization results are terrible compared to the ground truth and suggests that the authors should provide analysis of satisfied and terrible cases. Additionally, the comment references a specific work, \"Classincremental learning for semantic segmentation reusing neither old data nor old labels,\" which provides a concrete example of a related study. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the visualization results are \"terrible\" compared to the ground truth, suggesting that the authors should provide analysis of satisfied and terrible cases. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the visualization results, noting that they are \"terrible\" compared to the ground truth. It suggests that the authors should provide analysis of satisfied and terrible cases to better understand the performance of their method. Additionally, the comment references a related work, \"Classincremental learning for semantic segmentation reusing neither old data nor old labels,\" which could provide a useful comparison or context for the authors. This feedback is clear and actionable, offering a specific direction for improvement and providing a relevant reference. However, it could be more helpful if it included more detailed guidance on how to analyze the satisfied and terrible cases or suggestions on how to improve the visualization results. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the potential impact of limitations or issues in previous works on the validity and effectiveness of the proposed method, TIW. It also notes the similarity of the implementation process to previous work on GAN. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the potential issues or how to differentiate their work from previous studies. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the relevance of the paper to previous work and the potential impact of limitations in those works on the validity and effectiveness of the proposed method, TIW. However, it does not specify which parts of the paper discuss these previous works or how they relate to the current work. Additionally, it does not provide specific details on the limitations or issues in the previous works that could affect TIW. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper builds upon a large body of previous work, which could potentially affect the validity and effectiveness of the proposed method, TIW. It also notes the similarity of the implementation process to previous work on GAN. However, the comment lacks specific examples or references to the previous works or limitations that are being discussed. This makes it difficult for the authors to understand the exact nature of the potential issues or how they might impact their work. Without detailed evidence or examples, the claim remains somewhat vague and 1, aligning with a score of 2.", "helpfulness_rationale": "The review comment acknowledges the relevance of the paper to previous work but also highlights potential limitations or issues that could affect the validity and effectiveness of the proposed method, TIW. It notes the similarity of the implementation process to previous work on GAN. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It identifies a potential issue but does not guide the authors on how to address it or differentiate their work from previous studies. As a result, the comment is 3, as it points out a concern but does not offer detailed guidance for improvement, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the process of selecting a policy for each subgroup and whether any information unavailable to the policy is being used during the partitioning step. It also suggests that if patient characteristics are used for clustering but not for training the policy, they should be incorporated. While the comment implies that the authors should clarify the process and consider incorporating additional information, it does not provide explicit instructions or concrete steps on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the process of selecting a policy for each subgroup and whether any information unavailable to the policy is being used during the partitioning step. It also suggests that if patient characteristics are used for clustering but not for training the policy, they should be incorporated. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in its questioning of the process and suggests a potential improvement, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the process of selecting a policy for each subgroup and whether any information unavailable to the policy is being used during the partitioning step. It also suggests that if patient characteristics are used for clustering but not for training the policy, they should be incorporated. While the comment poses a logical question and provides a rationale for why incorporating additional information might be beneficial, it does not offer specific evidence or references to support the claim. The lack of detailed reasoning or examples makes the claim 3, as the authors would need to further explore the issue to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the process of selecting a policy for each subgroup, suggesting that it might be equivalent to designing a new policy. It also questions whether information unavailable to the policy is being used during the partitioning step and suggests that if patient characteristics are used for clustering but not for training the policy, they should be incorporated. This feedback is 3 as it prompts the authors to clarify their methodology and consider potential improvements. However, it lacks specific suggestions or detailed guidance on how to address these issues, which would make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, as discussed in Appendix C. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should consider to improve the rendering quality. Without any actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, providing a clear focus on the issue. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the rendering quality of NeRF compared to NeuS and Geo NeuS. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, as discussed in Appendix C. While it identifies a potential area of concern, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the rendering quality. The comment is 3 as it prompts the authors to consider this aspect of their work, but it does not offer actionable feedback or detailed insights into how to resolve the issue. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a bold assumption made in Section 3.7 regarding the suitability of purely unsupervised largescale pretraining for NLP applications. The reviewer expresses confusion about how this conclusion was reached based on the proposed evaluation approach. However, the comment does not provide any explicit or implicit guidance on how the authors might address this issue or improve their draft. It lacks actionable suggestions or details on how to clarify or substantiate the assumption, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the manuscript, which is the bold assumption about the suitability of purely unsupervised largescale pretraining for NLP applications. The comment questions how this conclusion was reached based on the proposed evaluation approach. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions a bold assumption made in the manuscript regarding the suitability of purely unsupervised largescale pretraining for NLP applications. The reviewer expresses confusion about how this conclusion was reached based on the proposed evaluation approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the assumption is unfounded. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a bold assumption made in the manuscript regarding the suitability of purely unsupervised largescale pretraining for NLP applications. It questions how this conclusion was reached based on the proposed evaluation approach, suggesting that the assumption may not be wellfounded. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide additional evidence to support or refute the assumption. While it highlights a potential weakness in the manuscript, it does not offer actionable feedback or detailed advice for improvement. As a result, the comment is 3, as it points out a critical area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as discussing recent related work qualitatively and quantitatively, including specific references like A and B. It also highlights the need to discuss DCN 18 and its performance in Table 3. These suggestions are clear and concrete, giving the authors specific tasks to address in their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Related work 2.1\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what is missing in the discussion of recent related work, including specific references like A and B, and highlights the need to discuss DCN 18 and its performance. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper misses to discuss recent related work, specifically mentioning A and B, which achieve higher performance on SUN and CUB, respectively. It also notes that DCN 18 is not discussed and is missing from Table 3, despite being better than other prior work. The comment provides specific references and performance comparisons, which are clear and logical, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these works relate to the paper\"s contributions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying several areas where the paper lacks discussion or comparison with recent related work. It highlights the need to discuss the performance of A on SUN and the omission of DCN 18 in Table 3, despite its better performance on CUB. Additionally, it points out the relevance of B with respect to transductive label propagation. This feedback is clear and detailed, offering the authors concrete steps to enhance the comprehensiveness and accuracy of their work. However, the comment could be more helpful if it included suggestions on how to integrate these discussions or comparisons into the paper. Overall, the comment is 4, as it effectively guides the authors toward improving the depth and accuracy of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to change the operator in Figure 2 from an addition to a Hadamard product between the DAG and Attention. This instruction is clear and direct, providing the authors with a specific action to take. The comment is concrete, as it specifies exactly what needs to be changed and how to implement it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely, the operator in Figure 2 should be a Hadamard product between the DAG and Attention, rather than an addition. This provides clear guidance on what needs to be revised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement suggesting a change in the operator used in Figure 2. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft. It identifies a potential error in the operator used in Figure 2, suggesting that it should be a Hadamard product between the DAG and Attention, rather than an addition. This feedback is clear and direct, offering the authors a concrete step to take to enhance the accuracy and clarity of their work. By addressing this issue, the authors can improve the technical correctness and presentation of their results. Therefore, the comment is 5, as it provides a clear and actionable suggestion that can significantly impact the quality of the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the authors have addressed the reviewer\"s concerns in their revision and response, specifically regarding the optimal rates for SOBA under additional smoothness assumptions. The reviewer has increased the score from 7 to 8 due to this improvement. However, the comment also notes that the limitations are only partially addressed, particularly regarding the nonstandard finite sum assumption and the discrepancy between theoretical and practical updates of SABA. While the comment highlights areas that need further attention, it does not provide explicit guidance on how the authors should address these limitations. The action is implicit and somewhat vague, as the authors are left to infer what specific changes are needed to fully address the limitations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"No.7. 2022. Post authors\" response,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as the limitations being only partially addressed and the need for more discussion on the nonstandard finite sum assumption and the discrepancy between theoretical and practical updates of SABA. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges that the authors have addressed the reviewer\"s concerns in their revision and response, specifically regarding the optimal rates for SOBA under additional smoothness assumptions. The reviewer has increased the score from 7 to 8 due to this improvement. However, the comment also notes that the limitations are only partially addressed, particularly regarding the nonstandard finite sum assumption and the discrepancy between theoretical and practical updates of SABA. While the comment provides some justification for the score increase, it lacks specific details or references to support the claim about the limitations being partially addressed. This makes the claim 3, as it provides some justification but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the authors have addressed the reviewer\"s concerns in their revision and response, specifically regarding the optimal rates for SOBA under additional smoothness assumptions. The reviewer has increased the score from 7 to 8 due to this improvement. However, the comment also notes that the limitations are only partially addressed, particularly regarding the nonstandard finite sum assumption and the discrepancy between theoretical and practical updates of SABA. While it highlights areas that need further attention, the comment does not provide specific suggestions or guidance on how the authors might fully address these limitations. The feedback is 3 as it points out areas for improvement but lacks depth and actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the claims made in the paper and the experimental results, specifically noting that UnKE\"s ability to retain original knowledge is worse than the baseline. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the issue or improve the draft, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that UnKE\"s ability to retain original knowledge is worse than the baseline, as evidenced by the results in the tables. The comment provides a specific reference to external work, which further supports the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s assertion about UnKE\"s ability to preserve pretrained knowledge during editing is contradicted by the experimental results, specifically noting that UnKE performs worse than the baseline in terms of retaining original knowledge (as shown in Table 2 and Table 3). The reviewer supports this claim by referencing an external work, \"Longform evaluation of model editing,\" which provides a detailed analysis of the issue. This external reference adds credibility to the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a discrepancy between the claims made in the paper and the experimental results, specifically regarding UnKE\"s ability to preserve pretrained knowledge during editing. It points out that UnKE performs worse than the baseline in terms of retaining original knowledge, as evidenced by the results in Tables 2 and 3. This feedback is valuable as it highlights a potential weakness in the paper\"s claims and provides specific references to the experimental results that support the critique. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or improve their methodology. Overall, the comment is 4 as it directs the authors\" attention to a critical area that needs further exploration or clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the explanation for the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first sight. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to improve the explanation and possibly move some details from the appendix to the main text. However, the comment lacks concrete details on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment addresses the explanation for the intention of BWTP/GLBW, which is mentioned in the appendix. However, it does not specify which part of the paper discusses BWTP/GLBW, making it weakly grounded. The comment is specific in pointing out the issue with the explanation and the location of the details in the appendix, but it lacks full grounding as it does not explicitly mention the section or figure where this information is presented. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the explanation for the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first sight. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or references, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 2, as it lacks sufficient evidence or explanation to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the explanation of the intention of BWTP/GLBW, noting that many details are in the appendix, which makes it difficult to understand at first sight. This feedback is 3 as it points out a potential barrier to understanding the paper, prompting the authors to consider how to improve the clarity and accessibility of their explanation. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending a reorganization of the content or providing examples of clearer explanations. To be more helpful, the comment could include actionable advice or examples of how to improve the clarity. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include a proof that was omitted due to space constraints, either in the main paper or as supplementary material. The comment provides a clear and direct action for the authors to take, specifying that they should include the proof in the revision. This feedback is concrete and actionable, as it leaves no ambiguity about what needs to be done. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of omitting a proof due to space constraints and suggests including it in the revision, either in the main paper or as supplementary material. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point suggests that a proof was omitted due to space constraints and requests that it be included in the revision, either in the main paper or as supplementary material. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or an addition to the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the omission of a proof due to space constraints. It provides a clear and actionable suggestion for the authors to include the proof, either in the main paper or as supplementary material. This feedback is valuable as it directs the authors to a specific area that needs attention and offers a concrete step to improve the draft. However, the comment could be more helpful if it provided additional context or rationale for why the proof is important or how it fits into the overall structure of the paper. Overall, the comment is 4, as it effectively guides the authors toward a meaningful improvement, but it could be more comprehensive with further explanation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide specific experimental results or references instead of relying on the statement \"Since the NPPs lack any direct dependence on magnitudes\" as the reason for NPPs performing worse than ETAS. This feedback is explicit and provides a clear action for the authors to take, which is to include specific experimental results or references to support their claims. The suggestion is concrete, as it specifies what needs to be added to the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests providing specific experimental results or references instead of relying on a general statement about the performance of NPPs compared to ETAS. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in suggesting the need for more detailed experimental results or references, but without clear grounding, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide specific experimental results or references instead of relying on a general statement about the performance of NPPs compared to ETAS. This is a claim that the current explanation is insufficient and requires more detailed evidence. However, the comment does not provide any specific reasoning or examples to support why the current explanation is inadequate or how the suggested experimental results or references would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide specific experimental results or references to support their claim that NPPs perform worse than ETAS. This feedback is clear and actionable, as it identifies a specific area where the paper lacks detailed evidence and suggests a way to improve it. By providing specific experimental results or references, the authors can strengthen their argument and enhance the credibility of their findings. However, the comment could be more helpful if it offered guidance on which specific results or references to include or how to present them. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the implementation details, specifically regarding the application of connectivity patterns to complex architectures like UNet, ResNet, and MobileNet. It notes that this issue is not addressed in the methodology section or the appendix. While the comment identifies a problem, it does not provide explicit guidance on how to address it or suggest specific actions for improvement. The authors are left to infer that they need to provide more detailed guidance on implementing the connectivity patterns for these complex architectures. However, the lack of concrete suggestions or examples makes the action vague, leaving the authors with limited direction on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, including Equations 3 and 4, Tables 1, 4, and 5, which allows the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out the lack of guidance on applying connectivity patterns to complex architectures like UNet, ResNet, and MobileNet, and the absence of these details in the appendix. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the implementation details are unclear, specifically regarding the application of connectivity patterns to complex architectures like UNet, ResNet, and MobileNet. The reviewer provides specific examples from the paper, such as Equations 3 and 4, and Tables 1, 4, and 5, which helps to ground the claim. However, the comment lacks detailed reasoning or examples of how these issues impact the paper\"s implementation or results. While the claim is somewhat supported by the references to specific sections, it could be strengthened with more detailed explanation or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of implementation details in the paper. It points out that while Equations 3 and 4 outline connectivity patterns between layers, there is no guidance on how to apply these connections to complex architectures like UNet, ResNet, and MobileNet, as shown in Tables 1, 4, and 5. This lack of clarity is highlighted as a problem that hinders the reviewer\"s understanding of the paper. The comment also notes that these details are not included in the appendix, which further complicates the issue. While the comment effectively identifies a critical area for improvement, it could be more helpful by suggesting specific ways to address the issue, such as providing examples or additional explanations. Overall, the feedback is 3 as it directs the authors\" attention to a significant weakness in their draft, but it could be more actionable with additional guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should experiment with other languages and annotations to verify the scalability of their HTER label calculation. This is an explicit action, as it directly instructs the authors to conduct additional experiments. However, the comment does not provide specific guidance on how to conduct these experiments or what specific languages or annotations to use. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the calculation of HTER label, which is based on automatic scripts, and suggests that it may not be scalable to other annotations like MQM or DA. However, it does not specify which part of the paper discusses this calculation, making it weakly grounded. The comment is specific in suggesting that the authors should experiment with other languages and annotations to verify scalability, but it lacks detailed guidance on how to conduct these experiments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the calculation of HTER label based on automatic scripts may not be scalable to other annotations like MQM or DA. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the calculation of HTER label, suggesting that it may not be scalable to other annotations like MQM or DA. It provides a clear suggestion for the authors to experiment with other languages and annotations to verify the scalability of their approach. This feedback is actionable and offers a specific direction for the authors to improve their work by expanding their experiments. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific annotations to consider. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with further details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about how overall performance depends on $m$ in $G_m$. While it implies that the authors should provide an explanation or analysis on this relationship, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the question. The authors can infer that they need to provide an analysis or discussion on the impact of $m$ on overall performance, but the comment does not offer detailed instructions on how to conduct this analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment poses a question about how overall performance depends on $m$ in $G_m$. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. Without explicit references, the authors may find it challenging to determine where this question should be addressed in the paper. Additionally, the comment lacks specificity regarding what aspects of performance or $m$ are being considered. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on how overall performance depends on $m$ in $G_m$. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about how overall performance depends on $m$ in $G_m$. While it highlights an area that may need further clarification or analysis, it does not provide any specific suggestions or guidance on how the authors might address this question or improve their draft. The comment lacks actionable feedback or detailed insights that could help the authors enhance their work. As a result, it is 2, as it identifies a potential area of interest but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a theoreticalpractical gap in deep learning research, specifically mentioning the difficulty of fitting sparse neural nets. It suggests that the authors should comment on this gap and discuss the key elements that allow CausalStonet to learn sparse neural nets. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the specific aspects they should discuss. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a theoreticalpractical gap in deep learning research, specifically mentioning the difficulty of fitting sparse neural nets. It references a specific work by Farrell, Liang, and Misra (ECTA 2021) to support the claim. However, the comment does not specify which part of the paper should include this discussion or where the authors should comment on the key elements of CausalStonet. While the authors might infer that this relates to the theoretical aspects of the paper, the lack of explicit grounding makes it difficult to pinpoint the exact section. The comment is specific in identifying the issue and suggesting a potential solution, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a theoreticalpractical gap in deep learning research, specifically mentioning the difficulty of fitting sparse neural nets. It references a specific work by Farrell, Liang, and Misra (ECTA 2021) to support this claim. The reference provides a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a theoreticalpractical gap in deep learning research, specifically mentioning the difficulty of fitting sparse neural nets. It references a specific work by Farrell, Liang, and Misra (ECTA 2021) to support this claim. The comment suggests that the authors should comment on this gap and discuss the key elements that allow CausalStonet to learn sparse neural nets. This feedback is clear and actionable, as it directs the authors to address a specific issue and provides a reference to support their discussion. However, the comment could be more helpful if it offered specific suggestions on how to integrate this discussion into the paper or provided examples of key elements to focus on. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the manuscript is densely packed, with figures and tables positioned closely to the text, which can make the paper seem cluttered and condensed. It provides specific actions for the authors to consider, such as making some tables smaller or relocating them to the Appendix (e.g., Table 1), and possibly reducing the size of certain figures (e.g., Figure 2 with fewer datasets). The comment also notes that these changes can be made in the cameraready version if the paper is accepted. The actions are explicit and provide concrete guidance on how to address the issue, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figures and tables\" and \"the text,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. The comment also notes that these changes can be made in the cameraready version if the paper is accepted. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the manuscript is densely packed, with figures and tables positioned closely to the text, which can make the paper seem cluttered and condensed. The reviewer suggests that the authors consider making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. This feedback is based on a logical observation about the layout and presentation of the paper, which is a common practice in academic writing. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact changes needed to address the issue, which could be challenging without detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the layout of the manuscript, noting that the figures and tables are positioned too closely to the text, which can make the paper seem cluttered and condensed. It provides actionable suggestions for improvement, such as making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. The comment also acknowledges that these changes can be made in the cameraready version if the paper is accepted. This feedback is clear and offers concrete steps for the authors to enhance the readability and presentation of their work, making it 4. However, it could be more helpful if it included specific examples of tables or figures that could be improved, which would provide even more detailed guidance. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the ReCPE method proposed in the article is too strategic and lacks theoretical guarantees. It suggests that the authors could strengthen the article by addressing this perspective. However, the comment does not provide specific guidance on how to strengthen the theoretical guarantees or what aspects of the method need improvement. The suggestion is implicit and lacks concrete details, making it 3. The authors can infer that they need to provide more theoretical justification for their method, but without explicit instructions, the action is not fully defined.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Note 2 on page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the incorrect spelling of \"real word\" and suggesting a way to improve the article by strengthening the theoretical guarantees of the ReCPE method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the ReCPE method is \"too strategic\" and lacks theoretical guarantees. However, the comment does not provide any specific examples, reasoning, or references to support this claim. The mention of \"intuitively\" suggests a subjective opinion, but without further elaboration or evidence, the claim remains 1. The inclusion of a minor comment about spelling does not affect the verifiability of the main claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: the strategic nature of the ReCPE method and the lack of theoretical guarantees. It suggests that the authors could strengthen their article by addressing these aspects. However, the comment lacks specific guidance or suggestions on how to enhance the theoretical foundation or make the method more robust. While it points out a minor spelling error, this does not significantly contribute to the overall improvement of the draft. The feedback is 3 as it highlights important areas for improvement but does not provide detailed guidance on how to address them. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the applicability of the method to generation tasks, other than NLU tasks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should explore this possibility, conduct experiments, or make any changes to their draft. The comment lacks actionable advice, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the method to generation tasks, other than NLU tasks. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide details on what aspects of the method might be relevant to generation tasks or how the authors could address this question. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the applicability of the method to generation tasks, other than NLU tasks. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of the method to generation tasks, other than NLU tasks. While it identifies a potential area for exploration, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or conduct further research. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is 2, as it points out a possible direction but does not provide enough detail or direction for the authors to act upon."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that $N_d$ is not defined and suggests that it would be beneficial to state explicitly that there could be a different number of observations per task. This feedback provides a clear and direct action for the authors to take, which is to define $N_d$ and clarify the potential variation in observations per task. The comment is specific and actionable, as it guides the authors on what needs to be addressed in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 145 and onward, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of $N_d$ not being defined and suggests that it would be beneficial to explicitly state that there could be a different number of observations per task. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that $N_d$ is not defined and suggests that it would be beneficial to explicitly state that there could be a different number of observations per task. This is a factual observation that does not require verification or justification. The comment is purely descriptive and does not contain any subjective opinions, claims, or suggestions that would necessitate verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that $N_d$ is not defined. It provides a clear and actionable suggestion by recommending that the authors explicitly state that there could be a different number of observations per task. This feedback is valuable as it directs the authors to a specific area that needs clarification, which can help improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided additional context or examples on how to address this issue. Overall, the comment is 4, as it offers a clear direction for improvement but lacks depth in its guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a formatting issue regarding the appendix, specifically noting that it is not cut from the main paper and that the provided PDF is a 14page document. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address this issue, such as whether the appendix should be separated or if the PDF should be revised. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Appendix\" and the \"main paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a formatting issue regarding the separation of the appendix from the main paper and notes the length of the PDF provided. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual statement about the format of the paper, specifically noting that the appendix is not cut from the main paper and that the provided PDF is a 14page document. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a formatting issue regarding the appendix, noting that it is not cut from the main paper and that the provided PDF is a 14page document. While this is a factual observation, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this issue or why it is important. As a result, the comment is 1, as it does not assist the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more insight into the main improvement in the proposed model, specifically the ternary potential. It implies that the authors should explain why the ternary potential is crucial for the model\"s performance and how it compares to existing models. While the comment explicitly states the need for additional explanation, it does not provide specific guidance on how to present this information or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to provide more explanation but may not be entirely sure of the exact details to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the main improvement in the proposed model coming from the ternary potential. The comment suggests that the authors should provide more insight into this aspect, particularly in relation to the existing models. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the main improvement in the proposed model is coming from the ternary potential, and without it, the model does not outperform existing models for a 2modality setup (except for HieCoAtt). However, the comment does not provide specific evidence or references to support this claim, such as comparisons with other models or detailed analyses of the results. The lack of supporting information makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the main improvement in the proposed model, which is attributed to the ternary potential. It points out that without the ternary potential, the proposed model does not outperform existing models for a 2modality setup, except for HieCoAtt. This feedback is clear and actionable, as it prompts the authors to provide more insight into the role of the ternary potential and its impact on the model\"s performance. By addressing this point, the authors can enhance the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it provided specific suggestions on how to present this information or what aspects to focus on. Overall, the comment is 4, as it directs the authors to a critical area that requires further explanation."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include additional information in their tables to facilitate a more straightforward assessment of the comparisons. Specifically, it recommends noting which methods use data augmentations, what architecture they use, and what objective they employ. While the comment implies that these details should be added, it does not explicitly instruct the authors to do so. The action is concrete, as it provides clear guidance on what information should be included, but it is implicit in nature. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests adding information to the tables to facilitate a more straightforward assessment of the comparisons. It explicitly mentions the need to note which methods use data augmentations, what architecture they use, and what objective they employ. This provides clear guidance on what specific information should be included. However, the comment does not specify which tables or sections of the paper these details should be added to, making it weakly grounded. The authors can infer that it pertains to the tables containing comparisons, but the exact location is not explicitly mentioned. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that including information about data augmentations, architecture, and objectives would aid in assessing the comparisons in the tables. The claim is 3 as it provides a logical reasoning for why this information would be beneficial, but it lacks specific examples or references to support the assertion that data augmentations were not common practice for fewshot classification until recently. Providing more detailed evidence or references would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity and comparability of the results presented in the tables. It recommends including information about data augmentations, architecture, and objectives used in the methods being compared, which would help readers better understand the degree of \"applestoapplesness\" in the comparisons. This feedback is clear and offers a concrete way for the authors to enhance the transparency and comprehensiveness of their results. However, the comment could be more helpful if it also suggested how this information might be integrated into the tables or provided examples of how it could be presented. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the claim that hyperpruning methods would beat the state of the art, noting that the architectures used (LSTM and LSH networks) are not state of the art for language modeling. It suggests that it would be interesting to see how LSH performs on actual stateoftheart models and questions the applicability of the results to more recent benchmarks and architectures. While the comment implies that the authors should address these concerns, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or provide more context to support their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"hyperpruning methods\" and the \"LSTM and LSH networks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the claim that hyperpruning methods would beat the state of the art, particularly in the context of language modeling. The comment further suggests that it would be interesting to see how LSH performs on actual stateoftheart models and questions the applicability of the results to more recent benchmarks and architectures. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point raises a claim about the paper\"s assertion that hyperpruning methods would beat the state of the art, questioning the validity of this claim due to the use of LSTM and LSH networks, which are not considered stateoftheart for language modeling. The reviewer suggests that it would be interesting to see how LSH performs on actual stateoftheart models and questions the applicability of the results to more recent benchmarks and architectures. While the comment provides a logical reasoning for questioning the claim, it lacks specific references or detailed examples to fully substantiate the critique. This makes the claim 3, as it requires additional evidence or context to be fully supported. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical point about the paper\"s claim that hyperpruning methods would beat the state of the art, questioning the validity of this claim due to the use of LSTM and LSH networks, which are not considered stateoftheart for language modeling. The reviewer suggests that it would be interesting to see how LSH performs on actual stateoftheart models and questions the applicability of the results to more recent benchmarks and architectures. This feedback is valuable as it highlights a potential weakness in the paper\"s claims and encourages the authors to provide more context and evidence to support their assertions. However, the comment could be more helpful if it offered specific suggestions on how to address these concerns or provided examples of stateoftheart models to consider. Overall, the comment is 4 as it directs the authors\" attention to a critical area that needs further exploration and justification."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include more experimental details, such as neural networks and hyperparameters, in the appendix. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be added to their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests including more experimental details, such as neural networks and hyperparameters, in the appendix. However, it does not specify which part of the paper these details should be added to, making it weakly grounded. The comment is specific in its request for additional information, but without clear grounding, the authors may struggle to determine where to make these additions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including more experimental details, such as neural networks and hyperparameters, in the appendix. This is a request for additional information rather than a claim or opinion. It does not contain subjective judgments, suggestions, or deductions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of more experimental details, such as neural networks and hyperparameters, in the appendix. This feedback is specific and offers a concrete way for the authors to enhance the transparency and comprehensiveness of their work. By addressing this feedback, the authors can provide readers with a more detailed understanding of their experimental setup, which is crucial for reproducibility and validation of their results. However, the comment could be more helpful if it specified which specific details should be included or why they are important. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that section 5.1 does not provide useful information regarding why the new model is superior. However, it does not specify what kind of information is missing or how the authors could address this issue. The comment lacks explicit guidance or concrete suggestions on how to improve the section, leaving the authors uncertain about what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of useful information regarding why the new model is superior. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that section 5.1 does not provide useful information regarding why the new model is superior. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific section of the paper, section 5.1, and points out that it does not provide useful information regarding why the new model is superior. This feedback is 3 as it highlights a potential gap in the paper that the authors need to address. However, the comment lacks specificity and does not provide suggestions or guidance on how to improve the section or what additional information could be included. To be more helpful, the comment could offer examples of what kind of information would be beneficial or suggest ways to enhance the section. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a comparison is necessary to evaluate the transferability of the singleIMP, implying that the authors should include such a comparison in their draft. While the comment explicitly states the need for a comparison, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to include a comparison but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a comparison is necessary to evaluate the transferability of the singleIMP, implying that the authors should include such a comparison in their draft. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on what aspects of transferability should be compared. This lack of specificity and grounding makes it difficult for the authors to identify the exact area that needs attention. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a comparison is necessary to evaluate the transferability of the singleIMP, implying that the current analysis may not fully capture its transferability. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why a comparison is needed or how it would improve the analysis. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that a comparison is necessary to evaluate the transferability of the singleIMP, implying that the current analysis may not fully capture its transferability. This feedback is 3 as it identifies a potential area for improvement by suggesting a comparison that could enhance the understanding of the singleIMP\"s transferability. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects to focus on. While it points out a relevant area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that there are no specific ethical concerns with the proposed methods but suggests that the authors consider checking humanfactors literature on creating systems that effectively interact with people. While the comment implies that the authors should explore this area, it does not provide specific guidance on how to incorporate this literature or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should explore humanfactors literature and determine how to integrate it into their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"No.03. 2020,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors consider checking humanfactors literature on creating systems that effectively interact with people. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point acknowledges that there are no specific ethical concerns with the proposed methods but suggests that the authors consider checking humanfactors literature on creating systems that effectively interact with people. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely descriptive and factual, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment acknowledges that there are no specific ethical concerns with the proposed methods but suggests that the authors consider checking humanfactors literature on creating systems that effectively interact with people. This feedback is 3 as it points out a potential area for improvement by suggesting a specific domain of literature that could be relevant to the authors. However, the comment lacks depth and does not provide specific guidance on how to incorporate this literature or what aspects to focus on. While it offers a direction for further exploration, it does not fully support the authors in making actionable improvements to their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scalability of the proposed model selection approach beyond the MNISTfashion dataset and suggests comparing it with other neural network pruning methods. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to conduct additional experiments or comparisons. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments to include other datasets and compare their approach with existing methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the proposed model selection approach beyond the MNISTfashion dataset and suggests comparing it with other neural network pruning methods. However, it does not specify which part of the paper discusses the experiments or the proposed model selection approach, making it weakly grounded. The comment is specific in suggesting the need for scalability testing and comparison with other methods, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the scalability of the proposed model selection approach beyond the MNISTfashion dataset and suggests comparing it with other neural network pruning methods. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the scalability of the proposed model selection approach beyond the MNISTfashion dataset. It suggests that the authors should consider testing their approach on other datasets to demonstrate its applicability and scalability. Additionally, the comment suggests comparing the proposed approach with other neural network pruning methods, which could provide a more comprehensive evaluation of the model selection approach. While the comment identifies important areas for improvement, it lacks specific guidance on how to conduct these comparisons or which datasets to consider. This limits the helpfulness of the feedback, as it provides a general direction but not detailed actionable steps. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point identifies several mathematical formulation issues and inconsistencies throughout the paper, providing specific examples of where these problems occur. The reviewer explicitly points out these issues, such as the use of \"max\" instead of \"shouldn\"t it be $max$?\" and the inconsistent use of indices, which are clear actions for the authors to address. The comment is explicit and provides concrete details on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and equations in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the mathematical formulation issues and inconsistencies, providing clear examples of what needs to be corrected. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point identifies several mathematical formulation issues and inconsistencies, providing specific examples of where these problems occur. The reviewer points out specific lines in the paper where these issues are present, such as the use of \"max\" instead of \"$max$,\" the inconsistent use of indices, and the redundant \"$x\"$\" in the hypervolume formula. This level of detail and specificity provides a clear basis for the reviewer\"s claim, making it 5. The authors can easily understand and address the issues raised, ensuring the paper\"s mathematical rigor and clarity.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on mathematical formulation issues and inconsistencies in the paper. It identifies several problematic areas, such as the use of \"max\" instead of \"$max$,\" the inconsistent use of indices, and the redundant \"$x\"$\" in the hypervolume formula. By pointing out these specific errors, the comment empowers the authors to make precise corrections, ensuring the mathematical rigor and clarity of their work. The detailed nature of the feedback makes it 5, allowing the authors to address these issues effectively and improve the overall quality of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests conducting experiments to show the effect of using different numbers of particles. It highlights the lack of clarity regarding the importance of this choice. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on how to design or execute these experiments. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments to show the effect of using different numbers of particles, indicating that the importance of this choice is unclear. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for experiments to clarify the importance of the choice, but without grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting experiments to show the effect of using different numbers of particles, indicating that the importance of this choice is unclear. However, the comment does not provide any specific reasoning, examples, or references to support why this information is crucial or how it would enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting experiments to show the effect of using different numbers of particles, indicating that the importance of this choice is unclear. This feedback is 3 as it points out a potential area for improvement by suggesting additional experiments that could provide valuable insights. However, the comment lacks specificity and does not offer detailed guidance on how to design or execute these experiments, nor does it explain why this information is crucial. While it provides a direction for enhancing the paper, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks a comparison of methods on plasticity evaluation metrics, such as the covariance metric. It provides a specific suggestion by referencing a particular metric, 1, which the authors can use to guide their comparison. This feedback is clear and actionable, as it directly instructs the authors to include a comparison using the specified metric. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison of methods on plasticity evaluation metrics, such as the covariance metric. This allows the authors to accurately identify the part of the paper being addressed, specifically the sections related to method comparisons. The comment is also specific because it provides a clear suggestion to include a comparison using the specified metric, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison of methods on plasticity evaluation metrics, such as the covariance metric. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks comparison of methods on plasticity evaluation metrics, such as the covariance metric. This feedback is clear and actionable, as it provides a concrete suggestion for improvement by recommending the inclusion of a particular metric. By addressing this point, the authors can enhance the comprehensiveness and rigor of their analysis, making the comment 4. However, the comment could be more helpful if it provided additional context or examples of how this comparison might be conducted, which would further guide the authors in implementing the suggestion. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Table 5 needs better explanation and asks for clarification on what A, B, C, and D represent. It also requests an explanation of why positive paths lead to monotonic solutions and under what scenarios. These are clear and direct actions for the authors to take, providing concrete guidance on how to improve the draft. The comment is explicit and provides specific details on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of what A, B, C, and D represent in Table 5, and why positive paths lead to monotonic solutions and under what scenarios. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements requesting clarification and additional explanation regarding Table 5. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that Table 5 needs better explanation. It asks for clarification on what A, B, C, and D represent and why positive paths lead to monotonic solutions. This feedback is clear and actionable, as it directs the authors to provide additional information and context in their table. However, the comment could be more helpful if it suggested specific ways to enhance the explanation or provided examples of what additional information might be relevant. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their table."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the feasibility of using a proxy or surrogate method to estimate the US accuracy, given the long time it takes to obtain a single US accuracy. It also suggests that an early prediction of US accuracy may not be a reliable predictor of DS accuracy, as seen in Figure 1. The reviewer further questions the applicability of power law prediction for model selection, referencing specific figures in the Appendix. While the comment raises important questions and points out potential issues, it does not provide explicit instructions or concrete suggestions for the authors to address these concerns. The authors are left to infer that they should explore alternative methods or provide further justification for their approach. Therefore, the comment is 3, as it highlights areas for consideration but lacks specific guidance on how to address them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and specific figures in the Appendix (F6, F7, F8, F9), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the early prediction of US accuracy and questions the applicability of power law prediction for model selection. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the feasibility of using a proxy or surrogate method to estimate the US accuracy, given the long time it takes to obtain a single US accuracy. It also questions the reliability of early predictions of US accuracy based on Figure 1, suggesting that power law prediction may not be suitable for model selection. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The absence of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some insight but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment raises an important question about the feasibility of using a proxy or surrogate method to estimate the US accuracy, given the long time it takes to obtain a single US accuracy. It also points out that an early prediction of US accuracy may not be a reliable predictor of DS accuracy, as seen in Figure 1. This feedback is 3 as it prompts the authors to consider alternative methods or provide further justification for their approach. However, the comment could be more helpful if it offered specific suggestions or examples of alternative methods that could be explored. Overall, the comment provides a valuable insight into a potential limitation of the current approach, but it lacks depth and actionable guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide ablation studies that isolate the impact of specific factors underlying epsilon sampling\"s strong performance. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be done to improve their draft. The comment provides concrete guidance on how to enhance the paper by identifying a specific type of study that could be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\"s strong performance. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or analysis where these ablation studies could be included. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for ablation studies, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\"s strong performance. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these ablation studies are necessary or how they would contribute to the paper\"s understanding. Without such support, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\"s strong performance. This feedback is clear and actionable, as it identifies a specific area for improvement that could enhance the understanding and interpretation of the results. By recommending ablation studies, the comment provides a concrete step for the authors to take to strengthen their analysis and presentation of the findings. However, the comment could be more helpful if it specified which factors should be isolated or provided examples of similar studies that could guide the authors. Overall, the comment is 4 as it offers a clear direction for enhancing the paper, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate how well their proposed attack performs against the mode connectivitybased defense proposed in the ICLR paper \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness.\" While the comment implies that the authors should conduct this evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the evaluation or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ICLR publication \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should do, which is to evaluate how well their proposed attack performs against the mode connectivitybased defense proposed in the ICLR paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point references a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" to support the claim that FineTuning is not the most effective approach to recover backdoor models. The reviewer suggests evaluating the proposed attack against the mode connectivitybased defense proposed in the ICLR paper. This provides a clear basis for the claim, as it references a relevant study and suggests a specific area for further evaluation. However, the comment could be strengthened by providing more detailed reasoning or examples of how the proposed attack might interact with the mode connectivity defense. Overall, the claim is 4, as it is supported by a reference but could benefit from additional explanation or examples.", "helpfulness_rationale": "The review comment references a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" which discusses the effectiveness of FineTuning in recovering backdoor models. It suggests that the authors should evaluate how well their proposed attack performs against the mode connectivitybased defense proposed in the ICLR paper. This feedback is clear and actionable, as it provides a specific area for the authors to explore and potentially improve their work. By suggesting a comparison with a known defense mechanism, the comment offers a concrete direction for the authors to enhance their draft. However, it could be more helpful if it included additional guidance on how to conduct this evaluation or what specific aspects to focus on. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors\" decision not to include the codes during the review process makes the claims less transparent. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should include the codes, how they should address the issue of transparency, or what specific changes are needed to improve the transparency of their claims. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" decision not to include codes during the review process, which it claims makes the claims less transparent. However, it does not specify which part of the paper this issue pertains to, such as a specific section or methodology where the codes would be relevant. Additionally, the comment lacks specificity regarding what aspects of the claims are less transparent due to the absence of codes. Without clear grounding and specificity, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors\" decision not to include codes during the review process makes the claims less transparent. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the absence of codes affects the transparency of the claims. Without specific details or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the authors\" decision not to include codes during the review process, suggesting that this could make the claims less transparent. However, the comment lacks specificity and does not provide any actionable advice or suggestions on how the authors might address this issue or improve the transparency of their claims. Without detailed guidance or examples, the authors are left without a clear understanding of what steps to take to enhance the clarity and transparency of their work. Therefore, the comment is 2, as it identifies a potential problem but does not offer meaningful guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed approach does not need to be validated using Waymax, which provides more traffic scenarios than the current version. However, it does not provide explicit guidance on how the authors should proceed or what specific actions they should take to address this suggestion. The comment lacks concrete details on how to implement the proposed change or what alternative validation methods might be considered. As a result, the authors are left without a clear understanding of how to apply the feedback, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that the proposed approach does not need to be validated using Waymax, which provides more traffic scenarios than the current version. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in suggesting an alternative validation method using Waymax, but without clear grounding, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed approach does not need to be validated using Waymax, which provides more traffic scenarios than the current version. However, the comment does not provide any reasoning or evidence to support why the current validation is insufficient or why Waymax would be a better choice. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the proposed approach does not need to be validated using Waymax, which provides more traffic scenarios than the current version. While it identifies a potential area for improvement by suggesting an alternative validation method, the comment lacks specificity and does not provide detailed guidance on how to implement this suggestion or why it would be beneficial. The feedback is 3 as it points out a possible enhancement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the technical contribution of the paper, suggesting that the transformerbased TAPG method has been studied in previous works and that the main difference lies in the use of visual features, 3D pose, and action features obtained by Laban Movement Analysis (LMA). The reviewer argues that LMA has been proven effective in dance action recognition, making the addition of these features not particularly surprising. While the comment highlights a potential limitation, it does not provide explicit guidance or suggestions for improvement. The authors are left to infer that they might need to further differentiate their contribution or provide additional insights, but the comment lacks concrete steps or actions to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, specifically mentioning the transformerbased TAPG method and its comparison to previous works like RTDNet. It highlights the main difference between the two methods as the use of visual features, 3D pose, and action features obtained by Laban Movement Analysis (LMA). However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the critique of the technical contribution and the potential limitations of the additional features, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing revision. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is not significant, suggesting that the transformerbased TAPG method has been studied in previous works and that the main difference lies in the use of visual features, 3D pose, and action features obtained by Laban Movement Analysis (LMA). The reviewer argues that LMA has been proven effective in dance action recognition, making the addition of these features not particularly surprising. While the comment provides some reasoning, it lacks specific references or detailed examples to fully substantiate the claim. The lack of concrete evidence or detailed reasoning makes the claim 3, as the authors might need to further explore the context and evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the technical contribution of the paper, suggesting that the transformerbased TAPG method has been studied in previous works and that the main difference lies in the use of visual features, 3D pose, and action features obtained by Laban Movement Analysis (LMA). The reviewer argues that LMA has been proven effective in dance action recognition, making the addition of these features not particularly surprising. While the comment identifies a potential limitation in the novelty of the contribution, it lacks specific suggestions or guidance on how the authors might address this issue or enhance the significance of their work. The feedback is 3 as it points out a weakness, but it does not provide actionable steps for improvement, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the implementation of tree construction should include more experimental comparisons regarding the different design choices of merging nodes among adjacent layers. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on which comparisons to make or how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the implementation of tree construction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that more experimental comparisons are needed regarding the different design choices of merging nodes among adjacent layers. This provides clear guidance on what aspect of the paper needs further exploration. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the implementation of tree construction should include more experimental comparisons regarding the different design choices of merging nodes among adjacent layers. However, the comment does not provide any specific reasoning, examples, or references to support why these comparisons are necessary or how they would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the implementation of tree construction, suggesting that more experimental comparisons are needed regarding the different design choices of merging nodes among adjacent layers. This feedback is 3 as it points out a potential gap in the experimental analysis, prompting the authors to consider additional comparisons that could enhance the understanding of their approach. However, the comment lacks specific guidance on which comparisons to make or how to conduct them, leaving the authors with a general direction but not a detailed roadmap for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to complete Table 2 by including baselines that outperform the reported results. It also specifies that these baselines are reported in the ReBART paper, providing a clear reference for the authors to follow. This feedback is direct and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing from the table, namely the inclusion of baselines that outperform the reported results. The comment provides a reference to the ReBART paper, which further supports the need for these baselines to be included. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 2 is incomplete because it hides several baselines that outperform the reported results. The reviewer supports this claim by referencing the ReBART paper, which is an external source that provides evidence for the existence of these baselines. This reference adds credibility to the claim, making it 4. However, the comment could be strengthened by providing more detailed information about the specific baselines or their performance relative to the reported results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 2, noting that it is incomplete and hides baselines that outperform the reported results. It provides a reference to the ReBART paper, which suggests that these baselines should be included for completeness, even though their results are slightly weak. This feedback is clear and actionable, as it directs the authors to address a specific omission in their work. By including these baselines, the authors can provide a more comprehensive comparison and enhance the transparency of their results. However, the comment could be more helpful if it offered suggestions on how to present these additional results or discussed the implications of these findings. Overall, the comment is 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluations on real datasets could be more thorough and questions the choice of only three scenes from the HSERGB dataset. It implies that the authors should consider evaluating on other sequences as well. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to conduct these additional evaluations or which sequences to consider. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluations and determine which sequences to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluations on real datasets, specifically questioning the choice of only three scenes from the HSERGB dataset. It implies that the evaluations could be more thorough and suggests considering performance on other sequences. However, the comment does not specify which part of the paper discusses these evaluations, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but the exact location is not explicitly mentioned. The comment is specific in suggesting that more scenes should be evaluated, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the thoroughness of the evaluations on real datasets, specifically asking why only three scenes from the HSERGB dataset were chosen and suggesting that performance on other sequences should be considered. This is a request for clarification or additional information, rather than a claim or opinion that requires verification. It does not present subjective judgments, suggestions, or deductions that need to be supported. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper\"s evaluation on real datasets. It questions the choice of only three scenes from the HSERGB dataset and suggests that the performance on other sequences should be considered. This feedback is clear and actionable, as it prompts the authors to expand their evaluations to include more scenes or sequences, which could enhance the robustness and comprehensiveness of their results. However, the comment could be more helpful if it provided specific suggestions on which sequences to consider or how to conduct these additional evaluations. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of 44 bits and suggests that more bits could be used without affecting computation time on GPU. It also questions the interpretation of bitembeddings, noting that the model is predicting the rank of words rather than their semantic relations. The reviewer implies that the model might be memorizing the data rather than understanding it. While the comment identifies areas for potential improvement, it does not provide explicit or concrete actions for the authors to take. The authors can infer that they should explore using more bits and consider the implications of predicting ranks, but the comment lacks specific guidance on how to address these issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the use of 44 bits and questions the interpretation of bitembeddings, suggesting that the model is predicting the rank of words rather than their semantic relations. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the use of bits and the interpretation of bitembeddings, but without clear references to specific sections, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of 44 bits and questions the interpretation of bitembeddings, suggesting that the model is predicting the rank of words rather than their semantic relations. The reviewer provides a logical reasoning by pointing out that using more bits would not significantly impact computation time on GPU, implying that the current choice is unnecessary. However, the comment lacks specific examples or references to support the claim about the model predicting ranks, which makes it 3. The authors would need to further explore and substantiate the claim to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises two specific concerns: first, it questions the use of 44 bits, suggesting that more bits could be used without affecting computation time on GPU, and second, it questions the interpretation of bitembeddings, noting that the model is predicting the rank of words rather than their semantic relations. The reviewer also poses a question about the semantic relations of words with odd ranks, implying that the model might be memorizing the data rather than understanding it. While the comment identifies areas for potential improvement and raises thoughtprovoking questions, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it prompts the authors to reconsider their approach and provides a basis for further exploration, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed method, specifically that it requires human annotation for providing semantically meaningful information, which can be subjective. The authors are informed of this issue and are aware that it is mentioned in the appendix. However, the comment does not provide any explicit or implicit suggestions for addressing this limitation or mitigating the subjectivity of the human annotation process. Without guidance on how to improve this aspect of the method, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the practical use of the method, specifically the requirement for human annotation to provide semantically meaningful information. It mentions that this limitation is discussed in the appendix, providing some grounding. However, the comment does not specify which part of the appendix this discussion is in, making it weakly grounded. The comment is specific in detailing the issue of subjectivity in human annotation and the lack of a solution for mitigation, but it does not provide guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method requires human annotation for providing semantically meaningful information, which can be subjective. The reviewer acknowledges that the authors mention this limitation in the appendix but criticizes them for not providing a solution for mitigation. This claim is 3 as it highlights a potential issue with the method and references the appendix for context. However, the comment lacks specific examples or detailed reasoning on how the subjectivity of human annotation could be mitigated, which would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation of the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. It acknowledges that the authors have mentioned this limitation in the appendix but points out that they have not provided a solution for mitigation. This feedback is 3 as it highlights a critical area for improvement and prompts the authors to address the issue of subjectivity in their methodology. However, the comment could be more helpful if it offered suggestions or potential solutions for mitigating the subjectivity of human annotation. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit instructions for the authors to pretrain a CausalLM using a specific dataset, excluding certain datasets used by ObscuraCoder. It also suggests comparing the performance of this pretraining against ObscuraCoder to attribute any improvements to the deobfuscation objective. These actions are clear and concrete, leaving no ambiguity about what the authors need to do to address the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment provides specific instructions for the authors to pretrain a CausalLM using a specific dataset, excluding certain datasets used by ObscuraCoder. It also suggests comparing the performance of this pretraining against ObscuraCoder to attribute any improvements to the deobfuscation objective. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or experimental sections, but this inference is not as direct as it could be. The comment is specific in detailing the actions needed, such as pretraining and performance comparison. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests pretraining a CausalLM using a specific dataset and comparing its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. However, the comment does not provide any reasoning, evidence, or references to support why this approach is necessary or how it would contribute to the paper\"s objectives. Without such justification, the claim remains 1, as the authors would need to infer the rationale themselves. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting a method for pretraining a CausalLM using a specific dataset and comparing its performance against ObscuraCoder. This recommendation aims to attribute any improvements to the deobfuscation objective, which is a clear and constructive suggestion for enhancing the paper. By following this advice, the authors can strengthen their experimental setup and provide a more robust analysis of their results. However, the comment could be more helpful if it explained why this approach is necessary or how it would address specific weaknesses in the current methodology. Overall, the feedback is 4 as it offers a concrete way to improve the paper, but it could be more comprehensive with additional context or rationale."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to add the geometric loss to the reconstruction loss, rather than having it as itself. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on how to modify the loss equation, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines in the paper where the loss equation is discussed (L264L266), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the loss equation, namely that the geometric loss should be added to the reconstruction loss rather than being itself. This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement that provides a specific suggestion for improving the loss equation. It does not contain any subjective opinions, claims, or requests for changes that would require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the loss equation, suggesting that the geometric loss should be added to the reconstruction loss rather than being itself. This feedback is clear and actionable, providing the authors with a precise direction for improving their draft. By addressing this minor but important detail, the authors can enhance the clarity and accuracy of their work. However, the comment could be more helpful if it explained why this change is necessary or how it might impact the overall results. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the method should also be employed in autoregressive language models, which are used more in realworld applications. However, it does not provide any explicit instructions or concrete steps for the authors to follow. The comment lacks specificity and does not offer guidance on how to implement this suggestion or what specific aspects of the method should be applied to autoregressive language models. As a result, the authors are left without a clear understanding of what actions to take to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method should also be employed in autoregressive language models, which are used more in realworld applications. However, it does not specify which part of the paper this suggestion pertains to, nor does it provide details on how the method should be applied or what specific improvements are needed. Without explicit references to sections or examples, the authors cannot confidently determine which parts of the paper need revision. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the method should also be employed in autoregressive language models, which are used more in realworld applications. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this suggestion is necessary or beneficial. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method should also be employed in autoregressive language models, which are used more in realworld applications. While it highlights a potential area for improvement, the comment lacks specificity and does not provide actionable guidance or detailed suggestions on how to implement this suggestion. It does not offer insights into why autoregressive language models are more relevant or how the method could be adapted for these models. As a result, the feedback is 3, as it points out a possible direction for expansion but does not fully support the authors in making improvements to their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the clarity of the paper regarding the proposed idea being better than GAN and the avoidance of issues like vanishing gradients and model collapsing. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The comment implies that the authors should clarify their claims and provide more detailed information on how their method avoids these issues, but it lacks concrete steps or examples for the authors to follow. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the claim that the GAN is difficult to optimize and suggests that the proposed idea is not clearly better than GAN. It also questions the presentation of how to avoid issues like vanishing gradients and model collapsing in the proposed method. However, the comment does not specify which part of the paper these claims are based on, making it weakly grounded. The authors can infer that it relates to the method section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, such as clarifying the advantages of the proposed idea and presenting a solution to the vanishing gradient issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the difficulty of optimizing GANs and suggests that the proposed idea is not clearly better than GAN. It also questions the presentation of how to avoid issues like vanishing gradients and model collapsing in the proposed method. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The absence of concrete evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the paper regarding the proposed idea being better than GAN and the avoidance of issues like vanishing gradients and model collapsing. It points out that these aspects are not adequately presented in the method section. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues or clarify their claims. The feedback is 3 as it directs the authors to focus on these areas, but it lacks depth and actionable advice, making it difficult for the authors to fully understand and implement the necessary changes. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind the ablation study, specifically asking why the ablations are designed on the BART and BART+Longformer models instead of the original model, GraphSum. While the comment implies that the authors should provide a justification for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to explain the reasoning behind their ablation study design, but they are not given specific guidance on how to address this issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind the ablation study, specifically asking why the ablations are designed on the BART and BART+Longformer models instead of the original model, GraphSum. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the ablation study section. The comment is specific in its inquiry about the choice of models for the ablation study, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind the ablation study, specifically asking why the ablations are designed on the BART and BART+Longformer models instead of the original model, GraphSum. This is a request for clarification and does not contain a subjective claim or opinion that requires verification. It is a factual inquiry seeking information, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises a specific question about the design of the ablation study, questioning why the ablations are conducted on the BART and BART+Longformer models instead of the original model, GraphSum. This is a relevant inquiry that prompts the authors to provide a justification for their choice, which could help clarify the methodology and enhance the transparency of the study. However, the comment does not offer any suggestions or guidance on how to address this issue or improve the study design. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the removal of the previous report of SciBERT, which is linked to the earlier problem of cursory and unsupported analyses in the previous version of the paper. However, the reviewer acknowledges that it is not fair to write this as a weakness since the current paper does not mention this issue. The comment provides a logical explanation for the omission but does not offer any actionable advice or suggestions for the authors to address the issue. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the removal of the previous report of SciBERT and its impact on the analysis of the outcomes of the models. However, it does not specify which part of the paper discusses these analyses, making it weakly grounded. The comment is specific in detailing the issue of cursory and unsupported analyses, but it lacks grounding as it does not point to a specific section or part of the paper where these issues are discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the removal of the previous report of SciBERT exacerbates the issue of cursory and unsupported analyses in the previous version of the paper. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to the previous report or the specific analyses that were insufficient, making it difficult for the authors to understand and address the issue. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue related to the removal of the previous report of SciBERT, which is linked to the earlier problem of cursory and unsupported analyses in the previous version of the paper. However, the reviewer acknowledges that it is not fair to write this as a weakness since the current paper does not mention this issue. While the comment provides some context and insight into the potential impact of the omission, it lacks actionable guidance or suggestions for the authors to address the issue. The feedback is 3 as it highlights a potential area of concern, but it does not offer specific advice on how to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the interpretation of Figure 4(b), suggesting that the proposed method does not necessarily result in faster training, given that all networks are trained for the same number of epochs. The reviewer also mentions that pruning is a significant field and recommends a longer discussion of related work. While the comment implies that the authors should address the interpretation of Figure 4(b) and provide a more detailed discussion of related work, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the figure\"s interpretation and expand the related work section. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4(b),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the interpretation of the figure and suggests that the proposed method may not result in faster training, given that all networks are trained for the same number of epochs. Additionally, the reviewer recommends a longer discussion of related work in the field of pruning. This provides clear guidance on what needs to be addressed and improved in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 4(b) does not convincingly demonstrate faster training with the proposed method, given that all networks are trained for the same number of epochs. The reviewer also suggests that the paper would benefit from a longer discussion of related work in the field of pruning. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the lack of evidence for faster training. This makes the claim 3, as it requires more detailed justification or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the interpretation of Figure 4(b), suggesting that the proposed method may not result in faster training, given that all networks are trained for the same number of epochs. This is a relevant observation that could impact the paper\"s claims about the effectiveness of the proposed method. Additionally, the reviewer recommends a longer discussion of related work in the field of pruning, which could provide context and depth to the paper. While the comment highlights important areas for improvement, it could be more helpful by offering specific suggestions on how to address the interpretation issue or expand the related work discussion. Overall, the feedback is 4 as it provides actionable insights for enhancing the paper, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the introduction part lacks background information about cognitive models, implying that the authors should refine their writing. However, it does not provide specific guidance on what aspects of the background need to be addressed or how the writing should be improved. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the introduction part lacks background information about cognitive models, indicating a specific area of the paper that needs improvement. However, it does not specify which aspects of the background are missing or how the writing could be refined. While the authors can infer that the issue relates to the introduction, the comment lacks specificity in detailing what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction part lacks background information about cognitive models, making the paper unclear. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to justify why the background is insufficient. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of the introduction, noting that it lacks background information about cognitive models. This feedback is 3 as it points out a potential weakness in the paper, prompting the authors to consider enhancing the introduction with more background information. However, the comment lacks specificity and does not provide actionable guidance on how to address this issue or what specific aspects of the background should be included. To be more helpful, the comment could suggest examples of relevant background information or provide a framework for structuring the introduction. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the performance of DFA and backpropagation on a specific NLP task, suggesting that this difference is not sufficiently emphasized in the paper. The reviewer points out that the abstract gives the impression that DFA performs at nearbackprop levels on this task, which is not accurate. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to improve the clarity or emphasis of the results. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the performance differences and potentially revise the abstract. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"NLP task\" and the \"DFA performance,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in performance between DFA and backpropagation, suggesting that this difference is not sufficiently emphasized in the paper. The comment further specifies that the abstract gives readers the impression that DFA performs at nearbackprop levels, which is not accurate. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of DFA on an NLP task is not sufficiently emphasized in the paper, particularly in the abstract. The reviewer points out that the abstract gives readers the impression that DFA performs at nearbackprop levels on this task, which is not accurate. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed evidence or references makes the claim 3, as it requires more information to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, specifically regarding the performance of DFA on an NLP task. It points out that the performance of DFA lags substantially behind backpropagation, which is not sufficiently emphasized in the paper. The comment also highlights that the abstract gives readers the impression that DFA performs at nearbackprop levels, which is misleading. This feedback is clear and actionable, as it prompts the authors to clarify and emphasize the performance differences in their results, particularly in the abstract. By addressing this issue, the authors can ensure that their readers have a more accurate understanding of the performance of their method. Therefore, the comment is 4, as it provides specific guidance for improvement but could be more comprehensive by suggesting how to present the results more accurately."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the baseline is lacking, particularly for the dimensional reduction methods in optimal transport estimation. It suggests that SRW and FROT, as mentioned in the paper, should be included as baselines. This feedback provides a clear and direct action for the authors to take, which is to add these baselines to their comparison. The suggestion is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"baseline\" and \"dimensional reduction methods in optimal transport estimation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is lacking in the baseline, namely the inclusion of SRW and FROT as baselines, as mentioned in the paper. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline is lacking, specifically for the dimensional reduction methods in optimal transport estimation. It suggests that SRW and FROT, as mentioned in the paper, should be included as baselines. However, the comment does not provide any reasoning or evidence to support why these baselines are necessary or how they would improve the study. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the lack of a comprehensive baseline for the dimensional reduction methods in optimal transport estimation. It suggests that SRW and FROT, as mentioned in the paper, should be included as baselines. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance the robustness and validity of their study. By addressing this feedback, the authors can improve the credibility and completeness of their work. However, the comment could be more helpful if it provided additional context or rationale for why these baselines are important or how they would contribute to the study. Overall, the comment is 4, as it directs the authors toward a meaningful improvement but could be more comprehensive with further elaboration."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a missing discussion on the advantages and disadvantages of transductive learning. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what aspects of the advantages and disadvantages should be discussed or how to structure this discussion. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Since the action is implicit and vague, the comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a missing discussion on the advantages and disadvantages of transductive learning. However, it does not specify which part of the paper should include this discussion, making it difficult for the authors to identify the exact section that needs attention. The comment is 1 as it does not mention any specific sections, figures, or tables. Additionally, it lacks specificity because it does not detail what aspects of the advantages and disadvantages should be discussed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the advantages and disadvantages of transductive learning have not been discussed in the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the paper by pointing out that the advantages and disadvantages of transductive learning have not been discussed. This is a critical area that could provide valuable insights into the methodology and its implications. However, the comment lacks specificity and does not offer guidance on how the authors might address this gap or what aspects of the advantages and disadvantages should be discussed. While it highlights an important area for improvement, the lack of detailed feedback limits its usefulness. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the invariance of the contractivity should be stated formally. While it implies that the authors should include a formal statement, it does not provide specific guidance on how to do so or what aspects of the contractivity should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the invariance of the contractivity should be stated formally. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or subsection where the contractivity is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs revision. The comment is specific in suggesting the need for formalization but lacks grounding, making it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests that the invariance of the contractivity should be stated formally. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the invariance of the contractivity should be stated formally, which is a specific and actionable piece of feedback. By making this suggestion, the reviewer points out a potential area for improvement in the paper, providing the authors with a clear direction to enhance the formalization of their work. However, the comment could be more helpful if it included additional guidance on how to formalize the invariance or what specific aspects of the contractivity should be emphasized. Despite this, the feedback is 4 as it directs the authors toward a meaningful enhancement of their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the lack of application or evaluation of uncertainty saliency maps, questioning their significance without such context. It also disagrees with the claim that uncertainty or confidence generated from the same mechanism as the explanation is more trustworthy than the explanation itself. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback lacks actionable details, leaving the authors uncertain about what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the potential contribution of uncertainty saliency maps and questions their significance without an application or evaluation. It also expresses a disagreement with the claim that uncertainty or confidence generated from the same mechanism as the explanation is more trustworthy than the explanation itself. However, the comment does not specify which part of the paper discusses these concepts, making it weakly grounded. The authors can infer that it relates to sections discussing uncertainty or explanation mechanisms, but the lack of explicit references makes it challenging to pinpoint the exact parts. The comment is specific in its critique of the paper\"s claims and the need for application or evaluation, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a claim that the significance of uncertainty saliency maps is unclear without an application or evaluation, and it disagrees with the notion that uncertainty or confidence generated from the same mechanism as the explanation is more trustworthy than the explanation itself. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claims but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning the significance of uncertainty saliency maps without an application or evaluation. It also expresses a disagreement with the claim that uncertainty or confidence generated from the same mechanism as the explanation is more trustworthy than the explanation itself. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance their work. The feedback is 3 as it points out critical issues, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of using the diffusion model in style transfer and asks what it can provide that other methods cannot. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific aspects of the diffusion model should be discussed. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the importance of using the diffusion model in style transfer and asks what it can provide that other methods cannot. However, it does not specify which part of the paper this issue is not discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its question about the unique contributions of the diffusion model, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of using the diffusion model in style transfer and asks what it can provide that other methods cannot. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of justification or examples makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the significance of using the diffusion model in style transfer, specifically asking what it can provide that other methods cannot. This is a relevant point that could help the authors clarify the unique contributions of their work. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or what aspects of the diffusion model should be discussed. While it identifies a potential area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it prompts the authors to consider an important aspect of their work but does not fully support them in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss or compare the multiview latent attack with other Adversarial MetaLearning methods in the related work section. This is an explicit action that provides a clear direction for the authors to enhance the understanding of the multiview\"s effect. The comment also references specific works that could be included in the discussion, which provides concrete guidance on how to implement the suggestion. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that the multiview latent attack enhances the model\"s meta generalizability and outperforms other Adversarial MetaLearning methods in the crossdomain setting. It also mentions that the multiview training is similar to task augmentation metalearning methods, suggesting a comparison or discussion in the related work section. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The suggestion to discuss or compare is specific, as it identifies a potential area for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the multiview latent attack enhances the model\"s meta generalizability and outperforms other Adversarial MetaLearning methods in the crossdomain setting. It also suggests that the multiview training is similar to task augmentation metalearning methods. However, the comment lacks specific evidence or references to support these claims, such as comparisons with other methods or detailed analyses. The suggestion to discuss or compare in the related work section is logical but not fully substantiated, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential enhancement in the paper\"s discussion of the multiview latent attack, suggesting that it outperforms other Adversarial MetaLearning methods in the crossdomain setting. It also notes that the multiview training is similar to task augmentation metalearning methods, which could be discussed or compared in the related work section. This feedback is clear and actionable, as it provides a specific area for improvement by suggesting a comparison or discussion in the related work section. However, the comment could be more helpful if it included specific examples or references to guide the authors in making these comparisons. Overall, the comment is 4, as it offers a clear direction for enhancing the paper\"s discussion and understanding of the multiview\"s effect."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the impact of Age and FaceID features is not studied in the ablation. This implies that the authors should include an analysis of these features in their ablation study. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to add an analysis but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"impact of Age and FaceID features,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the ablation study, namely, the analysis of these features. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the impact of Age and FaceID features is not studied in the ablation. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a significant omission or how it affects the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as the authors may not fully understand the importance of this omission or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks analysis, namely, the impact of Age and FaceID features in the ablation study. This feedback is clear and actionable, as it directs the authors to include an analysis of these features, which could enhance the comprehensiveness and depth of their study. However, the comment could be more helpful if it provided suggestions on how to conduct this analysis or what specific aspects to focus on. Despite this, the feedback is 4 as it guides the authors toward a meaningful improvement in their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include a discussion of Table 2 and Fig. 5 in the main manuscript, as they were not mentioned in the manuscript. It also asks for clarification on what the values in Table 2 and Fig. 5 represent and why the detailed discussion is given in the appendix. The comment provides clear and specific actions for the authors to take, including moving the discussion from the appendix to the main manuscript and clarifying the values in the figures. This level of detail and explicit guidance makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of discussion about these tables and figures in the main manuscript. The comment also suggests moving the discussion from the appendix to the main manuscript, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the absence of discussion for Table 2 and Fig. 5 in the main manuscript, suggesting that the detailed discussion is given in the appendix. The reviewer questions the values in Table 2 and Fig. 5 and suggests moving the discussion to the main manuscript. However, the comment does not provide any specific reasoning or evidence to support why this change is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the ablation study results, noting that Table 2 and Fig. 5 are not discussed in the main manuscript. It questions the values in these tables and figures and suggests moving the discussion from the appendix to the main manuscript. This feedback is clear and actionable, providing the authors with a direct suggestion for improving the clarity and accessibility of their results. By addressing this feedback, the authors can enhance the comprehensibility of their work for readers. Therefore, the comment is rated as 4, as it offers specific guidance that can significantly improve the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors should include more LLMrelated results in their experiments, specifically mentioning specific models like llama370B and Mistral7B. This provides a clear and concrete action for the authors to take, ensuring that they know exactly what additional experiments to conduct to improve their draft. The comment is explicit and provides detailed guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the experiments, namely more LLMrelated results such as llama370B and Mistral7B. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should include more LLMrelated results, specifically mentioning specific models like llama370B and Mistral7B. The reviewer provides a logical reasoning by referencing the stated purpose of the Lorta method in the introduction, which is to solve the problem of efficient finetune of LLM. This reasoning is clear and provides a basis for the expectation of more LLMrelated results. However, the comment could be strengthened by providing specific examples or references to support the claim that these additional results are necessary or beneficial. Overall, the claim is 4, as it provides a logical basis but lacks detailed evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include more LLMrelated results in their experiments. It specifically mentions models like llama370B and Mistral7B, which are relevant to the paper\"s focus on efficient finetuning of LLMs. By explicitly naming these models, the comment offers a concrete direction for the authors to expand their experimental results, which can significantly enhance the paper\"s contribution and relevance. This feedback is 5 as it provides specific guidance on how to improve the draft, making it a valuable resource for the authors. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the novelty of the proposed \"Depth First Searchbased Decision Tree\" (DFSDT) method, noting its similarity to existing techniques like selfconsistency + CoT and Treeofthoughts. It also questions the applicability of DFSDT to other types of LLMs beyond LLaMA, GPT, and Claude. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their work. The authors are left to infer that they need to clarify the novelty and applicability of their method, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the proposed \"Depth First Searchbased Decision Tree\" (DFSDT) method and its comparison to existing techniques like selfconsistency + CoT and Treeofthoughts. It also raises a question about the applicability of DFSDT to other types of LLMs. However, the comment does not specify which part of the paper discusses DFSDT, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the concerns about the novelty and applicability of DFSDT, providing some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed \"Depth First Searchbased Decision Tree\" (DFSDT) method is closely related to existing techniques like selfconsistency + CoT and Treeofthoughts. It also questions the applicability of DFSDT to other types of LLMs beyond LLaMA, GPT, and Claude. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the comparison or the potential issues with DFSDT. The lack of detailed evidence or references makes the claim 3, as the authors would need to invest effort to fully understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the proposed \"Depth First Searchbased Decision Tree\" (DFSDT) method, noting its similarity to existing techniques like selfconsistency + CoT and Treeofthoughts. It also questions the applicability of DFSDT to other types of LLMs beyond LLaMA, GPT, and Claude. While the comment identifies a potential issue with the originality of the method and its scope, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is 3 as it points out areas for consideration, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of acknowledging contributions, even in ArXiv papers, and criticizes the practice of proposing an identical method while claiming originality. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The comment implies that the authors should acknowledge previous work, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of acknowledging contributions, specifically in the context of ArXiv papers. However, it does not specify which part of the paper this issue pertains to, such as a particular section or method description. The authors can infer that it relates to the methodology or references sections, but this inference is not explicit. The comment is specific in its critique of claiming originality while proposing an identical method, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that it is inappropriate to propose an identical method while claiming originality, even in ArXiv papers. The reviewer provides a logical reasoning by emphasizing the importance of acknowledging contributions, which is a common practice in academia. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the specific methods or contributions being referred to, which could be challenging without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment highlights an important issue regarding the acknowledgment of contributions, particularly in the context of ArXiv papers. It points out the inappropriate practice of proposing an identical method while claiming originality, which is a common concern in academic writing. However, the comment lacks specific examples or suggestions on how the authors might address this issue, such as recommending the inclusion of references or acknowledgments. While it identifies a relevant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, as it provides insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of XDC and MMV compared to their fullysupervised pertaining baselines. It asks for an explanation of why MMV outperforms XDC, suggesting that it might be due to the use of a better backbone architecture. While the comment implies that the authors should provide an explanation, it does not explicitly instruct them to do so or offer specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of XDC and MMV compared to their fullysupervised pertaining baselines. It specifically mentions XDC and MMV, allowing the authors to identify the parts of the paper being addressed. However, the comment does not specify what needs to be addressed or improved in these sections, such as why MMV outperforms XDC or how the backbone architecture might affect performance. While the authors can infer that they need to provide an explanation, the comment lacks specificity in detailing what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of XDC and MMV compared to their fullysupervised pertaining baselines. It suggests that MMV outperforms XDC and asks for an explanation, potentially attributing the difference to the use of a better backbone architecture. However, the comment lacks specific evidence or references to support the claim that MMV is better due to its backbone architecture. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment raises a question about the performance of XDC and MMV compared to their fullysupervised pertaining baselines. It points out that XDC outperformed its baseline but MMV did not, and asks for an explanation. This is a relevant observation that prompts the authors to investigate and potentially clarify the reasons behind these performance differences. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue, such as suggesting potential factors to consider or methods to explore. As it stands, the comment is 3 as it identifies a potential area for improvement but lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a significant weakness in the paper, noting that the writing is too verbose and hard to follow. It suggests that the paper should focus on a main idea or two and provide analyses on why they work, rather than presenting a wellengineered system with many functions and considerations. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to streamline the writing or which main ideas should be emphasized. The action is explicit but somewhat vague, as the authors know they need to simplify the writing but may not be entirely sure how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment provides a general critique of the paper\"s writing style, suggesting it is too verbose and hard to follow. It also implies that the paper lacks theoretical depth and general advancement, focusing more on implementation details. However, the comment does not specify which parts of the paper are particularly verbose or where the theoretical or general advancement should be emphasized. Without explicit references to sections or specific examples, the authors cannot confidently determine which parts of the paper need revision. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the writing is too verbose and hard to follow, suggesting that the paper lacks theoretical depth and general advancement. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without concrete evidence or references, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the writing is too verbose and hard to follow. It suggests that the paper lacks theoretical depth and general advancement, focusing more on implementation details. The reviewer provides a clear and actionable suggestion to focus on a main idea or two and demonstrate why they work, rather than presenting a wellengineered system with many functions and considerations. This feedback is valuable as it guides the authors on how to improve the clarity and focus of their paper. However, the comment could be more helpful if it offered specific examples or suggestions on how to streamline the writing or identify the main ideas. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks the provision of code and supplementary documentation, which would enhance clarity and reproducibility. It suggests that providing these resources would be beneficial for the reader. This feedback is clear and provides a direct action for the authors to take, which is to include the missing code and documentation. The comment is specific and actionable, as it clearly instructs the authors on what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the lack of code and supplementary documentation, which is a specific issue that could enhance clarity and reproducibility. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. While the authors might infer that it relates to the methodology or experimental sections, the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in identifying the need for code and documentation but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks code and supplementary documentation, which would enhance clarity and reproducibility. This claim is supported by logical reasoning, as providing code and documentation is a common practice in scientific papers to facilitate understanding and replication of results. However, the comment could be strengthened by suggesting specific ways to present the code or documentation, or by referencing similar papers that have successfully included these resources. Overall, the claim is 4, as it provides a logical basis but lacks detailed guidance or examples. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of code and supplementary documentation, which could enhance clarity and reproducibility. It provides a clear and actionable suggestion for improvement by recommending the inclusion of these resources. This feedback is valuable as it directly addresses a critical aspect of the paper that could benefit both the authors and the readers. However, the comment could be more helpful if it offered specific guidance on how to present the code or documentation, such as suggesting a particular format or platform. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should discuss and empirically compare ensembles and uncertainty estimation in the context of offline reinforcement learning (RL), specifically mentioning the use of random ensembles (REM) to outperform DQN/naive ensembling in the offline setting. While the comment implies that the authors should include this discussion and comparison, it does not provide specific guidance on how to implement these changes or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ensembles and uncertainty estimation,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be discussed and compared, namely the use of random ensembles (REM) in offline reinforcement learning (RL) and its comparison to DQN/naive ensembling. This provides clear guidance on what the authors should address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that ensembles have been studied in the context of offline reinforcement learning (RL) and that random ensembles (REM) outperform DQN/naive ensembling in the offline setting. The reviewer supports this claim by referencing a specific study on discrete Atari games, which is a common benchmark in RL. This provides a clear and specific reference that substantiates the claim, making it 4. However, the comment could be strengthened by providing more detailed information about the study or its findings, which would further enhance the verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a relevant area for discussion and comparison in the context of ensembles and uncertainty estimation in offline reinforcement learning (RL). It references a specific study on discrete Atari games that found random ensembles (REM) outperforming DQN/naive ensembling in the offline setting. This provides the authors with a clear direction for incorporating this information into their paper, which could enhance the depth and relevance of their work. However, the comment could be more helpful if it included specific suggestions on how to integrate this comparison or discussed potential implications for the authors\" research. Overall, the feedback is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the combination of the two methods lacks novelty, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the perceived lack of novelty or what specific changes could be made to enhance the novelty of the proposed methodology. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph of the introduction and the proposed methodology, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the combination of the two methods lacks novelty, providing a clear direction for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the combination of the two methods lacks novelty, suggesting that the authors have not sufficiently differentiated their work from existing approaches. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed methodology, suggesting that the combination of two methods lacks originality. However, it does not provide specific examples or detailed feedback on how the authors could enhance the novelty or differentiate their work from existing approaches. Without actionable suggestions or guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the proposed approach, suggesting that it may require different models to be finetuned for each target language. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the scalability or whether the authors should consider alternative approaches. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the scalability of the proposed approach, specifically questioning whether a different model needs to be finetuned for each target language. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the scalability aspect, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the scalability of the proposed approach, suggesting that it may require different models to be finetuned for each target language. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment raises a valid concern about the scalability of the proposed approach, specifically questioning whether a different model needs to be finetuned for each target language. This is an important consideration for the authors to address, as it could impact the practicality and applicability of their method. However, the comment does not provide specific suggestions or guidance on how the authors might address this scalability issue or improve their approach. While it identifies a potential weakness, it lacks actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide more details for readers unfamiliar with bAbI or question answering in relation to Eq.20. It asks for clarification on what \"valid words\" means in the context of the equation. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to enhance the explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.20,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests providing more details for readers unfamiliar with bAbI or question answering, and it clarifies the meaning of \"valid words\" in the context of the equation. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that more details should be provided for readers unfamiliar with bAbI or question answering, specifically regarding the meaning of \"valid words\" in Eq.20. The comment does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification, which is factual and descriptive in nature. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors provide more details for readers unfamiliar with bAbI or question answering, specifically regarding the meaning of \"valid words\" in Eq.20. This feedback is clear and actionable, as it identifies a potential area where the paper could be improved by providing additional context for readers. However, the comment could be more helpful if it included specific suggestions on how to enhance the explanation or examples of what additional details might be beneficial. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point informs the authors that the \"interestedregionbased adversarial attacking\" is not a novel idea and references an earlier work by Yao et al. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to address this issue, such as whether the authors should acknowledge the prior work or how to differentiate their approach. Without any actionable steps or suggestions, the comment leaves the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"interestedregionbased adversarial attacking\" and references an earlier work by Yao et al. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies that the idea is not novel and references an earlier work, providing a clear basis for the claim. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"interestedregionbased adversarial attacking\" is not a novel idea and references an earlier work by Yao et al. This claim is 5 as it provides a specific reference to an earlier work that discusses the same concept, allowing the authors to verify the claim and understand the context of their work. The inclusion of a reference to a previous publication provides a clear basis for the claim, making it easily verifiable. Therefore, the comment is labeled as 5.", "helpfulness_rationale": "The review comment points out that the \"interestedregionbased adversarial attacking\" is not a novel idea and references an earlier work by Yao et al. This feedback is 3 as it informs the authors that their approach may not be original, which could impact the novelty of their work. However, the comment does not provide any suggestions on how the authors might differentiate their approach or address the issue of novelty. It lacks depth and actionable guidance, leaving the authors with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the proposed methods are comprised of wellknown effective components, which may not contribute significantly to the field. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the concern about the lack of significant contribution or what specific changes could be made to enhance the paper\"s impact. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed methods are comprised of wellknown effective components, which may not contribute significantly to the field. However, it does not specify which parts of the paper these components are discussed in, nor does it provide details on what aspects of the methods are considered wellknown or how they might not contribute significantly. Without specific references or guidance, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed methods are comprised of wellknown effective components, which may not contribute significantly to the field. However, the comment does not provide any specific examples or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the proposed methods are comprised of wellknown effective components, which may not contribute significantly to the field. However, it does not provide specific examples of these components or how they might be integrated into the paper. Additionally, it lacks actionable feedback or suggestions for improvement, such as recommending the inclusion of novel components or a more detailed analysis of the existing components. Without concrete guidance or detailed critique, the authors are left without a clear understanding of how to address the concern about the lack of significant contribution. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the test set, specifically mentioning the inclusion of multiturn data and the publicly available history conversation. It suggests that this could lead to data leakage, which is a risk in the dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to mitigate the risk of data leakage. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the data leakage issue but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the test set, mentioning the inclusion of multiturn data and the publicly available history conversation. This provides full grounding as it allows the authors to accurately identify the part of the paper being discussed, such as the section on dataset construction or evaluation. The comment is also specific because it details the issue of data leakage and how it could affect the dataset. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the test set includes multiturn data and that the publicly available history conversation, when used for training models, provides some assistance in answering the final question. This suggests a potential risk of data leakage in the dataset. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of evidence or detailed explanation makes the claim 3, as it requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the test set, specifically mentioning the inclusion of multiturn data and the publicly available history conversation. It suggests that this could lead to data leakage, which is a significant concern in dataset construction. However, the comment does not provide specific guidance on how to address this issue or suggest alternative methods to mitigate the risk of data leakage. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential issue but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether the paper applies TTUR, as proposed by DMD2 (Yin et al. 2024a), to Figure 7. It also suggests that a comparison with VSD + TTUR would be more convincing. While the comment implies that the authors should consider including this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning whether the paper applies TTUR, as proposed by DMD2 (Yin et al. 2024a), and suggests that a comparison with VSD + TTUR would be more convincing. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the paper applies TTUR, as proposed by DMD2 (Yin et al. 2024a), to Figure 7. It suggests that a comparison with VSD + TTUR would be more convincing. The comment provides a logical reasoning by referencing the DMD2 paper, which states that TTUR improves the performance of VSD. However, it does not include specific references or detailed examples from the DMD2 paper to fully substantiate the claim. While the reasoning is clear, the lack of detailed references or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the application of TTUR, as proposed by DMD2 (Yin et al. 2024a), to Figure 7. It suggests that a comparison with VSD + TTUR would be more convincing, providing a clear and actionable suggestion for improvement. By pointing out this potential enhancement, the comment offers valuable guidance to the authors on how to strengthen their analysis and presentation of results. However, the comment could be more helpful if it included specific details or examples of how to implement the suggested comparison. Overall, the feedback is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of depth in the linguistic dataset analysis, suggesting that it may not enhance the paper\"s value or clarity. It implies that the analysis might be better suited for the appendix and recommends integrating essential details from the appendix, such as dataset splitting justifications, into the main text. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to move the analysis to the appendix or specify how to integrate the details from the appendix into the main text. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the analysis of the linguistic dataset, suggesting that it lacks depth and does not provide clear takeaways or conclusions. It implies that the analysis might be better suited for the appendix and recommends integrating essential details from the appendix, such as dataset splitting justifications, into the main text. However, the comment does not specify which part of the paper discusses the dataset analysis, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the exact location is not explicitly mentioned. The comment is specific in suggesting improvements to the analysis, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper provides a shallow linguistic dataset analysis without clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\"s value or clarity, it might be better suited for the appendix. Additionally, it recommends integrating essential details from the appendix, such as dataset splitting justifications, into the main text. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the shallow analysis. This makes the claim 3, as it requires more detailed justification to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the paper\"s analysis, specifically noting that it lacks depth and does not provide clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\"s value or clarity, it might be better suited for the appendix. Additionally, the comment recommends integrating essential details from the appendix, such as dataset splitting justifications, into the main text. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting that the authors reconsider the placement of the analysis and ensure that important details are included in the main text. However, the comment could be more helpful if it offered additional guidance on how to enhance the analysis or what specific aspects should be included. Overall, the comment is 4, as it effectively guides the authors toward improving the clarity and structure of their paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies two issues with the experimental results: the lack of clarity in the metric of Table 1 and the absence of experimental details such as the backbone choice, learning rate, and optimization schedules. These are clear actions that the authors need to take to improve their draft. The comment provides specific guidance on what needs to be addressed, making it 5. The authors know exactly what needs to be done to enhance the clarity and completeness of their experimental section.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experimental results\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the experimental results, namely the lack of clarity in the metric of Table 1 and the absence of experimental details such as the backbone choice, learning rate, and optimization schedules. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the metric of Table 1 is not clearly stated and that experimental details like backbone choice, learning rate, and optimization schedules are missing. However, the comment does not provide any specific examples or references to support these claims, making it difficult for the authors to understand the exact nature of the issues or how to address them. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the specific issues and how to address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the experimental results section: the lack of clarity in the metric of Table 1 and the absence of experimental details such as the backbone choice, learning rate, and optimization schedules. This feedback is clear and actionable, as it directs the authors to provide more detailed information about their experimental setup and results. By addressing these points, the authors can enhance the transparency and comprehensibility of their experimental section, which is crucial for reproducibility and understanding. However, the comment could be more helpful if it provided suggestions on how to present these details or examples of best practices in experimental reporting. Overall, the comment is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential advantage of POMDPs, which is the assumption that the decisionmaker does not directly observe the target variable Y. It notes that this advantage is not leveraged in the paper, as it does not discuss how previous decisions affect the data observable to the decisionmaker. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors are left to infer that they should include a discussion on how previous decisions impact the observable data. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the advantage of POMDPs, which is the assumption that the decisionmaker does not directly observe the target variable Y. It also points out that this advantage is not leveraged in the paper, specifically noting that it does not discuss how previous decisions affect the observable data. This provides clear guidance on what aspect of the paper needs improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not leverage the advantage of POMDPs, which is the assumption that the decisionmaker does not directly observe the target variable Y. The reviewer provides a specific example by suggesting that the paper should discuss how previous decisions affect the observable data, since only outcomes are observed when the positive decision is given. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific sections of the paper where this discussion is lacking, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential advantage of POMDPs, which is the assumption that the decisionmaker does not directly observe the target variable Y. It points out that this advantage is not leveraged in the paper, as it does not discuss how previous decisions affect the observable data. This feedback is clear and actionable, as it highlights a specific area where the paper could be improved by discussing the impact of previous decisions on the observable data. However, the comment could be more helpful if it provided specific suggestions on how to incorporate this discussion or examples of how other papers have addressed this issue. Overall, the comment is 4, as it directs the authors to a meaningful area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the pretraining tokens_per_sample being too small (256) and suggests that batch_size=64 for pretraining might not be sufficient. However, it does not provide explicit guidance on what the authors should do to address these issues. The comment implies that the authors should consider increasing the tokens_per_sample and batch_size, but it lacks concrete suggestions on how to make these changes or what specific values might be more appropriate. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses specific aspects of the pretraining process, mentioning the tokens_per_sample and batch_size. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in its critique of the small tokens_per_sample and batch_size, suggesting that they may not be sufficient for a regularsize program. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the pretraining tokens_per_sample is too small (256) and suggests that batch_size=64 for pretraining might not be sufficient. However, the comment lacks specific reasoning or evidence to support these claims. It does not provide examples, references, or detailed explanations to justify why these settings are insufficient. Without additional context or justification, the authors may find it challenging to understand and address the concerns raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the pretraining process, noting that the tokens_per_sample is too small (256) and that batch_size=64 might not be sufficient. This feedback is 3 as it points out potential limitations in the experimental setup, which could impact the effectiveness of the pretraining. However, the comment lacks detailed suggestions or guidance on how the authors might address these issues, such as recommending specific values for tokens_per_sample or batch_size. While it highlights areas for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the work lacks sufficient ablation experiments to help readers understand the proposed method. It provides specific examples of what could be tested, such as replacing the clustering algorithm with KMeans or testing the model\"s performance on differentsized descendant models. These suggestions are clear and concrete, giving the authors a direct path to improve their draft by conducting additional experiments. The feedback is 5 as it provides specific actions and examples of what needs to be done to enhance the paper\"s clarity and comprehensiveness. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ablation experiments\" and \"the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for additional experiments, such as replacing the clustering algorithm with KMeans and testing the model\"s performance on differentsized descendant models. This level of detail guides the authors on what specific experiments are needed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the work lacks sufficient ablation experiments to help readers understand the proposed method. It provides specific examples of what could be tested, such as replacing the clustering algorithm with KMeans or testing the model\"s performance on differentsized descendant models. This level of detail and suggestion makes the claim 4, as it provides a clear direction for the authors to improve their work. However, the comment could be strengthened by including references to similar studies or best practices in the field, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, namely the lack of sufficient ablation experiments to help readers understand the proposed method. It provides specific examples of what could be tested, such as replacing the clustering algorithm with KMeans or testing the model\"s performance on differentsized descendant models. This feedback is clear and actionable, as it guides the authors on how to enhance the comprehensiveness and robustness of their experimental evaluation. By addressing these suggestions, the authors can significantly improve the clarity and depth of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include a comparison of their work to the Talking Heads Transformer 1 as a baseline for all tasks, rather than just for the tasks presented in Table 1. This implies that the authors should expand their comparisons to include the Talking Heads Transformer as a baseline for all tasks. While the comment explicitly states the need for this comparison, it does not provide specific guidance on how to implement it or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to expand the comparisons but may not be entirely clear on the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, suggesting that the authors should include the Talking Heads Transformer as a baseline for all tasks rather than just for the tasks presented in Table 1. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the Talking Heads Transformer should be the defacto baseline for all tasks, and it criticizes the current comparison in Table 1 for not including this baseline. The comment provides a logical reasoning by explaining that it is difficult to gauge the benefits of the proposed interaction modules and manytomany formulation without comparing them to the Talking Heads Transformer. However, it does not provide specific references or detailed comparisons to support the claim that the Talking Heads Transformer is the defacto baseline. This makes the claim 3, as it lacks comprehensive evidence or references to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of the Talking Heads Transformer as a baseline for all tasks, rather than just for the tasks presented in Table 1. This suggestion is important because it allows the authors to better gauge the benefits of their proposed interaction modules and manytomany formulation compared to a simpler linear transform approach. By addressing this feedback, the authors can enhance the comprehensiveness and validity of their comparisons, which is crucial for evaluating the effectiveness of their work. The comment is specific and provides a clear direction for improvement, making it 5 for the authors. Therefore, it aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a reframing of the paper\"s focus, noting that while the introduction discusses breast cancer, the paper\"s contributions are not particularly focused on it. It points out that the paper evaluates the loss function over multiple datasets, including breast cancer, and that the primary contribution is a loss function that can be applied to any semantic segmentation network. The reviewer suggests that a more appropriate framing would focus on the loss function and its applications. This feedback is explicit and provides a clear direction for the authors to consider a different framing of their work. However, it does not specify how to implement this reframing, such as which sections to revise or what specific changes to make. Therefore, the comment is 4, as it gives the authors a clear idea of what needs to be addressed but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Introduction\" and the \"paper and contributions,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting an alternative framing that focuses on the loss function and its applications, rather than solely on breast cancer. This provides clear guidance on what needs to be addressed to improve the paper\"s focus and clarity. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper\"s framing should focus more on the loss function and its applications rather than solely on breast cancer. It provides a logical reasoning by pointing out that the paper evaluates the loss function over multiple datasets, including breast cancer, and that the primary contribution is a loss function that can be applied to any semantic segmentation network. The comment also mentions the potential for extending the loss function to solve other problems in semantic segmentation, such as handling distribution shifts. This reasoning is clear and provides a basis for the suggestion, making the claim 4. However, the comment could be strengthened with specific examples or references to support the claim about the applicability of the loss function to other problems. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a constructive critique by suggesting a reframing of the paper\"s focus. It points out that while the introduction discusses breast cancer, the paper\"s contributions are not particularly focused on it. The comment highlights that the paper evaluates the loss function over multiple datasets, including breast cancer, and that the primary contribution is a loss function that can be applied to any semantic segmentation network. It further notes that the loss function can be extended to solve other problems in semantic segmentation, such as handling distribution shifts. The suggestion to focus on the loss function and its applications is clear and actionable, offering the authors a way to improve the clarity and relevance of their work. However, the comment could be more helpful if it provided specific guidance on how to implement this reframing or which sections to revise. Overall, the feedback is 4 as it offers a valuable perspective on the paper\"s framing and suggests a potential improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly requests the inclusion of agreement statistics for the corpus in sections 3.1 or 3.2. This is a clear and direct action for the authors to take, providing them with a specific task to complete. The comment is concrete because it specifies exactly what needs to be added to the draft, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"section 3.1 or 3.2,\" providing full grounding as the authors can accurately identify the parts of the paper being addressed. It also specifies the request for including agreement statistics for the corpus, which is clear and specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information, specifically asking for agreement statistics to be included in sections 3.1 or 3.2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional data, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, requesting the inclusion of agreement statistics for the corpus in sections 3.1 or 3.2. This feedback is specific and provides a direct suggestion for enhancing the paper by adding relevant data. By addressing this request, the authors can improve the comprehensiveness and clarity of their analysis, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the novelty of the instruction aggregation and the use of LLMs for it, but notes that existing LLMs are used. It also points out that the use of consecutive subtrajectories seems straightforward and that crosstrajectory chaining has novelty, but its techniques are inspired by goalconditioned RL approaches. The comment provides some insight into the novelty of the work but does not offer specific guidance or suggestions for improvement. While it highlights areas that could be further explored or clarified, it lacks actionable advice for the authors. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of the instruction aggregation and the use of LLMs, as well as the use of consecutive subtrajectories and crosstrajectory chaining. However, it does not specify which part of the paper these aspects are discussed in, making it weakly grounded. The comment is specific in detailing the novelty of the work and its relation to existing techniques, but it lacks explicit references to sections or figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the novelty of the instruction aggregation and the use of LLMs, but notes that existing LLMs are used. It also points out that the use of consecutive subtrajectories seems straightforward and that crosstrajectory chaining has novelty, but its techniques are inspired by goalconditioned RL approaches. The comment provides a logical reasoning by comparing the novelty of the work to existing techniques, which is a common practice in the field. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment acknowledges the novelty of the instruction aggregation and the use of LLMs, but it also points out that existing LLMs are used, which may not be entirely novel. It further notes that the use of consecutive subtrajectories seems straightforward and that crosstrajectory chaining has novelty, but its techniques are inspired by goalconditioned RL approaches. While the comment provides some insight into the novelty of the work, it lacks specific suggestions or guidance on how the authors might enhance the novelty or originality of their approach. The feedback is 3 as it highlights areas for potential improvement, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the identity of the attention map and its potential to improve the expressive power of the attention module. It also questions whether identity mapping is the best choice and suggests that more discussion is needed. While the comment implies that the authors should provide additional discussion or justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the questions or what additional discussion should be included. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the identity of the attention map and its potential to improve the expressive power of the attention module. It also questions whether identity mapping is the best choice and suggests that more discussion is needed. However, the comment does not specify which part of the paper discusses the attention module or identity mapping, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these topics are discussed, the lack of explicit references makes the comment weakly grounded. The comment is specific in suggesting that more discussion is needed, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point raises questions about the identity of the attention map and its potential to improve the expressive power of the attention module. It also questions whether identity mapping is the best choice and suggests that more discussion is needed. However, the comment lacks specific evidence, examples, or references to support these claims. The questions posed are logical and reasonable, but without further elaboration or justification, the authors may find it challenging to address the points effectively. Therefore, the comment is considered 2, as it provides a basis for discussion but requires more detailed support to be fully actionable.", "helpfulness_rationale": "The review comment raises important questions about the identity of the attention map and its potential to improve the expressive power of the attention module. It also questions whether identity mapping is the best choice and suggests that more discussion is needed. This feedback is 3 as it identifies a potential area for improvement and encourages the authors to provide additional justification or analysis. However, the comment lacks specific guidance or suggestions on how to address these questions or what additional discussion might be beneficial. To be more helpful, the comment could include examples or references to support the questions or provide a framework for the additional discussion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to explain why they are considering decoderonly transformers. This is a clear and direct action, providing the authors with a specific task to address in their draft. The comment is concrete because it specifies exactly what needs to be explained, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: an explanation for considering decoderonly transformers. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking the authors to explain their choice of considering decoderonly transformers. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, requesting the authors to provide an explanation for their choice of considering decoderonly transformers. This feedback is valuable as it directs the authors to clarify a specific aspect of their methodology, which can enhance the comprehensibility and justification of their work. However, the comment could be more helpful if it provided additional context or suggested specific aspects to focus on in the explanation. Overall, the comment is 4 as it guides the authors toward improving their draft by addressing a critical point."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of detailed analysis in the qualitative section, specifically mentioning the absence of information on the proportion of each error category. It suggests that including more \"fruitful thoughts\" or speculations about the underlying causes of observed issues and potential mitigation strategies could strengthen the contribution of the analysis. While the comment implies that the authors should provide more detailed analysis, it does not explicitly instruct them to do so or offer specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the analysis but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"qualitative analysis\" and the \"proportion of each error category,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of detailed analysis and suggesting that more \"fruitful thoughts\" or speculations about the underlying causes of observed issues and potential mitigation strategies could strengthen the contribution. The reference to Turpin et al. provides a specific example of work that could be relevant to the authors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the qualitative analysis lacks important details, such as the proportion of each error category. It suggests that including more \"fruitful thoughts\" or speculations about the underlying causes of observed issues and potential mitigation strategies could strengthen the contribution. The comment references a specific paper, \"Turpin et al. Language Models Don\"t Always Say What They Think: Unfaithful Explanations in ChainofThought Prompting,\" which provides a relevant context for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation but lacks comprehensive evidence or detailed examples.", "helpfulness_rationale": "The review comment identifies a specific weakness in the qualitative analysis, noting the absence of detailed information on the proportion of each error category. It suggests that including more \"fruitful thoughts\" or speculations about the underlying causes of observed issues and potential mitigation strategies could strengthen the contribution of the analysis. The comment provides a clear direction for improvement by referencing a relevant paper, \"Turpin et al. Language Models Don\"t Always Say What They Think: Unfaithful Explanations in ChainofThought Prompting,\" which could serve as a source of inspiration for the authors. This feedback is 4 as it offers a specific area for enhancement and provides a reference for further exploration. However, it could be more helpful if it included more detailed guidance on how to incorporate these suggestions into the analysis. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should empirically validate the claim that Reinforcement Learning, RNNs, and Wasserstein GANs are not suitable for incomplete, small data by applying these methods to data filled by simple methods. This feedback is explicit and provides a clear action for the authors to take, as it specifies what needs to be done to address the concern. The suggestion is also concrete, as it outlines a specific approach for validation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the issue is discussed, specifically the mention of \"The typical MTTP baselines like Reinforcement Learning, RNNs, Wasserstein GANs\" and the comparison with a Markov chain approach. This allows the authors to accurately identify the section being addressed. The comment is also specific because it suggests that the authors should empirically validate the claim that these methods are not suitable for incomplete, small data by applying them to data filled by simple methods. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should empirically validate their claim that Reinforcement Learning, RNNs, and Wasserstein GANs are not suitable for incomplete, small data by applying these methods to data filled by simple methods. This is a logical suggestion based on the premise that the current comparison with a Markov chain approach is insufficient. However, the comment lacks specific examples or references to support the claim that these methods are not suitable for incomplete data, making it 3. The authors would need to provide additional evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s argument by questioning the validity of the claim that Reinforcement Learning, RNNs, and Wasserstein GANs are not suitable for incomplete, small data. It suggests that the authors should empirically validate this claim by applying these methods to data filled by simple methods. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing a critical point in their argument. However, the comment could be more helpful if it offered additional guidance on how to conduct the empirical validation or what specific aspects to focus on. Overall, the comment is 4 as it effectively guides the authors toward a meaningful improvement in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of baseline comparison in the paper, specifically noting that the GEVAL method is based on GPT3.5 and GPT4 but does not demonstrate its performance using the simplest prompt for these LLMs. The reviewer suggests comparing the GEVAL method with the simplest prompt for these LLMs. This feedback is explicit and provides a clear action for the authors to take, which is to include a baseline comparison using the simplest prompt for GPT3.5 and GPT4. The suggestion is concrete, as it specifies what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GEVAL method\" and \"GPT3.5 and GPT4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking a baseline comparison and suggests comparing the GEVAL method with the simplest prompt for these LLMs. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the GEVAL method lacks a baseline comparison by not demonstrating its performance using the simplest prompt for GPT3.5 and GPT4. This claim is 3 as it highlights a potential gap in the paper\"s methodology, but it lacks specific examples or references to support the assertion. The reviewer suggests a comparison with the simplest prompt, which could be a logical step to improve the paper\"s evaluation. However, the comment could be strengthened by providing more detailed reasoning or examples of how this comparison would enhance the paper\"s contribution. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s methodology by pointing out the lack of a baseline comparison using the simplest prompt for GPT3.5 and GPT4. This feedback is clear and actionable, as it suggests a specific improvement that could be made to enhance the paper\"s evaluation and comparison with other methods. By addressing this issue, the authors can provide a more comprehensive assessment of their GEVAL method\"s performance and its advantages over simpler prompts. However, the comment could be more helpful if it provided additional context or examples of how this comparison might be conducted. Overall, the feedback is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific requirement for updating weights, which involves computing expected rewards or NE gaps for different perturbations. It also notes that this process differs from the base policies, which are updated based on observed rewards. Additionally, the comment mentions that computing NE gaps requires knowledge of the other agents\" policies. While the comment identifies a potential issue and provides some context, it does not explicitly instruct the authors on how to address these concerns or suggest specific changes to their methodology. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the process of updating weights and address the implications of computing NE gaps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to updating weights, mentioning the requirement to compute expected rewards or NE gaps for different perturbations. It also notes that this process differs from the base policies, which are updated based on observed rewards. Additionally, the comment highlights the need to know the policies of other agents for computing NE gaps. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing the issue with updating weights and the implications of computing NE gaps. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that updating weights requires full knowledge of game payoffs and NE gaps, which is different from the base policies that are updated based on observed rewards. The comment provides a logical reasoning by contrasting the requirements for updating weights with the base policies, suggesting that the authors need to clarify this aspect. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to further explore and justify the implications of these differences in their methodology. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the methodology for updating weights in a multiagent environment. It points out that computing expected rewards or NE gaps for different perturbations requires full knowledge of the game payoffs, unlike the base policies that are updated based on observed rewards. Additionally, it notes that computing NE gaps also requires knowledge of the other agents\" policies. This feedback is clear and actionable, as it highlights a potential limitation in the current approach and suggests that the authors should clarify or address this issue. However, the comment could be more helpful if it provided suggestions on how to overcome this limitation or offered alternative methods for updating weights. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their methodology that needs further consideration."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this comparison is sufficient, whether additional comparisons are needed, or how the authors might improve their analysis. Without any actionable suggestions or feedback, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the paper primarily compares the proposed methods with DiffUCO. However, it does not specify which part of the paper this comparison is discussed in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity regarding what aspects of the comparison are problematic or how it could be improved. Without explicit references to sections or detailed feedback, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point states that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any further context, reasoning, or evidence to support why this comparison is significant or how it impacts the paper. Without additional information or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the comment. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment notes that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any further context, analysis, or suggestions for improvement. Without additional information or guidance, the authors are left without actionable feedback on how to enhance their draft or address potential limitations in their comparison. The comment lacks depth and specificity, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the paper, including the lack of explicit definition of local subtasks and their corresponding policies, as well as the absence of a complete proof of the equivalence between the local policy product and the globally optimal policy. However, it does not provide specific guidance or suggestions on how the authors should address these issues. The comment highlights areas that need improvement but lacks actionable steps or concrete details on how to implement them. As a result, the authors are left with a general understanding of what needs to be done but without clear instructions on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the contribution of the paper, which is the value decomposition and the claim of proving the equivalence of the local policy product to the globally optimal policy. It also identifies specific issues with the exposition of the decomposition method, such as the lack of explicit definition of local subtasks and their corresponding policies, and the absence of a complete proof of the equivalence. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details what is missing or unclear in the paper, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is too repetitive and superficial in its exposition of the decomposition method, and it lacks explicit definitions of local subtasks and their corresponding policies, as well as a complete proof of the equivalence between the local policy product and the globally optimal policy. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed justification or references to specific sections of the paper makes the claim 3, as it requires more context and evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, specifically regarding the contribution and exposition of the value decomposition method. It points out that the paper claims to prove the equivalence of the local policy product to the globally optimal policy but lacks explicit definitions of local subtasks and their corresponding policies, as well as a complete proof of this equivalence. This feedback is clear and actionable, as it highlights specific areas where the paper is lacking in clarity and depth. By addressing these issues, the authors can significantly improve the comprehensibility and rigor of their work. However, the comment could be more helpful if it provided suggestions on how to improve the exposition or proof of the equivalence. Overall, the comment is 4, as it effectively guides the authors toward enhancing the quality and clarity of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the performance curve of each algorithm during the training is missing. This provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be added to the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"performance curve of each algorithm during the training,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the performance curves during training. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement requesting the inclusion of a specific piece of information, namely the performance curve of each algorithm during training. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the absence of the performance curve of each algorithm during training. This feedback is clear and actionable, as it directly points out a missing element that could enhance the paper\"s presentation of results. By including this information, the authors can provide a more comprehensive view of their algorithms\" performance, which is valuable for readers and reviewers. However, the comment could be more helpful if it suggested how to present this information or why it is important. Overall, the feedback is 4 as it directs the authors to a specific improvement that can enhance the clarity and completeness of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a computational complexity issue with the proposed Gaussian kernelbased graph construction method, specifically mentioning the O(N^2) time complexity for largescale graphs. However, it does not provide any explicit or implicit suggestions for addressing this issue. The authors are left without guidance on how to improve the computational efficiency or whether there are alternative methods or optimizations that could be considered. Without actionable advice or suggestions, the comment lacks direction for the authors to make improvements to their draft. Therefore, it is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Definition 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed Gaussian kernelbased graph construction method, specifically the computational complexity of computing the full adjacency matrix for largescale graphs. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed Gaussian kernelbased graph construction method (Definition 2) has a computational complexity issue due to the need to compute the full adjacency matrix, which is O(N^2) for largescale graphs. This claim is based on a logical reasoning about the computational complexity of the method, which is a common issue in graphbased algorithms. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to further investigate the complexity of their method to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed Gaussian kernelbased graph construction method, namely the computational complexity of computing the full adjacency matrix for largescale graphs. This is a relevant concern that could impact the practicality and scalability of the method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as proposing alternative methods or optimizations. Without actionable advice, the feedback is 3 as it highlights a potential limitation but does not offer a clear path for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the choice of loss reweighting in the paper, specifically questioning the use of case (1) in Eq. (5) despite case (3) achieving better performance for most widths. The reviewer disagrees with the authors\" explanation that the choice is made to ensure the performance of the smallest network. The comment implies that the authors should reconsider their choice of loss reweighting and provide a justification for their decision. While the action is implicit, it is clear and concrete, as the authors know they need to address the discrepancy between the results and their explanation. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 8\" and \"Table 2e,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by questioning the choice of loss reweighting in case (1) despite case (3) achieving better performance for most widths. The comment provides a clear rationale for why the authors\" explanation is not satisfactory and suggests that all subnetworks with different widths should be equally important. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the choice of loss reweighting in the paper, specifically questioning the use of case (1) despite case (3) achieving better performance for most widths. The reviewer provides a logical reasoning by questioning the authors\" explanation that the choice is made to ensure the performance of the smallest network. This reasoning is based on the assumption that all subnetworks with different widths should be equally important, which is a logical argument. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is 4, as it provides a logical basis for the claim but lacks detailed evidence or references. This aligns with a score of 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper\"s choice of loss reweighting in Table 2e, specifically questioning the use of case (1) despite case (3) achieving better performance for most widths. The reviewer challenges the authors\" explanation that the choice is made to ensure the performance of the smallest network, arguing that all subnetworks with different widths should be equally important. This feedback is clear and actionable, as it prompts the authors to reconsider their choice of loss reweighting and provides a logical rationale for doing so. By addressing this point, the authors can improve the clarity and justification of their methodology. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper for claiming to address a specific issue related to finetuning multiplicity in tabular LLMs, but the main results are general and do not leverage the unique characteristics of tabular data or LLMs. The comment highlights that the main result is irrelevant to the paper\"s scope. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the relevance of their results. The action is implicit and vague, as the authors are left without clear direction on how to rectify the problem. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the claim that the paper focuses on finetuning multiplicity in tabular LLMs, but the main results are general and do not leverage the unique characteristics of tabular data or LLMs. This implies that the comment is related to the introduction or the main results section, where the paper\"s scope and focus are discussed. However, it does not explicitly mention these sections, making it weakly grounded. The comment is specific in detailing the issue with the general nature of the results and their relevance to the paper\"s scope. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s main results are general and do not leverage the unique characteristics of tabular data or LLMs, making them irrelevant to the paper\"s scope. This claim is supported by the observation that the paper claims to address a specific issue related to finetuning multiplicity in tabular LLMs, but the results are not specific to this context. The reviewer provides a logical reasoning by contrasting the claim with the actual results, which helps substantiate the claim. However, the comment could be strengthened with specific examples or references to demonstrate how the results could be more relevant to the paper\"s scope. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s scope and relevance. It points out that while the paper claims to address a specific issue related to finetuning multiplicity in tabular LLMs, the main results are general and do not leverage the unique characteristics of tabular data or LLMs. This critique highlights a disconnect between the paper\"s claims and its actual contributions, which is crucial for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might refine their focus or improve the relevance of their results. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and suggestions for improvement. It questions the summation notation and asks for clarification on the function f(.). It also suggests comparing the paper to existing works like TailorNet and Patel et al. 2021, and requests details on the challenges of simulating multiple layers. While the comment implies that the authors should address these points, it does not provide explicit instructions on how to do so. The actions are implicit and somewhat vague, as the authors need to infer what specific changes are needed and how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"eq. 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the summation notation and the function f(.), and suggests comparing the paper to existing works like TailorNet and Patel et al. 2021. Additionally, it requests details on the challenges of simulating multiple layers. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises several questions and suggestions, including a request for clarification on the summation notation and the function f(.), as well as a comparison to existing works like TailorNet and Patel et al. 2021. While the comment provides some context by mentioning existing works, it lacks specific references or detailed reasoning to fully support the claims or suggestions. The authors would need to infer the basis of the questions and suggestions, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important questions and suggestions that could help the authors improve their draft. It questions the summation notation and asks for clarification on the function f(.), which is a critical aspect of the paper. Additionally, it suggests comparing the paper to existing works like TailorNet and Patel et al. 2021, which use PBS to drape garments on human bodies, and requests details on the challenges of simulating multiple layers. These questions and suggestions provide clear guidance on areas that need clarification or further exploration, making the comment 4. However, it could be more helpful if it offered specific suggestions on how to address these questions or integrate the comparison with existing works. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a confusion in the theoretical analysis, specifically questioning the use of the supremum in Definition 1. It also asks for clarification on how the proposed GRADE reduces this supremum. While the comment raises valid questions, it does not provide explicit instructions or suggestions on how the authors should address these issues. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the theoretical analysis and provide a proof of the reduction. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical analysis\" and \"Definition 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of the supremum in Definition 1 and asks for clarification on how the proposed GRADE reduces this supremum. This provides clear guidance on what needs to be addressed in the theoretical analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the theoretical analysis, specifically questioning the use of the supremum in Definition 1. It asks for clarification on how the proposed GRADE reduces this supremum. While the comment identifies a potential issue, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the theoretical analysis, specifically questioning the use of the supremum in Definition 1. It also asks for clarification on how the proposed GRADE reduces this supremum. This feedback is clear and actionable, as it prompts the authors to clarify and potentially revise their theoretical analysis. However, the comment could be more helpful if it provided additional guidance or suggestions on how to address the confusion or improve the theoretical section. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with further guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include results and analysis on lengthy dialogue samples, specifically asking if the performance drops on these samples. This comment provides a clear and explicit action for the authors to take, as it specifies what kind of analysis is needed and what specific question should be addressed. The suggestion is concrete, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including results and analysis on lengthy dialogue samples, specifically asking if the performance drops on these samples. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or analysis sections, but this inference is not explicit. The comment is specific in its request for additional analysis on lengthy dialogue samples, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include results and analysis on lengthy dialogue samples, specifically asking if the performance drops on these samples. This is a request for additional analysis, not a claim or opinion that requires verification. The comment is factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment suggests that the authors should include results and analysis on lengthy dialogue samples, specifically asking if the performance drops on these samples. This feedback is clear and actionable, as it provides a specific area for the authors to focus on and potentially address in their draft. By suggesting an additional analysis, the comment offers a constructive way for the authors to enhance their work. However, it could be more helpful if it provided guidance on how to conduct this analysis or what specific aspects to consider. Overall, the comment is 4 as it directs the authors to a meaningful improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the datasets used in the paper only contain the visual modality and recommends including more natural modalities, such as audio and visual, for better evaluation. The comment provides specific examples of works that have addressed this issue, which is a concrete suggestion for the authors to consider. However, it does not explicitly instruct the authors to include these modalities or provide detailed guidance on how to implement this change. While the action is clear, the lack of explicit instructions makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"All datasets only contain visual modality,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including more natural modalities, like audio and visual, for better evaluation. The comment provides specific examples of works that have addressed this issue, which further enhances its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the datasets used in the paper only contain the visual modality and suggests including more natural modalities, such as audio and visual, for better evaluation. This claim is supported by references to specific works that have addressed this issue, providing a solid foundation for the argument. The inclusion of these references enhances the verifiability of the claim, as it allows the authors to understand the context and rationale behind the suggestion. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that all datasets used only contain the visual modality and suggesting that more natural modalities, such as audio and visual, should be included for better evaluation. This feedback is clear and actionable, as it provides a specific direction for improvement by recommending the inclusion of additional modalities. The comment also supports its claim with references to relevant works, which further enhances its helpfulness. However, it could be more helpful if it offered guidance on how to incorporate these additional modalities or addressed potential challenges in doing so. Overall, the comment is 4, as it provides valuable insight and direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the oraclecontext model is similar to other prompt tuning works, such as Visual Prompt Tuning & Prompt Learning for VisionLanguage Models, but these works are not discussed in the paper. This feedback implies that the authors should include a discussion of these related works to provide context and differentiate their approach. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on how to integrate this discussion. The action is implicit and somewhat vague, as the authors can infer that they need to discuss related works but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a similarity between the oraclecontext model and other prompt tuning works, specifically mentioning Visual Prompt Tuning & Prompt Learning for VisionLanguage Models. However, it does not specify which part of the paper this comparison should be discussed in, making it weakly grounded. The comment is specific in identifying the lack of discussion about these related works, but without explicit references to sections or parts of the paper, the authors may struggle to determine where this discussion should be included. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the oraclecontext model is similar to other prompt tuning works, such as Visual Prompt Tuning & Prompt Learning for VisionLanguage Models, but these works are not discussed in the paper. The comment provides a specific reference to related works, which helps verify the claim. However, it does not elaborate on how these works are similar or why they are relevant to the paper, which could strengthen the justification. Overall, the claim is 4 as it provides a basis for the comparison but lacks detailed explanation or examples. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that the oraclecontext model is similar to other prompt tuning works, such as Visual Prompt Tuning & Prompt Learning for VisionLanguage Models, but these works are not discussed in the paper. This feedback is 3 as it highlights an area where the paper could be improved by including a discussion of related works. However, the comment lacks specific suggestions on how to integrate this discussion or what aspects of the related works should be highlighted. To be more helpful, the comment could provide guidance on how to effectively incorporate these references into the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should delve deeper into the research area by providing insights on how to use the observed phenomena to design better resilient systems. It implies that the authors should explore potential applications or extensions of their findings, such as integrating a proposed defense method into a hierarchical system. While the comment provides a clear direction for further exploration, it does not explicitly instruct the authors on how to implement this suggestion or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the exact steps needed to address the feedback. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should delve deeper into the research area by providing insights on how to use the observed phenomena to design better resilient systems. It implies that the authors should explore potential applications or extensions of their findings. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs improvement. Additionally, while it provides a general direction for further exploration, it lacks specific details on what aspects of the paper should be expanded or how to address the issue. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper only discusses observed phenomena without providing insights into how to use these observations to design better resilient systems. The reviewer suggests that the authors should explore potential applications or extensions of their findings, such as integrating a proposed defense method into a hierarchical system. However, the comment lacks specific examples or references to support the claim that the paper does not delve into these areas. The suggestion for further exploration is logical but requires more detailed reasoning or evidence to be 5. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it only discusses observed phenomena without providing deeper insights into how these observations can be used to design better resilient systems. It suggests that the authors should explore potential applications or extensions of their findings, such as integrating a proposed defense method into a hierarchical system. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by offering practical applications of their research. However, the comment could be more helpful if it included more detailed guidance on how to implement these suggestions or what specific aspects of the paper should be expanded. Overall, the comment is 4 as it offers a constructive path for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors want to evaluate a form of reliability or trust by looking at what LLMs \"knows,\" but it lacks a rigorous definition. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors need to provide a rigorous definition, but it does not specify what aspects of the definition should be included or how to construct it. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of rigorous definitions for evaluating a form of reliability or trust by looking at what LLMs \"knows.\" However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in pointing out the need for a rigorous definition, but without clear references to the sections where this issue arises, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors want to evaluate a form of reliability or trust by looking at what LLMs \"knows,\" but no rigorous definitions are given. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, noting that the authors want to evaluate a form of reliability or trust by looking at what LLMs \"knows,\" but no rigorous definitions are provided. This feedback highlights a significant gap in the paper, which is important for the authors to address. However, the comment does not provide specific suggestions or guidance on how to define or evaluate this aspect, leaving the authors with a general understanding of the problem but without actionable steps to improve their draft. While it points out a key area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the necessity of masked selfattention in the YFuture encoder and the preference for ProbSparse. It also inquires about the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in some experiments. While the questions imply that the authors should provide explanations or justifications for these aspects, they do not explicitly instruct the authors to address them. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information or analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the necessity of masked selfattention in the YFuture encoder and the preference for ProbSparse, as well as the impact on computational efficiency. However, it does not specify which part of the paper these questions pertain to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its questions about the encoder and computational efficiency, but it lacks grounding because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification and further explanation regarding the use of masked selfattention in the YFuture encoder and the preference for ProbSparse. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the necessity of masked selfattention in the YFuture encoder and the preference for ProbSparse. It also inquires about the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in some experiments. These questions are relevant and could prompt the authors to provide additional explanations or justifications in their paper. However, the comment lacks specific suggestions or guidance on how the authors might address these questions or improve their draft. While it identifies areas for clarification, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a lack of theoretical analysis regarding why deep layer parameters are more suitable for distillation. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects of the theoretical analysis should be included. Without guidance on what kind of analysis is needed or how to conduct it, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a lack of theoretical analysis regarding why deep layer parameters are more suitable for distillation. However, it does not specify which part of the paper this issue pertains to, such as a specific section or subsection where the theoretical analysis should be included. Without explicit references to the paper, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the theoretical analysis are missing or what specific improvements are needed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the theoretical analysis of why deep layer parameters are more suitable for distillation is lacking. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks theoretical analysis, specifically regarding why deep layer parameters are more suitable for distillation. This feedback is 3 as it points out a gap in the theoretical foundation of the paper, prompting the authors to consider expanding their analysis to address this issue. However, the comment does not provide specific suggestions or guidance on how to conduct this analysis or what aspects should be included. To be more helpful, the comment could offer examples of theoretical analyses or suggest potential areas to explore. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that important details are in the appendix, suggesting that the paper is not sufficiently selfcontained. However, it does not provide explicit guidance on how to address this issue or what specific details should be included in the main body of the paper. The action is implicit and vague, as the authors are left to infer that they need to move important details from the appendix to the main text. Without concrete instructions or examples, the comment lacks actionability.", "grounding_specificity_rationale": "The comment suggests that important details are in the appendix, implying that the paper is not sufficiently selfcontained. However, it does not specify which details are missing or which parts of the paper are affected by this issue. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine which parts of the paper need attention. This lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"a lot of important paper details are in the appendix,\" suggesting that the paper is not sufficiently selfcontained. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references to what details are missing or why they are crucial, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that important details are in the appendix, suggesting that the paper is not sufficiently selfcontained. This is a relevant observation that could help the authors improve the clarity and accessibility of their work. However, the comment lacks specificity and does not provide actionable guidance on which details should be included in the main body of the paper or how to better integrate them. Without detailed suggestions or examples, the feedback is 3 as it highlights an area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the argument for using gradient descent methods for clustering and their ability to scale to large datasets. However, it questions whether the largest dataset used in the paper, with 50K points, is truly \"large enough.\" While the comment raises a concern about the dataset size, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what steps to consider to improve the dataset size. As a result, the comment lacks actionability and provides no clear direction for the authors to follow.", "grounding_specificity_rationale": "The comment provides a general observation about the dataset size, noting that while the authors argue for the scalability of gradient descent methods, the largest dataset used in the paper is only 50K points. However, it does not specify which part of the paper discusses the dataset size or the scalability argument, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what needs to be addressed or improved regarding the dataset size. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the dataset size, suggesting that while the authors argue for the scalability of gradient descent methods, the largest dataset used in the paper (50K points) may not be considered \"large enough.\" However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples of what constitutes a \"large enough\" dataset or reference any studies or benchmarks that could be used for comparison. Without such support, the claim remains 1, as the authors would need to infer the basis of the critique themselves. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the argument for using gradient descent methods for clustering, which allows for scaling to large datasets. However, it questions whether the largest dataset used in the paper, with 50K points, is truly \"large enough.\" While the comment identifies a potential limitation in the dataset size, it does not provide specific suggestions or guidance on how the authors might address this issue or what alternative datasets or methods could be considered. The feedback is 3 as it points out a potential weakness, but it lacks depth and actionable advice, making it difficult for the authors to fully understand and improve their work. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a concern about the practicality of the assumptions made in the paper, specifically questioning the difficulty of overloading the library with ASD subroutines. However, it does not provide any explicit or implicit actions for the authors to take in response to this concern. There is no guidance on how to address the issue or improve the clarity of the assumptions. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumptions made in the paper, specifically mentioning \"overloading the library with ASD subroutines\" (assumption 3.2). However, it does not specify which part of the paper discusses these assumptions, making it weakly grounded. The comment is specific in questioning the practicality of the assumptions and the difficulty of overloading the library with ASD subroutines. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the practicality of the assumptions made in the paper, specifically regarding the difficulty of overloading the library with ASD subroutines. However, it does not provide any supporting evidence, reasoning, or references to justify why this assumption might be problematic or how it affects the practicality of the method. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the practicality of the assumptions made in the paper, specifically questioning the difficulty of overloading the library with ASD subroutines. However, it does not provide any specific suggestions or guidance on how the authors might address this concern or improve the clarity of the assumptions. The comment identifies a potential issue but lacks actionable feedback, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper should use a methodology commonly used in data augmentation to generate less excitement. However, it does not provide any specific guidance on how to implement this suggestion or what aspects of the current methodology should be changed. The action is implicit and vague, as the authors are left to infer that they should modify their approach but without concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should use a methodology commonly used in data augmentation to generate less excitement. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or methodology discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what aspects of the current methodology should be changed or how the suggested approach would address the issue of excitement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should use a methodology commonly used in data augmentation to generate less excitement. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this methodology would lead to less excitement. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the paper should use a methodology commonly used in data augmentation to generate less excitement. However, it does not provide any specific reasoning or examples to support why this methodology would be more effective or how it would address the issue of excitement. The comment lacks depth and actionable guidance, leaving the authors without a clear understanding of what changes to make or why they are necessary. As a result, the feedback is 2, as it identifies a potential area for improvement but does not offer sufficient direction for the authors to act upon."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies an issue with the paper, stating that some statements are incorrect. It provides specific examples, such as the statement in Section 4 regarding the results in Fig. 4, which the reviewer claims are not supported by the figure. This feedback is clear and actionable, as it directs the authors to correct the incorrect statements in their paper. The comment provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4\" and \"Fig. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a particular statement that is incorrect and provides a detailed explanation of the issue, namely that the results presented in Fig. 4 do not support the claim about the multiimage IMP improving the quality of LIPs in the crossdomain setting. This level of detail helps the authors understand what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some statements in the paper are incorrect, specifically mentioning a statement in Section 4 regarding the results in Fig. 4. The reviewer provides a specific example of the incorrect statement and supports it with a reference to the figure, which shows that the multiIMP does not significantly improve the quality of LIPs in the crossdomain setting. This level of detail and reference to the figure provides a clear and robust justification for the claim, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, pointing out that some statements are incorrect. It provides a detailed example from Section 4, where the authors claim that multiimage IMP significantly improves the quality of LIPs in the crossdomain setting, but the figure shows that the multiIMP performs essentially the same as others. This feedback is clear and actionable, as it directs the authors to correct the incorrect statements in their paper. By addressing this issue, the authors can improve the accuracy and credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the proposed method\"s results are not better than existing methods, as evidenced by its rank in the VLN Leaderboard. It provides specific examples of existing methods that outperform the proposed method, including references to 1,2,3. However, the comment does not offer any actionable advice or suggestions for the authors to improve their method or address the issue. It lacks guidance on how the authors might enhance their approach or what specific changes could be made to improve their results. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the rank in the VLN Leaderboard, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the results of the proposed method are not better than existing methods, and it provides specific examples of these existing methods, including references to 1,2,3. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method\"s results are not better than existing methods, as evidenced by its rank in the VLN Leaderboard. It supports this claim by providing specific examples of existing methods that outperform the proposed method, including references to 1,2,3. This provides a clear and logical basis for the claim, making it 5. The references to specific works and their results offer a robust foundation for the reviewer\"s assertion, ensuring that the authors can understand and address the critique effectively.", "helpfulness_rationale": "The review comment highlights a significant issue with the proposed method, noting that its results are not better than existing methods, as evidenced by its rank in the VLN Leaderboard. It provides specific examples of existing methods that outperform the proposed method, including references to 1,2,3. This feedback is valuable as it directly addresses a critical weakness in the paper, allowing the authors to understand the context of their work and potentially identify areas for improvement. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or improve their method. Overall, the comment is 4 as it provides clear and actionable information, but it could be enhanced with additional guidance or suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of convincing discussion in section 2.2 regarding how semantic similarity is modeled with the proposed approach. However, it does not provide specific guidance on what aspects of the discussion are lacking or how the authors might improve it. The comment implies that the authors should enhance the discussion to make it more convincing, but it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, leaving the authors uncertain about what specific changes are needed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, namely that it is not convincing regarding how semantic similarity is modeled with the proposed approach. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the discussion in section 2.2 is not convincing regarding how semantic similarity is modeled with the proposed approach. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion in section 2.2, noting that it is not convincing regarding how semantic similarity is modeled with the proposed approach. This feedback is 3 as it points out a potential weakness in the paper, prompting the authors to reconsider and improve the clarity and persuasiveness of their discussion. However, the comment lacks specific suggestions or guidance on how to enhance the discussion, such as what aspects need more explanation or examples. To be more helpful, the comment could include actionable advice or examples of how to address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the proposed SEPAI3R3O model, specifically the over 10 parameters it introduces and the challenge of reliably estimating them with limited realworld observations. It suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. While the comment implies that the authors should address these issues, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to conduct the sensitivity analysis or discuss the uncertainty in parameter values. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed SEPAI3R3O model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of over 10 parameters being difficult to estimate reliably and suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed SEPAI3R3O model introduces over 10 parameters, which may be difficult to reliably estimate given limited realworld observations. It further suggests that modeling these parameters as timevarying exacerbates the estimation challenge. The comment provides a logical reasoning by highlighting the complexity of the model and the potential issues with parameter estimation. However, it lacks specific examples or references to support the claim, such as detailed comparisons with similar models or studies that have addressed this issue. This makes the claim 3, as it provides a logical basis but requires more detailed evidence to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the proposed SEPAI3R3O model, specifically the introduction of over 10 parameters that may be difficult to reliably estimate given limited realworld observations. It highlights the challenge of modeling these parameters as timevarying, which further complicates the estimation process. The comment provides a clear and actionable suggestion for the authors to discuss the uncertainty in fitted parameter values and conduct a sensitivity analysis. This feedback is valuable as it directs the authors to address a critical aspect of their model\"s reliability and estimation, which is crucial for the paper\"s credibility. However, the comment could be more helpful if it offered specific guidance on how to conduct the sensitivity analysis or discuss the uncertainty in parameter values. Overall, the comment is 4, as it effectively points out a significant issue and provides a clear direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption that causal parameters across domains are random samples, suggesting that this assumption may not be valid due to the absence of latent confounders in the system. The reviewer also questions the reliability of the proposed method and the relative performances of MC, IB, and HSIC tests, suggesting that these depend on how the parameters are changing across domains. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer what changes might be necessary without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the assumption that causal parameters across domains are random samples, suggesting that this assumption may not be valid due to the absence of latent confounders in the system. It also questions the reliability of the proposed method and the relative performances of MC, IB, and HSIC tests, suggesting that these depend on how the parameters are changing across domains. However, the comment does not specify which part of the paper these concerns relate to, such as specific sections, figures, or tables. Without explicit references, the authors may find it challenging to pinpoint the exact areas needing revision. The comment is specific in its critique but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the assumption that causal parameters across domains are random samples, suggesting that this assumption may not be valid due to the absence of latent confounders in the system. The reviewer questions the reliability of the proposed method and the relative performances of MC, IB, and HSIC tests, suggesting that these depend on how the parameters are changing across domains. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the assumption is invalid or to explain how the performance depends on parameter changes. This makes the claim 3, as it provides a logical basis for the concern but lacks the necessary depth and evidence to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the assumption that causal parameters across domains are random samples, suggesting that this assumption may not be valid due to the absence of latent confounders in the system. It also questions the reliability of the proposed method and the relative performances of MC, IB, and HSIC tests, suggesting that these depend on how the parameters are changing across domains. While the comment identifies a potential issue with the assumption and highlights a critical aspect of the method\"s performance, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional direction or actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the novelty of the structural optimization method and suggests that it is not clear whether it is new or not. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the novelty or improve the narrative, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment questions the novelty of the structural optimization method and suggests that it is not clear whether it is new or not. However, it does not specify which part of the paper discusses this method, making it difficult for the authors to identify the exact section that needs attention. The comment also mentions the paper title, implying that the novelty claim is related to it, but this is not explicitly stated. Therefore, the comment is weakly grounded as it does not clearly identify the part of the paper being addressed, and it is not specific about what needs to be clarified regarding the novelty. This aligns with a score of 2.", "verifiability_rationale": "The review point questions the novelty of the structural optimization method, suggesting that it is not clear whether it is new or not. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the novelty of the structural optimization method, suggesting that it is not clear whether it is new or not. It also points out that the method is mentioned in the paper title, which further weakens the narrative. However, the comment does not provide any specific guidance or suggestions on how the authors might clarify the novelty or improve the narrative. Without actionable feedback or detailed advice, the authors are left without a clear path to address the issue. Therefore, the comment is 2, as it identifies a potential weakness but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proof, specifically that the assumption may not be correct due to the possibility of generating mixed samples with a lambda value of 0.5 in standard mixup. However, it does not provide explicit guidance on how the authors should address this issue or suggest ways to revise the proof to account for this possibility. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the assumptions or provide additional justification for the proof. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proof\" and the assumption about the lambda value, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proof, namely that the assumption may not be correct due to the possibility of generating mixed samples with a lambda value of 0.5 in standard mixup. This provides clear guidance on what needs to be addressed in the proof. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the proof requires the lambda not to be 0.5, but in standard mixup, the mixed sample can be generated with a lambda of 0.5. This claim is based on a logical reasoning that challenges the assumption in the proof. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to further explore the implications of this claim to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proof, specifically that the assumption may not be correct due to the possibility of generating mixed samples with a lambda value of 0.5 in standard mixup. This feedback is 3 as it points out a specific area where the authors might need to reconsider their assumptions or provide additional justification. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as proposing alternative approaches or providing examples of how to handle this scenario. While it highlights a potential weakness, it lacks depth and actionable advice, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point suggests two actions: highlighting which set of equations have the same form as the Riccati equation in the paragraph above Theorem 3.1 and extracting some of the currently inlined math into environments to facilitate symbol lookup on page 6. Both suggestions are explicit and provide clear guidance on what the authors need to do to improve their draft. The first suggestion is concrete, as it specifies which part of the paper to focus on and what to highlight. The second suggestion is also concrete, as it provides a specific action to improve the readability of the math. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paragraph above Theorem 3.1\" and \"page 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests highlighting which set of equations have the same form as the Riccati equation and extracting some math into environments to facilitate symbol lookup. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests highlighting which set of equations have the same form as the Riccati equation and extracting some math into environments to facilitate symbol lookup. However, it does not provide any reasoning or evidence to support why these changes are necessary or how they would improve the paper. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting two improvements: highlighting which set of equations have the same form as the Riccati equation and extracting some of the currently inlined math into environments to facilitate symbol lookup. These suggestions are clear and direct, offering the authors concrete steps to enhance the clarity and readability of their paper. By addressing these points, the authors can improve the accessibility and comprehensibility of their work, which is valuable for both readers and reviewers. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that certain sections of the paper could benefit from clearer structure and transitions, and it provides specific examples of subjective terms that could be clarified with statistical evidence. While the comment identifies areas for improvement, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors can infer that they need to improve clarity but may not be entirely sure of the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses issues related to clarity in writing, specifically mentioning the need for clearer structure and transitions, as well as the use of subjective terms like \"significant\" without statistical evidence. However, it does not specify which sections of the paper require improvement, making it weakly grounded. The comment is specific in suggesting how to improve clarity, such as providing statistical evidence for subjective terms. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that certain sections of the paper could benefit from clearer structure and transitions, and it provides a specific example of subjective terms like \"significant\" that could be clarified with statistical evidence. This feedback is 3 as it identifies a potential issue with clarity and provides a concrete suggestion for improvement. However, the comment lacks detailed examples or references to specific sections of the paper, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two areas for improvement in the paper: clarity in writing and the use of subjective terms. It suggests that certain sections could benefit from clearer structure and transitions, which is a valuable observation that can help the authors enhance the readability of their work. Additionally, the comment provides a specific example of a subjective term, \"significant,\" and suggests that it could be clarified with statistical evidence, such as pvalues. This feedback is clear and actionable, offering the authors concrete steps to improve their draft. However, it could be more helpful if it provided more detailed guidance on how to achieve these improvements. Overall, the comment is 4, as it effectively directs the authors toward enhancing the clarity and rigor of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of detailed information regarding graph construction, specifically mentioning the definition of edges and the construction of graphs for nonEuclidean datasets. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or what specific information should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details on graph construction, but they are not given concrete steps or examples to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"detailed information for graph construction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing, namely the definition of edges and the construction of graphs for nonEuclidean datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"the detailed information for graph construction is missing,\" specifically mentioning the definition of edges and the construction of graphs for nonEuclidean datasets. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detailed information, namely the construction of graphs for nonEuclidean datasets. It highlights the importance of defining edges and constructing graphs, which is crucial for understanding the methodology. However, the comment does not provide specific suggestions or examples on how the authors might address this gap in their draft. While it points out a critical area for improvement, the feedback could be more actionable by offering guidance on what additional information should be included or how to present it. Therefore, the comment is 3, as it provides insight into an area that needs attention but lacks detailed guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the visual or textual representations used in each method presented in Table 4. It suggests that without this information, it is unclear whether the endtoend performance gain is due to the proposed attention model. This comment implies that the authors should provide more details about the representations used in each method to clarify the results. While the action is implicit, it is clear and concrete, as the authors know exactly what information is missing and how to address it by specifying the representations used. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the visual or textual representations used in each method. This provides clear guidance on what needs to be addressed to improve the clarity of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of Table 4 by asking for the visual or textual representations used in each method. It suggests that without this information, it is unclear whether the endtoend performance gain is due to the proposed attention model. This is a logical claim that highlights a potential gap in the presentation of results. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional context or clarification to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of Table 4, specifically questioning the visual or textual representations used in each method. It highlights a potential issue with understanding the endtoend performance gain, suggesting that without this information, it is unclear whether the improvement is due to the proposed attention model. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the representations used in each method. By addressing this point, the authors can enhance the clarity and comprehensiveness of their results, making the comment 4. However, it could be more helpful if it provided specific suggestions on how to present this information or what aspects to focus on. Therefore, the comment is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the study, including the lack of a welldriven and illustrated description of the problems, particularly the uncertainty calibration, which is unfriendly for new readers. It also points out that the studied issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues or specific suggestions for reorganization or summarization. The actions are implicit and somewhat vague, as the authors can infer that they need to improve the clarity and organization of the study, but they are not given concrete steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity and organization of the studied problems, specifically mentioning the description of uncertainty calibration and the need for further organization and summarization of issues like small datasets, heterogeneous data distribution, uncertainty calibration, and new clients. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be improved, such as the description of uncertainty calibration and the organization of the studied issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the studied problems are not welldriven and illustrated, specifically mentioning the insufficient description of uncertainty calibration, which is unfriendly for new readers. It also suggests that the studied issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed reasoning or evidence makes the claim 3, as it provides a general direction for improvement but lacks the necessary details for the authors to fully understand and address the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically regarding the clarity and organization of the studied problems. It points out that the description of uncertainty calibration is insufficient, which can be unfriendly for new readers. Additionally, it suggests that the studied issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. This feedback is clear and actionable, as it provides specific areas for improvement and suggests a way to enhance the paper\"s readability and comprehensiveness. However, the comment could be more helpful if it offered more detailed guidance on how to reorganize or summarize the issues. Overall, the comment is 4, as it directs the authors toward meaningful improvements but could be more comprehensive with additional suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the results by noting that there are no explorations of incorporating PACtuning with other finetuning techniques like pruning and data augmentation. While the comment identifies a potential area for further investigation, it does not provide explicit guidance or suggestions on how the authors should address this gap. The action is implicit and somewhat vague, as it lacks concrete steps or specific recommendations for the authors to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a gap in the results by noting the absence of explorations on incorporating PACtuning with other finetuning techniques like pruning and data augmentation. However, it does not specify which part of the paper this observation pertains to, making it weakly grounded. The comment is specific in identifying the missing exploration, but without clear grounding, the authors may struggle to determine where to address this feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are no results exploring the incorporation of PACtuning with other finetuning techniques, such as pruning and data augmentation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the results by noting the absence of explorations on incorporating PACtuning with other finetuning techniques like pruning and data augmentation. This feedback is 3 as it points out an area where the authors could expand their research by exploring additional combinations of techniques. However, the comment lacks specific suggestions or guidance on how to incorporate these techniques or what specific aspects to focus on. While it highlights a potential area for improvement, it does not provide detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to validate their experimental analysis on more models. This is a clear and direct action that the authors can take to improve their draft. The comment also references a specific question below, which provides additional context and guidance. Therefore, this comment is 5, as it specifies a concrete action and provides a clear direction for improvement.", "grounding_specificity_rationale": "The comment addresses the experimental analysis, suggesting that it is insufficient and should be validated on more models. However, it does not specify which part of the experimental analysis is insufficient or which models should be used for validation. Additionally, it references a question below, but without providing context or details, it is challenging for the authors to determine the exact issue or improvement needed. Therefore, the comment is weakly grounded as it does not specify the part of the paper being addressed, and it is not specific about the improvements needed. This aligns with a score of 2.", "verifiability_rationale": "The review point claims that the experimental analysis is insufficient and suggests that it should be validated on more models. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental analysis, noting that it is insufficient and should be validated on more models. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, the comment could be more helpful if it offered specific examples of additional models that could be used for validation or provided guidance on how to enhance the experimental analysis. Despite this, the comment still offers valuable insight and direction for the authors to improve their draft, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed method improves over the original initialization but only demonstrates its trainability on a network with 100 layers on CIFAR. It notes that the ImageNet experiments involve networks with varying normalization layers, where the proposed method shows only marginal improvement over the baselines. The comment references two external works, 1 and 2, which could provide additional context or insights. However, it does not explicitly instruct the authors to address these issues or suggest specific actions to improve the paper. The feedback is 3 as it points out a limitation in the experimental results, but it lacks concrete guidance on how to address it. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and its improvement over the original initialization, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method only demonstrates its trainability on a network with 100 layers on CIFAR, while the ImageNet experiments involve networks with varying normalization layers, where the proposed method shows only marginal improvement over the baselines. The comment provides specific examples and references to external works, which further enhances its specificity. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method improves over the original initialization but only demonstrates its trainability on a network with 100 layers on CIFAR, while the ImageNet experiments involve networks with varying normalization layers and show only marginal improvement over the baselines. The comment references two external works, 1 and 2, which provide some support for the claim. However, the comment lacks detailed reasoning or specific examples from the referenced works to fully substantiate the claim. This makes the claim 3, as it provides some support but requires more detailed evidence to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the experimental results, noting that the proposed method only demonstrates its trainability on a network with 100 layers on CIFAR, while the ImageNet experiments involve networks with varying normalization layers. It points out that the proposed method shows only marginal improvement over the baselines in these experiments. The comment references two external works, 1 and 2, which could provide additional context or insights. While the comment highlights a critical area for improvement, it lacks detailed guidance or suggestions on how the authors might address this issue or expand their experiments to better demonstrate the method\"s effectiveness. Therefore, the feedback is 3, as it points out a significant limitation but does not provide comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. This is an explicit request for the authors to include a specific comparison, providing a clear action to take. The comment is concrete because it specifies what needs to be discussed and compared, giving the authors a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. However, it does not specify which part of the paper this discussion should be added to, making it weakly grounded. The comment is specific in its request for a comparison, but without explicit references to sections or parts of the paper, the authors may find it challenging to determine where to incorporate this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. However, it does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the importance of this comparison. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. This feedback is 3 as it identifies a potential area for improvement by suggesting a comparison that could enhance the paper\"s contribution. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, which limits its usefulness. To be more helpful, the comment could provide more detailed suggestions or examples of what should be discussed. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the claim that the proposed algorithm produces \"better\" samples, asking for clarification. The reviewer is open to revising their assessment based on the authors\" response. This implies that the authors should provide clarification or evidence to support their claim. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify their claim but are not given concrete steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3),\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that the proposed algorithm produces \"better\" samples. The reviewer is open to revising their assessment based on the authors\" response, which provides a clear direction for the authors to address the concern. However, the comment could be more specific by suggesting how the authors might demonstrate the superiority of their algorithm or by providing examples of what constitutes \"better\" samples. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the claim that the proposed algorithm produces \"better\" samples, asking for clarification. The reviewer is open to revising their assessment based on the authors\" response. This is a request for clarification rather than a claim, as it does not express an opinion or judgment that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the claim that the proposed algorithm produces \"better\" samples, suggesting that the authors clarify this point. The reviewer is open to revising their assessment based on the authors\" response, which is a constructive approach to feedback. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might demonstrate the superiority of their algorithm. While it identifies a potential area for improvement, it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding the postprocessing effort mentioned in footnote 2. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on what specific information should be included or how the authors might clarify the postprocessing effort. Without actionable advice or concrete steps, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnote 2\" and \"postprocessing effort,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear, namely the postprocessing effort mentioned in the footnote. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the lack of clarity regarding the postprocessing effort mentioned in footnote 2. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a specific area of confusion regarding the postprocessing effort mentioned in footnote 2. This feedback is 3 as it directs the authors\" attention to a particular aspect of their draft that needs clarification. However, the comment lacks depth and does not provide suggestions on how to address the issue or what specific information should be included to clarify the postprocessing effort. While it identifies a potential area for improvement, it does not offer actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks whether the authors have run the codes for multiple seeds and reported the mean. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be done to address the concern. The comment provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment explicitly asks about the authors\" practice of running codes for multiple seeds and reporting the mean. This provides clear guidance on what needs to be addressed, making it specific. However, it does not specify which part of the paper this practice is discussed in, so the authors may need to search for relevant sections. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point is a factual question asking whether the authors have run the codes for multiple seeds and reported the mean. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and direct, asking whether the authors have run the codes for multiple seeds and reported the mean. This is a specific and actionable question that prompts the authors to clarify their experimental setup and reporting practices. By addressing this point, the authors can ensure transparency and robustness in their results, which is crucial for reproducibility and credibility. However, the comment could be more helpful if it provided additional context or suggestions on why this information is important or how it might impact the paper\"s conclusions. Overall, the comment is 4 as it directs the authors to a critical aspect of their methodology that requires clarification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup for each. It also points out a discrepancy in the results presented in Tables 2 and 3, specifically noting the absence of results for models like InceptionV3 and ResNet in Table 3. While the comment highlights areas of confusion and inconsistency, it does not provide explicit instructions or suggestions for how the authors should address these issues. The authors can infer that they need to clarify the differences between the datasets and the experimental setups, as well as ensure consistency in the results presented. However, the comment lacks concrete guidance on how to achieve these improvements. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup for each. It also points out a discrepancy in the results presented in Tables 2 and 3, specifically noting the absence of results for models like InceptionV3 and ResNet in Table 3. While the comment does not explicitly mention specific sections or tables, the authors can infer that it relates to the experimental setup and results sections. The comment is specific in detailing the issues with the datasets and the experimental setup, providing clear guidance on what needs to be addressed. However, it lacks full grounding as it does not explicitly mention the sections or tables being addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the differences between the BCI and IHC4BC datasets and the experimental setup for each. It also points out a discrepancy in the results presented in Tables 2 and 3, specifically noting the absence of results for models like InceptionV3 and ResNet in Table 3. These are factual statements that do not contain subjective opinions, claims, or suggestions requiring verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the differences between the BCI and IHC4BC datasets and the experimental setup for each. It also points out a discrepancy in the results presented in Tables 2 and 3, specifically noting the absence of results for models like InceptionV3 and ResNet in Table 3. This feedback is valuable as it highlights potential inconsistencies and areas that need clarification or further explanation. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their presentation. While it identifies areas for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide a more thorough description of the results shown in Figure 4. This is a clear and direct action that the authors can take to improve their draft. The comment specifies exactly what needs to be done, making it 5. The authors know exactly what part of the paper to focus on and how to enhance it by providing a more detailed description of the results in Figure 4. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Fig 4,\" allowing the authors to accurately identify the part of the paper being addressed. This provides full grounding. However, the comment lacks specificity as it does not detail what aspects of the results in Figure 4 need further description. Without specific guidance on what to include or clarify, the authors may struggle to determine the exact improvements needed. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point is a request for additional information, specifically asking for a more thorough description of the results shown in Fig 4. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or expansion, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide a more thorough description of the results shown in Figure 4. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their results presentation. However, the comment could be more helpful if it provided specific suggestions on what aspects of the results should be elaborated upon or how the description could be improved. Despite this, the feedback is 4 as it guides the authors toward enhancing the comprehensibility of their results, making it a valuable contribution to the review process. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their work more extensively with the literature, specifically mentioning 11. However, it does not provide explicit instructions on how to incorporate this comparison into the method section or what specific aspects should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more detailed comparisons but are not given concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the work with a specific reference, 11, and mentions that this comparison should be more detailed. However, it does not specify which part of the paper should include this comparison, making it weakly grounded. The comment is specific in suggesting a particular reference and the need for more detailed comparisons, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the most relevant literature is 11 and recommends comparing the work more extensively with this reference. However, the comment does not provide any specific reasoning or evidence to support why 11 is the most relevant or how it should be compared. Without additional context or explanation, the claim lacks sufficient justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should compare their work more extensively with a specific reference, 11, particularly in the method section. This feedback is 3 as it identifies a potential area for improvement by recommending a more detailed comparison with relevant literature. However, the comment lacks specificity in terms of what aspects of the method should be compared or how the comparison should be conducted. Without detailed guidance, the authors may struggle to implement the suggestion effectively. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and actionable details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the justification for removing words with identical English counterparts in the class label translation and cleaning process. It suggests that there may be legitimate shared words between the English and languagespecific vocabulary, referencing a study by Navigli et al. (2021). However, the comment does not provide explicit guidance on how the authors should address this concern or what specific changes should be made to improve the justification. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more robust justification for their process. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to the process of removing words with identical English counterparts in the class label translation and cleaning. It raises a concern about the justification for this process, suggesting that there may be legitimate shared words between the English and languagespecific vocabulary. The comment references a study by Navigli et al. (2021) to support this claim. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the justification for the process and provides a reference to support the claim. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s process of removing words with identical English counterparts in the class label translation and cleaning may not be fully justified, as there can be legitimate shared words between the English and languagespecific vocabulary. The reviewer supports this claim by referencing a study by Navigli et al. (2021), which is a credible source. However, the comment could be strengthened by providing more detailed reasoning or examples from the paper to illustrate the issue. Overall, the claim is 4, as it provides a reference but lacks additional evidence or detailed explanation within the paper itself. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the justification for removing words with identical English counterparts in the class label translation and cleaning process. It suggests that there may be legitimate shared words between the English and languagespecific vocabulary, referencing a study by Navigli et al. (2021). This feedback is 3 as it points out a potential issue with the paper\"s methodology and provides a reference to support the claim. However, the comment could be more helpful if it offered specific suggestions on how the authors might address this concern or improve the justification for their process. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the study should focus on more models to verify the findings, implying that the authors should expand their analysis to include additional models. However, it does not provide specific guidance on which models to consider or how to incorporate them into the study. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without detailed instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the study should focus on more models to verify the findings, implying that the current focus on LLaVA and InstructBLIP is insufficient. However, it does not specify which models should be included or why they are necessary, leaving the authors without clear guidance on how to address this suggestion. Additionally, the comment does not mention specific sections or parts of the paper, making it difficult for the authors to pinpoint where these changes should be made. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the study should focus on more models to verify the findings, implying that the current focus on LLaVA and InstructBLIP is insufficient. However, the comment lacks specific reasoning or evidence to support why studying additional models is necessary or how it would enhance the findings. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the study should focus on more models to verify the findings, implying that the current focus on LLaVA and InstructBLIP is insufficient. While the comment identifies a potential limitation in the scope of the study, it lacks specific guidance or suggestions on which additional models should be considered or how to incorporate them into the analysis. The feedback is 3 as it points out a direction for improvement, but it does not provide detailed actionable steps, leaving the authors with a general idea of what needs to be addressed. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy between the results shown in Figure 7 and Table 3, suggesting that the norm shows significant reduction for OpenCLIP in Figure 7 but does not show significant improvement for object localization in Table 3, which is the main benefit of using register. The comment implies that the authors should provide further explanation or exploration of the reason behind this discrepancy to aid in the wide adoption of the method. While the action is implicit, it is clear and concrete, as it specifies what needs to be addressed: further explanation or exploration of the reason behind the discrepancy. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the results in Figure 7 and Table 3, particularly the lack of significant improvement for object localization despite the significant reduction for OpenCLIP in Figure 7. The comment suggests that further explanation or exploration of the reason behind this discrepancy would be beneficial for wider adoption of the method. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point highlights a discrepancy between the results shown in Figure 7 and Table 3, specifically noting that the norm shows significant reduction for OpenCLIP in Figure 7 but does not show significant improvement for object localization in Table 3, which is the main benefit of using register. The comment suggests that further explanation or exploration of the reason behind this discrepancy would be beneficial for wider adoption. While the comment identifies a potential issue, it lacks specific reasoning or evidence to support the claim that further explanation is necessary. The authors would need to infer the importance of this discrepancy and how it affects the wider adoption of the method. Therefore, the comment is 3, as it provides a basis for further exploration but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a discrepancy between the results shown in Figure 7 and Table 3, specifically noting that the norm shows significant reduction for OpenCLIP in Figure 7 but does not show significant improvement for object localization in Table 3, which is the main benefit of using register. This observation highlights a potential inconsistency or lack of clarity in the paper, which could impact the understanding and adoption of the method. The comment suggests that further explanation or exploration of the reason behind this discrepancy would be beneficial for wider adoption. While the comment points out an important issue, it could be more helpful by providing specific suggestions on how to address the discrepancy or what additional information would be beneficial. Overall, the feedback is 4 as it directs the authors to a critical area that needs clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a lack of clarity regarding the use of 3D renders in conjunction with G. It specifically asks for more details on how the 3D rendering and the GAN objective are combined. This provides a clear and direct action for the authors to take, which is to provide additional details on this aspect of their work. The comment is explicit and concrete, as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of 3D renders and the Point cloud in the context of the GAN objective. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of how 3D renders are used in conjunction with G, specifically questioning the use of the Point cloud in this context. The comment suggests that more details about how the 3D rendering and the GAN objective are combined would be helpful. While the comment identifies a potential area of confusion, it does not provide specific examples or detailed reasoning to support the claim. This makes the comment 3, as it highlights an area for improvement but lacks comprehensive evidence or explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the use of 3D renders in conjunction with G, particularly in Section 3.3. It questions how the Point cloud is used in this stage and suggests that more details about how the 3D rendering and the GAN objective are combined would be helpful. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the clarity and comprehensiveness of their work. By addressing this point, the authors can improve the transparency and understanding of their methodology, making the comment 4. However, it could be more helpful if it provided specific suggestions on how to present these details or examples of similar approaches. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the increased complexity of hyperparameters in the QIF model compared to the traditional LIF model. It questions the claim of parameter insensitivity, noting that the supporting evidence relies on simple architectures and datasets. However, the comment does not provide specific guidance on how the authors should address this issue or improve their evidence. The action is implicit, as the authors need to infer that they should provide more robust evidence or address the complexity of hyperparameters. Additionally, the comment lacks concrete details on how to do so, making it 3.", "grounding_specificity_rationale": "The comment addresses the issue of increased hyperparameter complexity in the QIF model compared to the traditional LIF model. It questions the claim of parameter insensitivity, noting that the supporting evidence relies on simple architectures and datasets. However, the comment does not specify which part of the paper discusses these claims or provides examples of the simple architectures and datasets used. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue with the evidence provided, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the increased complexity of hyperparameters in the QIF model compared to the traditional LIF model is not convincingly supported by evidence. It suggests that the supporting evidence relies on simple architectures and datasets, which is not sufficient. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as it requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the increased complexity of hyperparameters in the QIF model compared to the traditional LIF model. It questions the claim of parameter insensitivity, noting that the supporting evidence relies on simple architectures and datasets, which is not convincing. This feedback highlights an area where the authors may need to provide more robust evidence or address the complexity of hyperparameters. However, the comment could be more helpful if it offered specific suggestions on how to improve the evidence or address the issue. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the marginal improvements over baselines achieved by the proposed method, questioning the need for a sophisticated framework to achieve this level of performance. It suggests that further improvements might be possible with other PLMs, such as RoBERTa, T5, vicuna, or llama2. The comment also recommends discussing the meaningful aspects of the proposed method and experiments in the context of LLMs, such as computational costs or realworld scenarios. While the comment implies that the authors should consider these suggestions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the concerns or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"competitors,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion to discuss the meaningful aspects of the proposed method and experiments in the context of LLMs, such as computational costs or realworld scenarios. Additionally, it raises a concern about the marginal improvements over baselines and suggests considering other PLMs like RoBERTa, T5, vicuna, or llama2. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the marginal improvements over baselines achieved by the proposed method, questioning the need for a sophisticated framework. It suggests that further improvements might be possible with other PLMs, such as RoBERTa, T5, vicuna, or llama2. The comment provides a logical reasoning by suggesting that the proposed method could be improved with more advanced PLMs, but it lacks specific examples or detailed comparisons to support this claim. While the suggestion is reasonable, the lack of concrete evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the marginal improvements over baselines achieved by the proposed method, questioning the need for a sophisticated framework to achieve this level of performance. It suggests that further improvements might be possible with other PLMs, such as RoBERTa, T5, vicuna, or llama2. The comment also recommends discussing the meaningful aspects of the proposed method and experiments in the context of LLMs, such as computational costs or realworld scenarios. This feedback is clear and actionable, as it prompts the authors to consider alternative approaches and to provide a more comprehensive discussion of their method\"s relevance in the era of LLMs. However, it could be more helpful if it included specific suggestions on how to incorporate these considerations into the paper. Overall, the comment is 4, as it provides valuable insights and direction for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding the explanation of using soft assignment instead of hard assignment and questions whether the authors have reported an experiment to prove their conjecture. While the comment identifies a potential gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should provide additional evidence or experiments to support their claim. Additionally, the comment lacks concrete details on how to conduct these experiments or what specific evidence is needed. Therefore, the comment is 3, as it highlights an area for improvement but does not provide detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment addresses the explanation of using soft assignment instead of hard assignment in the methodology section. It questions whether the authors have reported an experiment to prove their conjecture. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the methodology section where the explanation is discussed. The comment is specific in its request for evidence or experiments to support the claim. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the explanation regarding the use of soft assignment instead of hard assignment and asks whether the authors have reported an experiment to prove their conjecture. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the explanation is unclear or that an experiment is needed. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the explanation of using soft assignment instead of hard assignment. It questions whether the authors have reported an experiment to support their conjecture, which is a valid point that could enhance the clarity and robustness of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or analyses to provide evidence for their claim. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, as it points out a weakness but does not provide comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the methods presented, noting that they are primarily applicable in the crosssilo setting and may not be suitable for general federated learning problems with a larger number of clients. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address this limitation, such as suggesting alternative methods or approaches that could be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the methods presented in the paper, specifically mentioning the crosssilo setting and its limitations in generalizing to a larger number of clients. However, it does not specify which part of the paper discusses these methods or where the limitation is mentioned, making it weakly grounded. The comment is specific in detailing the limitation of the methods, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the methods presented are mostly applicable in the crosssilo setting, as mentioned in the paper, which limits their applicability to general federated learning problems with a larger number of clients. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed justification makes it difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the applicability of the methods presented, specifically noting that they are mostly suitable for the crosssilo setting and may not be generalizable to a larger number of clients. This feedback is relevant and provides the authors with an insight into the scope of their work, allowing them to consider potential extensions or adaptations to broaden the applicability of their methods. However, the comment does not offer specific suggestions or guidance on how to address this limitation or improve the generalizability of the methods. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about what constitutes distributional generalization in the setting of regression. It provides a logical explanation of why distributional generalization might be expected in a regression setting, but it does not offer any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or improve their draft. As a result, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about what constitutes distributional generalization in the setting of regression. It provides a logical explanation of why distributional generalization might be expected in a regression setting, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper this comment addresses, making it weakly grounded. However, the comment is specific in its inquiry about distributional generalization in regression, which provides some guidance on what needs to be clarified. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about what constitutes distributional generalization in the setting of regression. It provides a logical explanation based on the nature of regression models, suggesting that distributional generalization is expected due to the smoothness of the regression model. However, the comment does not provide specific examples, references, or detailed reasoning to fully substantiate the claim. While the logic is sound, the lack of additional evidence or references makes the claim 3, as it requires the authors to infer the full justification themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about what constitutes distributional generalization in the context of regression. It provides a logical explanation of why distributional generalization might be expected in a regression setting, suggesting that a smooth regression model that interpolates the training data would inherently exhibit distributional generalization. However, the comment does not offer any specific suggestions or guidance on how the authors might address this issue or improve their draft. While it prompts the authors to consider a relevant aspect of their work, it lacks actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the references and baselines are out of date and suggests that more recent research should be covered. It also provides a specific suggestion for finding additional results by searching for \"Item Frequencies of Data Streams.\" This feedback is clear and provides concrete actions for the authors to take, such as updating the references and baselines with more recent research and exploring the suggested search term. The explicit nature of the actions and the concrete guidance make this comment 5.", "grounding_specificity_rationale": "The comment addresses the references and baselines, suggesting that they are out of date and should be updated with more recent research. It also provides a specific suggestion for finding additional results by searching for \"Item Frequencies of Data Streams.\" However, the comment does not specify which references or baselines are outdated, nor does it provide guidance on which recent research should be included. This lack of specificity and detailed guidance makes it difficult for the authors to pinpoint exactly what needs to be addressed. The comment is weakly grounded as it does not explicitly mention a specific section or part of the paper, but it is specific in suggesting a way to update the references. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the references and baselines are out of date and suggests that more recent research should be covered. It also provides a specific suggestion for finding additional results by searching for \"Item Frequencies of Data Streams.\" However, the comment lacks specific examples or references to recent research that should be included, making it difficult for the authors to understand which specific updates are needed. The suggestion to search for \"Item Frequencies of Data Streams\" is a general idea but does not provide a detailed plan for implementation. Therefore, the claim is 3, as it provides some guidance but lacks detailed evidence or examples to fully substantiate the need for updates.", "helpfulness_rationale": "The review comment identifies a significant issue with the references and baselines being out of date, suggesting that more recent research should be included. It also provides a specific suggestion for finding additional results by searching for \"Item Frequencies of Data Streams,\" which could be a valuable resource for the authors. This feedback is clear and actionable, offering a concrete direction for the authors to update their references and potentially expand their research scope. However, the comment could be more helpful if it provided specific examples of recent research or detailed guidance on how to incorporate these findings into the paper. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy between the introduction, which discusses computational challenges in highdimensional action spaces, and the experimental analysis in Section 5, which primarily focuses on lowerdimensional action spaces. The reviewer suggests that the performance of ARAM in highdimensional action spaces, such as complex robotic manipulators, would benefit from more indepth analysis. While the comment identifies a potential gap in the experimental analysis, it does not provide explicit guidance on how to address this issue or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they should expand their analysis to highdimensional action spaces but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and Section 5, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the introduction\"s focus on highdimensional action spaces and the experimental analysis\"s focus on lowerdimensional spaces. Additionally, it suggests that the performance of ARAM in highdimensional action spaces, such as complex robotic manipulators, would benefit from more indepth analysis. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy between the introduction, which discusses computational challenges in highdimensional action spaces, and the experimental analysis in Section 5, which primarily focuses on lowerdimensional action spaces. The reviewer suggests that the performance of ARAM in highdimensional action spaces, such as complex robotic manipulators, would benefit from more indepth analysis. This claim is 3 as it points out a potential gap in the experimental analysis, but it lacks specific examples or detailed reasoning to fully substantiate the need for more indepth analysis in highdimensional action spaces. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the introduction, which highlights the computational challenges of scaling quadratic programs to highdimensional action spaces, and the experimental analysis in Section 5, which primarily explores action constraints in relatively lowerdimensional spaces. The reviewer suggests that the performance of ARAM in highdimensional action spaces, such as complex robotic manipulators, would benefit from more indepth analysis. This feedback is 3 as it points out a potential gap in the experimental analysis and provides a direction for further exploration. However, it lacks specific suggestions or guidance on how to conduct this analysis or what aspects to focus on, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the lack of information on the additional computation required to achieve good experimental results. It suggests that the extra performance might be due to the extra parameters or computation needed. The reviewer implies that the authors should provide this information or conduct an experiment to compare the performance with the same number of floats. While the comment identifies a potential area for improvement, it does not explicitly instruct the authors to conduct a specific experiment or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide additional information but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results, specifically questioning the need for additional computation to achieve good results. It suggests that the extra performance might be due to extra parameters or computation and implies that the authors should provide information on this aspect. However, the comment does not specify which part of the paper discusses the experimental results, making it weakly grounded. It is specific in its request for additional information on computation and performance, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results are good but lacks information on the additional computation required to achieve them. The reviewer suggests that the extra performance might be due to extra parameters or computation and implies that the authors should conduct an experiment to compare performance with the same number of floats. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim about the extra computation or the potential impact of extra parameters. This lack of evidence makes the claim 3, as it requires further elaboration or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of information on the additional computation required to achieve good experimental results. It suggests that the extra performance might be due to the extra parameters or computation needed, and implies that the authors should provide this information or conduct an experiment to compare performance with the same number of floats. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a direction for the authors to address it. However, the comment could be more helpful if it offered specific suggestions on how to conduct the comparison or what metrics to focus on. Overall, the comment is 4 as it guides the authors toward enhancing the transparency and comprehensiveness of their experimental results."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the evaluation and results are not convincing due to inconsistent trends and lack of statistical significance in the improvements. However, it does not provide specific guidance on how the authors should address these issues or improve the evaluation and results. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about what steps to take to enhance the clarity and validity of their findings. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the evaluation and results, stating that they are not convincing due to inconsistent trends and lack of statistical significance in the improvements. However, it does not specify which part of the paper these issues are found in, such as specific sections, figures, or tables. This makes it difficult for the authors to pinpoint the exact areas needing revision. Additionally, the comment lacks specificity in detailing what aspects of the evaluation or results are problematic, such as which trends are inconsistent or which improvements are not statistically significant. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the evaluation and results are not convincing due to inconsistent trends and lack of statistical significance in the improvements. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references to particular trends or improvements, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation and results, noting that they are not convincing due to inconsistent trends and lack of statistical significance in the improvements. This feedback is important as it highlights a potential weakness in the paper that could impact its credibility. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these issues. Without detailed advice on how to improve the evaluation or present the results more convincingly, the authors are left with a general understanding of the problem but without a clear path to resolution. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the subjective nature of some questions in the paper and suggests that the authors should highlight the percentage of the error rate that is due to subjective questions. It implies that this information could be useful for understanding the impact of subjective questions on the overall error rate. However, the comment does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to calculate or present this information. While the action is implicit, it is concrete in suggesting a specific analysis that could be beneficial for the paper. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the issue of subjective questions in the paper, suggesting that the authors should highlight the percentage of the error rate that is due to subjective questions. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting a way to address the issue by looking at agreement among humans, which could help determine the impact of subjective questions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"several questions require subjective answers\" and suggests that the authors should highlight the percentage of the error rate due to subjective questions. The reviewer provides a logical reasoning by suggesting that looking at agreement among humans could help determine the impact of subjective questions. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that some questions are subjective and may contribute to the error rate. It suggests that the authors could address this by highlighting the percentage of the error rate due to subjective questions, which could be determined by looking at agreement among humans. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by quantifying the impact of subjective questions on the overall error rate. However, the comment could be more helpful if it included examples or further guidance on how to conduct this analysis. Overall, the comment is 4 as it offers a constructive suggestion for enhancing the paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the paper would benefit from considering additional NLP tasks beyond intent recognition, such as sentiment classification and namedentity recognition. This provides a clear and direct action for the authors to take, which is to expand the evaluation to include these additional tasks. The comment is specific and provides concrete guidance on how to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment addresses the evaluation section, specifically mentioning the use of a single dataset and limited NLP tasks (intent recognition). It suggests that the paper would improve by considering additional NLP tasks, such as sentiment classification and namedentity recognition. However, it does not explicitly mention which part of the paper discusses the evaluation or the specific tasks being considered. While the authors can infer that it relates to the evaluation section, the comment lacks full grounding. It is specific in suggesting additional tasks to consider, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the evaluation is weak due to the use of a single dataset and limited NLP tasks, specifically mentioning intent recognition. The comment suggests that the paper would improve by considering additional NLP tasks, such as sentiment classification and namedentity recognition. However, the comment lacks specific examples or references to support the claim that these additional tasks would enhance the evaluation. The reasoning is somewhat logical but could be strengthened with more detailed justification or evidence. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation section of the paper, noting that it is weak due to the use of a single dataset and limited NLP tasks, specifically mentioning intent recognition. It suggests that the paper would benefit from considering additional NLP tasks, such as sentiment classification and namedentity recognition, to enhance the evaluation. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by expanding the scope of their evaluation. However, the comment could be more helpful if it offered suggestions on how to incorporate these additional tasks or provided examples of datasets or methods to consider. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their evaluation, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point is explicit and concrete, as it clearly instructs the authors to label the class semantic feature as \"s\" instead of \"c\" in Figure 3. This provides a direct and specific action for the authors to take, ensuring they know exactly what needs to be changed in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the incorrect labeling of the class semantic feature as \"c\" instead of \"s.\" This provides clear guidance on what needs to be corrected. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point is a factual statement requesting a correction in the labeling of a figure. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it points out a minor but important error in the labeling of a figure. By suggesting a correction in the labeling of the class semantic feature from \"c\" to \"s,\" the comment provides clear guidance that can help the authors improve the accuracy and clarity of their work. This feedback is valuable as it directly addresses a specific issue that could impact the understanding of the figure and its content. However, the comment could be more helpful if it explained the significance of the correction or its impact on the overall interpretation of the figure. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a distinction between deidentification and face swapping, noting that the method proposed in the paper appears to be a form of face swapping, similar to deepfake technology. It suggests that the authors should compare their method with stateoftheart face swapping algorithms to clarify the boundary between the two approaches. While the comment implies that the authors should conduct a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the distinction between deidentification and face swapping, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the method proposed in the paper appears to be a form of face swapping, similar to deepfake technology, and suggests that the authors should compare their method with stateoftheart face swapping algorithms to clarify the boundary between the two approaches. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the method proposed in the paper is essentially a form of face swapping, similar to deepfake technology, and suggests that the authors should compare their method with stateoftheart face swapping algorithms. The comment provides a logical reasoning by contrasting the use of a real individual\"s face in deepfake technology versus the use of a 3DMMderived face in the proposed method. However, it lacks specific references or examples of stateoftheart face swapping algorithms, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the distinction between deidentification and face swapping. It points out that the method proposed in the paper appears to be a form of face swapping, similar to deepfake technology, but with a key difference: the target face is derived from a 3DMM rather than a real individual. The comment suggests that the authors should clarify this distinction by comparing their method with stateoftheart face swapping algorithms. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their paper by addressing a potential misunderstanding in the literature. However, it could be more helpful if it included examples of specific algorithms to compare with or detailed guidance on how to conduct the comparison. Overall, the comment is 4, as it effectively guides the authors toward enhancing the clarity and relevance of their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a perceived issue with the experimental results on word embeddings in Tables 1 and 2, noting that they are not as compelling as the Gaussian embeddings, which are the chief baseline from the literature. However, the comment does not provide any explicit or implicit suggestions for improvement. It lacks actionable guidance on how the authors might address this issue or what specific changes could be made to enhance the experimental results. Without any direction or concrete steps, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, noting that they are not as compelling as the Gaussian embeddings, which are the chief baseline from the literature. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results on word embeddings in Tables 1 and 2 are not as compelling as the Gaussian embeddings, which are the chief baseline from the literature. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the comparison or how to address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a perceived weakness in the experimental results, specifically noting that the results on word embeddings in Tables 1 and 2 are not as compelling as the Gaussian embeddings, which are the chief baseline from the literature. This feedback highlights an area where the authors might need to improve their experimental design or analysis to better demonstrate the effectiveness of their approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative experiments or analyses. While it identifies a potential weakness, it does not provide actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed method does not seem to differ significantly from previous studies, except for a change in the task and reward function. It suggests that the contribution is small if this is the only difference. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or enhance their contribution. The action is implicit and vague, as it lacks concrete steps for the authors to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and references specific studies (Shi et al., 2018; Ghosh et al., 2021) and a reference (Ramakanth Pasunuru and Mohit Bansal, 2018). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the similarities and differences between the proposed method and previous studies, highlighting the change in task and reward function. This provides clear guidance on what the authors need to address regarding the contribution of their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method does not differ significantly from previous studies, except for a change in the task and reward function. This claim is supported by references to specific studies (Shi et al., 2018; Ghosh et al., 2021) and a reference to a paper by Ramakanth Pasunuru and Mohit Bansal (2018). The inclusion of these references provides a solid basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons or examples of how the proposed method differs from the previous studies, which would further enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment points out that the proposed method does not seem to differ significantly from previous studies, except for a change in the task and reward function. It acknowledges that the finding of IRL being effective in text summarization is valuable but suggests that the contribution might be limited if this is the only difference. While the comment identifies a potential issue with the novelty of the proposed method, it lacks specific suggestions or guidance on how the authors might address this concern or enhance their contribution. The feedback is 3 as it prompts the authors to consider the uniqueness of their work, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the novelty of the paper is limited and that it consists of multiple pieces combined to create the paper. It suggests that the main contribution is a new ITrelated dataset. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might enhance the novelty or improve the paper\"s contribution. Without actionable suggestions or specific feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the novelty of the paper is limited and that it consists of multiple pieces combined to create the paper. It also implies that the main contribution is a new ITrelated dataset. However, the comment does not specify which parts of the paper are considered \"multiple pieces\" or how they are combined. This lack of specificity makes it difficult for the authors to identify the exact areas that need attention. Additionally, the comment does not provide any guidance on how to address the perceived limitations or enhance the novelty. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited and suggests that it consists of multiple pieces combined to create the paper. The reviewer further implies that the main contribution is a new ITrelated dataset. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the novelty of the paper is limited, implying that it consists of multiple pieces combined to create the paper. It also claims that the main contribution is a new ITrelated dataset. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might enhance the novelty or originality of their work, nor does it suggest ways to better articulate the contributions. As a result, the comment is 1, as it does not provide the authors with any actionable insights or direction for improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks an ablation study related to query embedding and suggests that such a study would provide insights into the significance and impact of this component. The comment clearly identifies the missing element and provides a direct action for the authors to take, which is to conduct an ablation study on query embedding. The feedback is specific and actionable, as it guides the authors on exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ablation study\" and \"query embedding,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014a study on the significance and impact of query embedding. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study related to query embedding, suggesting that such a study would provide insights into the significance and impact of this component. However, the comment does not provide any supporting evidence, reasoning, or references to justify why an ablation study on query embedding is necessary or how it would contribute to the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks an ablation study related to query embedding. It suggests that such a study would provide insights into the significance and impact of this component, which is a valuable addition to the paper. The feedback is clear and actionable, as it directly points out a missing element that could enhance the paper\"s contribution. However, the comment could be more helpful if it provided guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful improvement, but it could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion that the contribution is marginal compared to previous works, but it does not provide any specific guidance or suggestions for improvement. It lacks actionable details, such as what aspects of the contribution are considered marginal or how the authors could enhance their work to make it more significant. Without concrete steps or suggestions, the authors are left without a clear understanding of what changes to make or how to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the contribution being marginal compared to previous works, but it does not specify which part of the paper this assessment is based on. It lacks grounding as it does not identify a specific section, table, or figure that the reviewer is referring to. Additionally, the comment is not specific because it does not provide details on what aspects of the contribution are considered marginal or how it compares to the previous works. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution is marginal compared to previous works, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed comparisons to the cited works, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion that the contribution is marginal compared to previous works, but it does not provide any specific details or examples to support this claim. It lacks actionable feedback or suggestions for improvement, leaving the authors without a clear understanding of what aspects of their work are considered marginal or how they could enhance their contribution. Without specific guidance or constructive criticism, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question to the authors regarding the loss of performance of w2gm against w2g in the analysis of SWCS. However, it does not provide any explicit or implicit actions for the authors to take. The question is more of a request for clarification, and the authors are not given any guidance on how to address the issue or improve their draft. Without any actionable steps or suggestions, the comment lacks direction for the authors, making it 1.", "grounding_specificity_rationale": "The comment poses a question to the authors regarding the loss of performance of w2gm against w2g in the analysis of SWCS. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not provide details on what aspects of the performance loss need clarification or improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question posed to the authors, seeking clarification on the loss of performance of w2gm against w2g in the analysis of SWCS. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment poses a question to the authors regarding the loss of performance of w2gm against w2g in the analysis of SWCS. While it seeks clarification, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer any guidance on how the authors might address this issue or enhance their analysis. As a result, it provides minimal value to the authors in terms of improving their draft, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should directly evaluate for overoptimization rather than focusing on calibration and human evaluation. It implies that the authors should discuss the benefits of not using early stopping, as current works like AlignProp address overoptimization through early stopping. The comment provides a clear action for the authors to take, which is to evaluate for overoptimization and discuss the benefits of not using early stopping. However, it does not specify how the authors should conduct this evaluation or what specific aspects to focus on. While the action is explicit, it lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation of overoptimization, calibration, and human evaluation, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, which is to evaluate for overoptimization without early stopping and discuss the benefits of not using early stopping. The comment references AlignProp as an example of a current work that addresses overoptimization through early stopping, providing a specific context for the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not directly evaluate for overoptimization, despite mentioning it as a motivation. The reviewer suggests that current works address overoptimization through early stopping, referencing AlignProp as an example. However, the comment lacks specific examples or detailed reasoning to support the claim that early stopping is the only way to address overoptimization. While the reference to AlignProp provides some context, the comment would be more verifiable with additional evidence or examples. Therefore, the claim is 3, as it provides a starting point for the authors to explore but requires further elaboration.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that while it discusses overoptimization as a motivation, it does not directly evaluate for overoptimization. Instead, it focuses on calibration and human evaluation. The reviewer points out that current works address overoptimization through early stopping, such as AlignProp, but this is not discussed in the paper. The comment suggests that the paper should evaluate for overoptimization without early stopping and discuss the benefits of not using early stopping. This feedback is clear and actionable, providing the authors with a specific direction for improvement by suggesting a more comprehensive evaluation and discussion of the topic. However, it could be more helpful if it included examples or detailed guidance on how to conduct the evaluation. Overall, the comment is 4, as it effectively guides the authors toward enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed TW model is equivalent to TR and proposes a way to demonstrate this equivalence by fusing the cores G_n with the core tensor C. It explicitly requests that this analysis and a discussion justifying TW over TR be included in the paper. The comment provides a clear and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed TW model\" and the \"TR representation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing, namely, the analysis and discussion justifying TW over TR. The comment provides a clear direction for the authors to include this analysis and discussion, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed TW model is equivalent to TR and suggests that this equivalence can be demonstrated by fusing the cores G_n with the core tensor C. However, the comment lacks specific reasoning or examples to support this claim, such as detailed mathematical or logical explanations. Without such evidence, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential equivalence between the proposed TW model and TR, suggesting that the authors include an analysis and discussion justifying the use of TW over TR. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by addressing a critical point of comparison. However, the comment could be more helpful if it offered additional insights or suggestions on how to conduct this analysis or what specific aspects of TW might be advantageous over TR. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should discuss the transferability of their toolset, noting that the toolsets for the VQA task and the reasoning task are not the same. It implies that the authors should experiment with creating a general toolset for all tasks and observe the results. While the comment explicitly states the need for a discussion on transferability and suggests an experiment, it does not provide specific guidance on how to conduct the experiment or what aspects to focus on. The action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the transferability of the toolset, specifically mentioning that the toolsets for the VQA task and the reasoning task are not the same. This provides full grounding as it explicitly mentions the specific aspect of the paper being addressed, allowing the authors to accurately identify the part of the paper being discussed. The comment is also specific because it suggests discussing the transferability of the toolset and implies that the authors should experiment with creating a general toolset for all tasks. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the transferability of the toolset should be discussed, noting that the toolsets for the VQA task and the reasoning task are not the same. The reviewer implies that this discrepancy could be addressed by creating a general toolset for all tasks and observing the results. However, the comment lacks specific examples or references to support the claim that the current toolsets are not transferable. Without detailed evidence or reasoning, the claim remains 3, as the authors would need to infer the potential issues and how to address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the transferability of the toolset used in the paper, noting that the toolsets for the VQA task and the reasoning task are not the same. It suggests that the authors should discuss this discrepancy and potentially experiment with creating a general toolset for all tasks to see what happens. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a concrete suggestion for further exploration. By addressing this issue, the authors can enhance the comprehensiveness and applicability of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests evaluating the model\"s performance using multiple random feature orders as a baseline to determine if the benefits of feature reordering are due to the specific order found by the metacontroller or can be achieved by exposing the model to diverse orders. While the comment implies an action, it does not provide explicit instructions on how to implement this suggestion. The authors can infer that they should conduct this evaluation, but the lack of concrete guidance on how to proceed makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Multiple Random Orders,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: evaluating the model\"s performance using multiple random feature orders as a baseline to determine the impact of feature order variability. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests evaluating the model\"s performance using multiple random feature orders as a baseline to determine if the benefits of feature reordering are due to the specific order found by the metacontroller or can be achieved by exposing the model to diverse orders. This suggestion is based on logical reasoning, as it proposes a method to test the robustness of the model to feature order variability. However, the comment lacks specific examples or references to support the claim that this approach would be beneficial or necessary. Therefore, the claim is 3, as it provides a logical basis but requires more detailed justification or evidence to be fully convincing.", "helpfulness_rationale": "The review comment suggests a novel approach to evaluating the model\"s performance by using multiple random feature orders as a baseline. This suggestion is clear and actionable, as it provides a specific method for assessing the impact of feature order variability without relying on a complex controller. By proposing this baseline, the comment offers a concrete way for the authors to determine if the benefits of feature reordering are due to the specific order found by the metacontroller or can be achieved by exposing the model to diverse orders. This feedback is highly valuable as it empowers the authors to enhance their experimental design and analysis, making it 5 for improving the draft. Therefore, the comment deserves a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the related work section is severely lacking and provides a specific example of what is missing: lexically constrained decoding methods. It also mentions that these methods are not included as baselines for comparison. This feedback is clear and provides a direct action for the authors to take, which is to include these methods in the related work section and consider them as baselines for comparison. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the inclusion of lexically constrained decoding methods in both the related work and as baselines for comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work section is severely lacking and provides a specific example of what is missing: lexically constrained decoding methods. This claim is supported by the explicit mention of the missing references, which provides a clear basis for the critique. However, the comment could be strengthened by including specific references to the missing methods or examples of how they should be integrated into the related work section. Overall, the claim is 4, as it provides a solid foundation for the critique but lacks detailed references or examples. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the related work section, specifically noting the omission of lexically constrained decoding methods. It provides a clear and actionable suggestion for improvement by pointing out what is missing and why it is important. This feedback is valuable as it directs the authors to enhance their related work section by including relevant methods and baselines, which can help strengthen the paper\"s contribution and context. However, the comment could be more helpful if it offered specific references or examples of how these methods should be integrated into the paper. Overall, the comment is 4 as it provides clear guidance for improvement but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that important baseline models and datasets are missing, making the comparison incomplete. It provides specific examples of missing models and datasets, such as SimVLM and OFA. This feedback is explicit and provides concrete details on what needs to be addressed, giving the authors a clear direction for improvement. By including these models and datasets in the comparison, the authors can enhance the comprehensiveness of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper\"s comparison, noting that important baseline models and datasets are missing. It provides specific examples of missing models and datasets, such as SimVLM and OFA. However, the comment does not specify which part of the paper this issue pertains to, such as the methodology or results sections. While the authors can infer that it relates to the comparison section, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what is missing, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the comparison is incomplete due to the absence of important baseline models and datasets. It supports this claim by providing specific examples of missing models and datasets, such as SimVLM and OFA. This level of detail and the inclusion of references to external works (e.g., 1 and 2) provide a robust basis for the claim, making it 5. The authors can easily understand the basis of the critique and how to address it by including these models and datasets in their comparison. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that important baseline models and datasets are missing from the comparison. This feedback is valuable as it highlights a critical gap in the study that could impact the comprehensiveness and validity of the results. By providing specific examples of missing models and datasets, such as SimVLM and OFA, the comment offers actionable guidance for the authors to enhance their work. However, the comment could be more helpful if it suggested how to incorporate these models and datasets into the comparison or provided additional context on their relevance. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the manuscript for being framed as a dataset paper but lacking new data collection or release. It highlights that the paper presents derivative data, such as 3D pose estimates from existing datasets, which is disappointing for readers expecting a new data source. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their draft. Without actionable suggestions or a clear path forward, the authors are left without direction on how to respond to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions that the manuscript is framed as a dataset paper but lacks new data collection or release. It specifies that the paper presents derivative data, such as 3D pose estimates from existing datasets, which is disappointing for readers expecting a new data source. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the manuscript is framed as a dataset paper but lacks new data collection or release, instead presenting derivative data. The reviewer provides a clear and logical reasoning for this claim, explaining that the paper offers 3D pose estimates from existing datasets, which is disappointing for readers expecting a new data source. This reasoning is supported by the explicit mention of the lack of new data, making the claim 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a significant issue with the manuscript, noting that it is framed as a dataset paper but lacks new data collection or release. It points out that the paper presents derivative data, such as 3D pose estimates from existing datasets, which is disappointing for readers expecting a new data source. This feedback is clear and actionable, as it highlights a critical flaw in the paper\"s presentation and suggests that the authors need to clarify their contribution or revise their framing. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or improve their draft. Overall, the comment is 4, as it effectively points out a major weakness in the paper, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the authors for criticizing Lsoftmax and Asoftmax for requiring an annealinglike training procedure, noting that this method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this critique or improve their draft. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors for criticizing Lsoftmax and Asoftmax for requiring an annealinglike training procedure, noting that this method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not specify which part of the paper this critique is based on, nor does it provide details on how the authors should address this issue. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine where to make improvements. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors should respond to the critique. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the authors for criticizing Lsoftmax and Asoftmax for requiring an annealinglike training procedure, noting that this method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. The comment provides a factual observation about the learning rate schedule of the method being criticized, which is verifiable. However, it does not offer any additional reasoning or evidence to support the claim that the authors\" criticism is unfounded. Therefore, the comment is 3, as it provides a factual basis but lacks comprehensive justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment critiques the authors for criticizing Lsoftmax and Asoftmax for requiring an annealinglike training procedure, noting that this method itself has a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any actionable feedback or suggestions for the authors to address this critique or improve their draft. It lacks depth and does not offer any guidance on how the authors might respond to this critique or how they could enhance their work. As a result, the comment is not helpful, as it does not provide the authors with any actionable insights or direction for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the focus of the quantitative and qualitative analysis, suggesting that it primarily compares AE to diffusion rather than analyzing the results themselves. It asks specific questions about the visualizations, such as whether the handle is consistently transformed across a wide range of chairs and if it is the most prominent feature. These questions imply that the authors should provide more detailed analysis and discussion of the results, particularly regarding the elements crucial for detecting a chair. While the comment does not explicitly instruct the authors to conduct this analysis, it provides clear guidance on what aspects to focus on. The action is implicit but concrete, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"quantitative and qualitative analysis\" and the \"more profound idea\" of analyzing the results themselves. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it raises questions about the visualizations, asking what can be learned about the elements crucial for detecting a chair, such as whether the handle is consistently transformed across a wide range of chairs and if it is the most prominent feature. This provides clear guidance on what aspects of the analysis need further exploration and clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the focus of the analysis, suggesting that it primarily compares AE to diffusion rather than analyzing the results themselves. The reviewer questions the utility of the visualizations, asking what can be learned about the elements crucial for detecting a chair, such as whether the handle is consistently transformed across a wide range of chairs and if it is the most prominent feature. This critique is based on logical reasoning and a clear understanding of the analysis, as it highlights the need for a more detailed exploration of the results. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the focus of the quantitative and qualitative analysis, noting that it primarily compares AE to diffusion rather than analyzing the results themselves. It raises a pertinent question about the visualizations, asking what can be learned about the elements crucial for detecting a chair, such as whether the handle is consistently transformed across a wide range of chairs and if it is the most prominent feature. This feedback is clear and actionable, as it prompts the authors to provide a more detailed analysis and discussion of the results, particularly regarding the elements that contribute to the detection of a chair. By addressing these questions, the authors can enhance the depth and utility of their analysis. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or provided examples of what a more detailed analysis might entail. Overall, the comment is 4, as it directs the authors to a critical area for improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a potential error in the draft, suggesting that the phrase \"must incur a competitive ratio of at most $b$\" should be changed to \"at least $b$.\" The reviewer provides a clear rationale for this change, explaining that in the worst case (x=1), the ratio would be b/1=b, but in all other cases (x>1), the ratio is either b/x or eventually b/b=1. This feedback is explicit and provides concrete guidance on how to correct the error, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Beginning of Section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, suggesting a correction from \"at most\" to \"at least\" in the phrase \"must incur a competitive ratio of at most $b$.\" This provides clear guidance on what needs to be changed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a correction in the wording of a statement in Section 2.2, specifically proposing a change from \"at most\" to \"at least.\" The reviewer provides a logical reasoning for this change by explaining that in the worst case scenario (x=1), the ratio would be b/1=b, but in all other cases (x>1), the ratio is either b/x or eventually b/b=1. This reasoning is clear and provides a solid basis for the claim, making the comment 4. However, the comment could be strengthened by providing specific examples or references to support the reasoning further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential error in the wording of a statement in Section 2.2, suggesting that \"at most\" should be changed to \"at least.\" The reviewer provides a clear rationale for this correction by explaining that in the worst case scenario (x=1), the ratio would be b/1=b, but in all other cases (x>1), the ratio is either b/x or eventually b/b=1. This feedback is actionable and provides a specific suggestion for improvement, making it 5 for the authors to correct the error and enhance the clarity of their draft. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly identifies a specific issue with the third face image in Figure 2, noting that it lacks a proper expression. This provides a clear and direct action for the authors to take, which is to ensure that the expression is correctly represented in the figure. The comment is explicit and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the missing proper expression for the third face image in the figure. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement that describes a specific issue with the figure, namely the missing proper expression for the third face image. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the third face image in Figure 2, noting that it lacks a proper expression. This feedback is clear and actionable, as it directs the authors to correct the issue by ensuring the expression is correctly represented in the figure. However, the comment does not provide additional context or suggestions on why this omission might be important or how it could impact the paper\"s overall presentation. While it highlights a specific area for improvement, it lacks depth and does not fully guide the authors in enhancing their draft. Therefore, the comment is 3, as it provides a clear direction but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests including an example created by BERT and comparing it with an example created by the proposed model. This is an explicit action that provides a clear direction for the authors to follow. The suggestion is concrete, as it specifies what needs to be done and how to implement it. The authors know exactly what they need to do to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment suggests including an example created by BERT and comparing it with an example created by the proposed model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. Without explicit references to sections or figures, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in its request for a comparison but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including an example created by BERT and comparing it with an example created by the proposed model. However, it does not provide any reasoning or evidence to support why this comparison would be beneficial or how it would contribute to the paper. The suggestion is vague and lacks specific justification, making it difficult for the authors to understand the rationale behind the recommendation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests including an example created by BERT and comparing it with an example created by the proposed model. This feedback is 3 as it provides a specific suggestion for enhancing the paper by offering a comparative analysis. However, the comment lacks depth and does not explain why this comparison would be beneficial or how it could contribute to the paper\"s findings. To be more helpful, the comment could include a rationale for why this comparison is important or how it could improve the paper\"s results or conclusions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the dataset sizes for the code summarization task and the code search task should be the same in order to demonstrate that Vault is better in terms of data quality compared to CSN. This provides a clear and direct action for the authors to take, ensuring consistency in dataset sizes across tasks. The comment is explicit and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"code summarization task\" and the \"code search task,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of dataset size inconsistency and the need for equal sizes to demonstrate the superiority of Vault over CSN in terms of data quality. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the dataset sizes for the code summarization task and the code search task should be the same to demonstrate the superiority of Vault over CSN in terms of data quality. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would demonstrate Vault\"s superiority. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the basis for the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the dataset sizes for the code summarization task and the code search task, suggesting that they should be the same to demonstrate the superiority of Vault over CSN in terms of data quality. This feedback is clear and actionable, as it provides a concrete suggestion for improving the experimental setup and analysis. By ensuring consistency in dataset sizes, the authors can more effectively compare the performance of Vault and CSN, which is crucial for demonstrating the superiority of Vault. However, the comment could be more helpful if it provided additional context or reasoning behind the importance of this comparison. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of explanation for important concepts, specifically mentioning \"actionrepeat\" and \"dithering phenomenon.\" It suggests that these terms should be explained more carefully, implying that the authors should provide a detailed explanation of these concepts. While the comment explicitly states the need for clarification, it does not provide specific guidance on how to explain these concepts or what level of detail is required. The action is explicit but somewhat vague, as the authors know they need to clarify these concepts but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a lack of explanation for important concepts, specifically mentioning \"actionrepeat\" and \"dithering phenomenon.\" It suggests that these terms should be explained more carefully, as they appear throughout the paper. However, the comment does not specify which part of the paper these concepts are discussed in, making it weakly grounded. The authors can infer that it relates to sections where these terms are used, but the exact location is not explicitly mentioned. The comment is specific in detailing what needs to be addressed, namely the explanation of these concepts. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some important concepts are not explained well,\" specifically mentioning \"actionrepeat\" and \"dithering phenomenon.\" The reviewer suggests that these terms should be explained more carefully, as they appear throughout the paper. However, the comment lacks specific examples or detailed reasoning to support why these concepts are not wellexplained. Without additional context or examples, the authors may find it challenging to understand the exact nature of the issue and how to address it. Therefore, the claim is 3, as it provides a general observation but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that important concepts such as \"actionrepeat\" and \"dithering phenomenon\" are not explained well. It suggests that these terms should be explained more carefully, as they appear throughout the paper. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensibility of their work by providing detailed explanations for these concepts. However, the comment could be more helpful if it offered specific suggestions on how to explain these concepts or provided examples of how other papers have addressed similar issues. Overall, the comment is 4 as it highlights a critical area for improvement and guides the authors toward enhancing the clarity of their manuscript."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests an alternative approach to the current method, proposing a way to create an instruction embedding from the state encoding and pass it directly to the executor. It also suggests adding an auxiliary objective to bring the instruction encoding closer to the gold instruction encoding. While the comment provides a clear and explicit action, it does not offer detailed guidance on how to implement this suggestion, such as specific steps or modifications to the existing code. The authors know what needs to be done but may need further guidance on execution. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests an alternative approach to the current method, proposing a way to create an instruction embedding from the state encoding and pass it directly to the executor. It also suggests adding an auxiliary objective to bring the instruction encoding closer to the gold instruction encoding. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or experimental design, but this inference is not as direct as it could be. The comment is specific in detailing the proposed alternative approach and its potential benefits, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an alternative approach to the current method, proposing a way to create an instruction embedding from the state encoding and pass it directly to the executor. The reviewer provides a logical reasoning for why this approach might be beneficial, such as avoiding discretization errors due to single wrong decoding. However, the comment lacks specific examples or references to support the claim that this approach would be more effective. While the reasoning is clear, the lack of detailed evidence or references makes the claim 3, as the authors would need to further explore and substantiate the suggestion themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the methodology by proposing an alternative approach to generating text using an instruction model and an encoder. It suggests creating an instruction embedding from the state encoding and passing it directly to the executor, rather than generating text first. The comment also proposes adding an auxiliary objective to bring the instruction encoding closer to the gold instruction encoding, which could potentially improve the model\"s performance. This feedback is clear and offers a concrete way for the authors to enhance their work, making it 5 for the authors to consider and potentially implement. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the novelty of the proposed model is not significant, but it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their model. There is no explicit or implicit action for the authors to take, leaving them without any direction on how to enhance the novelty of their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment claims that the novelty of the proposed model is not significant, but it does not specify which aspects of the model lack novelty or how it could be improved. Additionally, it does not mention any specific sections of the paper, making it difficult for the authors to identify the exact parts that need attention. Without clear guidance or references, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the proposed model is not significant. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment claims that the novelty of the proposed model is not significant, but it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed explanation or guidance on what aspects of the model are lacking in novelty or how they could be enhanced, the authors are left without a clear understanding of how to address the issue. This makes the comment unhelpful, as it does not offer any constructive direction for the authors to improve their work. Therefore, it aligns with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the dataset, suggesting that the proportion of each class used for the pool subset makes it easier rather than harder, as it removes ambiguity between numbers that look alike. The reviewer points out that the accuracy is not a good measure of quality, as it will be good even if the smaller classes are poorly classified. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analysis. The action is implicit and vague, as the authors are left to infer that they need to reconsider their evaluation metrics or dataset selection, but without concrete steps or examples, the comment lacks actionable advice. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the dataset, specifically the proportion of each class used for the pool subset, which the reviewer claims makes the dataset easier rather than harder. The comment provides a detailed example of how the dataset might be biased, mentioning the imbalance between classes like 9, 6, and 7 compared to 1. This provides a clear and specific critique of the dataset, allowing the authors to understand the issue and potentially address it. However, the comment does not explicitly mention which part of the paper discusses the dataset, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the dataset is biased due to the proportion of each class used for the pool subset, making it easier rather than harder. The reviewer provides a specific example of how the dataset might be biased, mentioning the imbalance between classes like 9, 6, and 7 compared to 1. This reasoning is 3 as it provides a logical explanation of how the dataset could impact the accuracy measure. However, the comment could be strengthened by referencing similar datasets or studies that have encountered similar issues, which would make the claim more 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset, specifically the imbalance in the proportion of each class used for the pool subset. It suggests that this imbalance might make the dataset easier rather than harder, as it removes ambiguity between numbers that look alike. The reviewer points out that the accuracy measure is not a good indicator of quality in this case, as it could be high even if the smaller classes are poorly classified. This feedback is 3 as it highlights a critical issue with the dataset that could impact the accuracy of the results. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative evaluation metrics or suggesting ways to balance the dataset. Therefore, the comment is rated as 3, as it provides insight but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point agrees with the statement that prediction is not done in isolation but questions the main contribution of showing that the task of prediction may have strategic aspects. It also raises a specific question about the \"true\" payoff in Table 1, suggesting that the test set payoff should be included in that column. Additionally, the reviewer mentions the work by Vapnik about teaching a learner with side information, suggesting a potential connection. While the comment raises specific questions and points out a potential connection to existing work, it does not provide explicit instructions or detailed guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors need to infer what changes are needed and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the \"true\" payoff in Table 1 and suggests that the test set payoff should be included in that column. Additionally, it mentions the work by Vapnik about teaching a learner with side information, providing a potential connection to existing work. This level of detail and specificity helps the authors understand what needs to be addressed in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and observations, such as questioning the \"true\" payoff in Table 1 and suggesting a potential connection to the work by Vapnik. These are factual statements that do not contain subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment acknowledges the contribution of the paper regarding the strategic aspects of prediction but questions the main contribution. It raises a specific question about the \"true\" payoff in Table 1, suggesting that the test set payoff should be included in that column. Additionally, the reviewer mentions the work by Vapnik, which could provide a relevant context for the paper. While the comment identifies a potential area for clarification and suggests a connection to existing work, it lacks detailed guidance on how to address these points or improve the paper. The feedback is 3 as it provides some direction for improvement but could be more comprehensive and actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should explore another UDA method based on selftraining, beyond the current focus on domainalignment methods. While the comment implies an action, it does not provide specific guidance on which UDA method to explore or how to implement this suggestion. The action is explicit but vague, as the authors are left to infer the details of the exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should explore another UDA method based on selftraining, beyond the current focus on domainalignment methods. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. The comment is specific in suggesting an alternative approach, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that selftraining is a prominent and effective approach within the field of unsupervised domain adaptation (UDA) and suggests exploring another UDA method based on selftraining. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the proposed method solely focuses on domainalignment methods. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 2, as it provides a general idea but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment acknowledges the prominence and effectiveness of selftraining in the field of unsupervised domain adaptation (UDA) and suggests that the authors should explore another UDA method based on selftraining. This feedback is 3 as it points out a potential area for improvement by suggesting an alternative approach. However, the comment lacks specificity and does not provide detailed guidance on which specific UDA method to explore or how to implement it. While it identifies a direction for further exploration, it does not offer actionable steps or detailed suggestions, leaving the authors with a general idea but limited guidance on how to enhance their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the reliability diagrams (Fig 1, top) and questions whether the observed pathologies are due to dataset issues or inherent to the proposed methods. While it highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should investigate the cause of these pathologies, but it lacks concrete steps or actions for the authors to take. Therefore, the comment is 3, as it identifies an area for further exploration but does not offer specific guidance on how to proceed.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1, top,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the accuracy vs confidence plots and the observed pathologies, such as highaccuracy spikes in low confidence regimes. The comment raises a question about whether these pathologies are due to dataset issues or inherent to the proposed methods, providing a clear direction for further investigation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the reliability diagrams (Fig 1, top) and questions whether the observed pathologies are due to dataset issues or inherent to the proposed methods. The comment provides a logical reasoning by pointing out that a perfect system would have the identify function in the accuracy vs confidence plots, and it highlights specific pathologies like highaccuracy spikes in low confidence regimes. This reasoning is clear and provides a basis for the authors to investigate the cause of these issues. However, the comment could be strengthened by referencing similar observations in other works or providing more detailed examples of the pathologies. Overall, the claim is 4, as it provides a solid foundation for further exploration but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment raises a concern about the reliability diagrams (Fig 1, top), specifically the accuracy vs confidence plots, which are used to evaluate the proposed methods. It points out that the plots do not make the methods look better and highlights specific pathologies, such as highaccuracy spikes in low confidence regimes. The comment questions whether these pathologies are due to dataset issues or inherent to the proposed methods, prompting the authors to investigate the cause. This feedback is clear and actionable, as it identifies a potential issue with the evaluation methodology and encourages the authors to explore the source of these pathologies. However, it could be more helpful if it provided suggestions on how to address these issues or improve the evaluation process. Overall, the comment is 4, as it directs the authors to a critical area for improvement but lacks comprehensive guidance on how to resolve the issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several areas where the paper could be improved. It suggests that the attacker could perform more advanced attacks beyond those evaluated in the paper, such as finetuning on a partial subset of the dataset. The comment also notes that the paper does not evaluate the possibility of the backdoor remaining even with partial finetuning and does not discuss stateoftheart methods for backdoor removal. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues or conduct additional evaluations. The authors can infer that they need to expand their analysis to include more advanced attacks and discuss backdoor removal methods, but the feedback lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation of advanced attacks and the consideration of backdoor removal methods, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a detailed critique of the paper\"s evaluation of advanced attacks and the lack of discussion on backdoor removal methods. The comment clearly specifies what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not evaluate advanced attacks beyond those mentioned, such as finetuning on a partial subset of the dataset. It provides a logical reasoning by explaining that even with partial finetuning, the backdoor may still be present, making it difficult for customers to verify misbehaviors. Additionally, the comment points out that the paper only considers backdoor detection and does not discuss stateoftheart methods for backdoor removal. This reasoning is clear and logical, providing a solid basis for the claim. However, the comment could be strengthened by referencing specific examples or studies that demonstrate the effectiveness of these advanced attacks or removal methods. Overall, the claim is 4, as it provides a logical framework but lacks detailed references or examples. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, identifying several areas where it could be improved. It highlights the lack of evaluation of advanced attacks beyond those already considered, such as finetuning on a partial subset of the dataset. The comment also points out that the paper does not discuss stateoftheart methods for backdoor removal, which is an important aspect of the work. This feedback is clear and actionable, as it directs the authors to expand their analysis to include more advanced attacks and discuss backdoor removal methods. However, the comment could be more helpful if it offered specific suggestions on how to conduct these evaluations or discussed potential methods for backdoor removal. Overall, the comment is 4 as it provides valuable insights for improving the draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using the original adjacency matrix instead of the normalized adjacency matrix with the renormalization trick, as used in the original GCN. It implies that the authors should provide an explanation or conduct an ablation study to justify this decision. While the comment suggests that an explanation or study is needed, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation or conduct an ablation study. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of the original adjacency matrix instead of the normalized adjacency matrix with the renormalization trick, as used in the original GCN. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises a question about the rationale behind not using the conventional graph convolutional operation and suggests that an explanation or ablation study might be necessary. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the choice of using the original adjacency matrix instead of the normalized adjacency matrix with the renormalization trick, as used in the original GCN. The comment suggests that this choice should be explained or studied, implying that it might be unconventional. However, the comment does not provide any specific reasoning or evidence to support why this choice is problematic or why it requires further explanation. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the potential issues and address them themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the choice of using the original adjacency matrix instead of the normalized adjacency matrix with the renormalization trick, as used in the original GCN. It points out that this choice is unconventional and suggests that the authors should provide an explanation or conduct an ablation study to justify their decision. This feedback is 3 as it identifies a potential area for improvement and suggests a specific direction for the authors to explore. However, it could be more helpful if it provided more detailed guidance on what aspects of the ablation study should be included or how the explanation should be structured. Overall, the comment is 3, as it prompts the authors to address a critical aspect of their methodology but lacks depth in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the inclusion of a link for the WMT\"15 training corpora but not for WMT\"14. While it highlights a potential inconsistency, it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on whether this is a significant issue or how to address it. Without any suggestions or instructions, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a question about the inclusion of a link for the WMT\"15 training corpora but not for WMT\"14. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the link inclusion, but it lacks grounding as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the inclusion of a link for the WMT\"15 training corpora but not for WMT\"14. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the inclusion of a link for the WMT\"15 training corpora but not for WMT\"14. While it points out a potential inconsistency, it does not provide any context, reasoning, or suggestions for why this discrepancy might be important or how it could impact the paper. The comment lacks depth and actionable feedback, leaving the authors without a clear understanding of what needs to be addressed or improved. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the upper and lower bounds for adaptive matrices A t and B t need to be known in order to pick other hyperparameters. However, it does not provide explicit guidance on how to determine these bounds or what specific hyperparameters should be considered. The action is implicit and somewhat vague, as the authors are left to infer that they need to determine these bounds and their impact on hyperparameter selection. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the upper and lower bounds for adaptive matrices A t and B t need to be known in order to pick other hyperparameters. However, it does not specify which part of the paper discusses these matrices or where the hyperparameters are mentioned. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved, such as how to determine these bounds or which hyperparameters are affected. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that \"upper and lower bounds for adaptive matrices A t and B t need to be known in order to pick other hyperparameters,\" but it does not provide any supporting evidence, reasoning, or examples to justify this claim. The comment lacks specific details or references that would help the authors understand the basis of this suggestion or how it relates to their work. As a result, the claim is 1, as it does not provide sufficient information for the authors to address it effectively.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the upper and lower bounds for adaptive matrices A t and B t need to be known in order to pick other hyperparameters. This feedback is clear and actionable, as it directs the authors to consider these bounds and their impact on hyperparameter selection. However, the comment could be more helpful if it provided additional guidance on how to determine these bounds or what specific hyperparameters might be affected. Despite this, the comment is 4 as it highlights a critical aspect of the methodology that requires attention. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the novelty of the techniques used is not particularly high, as they were proposed and demonstrated before. It also suggests that the authors include experimental results on the PDBbind dataset. While the comment implies that the authors should provide additional experimental results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the experiments or what specific results to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the novelty of the techniques used is not particularly high, as they were proposed and demonstrated before. It also implies that the authors should include experimental results on the PDBbind dataset. However, the comment does not specify which part of the paper discusses the novelty or where the experimental results should be included. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting the inclusion of experimental results on the PDBbind dataset, but without explicit grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the novelty of the techniques used is not particularly high, as they were proposed and demonstrated before. However, it does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the assertion. Without additional context or references, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential weakness in the paper, suggesting that the novelty of the techniques used is not particularly high, as they were proposed and demonstrated before. It also implies that the authors should include experimental results on the PDBbind dataset, which could provide additional context and relevance to the work. While the comment identifies a specific area for improvement, it lacks detailed guidance or suggestions on how to enhance the novelty or conduct the experiments. The feedback is 3 as it directs the authors\" attention to a critical aspect of their work, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests adding error bars to the results of comparing pairs of models to demonstrate that the differences are significant and not due to noise. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment leaves no ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment suggests adding error bars to the results of comparing pairs of models to demonstrate that the differences are significant and not due to noise. However, it does not specify which part of the paper this suggestion pertains to, such as specific figures or tables where these comparisons are presented. Without explicit references to sections or figures, the authors may find it challenging to identify the exact areas that need revision. The comment is specific in its suggestion to add error bars but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests adding error bars to the results of comparing pairs of models to demonstrate that the differences are significant and not due to noise. This claim is based on a logical reasoning that error bars can help distinguish between real differences and noise. However, the comment does not provide specific examples or references to support why this is necessary or how it would improve the paper. While the reasoning is sound, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to improve the presentation of results by recommending the addition of error bars to demonstrate the significance of differences between models. This feedback is clear and offers a concrete way for the authors to enhance the clarity and robustness of their findings. By addressing this suggestion, the authors can strengthen their paper and provide a more comprehensive understanding of the model comparisons. However, the comment could be more helpful if it explained why error bars are important or how they would impact the interpretation of the results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the full state is not defined properly and asks for clarification on what is included in a full state. This provides a clear and direct action for the authors to take, which is to define the full state and specify what it includes. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, line 81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the full state not being defined properly and asks for clarification on what is included in a full state. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual statement questioning the definition of \"full state\" on page 2, line 81. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of \"full state\" on page 2, line 81. It points out that the full state is not defined properly and asks for clarification on what is included in a full state. This feedback is clear and actionable, as it directs the authors to clarify an important concept in their paper. By addressing this point, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to define or clarify the concept of a full state. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the empirical study as good but notes the absence of new proposals for neural architecture encoding. It suggests that a good empirical analysis should not only provide insights but also include new initial proposals based on the analysis. However, the comment does not provide explicit guidance or suggestions on how the authors might incorporate new proposals or what specific aspects of their analysis could be expanded to include such proposals. The action is implicit and vague, leaving the authors without clear direction on how to address the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment acknowledges the empirical study as good but points out a lack of new proposals for neural architecture encoding. However, it does not specify which part of the paper lacks these proposals or where the authors should include them. The comment provides a general suggestion but lacks specific guidance or references to particular sections or elements of the paper. As a result, the authors cannot confidently determine which part of the paper needs attention, making the comment 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point acknowledges the empirical study as good but notes the absence of new proposals for neural architecture encoding. It suggests that a good empirical analysis should not only provide insights but also include new initial proposals based on the analysis. However, the comment lacks specific examples or references to support the claim that new proposals are necessary or how they could be integrated into the analysis. The absence of detailed reasoning or evidence makes it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the empirical study as good but points out a lack of new proposals for neural architecture encoding. It suggests that a good empirical analysis should not only provide insights but also include new initial proposals based on the analysis. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might incorporate new proposals or what aspects of their analysis could be expanded to include them. The feedback is 3 as it highlights a gap in the paper but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the performance of the proposed approach in real data compared to simulations, questioning the practical advantage of the method. It suggests including more real data analyses or comparisons to support the method\"s practicality. While the comment implies that the authors should include more real data analyses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct these analyses or comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of the proposed approach in various simulations and real data, questioning the practical advantage of the method. However, it does not specify which part of the paper discusses these simulations or real data analyses, making it weakly grounded. The comment is specific in suggesting the inclusion of more real data analyses or comparisons to support the method\"s practicality. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed approach performs well in simulations but not in real data, questioning its practical advantage. However, the comment lacks specific examples, detailed comparisons, or references to support this claim. Without concrete evidence or detailed analysis, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient evidence or reasoning to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the proposed approach performs well in simulations but not in real data, which questions its practical advantage. It suggests that including more real data analyses or comparisons could help support the method\"s practicality. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by addressing the gap between simulation and realworld performance. However, the comment could be more helpful if it offered additional guidance on how to conduct these real data analyses or comparisons. Overall, the comment is 4, as it effectively points out a critical area for improvement and provides a clear path forward."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the claim that the solution provided by the authors minimizes discrimination risk while maintaining utility and fairness. It also mentions that the underlying data distribution should be preserved after imputation, which affects the effectiveness of the models. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the claim made by the authors regarding the solution\"s impact on discrimination risk, utility, and fairness. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also mentions the importance of preserving the underlying data distribution after imputation, but it does not provide specific guidance on how this should be addressed. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point consists of factual statements and questions, such as \"The authors claim that the solution they provided have a low discrimination risk (while minimally sacrificing utility) and improve the fairness of models.\" It does not contain subjective opinions, suggestions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a concern about the authors\" claim regarding the solution\"s impact on discrimination risk, utility, and fairness. It also points out the importance of preserving the underlying data distribution after imputation, which directly affects the effectiveness of the models. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or improve their draft. While it identifies important issues, it lacks actionable feedback, making it 3. The authors are left to infer what changes might be necessary, but without detailed guidance, the comment does not fully support their efforts to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors could further exploit the ReferIt dataset by using more of its data before moving on to other datasets. While the comment implies that the authors should consider using more data from ReferIt, it does not provide specific guidance on how to implement this suggestion or what aspects of the dataset should be explored. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors could exploit the ReferIt dataset more before moving on to other datasets. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where the authors discuss the ReferIt dataset. Without explicit references to sections or experiments, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the ReferIt dataset should be explored or how it could be exploited further. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors could exploit the ReferIt dataset more before moving on to other datasets. However, it does not provide any specific reasoning, examples, or references to support why this suggestion would be beneficial or how it could be achieved. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the authors could further exploit the ReferIt dataset by using more of its data before moving on to other datasets. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to implement this suggestion or what aspects of the dataset should be explored. The authors are left with a general idea but without actionable steps to enhance their work. Therefore, the comment is 3, as it points out a direction for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests clarification on specific points in the paper, asking for elaboration on the explanation in lines 243245 and the choice of kNN in line 247. The reviewer provides clear questions that guide the authors on what aspects need further explanation. This feedback is explicit and provides concrete details on how to address the issues, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (243245 and 247) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be clarified, such as the explanation of 5*3 and the choice of kNN over other classifiers. This provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification on specific aspects of the paper, such as the explanation in lines 243245 and the choice of kNN in line 247. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific sections of the paper (lines 243245 and 247) where the explanation is unclear. It provides clear and actionable feedback by asking for elaboration on the explanation of 5*3 and the choice of kNN over other classifiers. This feedback is valuable as it guides the authors on what aspects of their draft need further clarification or explanation. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided additional context for understanding these sections. Overall, the comment is 4 as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly instructs the authors to provide a detailed description of the background of SharpnessAware Minimization (SAM). This is a clear and direct action for the authors to take, leaving no ambiguity about what needs to be done. The comment provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment suggests that the background of SharpnessAware Minimization (SAM) should be described in detail. However, it does not specify which part of the paper this background should be included in, such as a specific section or chapter. Without explicit references to sections or chapters, the authors may find it challenging to pinpoint the exact location where this background should be added. The comment is specific in its request for more detail on SAM but lacks grounding because it does not specify where this detail should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the background of SharpnessAware Minimization (SAM) should be described in detail. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the background of SharpnessAware Minimization (SAM) should be described in more detail. This feedback is 3 as it identifies a specific area where the paper could be improved by providing additional context or explanation. However, the comment lacks depth and does not offer specific guidance on what aspects of the background should be elaborated upon or how to present this information effectively. While it points out a potential area for enhancement, it does not provide detailed suggestions or examples, leaving the authors with a general direction but limited actionable steps. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the experimental setup lacks comprehensive comparisons between languageassisted and visionassisted approaches. It provides a specific example of how this could be addressed by incorporating image guidance using related reference normal images or coloraugmentation for the kNN baseline. The comment also recommends a thorough examination of both languagebased and visionbased assistance to strengthen the evaluation of LAFT\"s efficacy. This feedback is clear and provides concrete suggestions on how to improve the experimental setup, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental setup\" and \"comparisons between languageassisted and visionassisted approaches,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending the incorporation of image guidance using related reference normal images or coloraugmentation for the kNN baseline. This specificity guides the authors on how to enhance their experimental setup. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental setup lacks comprehensive comparisons between languageassisted and visionassisted approaches. It suggests incorporating image guidance by utilizing related reference normal images or coloraugmentation for the kNN baseline. The comment provides a specific example of how this could be achieved, which is a clear and logical suggestion. However, it does not provide detailed reasoning or references to support why these comparisons are necessary or how they would enhance the evaluation of LAFT\"s efficacy. While the suggestion is sound, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental setup, namely the lack of comprehensive comparisons between languageassisted and visionassisted approaches. It provides a concrete suggestion for improvement by recommending the incorporation of image guidance using related reference normal images or coloraugmentation for the kNN baseline. This feedback is actionable and offers a clear direction for enhancing the evaluation of LAFT\"s efficacy. By addressing this feedback, the authors can strengthen their experimental design and provide a more robust evaluation of their approach. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing related work, specifically collective entity linking, which the reviewer believes is closely related to the proposed model. The comment suggests that the proposed model could be considered a special case of collective entity linking. While the comment implies that the authors should include this related work, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to integrate this information into the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"collective entity linking,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the missing related work and suggests that the proposed model could be considered a special case of collective entity linking. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks related work on collective entity linking, which the reviewer suggests is closely related to the proposed model. The comment provides a logical reasoning by stating that the proposed model could be considered a special case of collective entity linking. However, it does not include specific references or examples to support the claim, which would strengthen the argument. The lack of detailed evidence or references makes the claim 3, as the authors would need to investigate the claim further to fully understand its basis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, specifically the lack of related work on collective entity linking. It suggests that the proposed model could be considered a special case of collective entity linking, which is a closely related line of work. This feedback is valuable as it highlights an important area for the authors to address, providing a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to integrate this related work into the paper or provided examples of relevant studies. Despite this, the comment is 4 as it directs the authors to a critical area for enhancement, making it a 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about truncating the log likelihood function, suggesting that it could lower sensitivity and asking for a comparison. It also points out a discrepancy between the algorithm and the general framework regarding the query functions for different data sources. The comment implies that the authors should address these issues by either designing customized query functions or clarifying the subscript. While the actions are implicit, they are concrete in terms of what needs to be done to improve the draft. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1\" and \"the general framework,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the algorithm and the general framework regarding the query functions for different data sources, and it suggests either designing customized query functions or removing the subscript for clarity. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises a claim about truncating the log likelihood function potentially lowering sensitivity and suggests comparing it. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The suggestion to compare is vague, and the authors may find it challenging to understand the basis of the claim without further explanation. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about truncating the log likelihood function, suggesting that it could lower sensitivity and asking for a comparison. It also points out a discrepancy between the algorithm and the general framework regarding the query functions for different data sources, questioning how to design customized query functions or whether it would be clearer to remove the subscript. While the comment identifies potential issues and areas for improvement, it lacks specific guidance or suggestions on how to address these concerns. The feedback is 3 as it prompts the authors to consider these aspects, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation should be expanded to include a larger and more diverse dataset, encompassing more complex molecules and materials. While the comment implies that the authors should consider this expansion, it does not provide specific guidance on how to achieve this or which datasets to consider. The action is implicit and somewhat vague, as the authors need to infer that they should expand the evaluation and determine which datasets to use. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the evaluation to include a larger and more diverse dataset, encompassing more complex molecules and materials. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the evaluation section, but the comment lacks full grounding as it does not explicitly mention a specific section. The suggestion is specific in terms of what needs to be addressed, namely the inclusion of a larger and more diverse dataset. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation is limited to a small set of molecules from the MD17 dataset and recommends expanding the evaluation to a larger and more diverse dataset. This claim is 3 as it provides a logical reasoning for the suggestion, noting the potential benefits of evaluating on a broader dataset. However, the comment lacks specific examples or references to datasets that could be used for comparison, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation, noting that it is restricted to a small set of molecules from the MD17 dataset. It suggests that the method should be evaluated on a larger and more diverse dataset, including more complex molecules and materials. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their evaluation to improve the robustness and generalizability of their method. However, the comment could be more helpful if it offered suggestions on which datasets to consider or how to approach the evaluation of more complex molecules. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their evaluation process."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors clarify the differences between their work and the StreamingLLM paper, which is similar in some aspects. It implies that the authors should highlight the unique contributions of their work compared to StreamingLLM. While the comment explicitly states the need for clarification, it does not provide specific guidance on how to present these differences or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to clarify but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the StreamingLLM paper 1 by Xiao et al., allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out similarities between the two works, particularly the use of sink tokens and local attention, and suggests clarifying the differences. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the StreamingLLM paper is similar to the current work, noting specific similarities like the use of sink tokens and local attention. It also suggests that the StreamingLLM paper has recently been uploaded, making it unlikely to compare the current paper with it. The comment provides a reference to the StreamingLLM paper, which supports the claim of similarity. However, it lacks detailed comparison or specific points of difference, which would strengthen the justification. Overall, the claim is 4, as it provides some evidence but could be more comprehensive with additional details. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential similarity between the authors\" work and the StreamingLLM paper, noting specific aspects like the use of sink tokens and local attention. It suggests that the authors clarify the differences between their work and the StreamingLLM paper, which is a valuable suggestion for improving the clarity and distinctiveness of the paper. However, the comment could be more helpful if it provided specific guidance on how to highlight these differences or what aspects to focus on. While it points out an area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that there is no significant improvement in the qualitative results compared to ConceptWeaver, which can handle more than two concepts. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to improve the qualitative results or explaining why ConceptWeaver is relevant. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the qualitative results and compares them to ConceptWeaver, which is also mentioned in the reference. However, it does not specify which part of the paper discusses the qualitative results, making it weakly grounded. The comment is specific in pointing out the lack of significant improvement compared to ConceptWeaver, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no significant improvement in the qualitative results compared to ConceptWeaver, which can handle more than two concepts. This claim is supported by a reference to a specific paper, \"Concept Weaver,\" which provides a basis for the comparison. However, the comment could be strengthened by providing more detailed analysis or examples of how ConceptWeaver outperforms the current work. Overall, the claim is 4 as it includes a reference to external work, but it lacks comprehensive evidence or detailed comparison within the text. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment points out a potential issue with the qualitative results, suggesting that there may not be a significant improvement compared to ConceptWeaver, which can handle more than two concepts. This feedback is 3 as it highlights a specific area where the authors might need to improve their results or provide additional context. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or what specific improvements could be made. While it identifies a potential weakness, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the problem can be reduced to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. However, it does not provide explicit instructions or concrete steps for the authors to follow. The comment implies that the authors should consider this approach, but it lacks detailed guidance on how to implement it or what specific changes should be made to their draft. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the problem can be reduced to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion but lacks grounding, as it does not reference any particular part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the problem can be reduced to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the problem can be reduced to subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. While this provides a potential direction for the authors to explore, it lacks specificity and does not offer detailed guidance or suggestions on how to implement this approach or what specific improvements it would bring to the paper. The comment is 3 as it points out a possible avenue for improvement, but it does not provide enough detail or actionable advice to be fully beneficial. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with CCKTDet++\"s reliance on the quality and alignment of teacher models, noting that limitations or biases in these models could affect performance and introduce unintended biases. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or mitigate the potential risks. The action is implicit, as the authors need to infer that they should consider the quality and alignment of teacher models in their work. Additionally, the comment lacks concrete details on how to address this issue, making it 3.", "grounding_specificity_rationale": "The comment highlights a potential issue with CCKTDet++\"s reliance on the quality and alignment of teacher models, noting that limitations or biases in these models could affect performance and introduce unintended biases. However, it does not specify which part of the paper discusses CCKTDet++ or the teacher models, making it weakly grounded. The comment is specific in detailing the issue of reliance on teacher models and the potential consequences, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point highlights a potential issue with CCKTDet++\"s reliance on the quality and alignment of teacher models, noting that limitations or biases in these models could affect performance and introduce unintended biases. The comment provides a logical reasoning by explaining how the teacher model\"s quality and alignment could impact the performance of CCKTDet++. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to consider this issue and address it in their work, but the comment could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with CCKTDet++\"s reliance on the quality and alignment of teacher models, noting that limitations or biases in these models could affect performance and introduce unintended biases. This is a valuable observation that highlights a critical aspect of the methodology that the authors should consider. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the potential risks. While it points out a significant concern, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the comparison objects in the comparison experiment are outdated and that the performance has not been significantly improved. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether the authors should update the comparison objects, conduct additional experiments, or make any other changes to improve the performance. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the comparison objects in the comparison experiment are outdated and that the performance has not been significantly improved. However, it does not specify which part of the paper this critique is based on, such as which comparison experiment or section is being referred to. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what specific improvements are needed or how the authors might address the issue of outdated comparison objects. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the comparison objects in the comparison experiment are outdated and that the performance has not been significantly improved. However, the comment lacks specific examples or references to support this claim, such as which comparison objects are outdated or how the performance has not improved. Without detailed evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the comparison objects used in the comparison experiment are outdated, suggesting that the performance has not been significantly improved. This is a relevant observation that could help the authors identify areas for improvement in their experimental setup or analysis. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or recommendations, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it highlights a potential issue but does not fully support the authors in resolving it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about how masks are handled in CNN layers, specifically in the representation block. While it implies that the authors should provide information on this topic, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on what information should be included or how to address the question. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment asks about how masks are handled in CNN layers, specifically in the representation block. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion of CNN layers or the representation block. This provides weak grounding, as the authors can make an educated guess but cannot pinpoint the exact section. The comment is specific in its inquiry about masks in CNN layers, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about how masks are handled in CNN layers (representation block). It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about how masks are handled in CNN layers, particularly in the representation block. While it identifies a potential area of interest or confusion, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. The comment is 3 as it prompts the authors to clarify a specific aspect of their work, but it does not offer actionable feedback or insights into how to enhance the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results in Figure 8, specifically asking for an explanation of why the \"without dropout\" condition has a larger training loss. The reviewer suggests that activation clipping might reduce the model capacity, implying that this could be a potential reason for the observed result. While the comment does not explicitly instruct the authors to provide an explanation or make changes, it does prompt them to consider a possible reason for the observed result. The action is implicit but concrete, as the authors can infer that they need to provide an explanation for the observed result. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the reason for the larger training loss in the \"without dropout\" condition and suggests that activation clipping might be a contributing factor. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the results in Figure 8, specifically asking for an explanation of why the \"without dropout\" condition has a larger training loss. The reviewer suggests that activation clipping might reduce the model capacity, which could be a potential reason for the observed result. However, the comment does not provide any specific evidence, examples, or references to support the claim that activation clipping could lead to this outcome. The reasoning is logical but lacks detailed justification or empirical evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the results presented in Figure 8, specifically asking for an explanation of why the \"without dropout\" condition has a larger training loss. It suggests that activation clipping might be a contributing factor, which is a logical inference. While the comment does not provide detailed guidance on how to address this issue or improve the explanation, it does prompt the authors to consider a potential reason for the observed result. This feedback is 3 as it directs the authors to a potential area of improvement, but it could be more helpful with additional suggestions or guidance on how to address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights the significance of the paper in establishing a largescale matting dataset, which is not explicitly mentioned in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to include this information. The comment lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights the significance of the paper in establishing a largescale matting dataset, which is not explicitly mentioned in the paper. However, it does not specify which part of the paper should include this information or how it could be integrated. The authors might infer that it relates to the introduction or discussion sections, but this inference is not explicit. The comment is specific in identifying the importance of the dataset but lacks grounding as it does not pinpoint a specific section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s significance lies in establishing a largescale matting dataset, which is not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant contribution of the paper, which is the establishment of a largescale matting dataset. However, it fails to provide any actionable feedback or suggestions on how the authors could better highlight or discuss this contribution in their paper. Without specific guidance or recommendations, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 1, as it does not offer any actionable insights or constructive feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the number of adversarial examples is insufficient to demonstrate a particular distribution. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on how to increase the number of examples, what distribution should be demonstrated, or how to improve the analysis. Without specific instructions or concrete steps, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the number of adversarial examples is insufficient to demonstrate a particular distribution. However, it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding which distribution is not adequately demonstrated or how the authors might address this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the number of adversarial examples is insufficient to demonstrate a particular distribution. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is the case. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the number of adversarial examples being insufficient to demonstrate a particular distribution. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, the comment is 1, as it does not offer any meaningful direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point raises concerns about the appropriateness of the proposed channelsparse gradients and suggests that they may not save time or memory in practice. It also points out that the analysis experiments in Section 5.2 are done with a subset of common corruptions, questioning whether the findings generalize to the full set. The comment provides explicit suggestions for improvement, such as conducting experiments with the full set of corruptions for thoroughness and comparability. These suggestions are clear and actionable, giving the authors concrete steps to take to enhance their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.2\" and \"the full set of corruptions,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the proposed channelsparse gradients and suggests conducting experiments with the full set of corruptions for thoroughness and comparability. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the appropriateness of the proposed channelsparse gradients, suggesting that they may not save time or memory in practice due to the limitations of most frameworks supporting only dense gradients. It also questions the generalizability of the analysis experiments conducted with a subset of common corruptions, suggesting that they should be done with the full set for thoroughness and comparability. The comment provides logical reasoning and a clear explanation of the potential issues, making it 4. However, it could be strengthened by providing specific examples or references to support the claim about the limitations of frameworks. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several issues with the paper, providing specific and actionable feedback. It questions the appropriateness of the proposed channelsparse gradients, suggesting that they may not save time or memory in practice due to limitations in most frameworks. The comment also points out that the analysis experiments in Section 5.2 are conducted with a subset of common corruptions, questioning the generalizability of the findings. It recommends conducting these experiments with the full set of corruptions for thoroughness and comparability with other results. This feedback is clear and provides the authors with concrete steps to enhance the validity and comprehensiveness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the authors\" claims regarding the lack of consideration for sparsity or low rank in their proof. It suggests that the proof might be using concentrationofmeasure, which has a connection to low rank, and questions the strength of the claim. Additionally, the comment critiques the results, stating that they are a simple extension of existing results. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The actions are implicit and vague, leaving the authors without clear direction on how to respond to the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses multiple issues, including the lack of consideration for sparsity or low rank in the proof and the claim that the results are a simple extension of existing results. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the claims and the results, but it lacks grounding as it does not identify the specific sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including the lack of consideration for sparsity or low rank in the proof and the assertion that the results are a simple extension of existing work. The comment provides some reasoning by suggesting that the proof might be using concentrationofmeasure, which has a connection to low rank. However, it lacks specific references or detailed examples to support these claims, making it 3. The authors would need to further explore the reasoning and evidence provided to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several concerns about the paper, including the lack of consideration for sparsity or low rank in the proof and the claim that the results are a simple extension of existing work. It provides some reasoning by suggesting that the proof might be using concentrationofmeasure, which has a connection to low rank, and questions the strength of the claim. However, the comment lacks specificity and actionable guidance on how the authors might address these issues or improve their draft. It does not provide detailed suggestions or examples of how to incorporate sparsity or low rank considerations into the proof or how to differentiate the results from existing work. As a result, the feedback is 3, as it identifies areas for improvement but does not offer comprehensive guidance for the authors to effectively address the issues raised."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the Limitations section is too concise compared to the detailed writing style in the main body of the paper. However, it does not provide any explicit or implicit suggestions on how to improve the section or what specific details should be added. The comment lacks actionable guidance, leaving the authors uncertain about how to address the issue. Without concrete advice or examples, the authors are unable to make meaningful improvements to the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the Limitations section, which is a specific part of the paper, providing full grounding. It specifies the issue by noting that the section is too concise compared to the detailed writing style in the main body. However, it does not provide further details or suggestions on how to improve the section, making it underspecific. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the Limitations section is too concise compared to the detailed writing style in the main body of the paper. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, noting that the Limitations section is too concise compared to the detailed writing style in the main body. This feedback is 3 as it points out a potential area for improvement, suggesting that the authors should expand the Limitations section to match the level of detail in the main body. However, the comment lacks specific guidance or suggestions on how to achieve this expansion, such as what additional details or examples should be included. While it provides some direction, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the novelty of the proposed method is weak, suggesting that it is a modified version of previous work, PatchCore, with the addition of a denoising process to the memory bank. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the novelty of their method. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed method, suggesting it is a modified version of previous work, PatchCore, with the addition of a denoising process to the memory bank. However, it does not specify which part of the paper this critique is based on, such as a specific section or experiment where the novelty is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the novelty, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is weak, suggesting it is a modified version of previous work: PatchCore, with the addition of a denoising process to the memory bank. This claim is 3 as it provides a specific reference to PatchCore, allowing the authors to understand the basis of the critique. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as how the proposed method differs from PatchCore or why the addition of a denoising process does not contribute significantly to novelty. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the novelty of the proposed method, suggesting that it is a modified version of previous work, PatchCore, with the addition of a denoising process to the memory bank. This feedback is 3 as it points out an area where the authors might need to clarify or differentiate their work from existing literature. However, the comment lacks specific suggestions or guidance on how the authors could enhance the novelty or originality of their method. Without actionable advice, the authors may find it challenging to address the feedback effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the code repository, noting that it lacks clear instructions for installation and running. The reviewer suggests providing more details about each challenge, similar to how binpwn does it, and also recommends listing all prompts used in the evaluation. These suggestions are explicit and provide concrete guidance on how to improve the code repository and the appendix. The authors know exactly what steps to take to address these issues, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the code repository, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the code repository, such as the lack of clear instructions for installation and running, and suggests providing more details about each challenge and listing all prompts used in the evaluation. This provides clear guidance on what needs to be addressed to improve the code repository. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the code repository lacks clear instructions for installation and running, which is a factual statement. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a critical issue with the code repository, specifically noting that it lacks clear instructions for installation and running. It provides a specific suggestion to improve this by recommending the inclusion of more detailed information about each challenge, similar to how binpwn does it, and also suggests listing all prompts used in the evaluation. This feedback is clear and actionable, offering the authors concrete steps to enhance the usability and clarity of their code repository. By addressing these points, the authors can significantly improve the accessibility and reproducibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, where correct answers are anchored on correct visual content. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the discrepancy or what changes, if any, should be made to the draft. As a result, the authors are left without a clear understanding of how to improve their work based on this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a discrepancy between the model ablation results and the major claim of interpretable VQA, where correct answers are anchored on correct visual content. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model ablation results in Table 3 suggest that the global representation g_v is more crucial than other components, which \"opens back door for grounded QA.\" However, it also notes a discrepancy with the major claim of interpretable VQA, where correct answers are anchored on correct visual content. The comment provides a logical reasoning by contrasting the ablation results with the major claim, but it lacks specific examples or references to support the claim fully. While the reasoning is clear, the lack of detailed evidence or references makes the claim 3, as it requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, where correct answers are anchored on correct visual content. This observation highlights a critical issue that the authors need to address, as it challenges the core claim of their work. However, the comment does not provide specific suggestions or guidance on how the authors might reconcile this discrepancy or improve their interpretation of the results. While it points out an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include comparisons with stateoftheart RVQVAE models, such as MoMask, in their ablation studies on the motion tokenizer. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional comparisons to enhance the comprehensiveness of their analysis. The suggestion is concrete, as it specifies the type of models to compare with and the rationale for doing so. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of comparisons with stateoftheart RVQVAE models, such as MoMask, in the ablation studies on the motion tokenizer. This provides clear guidance on how to improve the analysis and understanding of the model\"s effectiveness. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the ablation studies on the motion tokenizer in Table 4 should include comparisons with stateoftheart RVQVAE models, such as MoMask, to provide a more comprehensive understanding of the model\"s effectiveness. The claim is supported by logical reasoning, as it highlights the importance of comparing the proposed approach with existing models in the same category to better evaluate its performance. However, the comment could be strengthened by providing specific examples or references to MoMask or other relevant works, which would make the claim 5. Therefore, the comment is 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for comparisons with stateoftheart RVQVAE models, such as MoMask, in the ablation studies on the motion tokenizer. This suggestion is clear and actionable, as it provides a concrete step for the authors to take to enhance the comprehensiveness and validity of their analysis. By including these comparisons, the authors can better understand the relative effectiveness of their model and provide a more robust evaluation of its performance. However, the comment could be more helpful if it offered specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the feedback is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the \"primarysecondary\" relationship is mentioned frequently in the paper but its difference from nuclearity is unclear and not precisely defined. While the comment identifies an area that needs clarification, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the distinction between the two concepts. Additionally, the comment lacks concrete details on how to make this distinction clear, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the \"primarysecondary\" relationship and its distinction from nuclearity, which is mentioned frequently in the paper. However, it does not specify which part of the paper discusses this relationship, making it weakly grounded. The comment is specific in pointing out the lack of clarity and precise definition of the \"primarysecondary\" relationship, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the \"primarysecondary\" relationship is mentioned frequently in the paper but its difference from nuclearity is unclear and not precisely defined. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the \"primarysecondary\" relationship is mentioned frequently but its distinction from nuclearity is unclear and not precisely defined. This feedback is 3 as it points out a potential area for clarification or improvement in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing a clearer definition or explanation of the relationship. While it highlights an area for improvement, the comment could be more helpful with additional details or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy in the effect of mask ratio across different datasets, noting that this could lead to more tuning, as mentioned in the limitations. It also points out that the impact of mask ratio is missing from the discussions and suggests providing an intuitive guide for choosing this ratio. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to include discussions on the impact of mask ratio and provide guidance on choosing this ratio, but the comment lacks concrete steps or examples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the effect of mask ratio on different datasets, noting that this could lead to more tuning, as mentioned in the limitations. It also points out that the impact of mask ratio is missing from the discussions and suggests providing an intuitive guide for choosing this ratio. However, the comment does not specify which part of the paper discusses the mask ratio or where the discussion on tuning is located. This makes it weakly grounded, as the authors cannot confidently determine the exact sections being referred to. The comment is specific in detailing what is missing and what should be addressed, such as providing an intuitive guide for choosing the mask ratio. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effect of mask ratio is different for different datasets, which could lead to more tuning, as mentioned in the limitations. It also notes that the impact of mask ratio is missing from the discussions and suggests providing an intuitive guide for choosing this ratio. The comment provides a logical reasoning by pointing out the potential impact of mask ratio on tuning and the need for guidance, but it lacks specific examples or references to support the claim. This makes the comment 3, as it provides a clear direction for improvement but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the effect of mask ratio seems to vary across different datasets, which could lead to more tuning, as mentioned in the limitations. It also points out that the impact of mask ratio is missing from the discussions, suggesting that an intuitive guide for choosing this ratio would be helpful. This feedback is clear and actionable, as it highlights a gap in the paper and provides a specific suggestion for improvement. By addressing these points, the authors can enhance the comprehensiveness and practicality of their work. However, the comment could be more helpful if it included examples or detailed guidance on how to incorporate this insight into the discussions. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper could benefit from another round of proofreading due to sections that are difficult to follow. However, it does not provide specific examples of what is unclear or how the authors might improve the readability. The action is implicit and vague, as it lacks concrete guidance on what needs to be addressed or how to address it. As a result, the authors are left without a clear understanding of what changes to make to improve the draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from another round of proofreading due to sections that are difficult to follow. However, it does not specify which sections are problematic or what specific issues make them difficult to follow. This lack of detail makes it difficult for the authors to pinpoint the exact areas that need attention. The comment is 1 as it does not identify a specific part of the paper, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper could benefit from another round of proofreading due to sections that are difficult to follow. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks evidence or references to substantiate why the sections are challenging to follow, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1, as it lacks sufficient justification or evidence to support the need for additional proofreading.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from another round of proofreading due to sections that are difficult to follow. While it identifies a potential issue, it lacks specificity and does not provide detailed guidance on what aspects of the paper are unclear or how the authors might improve the readability. Without specific examples or suggestions for improvement, the comment offers limited value to the authors in terms of actionable feedback. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"STG layer\" in Figure 2 has not been mentioned anywhere else in the manuscript, and the reviewer guesses it refers to stochastic gates. While the comment identifies a potential issue with the manuscript\"s consistency, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the term \"STG layer\" and ensure its consistency throughout the manuscript. However, the comment lacks concrete details on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the term \"STG layer\" has not been mentioned anywhere else in the manuscript, and the reviewer guesses it refers to stochastic gates. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the term \"STG layer\" in Figure 2, noting that it has not been mentioned elsewhere in the manuscript. The reviewer provides a guess that it might refer to stochastic gates, but this is not a claim or an opinion that requires verification. It is a factual observation or a request for clarification, fitting the \"No\" label.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, noting that the term \"STG layer\" in Figure 2 has not been mentioned anywhere else in the text. This observation is important as it highlights a potential inconsistency or lack of clarity in the manuscript. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the term. While it points out a potential problem, it lacks actionable feedback or detailed advice, making it 3. The authors are informed of a specific area needing attention but are not given a clear path to improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed methodology has limited improvements in some instances and even underperforms compared to the baseline in specific cases, such as FiQA and CONALA. However, it does not provide any explicit or implicit suggestions for how the authors might address these issues or improve their methodology. Without guidance on potential modifications or areas for further exploration, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed methodology, noting that it has limited improvements in some instances and even underperforms compared to the baseline in cases like FiQA and CONALA. However, it does not specify which part of the paper discusses these instances or provides details on how the methodology could be improved. The authors can infer that it relates to the results or evaluation sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, while it identifies a specific issue, it does not provide detailed guidance on how to address it, making it underspecific. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the improvements resulting from the proposed methodology are limited in some instances and that it even underperforms compared to the baseline in specific cases, such as FiQA and CONALA. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without specific data or analysis to back up the assertions, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific issue with the proposed methodology, noting that it has limited improvements in some instances and even underperforms compared to the baseline in cases like FiQA and CONALA. This feedback is relevant and could help the authors identify areas for improvement or further exploration. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these issues or improve their methodology. While it highlights a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the comparisons with 1 are not clear and asks for clarification on the contributions or advantages beyond 1. This provides a direct action for the authors to take, which is to clarify the comparisons and highlight the unique contributions of their work. The reference to 1 provides a specific point of comparison, making the action concrete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Comparisons with 1 are not clear,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on the contributions or advantages beyond 1, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparisons with 1 are not clear and asks for clarification on the contributions or advantages beyond 1. However, it does not provide any specific reasoning or evidence to support this claim. The reference to 1 is included, but it does not explain how the current work differs or what aspects are unclear. Without additional context or explanation, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity in comparisons with a referenced work (1). It explicitly asks for clarification on the contributions or advantages beyond 1, which is a clear and actionable suggestion for the authors to address. By highlighting this gap, the comment provides a direct path for improvement, making it 4. However, the comment could be more helpful if it included additional guidance or examples on how to effectively present the comparisons or contributions. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide a better explanation of the rebalancing step method, which is used to make multimodal learning less greedy. It also suggests that the authors should explain why using the average feature of previous samples can stop the training of the unimodal branch. This feedback is clear and provides specific actions for the authors to take, such as improving the explanation and analysis of the rebalancing step method. The concrete guidance on what needs to be addressed makes this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rebalancing step method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing in the explanation, namely the analysis of how the method makes multimodal learning less greedy and why using the average feature of previous samples can stop the training of the unimodal branch. This provides clear guidance on what the authors need to address in their explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rebalancing step method, used to make multimodal learning less greedy, is not well described and analyzed in the full text. The reviewer suggests that the authors should provide a better explanation of why using the average feature of previous samples can stop the training of the unimodal branch. However, the comment lacks specific examples or detailed reasoning to support the claim that the method is not well described. Without additional context or references, the authors may find it challenging to understand the exact issue and how to address it. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity and provides a clear suggestion for improvement. It points out that the rebalancing step method, used to make multimodal learning less greedy, is not well described and analyzed in the full text. The comment suggests that the authors should provide a detailed explanation of why using the average feature of previous samples can stop the training of the unimodal branch. This feedback is actionable and provides a clear direction for the authors to enhance the comprehensiveness and clarity of their work. However, it could be more helpful if it included examples or additional context to guide the authors further. Overall, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the differences and advantages of the \"Reduce\" part compared to EATA and whether harmful OOD instances can be identified using an entropy metric instead of an energy metric. While the comment implies that the authors should provide more detailed explanations or comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions in their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1\" and the \"Reduce\" part, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the differences and advantages of the \"Reduce\" part compared to EATA and whether harmful OOD instances can be identified using an entropy metric instead of an energy metric. This provides clear guidance on what aspects need further clarification or discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification and additional information about the \"Reduce\" part in Section 4.1, specifically regarding the differences and advantages compared to EATA and the use of entropy versus energy metrics for identifying harmful OOD instances. These are requests for clarification and do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises specific questions about the differences and advantages of the \"Reduce\" part compared to EATA, as well as whether harmful OOD instances can be identified using an entropy metric instead of an energy metric. This feedback is 3 as it prompts the authors to clarify and expand their explanations in the manuscript. However, the comment could be more helpful if it provided suggestions on how to address these questions or offered examples of how to compare the methods. Overall, the comment identifies areas for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it might be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policy. However, it does not explicitly instruct the authors to conduct this comparison or provide guidance on how to implement it. The comment implies that this comparison is optional, as it is not necessary to support the main claims of the paper. While the suggestion is clear, it lacks concrete details on how to execute the comparison, making it 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed method against deterministic control, given the popularity of deterministic policy. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in suggesting a comparison, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it might be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policy. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or beneficial. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that it might be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policy. While the suggestion is clear and provides a potential direction for further exploration, it lacks specific guidance or actionable steps for the authors to implement this comparison. The comment does not explain why this comparison is important or how it could enhance the paper\"s contribution. As a result, the feedback is 3, as it offers a direction for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the 3r column in Table 4 should not be named \"ATE\" and suggests that \"Corr\" should also be \"CauAnt.\" This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be corrected in the table. The comment is explicit and concrete, leaving no ambiguity about how to implement the suggested change. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the column names, suggesting that \"3r\" should not be named \"ATE\" and that \"Corr\" should be \"CauAnt.\" This provides clear guidance on what needs to be corrected in the table. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement questioning the naming of columns in Table 4. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not contain any claims or subjective elements. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the labeling of columns in Table 4, pointing out that the 3r column should not be named \"ATE\" and suggesting that \"Corr\" should be \"CauAnt.\" This feedback is clear and actionable, providing the authors with a precise correction to make in their table. By addressing this issue, the authors can ensure that their table is accurate and consistent, which is crucial for the clarity and credibility of their work. However, the comment could be more helpful if it explained the rationale behind the suggested changes or provided additional context on why these corrections are necessary. Overall, the comment is 4 as it directs the authors to a specific improvement that can enhance the quality of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two distinct points. The first point suggests that the mechanism is not clearly anchored in prior work, even after the experiments section, and recommends providing more clarity on what the methods are built off of. This is an implicit suggestion to include more detailed references or explanations to anchor the mechanism in prior work. The second point addresses the clarity of the figures, suggesting that annotating or zooming in on the curves would help ground the excitement about the differences. This is also an implicit suggestion to enhance the visual presentation of the results. Both points are 3 as they provide a direction for improvement but lack specific guidance on how to implement the suggested changes. The authors can infer that they need to provide more context and references to anchor the mechanism and improve the clarity of the figures, but the comment does not specify exactly how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"mechanism\" and the \"experiments section,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the lack of clear anchoring in prior work and suggesting that more detailed references or explanations are needed. Additionally, the comment provides specific feedback on the clarity of the figures, suggesting that annotating or zooming in on the curves would help ground the excitement about the differences. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: the first part claims that the mechanism is not clearly anchored in prior work, and the second part suggests that the figures lack clarity and could be improved with annotations or zooming. The first part is 3 as it highlights a lack of clear references to prior work, but it does not provide specific examples or detailed reasoning to fully substantiate the claim. The second part is verifiable as it provides a clear suggestion for improvement by recommending annotations or zooming to enhance the clarity of the figures. Therefore, the overall comment is 3, as it contains a mix of verifiable and 1 elements.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. The first point highlights a lack of clear anchoring in prior work, suggesting that the mechanism is not wellconnected to existing literature. It recommends providing more detailed references or explanations to establish the novelty and relevance of the work. This feedback is clear and actionable, as it directs the authors to enhance the context and justification of their work. The second point addresses the clarity of the figures, suggesting that annotating or zooming in on the curves would help ground the excitement about the differences. This is a specific and constructive suggestion that could significantly improve the paper\"s presentation. Overall, the comment is 4 as it offers actionable feedback on both the theoretical and visual aspects of the paper, providing the authors with clear directions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the limited novelty of the paper, specifically noting that the key contribution is the application of a pretrained mechanism to the task of fewshot graph learning. The reviewer suggests that the idea is plausible but not exciting and feels complicated. However, the comment does not provide any explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how to enhance the novelty or simplify the approach, leaving the authors without a clear path for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the limited novelty of the paper, specifically mentioning the pretrained mechanism applied to the task of fewshot graph learning. However, it does not specify which part of the paper this concern is based on, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in its critique of the novelty and complexity of the idea, but it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty and that the key contribution is the application of a pretrained mechanism to fewshot graph learning. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the assertion. Without additional context or justification, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the limited novelty of the paper, specifically noting that the key contribution is the application of a pretrained mechanism to the task of fewshot graph learning. While the comment acknowledges that the idea is plausible, it suggests that it is not particularly exciting or straightforward. However, the comment lacks specific suggestions or guidance on how the authors might enhance the novelty or simplify the approach. Without actionable feedback or detailed advice, the authors are left with a general critique but no clear path for improvement. Therefore, the comment is 3, as it identifies an area for improvement but does not provide sufficient detail or direction to be fully actionable."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper, noting that while it empirically validates the usefulness of certain setups and parameters for test time training, it lacks theoretical understanding of why these setups do not collapse. However, the comment does not provide explicit guidance or suggestions on how the authors might address this gap or what specific theoretical understanding is needed. The action is implicit and vague, as the authors are left to infer that they should provide theoretical explanations but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the lack of theoretical understanding regarding why certain setups and parameters do not collapse during test time training. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the gap in theoretical understanding, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper empirically validates the usefulness of certain setups and parameters for test time training but lacks theoretical understanding of why these setups do not collapse. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper, noting that while it empirically validates the usefulness of certain setups and parameters for test time training, it lacks theoretical understanding of why these setups do not collapse. This feedback is 3 as it points out a specific area where the paper could be strengthened by providing theoretical explanations. However, the comment does not offer suggestions or guidance on how the authors might address this gap or what specific theoretical understanding is needed. To be more helpful, the comment could include suggestions for potential theoretical frameworks or approaches that could be explored. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the visual analysis in Section 4.4, questioning whether it is based on training or test images. However, it does not provide explicit guidance on how the authors should address this issue or clarify the confusion. The action is implicit, as the authors need to infer that they should clarify the source of the visual analysis, but it is not concrete, as there is no specific direction on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the visual analysis in Section 4.4, questioning whether it is based on training or test images. This provides some level of specificity by identifying a potential issue with the analysis. However, it does not explicitly mention which part of Section 4.4 is being addressed, making it weakly grounded. The authors can infer that it relates to the visual analysis, but they may not be able to pinpoint the exact section within the section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the visual analysis in Section 4.4, specifically whether it is based on training or test images. However, it does not provide any supporting evidence, reasoning, or references to justify why this distinction is important or how it affects the analysis. The comment lacks specific details or examples that would help the authors understand the issue or address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the clarity of the visual analysis in Section 4.4, questioning whether it is based on training or test images. This is a relevant point that could help the authors clarify their methodology and ensure that their results are accurately presented. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their analysis. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should apply the DEER method to other methods like LEM or UnICORNN to explore potential performance improvements. It raises questions about whether these methods could maintain the same performance or achieve better results with the DEER method. The comment provides a clear and explicit action for the authors to take, which is to conduct an exploration of these methods using the DEER approach. Additionally, it offers a rationale for why this exploration would strengthen the paper and broaden its impact. The feedback is concrete and direct, providing the authors with a clear path to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests applying the DEER method to other methods like LEM or UnICORNN to explore potential performance improvements. It raises questions about whether these methods could maintain the same performance or achieve better results with the DEER method. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit reference makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting an exploration of these methods using the DEER approach, which would strengthen the paper and broaden its impact. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that applying the DEER method to other methods like LEM or UnICORNN could be beneficial. It raises questions about whether these methods could maintain the same performance or achieve better results with the DEER method. However, the comment lacks specific examples or references to support the claim that these methods could be trained faster or hyperparameter tuned more effectively. While the suggestion is logical, the lack of detailed evidence or examples makes it 3, as the authors would need to conduct their own experiments to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a constructive suggestion for enhancing the paper by proposing an exploration of the DEER method on other methods like LEM or UnICORNN. It raises interesting questions about the potential performance improvements and faster training that could be achieved with the DEER method. The comment also highlights the potential for broadening the impact of the paper by applying the method to different contexts. This feedback is clear and actionable, offering the authors a specific direction for expanding their work and improving its depth and relevance. However, it could be more helpful if it included specific guidance on how to conduct this exploration or what aspects to focus on. Overall, the comment is 4, as it provides valuable insights and a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment indicates that the presentation is difficult to follow due to the use of too many notations. However, it does not provide any explicit or implicit suggestions on how to address this issue or which notations should be simplified or removed. Without specific guidance or actionable steps, the authors are left without a clear understanding of what changes they should make to improve the clarity of their presentation. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the presentation is difficult to follow due to the use of too many notations. However, it does not specify which part of the paper this issue occurs in, such as specific sections, figures, or tables where these notations are used. Without explicit references to these parts, the authors cannot confidently determine where the issue lies. Additionally, the comment lacks specificity regarding which notations are problematic or how they could be simplified or clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the presentation is difficult to follow due to the use of too many notations. However, it does not provide any specific examples of these notations or explain how they contribute to the difficulty in understanding the paper. Without detailed justification or references to particular notations, the claim lacks verifiability. Therefore, it is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the presentation of the paper, noting that it is difficult to follow due to the use of too many notations. However, it lacks specificity and does not provide any suggestions or guidance on how to address this issue. Without actionable feedback or examples of which notations are problematic or how they could be simplified, the authors are left without a clear understanding of what changes are needed to improve the clarity of their presentation. Therefore, the comment is 1, as it does not offer any actionable insights or direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests including results from GPT4V, noting that while the API is not yet released, quick experiments through ChatGPT\"s UI are sufficient. This comment provides a clear and explicit action for the authors to take, which is to conduct experiments with GPT4V and include the results in their draft. The suggestion is concrete, as it specifies what needs to be done and how to do it, making the comment 5.", "grounding_specificity_rationale": "The comment suggests including results from GPT4V, noting that while the API is not yet released, quick experiments through ChatGPT\"s UI are sufficient. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or methodology sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of GPT4V results, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including results from GPT4V, noting that while the API is not yet released, quick experiments through ChatGPT\"s UI are sufficient. The comment provides a logical reasoning for why including GPT4V results would be beneficial, even though the API is not yet available. However, it lacks specific examples or references to support the claim that GPT4V results would be valuable or relevant to the paper. This makes the claim 3, as it provides a rationale but lacks detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests including results from GPT4V, noting that while the API is not yet released, quick experiments through ChatGPT\"s UI are sufficient. This feedback is 3 as it provides a specific suggestion for enhancing the paper by including additional results, which could potentially strengthen the study\"s scope and relevance. However, the comment could be more helpful if it offered guidance on how to conduct these experiments or what specific aspects of GPT4V results should be included. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss the implications of their theoretical analysis and compare it with baselines to explain why CoPur performs better. While the comment implies that the authors should provide more context and analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the implications of their theoretical analysis and compare it with baselines to explain why CoPur performs better. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in suggesting what the authors should address, namely the implications and comparison with baselines. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper provides an extensive theoretical analysis and recommends discussing the implications of this analysis. It also questions why CoPur performs better compared to baselines. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the analysis is extensive or to justify why CoPur performs better. Without such evidence or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors should discuss the implications of their theoretical analysis and compare it with baselines to explain why CoPur performs better. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by offering more context and analysis. However, the comment could be more helpful if it included suggestions on how to conduct the comparison or what specific aspects to focus on. Overall, the feedback is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the reported metrics, specifically noting that they are mostly for 3D NVS and that the evaluation protocol is not clear. It questions whether the camera parameters are the same for all frames when generating the videos, which could affect the keypoint distance metric. While the comment identifies potential issues, it does not provide explicit instructions or concrete suggestions on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the evaluation protocol and potentially adjust the metrics to better assess motion quality. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Result/eval,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the reported metrics, noting that they are mostly for 3D NVS and that the evaluation protocol is unclear. The comment raises a specific concern about the keypoint distance metric, questioning whether it assesses motion quality adequately. Additionally, it asks whether the camera parameters are the same for all frames when generating the videos, which could affect the keypoint distance. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the reported metrics, specifically questioning the evaluation protocol and the relevance of the keypoint distance metric. It suggests that the metric only assesses the size of motions and not their quality. The comment also questions whether the camera parameters are consistent across frames, which could affect the keypoint distance. While the comment identifies potential issues, it lacks specific examples or references to support the claims, making it 3. The authors would need to further explore and substantiate these points to fully understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the reported metrics and evaluation protocol, which are crucial for assessing the quality of the paper. It points out that the metrics are mostly for 3D NVS and questions the relevance of the keypoint distance metric, suggesting that it only assesses the size of motions rather than their quality. Additionally, the comment raises a concern about the evaluation protocol, questioning whether the camera parameters are consistent across frames, which could affect the keypoint distance. This feedback is clear and actionable, as it highlights areas where the authors need to clarify their evaluation methodology and potentially adjust their metrics to better assess motion quality. However, the comment could be more helpful if it provided specific suggestions on how to improve the evaluation protocol or metrics. Overall, the comment is 4, as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the two parts of pretraining and regularization are presented as incremental additions rather than naturally integrated components, which detracts from the coherence of the paper. However, it does not provide specific guidance on how the authors should address this issue or suggest ways to integrate these components more seamlessly. The action is implicit and vague, as the authors are left to infer that they need to restructure their presentation but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the presentation of the two parts of pretraining and regularization, suggesting that they are presented as incremental additions rather than integrated components, which detracts from the coherence of the paper. However, it does not specify which sections or parts of the paper this issue pertains to, making it weakly grounded. The comment is specific in identifying the problem of disjointed presentation, but without clear references to specific sections, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the two parts of pretraining and regularization are presented as incremental additions rather than integrated components, which detracts from the coherence of the paper. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the paper, noting that the two parts of pretraining and regularization are presented as incremental additions rather than integrated components. This observation is relevant and could impact the coherence and flow of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending ways to integrate these components more seamlessly or suggesting alternative structures for the presentation. While it highlights a potential weakness, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the importance of Renyi divergence is not well explained and that it is unclear why it is special for a reader unfamiliar with differential privacy. However, it does not provide explicit guidance or suggestions on how to improve the explanation or clarify the significance of Renyi divergence. The action is implicit, as the authors can infer that they need to provide a more detailed explanation, but it lacks concrete steps or examples on how to achieve this. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the explanation of Renyi divergence, specifically questioning its importance and why it is special for a reader unfamiliar with differential privacy. However, it does not specify which part of the paper discusses Renyi divergence, making it weakly grounded. The comment is specific in detailing what is missing in the explanation, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the importance of Renyi divergence is not well explained, particularly for a reader unfamiliar with differential privacy. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this explanation is insufficient. Without additional context or references, the claim remains vague and 1, leaving the authors without a clear understanding of what needs to be addressed. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely the explanation of the importance of Renyi divergence. It highlights the need for a more detailed explanation, particularly for readers unfamiliar with differential privacy. However, the comment does not provide specific suggestions or examples on how to improve the explanation, leaving the authors with a general direction but without actionable guidance. While it points out a weakness, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the authors should focus more on simplicity and clarity rather than relying on \"mathematical theories.\" However, it does not provide specific guidance on how to achieve this or what aspects of the paper should be simplified or clarified. The action is implicit and vague, as the authors are left to infer what changes are needed without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should focus more on simplicity and clarity rather than relying on \"mathematical theories.\" However, it does not specify which parts of the paper are overly complex or need simplification, nor does it provide examples or details on how to achieve this goal. Without explicit references to specific sections or examples, the authors cannot confidently determine which parts of the paper need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should focus more on simplicity and clarity rather than relying on \"mathematical theories.\" However, it does not provide any specific examples, reasoning, or evidence to support why this shift in focus is necessary or beneficial. Without detailed justification or references, the claim remains vague and 1, leaving the authors without a clear understanding of how to address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the authors should prioritize simplicity and clarity over \"mathematical theories,\" but it lacks specificity and actionable guidance. It does not provide examples of where the paper might be overly complex or how to simplify it, nor does it offer suggestions on how to achieve greater clarity. Without detailed feedback or concrete steps, the authors are left without a clear understanding of what changes are needed to improve the draft. Therefore, the comment is 2, as it identifies a potential area for improvement but does not provide sufficient direction for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation in the ablation study, specifically mentioning the need to further study the impact of the predefined threshold \u03f5. While the comment identifies an area for improvement, it does not provide specific guidance on how to conduct this study or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the ablation study in the paper, specifically mentioning the need to further study the impact of the predefined threshold \u03f5. However, it does not specify which part of the ablation study this issue pertains to, such as a particular section or figure. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting that the impact of the threshold should be further studied, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the ablation study is limited, specifically mentioning the need to further study the impact of the predefined threshold \u03f5. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this aspect of the study is limited or how it could be improved. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the ablation study, specifically pointing out the need to further study the impact of the predefined threshold \u03f5. This feedback is 3 as it highlights an area for improvement in the paper, prompting the authors to consider expanding their analysis to better understand the impact of this threshold. However, the comment lacks specific suggestions or guidance on how to conduct this additional study or what aspects to focus on. While it provides a direction for improvement, it does not offer detailed actionable steps, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that using only RougeL for evaluation is not reliable, especially for classification tasks where RougeL may not be sensitive enough. However, it does not provide explicit guidance on what alternative evaluation metrics should be used or how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should consider additional evaluation metrics but are not given specific instructions on which ones to use or how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation methodology, specifically mentioning the use of RougeL and its limitations for classification tasks. However, it does not specify which part of the paper discusses the evaluation methodology, making it weakly grounded. The comment is specific in pointing out the unreliability of RougeL for classification tasks, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that using only RougeL for evaluation is not reliable, especially for classification tasks where RougeL may not be sensitive enough. However, the comment lacks specific examples or references to support this claim. Without detailed evidence or comparisons to other evaluation metrics, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment points out a potential limitation in the evaluation methodology, specifically the use of RougeL for evaluation. It highlights that this metric may not be sensitive enough for classification tasks, which could impact the reliability of the evaluation. While the comment identifies a critical issue, it lacks specific suggestions or guidance on how the authors might address this concern, such as recommending alternative evaluation metrics or providing examples of more suitable metrics for classification tasks. This limits the comment\"s usefulness, as it provides insight into a potential weakness but does not offer actionable steps for improvement. Therefore, the comment is 3, as it prompts the authors to consider the limitations of their evaluation approach but does not fully support them in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a specific issue with the definitions of variables not matching the formula in lines 580588, specifically mentioning that the variable n_k is not found in Equation 3. This provides a clear and direct action for the authors to take, which is to ensure that the definitions of variables align with the equations in the paper. The comment is explicit and provides concrete guidance on what needs to be corrected, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lines 580588, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions of variables not matching the formula, particularly mentioning the absence of n_k in Equation 3. This provides clear guidance on what needs to be corrected, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the definitions of variables do not match the formula, specifically mentioning the absence of n_k in Equation 3. This is a factual observation that can be verified by checking the paper for consistency between the definitions and the equations. However, the comment does not provide any additional context, reasoning, or examples to support why this inconsistency is significant or how it affects the paper\"s validity. Therefore, the claim is 3, as it requires the authors to verify the claim themselves but lacks detailed justification or evidence to fully substantiate the issue.", "helpfulness_rationale": "The review comment identifies a specific issue with the definitions of variables not matching the formula, particularly mentioning the absence of n_k in Equation 3. This feedback is clear and actionable, as it directs the authors to ensure consistency between the definitions and the equations in their paper. By addressing this inconsistency, the authors can improve the clarity and accuracy of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve the issue, such as recommending specific changes to the definitions or equations. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, given the assumption of whole samplespecific vectors. It also mentions the absence of key experiments. While the comment implies that the authors should address these concerns, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the vector strategy and conduct the missing experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of a single vector for each class with large variances in the semantic space, questioning whether this conflicts with the assumption of whole samplespecific vectors. It also mentions the absence of key experiments. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in its critique of the vector strategy and the missing experiments, but without clear grounding, it is challenging for the authors to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of a single vector for each class with large variances in the semantic space, suggesting that this might conflict with the assumption of whole samplespecific vectors. The comment also mentions the absence of key experiments. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the vector strategy is problematic or that key experiments are missing. Without such evidence or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a critical question about the use of a single vector for each class with large variances in the semantic space, questioning whether this conflicts with the assumption of whole samplespecific vectors. It also points out the absence of key experiments, which could provide valuable insights into the effectiveness of the proposed method. While the comment identifies important areas for consideration, it lacks specific suggestions or guidance on how the authors might address these issues or conduct the missing experiments. This limits the comment\"s usefulness, as it provides insight but does not offer actionable steps for improvement. Therefore, the comment is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the work regarding the assumption of known intent classes during graph construction. It questions whether the IntenDD experiments reported in Table 1 are comparable to the cited baselines, given this assumption. The reviewer acknowledges that the authors have identified this as a limitation but suggests that further clarification is needed on the intent discovery experiment setting to ensure fair comparison with baselines. While the comment implies that the authors should provide more details on the experiment setting, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors know they need to clarify the experiment setting but may not be entirely sure of the specific details required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the comparability of the IntenDD experiments under the assumption of known intent classes, which is a key limitation of the work. The comment further suggests that the authors clarify the intent discovery experiment setting to ensure fair comparison with baselines. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the assumption of known intent classes during graph construction is a limitation, questioning the comparability of the IntenDD experiments reported in Table 1 with the cited baselines. The reviewer acknowledges that the authors have identified this as a limitation but suggests that further clarification is needed on the intent discovery experiment setting to ensure fair comparison. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to provide additional information to fully understand and address the concern. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or explanation.", "helpfulness_rationale": "The review comment identifies a key limitation in the work, specifically the assumption of known intent classes during graph construction. It questions the comparability of the IntenDD experiments reported in Table 1 with the cited baselines, given this assumption. The reviewer acknowledges that the authors have identified this as a limitation but suggests that further clarification is needed on the intent discovery experiment setting to ensure fair comparison. This feedback is clear and actionable, as it directs the authors to provide additional details on the experiment setting to address the concern about the reported SOTA. By doing so, the authors can improve the transparency and validity of their results. Therefore, the comment is 4, as it provides specific guidance for improvement but could be more comprehensive by offering suggestions on how to address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point appreciates the rigorous experimentation but criticizes the limited significance of the results due to the known variables and causal relationships in the intervened graph. It also points out that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which simplifies the problem. The comment references two papers that provide alternative approaches to address these issues. However, it does not explicitly instruct the authors to address these concerns or suggest specific changes to improve the work. The action is implicit and somewhat vague, as the authors can infer that they need to address the limitations mentioned but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rigorous experimentation\" and the \"application of dseparation criteria in the intervened graph with known variables and causal relationships,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the limited significance of the results due to the known variables and causal relationships, as well as the requirement of corruption labels in the experiments. The comment further supports its claims with references to external works, which adds to the specificity of the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the significance of the results is limited due to the known variables and causal relationships in the intervened graph, as well as the requirement of corruption labels in the experiments. The reviewer supports this claim by referencing two external works that provide alternative approaches to address these limitations. This provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges the rigorous experimentation in the work but points out the limited significance of the results due to the known variables and causal relationships in the intervened graph. It also highlights the requirement of corruption labels in the experiments on corrupted CIFAR and ImageNet, which simplifies the problem. The comment references two external works that provide alternative approaches to address these limitations, which is a valuable addition. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these issues or integrate the referenced works into their own study. Despite this, the feedback is 4 as it identifies important limitations and points the authors in the direction of potential improvements. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the reliance on gradientbased saliency methods to evaluate the importance of feature map channels, suggesting that this approach may not align with the underlying feature selection mechanisms in the human brain. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or suggest alternative methods for evaluation. Without specific recommendations or suggestions for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the reliance on gradientbased saliency methods to evaluate the importance of feature map channels, suggesting that this approach may not align with the underlying feature selection mechanisms in the human brain. However, the comment does not specify which part of the paper this critique is based on, nor does it provide detailed guidance on how to address this concern. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to focus their efforts. Additionally, the comment lacks specificity regarding what alternative methods or approaches could be considered. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the reliance on gradientbased saliency methods to evaluate the importance of feature map channels, suggesting that this approach may not align with the underlying feature selection mechanisms in the human brain. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the reliance on gradientbased saliency methods to evaluate the importance of feature map channels, suggesting that this approach may not align with the underlying feature selection mechanisms in the human brain. While the comment identifies a potential issue with the methodology, it lacks specific suggestions or guidance on how the authors might address this concern or explore alternative methods. Without actionable feedback or detailed advice, the authors are left with a general observation that does not provide a clear path for improvement. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the paper uses Pythia, which is not stateoftheart (SOTA), but acknowledges its advantage of available checkpoints. However, it does not provide any explicit or implicit guidance on whether the authors should consider using a different model or how to address this issue. The comment lacks actionable advice or suggestions, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the choice of the model Pythia, which is not stateoftheart (SOTA). However, it does not specify which part of the paper discusses this model choice, making it weakly grounded. The comment is specific in pointing out that Pythia is not SOTA but acknowledges its advantage of available checkpoints. This provides some guidance on the model choice but lacks detailed suggestions for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper uses Pythia, which is not stateoftheart (SOTA), but acknowledges its advantage of available checkpoints. However, the comment does not provide any supporting evidence or references to justify why Pythia is not SOTA or why the available checkpoints are significant. Without specific examples or comparisons to other models, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the paper uses Pythia, which is not stateoftheart (SOTA), but acknowledges its advantage of available checkpoints. While it identifies a potential weakness in the choice of model, it does not provide any suggestions or guidance on how the authors might address this issue or consider alternative models. The comment lacks depth and actionable feedback, leaving the authors without a clear understanding of how to improve their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggests that more information or resources should be provided to challenge the community in solving the image observation version of the Franka Kitchen task. It also asks whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. The comment implies that the authors should provide more information or resources to address these questions, but it does not explicitly instruct them to do so. While the authors can infer that they need to provide additional information, the action is not directly stated, and the comment lacks concrete guidance on how to address the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and suggests that more information or resources should be provided to challenge the community in solving the image observation version of the Franka Kitchen task. It also asks whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. However, the comment does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in its questions and suggestions, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point consists of a series of questions and suggestions, rather than a claim or opinion. It does not express a subjective judgment, disagreement, or request for change. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions and suggests that the authors provide more information or resources to challenge the community in solving the image observation version of the Franka Kitchen task. It questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning, and asks if the task can be completed solely with the provided offline data. Additionally, it suggests that if not, there might be an alternative data source that the community can leverage. While the comment identifies areas for improvement and provides some direction, it lacks specific suggestions or detailed guidance on how to address these questions or challenges. The feedback is 3 as it prompts the authors to consider these aspects, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for additional insight into why the multilingual model performs worse on specific evaluations, specifically ET\u2192En and LV\u2192EN. This request is clear and direct, providing a specific action for the authors to take. The comment also specifies the line number where the issue is mentioned, which further aids the authors in understanding what needs to be addressed. Therefore, this comment is 5, as it provides a concrete and explicit instruction on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 236,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for additional insight into why the multilingual model performs worse on specific evaluations, providing a clear direction for the authors to address. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking for additional insight into why the multilingual model performs worse on specific evaluations. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of concern regarding the performance of the multilingual model on certain evaluations. It prompts the authors to provide additional insight into why the model performs worse on specific tasks, which could lead to a deeper understanding of the model\"s limitations and potential improvements. However, the comment does not offer specific suggestions or guidance on how to address this issue, leaving the authors with a clear question but without actionable steps to enhance their draft. Therefore, the comment is rated as 3, as it provides a direction for further exploration but lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for clarification regarding the meaning of the numbers in brackets in Tables 1 and 2. This is a clear and direct request for the authors to provide an explanation, making the action 5. The comment specifies exactly what needs to be addressed, ensuring that the authors know precisely how to apply the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"tables#1,2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the meaning of the numbers in brackets (1) and (4). This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual question seeking clarification about the meaning of the numbers in brackets in Tables 1 and 2. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it directly asks for clarification regarding the meaning of the numbers in brackets in Tables 1 and 2. This feedback is valuable as it prompts the authors to provide an explanation for these numbers, which could be important for the understanding and interpretation of the results. By addressing this point, the authors can enhance the clarity and transparency of their work. However, the comment could be more helpful if it provided additional context or suggested potential meanings for these numbers. Overall, the comment is 4, as it directs the authors to a specific area needing clarification, but it could be more comprehensive with further guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the connection between the presented RDRO results and the listed limitations of some previous fairness notions, specifically in the context of longterm fairness. While it identifies a potential gap in the paper, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the connection between the results and the limitations, and it is vague because it lacks concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the connection between the presented RDRO results and the listed limitations of some previous fairness notions, particularly in the context of longterm fairness. However, it does not specify which part of the paper discusses these limitations or where the results are presented, making it weakly grounded. The comment is specific in detailing the concern about the connection between the results and the limitations, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the connection between the presented RDRO results and the listed limitations of some previous fairness notions, specifically in the context of longterm fairness. The reviewer acknowledges the fact that the paper considers RDRO and presents convergence analysis but expresses uncertainty about how these results relate to the listed limitations. The comment does not provide specific examples or references to support the claim, making it 3. The authors would need to further explore and clarify the connection themselves, which is a reasonable expectation but lacks explicit guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential disconnect between the presented RDRO results and the listed limitations of some previous fairness notions, specifically in the context of longterm fairness. It raises a valid question about how the results relate to these limitations, which is an important point for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this connection or improve their discussion. While it highlights an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a gap in the paper but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the accuracy and error units reported in the paper, specifically questioning the 29% accuracy with table assembly tasks and the high Euclidean distance error units in Table 1. It asks whether these errors are normalized to per datapoint position errors and questions the reasonableness of an error of 5 cm with HDRIL. While the comment identifies specific issues with the reported results, it does not provide explicit guidance on how the authors should address these concerns or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or justify the reported accuracy and error units. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the accuracy and error units reported in the table, specifically the 29% accuracy with table assembly tasks and the high Euclidean distance error units. The comment further asks whether these errors are normalized to per datapoint position errors and questions the reasonableness of an error of 5 cm with HDRIL. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the accuracy and error units reported in the paper, specifically the 29% accuracy with table assembly tasks and the high Euclidean distance error units in Table 1. It asks whether these errors are normalized to per datapoint position errors and questions the reasonableness of an error of 5 cm with HDRIL. While the comment raises valid concerns, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to provide additional context or evidence to fully understand and address the issues raised. Therefore, the comment is 3, as it provides a basis for further inquiry but requires more detailed justification.", "helpfulness_rationale": "The review comment raises a concern about the accuracy and error units reported in the paper, specifically questioning the 29% accuracy with table assembly tasks and the high Euclidean distance error units in Table 1. It asks whether these errors are normalized to per datapoint position errors and questions the reasonableness of an error of 5 cm with HDRIL. This feedback is 3 as it identifies a potential issue with the reported results and prompts the authors to clarify or justify these metrics. However, the comment could be more helpful if it provided suggestions on how to address these concerns or offered guidance on how to improve the accuracy or error reporting. Overall, the comment provides some direction for improvement but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the article does not reach a conclusion and implies that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The comment lacks actionable details, such as recommending specific changes or additional analyses to support the conclusion. As a result, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the article does not reach a conclusion and implies that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, it does not specify which part of the paper lacks a conclusion or where the suggestion about existing models\" capabilities is made. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the article does not reach a conclusion and suggests that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment acknowledges the article\"s fresh perspective but points out a significant weakness: the lack of a clear conclusion. It suggests that the article implies existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences, which could be a misleading claim. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their work. Therefore, the comment is 2, as it identifies a problem but lacks depth and actionable guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the theoretical results, stating that they do not provide much surprising information and have limited contribution to the algorithm design. It suggests that the algorithm design is primarily based on the labeler\"s strategy, which is already predefined. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their theoretical results. Without actionable suggestions or a clear direction for revision, the authors are left without a path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the theoretical results, suggesting that they do not provide much surprising information and have limited contribution to the algorithm design. However, it does not specify which part of the paper discusses these theoretical results, making it weakly grounded. The comment is specific in its critique of the theoretical results\" contribution to the algorithm design, but without clear references to specific sections or elements of the paper, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical results do not provide much surprising information and have limited contribution to the algorithm design. The comment suggests that the algorithm design is primarily based on the labeler\"s strategy, which is already predefined. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment critiques the theoretical results, suggesting that they do not provide much surprising information and have limited contribution to the algorithm design. It further implies that the algorithm design is primarily based on the labeler\"s strategy, which is already predefined. While the comment identifies a potential weakness in the theoretical contribution, it lacks specific suggestions or guidance on how the authors might enhance the theoretical results or their relevance to the algorithm design. Without actionable feedback or detailed advice, the authors are left without a clear path for improvement. Therefore, the comment is 3, as it points out an area for improvement but does not provide sufficient detail or direction for the authors to address it effectively."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the lack of detailed explanation regarding how the reverse chain proved effective in multiAPI planning and questions the research contribution of the article. However, it does not provide explicit guidance or suggestions on how the authors might address these issues. The comment implies that the authors should provide more detailed explanations and clarify the research contribution, but it lacks concrete steps or examples on how to achieve this. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses two specific points: the lack of detailed explanation regarding how the reverse chain proved effective in multiAPI planning and the focus of the article on comparing multiple tools or methods in API calling and planning, which the reviewer perceives as reducing the research contribution. However, the comment does not specify which sections of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact parts that need revision. While the authors might have an idea of where these issues could be addressed, the comment lacks full grounding. It is specific in detailing the concerns about the lack of detailed explanation and the perceived reduction in research contribution, but without explicit references to sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the article lacks detailed explanation of how the reverse chain proved effective in multiAPI planning and questions the research contribution by focusing on comparing multiple tools or methods in API calling and planning. However, the comment does not provide specific examples, reasoning, or references to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific areas of concern: the lack of detailed explanation regarding how the reverse chain proved effective in multiAPI planning and the perceived reduction in research contribution due to the focus on comparing multiple tools or methods in API calling and planning. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. Without actionable feedback or detailed advice, the authors are left with a general understanding of what needs to be improved but without a clear path forward. Therefore, the comment is 3, as it points out weaknesses but does not provide comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point explicitly recommends rejecting the paper due to the weaknesses identified in the previous comments, specifically related to experimental rigor. It suggests that the issues cannot be fixed within the available time and content space, implying that the authors should not invest further effort in addressing these concerns. However, the comment does not provide any actionable steps or suggestions for improvement, leaving the authors without guidance on how to address the issues or what specific changes might be necessary. The lack of concrete advice or detailed feedback makes this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the weaknesses in the review above,\" allowing the authors to identify the specific parts of the paper being addressed. It is also specific because it clearly specifies the recommendation to reject the paper due to the weaknesses in experimental rigor, which cannot be fixed within the available time and content space. The comment provides a clear and direct suggestion, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a recommendation to reject the paper due to the identified weaknesses in experimental rigor. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a recommendation based on the reviewer\"s assessment of the paper\"s weaknesses, which is factual and does not necessitate further justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and direct recommendation to reject the paper due to the identified weaknesses in experimental rigor. It acknowledges that these issues cannot be fixed within the available time and content space, implying that the authors should not invest further effort in addressing them. While the comment highlights the significant challenges in improving the paper, it does not offer any constructive feedback or suggestions for improvement. This lack of actionable guidance limits the comment\"s usefulness, as it does not provide the authors with a clear path forward. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the unfair competition between standalone Medusa and Medusa+ParallelSpec, noting that the draft model architecture changes from an MLPlike architecture to a singlelayer Transformer model when Medusa is adapted with ParallelSpec. The reviewer suggests providing a baseline where the only alteration is the draft model architecture and recommends giving the modified setting a different name to avoid confusion. While the comment implies that the authors should provide a baseline and consider renaming the modified setting, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (266267) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the unfair competition between standalone Medusa and Medusa+ParallelSpec due to the change in draft model architecture. The comment suggests providing a baseline with only the draft model architecture altered and recommends renaming the modified setting to avoid confusion. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that there is unfair competition between standalone Medusa and Medusa+ParallelSpec due to a change in the draft model architecture. It suggests providing a baseline with only the draft model architecture altered and recommends renaming the modified setting to avoid confusion. The comment provides a logical reasoning for the claim by pointing out the architectural differences between the two setups and the potential impact on the speedup gain. However, it lacks specific examples or references to support the claim fully, making it 3. The authors would need to further explore and substantiate the claim themselves to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between standalone Medusa and Medusa+ParallelSpec. It points out that the draft model architecture changes from an MLPlike architecture to a singlelayer Transformer model when Medusa is adapted with ParallelSpec, which could impact the speedup gain. The reviewer suggests providing a baseline where the only alteration is the draft model architecture and recommends renaming the modified setting to avoid confusion. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a concrete suggestion for addressing it. By following the advice, the authors can ensure a fair comparison and enhance the clarity of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the focus on Masked Language Models (MLMs) in the paper, asking for a justification or whether experiments with autoregressive Language Models (LMs) were unsuccessful. While the comment implies that the authors should provide a rationale for their choice of MLMs, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question of why MLMs were chosen. However, the comment does not specify how to provide this rationale or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the focus on Masked Language Models (MLMs) in the paper, asking for a justification or whether experiments with autoregressive Language Models (LMs) were unsuccessful. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment raises a specific question about the choice of MLMs, it does not provide detailed guidance on how to address this issue or what specific aspects of the paper need clarification. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question seeking clarification about the focus on Masked Language Models (MLMs) in the paper. It does not contain a claim or opinion that requires verification. It is a request for information or explanation, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the focus on Masked Language Models (MLMs) in the paper, asking for a justification or whether experiments with autoregressive Language Models (LMs) were unsuccessful. While this question prompts the authors to consider the rationale behind their choice of MLMs, it does not provide specific guidance or suggestions on how to address this issue or improve the paper. The comment lacks depth and actionable feedback, leaving the authors with only a vague direction for improvement. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: \"How is the map encoded?\" and \"Why haven\"t the authors shown the effectiveness of their method on the experiments proposed in YNet?\" These questions imply that the authors should provide more information about the encoding process and demonstrate the effectiveness of their method on the experiments mentioned. However, the comments do not explicitly instruct the authors to address these points, leaving the actions implied. While the authors can infer that they need to provide additional information, the lack of explicit guidance makes the comment 3. The authors know what needs to be done but may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment raises two questions: \"How is the map encoded?\" and \"Why haven\"t the authors shown the effectiveness of their method on the experiments proposed in YNet?\" However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The lack of explicit references to specific sections or parts of the paper results in weak grounding. The comment is specific in its requests for additional information, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point consists of two questions: \"How is the map encoded?\" and \"Why haven\"t the authors shown the effectiveness of their method on the experiments proposed in YNet?\" These are factual questions seeking clarification or additional information, rather than claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions: \"How is the map encoded?\" and \"Why haven\"t the authors shown the effectiveness of their method on the experiments proposed in YNet?\" These questions are relevant and could help the authors clarify their methodology and demonstrate the effectiveness of their approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address these questions. While it identifies areas for improvement, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address this issue. The comment lacks actionable details, such as recommending specific changes or experiments to enhance the model\"s performance. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to the proposed model and its performance compared to the MSA Transformer in terms of r2. However, it does not specify which part of the paper discusses the proposed model or its performance, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity as it does not detail what aspects of the proposed model are not better than the MSA Transformer or how the authors might improve their model. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data to support the assertion, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, it does not provide any further explanation, reasoning, or suggestions for improvement. Without additional context or guidance, the authors are left without actionable feedback on how to address this issue or enhance their model\"s performance. The comment lacks depth and specificity, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests more mathematical details to explain the concept of \"an ensemble of independent measures on the full feature space\" and its relation to the scaling observed in Fig. 2. This provides a clear and direct action for the authors to take, as it specifies what additional information is needed to clarify the explanation. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"top of page 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the explanation of \"an ensemble of independent measures on the full feature space\" and its relation to the scaling observed in Fig. 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the explanation of \"an ensemble of independent measures on the full feature space\" and its relation to the scaling observed in Fig. 2. The reviewer expresses confusion about the concept and requests more mathematical details. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the explanation is unclear or insufficient. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the explanation of \"an ensemble of independent measures on the full feature space\" and its relation to the scaling observed in Fig. 2. It requests more mathematical details to clarify this concept, which is a clear and actionable suggestion for the authors to improve the clarity and comprehensibility of their work. By addressing this feedback, the authors can enhance the understanding of their readers and strengthen the overall quality of their draft. Therefore, the comment is rated as 4, as it provides specific guidance for improvement but could be more comprehensive with additional details or examples."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider using BlenderBot 2.0 with incorporated knowledge and explore how this might improve dialogues by using domain ontologies from the SGD dataset. While the comment implies that the authors should conduct this experiment, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested experiment or what specific aspects of the SGD dataset should be used. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using BlenderBot 2.0 with incorporated knowledge and explore how this might improve dialogues by using domain ontologies from the SGD dataset. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a particular approach to improve the dialogues, but without clear grounding, the authors may struggle to identify where this suggestion fits into their work. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider using BlenderBot 2.0 with incorporated knowledge and explore how this might improve dialogues by using domain ontologies from the SGD dataset. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or how it could improve the paper. Without such evidence or justification, the claim remains 1, as the authors are left without a clear understanding of the potential impact or significance of this suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests a specific experiment that the authors could conduct to improve their work. It proposes using BlenderBot 2.0 with incorporated knowledge and exploring how this might enhance dialogues by utilizing domain ontologies from the SGD dataset. This feedback is actionable and provides a clear direction for the authors to consider, offering a potential avenue for improving the paper. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or what specific aspects of the SGD dataset should be used. Overall, the comment is 4 as it offers a constructive and actionable suggestion for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the number of samples rated by GPT4 and whether they overlap with the samples used in the human evaluation. The reviewer assumes that the samples should overlap since the paper calculates Krippendorff alpha. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of the number of samples rated by GPT4 and whether they overlap with the samples used in the human evaluation. However, it does not specify which part of the paper this information is missing from, making it weakly grounded. The comment is specific in detailing what is unclear and provides a logical assumption about the overlap of samples. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the number of samples rated by GPT4 and whether they overlap with the samples used in the human evaluation. The reviewer assumes that the samples should overlap since the paper calculates Krippendorff alpha. However, the comment does not provide specific examples or references to support this assumption, making it 3. The authors would need to infer the importance of this overlap and its impact on the analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the number of samples rated by GPT4 and whether they overlap with the samples used in the human evaluation. This is a relevant point that could impact the interpretation of the results, as it relates to the calculation of Krippendorff alpha. However, the comment does not provide specific guidance on how the authors might address this issue or suggest ways to clarify the information. While it highlights an important area for improvement, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the difference between \"argwise consistency\" and \"accuracy,\" suggesting that the intuition is that label annotation agreement should be lower due to inconsistent predicates. However, it does not provide explicit guidance or suggestions on how the authors should address this confusion or improve the clarity of their work. The comment implies that the authors need to clarify these terms and their relationship, but it lacks concrete steps or actions for the authors to take. As a result, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment raises a question about the difference between \"argwise consistency\" and \"accuracy,\" suggesting that the label annotation agreement should be lower due to inconsistent predicates. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the terminology and the logic behind the label annotation agreement, but it lacks grounding as it does not reference a specific section or figure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the difference between \"argwise consistency\" and \"accuracy,\" suggesting that the label annotation agreement should be lower due to inconsistent predicates. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the terminology used in the paper, specifically the difference between \"argwise consistency\" and \"accuracy.\" It also provides an intuition about the label annotation agreement, suggesting that it should be lower due to inconsistent predicates. While the comment identifies a potential area of confusion, it lacks specific suggestions or guidance on how the authors might clarify or address this issue. The feedback is 3 as it points out a potential area for improvement, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that providing more details on the neural network parametrization of the reverse process, particularly regarding how position embeddings are being provided, could enhance reproducibility. It also recommends sharing the code for their implementation, which is considered a reasonable request for reproducibility. Both suggestions are explicit and provide clear guidance on what the authors need to do to improve their draft. The actions are concrete, as they specify the details that need to be included and the code that should be shared. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests providing more details on the neural network parametrization of the reverse process, particularly regarding how position embeddings are being provided, to enhance reproducibility. It also recommends sharing the code for their implementation. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or implementation sections. The suggestion is specific in terms of what details are needed to improve reproducibility. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that providing more details on the neural network parametrization of the reverse process, particularly regarding how position embeddings are being provided, could enhance reproducibility. It also recommends sharing the code for their implementation. The claim is 3 as it provides a logical reasoning for why additional details and code sharing would improve reproducibility. However, it lacks specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement that could enhance the reproducibility of the paper. First, it suggests providing more details on the neural network parametrization of the reverse process, particularly regarding how position embeddings are being provided. This feedback is actionable and clear, as it directs the authors to a specific aspect of their methodology that could benefit from additional explanation. Second, the comment recommends sharing the code for their implementation, which is a reasonable request for reproducibility. While the comment could be more detailed in explaining why these details are crucial for reproducibility, it provides valuable guidance that can help the authors improve their draft. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with the first paragraph of section 3.3, noting that it contains a repeated paragraph. However, it does not provide any guidance on how to address this issue or suggest ways to improve the draft. The comment lacks explicit instructions or concrete details on what the authors should do to resolve the repetition. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the first paragraph of section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of a repeated paragraph, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of section 3.3 contains a repeated paragraph. However, it does not provide any further explanation, examples, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the first paragraph of section 3.3, noting that it contains a repeated paragraph. This feedback is valuable as it points out a potential problem that could confuse readers or waste their time. However, the comment lacks depth and does not provide suggestions on how to address the repetition or improve the clarity of the paragraph. While it highlights an area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it provides some insight but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reusability and sustainability of synthetic data, which is generated onthefly to save storage costs and improve relevance. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the question or what steps to consider to improve the sustainability of synthetic data. As a result, the authors are left without a clear understanding of what actions to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the reusability and sustainability of synthetic data, which is generated onthefly to save storage costs and improve relevance. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity as it does not provide detailed guidance on what aspects of reusability or sustainability should be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the reusability and sustainability of synthetic data, which is generated onthefly to save storage costs and improve relevance. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this aspect should be considered or how it might impact the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the reusability and sustainability of synthetic data, which is generated onthefly to save storage costs and improve relevance. This is a relevant concern that the authors should consider, as it could impact the practicality and applicability of their approach. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or recommendations, the authors are left with a general question to consider but no clear path for improvement. Therefore, the comment is 3, as it identifies a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two areas for improvement: the authors should examine the likelihood of alternative RNA structures arising and consider RNA abundance when building datasets. While the comment identifies specific actions, it does not provide detailed guidance on how to implement these suggestions. The authors are left with a general idea of what needs to be done but without concrete steps or examples to follow. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of the ProbTransfomer model and the challenge of RNA folding, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the authors do not examine the likelihood of alternative RNA structures arising and suggesting that they consider RNA abundance when building datasets. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the likelihood of alternative RNA structures is mostly dictated by biological circumstances, which the authors do not examine. It also suggests considering RNA abundance when building datasets. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The absence of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some insight but requires more detailed support to be fully actionable.", "helpfulness_rationale": "The review comment identifies two areas for improvement in the paper. First, it points out that the authors do not examine the likelihood of alternative RNA structures arising, which is a critical aspect of the challenge they are addressing. This feedback is clear and actionable, as it suggests a specific area where the authors could enhance their analysis. Second, the comment recommends considering RNA abundance when building datasets, which is a relevant and practical suggestion that could improve the robustness of the model. However, the comment could be more helpful if it provided additional context or examples on how to incorporate RNA abundance into the dataset building process. Overall, the feedback is 4 as it offers actionable insights for improving the paper, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the use of a single entropic regularization coefficient in the numerical results, suggesting that it may be a weak regularization term that leads to sparse couplings. The reviewer acknowledges that this might be favorable to the method but emphasizes the need to acknowledge this in the paper. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so, such as suggesting specific ways to acknowledge or address the issue. The action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"numerical results\" and the use of a single entropic regularization coefficient (\u03b7=1200), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the weak regularization term leading to sparse couplings, which is favorable to the method. The comment further specifies that this issue should be acknowledged in the paper and not \"swept under the rug.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the use of a single entropic regularization coefficient (\u03b7=1200) in the numerical results, suggesting that it may be a weak regularization term leading to sparse couplings. The reviewer acknowledges that this might be favorable to the method but emphasizes the need to acknowledge this in the paper. The comment provides a logical reasoning for the concern, suggesting that the authors should address this issue. However, it lacks specific examples or references to support the claim about the weak regularization term or its impact on the results. This makes the claim 3, as it requires further elaboration or evidence to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a potential issue with the numerical results, specifically the use of a single entropic regularization coefficient (\u03b7=1200). It suggests that this may be a weak regularization term, leading to sparse couplings that are favorable to the method. The reviewer acknowledges that this might be acceptable in the weakregularization regime but emphasizes the need for the authors to acknowledge this in the paper. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a rationale for why it is important. However, it could be more helpful if it offered suggestions on how to address this issue or provide additional context. Overall, the comment is 4, as it directs the authors to a critical aspect of their work that requires clarification."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the information provided in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how to resolve this discrepancy or what steps to take to ensure consistency between the table and the text. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the information provided in the table and the text of the paper regarding the Vlachos and Riedel 2014 dataset. The comment specifies the issue by detailing the inconsistency between the table and the text, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy between the information provided in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. It points out that the table states the dataset has no Evidence, while the text mentions that sources were collected for the analysis. This discrepancy is factual and requires no subjective opinion or justification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific discrepancy between the information provided in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. It points out that the table states the dataset has no Evidence, while the text mentions that sources were collected for the analysis. This feedback is valuable as it highlights a potential error or inconsistency that needs to be addressed. However, the comment does not provide any suggestions or guidance on how to resolve this discrepancy or ensure consistency between the table and the text. While it identifies an issue, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include details of parameters for each simulator, such as whether the GPU or CPU pipeline was used, the substeps for physics simulation, and the number of total vertices in the simulation. This provides clear and concrete guidance on what specific information should be included in the paper. The authors know exactly what details to provide to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"different simulators\" and \"parameters,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what details should be included, such as whether the GPU or CPU pipeline was used, the substeps for physics simulation, and the number of total vertices in the simulation. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including details about the parameters used in different simulators, such as whether the GPU or CPU pipeline was used, the substeps for physics simulation, and the number of total vertices in the simulation. This is a request for additional information to support the claims made in the paper, rather than a subjective opinion or judgment. It does not contain any claims or suggestions that require verification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include details about the parameters used in different simulators, such as whether the GPU or CPU pipeline was used, the substeps for physics simulation, and the number of total vertices in the simulation. This request is clear and directly addresses a potential area for improvement in the paper, which could enhance the transparency and reproducibility of the results. By following this advice, the authors can provide more detailed information that would benefit readers and reviewers. Therefore, the comment is 4, as it offers a concrete suggestion for enhancing the draft, but it could be more comprehensive by explaining why these details are important or how they might impact the results. Overall, the feedback is valuable and actionable, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a critical issue with the choice of hyperparameters $s$ and $k$ in the proposed sparseCL and kNL loss function. It notes that these hyperparameters are crucial for the effectiveness of the method but are only empirically selected based on crossvalidation, which limits the generalizability of the loss function. The comment suggests that the authors should provide a more rigorous justification for the choice of $s$ and $k$ or explore alternative methods for selecting these hyperparameters. While the comment identifies a specific issue and suggests a potential solution, it does not provide explicit instructions on how to implement the suggested changes. The action is mostly implicit but concrete, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Supplementary Material A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the choice of hyperparameters $s$ and $k$, noting that their empirical selection based on crossvalidation reduces the generalizability of the proposed loss function. The comment provides a clear direction for improvement by suggesting a more rigorous justification for the choice of these hyperparameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the choice of hyperparameters $s$ and $k$ is crucial for the effectiveness of the proposed method but is only empirically selected based on crossvalidation, which limits the generalizability of the loss function. The comment provides a logical reasoning by explaining how the empirical selection affects the generalizability of the method. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional evidence or justification to fully understand the impact of this choice on the method\"s effectiveness. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the choice of hyperparameters $s$ and $k$ in the proposed sparseCL and kNL loss function. It highlights that these hyperparameters are crucial for the effectiveness of the method but are only empirically selected based on crossvalidation, which limits the generalizability of the loss function. This feedback is clear and actionable, as it prompts the authors to provide a more rigorous justification for the choice of $s$ and $k$ or explore alternative methods for selecting these hyperparameters. By addressing this feedback, the authors can enhance the robustness and applicability of their method. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare the optimization times of using only simulated annealing with OpenTuner, which can adaptively use different search techniques. This is an explicit request for additional analysis or experimentation, providing a clear action for the authors to take. The comment is specific in its suggestion, offering a concrete way to improve the draft by comparing optimization times. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OpenTuner,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing optimization times between using only simulated annealing and OpenTuner, which can adaptively use different search techniques. This provides clear guidance on what the authors should address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should compare the optimization times of using only simulated annealing with OpenTuner, which can adaptively use different search techniques. This is a request for additional analysis or experimentation, but it does not contain a claim or opinion that requires verification. It is a suggestion for improvement, which is consistent with the \"No\" label.", "helpfulness_rationale": "The review comment suggests a specific area for improvement by asking the authors to compare the optimization times of using only simulated annealing with OpenTuner, which can adaptively use different search techniques. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their draft by conducting additional analysis. However, the comment could be more helpful if it offered guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the work, noting that it is not original in introducing a diffusion model to the anomaly detection area. It mentions specific works that have already explored this concept and highlights that the current work only makes minor adjustments to the NCSN model. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue of limited novelty or improve their work. Without actionable suggestions or a clear path forward, the authors are left without direction on how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the work by pointing out that it is not original in introducing a diffusion model to the anomaly detection area. It mentions specific works that have already explored this concept, providing examples such as 1, 2, and 3. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs revision. While the authors might infer that it relates to the introduction or discussion of novelty, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the lack of originality and the minor adjustments made to the NCSN model, but without explicit grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the work lacks novelty, specifically mentioning that it is not original in introducing a diffusion model to the anomaly detection area. The reviewer supports this claim by referencing specific works that have already explored this concept, such as 1, 2, and 3. This provides a clear basis for the claim, as it highlights that the current work is not entirely novel. However, the comment could be strengthened by providing more detailed comparisons or examples of how the current work differs from these previous studies. Overall, the claim is 4 due to the references provided, but it could be more robust with additional context or analysis. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment critiques the novelty of the work, noting that it is not original in introducing a diffusion model to the anomaly detection area. It references specific works that have already explored this concept, such as 1, 2, and 3, and points out that the current work only makes minor adjustments to the NCSN model. While the comment identifies a potential weakness in the work, it lacks actionable suggestions or guidance on how the authors might address this issue or enhance the originality of their contribution. The feedback is 3 as it highlights a concern, but it does not provide specific advice or direction for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two specific issues: grammar errors and unlabeled axes in Figure 2. The comment explicitly identifies these problems, providing clear actions for the authors to take. The authors know exactly what needs to be corrected, such as fixing grammar errors and labeling the axes in Figure 2. This level of detail makes the actions concrete and direct, ensuring the authors can effectively address the issues. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific examples of grammar errors, such as \"The teacher and the student are jointly trained to make the teacher\u2019s knowledge more friendly to the students called online distillation\" and \"Our approach achieves better parameterefficient and studentfriendly KD.\" It also addresses a specific issue with Figure 2, noting that the axes are not labeled. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issues with grammar and the need for labeled axes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about grammar errors and unlabeled axes in Figure 2. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues: grammar errors and unlabeled axes in Figure 2. It provides concrete examples of grammar errors, which is helpful for the authors to address. The mention of unlabeled axes in Figure 2 is also actionable, as it directs the authors to improve the clarity and accessibility of their figures. However, the comment could be more helpful if it offered suggestions on how to correct the grammar errors or provided guidance on labeling the axes. Despite this, the feedback is 4 as it highlights clear areas for improvement that the authors can address to enhance the quality of their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the error analysis in Section 5.2 is \"crappy\" and suggests that a more quantitative error analysis would be beneficial. This provides a clear and direct action for the authors to take, which is to improve the error analysis in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be done to enhance the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the error analysis, stating that it is \"crappy\" and suggesting that a more quantitative approach would be beneficial. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the error analysis in Section 5.2 is \"crappy\" and suggests that a more quantitative error analysis would be beneficial. However, the comment does not provide any specific examples, reasoning, or references to support why the current error analysis is inadequate or how a more quantitative approach would improve it. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the error analysis in Section 5.2, describing it as \"crappy\" and suggesting that a more quantitative approach would be beneficial. This feedback is clear and actionable, as it provides a direct suggestion for improvement that the authors can address to enhance the quality of their analysis. However, the comment could be more helpful if it offered specific guidance on how to implement a more quantitative error analysis or provided examples of what such an analysis might entail. Despite this, the comment is 4 as it directs the authors to a critical area that needs attention, making it a valuable input for improving the draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should not rely solely on tSNE to evaluate distribution alignment and recommends measuring the ProxyA distance between the distributions. It also mentions a potential issue with Figure 6c and 6d, suggesting that they might be identical and that the ProxyA distance should be close to zero. While the comment implies that the authors should consider additional methods for evaluation and check the figures, it does not provide explicit instructions on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer that they should measure the ProxyA distance and check the figures for consistency. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 6c, 6d,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should not rely solely on tSNE for evaluating distribution alignment and recommends measuring the ProxyA distance between the distributions. Additionally, it points out a potential issue with the figures, suggesting that they might be identical and that the ProxyA distance should be close to zero. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point suggests that tSNE should not be the sole method for evaluating distribution alignment and recommends measuring the ProxyA distance between distributions. The comment provides a specific suggestion for an alternative method, which is a clear and logical recommendation. However, it does not provide detailed reasoning or examples to fully substantiate why the ProxyA distance is a better choice or how it would improve the evaluation. While the suggestion is 4, the lack of detailed justification or examples makes it somewhat challenging for the authors to fully understand and implement the recommendation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the evaluation of distribution alignment in the paper. It recommends using the ProxyA distance as an additional method to complement tSNE, which is a common approach for evaluating distribution alignment. This feedback is actionable and offers a concrete alternative to enhance the robustness of the evaluation. Additionally, the comment points out a potential issue with Figure 6c and 6d, suggesting that they might be identical, and advises the authors to check the ProxyA distance. This additional observation could help the authors identify and address potential errors in their analysis. Overall, the comment is clear, actionable, and provides valuable insights for improving the draft, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the rationale behind using cross entropy for the first phrases and suggests evaluating the performance when using a reinforcement algorithm for all phrases. While the comment implies that the authors should provide a rationale for their choice of method and potentially conduct an additional analysis, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the questions or conduct the suggested analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 216217, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the rationale behind using cross entropy for the first phrases and suggests evaluating the performance when using a reinforcement algorithm for all phrases. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification and additional information about the methodology. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the rationale behind using cross entropy for the first phrases and suggests evaluating the performance when using a reinforcement algorithm for all phrases. This feedback is 3 as it prompts the authors to provide a justification for their methodological choices and encourages them to explore alternative approaches. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address these questions or conduct the suggested analysis. While it points out areas for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the proposed crossmodality adaptation has been validated in two specific works, BEVDepth 1 and 2DPASS 2, but the paper does not discuss these works in the related work section. This feedback implies that the authors should include a discussion of these works in the related work section to provide context and relevance to their proposed method. However, the comment does not explicitly instruct the authors to do so, leaving the action implicit. Additionally, while the authors can infer the need to include these references, the comment lacks concrete guidance on how to integrate them into the related work section. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed crossmodality adaptation\" and references specific works, \"BEVDepth 1\" and \"2DPASS 2,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of discussion of these works in the related work section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed crossmodality adaptation has been validated in specific works, BEVDepth 1 and 2DPASS 2, but the paper does not discuss these works in the related work section. This claim is 3 as it provides references to specific works that could be included in the related work section. However, the comment lacks detailed reasoning or examples of how these works relate to the paper\"s contributions, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, noting that the proposed crossmodality adaptation has been validated in two specific works, BEVDepth 1 and 2DPASS 2, but these works are not discussed in the related work section. This feedback is clear and actionable, as it directs the authors to include a discussion of these works in the related work section to provide context and relevance to their proposed method. However, the comment could be more helpful if it offered suggestions on how to integrate these references or explained their significance to the paper. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with Table 1, noting that it only presents test loss as a metric for performance degradation and lacks generation results such as BLEU scores to assess the quality of output. This feedback provides a clear and direct action for the authors to take, which is to include generation results like BLEU scores in Table 1 to provide a more comprehensive assessment of performance. The comment is explicit and concrete, giving the authors precise guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the table, which is the lack of inclusion of generation results such as BLEU scores to assess the quality of output. This provides clear guidance on what needs to be addressed to improve the table. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 1 only presents test loss as a metric for performance degradation, without including generation results such as BLEU scores to assess the quality of output. This is a valid observation, as the comment highlights a specific aspect of the table that could be improved by including additional metrics. However, the comment does not provide any reasoning or evidence to support why including BLEU scores would be beneficial or how it would enhance the assessment of performance degradation. Without additional context or justification, the claim remains 3, as it points out a potential improvement but lacks detailed explanation or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it only presents test loss as a metric for performance degradation and lacks generation results such as BLEU scores to assess the quality of output. This feedback is clear and actionable, as it highlights a gap in the evaluation metrics used in the table, which could be addressed by including additional metrics like BLEU scores. By pointing out this omission, the comment provides the authors with a concrete suggestion for improving the comprehensiveness and quality of their evaluation. However, it could be more helpful if it offered guidance on how to interpret or present these additional metrics. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include experiments to validate the analysis, particularly for discussions on different regimes. While the comment implies that the authors should conduct experiments, it does not provide specific guidance on what kind of experiments should be performed or how they should be designed. The action is implicit and somewhat vague, as the authors need to infer the type of experiments needed and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that including experiments to validate the analysis, particularly for discussions on different regimes, would be appreciated. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or discussion. The authors can infer that it relates to the theoretical analysis, but without explicit references, it is weakly grounded. The comment is specific in suggesting the inclusion of experiments, but it lacks grounding due to the absence of explicit references. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including experiments to validate the analysis, particularly for discussions on different regimes, would be appreciated. However, the comment does not provide any specific reasoning, examples, or references to support why this is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that, despite being a theory paper, including experiments to validate the analysis, particularly for discussions on different regimes, would be appreciated. This feedback is 3 as it identifies a potential area for improvement by suggesting a way to enhance the paper\"s credibility and relevance. However, the comment lacks specificity and does not provide detailed guidance on what kind of experiments should be conducted or how they should be designed. While it points out a direction for improvement, it does not offer actionable steps or detailed suggestions, leaving the authors with a general idea but limited guidance on execution. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. While the comment explicitly states the action of including these baselines, it does not provide specific guidance on how to implement them or what specific insights might be gained from them. The authors are left with a clear direction but without detailed instructions on how to execute the suggestion. Therefore, the comment is 3, as it provides an explicit action but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. Without explicit references to sections or figures, the authors cannot confidently determine where to incorporate this suggestion. The comment is specific in its request for additional baselines but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. However, the comment does not provide any reasoning or evidence to support why these baselines would be beneficial or how they might contribute to the study. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests including two naive baselines with only text and a single center frame to provide insights about the benchmark. This feedback is 3 as it offers a specific suggestion for improving the paper by adding additional baselines. However, the comment lacks depth and does not explain why these baselines would be beneficial or how they might contribute to the study. It also does not provide guidance on how to implement these baselines or what specific insights they might offer. While the suggestion is actionable, the lack of detailed explanation or context limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that while each part of the proposed method is effective, the overall algorithm is cumbersome due to its multiple stages. It contrasts this with existing pruning methods that do not require finetuning. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the overall algorithm. There is no direct action for the authors to take, and the feedback lacks concrete details on how to simplify the algorithm or make it more efficient. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the overall algorithm of the proposed method, noting its complexity due to multiple stages and contrasting it with existing pruning methods that do not require finetuning. However, it does not specify which part of the paper discusses the proposed method or its stages, making it difficult for the authors to pinpoint the exact sections that need attention. The comment lacks specificity as it does not provide detailed feedback on how to simplify the algorithm or improve its efficiency. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that while each part of the proposed method is effective, the overall algorithm is cumbersome due to its multiple stages. It contrasts this with existing pruning methods that do not require finetuning. However, the comment lacks specific examples or references to existing pruning methods that are more efficient, making it difficult for the authors to understand the basis of the comparison. The lack of detailed evidence or examples makes the claim 3, as it provides a general observation but requires more substantiation to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, noting that while each part is effective, the overall algorithm is cumbersome due to its multiple stages. It contrasts this with existing pruning methods that do not require finetuning. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might simplify the algorithm or improve its efficiency. Without detailed feedback or examples, the authors are left with a general observation but no clear path for improvement. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the advantage of the new quantile function (3) compared to the existing function (2) is not adequately justified. It highlights that the new function changes the multiplicative factors containing the up and down tail parameters into an additive term, which makes the function less sensitive to the tail parameters when they are large. However, the comment notes that the paper lacks supporting data on why this reduced sensitivity is desired. While the comment identifies a specific issue with the justification of the new function, it does not provide explicit guidance on how the authors should address this gap. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide supporting data or further explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the new quantile function (3) and the existing function (2), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the advantage of the new function over the existing one is not adequately justified. The comment details the specific change in the function, noting that the multiplicative factors containing the up and down tail parameters are changed to an additive term, and highlights the lack of supporting data on why this reduced sensitivity is desired. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the advantage of the new quantile function (3) compared to the existing function (2) is not adequately justified. It provides a specific critique by explaining that the new function changes the multiplicative factors containing the up and down tail parameters into an additive term, which reduces sensitivity to the tail parameters when they are large. However, the comment notes that the paper lacks supporting data on why this reduced sensitivity is desired. While the reasoning is clear, the absence of supporting data or references makes the claim 3. The authors would need to provide additional evidence or explanation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the justification of the advantage of the new quantile function (3) compared to the existing function (2). It points out that the change from multiplicative factors to an additive term reduces sensitivity to the tail parameters when they are large, but the paper lacks supporting data on why this reduced sensitivity is desired. This feedback is 3 as it highlights a gap in the paper\"s justification and suggests that the authors need to provide evidence or reasoning to support their claim. However, the comment could be more helpful if it offered specific suggestions on how to present this evidence or what kind of data would be most relevant. Overall, the comment provides a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that Figure 3 is confusing and suggests improving the contribution section regarding the benchmark. It provides specific feedback by pointing out that the contribution over SWEBench is low and that the authors\" claims about testing fault localization and LLM\"s capability of discovering issues are not supported. The reviewer offers concrete reasoning and examples to support their critique, such as explaining that if a model can fix a bug, it implicitly tests fault localization capabilities, and that passing a failed unit test to an LLM via scripts does not require LLM for issue generation. This feedback provides clear guidance on what needs to be addressed and how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the contribution section and provides clear reasoning and examples to support the critique. The comment specifies what needs to be improved, such as the low contribution over SWEBench and the claims about testing fault localization and LLM\"s capability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is confusing and that the contribution over SWEBench is low. It provides a detailed critique of the authors\" claims about testing fault localization and LLM\"s capability of discovering issues, offering logical reasoning and examples to support the claim. The reviewer explains that if a model can fix a bug, it implicitly tests fault localization capabilities, and that passing a failed unit test to an LLM via scripts does not require LLM for issue generation. This level of detail and reasoning makes the claim 4, as it provides a clear basis for the critique but could be further strengthened with specific references or examples. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying a confusion in Figure 3 and suggesting improvements to the contribution section. It critiques the authors\" claims about testing fault localization and LLM\"s capability of discovering issues, offering logical reasoning and examples to support the critique. The reviewer points out that if a model can fix a bug, it implicitly tests fault localization capabilities, and that passing a failed unit test to an LLM via scripts does not require LLM for issue generation. This feedback is clear and constructive, guiding the authors on how to enhance their draft by addressing the confusion and strengthening their claims. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing description regarding the selection of topics for complementary attributes in topic control experiments. It explicitly asks for clarification on how to select these topics, providing a clear and direct action for the authors to take. The comment is specific and provides a concrete step for the authors to follow, ensuring they know exactly what needs to be addressed in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights a specific issue with the description of topic control experiments, noting that some key descriptions are missing. It specifically mentions the selection of topics for complementary attributes, which provides clear guidance on what needs to be addressed. However, the comment does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about missing key descriptions in the paper, specifically regarding the selection of topics for complementary attributes in topic control experiments. However, it does not provide any supporting evidence, reasoning, or examples to justify why these descriptions are crucial or how their absence impacts the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely the description of topic control experiments. It highlights a gap in the explanation of how to select topics for complementary attributes, which is a critical aspect of the methodology. By pointing out this omission, the comment provides the authors with a clear direction for improvement, suggesting that they need to clarify this aspect of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how similar experiments have been described in other papers. Despite this, the feedback is actionable and guides the authors toward enhancing the comprehensiveness of their draft. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the limited scope of the realworld manipulation case, suggesting that it may not be sufficient to demonstrate the effectiveness of the system identification method for simtoreal policy deployment. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this concern or improve the study\"s generalizability. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of the limited scope of the realworld manipulation case, suggesting that it may not be sufficient to demonstrate the effectiveness of the system identification method for simtoreal policy deployment. However, it does not specify which part of the paper this critique is based on, such as a particular section or experiment. Without explicit references, the authors cannot confidently determine the exact part of the paper being discussed. Additionally, the comment lacks specificity regarding what improvements or changes are needed to address this concern. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the realworld manipulation case is insufficient to demonstrate the effectiveness of the system identification method for simtoreal policy deployment. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to other studies or methods that could support the claim, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the study\"s scope, specifically noting that the realworld manipulation case is limited to a single instance. It suggests that this may not be sufficient to demonstrate the effectiveness of the system identification method for simtoreal policy deployment. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or expand their study to include more diverse realworld scenarios. Without detailed feedback or recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment raises concerns about the quality of the ShortcutQA and suggests that the edits might introduce ambiguity, leading to performance degradation. It explicitly asks for details about the \"answerable\" distracted texts and requests examples and qualitative results. These requests are clear and direct, providing the authors with specific actions to take to address the reviewer\"s concerns. The comment is 5 as it offers concrete steps for the authors to follow, ensuring they know exactly what is needed to improve their draft.", "grounding_specificity_rationale": "The comment raises concerns about the quality of the ShortcutQA and suggests that the edits might introduce ambiguity, leading to performance degradation. It explicitly asks for details about the \"answerable\" distracted texts and requests examples and qualitative results. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion or results section where the ShortcutQA is presented. The request for details and examples provides clear guidance on what needs to be addressed, making the comment specific. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the quality of the ShortcutQA, specifically questioning whether the edits introduce ambiguity that could lead to performance degradation. The reviewer provides a logical reasoning by pointing out that the edits are manually verified to not change semantics, but this does not guarantee that they do not introduce ambiguity. The comment requests specific details, examples, and qualitative results to support the claim. While the reasoning is sound, the lack of specific examples or references makes the claim 3, as the authors need to provide additional evidence to fully substantiate the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the quality of the ShortcutQA, specifically questioning whether the edits introduce ambiguity that could lead to performance degradation. It provides a logical reasoning by pointing out that while the edits are manually verified to not change semantics, they may still introduce ambiguity. The comment is actionable as it requests specific details, examples, and qualitative results to support the claim. This feedback is clear and constructive, offering the authors a clear path to address the reviewer\"s concerns and improve the robustness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the text would be clearer if it included a forward pointer to the definition of \"deep.\" However, it does not provide explicit instructions on where or how to insert this pointer, leaving the authors to infer that they should add a reference to the definition of \"deep\" in the text. The action is implicit and somewhat vague, as the authors are not given specific guidance on where to place the pointer or how to integrate it seamlessly into the text. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"41,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that a forward pointer to the definition of \"deep\" would make the text clearer. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the text would be clearer with a forward pointer to the definition of \"deep.\" However, it does not provide any reasoning or evidence to support why this would improve clarity or how it would benefit the reader. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the text would be clearer if it included a forward pointer to the definition of \"deep.\" While this feedback identifies a specific area for improvement, it lacks depth and does not provide detailed guidance on how to implement this suggestion or why it would enhance the clarity of the text. The authors are given a general direction but are left without concrete steps to take, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the practical significance of the number of archetypes (k) in the presented framework and suggests that model selection could be used to identify an appropriate k. While the comment implies that the authors should consider model selection for k, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should explore model selection for k. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the practical significance of the number of archetypes (k) in the presented framework and suggests that model selection could be used to identify an appropriate k. However, it does not specify which part of the paper this question pertains to, such as a specific section or methodology discussion. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper being addressed. The comment is specific in its suggestion about model selection, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification on the practical significance of the number of archetypes (k) in the presented framework and whether model selection could be used to identify an appropriate k. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the practical significance of the number of archetypes (k) in the presented framework. It suggests that model selection could be used to identify an appropriate k, which is a valuable consideration for the authors to explore. However, the comment lacks depth and does not provide specific guidance or suggestions on how to implement model selection or what criteria to consider when selecting k. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, as it provides some insight but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly points out the absence of Theorem 1 and suggests that the authors should keep separate counts between assumptions, lemmas, and theorems. This feedback provides a clear and direct action for the authors to take, which is to insert Theorem 1 where it is missing. The comment is specific and actionable, as it guides the authors on what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of Theorem 1 and suggesting that the authors should keep separate counts between assumptions, lemmas, and theorems. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the absence of Theorem 1 and the need to keep separate counts between assumptions, lemmas, and theorems. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it points out a specific issue with the organization of the paper, namely the absence of Theorem 1 and the need to keep separate counts between assumptions, lemmas, and theorems. This feedback is actionable, as it directs the authors to correct the omission of Theorem 1 and to ensure proper categorization of theorems, assumptions, and lemmas. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively present these elements in the paper. Overall, the feedback is clear and actionable, but it lacks depth and comprehensive guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption that a shorter subsequence within a longer text is necessary and sufficient for performing a target task, particularly in the context of QA and long document summarization. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern, whether it should be tested, or how it might impact the methodology or results. Without any actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the assumption that a shorter subsequence within a longer text is necessary and sufficient for performing a target task, particularly in the context of QA and long document summarization. However, it does not specify which part of the paper this assumption is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the assumption but lacks grounding as it does not reference a particular part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the assumption that a shorter subsequence within a longer text is necessary and sufficient for performing a target task, particularly in the context of QA and long document summarization. The comment questions the generalizability of this assumption, suggesting that it may not hold for tasks like long document summarization. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the assumption that a shorter subsequence within a longer text is necessary and sufficient for performing a target task, particularly in the context of QA and long document summarization. This is a valid point that challenges the generalizability of the approach and prompts the authors to consider its applicability to other tasks. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or explore alternative approaches. While it identifies a potential weakness, it lacks actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the clarity of the proposed method and its novelty, specifically questioning how multiple different graphs can be obtained and whether learning different weights for edges would result in too many parameters. While the comment highlights areas of confusion, it does not provide explicit guidance or suggestions on how the authors might address these issues. The feedback is implicit and somewhat vague, as it lacks concrete steps or actions for the authors to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of the proposed method and its novelty, specifically questioning how multiple different graphs can be obtained and whether learning different weights for edges would result in too many parameters. However, it does not specify which part of the paper these concerns relate to, such as a particular section, figure, or equation. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas needing revision. The comment is specific in detailing the issues with clarity and novelty, but without clear grounding, it aligns with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method is straightforward and lacks novelty, and it questions the clarity of certain aspects, such as how multiple different graphs can be obtained and whether learning different weights for edges would result in too many parameters. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of evidence or detailed explanation makes the claim 1, as the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises concerns about the clarity and novelty of the proposed method, specifically questioning how multiple different graphs can be obtained and whether learning different weights for edges would result in too many parameters. While it identifies areas of confusion, it does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their work. The comment highlights potential weaknesses but lacks actionable feedback, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the experiments are limited in scope, with only two simulation experiments on a unit sphere and spiral curves, and a third example using time of travel by taxis. The reviewer suggests that it would be beneficial to include an example of learning geometry on a more complicated manifold. While the comment implies that the authors should expand their experiments to include a more complex scenario, it does not provide specific guidance on how to achieve this or what specific aspects of the geometry should be explored. The action is implicit and somewhat vague, as the authors are left to infer the details of what needs to be done. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, including the simulation experiments on a unit sphere and spiral curves, and the example using time of travel by taxis. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it points out the limitation of the experiments in scope and suggests that it would be beneficial to include an example of learning geometry on a more complicated manifold. This provides clear guidance on what the authors could do to improve their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited in scope, specifically mentioning the use of a unit sphere and spiral curves as examples. The reviewer suggests that it would be beneficial to include an example of learning geometry on a more complicated manifold. While the comment provides a logical reasoning for the limitation, it lacks specific examples or references to support the claim that a more complex manifold would be beneficial. This makes the claim 3, as it provides a direction for improvement but lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the experiments, specifically noting that they are limited to two simulation experiments on a unit sphere and spiral curves, and a third example using time of travel by taxis. The reviewer suggests that it would be beneficial to include an example of learning geometry on a more complicated manifold. This feedback is clear and actionable, as it provides a specific suggestion for expanding the scope of the experiments to include a more complex scenario. However, the comment could be more helpful if it offered additional guidance on how to select or design such a scenario or what specific aspects of geometry should be explored. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the authors\" previous mention of the specific template\"s limitations in terms of naturalness and the underutilization of the LLM\"s capabilities. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address these weaknesses or suggestions for improvement. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment acknowledges the authors\" previous mention of the specific template\"s limitations in terms of naturalness and the underutilization of the LLM\"s capabilities. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in identifying the weakness of the current knowledge relying on the specific template, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the authors\" previous mention of the specific template\"s limitations in terms of naturalness and the underutilization of the LLM\"s capabilities. However, it does not provide any additional reasoning, evidence, or examples to support the claim that this is an \"obvious weakness\" for the paper. Without further elaboration or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the authors\" previous mention of the specific template\"s limitations in terms of naturalness and the underutilization of the LLM\"s capabilities. However, it does not provide any actionable feedback or suggestions for improvement. The comment merely restates the issue without offering guidance on how the authors might address these weaknesses or enhance their work. As a result, the comment lacks depth and does not assist the authors in making meaningful improvements to their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point notes that the number of baselines is small, which affects the universality and generality of the study. However, it does not provide any explicit or implicit suggestions on how to address this issue. The authors are left without guidance on what steps to take to improve the number of baselines or how to enhance the universality and generality of their study. Without actionable advice or concrete steps, the comment lacks utility for the authors in terms of improving their draft. Therefore, it is rated as 1.", "grounding_specificity_rationale": "The comment mentions the number of baselines, which implies that it relates to the methodology or results section. However, it does not specify which part of the paper discusses the baselines, making it weakly grounded. The comment is specific in pointing out the issue with the number of baselines and its impact on universality and generality. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the number of baselines is small, which affects the universality and generality of the study. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why a larger number of baselines would enhance universality and generality. Without specific details or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential limitation in the number of baselines used in the study, suggesting that this could impact the universality and generality of the findings. However, it does not provide specific suggestions or guidance on how to address this issue, such as recommending additional baselines or discussing the implications of the current number of baselines. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of information about the tokenizer training, specifically mentioning the mixture of corpus size used and the software stack, which are known to matter in practice. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or what specific information should be included. The authors can infer that they need to provide details about the tokenizer training, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment highlights the absence of information about the tokenizer training, specifically mentioning the mixture of corpus size used and the software stack, which are known to matter in practice. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or experimental setup, but the lack of explicit grounding makes it difficult to pinpoint the exact location. The comment is specific in detailing what information is missing, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no information about the tokenizer training, specifically mentioning the mixture of corpus size used and the software stack, which are known to matter in practice. The reviewer provides a reference to external work 4, which supports the claim that these factors are important. However, the comment could be strengthened by providing more detailed information or examples from the referenced work to fully substantiate the claim. Overall, the comment is 4, as it provides a logical basis for the claim but lacks specific details or examples from the referenced work. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper regarding the lack of information about the tokenizer training, specifically mentioning the mixture of corpus size used and the software stack, which are known to matter in practice. This feedback is clear and actionable, as it directs the authors to include this information to enhance the comprehensiveness and rigor of their study. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific metrics or methods to evaluate the tokenizer training. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of the additional complexity introduced by the proposed positive mining framework compared to a simple multiview contrastive objective. It suggests that the paper does not answer whether this additional complexity is warranted. While the comment implies that the authors should address this question, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as it lacks concrete steps or suggestions for the authors to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"positive mining framework\" and \"cotraining, positive mining, and alternate optimization steps,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the necessity of the additional complexity introduced by the proposed method compared to simpler approaches. However, the comment does not provide specific suggestions or examples on how to address this issue, making it specific but not fully grounded. Therefore, this comment aligns with a score of 4.", "verifiability_rationale": "The review point raises a question about the necessity of the additional complexity introduced by the proposed positive mining framework compared to simpler approaches. It suggests that the paper does not answer whether this additional complexity is warranted. However, the comment does not provide specific examples, reasoning, or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence makes the claim 3, as it requires more information to fully substantiate the critique.", "helpfulness_rationale": "The review comment raises a critical question about the necessity of the additional complexity introduced by the proposed positive mining framework compared to simpler approaches. It highlights a gap in the paper, noting that it does not address whether the added complexity is warranted. This feedback is 3 as it points out a potential weakness in the paper and prompts the authors to consider whether their contributions are necessary. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue or evaluate the added complexity. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the approach regarding computational complexity and scalability for large datasets, suggesting that a more comprehensive discussion is needed. While the comment identifies an area for improvement, it does not provide specific guidance on how to address this issue or what aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss the computational complexity and scalability in more detail. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the computational cost and scalability of the multimarginal OT and spline calculations, suggesting that a more comprehensive discussion is needed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a more detailed discussion on computational complexity and scalability, which could be problematic for realworld applications. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the computational complexity of multimarginal OT and spline calculations may limit the scalability of the approach for large datasets, which could be problematic for realworld applications. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed approach, specifically the computational complexity and scalability issues that could arise with multimarginal OT and spline calculations. It suggests that a more comprehensive discussion is needed to address these concerns, which could be problematic for realworld applications. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how the authors might address these issues or what aspects of the discussion should be expanded. The feedback is 3 as it points out a critical area for consideration, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point challenges the authors\" claim that nonuniform label noise is not common in practice, citing a specific example from the realworld dataset Clothing1M. It provides a reference to a study by Kun Yi and Jianxin Wu that verifies the existence of nonuniform label noise in this dataset. This comment is explicit in its action, as it directs the authors to reconsider their claim and potentially revise their statement based on the evidence provided. The reference to a specific study adds concrete detail on how to address the issue, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about nonuniform label noise not being common in practice, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a reference to a realworld dataset, Clothing1M, where nonuniform label noise has been verified, and it cites a specific study by Kun Yi and Jianxin Wu. This provides clear guidance on what needs to be addressed in the paper, making the comment 5.", "verifiability_rationale": "The review point challenges the authors\" claim that nonuniform label noise is not common in practice by citing a specific example from the realworld dataset Clothing1M. It references a study by Kun Yi and Jianxin Wu that verifies the existence of nonuniform label noise in this dataset. This provides a clear and specific reference to support the claim, making it 5. The inclusion of a reference to a published study adds robustness to the claim, ensuring that the authors can easily verify the validity of the critique.", "helpfulness_rationale": "The review comment challenges the authors\" claim that nonuniform label noise is not common in practice by citing a specific example from the realworld dataset Clothing1M. It references a study by Kun Yi and Jianxin Wu that verifies the existence of nonuniform label noise in this dataset. This feedback is 5 as it provides a concrete example and reference that the authors can use to reconsider their claim and potentially revise their statement. By offering a specific dataset and a reference to a relevant study, the comment empowers the authors to make a more accurate and evidencebased claim in their paper. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the limited sample size used in Section 6.2, suggesting that it may have resulted in biased findings. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as recommending additional samples or providing a rationale for the chosen sample size. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 6.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the limited sample size used in the evaluation, which may have resulted in biased findings due to the small scale of the experiment. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in Section 6.2 is based on only 10 samples, which may lead to biased findings due to the small sample size. However, the comment does not provide any supporting evidence, such as comparisons with larger sample sizes or references to studies that highlight the potential impact of small sample sizes on results. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the limited sample size used in the evaluation, specifically in Section 6.2. It points out that this may have resulted in biased findings due to the small scale of the experiment. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional samples or providing a rationale for the chosen sample size. Without actionable advice, the authors are left with a general understanding of the problem but without a clear path to resolution. Therefore, the comment is 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the method, noting that it is tailored to similar MILP tasks and may not be generalizable to significantly different combinatorial optimization problems. The comment acknowledges that the paper addresses this issue but does not provide experimental evidence to support the claim. While the comment identifies a concern, it lacks explicit guidance or suggestions on how the authors might address this issue or provide experimental evidence to demonstrate generalizability. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct experiments to demonstrate generalizability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the method\"s generalizability to different combinatorial optimization problems, acknowledging that the paper acknowledges this limitation but does not address it experimentally. However, it does not specify which part of the paper discusses this limitation or where the authors should provide experimental evidence to address it. The authors can infer that it relates to the experimental section, but the comment lacks full grounding as it does not explicitly mention a specific section or experiment. Additionally, while it identifies a potential issue, it does not provide specific guidance on how to address it, making it underspecific. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the method is tailored to similar MILP tasks, potentially limiting its generalizability to significantly different combinatorial optimization problems. The comment acknowledges that the paper addresses this issue but does not provide experimental evidence to support the claim. While the claim is logical and based on the paper\"s acknowledgment, it lacks specific examples or references to substantiate the limitation. This makes the claim 3, as it requires further elaboration or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a potential limitation of the method, noting that it is tailored to similar MILP tasks and may not be generalizable to significantly different combinatorial optimization problems. The comment acknowledges that the paper addresses this issue but does not provide experimental evidence to support the claim. While it highlights a relevant concern, it lacks specific suggestions or guidance on how the authors might address this limitation or provide experimental evidence to demonstrate generalizability. The feedback is 3 as it points out an area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity in the description of the baseline in the Results section, specifically mentioning lines 256261 (denoted as Rerank and Adv). The reviewer expresses difficulty understanding how these baselines work, how they relate to InterFair, and whether they are sufficiently competitive. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how to address these issues or suggest specific changes to improve clarity. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the description of the baselines and their relationship to InterFair. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section of the paper, \"Results,\" and references lines 256261, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in the description of the baseline, particularly regarding how it relates to InterFair and whether it is sufficiently competitive. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have difficulty understanding how the baselines work and how they relate to InterFair, suggesting that the description in the Results section is insufficient. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence or justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of the baseline in the Results section, noting that the authors attempt to explain it but that the reviewer still struggles to understand how the baselines work, their relationship to InterFair, and whether they are sufficiently competitive. This feedback is 3 as it points out a lack of clarity in the paper, prompting the authors to revise their explanation to ensure that readers can fully grasp the baselines and their relevance. However, the comment could be more helpful if it provided specific suggestions on how to improve the clarity or examples of what additional information would be beneficial. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue with the comparison to other baselines on cycle counting and ZINC, indicating that it is insufficient. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or improve the comparison. There is no suggestion on what additional information or analysis should be included, nor are there any concrete steps for the authors to follow. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the comparison to other baselines on cycle counting and ZINC, indicating that it is insufficient. However, it does not specify which part of the paper this comparison is discussed in, nor does it provide details on what aspects of the comparison are lacking or how it could be improved. Without explicit references to sections or examples, the authors cannot confidently determine which part of the paper needs attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison to other baselines on cycle counting and ZINC, suggesting that it is insufficient. However, it does not provide any further details or suggestions on how the authors might improve this comparison or what additional information or analysis could be included. Without actionable guidance or specific feedback, the authors are left without a clear understanding of how to address the issue. Therefore, the comment is 2, as it highlights a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. This feedback implies that the authors should provide a rationale for the effectiveness of the chosen combination, which is an explicit action. However, the comment does not specify how to present this explanation or what specific aspects should be included in the explanation. While the action is explicit, it lacks concrete guidance on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment. Without explicit references, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. The comment is specific in its request for an explanation but lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. This claim is 3 as it highlights a potential gap in the paper\"s explanation. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Providing more detailed reasoning or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors provide a clear explanation of why a particular combination of mask snippets is effective, while most similar ones are not. This feedback is actionable as it directs the authors to a specific aspect of their work that requires further elaboration. However, the comment could be more helpful if it provided examples or specific questions to guide the authors in crafting this explanation. Overall, the comment is 3 as it points out a clear area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point compares the performance of SLQ (quantified by F1 score and conductance values) with previous CRD methods, specifically noting that SLQ shows worse performance in Figure 3 and only a small improvement over ACL in Figure 4. However, the comment does not provide any explicit or implicit suggestions for improvement. It lacks actionable guidance on how the authors might address this issue or improve the performance of SLQ. Without specific recommendations or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the performance of SLQ compared to previous CRD methods, noting that SLQ shows worse performance in Figure 3 and only a small improvement over ACL in Figure 4. This provides clear guidance on what needs to be addressed in terms of performance evaluation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of SLQ (quantified by F1 score and conductance values) appears to have limited competitiveness compared to previous CRD methods. It supports this claim by referencing specific figures (Figure 3 and Figure 4) where SLQ shows worse performance compared to CRD and only a small improvement over ACL. This provides a clear basis for the claim, as it uses visual evidence to substantiate the assertion. However, the comment could be strengthened by providing more detailed analysis or references to specific benchmarks or studies that support the claim. Overall, the claim is 4, as it provides a logical basis but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the performance of SLQ (quantified by F1 score and conductance values) compared to previous CRD methods. It specifically points out that SLQ shows worse performance than CRD in Figure 3 and only a small improvement over ACL in Figure 4. This feedback is clear and actionable, as it highlights a specific area where the authors might need to improve their method\"s performance. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered insights into potential improvements. Despite this, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that requires further attention. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should add more baselines to their selection, specifically encouraging the inclusion of more robust and uptodate models for performance comparisons. This feedback provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and actionable, as it provides a concrete suggestion for enhancing the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the selection of baselines in the paper, specifically noting that it is limited to naive or old models. However, it does not specify which part of the paper discusses the baselines, making it weakly grounded. The comment is specific in suggesting the addition of more baselines for robust performance comparisons, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the selection of baselines is limited to naive or old models, suggesting that more robust baselines should be included for performance comparisons. However, the comment does not provide specific examples of what constitutes \"naive\" or \"old\" models, nor does it reference any external works or studies that support this claim. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the selection of baselines in the paper, noting that it is limited to naive or old models. It provides a clear and actionable suggestion for improvement by encouraging the authors to add more baselines for robust performance comparisons. This feedback is valuable as it directs the authors to enhance the comprehensiveness and rigor of their analysis. However, the comment could be more helpful if it offered specific examples of additional baselines that could be included or provided guidance on how to select them. Overall, the comment is 4 as it effectively points out a weakness and offers a constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment raises a concern about the choice of target structure in Table 2, questioning the generalizability of the proposed method to other target structures with different dimensions. It suggests that the authors should either justify their choice or provide additional experiments to demonstrate the method\"s adaptability. While the comment implies an action, it does not explicitly instruct the authors to conduct additional experiments or provide a justification. The action is somewhat vague, as it does not specify the exact steps the authors should take to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and the specific choice of target structure (2816, 7680, 8), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of target structure and suggests that the authors should either justify their choice or provide additional experiments to demonstrate the method\"s adaptability to different target structures. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of target structure in Table 2, suggesting that the authors should either justify their choice or provide additional experiments to demonstrate the method\"s adaptability to different target structures. The comment logically reasons that the choice of a single target structure limits the generalizability of the proposed method. However, it does not provide specific examples or references to support the claim that other target structures should be considered. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper regarding the choice of target structure in Table 2. It questions the generalizability of the proposed method by pointing out that only one target structure is evaluated, which could limit the applicability of the approach. The comment suggests that the authors should either justify their choice or provide additional experiments to demonstrate the method\"s adaptability to different target structures. This feedback is clear and actionable, as it directs the authors to address a specific concern about the scope and applicability of their work. By following the suggestion, the authors can enhance the robustness and generalizability of their method, making the comment 5. Therefore, it deserves a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the scope of the research, which primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare would increase the paper\"s impact and relevance. While the comment identifies a potential area for expansion, it does not provide explicit guidance on how to incorporate these applications or what specific aspects of healthcare should be considered. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a limitation in the scope of the research, specifically noting that it primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare would increase the paper\"s impact and relevance. However, the comment does not specify which part of the paper discusses the knapsack problem or where the authors should consider expanding to include healthcare applications. While the authors might infer that this relates to the introduction or discussion sections, the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific in terms of the need to explore healthcare applications, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the research primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare would increase the paper\"s impact and relevance. However, the comment lacks specific examples or references to support the claim that medical diagnosis is a more realistic scenario or how it would significantly impact the paper. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the research, which primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare would significantly increase the paper\"s impact and relevance. This feedback is 3 as it points out a potential area for expansion and improvement, encouraging the authors to consider broader applications of their work. However, the comment lacks specific guidance on how to incorporate these applications or what aspects of healthcare should be considered. While it provides a direction for enhancing the paper, it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the method for not improving robustness and sensitivity as claimed in the motivation, specifically noting that the new method is noisier in some domains and equally noisy as competitors in others. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the robustness and sensitivity of their method. The feedback lacks actionable details, such as recommending specific changes or experiments to enhance robustness or sensitivity. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the method for not improving robustness and sensitivity as claimed, specifically mentioning Figure 3. This provides full grounding as it explicitly references a specific figure in the paper, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issue with the method\"s robustness and sensitivity, noting that the new method is noisier in some domains and equally noisy as competitors in others. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method does not improve robustness and sensitivity as claimed in the motivation, specifically noting that the new method is noisier in some domains and equally noisy as competitors in others. This claim is 3 as it provides a specific observation from Figure 3, which supports the assertion that the method may not meet the claimed robustness and sensitivity improvements. However, the comment lacks detailed reasoning or references to specific studies or benchmarks that could further substantiate the claim. Providing more detailed evidence or examples would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the method for not improving robustness and sensitivity as claimed in the motivation, specifically pointing out that the new method is noisier in some domains and equally noisy as competitors in others. This feedback is 3 as it identifies a potential weakness in the paper\"s claims about the method\"s performance. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the robustness and sensitivity of their method. To be more helpful, the comment could include recommendations for further analysis, experiments, or modifications to enhance the method\"s performance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the robustness of the conclusion against more sophisticated or aggressive removal methods. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should test their conclusion against these methods, how they might do so, or what specific aspects of the conclusion need to be reconsidered. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the robustness of the conclusion against more sophisticated or aggressive removal methods. However, it does not specify which part of the paper this question pertains to, such as the conclusion section or a specific experiment. Without explicit references to sections or experiments, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspects of the conclusion need to be reconsidered or how the authors might address this question. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the robustness of the conclusion against more sophisticated or aggressive removal methods. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the robustness of the conclusion against more sophisticated or aggressive removal methods. This is a valid concern that could impact the generalizability and applicability of the findings. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern or test the conclusion against these methods. Without actionable feedback or detailed advice, the authors are left with a general question that does not directly assist them in improving their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the paper regarding the distinction between explainable AI and interpretable methods, as well as the absence of a definition for interpretability. It also notes the absence of work in this line. While the comment identifies specific areas that need clarification or elaboration, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to define interpretability, explain the difference between explainable AI and interpretable methods, and include relevant work in this line. However, the comment lacks concrete guidance on how to implement these changes, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of explanation for the definition of interpretability and the difference between explainable AI and interpretable methods. Additionally, it notes the absence of work in this line. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper introduces explainable AI in the introduction but focuses on interpretable methods, without defining interpretability or explaining the difference between the two concepts. The comment also notes the absence of work in this line. While the claim highlights a lack of clarity and definition, it lacks specific examples or references to support the assertion. The reasoning is somewhat logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is 3, as it provides a basis for the claim but requires additional information for full verification.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it introduces explainable AI in the introduction but focuses on interpretable methods without defining interpretability or explaining the difference between the two concepts. It also points out the absence of work in this line. This feedback is clear and actionable, as it highlights specific areas where the authors need to clarify their terminology and provide context for their work. By addressing these points, the authors can improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered suggestions on how to define interpretability or provided examples of relevant work in this area. Overall, the comment is 4, as it directs the authors to important areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification about the training data used for the probes in the compositionality and transitivity experiments. This is a direct request for information, making the action clear and explicit. The authors know exactly what they need to provide to address this comment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly asks about the training data for probes in the compositionality and transitivity experiments, providing full grounding as it directs the authors to a specific aspect of their work. However, it lacks specificity as it does not detail what is wrong or missing in the training data description. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point is a factual question seeking clarification about the training data used for probes in the compositionality and transitivity experiments. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of concern regarding the training data for probes in the compositionality and transitivity experiments. By asking for clarification on this aspect, the reviewer prompts the authors to provide more detailed information about their methodology. However, the comment lacks depth and does not offer suggestions or guidance on how to address this issue or improve the clarity of the training data description. While it points out a potential area for improvement, it does not provide actionable feedback or detailed advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity regarding the phrase \"not only the complete captions but also parts thereof\" and the argument about why filling in the blanks is hard. It suggests that the authors should clarify this point and notes that there are ways to do bidirectional beam search for fillintheblanks applications, referencing a source C. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to clarify the argument or implement the suggested bidirectional beam search. The action is explicit but somewhat vague, as the authors know what needs to be addressed but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 133134, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the phrase \"not only the complete captions but also parts thereof\" and the argument about why filling in the blanks is hard. Additionally, it provides a suggestion for improvement by noting that there are ways to do bidirectional beam search for fillintheblanks applications, referencing a source C. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the argument about why filling in the blanks is hard is unconvincing and suggests that the authors clarify their reasoning. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The mention of bidirectional beam search as a potential solution is a suggestion rather than a claim, and it lacks detailed reasoning or evidence to substantiate the initial claim. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient support for the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the argument regarding filling in the blanks, particularly the phrase \"not only the complete captions but also parts thereof.\" It questions the logic behind the argument and suggests that the authors should clarify this point. Additionally, the comment provides a constructive suggestion by noting that there are ways to do bidirectional beam search for fillintheblanks applications, referencing a source C. This feedback is clear and actionable, as it directs the authors to improve the clarity of their argument and offers a potential solution. However, the comment could be more helpful if it provided more detailed guidance on how to implement the bidirectional beam search or how to clarify the argument. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of reverse KL for training flows, specifically mentioning the assumption of differentiability of the function g and the modeseeking nature of the reverse KL. It suggests that covering all modes of a density is crucial for most applications in rare event sampling and mentions a recent line of work to overcome this limitation. While the comment highlights potential issues and suggests considering recent work, it does not provide explicit instructions or concrete steps for the authors to address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they should discuss the differentiability assumption and consider the recent work mentioned. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the flows are trained with the reverse KL,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the realism of the differentiability assumption of the function g and the modeseeking nature of the reverse KL, suggesting that covering all modes of a density is crucial for rare event sampling. Additionally, it mentions a recent line of work to overcome this limitation, providing specific references. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the use of reverse KL for training flows, specifically mentioning the assumption of differentiability of the function g and the modeseeking nature of the reverse KL. The reviewer suggests that covering all modes of a density is crucial for most applications in rare event sampling and mentions a recent line of work to overcome this limitation. While the comment provides some reasoning and references a recent line of work, it lacks specific examples or detailed explanations of how the modeseeking nature of the reverse KL affects the application. This makes the claim 3, as the authors would need to further explore and substantiate the concerns raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the use of reverse KL for training flows, specifically questioning the differentiability assumption of the function g and the modeseeking nature of the reverse KL. It suggests that covering all modes of a density is crucial for most applications in rare event sampling and mentions a recent line of work to overcome this limitation. While the comment identifies potential issues and provides a reference to recent work, it lacks specific guidance or actionable suggestions for the authors to address these concerns. The feedback is 3 as it highlights areas for consideration, but it could be more beneficial with additional detail or concrete advice on how to improve the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the annotations in the visual event detection stage of ViStruct Suite, suggesting that they might contain noise due to the use of an offtheshelf semantic role labeling system. The reviewer recommends a detailed analysis of the curated dataset to address this concern. While the comment implies that the authors should conduct a detailed analysis, it does not provide specific guidance on how to perform this analysis or what aspects to focus on. The action is implicit and somewhat vague, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ViStruct Suite,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out potential noise in the annotations due to the use of an offtheshelf semantic role labeling system. The comment suggests that a detailed analysis of the curated dataset is needed to address this issue. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the annotations in the visual event detection stage of ViStruct Suite might contain noise due to the use of an offtheshelf semantic role labeling system. The reviewer suggests that a detailed analysis of the curated dataset is needed to address this issue. However, the comment lacks specific examples or references to support the claim about the potential noise in the annotations. Without detailed evidence or examples, the claim is 3, as it provides a logical reasoning but lacks sufficient support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the annotations in the visual event detection stage of ViStruct Suite, suggesting that they might contain noise due to the use of an offtheshelf semantic role labeling system. The reviewer recommends a detailed analysis of the curated dataset to address this concern. While the comment highlights a specific area for improvement, it does not provide detailed guidance on how to conduct this analysis or what specific aspects to focus on. The feedback is 3 as it points out a potential issue and suggests a direction for further investigation, but it could be more actionable with additional details. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the model implementation should be better justified, specifically mentioning the stopping rule with n consecutive identical samples as arbitrary and lacking discussion on sensitivity with regard to n. While the comment identifies areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The authors are left to infer that they need to provide a more detailed justification for the stopping rule and discuss its sensitivity, but without concrete instructions, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"model implementation\" and the \"stopping rule with n consecutive identical samples,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the arbitrariness of the stopping rule and the lack of discussion on sensitivity with regard to n. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model implementation should be better justified, specifically mentioning the stopping rule with n consecutive identical samples as arbitrary and lacking discussion on sensitivity with regard to n. The comment provides a logical reasoning by questioning the arbitrariness of the stopping rule and suggesting that it lacks behavioral or neural parallels. However, it does not provide specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the model implementation, namely the stopping rule with n consecutive identical samples, which is described as arbitrary and lacking discussion on sensitivity with regard to n. This feedback is clear and actionable, as it points out a potential weakness in the paper and suggests that the authors should provide a more detailed justification for the stopping rule and discuss its sensitivity. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar rules are typically justified in the literature. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide time complexity analysis and running time of the proposed method, which is a clear and direct action. It also suggests comparing the search time of the proposed method with stateoftheart algorithms as the number of nodes increases. These suggestions are concrete and provide specific guidance on how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"maximum common subgraph detection problem\" and the \"proposed algorithms,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the time complexity analysis and running time of the proposed method, as well as the comparison with stateoftheart algorithms. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should provide time complexity analysis and running time for the proposed algorithms, as well as compare the search time of the proposed method with stateoftheart algorithms. The reviewer provides a logical reasoning by pointing out the importance of time complexity analysis, given the mention of the NPhard nature of the problem. However, the comment lacks specific examples or references to support the claim that the proposed method should be compared with stateoftheart algorithms. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of time complexity analysis and running time for the proposed algorithms. It also suggests comparing the search time of the proposed method with stateoftheart algorithms, which could provide valuable insights into the efficiency and scalability of the approach. This feedback is clear and actionable, offering the authors specific areas for improvement that could enhance the comprehensiveness and impact of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the time complexity analysis or suggested specific metrics to consider. Overall, the comment is 4, as it effectively directs the authors to address a critical aspect of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of quality control or manual evaluation on the quality of data collected through an automatic modelbased approach. While it identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment lacks concrete details on what specific actions should be taken to improve the quality control or manual evaluation process. As a result, the authors are left without a clear understanding of how to implement the necessary changes. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of quality control or manual evaluation on the quality of data collected through an automatic modelbased approach. However, it does not specify which part of the paper this issue pertains to, such as a specific section or methodology discussion. Without explicit references, the authors may find it challenging to pinpoint the exact area needing revision. The comment is specific in identifying the absence of quality control or manual evaluation, but it lacks grounding as it does not clearly indicate where in the paper this issue arises. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no quality control or manual evaluation on the quality of data collected through an automatic modelbased approach. This claim is 3 as it highlights a potential issue with the data collection process. However, the comment lacks specific examples or references to support the claim, such as comparing it to similar studies or best practices in the field. Providing more detailed evidence or examples would strengthen the justification for the claim, making it more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the lack of quality control or manual evaluation on the quality of data collected through an automatic modelbased approach. This is a critical issue that could impact the reliability and validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending specific methods for quality control or manual evaluation. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that a confidence interval from a small development set could be compared to the Frechet bound. While it implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the comparison or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"most tasks\" and \"snorkel,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the comparison of a confidence interval from a small development set with the Frechet bound. This provides clear guidance on what the authors should consider for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the availability of labeled data for most tasks and the potential use of a small development set to tune hyperparameters and provide a bound on classifier performance. The reviewer suggests comparing a confidence interval from a small development set with the Frechet bound. While the comment provides a logical reasoning for the comparison, it lacks specific examples or references to support the claim or the suggestion. This makes the claim 3, as the authors would need to further develop the reasoning or provide additional evidence to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting a comparison between a confidence interval from a small development set and the Frechet bound. This suggestion is clear and actionable, as it provides a specific direction for the authors to explore in their analysis. By comparing these two methods, the authors could gain insights into the performance bounds of their classifier, which could enhance the robustness and reliability of their results. However, the comment could be more helpful if it included additional context or examples to guide the authors on how to implement this comparison. Overall, the feedback is 4 as it offers a constructive suggestion for enhancing the paper, but it could be more comprehensive with further elaboration."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation of the proposed method, stating that it is only applicable to problems with lowdimensional input spaces. It also explains the reason for this limitation, which is the curse of dimensionality caused by the use of a finite set of points to cover the region of interest in the surrogate modeling of the shape constraint. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest ways to address this limitation, such as exploring methods to handle higherdimensional input spaces or discussing potential workarounds. Without actionable guidance, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the proposed method, specifically mentioning that it is only applicable to problems with lowdimensional input spaces. It also provides a reason for this limitation, which is the curse of dimensionality caused by the use of a finite set of points to cover the region of interest in the surrogate modeling of the shape constraint. However, the comment does not specify which part of the paper discusses the experiments or the method, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the exact location is not explicitly mentioned. The comment is specific in detailing the limitation and its cause, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the proposed method is only applicable to problems with lowdimensional input spaces, citing the largest dimensionality in the experiments as 3. It provides a logical explanation for this limitation, stating that it is due to the curse of dimensionality caused by the use of a finite set of points to cover the region of interest in the surrogate modeling of the shape constraint. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by referencing specific experiments or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant limitation of the proposed method, specifically that it is only applicable to problems with lowdimensional input spaces. It provides a clear explanation for this limitation, which is the curse of dimensionality caused by the use of a finite set of points to cover the region of interest in the surrogate modeling of the shape constraint. This feedback is valuable as it highlights a critical constraint on the method\"s applicability, allowing the authors to consider potential improvements or modifications to address this limitation. However, the comment could be more helpful if it suggested ways to overcome this limitation or provided examples of how to handle higherdimensional input spaces. Overall, the comment is 4 as it directs the authors\" attention to a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the results presented in Tables 1 and 2, stating that the methods\" results are typically within their standard deviations, which undermines the claim of the presented method being significantly better than others. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their claims, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment refers to specific tables, \"Table 1 and Table 2,\" which provides full grounding as the authors can accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the results are typically within their standard deviations, which challenges the claim of the presented method being significantly better than others. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Tables 1 and 2 are typically within their standard deviations, which undermines the claim of the presented method being significantly better than others. However, the comment does not provide any supporting evidence, such as specific examples or statistical analysis, to substantiate this claim. Without detailed reasoning or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the results presented in Tables 1 and 2, noting that the methods\" results are typically within their standard deviations. This raises a concern about the significance of the presented method being better than others, which is a critical aspect of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their claims. While it highlights a potential weakness, it lacks actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the complexity of generating synthetic tabular data due to several factors, specifically mentioning that multiple entries in a table can be associated with the same entity, resulting in additional relationships. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how to address the complexity or improve the generation process, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment highlights the complexity of generating synthetic tabular data due to several factors, specifically mentioning that multiple entries in a table can be associated with the same entity, resulting in additional relationships. However, it does not specify which part of the paper this issue pertains to, nor does it provide detailed guidance on how to address this complexity. Without explicit references to sections or examples, the authors cannot confidently determine where to focus their efforts. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point makes a claim about the complexity of generating synthetic tabular data, specifically mentioning that multiple entries in a table can be associated with the same entity, resulting in additional relationships. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a specific challenge in generating synthetic tabular data, namely the complexity arising from multiple entries in a table being associated with the same entity. This observation is relevant and could help the authors understand the intricacies of their data generation process. However, the comment lacks actionable suggestions or guidance on how to address this complexity or improve the generation process. Without specific advice or examples, the authors may find it challenging to apply the feedback effectively. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance for action."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the value of the AmbiQT benchmark but raises concerns about its overemphasis without a broader context or validation on other datasets. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider providing a broader context or validating the benchmark on other datasets, but it does not specify how to do so or what specific actions should be taken. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the creation of the AmbiQT benchmark and raises concerns about its overemphasis without a broader context or validation on other datasets. However, it does not specify which part of the paper discusses the benchmark, making it weakly grounded. The comment is specific in pointing out the potential issue of overemphasis and the need for broader context or validation, but it lacks detailed guidance on how to address this concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the value of the AmbiQT benchmark but raises concerns about its overemphasis without a broader context or validation on other datasets. This claim is 3 as it highlights a potential issue with the paper\"s focus on a specific benchmark without considering its applicability to other scenarios. However, the comment lacks specific examples or references to other datasets or benchmarks that could be used for validation, which would strengthen the argument. The authors would need to infer the need for broader context and validation themselves, making the claim 3.", "helpfulness_rationale": "The review comment acknowledges the value of the AmbiQT benchmark but raises a concern about its overemphasis without a broader context or validation on other datasets. This feedback highlights a potential limitation in the paper\"s focus, suggesting that the authors should consider providing a broader context or validating the benchmark on other datasets to enhance its applicability and relevance. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as recommending additional datasets or methods for validation. While it identifies a relevant area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of annotation training details and guidelines, which are important for professional translators working on nonstandard tasks. It also mentions the absence of information about the tool used. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues or what specific details should be included. The action is implicit and somewhat vague, as the authors are left to infer what information should be added and how to present it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of annotation training details and guidelines, which is an important aspect of the paper. However, it does not specify which part of the paper this issue pertains to, such as a specific section or chapter. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being discussed. The comment is specific in detailing what is missing, namely the annotation training details and guidelines, as well as the lack of information about the tool used. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that no annotation training details or guidelines are shared, which is important for professional translators working on nonstandard tasks. The comment also mentions the absence of information about the tool used. However, the claim lacks specific examples or references to support the assertion that professional translators have issues with such tasks. Without detailed evidence or examples, the claim is 3, as it provides a general observation but lacks the necessary depth to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of annotation training details and guidelines, which are crucial for professional translators working on nonstandard tasks. It also mentions the absence of information about the tool used. This feedback is clear and actionable, as it highlights specific areas that need to be addressed to improve the paper. However, the comment could be more helpful if it provided suggestions on how to present these details or what kind of information should be included. Despite this, the comment is 4 as it directs the authors to important aspects that need attention in their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the presentation of data in Table 1, specifically questioning the need for boldfacing the EX/NORB values and the statistical significance of the difference between 0.59+/0.12 and 0.58+/0.11. While the comment implies that the authors should reconsider these aspects, it does not provide explicit instructions or suggestions on how to address these questions. The action is implicit and somewhat vague, as the authors need to infer that they should reassess the presentation and statistical significance of the data. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the need for boldfacing the EX/NORB values and the statistical significance of the difference between 0.59+/0.12 and 0.58+/0.11. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions about the presentation of data in Table 1, specifically questioning the need for boldfacing the EX/NORB values and the statistical significance of the difference between 0.59+/0.12 and 0.58+/0.11. These are factual questions that do not express opinions, judgments, or suggestions for improvement. They are purely descriptive and do not require verification or justification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises specific questions about the presentation of data in Table 1, questioning the need for boldfacing the EX/NORB values and the statistical significance of the difference between 0.59+/0.12 and 0.58+/0.11. While it identifies potential issues with the data presentation, it does not provide actionable suggestions or guidance on how the authors might address these questions or improve the clarity of the data. The comment is 3 as it prompts the authors to reconsider their data presentation, but it lacks depth and specific advice, leaving the authors with only a general direction for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the metric used for the video level supervision experiment, suggesting that it is not using trackletbased metrics. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific action they should take. The comment lacks actionable details, such as suggesting alternative metrics or explaining why trackletbased metrics are important. As a result, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the metric used for the video level supervision experiment, suggesting that it is not using trackletbased metrics. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the metric used, but it lacks grounding as it does not explicitly mention a section or figure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the metric used for the video level supervision experiment, suggesting that it is not using trackletbased metrics. The comment does not provide any supporting evidence or reasoning to justify why trackletbased metrics should be used or why the current metric is insufficient. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the metric used for the video level supervision experiment, suggesting that it is not using trackletbased metrics. This is a relevant point that could help the authors clarify their methodology and ensure consistency in their evaluation. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or improve their analysis. While it identifies a potential area for improvement, the feedback is somewhat vague and incomplete, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the impact of \"person blocking\" on the models, as shown in Figure 4. It suggests that the models might be learning personrelated features, which could be undesirable. The comment explicitly asks the authors to comment on this issue, providing a clear and direct action for the authors to take. However, it does not offer specific guidance on how to address the issue or what aspects of the models might be affected by person blocking. While the action is explicit, the lack of concrete details on how to implement the suggestion makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the impact of \"person blocking\" on the models and suggests a possible reason for this effect, asking the authors to comment on it. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the impact of \"person blocking\" on the models, as shown in Figure 4. It suggests that the models might be learning personrelated features, which could be undesirable. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the impact of \"person blocking\" on the models, as shown in Figure 4. It suggests that the models might be learning personrelated features, which could be undesirable. The comment provides a specific area for the authors to consider and offers a potential explanation for the observed effect. By asking for a comment on this issue, the reviewer encourages the authors to reflect on and address a potential limitation or concern in their work. This feedback is clear and actionable, as it prompts the authors to consider and discuss a specific aspect of their models that could impact their performance. However, it could be more helpful if it included suggestions on how to address this issue or potential solutions. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about whether the authors tried a specific combination of TFIDF and dense retrieval for evidence sentence extraction. While it implies that the authors should consider this combination, the comment does not provide explicit guidance on how to implement it or why it might be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should consider this combination and determine how to integrate it into their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment asks a question about whether the authors tried a specific combination of TFIDF and dense retrieval for evidence sentence extraction. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references to sections or experiments, the authors may find it challenging to determine the exact context of the question. The comment is specific in its inquiry but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question asking whether the authors tried a specific combination of TFIDF and dense retrieval for evidence sentence extraction. It does not contain any claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about whether the authors tried a specific combination of TFIDF and dense retrieval for evidence sentence extraction. While it highlights a potential area for exploration, it lacks depth and does not provide any guidance or suggestions on how this combination might be implemented or why it could be beneficial. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is 2, as it prompts the authors to consider a specific approach but does not provide enough detail or context to be truly beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should include examples where the timeseries prediction did not perform well, such as in the COVID19 dataset where UK and Russia are highly correlated despite not being neighboring countries. It also asks about countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment implies that the authors should provide these examples or analyses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these examples or analyses. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include examples where the timeseries prediction did not perform well, specifically mentioning the COVID19 dataset and the correlation between UK and Russia. It also asks about countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or discussion sections where such examples or analyses might be included. The comment is specific in detailing what needs to be addressed, but it lacks full grounding as it does not explicitly mention a specific section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include examples where the timeseries prediction did not perform well, specifically mentioning the COVID19 dataset and the correlation between UK and Russia. It also asks about countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment provides a logical reasoning for why such examples could be beneficial, it lacks specific references or detailed explanations to fully substantiate the claim. The authors would need to infer the importance of these examples and how they relate to the paper\"s findings. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment suggests that the paper could include examples where the timeseries prediction did not perform well, such as in the COVID19 dataset where UK and Russia are highly correlated despite not being neighboring countries. It also asks about countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. This feedback is 3 as it provides a specific direction for the authors to enhance their paper by including examples or analyses that could strengthen their findings. However, the comment could be more helpful if it offered more detailed guidance on how to present these examples or what specific aspects to focus on. Overall, the comment is 3 as it identifies a potential area for improvement but lacks depth in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the claims of proposing a \"learning framework\" as being overblown, stating that it is not a new framework but rather a modified loss and architecture. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their claims. Without actionable suggestions or a clear direction for revision, the authors are left without a path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the claims of proposing a \"learning framework\" as being overblown, suggesting that it is not a new framework but rather a modified loss and architecture. However, it does not specify which parts of the paper make these claims, making it difficult for the authors to identify the exact sections that need revision. The comment lacks grounding as it does not mention specific sections, figures, or tables, and it is also not specific about what aspects of the claims are considered overblown. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the claims of proposing a \"learning framework\" are overblown, suggesting that it is not a new framework but rather a modified loss and architecture. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques the claims of proposing a \"learning framework\" as being overblown, suggesting that it is not a new framework but rather a modified loss and architecture. While the comment identifies a potential issue with the claims, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The authors are left without guidance on how to address the critique or enhance their claims. Therefore, the comment is 2, as it points out a weakness but does not offer meaningful direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential limitation in the learned prompts, noting that they are customized for specific transformerbased architectures, which may not translate effectively to other model types or even to transformers with slight architectural variations. The reviewer suggests exploring whether prompts could be designed with more universal features or optimized independently of model architecture to enhance broader applicability. While the comment identifies a specific issue and provides a direction for improvement, it does not offer concrete steps or detailed guidance on how to implement these suggestions. The authors are left with a general idea of what needs to be explored but without specific instructions on how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of learned prompts being customized for specific transformerbased architectures, such as CLIP and DINOv2, which may limit their generalizability to other model types or even transformers with slight architectural variations. However, it does not specify which part of the paper discusses these prompts or their customization, making it weakly grounded. The comment is specific in detailing the limitation and suggesting ways to enhance broader applicability, such as exploring universal features or optimizing prompts independently of model architecture. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the learned prompts are customized for specific transformerbased architectures, which may limit their generalizability to other model types or even transformers with slight architectural variations. The reviewer suggests exploring whether prompts could be designed with more universal features or optimized independently of model architecture. While the comment provides a logical reasoning for the limitation and suggests a potential solution, it lacks specific examples or references to support the claim fully. The authors would need to infer the exact nature of the limitation and the potential benefits of the suggested approach. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment identifies a potential limitation in the learned prompts, noting that they are customized for specific transformerbased architectures, which may limit their generalizability to other model types or even transformers with slight architectural variations. The reviewer suggests exploring whether prompts could be designed with more universal features or optimized independently of model architecture to enhance broader applicability. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in improving the generalizability of their approach. However, the comment could be more helpful if it offered examples or specific suggestions on how to achieve this goal. Overall, the comment is 4, as it effectively guides the authors toward a potential enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the absence of baselines and the antiquated nature of the model architecture used in the paper. It suggests that without comparisons to other models, there is no evidence that the current methodology is more effective or novel for fMRI forecasting. The comment implies that the authors should consider including baselines, such as those available in the \"TimeSeries Library\" repository, to provide a more comprehensive evaluation of their methodology. While the action is implicit, it is concrete in suggesting specific baselines and resources that could be used for comparison. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the absence of baselines and the antiquated nature of the model architecture used in the paper. It suggests that without comparisons to other models, there is no evidence of the current methodology\"s effectiveness or novelty for fMRI forecasting. The comment also implies that advanced timeseries forecasting models could be potential baselines, referencing the \"TimeSeries Library\" repository. However, the comment does not explicitly mention which part of the paper this critique pertains to, making it weakly grounded. The suggestion to include baselines is specific, as it provides a concrete example of resources that could be used for comparison. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the absence of baselines and the antiquated nature of the model architecture used in the paper. It suggests that without comparisons to other models, there is no evidence of the current methodology\"s effectiveness or novelty for fMRI forecasting. The comment provides a specific reference to the \"TimeSeries Library\" repository, which could be used to identify potential baselines. This reference adds credibility to the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to specific models that could be used as baselines. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out the absence of baselines and the antiquated nature of the model architecture used. It highlights the importance of comparing the current methodology to contemporary timeseries forecasting architectures to establish its effectiveness and novelty. The comment provides a specific suggestion by referencing the \"TimeSeries Library\" repository, which could be used to identify potential baselines for comparison. This feedback is clear and actionable, offering the authors a concrete direction for improving their draft by including relevant baselines. However, it could be more helpful if it provided more detailed guidance on which specific models from the repository might be most relevant for comparison. Overall, the comment is 4, as it effectively guides the authors toward enhancing the rigor and relevance of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include at least one strong baseline in one of the tasks, beyond the standard MLPs presented in the paper. While the comment implies that the authors should add a baseline, it does not explicitly instruct them to do so. Additionally, it does not provide specific guidance on which baseline to choose or how to implement it. The action is implicit and somewhat vague, as the authors can infer that they need to add a baseline but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include at least one strong baseline beyond the standard MLPs presented, particularly in one of the tasks. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing improvement. While the comment is specific in suggesting the inclusion of a strong baseline, it is 1 because it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include at least one strong baseline beyond the standard MLPs presented, particularly in one of the tasks. The reviewer acknowledges that the work is primarily theoretical but still expects a strong baseline. However, the comment lacks specific examples or references to what constitutes a \"strong baseline\" or how it should be implemented. This makes the claim 3, as the authors would need to infer what a strong baseline might be and how to incorporate it into their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the only baselines presented are standard MLPs, which may not be sufficient for a theoretical work. It suggests that the authors should include at least one strong baseline in one of the tasks to provide a more comprehensive evaluation. This feedback is clear and actionable, as it directs the authors to enhance the robustness of their evaluation by including additional baselines. However, the comment could be more helpful if it provided specific suggestions on which baselines to consider or how to implement them. Overall, the comment is 4 as it guides the authors toward improving their draft by addressing a critical aspect of their evaluation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to more clearly compare their proposed method to the prior works cited in the paper and to include these prior works in the tables of experimental results. This feedback provides a direct and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is clear and actionable, as it specifies both the comparison aspect and the inclusion of prior works in the experimental results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the prior works cited by the authors, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: a more detailed comparison of the proposed method with the prior works and the inclusion of these prior works in the tables of experimental results. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is similar to two prior works cited by the authors and suggests that the paper should more clearly compare the proposed method to these prior works. However, the comment does not provide specific examples or detailed comparisons to support this claim, making it difficult for the authors to understand the exact similarities or differences. Without such detailed evidence or references, the claim remains somewhat vague and lacks sufficient justification. Therefore, the comment is rated as 3, as it provides some basis for the claim but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the proposed method is similar to two prior works cited by the authors. It suggests that the paper should more clearly compare the proposed method to these prior works and include them in the tables of experimental results. This feedback is clear and actionable, providing the authors with a direct way to enhance the clarity and comprehensiveness of their work by comparing their method to relevant prior works. By addressing this feedback, the authors can improve the rigor and transparency of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment questions the broader goals identified in the paper, noting that it is unclear what these goals are. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify or specify these goals, nor is there a suggestion on how to address the evaluation of the claim. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the broader goals identified in the paper, specifically the claim that there do not exist visualization systems built for interpretable reinforcement learning that effectively address these goals. However, it does not specify which part of the paper discusses these goals, making it weakly grounded. The comment is specific in questioning the clarity of the broader goals and the evaluation of the claim, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim that there do not exist visualization systems built for interpretable reinforcement learning that effectively address the broader goals identified. The reviewer points out that it is unclear what these broader goals are, making it difficult to evaluate the claim. However, the comment does not provide any additional context, reasoning, or examples to support the claim or clarify the issue. Without further elaboration, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the broader goals identified in the paper, specifically the claim that there do not exist visualization systems built for interpretable reinforcement learning that effectively address these goals. However, it does not provide any specific guidance or suggestions on how the authors might clarify or specify these goals, nor does it offer insights into how the authors might address the evaluation of the claim. Without actionable feedback or constructive advice, the comment does not help the authors improve their draft. Therefore, it is rated as 1."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the independence of AAL and SLS and questions the stability of their improvements when applied separately. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The comment lacks actionable details, such as recommending specific analyses or experiments to conduct to validate the stability of the improvements. As a result, the authors are left without a clear understanding of what steps to take to address the concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table (14),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the stability of the improvements when AAL or SLS are applied separately. However, the comment lacks specificity in terms of what specific aspects of the improvements are questionable or how the authors might address this concern. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises a claim about the independence of AAL and SLS and questions the stability of their improvements when applied separately. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the independence of AAL and SLS and questions the stability of their improvements when applied separately. This is a relevant observation that could impact the interpretation of the results. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this concern or improve their analysis. Without detailed feedback or suggestions, the authors are left with a general understanding of the issue but without a clear path to resolution. Therefore, the comment is 3, as it highlights a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiments are limited to only one task and one dataset, which could limit the insights gained. It explicitly recommends exploring the effects on different tasks or utilizing multiple datasets for the same task. This feedback provides a clear and direct action for the authors to take, offering a specific direction for expanding the scope of their experiments. The suggestion is concrete, as it specifies what the authors should do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitation of the experiments being restricted to only one task  sentiment classification  and one dataset  SST2. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: exploring the effects on different tasks or utilizing multiple datasets for the same task. This provides clear guidance on how to expand the scope of the experiments. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to only one task and one dataset, which could limit the insights gained. The reviewer suggests exploring the effects on different tasks or utilizing multiple datasets for the same task. This claim is 3 as it provides a logical reasoning for the limitation and suggests a potential improvement. However, it lacks specific examples or references to support the claim or demonstrate the potential benefits of expanding the scope. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the experiments, noting that they are restricted to only one task and one dataset. It suggests that exploring different tasks or utilizing multiple datasets for the same task could provide deeper insights. This feedback is clear and actionable, as it offers a specific direction for expanding the experimental scope, which could significantly enhance the paper\"s contribution. However, the comment could be more helpful if it provided examples of tasks or datasets that could be considered or suggested ways to integrate them into the current setup. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the use of simulated data instead of realworld data in the experiments. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should switch to realworld data, how they might address this issue, or what specific changes are needed to improve the study. The comment lacks actionable details, leaving the authors without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it addresses, such as a particular section, experiment, or methodology. It also lacks specificity because it does not detail what is wrong with the use of simulated data or how it could be improved. The authors cannot confidently determine which part of the paper is being critiqued, and the comment does not provide clear guidance on what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the use of simulated data instead of realworld data in the experiments, suggesting that simulated data might be easier to fit. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the use of simulated data instead of realworld data in the experiments, suggesting that simulated data might be easier to fit. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or why it is a concern. The comment lacks depth and actionable feedback, leaving the authors without a clear understanding of how to improve their work. Therefore, it is rated as 2, as it identifies a potential issue but does not offer meaningful guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the study, specifically the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests including metrics like interclass or intraclass Frechet Inception Distance (FID) to enhance the comprehensiveness of the evaluation and comparison between different models. While the comment implies that the authors should consider adding these metrics, it does not explicitly instruct them to do so. The action is concrete in suggesting specific metrics to include, but it is implicit in nature. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the absence of a dedicated image quality metric for evaluating the performance of image generation models. This allows the authors to accurately identify the part of the paper being addressed, specifically the evaluation section. The comment is also specific because it suggests including metrics like interclass or intraclass Frechet Inception Distance (FID) to enhance the comprehensiveness of the evaluation. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the study lacks a dedicated image quality metric for evaluating the performance of image generation models. It suggests including metrics like interclass or intraclass Frechet Inception Distance (FID) to enhance the evaluation. The comment provides a specific suggestion for improvement, which is a quantitative assessment of image quality. However, it does not provide detailed reasoning or examples of how these metrics would enhance the evaluation or comparison between different models. While the suggestion is clear, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the study by pointing out the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests including metrics like interclass or intraclass Frechet Inception Distance (FID) to enhance the comprehensiveness of the evaluation and comparison between different models. This feedback is clear and actionable, providing the authors with a specific suggestion for improving the rigor and depth of their evaluation. However, the comment could be more helpful if it explained why these metrics are important or how they would enhance the study. Overall, the comment is 4 as it offers a concrete direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about whether the mechanism discussed in the paper can be applied to vision transformers. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or whether it is relevant to the paper\"s scope. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the mechanism discussed in the paper to vision transformers. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the mechanism or vision transformers are being questioned. Without clear grounding or specificity, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the applicability of the mechanism discussed in the paper to vision transformers. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of the mechanism discussed in the paper to vision transformers. While it identifies a potential area for exploration, it lacks specificity and does not provide any actionable feedback or suggestions for the authors to consider. The comment does not offer guidance on how the authors might address this question or whether it is relevant to their work. As a result, the comment is 1, as it does not provide any actionable insights or direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the precision of the proposed Adaptive IMLE compared to the IMLE and asks whether the method can be applied to different domains. While it implies that the authors should provide explanations or evidence for these questions, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the questions or what kind of evidence or examples to provide. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the precision of the proposed Adaptive IMLE compared to IMLE and asks whether the method can be applied to different domains. However, it does not specify which part of the paper these questions are based on, making it difficult for the authors to pinpoint the exact sections that need clarification. The comment is specific in its questions but lacks grounding, as it does not refer to any particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification and additional information. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the precision of the proposed Adaptive IMLE compared to IMLE and whether the method can be applied to different domains. This feedback prompts the authors to provide explanations or evidence for these questions, which could enhance the clarity and comprehensiveness of their paper. However, the comment does not offer specific suggestions or guidance on how to address these questions or improve the paper. While it identifies areas for clarification, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the experimental results, specifically questioning whether all the modules are necessary. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what specific aspects of the experimental results need improvement or how the authors might determine which modules are necessary. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the experimental results, specifically questioning whether all the modules are necessary. However, it does not specify which part of the paper discusses the experimental results or which modules are being questioned. This lack of explicit reference to a specific section or module makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, the comment does not provide specific details on what aspects of the experimental results are lacking or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the experimental results, specifically questioning whether all the modules are necessary. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it affects the paper\"s findings. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, specifically questioning whether all the modules are necessary. This is a relevant observation that could prompt the authors to reconsider the design and implementation of their experiments. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern or improve their experimental setup. Without actionable advice or detailed feedback, the authors are left with a general idea of an area that needs attention but without a clear path to improvement. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises an interesting question about how the network would behave with more layers, such as 32 and 64, given that many GNNs tend to oversmooth with additional layers. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should conduct additional experiments with these layer configurations, or if they should discuss the potential impact of oversmoothing on their results. Without specific instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the behavior of the network with more layers, specifically mentioning 32 and 64 layers. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. The authors can infer that it relates to the discussion of the network architecture or experimental setup, but this inference is not direct. The comment is specific in its suggestion to explore more layers, but it lacks grounding as it does not explicitly mention a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the behavior of the network with more layers, specifically mentioning 32 and 64 layers. It references a known issue with GNNs, which tend to oversmooth as more layers are added. However, the comment does not provide specific evidence or references to support this claim, such as studies or examples of GNNs that exhibit this behavior. The lack of detailed justification or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises an interesting question about the behavior of the network with more layers, specifically suggesting that the authors explore configurations with 32 and 64 layers. This feedback is 3 as it prompts the authors to consider a broader range of layer configurations, which could provide valuable insights into the network\"s behavior and potential limitations. However, the comment lacks specific guidance on how to conduct these experiments or what to look for in the results. Additionally, it does not address any specific weaknesses or improvements in the current draft, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should perform significance tests to ensure the reliability of their experimental results, particularly regarding the improvement of MT over ST. This comment explicitly states an action for the authors to take, which is to conduct significance tests. However, it does not provide specific guidance on how to perform these tests or what statistical methods to use, leaving the authors with a clear direction but less detailed instructions on execution. Therefore, the comment is 3, as it provides a direct action but lacks concrete details on implementation.", "grounding_specificity_rationale": "The comment suggests that the improvement of MT over ST is limited and recommends performing significance tests to ensure the reliability of the experimental results. However, it does not specify which part of the paper discusses these results or where the authors should perform the significance tests. This lack of explicit reference to a specific section or table makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for significance tests, but without grounding, it is difficult for the authors to know where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvement of MT over ST is limited and suggests performing significance tests to ensure the reliability of the experimental results. However, the comment lacks specific examples, data, or references to support the claim about the limited improvement or the need for significance tests. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 2, as it provides some justification but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, specifically noting that the improvement of MT over ST is limited. It suggests that the authors should perform significance tests to ensure the reliability of their results. This feedback is 3 as it points out a specific area for improvement and provides a clear action for the authors to take. However, the comment could be more helpful if it offered guidance on how to perform the significance tests or what statistical methods to use. Overall, the comment provides a useful direction for the authors to enhance the robustness of their experimental findings, but it could be more comprehensive with additional details or examples."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the claim that the proposed framework is modelagnostic, as it is only evaluated under different GCN architectures. The reviewer expresses curiosity about how the framework would perform on different GNN blocks, such as GAT, GraphSAGE, GIN, Geniepath, and others. This comment implies that the authors should evaluate their framework on a broader range of GNN blocks to substantiate the claim of modelagnosticism. While the action is implicit, it is concrete in suggesting specific GNN blocks to consider for evaluation. The authors can infer that they need to expand their evaluation to include these blocks to address the concern. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5\" and the specific models employed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim of modelagnosticism and suggests evaluating the framework on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, to substantiate the claim. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the authors\" assertion of modelagnosticism is not fully substantiated, as the evaluation is limited to different GCN architectures. The reviewer expresses curiosity about how the framework would perform on other GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath. This claim is 3 as it highlights a potential limitation in the evaluation and suggests a specific area for further exploration. However, the comment lacks detailed reasoning or examples of how these other GNN blocks might impact the framework\"s modelagnosticism. Providing more detailed justification or references would strengthen the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s claim of modelagnosticism, as it is only evaluated under different GCN architectures. The reviewer expresses curiosity about how the framework would perform on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, which are not evaluated in the current study. This feedback is clear and actionable, as it suggests a specific area for further evaluation that could strengthen the claim of modelagnosticism. By addressing this concern, the authors can enhance the robustness and applicability of their framework. However, the comment could be more helpful if it provided additional guidance on how to conduct these evaluations or what specific aspects to focus on. Overall, the comment is 4, as it directs the authors to a critical area for improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the method has many components and recommends conducting an error analysis to understand how the approach would perform if one of the components, such as GPT4o, makes a mistake. The reviewer explicitly asks for an analysis of what happens if GPT4o misses some details. This feedback provides a clear and specific action for the authors to take, offering a concrete suggestion on how to improve their draft. The explicit nature of the request and the detailed guidance on what to analyze make this comment 5.", "grounding_specificity_rationale": "The comment suggests conducting an error analysis to understand how the approach would perform if one of the components, such as GPT4o, makes a mistake. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for an error analysis and provides a concrete example of what should be analyzed (the impact of GPT4o missing details). Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an error analysis to understand how the approach would perform if one of the components, such as GPT4o, makes a mistake. The reviewer provides a specific example of what could be analyzed, which is the impact of GPT4o missing details. This suggestion is logical and provides a clear direction for the authors to improve their work. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the method by pointing out that it has many components and suggests conducting an error analysis to understand how the approach would perform if one of the components, such as GPT4o, makes a mistake. This feedback is clear and actionable, as it provides a specific area for improvement by recommending an error analysis. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for enhancement, but it could be more comprehensive with further guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that an error analysis should be included to understand the limitations of SetCSE in specific scenarios. While the comment implies that an error analysis should be added, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that they need to include an error analysis but may not be entirely sure of the details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that an error analysis should be included to understand the limitations of SetCSE in certain scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where an error analysis could be beneficial. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in suggesting an error analysis, it is 1 because it does not indicate where this analysis should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an error analysis should be included to understand the limitations of SetCSE in certain scenarios. However, the comment does not provide any specific examples, reasoning, or references to support why an error analysis is necessary or how it would benefit the understanding of limitations. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that an error analysis should be included to understand the limitations of SetCSE in specific scenarios. This feedback is 3 as it points out an area where the paper could be strengthened by providing additional insights into the robustness and limitations of the method. However, the comment lacks specificity and does not provide detailed guidance on how to conduct the error analysis or what aspects to focus on. While it highlights an important area for improvement, the lack of detailed suggestions limits its usefulness to the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of measuring toolknowledge by prompting and suggests that in a scenario where model weights are shared, there might be unintentional finetuning that recovers toolknowledge. It also mentions the possibility of other prompts that could elicit the model\"s ability to use a tool. However, the comment does not provide explicit guidance on how the authors should address these concerns or suggest specific actions to take. The authors are left to infer that they should explore alternative methods or prompts, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of measuring toolknowledge by prompting and suggests that in a scenario where model weights are shared, there might be unintentional finetuning that recovers toolknowledge. It also mentions the possibility of other prompts that could elicit the model\"s ability to use a tool. However, the comment does not specify which part of the paper this concern pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in detailing the issue with measuring toolknowledge and suggesting alternative approaches, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of measuring toolknowledge by prompting and suggests that in a scenario where model weights are shared, there might be unintentional finetuning that recovers toolknowledge. It also mentions the possibility of other prompts that could elicit the model\"s ability to use a tool. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that measuring toolknowledge by prompting is insufficient. The suggestion about unintentional finetuning is a logical inference but requires further elaboration to be 5. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of measuring toolknowledge by prompting, suggesting that in a scenario where model weights are shared, there might be unintentional finetuning that recovers toolknowledge. It also mentions the possibility of other prompts that could elicit the model\"s ability to use a tool. While the comment identifies a potential limitation in the current approach, it lacks specific suggestions or guidance on how the authors might address this issue or explore alternative methods. The feedback is 3 as it prompts the authors to consider the limitations of their current methodology and potentially explore other avenues, but it does not provide detailed actionable steps. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should find other tasks or even create artificial tasks to demonstrate the effectiveness of HA3C, as the improvement over baseline algorithms on MuJoCo control tasks is marginal. While the comment implies that the authors should explore alternative tasks, it does not provide specific guidance on how to identify or create these tasks. The action is implicit and somewhat vague, as the authors are left to infer the steps needed to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experimental results\" and \"the improvement of HA3C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed explanation of why the improvement over baseline algorithms on MuJoCo control tasks is marginal, suggesting that the benefit of HA3C relies on the structure of the problem and that MuJoCo tasks may not be suitable for demonstrating its effectiveness. The reviewer further suggests finding other tasks or even creating artificial tasks to demonstrate HA3C\"s effectiveness. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the improvement of HA3C over baseline algorithms on MuJoCo control tasks is marginal, suggesting that this does not indicate HA3C\"s ineffectiveness. The reviewer provides a rationale by explaining that the benefit of HA3C relies on the structure of the problem, where the causal relationship based on the current state is complex but the causal relationship based on the history can be simple. This reasoning is logical and provides a clear explanation for the claim, making it 4. However, the comment could be strengthened by referencing specific examples or studies that support this reasoning, which would align with a score of 4.", "helpfulness_rationale": "The review comment provides a detailed analysis of the experimental results, specifically noting the marginal improvement of HA3C over baseline algorithms on MuJoCo control tasks. The reviewer offers a rationale for this observation, suggesting that the benefit of HA3C relies on the structure of the problem, where the causal relationship based on the current state is complex but the causal relationship based on the history can be simple. This insight could help the authors understand the limitations of their approach in the context of MuJoCo tasks. The comment also suggests that the authors should explore other tasks or even create artificial tasks to demonstrate the effectiveness of HA3C, which is a clear and actionable suggestion. However, the comment could be more helpful by providing specific examples of alternative tasks or by offering guidance on how to create artificial tasks. Overall, the feedback is 4 as it identifies a potential limitation and offers a constructive suggestion for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the key contributions should focus on insights derived from the data rather than the dataset itself. It criticizes the paper for primarily reporting aggregate numbers without clearly presenting key takeaways beyond the general message that LLM performance does not align with human abilities. The reviewer explicitly requests to see key insights or takeaways derived from the experiments that are generalizable and hold broader significance for the community. This feedback provides a clear and explicit action for the authors to take, which is to present key insights or takeaways from their experiments. The comment is specific and actionable, as it guides the authors on what they need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the aspect of novelty and the focus on insights derived from the data, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of key insights or takeaways beyond general observations about LLM performance. The comment provides a clear direction for improvement by suggesting that the authors should present key insights or takeaways that are generalizable and hold broader significance for the community. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not fully address the key contributions, focusing primarily on aggregate numbers without presenting key insights or takeaways. The reviewer suggests that the paper should focus on insights derived from the data to deepen our understanding of LLM capabilities. However, the comment lacks specific examples or references to support the claim that the paper does not provide key insights or takeaways. Without detailed evidence or examples, the claim remains 3, as the authors may need to infer the specific areas lacking in the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the focus on insights derived from the data rather than the dataset itself. It points out that the paper primarily reports aggregate numbers without clearly presenting key takeaways beyond the general message that LLM performance does not align with human abilities. The reviewer suggests that the authors should present key insights or takeaways that are generalizable and hold broader significance for the community. This feedback is clear and actionable, providing the authors with a specific direction to enhance their draft by highlighting the insights gained from their experiments. However, the comment could be more helpful if it offered examples of how to present these insights or suggested specific areas to focus on. Overall, the comment is 4 as it guides the authors toward improving their paper by emphasizing the importance of deriving meaningful insights from their data."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the claim in Section 3.1 regarding GAN being the \"de facto choice for vocoders\" is false and ignores other important works in the community. It provides a list of alternative vocoders, such as WaveNet, WaveRnn, and diffusionbased approaches, which the authors should consider. This feedback is clear and actionable, as it directly instructs the authors to correct the false claim and acknowledge the existence of other popular vocoders. The authors know exactly what needs to be done to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim about GAN being the \"de facto choice for vocoders\" and provides a list of alternative vocoders, such as WaveNet, WaveRnn, and diffusionbased approaches, that should be acknowledged. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"GAN has been the de facto choice for vocoders\" is false and ignores other important works in the community. The reviewer provides a list of alternative vocoders, such as WaveNet, WaveRnn, and diffusionbased approaches, which supports the claim that GAN is not the only choice. This provides a clear and specific counterargument, making the claim 4. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific claim in Section 3.1 that GAN is the \"de facto choice for vocoders,\" which is incorrect and overlooks other important works in the field. It provides a list of alternative vocoders, such as WaveNet, WaveRnn, and diffusionbased approaches, that should be acknowledged. This feedback is clear and actionable, as it directly points out an error in the paper and suggests a way to correct it by including other relevant works. By addressing this issue, the authors can improve the accuracy and completeness of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the approach, while straightforward and sensible, contains design choices that are not fully explained or empirically justified. It specifically mentions the choice of token similarity metric as an example. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific aspects need further explanation or justification. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations and empirical justifications for their design choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment provides a general critique of the approach, stating that it contains design choices that are not fully explained or empirically justified. However, it does not specify which part of the paper these design choices are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, while it mentions the choice of token similarity metric as an example, it does not provide specific details or examples of other design choices that are lacking in explanation or justification. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the approach contains design choices that are not fully explained or empirically justified. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of the choice of token similarity metric as an example is vague and lacks context, making it difficult for the authors to understand the basis of the critique. Without specific examples or detailed justification, the claim remains 1, as it does not provide sufficient evidence or reasoning for the authors to address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a weakness in the paper, noting that the approach contains design choices that are not fully explained or empirically justified. It specifically mentions the choice of token similarity metric as an example. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how the authors might address these issues or provide the necessary explanations and justifications. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific inconsistencies in the notation, pointing out that the lefthand side (LHS) of Equation (4) has \"T\" and \"W\" but the righthand side (RHS) does not, and that the formulas for the mean and variance in Equation (6) have \"j\" on the LHS but not on the RHS. This feedback is explicit and provides clear guidance on what needs to be corrected in the notation. The authors know exactly what inconsistencies to address, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (4 and 6) and the inconsistencies in the notation, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the exact inconsistencies in the notation, such as the absence of \"T\" and \"W\" on the righthand side of Equation (4) and the absence of \"j\" on the righthand side of Equation (6). This level of detail provides clear guidance on what needs to be corrected, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point identifies specific inconsistencies in the notation, pointing out that Equation (4) has \"T\" and \"W\" on the lefthand side (LHS) but not on the righthand side (RHS), and that Equation (6) has \"j\" on the LHS but not on the RHS. This is a factual observation about the paper\"s notation, which does not require any subjective claims or opinions. It is purely descriptive and does not contain any claims that need verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific inconsistencies in the notation, pointing out that Equation (4) has \"T\" and \"W\" on the lefthand side (LHS) but not on the righthand side (RHS), and that Equation (6) has \"j\" on the LHS but not on the RHS. This feedback is clear and actionable, as it directly points out where the notation is inconsistent and needs to be corrected. By addressing these inconsistencies, the authors can improve the clarity and accuracy of their mathematical expressions, which is crucial for the understanding and reproducibility of their work. However, the comment could be more helpful if it provided additional context or explained why these inconsistencies are important. Overall, the comment is 4 as it guides the authors toward a specific improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several areas where the evaluation is insufficient, including the number of models constructed during the evaluations and the lack of evaluation regarding the distortion of the image after warping. It also notes the absence of discussion on potential countermeasures against the proposed approach. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific evaluations or discussions should be included. The actions are implicit and somewhat vague, as the authors need to infer what additional evaluations or discussions are necessary. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Insufficient Evaluation,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issues with the evaluation, such as the limited number of models constructed and the lack of evaluation regarding image distortion after warping. Additionally, it points out the absence of discussion on potential countermeasures against the proposed approach. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation is insufficient due to the limited number of models constructed and the lack of evaluation regarding image distortion after warping. It also notes the absence of discussion on potential countermeasures against the proposed approach. While the comment identifies specific areas where the evaluation could be improved, it lacks detailed reasoning or examples to support the claim. The authors might infer that more models and evaluations are needed, but the comment does not provide specific guidance or references to substantiate the claim. Therefore, the comment is 3, as it provides a general direction but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies several areas where the evaluation of the paper is insufficient, specifically noting the limited number of models constructed during the evaluations and the lack of evaluation regarding the distortion of the image after warping. It also points out the absence of discussion on potential countermeasures against the proposed approach. While the comment highlights important gaps in the evaluation, it does not provide specific suggestions or guidance on how to address these issues or what additional evaluations or discussions might be beneficial. The feedback is 3 as it directs the authors\" attention to areas needing improvement, but it lacks actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the classification of elements in Table A3, specifically whether they are discourse particles or discourse + imported vocab. It suggests that if the latter is the case, the elements should be separated into different tables and that glosses would be helpful. While the comment implies that the authors should clarify the classification and potentially reorganize the table, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the classification of elements in the table and suggests separating them if they are discourse + imported vocab. The comment further recommends providing glosses to aid understanding. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the classification of elements in Table A3, specifically whether they are discourse particles or discourse + imported vocab. It suggests that if the latter is the case, the elements should be separated into different tables and that glosses would be helpful. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this separation is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific question about the classification of elements in Table A3, asking whether they are discourse particles or discourse + imported vocab. It suggests that if the latter is the case, the elements should be separated into different tables and that glosses would be helpful. This feedback is clear and actionable, as it directs the authors to clarify the classification and potentially reorganize the table to improve its clarity and usefulness. However, the comment could be more helpful if it provided additional context or examples of how the separation would benefit the paper. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses confusion about the idea behind formula (4) and questions the rationale for taking the maximum over all possible pieces for unoccupied squares. However, it does not provide any explicit or implicit guidance on how the authors might clarify or improve this aspect of their work. The comment lacks actionable details, such as suggestions for rephrasing, additional explanations, or examples that could help the authors address the issue. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"formula (4),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the rationale behind the max over all possible pieces for unoccupied squares. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point expresses confusion about the idea behind formula (4) and questions the rationale for taking the maximum over all possible pieces for unoccupied squares. However, the comment does not provide any supporting evidence, reasoning, or references to explain why this aspect is unclear or why it might be problematic. Without additional context or justification, the authors may find it challenging to understand the basis of the reviewer\"s confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about the idea behind formula (4) and questions the rationale for taking the maximum over all possible pieces for unoccupied squares. While it identifies a specific area of confusion, it does not provide any suggestions or guidance on how the authors might clarify or improve this aspect of their work. The comment lacks actionable feedback or detailed explanations that could help the authors address the issue. As a result, it is 2, as it points out a potential problem but does not offer a path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the experiments lack a comparison to stateoftheart subset selection methods. This provides a clear and direct action for the authors to take, which is to include such comparisons in their experiments. The comment is explicit and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparison to stateoftheart subset selection methods. This provides clear guidance on what needs to be addressed in the experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments lack a comparison to stateoftheart subset selection methods. However, it does not provide any specific examples of these stateoftheart methods or detailed reasoning as to why such comparisons are necessary. Without additional context or references, the claim remains vague and lacks sufficient evidence to be considered verifiable. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of comparison to stateoftheart subset selection methods in the experiments. This feedback is clear and actionable, as it directs the authors to include such comparisons to enhance the validity and relevance of their work. However, the comment could be more helpful if it provided examples of specific stateoftheart methods or suggested how to incorporate them into the experiments. Despite this, the feedback is 4 as it guides the authors toward a meaningful enhancement of their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the novelty of the paper is somewhat vague and suggests that it needs to be more concise. However, it does not provide specific guidance on how to achieve this conciseness or which aspects of the paper should be clarified. The comment mentions integrating effective elements of previous works, but it does not specify which aspects of these works should be integrated or how they should be integrated. Without concrete suggestions or examples, the authors are left without a clear understanding of what changes are needed to improve the paper\"s novelty. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the novelty of the paper, suggesting that it is somewhat vague and needs to be more concise. It mentions integrating effective elements of previous works, including SCL, Aligned, and CLNN, among others. However, the comment does not specify which parts of the paper are vague or how the integration of these elements could be improved. While the authors might infer that the novelty section is the focus, the comment lacks full grounding as it does not explicitly mention a specific section or part of the paper. Additionally, it is specific in identifying the need for more conciseness but lacks detailed guidance on how to achieve this. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is somewhat vague and suggests that it integrates effective elements of previous works. However, the comment lacks specific examples or references to support this claim, such as which previous works are being integrated or how they contribute to the novelty of the paper. Without detailed evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the novelty is somewhat vague and could be more concise. It points out that the paper seems to integrate effective elements of previous works, such as SCL, Aligned, and CLNN. However, the comment lacks specificity and does not provide detailed guidance on how to improve the novelty or which aspects of the paper should be clarified. Without actionable suggestions or examples, the authors are left with a general understanding of the issue but without clear steps to address it. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests using evaluation benchmarks for user simulators to demonstrate how smaller models perform in this role. This implies that the authors should include such benchmarks to make the evaluation more usable and accessible to the community. However, the comment does not provide specific guidance on how to implement these benchmarks or which models to use for comparison. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take, such as selecting appropriate models and designing the evaluation framework. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests using evaluation benchmarks for user simulators to demonstrate how smaller models perform in this role. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the evaluation or results sections, but this inference is not explicit. The comment is specific in suggesting the use of such benchmarks to make the evaluation more usable and accessible to the community. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests using evaluation benchmarks for user simulators to demonstrate how smaller models perform in this role. This is a request for additional information or analysis, rather than a claim or opinion that requires verification. It does not present subjective opinions, judgments, or suggestions that need to be supported by evidence or reasoning. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests using evaluation benchmarks for user simulators to demonstrate how smaller models perform in this role. This feedback is 3 as it provides a direction for the authors to enhance their evaluation methodology, making it more usable and accessible to the community. However, the comment lacks specific guidance on how to implement these benchmarks or which models to use for comparison, leaving the authors with a general idea but no detailed steps to follow. To be more helpful, the comment could include examples or suggestions on how to incorporate these benchmarks effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of openset detectors on the performance of the proposed method. While it implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as it lacks specific instructions on what aspects of the impact should be explored or how to evaluate it. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the impact of openset detectors on the performance of the proposed method. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where openset detectors are discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its inquiry about the impact of openset detectors, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification on the impact of openset detectors on the performance of the proposed method. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the impact of openset detectors on the performance of the proposed method. This is a relevant inquiry that could help the authors better understand and evaluate the effectiveness of their approach. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or conduct further analysis. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it prompts the authors to consider an important aspect of their work but does not fully support them in making improvements."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises two specific issues regarding the interpretation of symbols in Tables 1 and 5. It points out that the star (*) next to \"oracle goals\" in Table 1 is not explained and asks for clarification. Additionally, it questions the meaning of \"fromscratch\" in Table 5, suggesting that it might be misinterpreted as a random initialization when it appears to be a pretrained model. The comment explicitly requests clarification or correction from the authors. While the actions are clear, they are not fully concrete as they do not provide specific guidance on how to clarify or fix the issues. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the star (*) next to \"oracle goals\" in Table 1 and questions the meaning of \"fromscratch\" in Table 5, suggesting that it might be misinterpreted as a random initialization when it appears to be a pretrained model. The comment requests clarification or correction, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and questions, such as the absence of an explanation for the star (*) next to \"oracle goals\" in Table 1 and the clarification needed for the term \"fromscratch\" in Table 5. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues in the paper: the absence of an explanation for the star (*) next to \"oracle goals\" in Table 1 and the potential misinterpretation of \"fromscratch\" in Table 5. It requests clarification or correction on these points, which is a clear and actionable suggestion for the authors to improve the clarity and accuracy of their work. By addressing these issues, the authors can enhance the comprehensibility and validity of their results. However, the comment could be more helpful if it provided additional context or examples to guide the authors in making these clarifications. Overall, the feedback is 4 as it directs the authors to specific areas needing attention, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results in Table 1, suggesting that the observed increase in transferability with higher noise intensity is not expected. The reviewer implies that as inputs are increasingly deformed by noise, different neurons should be activated to reduce confidence in the source samples, potentially leading to increased misclassification. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to improve the results. The action is implicit and vague, as the authors are left to infer that they should explore or explain the unexpected results, but without concrete steps or suggestions, the comment lacks actionability. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the observation that transferability appears to increase with higher noise intensity and questions the expected outcome of different neurons being activated to reduce confidence in the source samples. The comment further expresses a lack of excitement about the results. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the results in Table 1, suggesting that the observed increase in transferability with higher noise intensity is unexpected. The reviewer provides a logical reasoning by explaining that as inputs are increasingly deformed by noise, different neurons should be activated to reduce confidence in the source samples, potentially leading to increased misclassification. This reasoning is based on common knowledge about the effects of noise on neural networks. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to consider the reasoning and potentially provide additional evidence or explanation to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the results presented in Table 1, specifically the observation that transferability appears to increase with higher noise intensity. The reviewer provides a logical reasoning for why this result might be unexpected, suggesting that as inputs are increasingly deformed by noise, different neurons should be activated to reduce confidence in the source samples, potentially leading to increased misclassification. This feedback is 3 as it prompts the authors to reconsider their interpretation of the results and potentially explore alternative explanations or analyses. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take. It suggests adding ablation studies with only importance weighting or the rejection to better understand their effects. Additionally, it points out that the fonts in the figures are too small to read and requests an explanation for the ChopperCommand results in Fig. 6 (a). The comment is clear and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the lack of ablation studies and the issue with the fonts in the figures. It also references Figure 6 (a) and the ChopperCommand results, allowing the authors to accurately identify the parts being addressed. The comment is specific in detailing what needs to be addressed, such as adding ablation studies and explaining the ChopperCommand results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and requests for clarification. The first claim suggests that adding ablation studies with only importance weighting or the rejection would help understand their effects better. This claim is 3 as it provides a logical suggestion for improving the paper, but it lacks specific examples or references to support the assertion. The second claim points out that the fonts in the figures are too small to read, which is a factual observation. The third claim questions the ChopperCommand results in Figure 6 (a), asking whether they are too easy or too hard to learn and why the reward behavior is observed. This part is 3 as it raises valid questions but lacks detailed analysis or references to support the claim. Overall, the comment is a mix of factual observations and claims, with some parts being more verifiable than others, justifying a score of 3.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper. It recommends adding ablation studies with only importance weighting or the rejection to better understand their effects, which is a clear and specific suggestion for enhancing the study. Additionally, it points out that the fonts in the figures are too small to read, offering a practical improvement for the authors to make. The comment also raises questions about the ChopperCommand results in Figure 6 (a), asking whether they are too easy or too hard to learn and why the reward behavior is observed. This prompts the authors to provide a more detailed explanation in the paragraph. Overall, the comment is 5 as it offers constructive feedback and actionable suggestions that can significantly enhance the clarity and comprehensiveness of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of technical clarity regarding the main learning framework Equation (18) and questions how to implement the balancing term and the penalty term. While it identifies specific areas that need clarification, it does not provide explicit guidance on how the authors should address these issues. The comment implies that the authors should provide more detailed explanations, but it lacks concrete steps or suggestions on how to improve the clarity. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (18),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking explanation for the main learning framework and questions the implementation of the balancing term and the penalty term. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the technical clarity is weak and questions the explanation of the main learning framework, specifically Equation (18). It also asks how to implement the balancing term and the penalty term. However, the comment lacks specific examples or detailed reasoning to support the claim of weak technical clarity. Without additional context or references, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed justification or examples to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the technical clarity of the paper, noting that the main learning framework, Equation (18), is not explained. It also questions how to implement the balancing term and the penalty term. This feedback is clear and actionable, as it directs the authors to clarify and explain these critical aspects of their work. By addressing these points, the authors can enhance the technical rigor and comprehensibility of their paper. However, the comment could be more helpful if it provided suggestions on how to improve the explanation or offered examples of similar frameworks for comparison. Overall, the comment is 4, as it effectively guides the authors toward improving the technical clarity of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the decision boundary generation, specifically noting that the projection results and Voronoi tessellation appear fixed across multiple rounds, despite the feature vectors updating during training. It suggests that the fixed tessellations with updated predictions should be clarified to capture the model\"s behavior. Additionally, it questions the use of 2D projections to represent highdimensional decision boundaries, highlighting the potential for significant variation based on the selected projection method and parameters. While the comment identifies areas of concern, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors are left to infer that they need to clarify the fixed tessellations and consider alternative methods for representing decision boundaries. Therefore, the comment is 3, as it points out areas for improvement but lacks detailed guidance on how to implement these changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figures\" and \"Voronoi tessellation results,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the fixed nature of the projection results and Voronoi tessellations, despite the feature vectors updating during training. Additionally, it raises concerns about the use of 2D projections to represent highdimensional decision boundaries and the potential variation in results based on the selected projection method and parameters. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the decision boundary generation, specifically questioning the fixed nature of the projection results and Voronoi tessellation across multiple rounds, despite the feature vectors updating during training. It suggests that the fixed tessellations with updated predictions may not accurately capture the model\"s behavior. Additionally, it highlights the potential issue of using 2D projections to represent highdimensional decision boundaries, noting that results can vary significantly based on the selected projection method and parameters. While the comment provides logical reasoning and raises valid concerns, it lacks specific examples or references to support the claim fully. Therefore, the comment is 3, as it provides a logical basis for the concern but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment raises a significant concern about the decision boundary generation process, specifically noting that the projection results and Voronoi tessellation appear fixed across multiple rounds, despite the feature vectors updating during training. It highlights the importance of clarifying how well these fixed tessellations with updated predictions capture the model\"s behavior. Additionally, the comment questions the use of 2D projections to represent highdimensional decision boundaries, pointing out the potential for significant variation based on the selected projection method and parameters. This feedback is clear and actionable, as it identifies specific areas for improvement and provides a logical rationale for addressing them. However, it could be more helpful if it offered suggestions on alternative methods or approaches to address these concerns. Overall, the comment is 4, as it effectively guides the authors toward enhancing the clarity and robustness of their decision boundary generation process."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that there is no ablation study and no comparison to methods from the past decade. This provides clear and direct actions for the authors to take: they should conduct an ablation study and compare their methods to those from the past decade. The feedback is explicit and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment mentions the absence of an ablation study and a comparison to methods from the past decade. However, it does not specify which part of the paper lacks these elements, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the comment lacks specificity regarding what aspects of the ablation study or comparison are missing. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that there is no ablation study and no comparison to methods from the past decade. However, it does not provide any supporting evidence, reasoning, or references to justify why these aspects are necessary or important. Without additional context or explanation, the authors may find it challenging to understand the significance of these claims or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two significant gaps in the paper: the absence of an ablation study and a lack of comparison to methods from the past decade. These are important aspects that can help validate the effectiveness and novelty of the proposed method. However, the comment does not provide specific suggestions on how to conduct the ablation study or which methods from the past decade should be compared. While it highlights critical areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, as it points out important areas for enhancement but lacks detailed guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should include more theoretical results on more complicated models beyond SVC. However, it does not provide specific guidance on which models should be considered or how to approach the theoretical analysis for these models. The action is implicit and somewhat vague, as the authors are left to infer which models to focus on and how to develop the theoretical analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should include more theoretical results on more complicated models beyond SVC. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or chapter where theoretical results are discussed. Additionally, it does not provide specific examples of models that should be included or how the theoretical analysis should be expanded. Without explicit references to sections or detailed guidance, the authors cannot confidently determine which parts of the paper need revision. Therefore, this comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should include more theoretical results on more complicated models beyond SVC. However, it does not provide any specific examples, reasoning, or references to support why this is necessary or how it would enhance the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper should include more theoretical results on more complicated models beyond SVC. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which models should be considered or how to approach the theoretical analysis for these models. The feedback is 3 as it points out a direction for expansion, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that more ablation studies should be provided, specifically to demonstrate the necessity of the proposed DA Inversion. It also critiques the existing results in Figure 11, indicating that they are insufficient to demonstrate the necessity of the proposed method. This feedback provides a clear and direct action for the authors to take, which is to conduct additional ablation studies to strengthen their argument. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that more ablation studies should be provided, specifically to demonstrate the necessity of the proposed DA Inversion. It critiques the existing results in Figure 11, indicating that they are insufficient. However, the comment does not specify which part of the paper these results are presented in, making it weakly grounded. The suggestion to provide more ablation studies is specific, as it clearly identifies what is missing. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more ablation studies are needed to demonstrate the necessity of the proposed DA Inversion. The reviewer critiques the existing results in Figure 11, stating that they are insufficient. However, the comment does not provide specific examples or detailed reasoning to support why the current results are inadequate. This lack of detailed justification makes the claim 3, as the authors would need to infer the exact issues with the current results and how additional ablation studies could address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that more ablation studies should be conducted to demonstrate the necessity of the proposed DA Inversion. It critiques the existing results in Figure 11, indicating that they are insufficient. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper by conducting additional analyses. However, the comment could be more helpful if it offered specific examples of what types of ablation studies would be beneficial or how they could be conducted. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the necessity of clustering in the second phase of training if a linear regressor is used for evaluation. It suggests that a clear ablation study should be presented to address this issue. While the comment implies that the authors should conduct an ablation study to determine the impact of clustering, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the ablation study or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the necessity of clustering in the second phase of training and suggests that a clear ablation study should be presented. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point questions the necessity of clustering in the second phase of training if a linear regressor is used for evaluation. It suggests that a clear ablation study should be presented to address this issue. However, the comment lacks specific reasoning or evidence to support why clustering might not be necessary or how it could impact the results. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3, as it provides a logical suggestion but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a pertinent question about the necessity of clustering in the second phase of training if a linear regressor is used for evaluation. It suggests that a clear ablation study should be presented to address this issue, which is a valuable piece of feedback. By highlighting this potential area for improvement, the comment provides the authors with a specific direction to enhance their draft. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it identifies a critical area for improvement and suggests a clear action for the authors to take."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the figures, specifically mentioning Figure 2a, where the forgetting is not as drastic as in class incremental learning and even shows a slight increase near epoch 150. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest ways to address this issue, such as providing alternative explanations, revising the figures, or discussing the implications of this observation. Without actionable guidance, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig2a,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the forgetting rate in the figure, noting that it is not as drastic as in class incremental learning and even shows a slight increase near epoch 150. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the forgetting rate in Figure 2a is not as drastic as in class incremental learning and even shows a slight increase near epoch 150. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the figures, particularly Figure 2a, where the forgetting rate is not as drastic as in class incremental learning and even shows a slight increase near epoch 150. This feedback is 3 as it points out a potential weakness in the presentation of the results, prompting the authors to reconsider their analysis or interpretation of the forgetting rate. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their presentation. To be more helpful, the comment could include suggestions for alternative analyses, explanations, or visualizations to clarify the results. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should highlight the datadependent nature of their approximation results, specifically mentioning the covariance spectrum. While the comment implies that this should be done in the abstract, it does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to highlight this aspect or what specific information should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should highlight the datadependent nature of their approximation results, specifically mentioning the covariance spectrum. However, it does not specify which part of the paper this suggestion pertains to, such as the abstract, introduction, or results section. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to highlight the datadependent nature of the results, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should highlight the datadependent nature of their approximation results, specifically mentioning the covariance spectrum. The comment provides a clear and logical reasoning for why this information should be emphasized, as it is relevant to the understanding of the results. However, it does not provide specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment suggests that the authors should highlight the datadependent nature of their approximation results, specifically mentioning the covariance spectrum. This is a clear and actionable piece of feedback that can help the authors improve the clarity and comprehensiveness of their paper. By emphasizing this aspect, the authors can provide a more complete understanding of their results and their limitations. However, the comment could be more helpful if it included specific suggestions on how to incorporate this information into the abstract or other sections of the paper. Overall, the feedback is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks for clarification regarding the meaning of RMSD in Figure 3. It provides a specific question about whether RMSD is the distance between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. This feedback is clear and direct, giving the authors a concrete action to take by clarifying the meaning of RMSD in their figure. The explicit nature of the request and the detailed guidance on what needs to be clarified make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the meaning of RMSD in the figure. The comment provides a direct question about whether RMSD is the distance between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. This level of detail guides the authors on what aspect of the figure needs clarification, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the meaning of RMSD in Figure 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual question seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area of confusion in the paper, namely the meaning of RMSD in Figure 3. It provides a clear and actionable suggestion by asking the authors to clarify whether RMSD is the distance between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. This feedback is valuable as it directs the authors to clarify an important aspect of their results, which can enhance the clarity and understanding of their work for readers. By addressing this point, the authors can improve the comprehensibility and impact of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It also poses a question about whether there could be a smooth regret scaling without phase transitions that would still hold. While the comment implies that the authors should address these points, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on what specific aspects of the treatment or question should be addressed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It also poses a question about whether there could be a smooth regret scaling without phase transitions that would still hold. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The authors might infer that it relates to the sections discussing regret scaling or phase transitions, but this is not explicitly stated. The comment is specific in its request for a more thorough treatment and the question posed, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It poses a question about whether there could be a smooth regret scaling without phase transitions that would still hold. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that a more thorough treatment is necessary. The suggestion is 3, as it highlights a potential area for improvement, but it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It poses a question about whether there could be a smooth regret scaling without phase transitions that would still hold. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically the need for a more comprehensive analysis of the phase transitions. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as proposing alternative analyses or experiments. While it points out a relevant area for further exploration, the feedback could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the paper, noting that while previous robust RL methods are cited, their comparison is missing. It suggests that if GAD or EG already include these prior works, the authors should be explicit about it. This feedback provides a clear action for the authors to take, which is to either include a comparison or clarify the inclusion of these prior works. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment addresses the absence of a comparison to previous robust RL methods, despite citing them (e.g., RARL). It suggests that if GAD or EG already include these prior works, the authors should be explicit about it. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the discussion or results sections where comparisons are typically made. The comment is specific in its request for explicit inclusion of prior works, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to previous robust RL methods, despite citing them (e.g., RARL). The comment suggests that if GAD or EG already include these prior works, the authors should be explicit about it. This claim is 3 as it highlights a potential gap in the paper\"s comparison section. However, it lacks specific examples or detailed reasoning on why this comparison is crucial or how it would enhance the paper. Providing more context or references to similar works would strengthen the claim, making it more verifiable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by noting the absence of a comparison to previous robust RL methods, despite citing them. It suggests that if GAD or EG already include these prior works, the authors should be explicit about it. This feedback is clear and actionable, as it directs the authors to either include a comparison or clarify the inclusion of these prior works. By addressing this issue, the authors can enhance the comprehensiveness and rigor of their work. However, the comment could be more helpful if it provided specific examples of prior works to consider or suggested how the comparison might be integrated into the paper. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more details about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. While the comment implies that these details should be included, it does not specify how the authors should present this information or what specific aspects need to be addressed. The action is implicit and somewhat vague, as the authors can infer that they need to add more details but are not given explicit guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details should be provided about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. However, it does not specify which part of the paper these details should be added to, making it weakly grounded. The comment is specific in identifying the areas that need more detail, such as the choice of hyperparameters and the learning objectives. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details should be provided about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. However, it does not provide any reasoning, examples, or references to support why these details are necessary or how they would improve the paper. Without additional context or justification, the authors may find it challenging to understand the importance of these details or how to address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that more details should be provided about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. This feedback is clear and actionable, as it directs the authors to enhance the clarity and comprehensiveness of their work by providing additional details. However, the comment could be more helpful if it offered specific suggestions on what aspects of these details should be included or how they might impact the paper\"s results. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the rationale behind the relationship between HIS and the negative inverse of mean response time. However, it does not provide any explicit or implicit guidance on how the authors should address this question or improve their draft. There is no suggestion for further explanation, clarification, or modification. As a result, the authors are left without any actionable steps to take in response to this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the rationale behind a specific relationship mentioned in the paper, specifically asking why HIS is proportional to the negative inverse of mean response time. However, it does not specify which part of the paper this relationship is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its inquiry about the relationship but lacks grounding as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind a specific relationship mentioned in the paper, specifically asking why HIS is proportional to the negative inverse of mean response time. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the rationale behind a specific relationship mentioned in the paper, specifically asking why HIS is proportional to the negative inverse of mean response time. While it identifies a potential area of confusion or lack of clarity, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the relationship. The comment lacks depth and actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, as it points out a potential issue but does not offer meaningful guidance for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the choice of the sparse representation learning method and suggests that the authors should compare FTA as a baseline in both supervised learning and RL settings. It also implies that a rigorous comparison is necessary for an empirical paper. While the comment explicitly questions the choice of the method and suggests a comparison with FTA, it does not provide specific guidance on how to conduct the comparison or what aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to address the choice of method and the comparison with FTA but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the choice of the sparse representation learning method and suggests comparing FTA as a baseline in both supervised learning and RL settings. It also mentions the need for a rigorous comparison in an empirical paper. However, the comment does not specify which part of the paper discusses the sparse representation learning method or the experiments, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it challenging to pinpoint the exact parts. The comment is specific in its request for a rigorous comparison, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the choice of the sparse representation learning method and suggests that FTA should be compared as a baseline. The reviewer questions the rationale behind the choice of method and the omission of FTA in the RL setting. The comment provides a logical reasoning by pointing out the need for a rigorous comparison in an empirical paper, which is a common expectation in such studies. However, it lacks specific examples or references to support the claim that FTA should be included as a baseline. This makes the claim 3, as it provides a logical basis but requires more detailed justification or evidence to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important points that can help the authors improve their draft. It questions the rationale behind the choice of the sparse representation learning method, suggesting that the authors should provide a justification for this selection. Additionally, it points out a gap in the experimental comparison by noting that FTA is compared in a supervised learning setting but not in a RL setting, which is necessary for a rigorous comparison. The comment also emphasizes the importance of a rigorous comparison in an empirical paper, which is a valuable insight for the authors. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to conduct a more comprehensive comparison. Overall, the feedback is 4 as it identifies key areas for improvement and provides a clear direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors describe a particular choice of shift and scaling on page 4, line 154, and state that it is the more appropriate choice. However, the comment highlights that the authors do not explain why this choice is more appropriate. This feedback implies that the authors should provide an explanation for their choice, which is an explicit action. The comment is 3 because it clearly identifies the need for an explanation but does not provide specific guidance on how to construct that explanation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p.4, l.154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of explanation for the choice of shift and scaling, which is a clear and actionable issue. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors describe a particular choice of shift and scaling on page 4, line 154, and state that it is the more appropriate choice, but neglect to explain why. This is a claim that requires justification, as the authors need to provide an explanation for their choice. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors describe a particular choice of shift and scaling on page 4, line 154, and state that it is the more appropriate choice. However, the comment points out that the authors do not provide an explanation for why this choice is more appropriate. This feedback is clear and actionable, as it highlights a gap in the paper that the authors need to address by providing an explanation for their choice. By doing so, the authors can enhance the clarity and justification of their work. Therefore, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions on how to construct the explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere should be revised. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment leaves no ambiguity about what needs to be changed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the use of these terms and suggests that they should be revised. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses a concern about the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere, suggesting that it should be revised. However, the comment does not provide any reasoning or evidence to support why this term is problematic or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of \"partial inference of GFlowNets\" in the title and \"partial inference\" elsewhere, suggesting that it should be revised. This feedback is clear and actionable, providing the authors with a direct suggestion to improve their draft by revising the terminology used. However, the comment could be more helpful if it explained why the current terminology is problematic or how it could be improved. Despite this, the comment is 4 as it directs the authors to a specific area that needs attention, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should consider other metrics beyond bertscore to measure the stealthiness of generated content. However, it does not provide specific examples of these alternative metrics or guidance on how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors are left to infer which metrics to consider and how to integrate them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should consider other metrics beyond bertscore to measure the stealthiness of generated content. However, it does not specify which part of the paper discusses bertscore or where the authors should consider additional metrics. This makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in suggesting the need for alternative metrics but lacks grounding, as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper only uses bertscore to measure the similarity of generated text and suggests that there are other metrics that could measure stealthiness. However, the comment does not provide specific examples of these alternative metrics or explain why they are more suitable for measuring stealthiness. This lack of detailed justification or references makes the claim 3, as the authors would need to explore and justify the use of these alternative metrics themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper by pointing out that it only uses bertscore to measure the similarity of generated text, without discussing other metrics that could measure stealthiness. This feedback is 3 as it highlights an area for improvement by suggesting that the paper should consider additional metrics. However, the comment lacks specific guidance on which alternative metrics to explore or how to incorporate them into the paper. To be more helpful, the comment could provide examples of other metrics or suggest ways to integrate them into the analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the notation and clarity of the paper. It explicitly mentions that the basic notation is not defined and that the authors need to clearly highlight the issues with existing estimators. Additionally, it provides specific examples of notation that is unclear, such as \"the dimensionality p,\" \"the unit ball S p,\" and \"the constant d 2.\" The comment also suggests clarifying the heuristic nature of Algorithm 2. These explicit actions and concrete suggestions provide clear guidance on how to improve the draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"p.2 or Eq. 3,\" \"Alg. 1,\" \"Alg. 2,\" \"Thm. 2,\" and \"Eq. 5,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it details the issues with notation, such as the lack of definition for \"p,\" \"S p,\" \"( v ) \u2297 2,\" \"\u0398,\" and \"d 2,\" and suggests clarifying the heuristic nature of Algorithm 2. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point consists of factual statements and questions, such as \"Basic notation is not defined\" and \"Clarity about the heuristic nature of Alg.\" These statements do not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several issues with the clarity and notation of the paper. It points out that the basic notation is not defined, which makes it difficult for readers to understand the paper. The comment provides specific examples of unclear notation, such as \"the dimensionality p,\" \"the unit ball S p,\" and \"the constant d 2,\" and suggests that these should be clarified. Additionally, it highlights the need to clearly highlight the issues with existing estimators. The comment also raises a question about the heuristic nature of Algorithm 2, which could be addressed by the authors. While the feedback is clear and actionable, it could be more helpful if it provided specific suggestions on how to clarify the notation or address the issues with existing estimators. Overall, the comment is 4 as it directs the authors to improve the clarity and comprehensibility of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper claims that certain loss functions are new, while they are not unheard of in the field of medical imaging. It suggests that the authors should elaborate on which parts of the loss functions are new. This feedback is explicit in its request for clarification and provides a clear action for the authors to take. However, it does not specify how the authors should elaborate on the new aspects of the loss functions, which could be considered vague. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper that addresses the use of loss functions, allowing the authors to accurately identify the section being addressed. It is also specific because it points out a potential issue with the claim that certain loss functions are new, suggesting that the authors should elaborate on which parts of the loss functions are new. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper states that certain loss functions are new, while they are not unheard of in the field of medical imaging. The reviewer suggests that the authors should elaborate on which parts of the loss functions are new. This claim is 3 as it points out a potential discrepancy in the paper\"s claims, but it lacks specific examples or references to support the assertion that the loss functions are not entirely new. The authors would need to investigate the claim further to determine its validity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim that certain loss functions are new, while they are not unheard of in the field of medical imaging. It suggests that the authors should elaborate on which parts of the loss functions are new, providing a clear and actionable piece of feedback. This guidance is valuable as it directs the authors to clarify their claims and enhance the transparency of their work. However, the comment could be more helpful if it offered specific examples or suggestions on how to elaborate on the new aspects of the loss functions. Overall, the comment is 4 as it effectively points out a weakness and offers a constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experimental results, like those in many GNN papers, justify theoretical statements but do not show significant improvements in reallife datasets. It also criticizes the comparison on the ZINC dataset, suggesting that it is lacking. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their experimental results. The feedback lacks actionable details, such as suggesting specific changes or improvements that could be made to enhance the experimental section. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experimental Results\" and \"Table 5 in 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental results, noting that they justify theoretical statements but do not show significant improvements in reallife datasets. The comment further specifies the issue with the comparison on the ZINC dataset, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results, like those in many GNN papers, justify theoretical statements but do not exhibit significant improvements in reallife datasets. It also criticizes the comparison on the ZINC dataset, suggesting it is lacking. The comment provides a specific reference to Table 5 in 1, which supports the claim about the ZINC dataset. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the lack of significant improvements in reallife datasets. This makes the claim 3, as it provides some support but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that they justify theoretical statements but do not demonstrate significant improvements in reallife datasets. It also points out a lack of clarity in the comparison on the ZINC dataset, suggesting that it is not sufficiently detailed or informative. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. Providing more detailed feedback, such as recommending additional experiments or analyses, could enhance the comment\"s helpfulness. Therefore, the comment is 3, as it directs the authors\" attention to critical areas but does not fully support them in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the SLM may perform better than larger models due to limited data availability, but it also points out that larger models typically perform better. The reviewer provides an example from Figure 3 (b) to support this claim, comparing LucaOne with BSM models and BSM270M with BSM110M. While the comment highlights a potential issue with the SLM\"s performance, it does not explicitly instruct the authors to address this concern or suggest ways to improve the draft. The action is implicit and somewhat vague, as the authors can infer that they need to address the performance comparison but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3 (b),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue by comparing the performance of LucaOne with BSM models and the BSM270M model with the BSM110M model, providing a clear basis for the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the SLM may perform better than larger models due to limited data availability, but it also points out that larger models typically perform better. The reviewer supports this claim by referencing specific experiments, such as Figure 3 (b), where LucaOne performs better than BSM models, and BSM270M performs better than BSM110M. This provides a logical and verifiable basis for the claim, as it uses concrete examples to illustrate the point. Therefore, the comment is 4, as it offers a clear rationale but could be strengthened with additional references or detailed explanations. The score aligns with a label of 4.", "helpfulness_rationale": "The review comment addresses a potential issue with the paper\"s claims regarding the performance of the SLM compared to larger models. It points out that larger models typically perform better, even in the context of limited data availability, and provides specific examples from Figure 3 (b) to support this claim. This feedback is valuable as it highlights a potential weakness in the paper\"s argument and provides concrete evidence to consider. However, the comment could be more helpful if it suggested ways to address this issue or offered alternative explanations for the observed performance differences. Overall, the comment is 4 as it identifies a critical area for improvement and provides some guidance, but it could be more comprehensive with additional suggestions or analysis."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out inconsistencies in the notation, specifically mentioning the use of \"nu\" and its variation across different sections of the paper, such as Figures 2 & 3, Alg 1, and Page 4 & Figure 4. While the comment identifies the issue of inconsistent notation, it does not provide explicit guidance on how to resolve it or suggest specific actions for the authors to take. The authors are left to infer that they need to standardize the notation across the paper, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, including Figures 2 & 3, Alg 1, and Page 4 & Figure 4, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of inconsistent notation, particularly with the use of \"nu,\" which is clearly detailed. This provides the authors with a clear understanding of what needs to be addressed in terms of consistency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation is inconsistent, specifically mentioning the use of \"nu\" and its variation across different sections of the paper. The reviewer provides specific examples, such as Figures 2 & 3, Alg 1, and Page 4 & Figure 4, where the notation changes. This level of detail supports the claim, making it 4. However, the comment could be strengthened by providing more context or explanation about why this inconsistency is problematic or how it affects the paper\"s clarity. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, pointing out inconsistencies in the use of \"nu\" across different sections, such as Figures 2 & 3, Alg 1, and Page 4 & Figure 4. This feedback is clear and actionable, as it highlights a potential source of confusion for readers and suggests that the authors should standardize their notation to ensure consistency throughout the paper. By addressing this issue, the authors can improve the clarity and readability of their work. However, the comment could be more helpful if it provided specific suggestions on how to resolve the inconsistency or offered examples of how to standardize the notation. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests conducting more experiments in more challenging tasks, such as dexterous manipulations in Adroit, to validate the effectiveness of the proposed method. This is a clear and direct action for the authors to take, providing a specific task and reference to guide their experimental design. The comment is concrete in its instruction, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting more experiments in more challenging tasks, specifically mentioning dexterous manipulations in Adroit. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The reference to Adroit provides some context, but without explicit grounding, the authors may find it challenging to determine where to incorporate these suggestions. The comment is specific in suggesting additional experiments but lacks full grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting more experiments in more challenging tasks, specifically mentioning dexterous manipulations in Adroit. This suggestion is based on a logical reasoning that the proposed method should be tested in more challenging scenarios to validate its effectiveness. However, the comment does not provide specific examples or references to support why dexterous manipulations in Adroit are particularly relevant or challenging. While the suggestion is logical, it lacks detailed justification or evidence, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment suggests conducting more experiments in more challenging tasks, specifically mentioning dexterous manipulations in Adroit. This feedback is clear and actionable, providing the authors with a specific direction for expanding their experimental validation. By suggesting a particular task and referencing a relevant study, the comment offers a concrete way for the authors to enhance the robustness and applicability of their proposed method. However, the comment could be more helpful if it included additional guidance on how to design these experiments or what specific metrics to focus on. Overall, the comment is 4 as it provides a clear and actionable suggestion for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the summary of certain papers in the introduction, specifically noting that some papers assume linear separability. It questions whether the statement \"the feature direction of each arbitrary training sample could act as a perfect linear classifier\" refers to orthogonally separable data. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the assumption. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the assumptions or provide additional context. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and references specific papers (Williams et al. (2019); Lyu et al. (2021); Boursier et al. (2022); Wang & Ma (2023)) that are being discussed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out a potential issue with the summary of these papers, noting that some assume linear separability and questioning whether a particular statement refers to orthogonally separable data. This provides clear guidance on what needs to be addressed or clarified. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the fairness of the summary of certain papers in the introduction, specifically noting that some papers assume linear separability. It challenges the statement \"the feature direction of each arbitrary training sample could act as a perfect linear classifier\" by questioning whether it refers to orthogonally separable data. While the comment raises a valid point, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to investigate the referenced papers to understand the basis of the critique. Therefore, the comment is 3, as it provides a logical basis for the claim but requires further elaboration or evidence to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the summary of certain papers in the introduction, specifically noting that some papers assume linear separability. It questions the fairness of this summary and points out a specific assumption that seems even stronger. The comment also raises a question about whether the statement \"the feature direction of each arbitrary training sample could act as a perfect linear classifier\" refers to orthogonally separable data. While the comment highlights a critical area for clarification, it does not provide specific guidance on how the authors should address this issue or improve the summary. The feedback is 3 as it prompts the authors to reconsider their summary and clarify assumptions, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the paper\"s persample weight tuning method, which relies on the influence function. It explains that the theoretical approximation of each sample\"s contribution from Taylor\"s firstorder expansion is not valid when the upweight (parameter weights in this paper\"s context) is far from 0. The reviewer suggests that if this is the case, the influence function might not accurately reflect each sample\"s influence, making the weights unreliable. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific actions to take. The authors are left to infer that they should investigate the validity of the influence function under different conditions, but without concrete steps or suggestions, the comment remains 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"persample weight tuning method\" and the \"influence function,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by explaining that the theoretical approximation of each sample\"s contribution from Taylor\"s firstorder expansion is not valid when the upweight (parameter weights in this paper\"s context) is far from 0. This provides clear guidance on what needs to be addressed regarding the validity of the influence function. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s persample weight tuning method relies on the influence function, but the explanation of the influence function holds only when the upweight is very close to 0. The reviewer provides a logical reasoning by explaining that the theoretical approximation of each sample\"s contribution from Taylor\"s firstorder expansion is not valid when the upweight is far from 0. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s persample weight tuning method, which relies on the influence function. It explains that the theoretical approximation of each sample\"s contribution from Taylor\"s firstorder expansion is not valid when the upweight (parameter weights in this paper\"s context) is far from 0. This observation is important as it highlights a limitation in the method\"s applicability and suggests that the weights produced might be unreliable. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the method\"s robustness. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of centering as a canonicalization method for partial shapes or scenes, suggesting that the authors should address this issue. It also points out that the experiment with up to 50% missing points is merely an augmentation and that the groundtruth center is provided, which may not be the case in general when training with partial shapes. While the comment identifies an area for improvement, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors are left to infer what specific changes or additions are needed to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Centering in Partial Shapes and Scenes,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the applicability of centering as a canonicalization method for partial shapes or scenes. Additionally, it provides a specific example of an experiment with up to 50% missing points, which is an augmentation but does not reflect the general case of training with partial shapes. This level of detail provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the applicability of centering as a canonicalization method for partial shapes or scenes. It suggests that the authors should address this issue, but the comment does not provide specific examples or references to support why centering might not be welldefined in these contexts. The claim is 3 as it highlights a potential issue, but it lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the applicability of centering as a canonicalization method for partial shapes or scenes. It highlights that while centering may be effective for complete shapes, it might not be welldefined for partial shapes or scenes. The comment also points out that the experiment with up to 50% missing points is merely an augmentation, suggesting that the groundtruth center is provided, which may not be the case in general when training with partial shapes. This feedback is 3 as it prompts the authors to consider the limitations of their approach and potentially explore alternative methods for canonicalization in partial shapes or scenes. However, the comment could be more helpful if it provided specific suggestions or examples of how to address this issue. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific experiment to conduct, which is to ensemble models trained with the proposed negative augmentations and without them to see if it improves performance. This suggestion is explicit and provides a clear action for the authors to take. The comment also offers a concrete example of how to implement this action by referencing a similar approach in 1. This level of detail and guidance makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method of learning less about texture semantics by adding negative samples that share texture semantics with anchor images. It also suggests a specific experiment to conduct, which is to ensemble models trained with the proposed negative augmentations and without them to see if it improves performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed method of learning less about texture semantics by adding negative samples that share texture semantics with anchor images may not be effective. It references a similar approach in 1 and suggests an experiment to ensemble models trained with and without the proposed negative augmentations to see if it improves performance. This provides a logical reasoning and a specific suggestion for further exploration, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples from 1 to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential limitation in the proposed method, which aims to learn less about texture semantics by adding negative samples that share texture semantics with anchor images. It suggests that this approach might not be effective, as texture semantics could still be helpful in some cases. The comment provides a specific suggestion for further exploration by recommending an ensemble experiment with models trained with and without the proposed negative augmentations. This feedback is clear and actionable, offering a concrete way for the authors to test and potentially improve their method. However, it could be more helpful if it included additional context or examples to fully explain the rationale behind the suggestion. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sample efficiency of Eq. 7 compared to Eq. and suggests that the authors should guarantee that D i sufficiently goes through all possible transition probabilities. However, it does not provide explicit instructions or concrete steps on how to address this concern. The authors are left to infer that they need to provide a justification or evidence for the claim regarding sample efficiency and the transition probabilities. While the comment implies an action, it lacks specificity and detailed guidance, making it 3.", "grounding_specificity_rationale": "The comment raises questions about the sample efficiency of Eq. 7 compared to Eq. and the sufficiency of D i in covering all possible transition probabilities. It references specific pages (5 and 6) and the Appendix B, providing some grounding by indicating the sections where these issues are discussed. However, the comment does not specify what needs to be addressed or improved in these sections, making it weakly grounded but specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the sample efficiency of Eq. 7 compared to Eq. and the sufficiency of D i in covering all possible transition probabilities. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concerns and address them effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the sample efficiency of Eq. 7 compared to Eq. and the sufficiency of D i in covering all possible transition probabilities. It also notes a difference in the partitioning method used, which is important for understanding the context of the question. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these concerns or improve their draft. While it identifies potential areas for clarification or improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the method used to form clusters for tokens in Figure 1, specifically noting that this is unclear in Section 3. While the comment identifies a specific area of confusion, it does not provide explicit guidance or suggestions on how the authors might clarify this aspect of their work. The action is implicit, as the authors need to infer that they should provide more detailed information about the clustering process. Additionally, the comment lacks concrete details on how to address the issue, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the method used to form clusters for tokens in Figure 1, specifically noting that this is unclear in Section 3. This provides full grounding as it explicitly mentions both the figure and the section, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is unclear, namely the clustering method for tokens. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the method used to form clusters for tokens in Figure 1, noting that it is unclear in Section 3. This is a factual statement seeking clarification, as it does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not contain any claims or subjective elements. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the method used to form clusters for tokens in Figure 1, noting that it is unclear in Section 3. This feedback is 3 as it identifies a potential area of confusion in the paper and prompts the authors to clarify their methodology. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending additional explanations or examples. While it points out a weakness, it does not fully support the authors in improving their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of SimNPO, noting that it introduces two additional hyperparameters that require manual adjustment for optimal performance. This increases the complexity and time cost of experiments, potentially limiting its application in realworld settings with large language models. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or mitigate the impact on complexity. Without guidance on potential solutions or alternatives, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the introduction of two additional hyperparameters in SimNPO that require manual adjustment for optimal performance. This increases the complexity and time cost of experiments, potentially limiting the method\"s application in realworld settings with large language models. However, the comment does not specify which part of the paper discusses these hyperparameters or their impact on experiments. While the authors might infer that it relates to the methodology or experimental sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the issue with the hyperparameters but lacks grounding, aligning with a score of 3.", "verifiability_rationale": "The review point claims that SimNPO introduces two additional hyperparameters that significantly increase the complexity and time cost of experiments, limiting its application in realworld settings. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion about the impact of these hyperparameters on performance or applicability. Without such evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant limitation of SimNPO, specifically the introduction of two additional hyperparameters that require manual adjustment for optimal performance. This increases the complexity and time cost of experiments, potentially limiting the method\"s applicability in realworld settings with large language models. While the comment highlights a critical issue, it does not provide suggestions or guidance on how the authors might address this limitation or mitigate its impact. Without actionable advice, the authors are left with a clear understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it points out a significant issue but lacks depth and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the work for placing too much emphasis on affordance prompting, which is described as overengineered. It provides a specific example, such as the Pick&place example, to illustrate the lack of advantage demonstrated by affordance prompting. While the comment identifies a potential issue with the focus on affordance prompting, it does not provide explicit guidance on how the authors should address this concern or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider the emphasis on affordance prompting and potentially provide more evidence of its advantages. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the work for placing too much emphasis on affordance prompting, which is described as overengineered. It provides a specific example, such as the Pick&place example, to illustrate the lack of advantage demonstrated by affordance prompting. However, the comment does not specify which part of the paper discusses affordance prompting or where the Pick&place example is presented. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in its critique, it lacks grounding, as it does not explicitly mention the sections or examples being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work places too much emphasis on affordance prompting, which is described as overengineered. It provides a specific example, such as the Pick&place example, to illustrate the lack of advantage demonstrated by affordance prompting. This claim is 3 as it provides a specific example to support the critique, but it lacks detailed reasoning or references to substantiate the claim fully. The authors would need to further explore the example to understand the critique fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the work, namely that it places too much emphasis on affordance prompting, which is described as overengineered. It provides a concrete example, such as the Pick&place example, to illustrate the lack of advantage demonstrated by affordance prompting. This feedback is clear and actionable, as it prompts the authors to reconsider their focus on affordance prompting and potentially provide more evidence of its benefits. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative approaches. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. This provides a clear and direct action for the authors to take, which is to conduct ablation studies to validate the effectiveness of each component. The comment is specific and provides a concrete step for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. However, it does not specify which parts of the paper discuss the proposed methodology or where the ablation studies should be conducted. This lack of explicit reference to specific sections or elements of the paper makes it weakly grounded. The comment is specific in its request for ablation studies, but without clear grounding, the authors may struggle to determine where these studies should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. This claim is based on the complexity of the proposed methodology, which involves multiple components. The suggestion is logical and aligns with common practices in evaluating the contribution of individual components in a complex system. However, the comment lacks specific examples or references to similar studies that have successfully used ablation studies to validate their methodology. This makes the claim 3, as it provides a logical rationale but lacks detailed evidence or examples to fully substantiate the need for ablation studies.", "helpfulness_rationale": "The review comment identifies a critical area for improvement by suggesting that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by validating the contribution of each component. However, the comment could be more helpful if it offered guidance on how to conduct these ablation studies or what specific components should be tested. Despite this, the suggestion is valuable and provides the authors with a clear path to strengthen their draft. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the conclusion regarding the necessity of the instructiontuning stage in MoE models. It suggests that the performance improvement could be attributed to the additional training cost rather than the instructiontuning stage itself. While the comment implies that the authors should provide a more convincing demonstration of the necessity of the instructiontuning stage, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the conclusion about the necessity of the instructiontuning stage in MoE models, specifically questioning whether the performance improvement could be attributed to the additional training cost rather than the instructiontuning stage itself. However, it does not specify which part of the paper discusses this conclusion, making it weakly grounded. The comment is specific in its critique of the conclusion and suggests a potential alternative explanation for the performance improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the conclusion about the necessity of the instructiontuning stage in MoE models, suggesting that the performance improvement could be attributed to the additional training cost rather than the instructiontuning stage itself. The comment provides a logical reasoning by pointing out the potential impact of the additional training cost, which is a relevant consideration. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the claim to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the conclusion regarding the necessity of the instructiontuning stage in MoE models. It questions whether the performance improvement could be attributed to the additional training cost rather than the instructiontuning stage itself. This is a relevant point that the authors should consider, as it challenges the basis of their conclusion. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or conduct further analysis to substantiate their claim. While it identifies a potential issue, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights that the evaluation setup is outdated, as newer models have been released since the original evaluation. It suggests testing the approach on more challenging and representative finetuning setups, such as instruction tuning on Alpaca/OASST or other instruction finetuning datasets. This feedback provides a clear and explicit action for the authors to take, which is to update their evaluation setup to include newer models and more challenging scenarios. The suggestion is concrete, as it specifies the types of datasets to consider for testing. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation setup, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the evaluation setup is outdated due to the release of newer models and the advancement of quality in current models. Additionally, the comment suggests testing the approach on more challenging and representative finetuning setups, such as instruction tuning on Alpaca/OASST or other instruction finetuning datasets. This provides clear guidance on what needs to be addressed to improve the evaluation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation setup is outdated due to the release of newer models and advancements in quality. It provides specific examples of newer models, such as Llama3, Llama3.1, Qwen2.5, and gemma2, which have been released more than a year after the original evaluation. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by including references or links to these newer models, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation setup, noting that it is outdated due to the release of newer models and advancements in quality. It provides specific examples of newer models that have been released since the original evaluation, such as Llama3, Llama3.1, Qwen2.5, and gemma2. This feedback is valuable as it highlights the need for the authors to update their evaluation to reflect the current state of the art. Additionally, the comment suggests testing the approach on more challenging and representative finetuning setups, such as instruction tuning on Alpaca/OASST or other instruction finetuning datasets, to fully appreciate the efficacy of SparseMeZO. This suggestion is actionable and provides clear guidance for improving the evaluation process. Overall, the comment is 5 as it offers specific and constructive feedback that can significantly enhance the paper."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of logical coherence in the second section, where many related works are presented, resulting in a somewhat disorganized content. However, it does not provide specific guidance on how to improve the logical coherence or suggest ways to organize the content more effectively. The comment implies that the authors should address the issue of logical coherence, but it lacks concrete details on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment mentions the \"second section\" and the \"lack of logical coherence,\" which provides some grounding as the authors can infer that it relates to the section where related works are presented. However, it does not specify which part of the section is problematic or what aspects of the logical coherence are lacking, making it weakly grounded. The comment is specific in identifying the issue of disorganization but lacks detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the second section lacks logical coherence, resulting in a somewhat disorganized content. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks evidence or references to substantiate the assertion, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the second section of the paper, noting that while many related works are presented, the lack of logical coherence results in a somewhat disorganized content. This feedback is 3 as it points out a potential weakness in the organization and coherence of the paper. However, it lacks specific suggestions or guidance on how the authors might improve the logical coherence or reorganize the content. Without actionable advice, the authors may struggle to address the issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to mention the language they focus on to retrieve Reddit posts. This is a clear and direct action, providing the authors with a specific task to complete. The comment is concrete, as it specifies exactly what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment explicitly instructs the authors to mention the language they focus on to retrieve Reddit posts, providing clear guidance on what needs to be addressed. However, it does not specify which part of the paper this information should be included in, such as the methodology or results sections. While the authors can infer that it relates to the methodology or data collection, the comment lacks full grounding as it does not explicitly mention a specific section. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point is a request for clarification, asking the authors to specify the language they focus on to retrieve Reddit posts. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, requesting the authors to specify the language they focus on to retrieve Reddit posts. This feedback is specific and provides a direct way for the authors to enhance their draft by addressing a missing detail. By including this information, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it provided additional context or explained why this information is important. Overall, the comment is 4 as it guides the authors toward a specific improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the paper lacks comparisons with recent works, specifically mentioning 1. This provides a clear action for the authors to take, which is to include comparisons with recent works, particularly those referenced. The comment is explicit and provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment lacks grounding as it does not specify which part of the paper lacks comparisons with recent works. It also lacks specificity because it does not provide details on which recent works should be compared or why these comparisons are important. Without specific guidance, the authors cannot effectively address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks comparisons with recent works, specifically mentioning \"1.\" However, it does not provide any further explanation or justification for why these comparisons are necessary or how they would enhance the paper. Without additional context or reasoning, the claim is vague and lacks verifiability. Therefore, it is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparisons with recent works, specifically mentioning 1. This feedback is valuable as it highlights an area where the authors can enhance the relevance and impact of their work by incorporating comparisons with current literature. However, the comment does not provide specific suggestions on which recent works to compare or how to integrate these comparisons into the paper. While it directs the authors to a critical area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the applicability of TSG (TimestepSpecific Guidance) in diffusion models that do not embed class labels into timesteps, such as UViT. However, it does not provide any explicit or implicit actions for the authors to take. The question is purely informational and does not offer guidance on how the authors might address this issue or improve their draft. As a result, the comment lacks actionability and provides no direction for the authors to follow. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment raises a question about the applicability of TSG (TimestepSpecific Guidance) in diffusion models that do not embed class labels into timesteps, specifically mentioning UViT as an example. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the applicability of TSG in a particular context, but without clear grounding, the authors may struggle to determine where this question fits within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the applicability of TSG (TimestepSpecific Guidance) in diffusion models that do not embed class labels into timesteps. It does not contain a claim or opinion that requires verification. It is a factual inquiry that does not suggest changes or offer judgments. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of TSG (TimestepSpecific Guidance) in diffusion models that do not embed class labels into timesteps, specifically mentioning UViT as an example. While the comment identifies a potential area of interest, it lacks depth and does not provide any actionable feedback or suggestions for the authors to address this issue. The question is more of a curiosity than a constructive critique, leaving the authors without clear guidance on how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the reproducibility of the paper is limited and suggests that the authors release their training code, dialogue dataset, and model checkpoints to facilitate verification of the claims and allow reviewers to try out the model. The comment provides a clear and direct action for the authors to take, which is to make these resources available through anonymous repositories. This guidance is specific and concrete, leaving no ambiguity about what needs to be done. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of limited reproducibility, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the action needed, which is to release the training code, dialogue dataset, and model checkpoints through anonymous repositories. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the reproducibility of the paper is limited due to the lack of availability of training code, dialogue dataset, and model checkpoints. The reviewer encourages the authors to release these resources through anonymous repositories to facilitate verification of the claims and allow reviewers to try out the model. This claim is 3 as it provides a logical reasoning for the need to release these resources for reproducibility. However, it lacks specific examples or references to similar practices in the field, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s reproducibility, noting that without access to the training code, dialogue dataset, and model checkpoints, it is challenging to verify the claims made in the paper. The reviewer provides a clear and actionable suggestion by encouraging the authors to release these resources through anonymous repositories, allowing reviewers to test the model and verify the claims. This feedback is valuable as it directly addresses a critical weakness in the paper and offers a concrete step for improvement. By following this advice, the authors can enhance the transparency and credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the main result is considered obvious because gradient boosting minimizes objectives in functional space. However, it does not provide any actionable advice or suggestions for the authors to address this issue. There is no guidance on how the authors might improve their results or presentation to make them less obvious. Without specific recommendations or a clear direction for improvement, the comment lacks actionability. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment critiques the main result as being \"obvious\" due to gradient boosting minimizing objectives in functional space. However, it does not specify which part of the paper this observation pertains to, such as a specific section, figure, or table. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the result is considered obvious or how it could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the main result is \"obvious\" because gradient boosting minimizes objectives in functional space. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this result is considered obvious. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the main result is considered obvious because gradient boosting minimizes objectives in functional space. However, it does not provide any further explanation, reasoning, or suggestions for improvement. Without additional context or guidance, the authors are left without actionable feedback on how to address this observation or enhance their results. The comment lacks depth and specificity, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the paper, including the insufficient contribution, lack of explicit expression of the contribution, incomplete details, limited related work, and absence of appropriate analysis. However, it does not provide specific guidance or suggestions on how the authors might address these issues. The comment lacks actionable details, such as recommending what aspects of the contribution should be clarified, how to improve the related work section, or what type of analysis should be included. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the overall contribution and the lack of explicit expression of the contribution within the paper. It also mentions the incomplete details, limited related work, and absence of appropriate analysis. However, it does not specify which sections of the paper these issues pertain to, making it difficult for the authors to pinpoint the exact areas needing revision. The comment is specific in its critique of the contribution and the lack of analysis, but it lacks grounding as it does not identify specific parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution of the work is insufficient and not explicitly expressed within the paper. It further states that the details provided are incomplete, there is limited related work mentioned, and no appropriate analysis is provided. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence makes the claim 3, as it provides a general critique but does not offer sufficient guidance for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, including the insufficient contribution, lack of explicit expression of the contribution, incomplete details, limited related work, and absence of appropriate analysis. However, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their draft. The comment highlights areas that need attention but lacks actionable feedback, leaving the authors with a general understanding of the problems but without a clear path to resolution. Therefore, the comment is 3, as it points out important weaknesses but does not offer detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit guidance on how to improve the presentation of the results in Figures 2a and 2b. It suggests that Figure 2a should include iterations or training steps as the xaxis, rather than walltime, and clarifies that the xaxis label in Figure 2b should be changed to \"training steps\" or \"outerloop iterations.\" This feedback is clear and provides concrete steps for the authors to take, ensuring they know exactly what changes to make to improve the clarity of their results. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2a\" and \"Figure 2b,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the xaxis labels in Figure 2a should be changed to iterations or training steps, and the label \"item\" in Figure 2b should be clarified as \"training steps\" or \"outerloop iterations.\" This provides clear guidance on how to improve the clarity and accuracy of the figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results in Figure 2a are given in walltime, while Figure 2b uses training steps as the xaxis, but the label \"item\" is used instead of \"training steps.\" The comment provides a clear and logical reasoning for why this is confusing and suggests that Figure 2a should also use iterations or training steps as the xaxis. This reasoning is based on common knowledge about the typical use of training steps or iterations in machine learning experiments. However, the comment could be strengthened by providing specific examples or references to support the claim that using walltime is not appropriate. Therefore, the comment is 4, as it provides a logical basis for the suggestion but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides clear and actionable feedback on the presentation of results in Figures 2a and 2b. It points out that the xaxis labels in Figure 2a are given in walltime, which is not clear, and suggests that it should be changed to iterations or training steps. Additionally, it notes that the xaxis label in Figure 2b is labeled \"item,\" which should be clarified as \"training steps\" or \"outerloop iterations.\" This feedback is specific and provides concrete steps for the authors to improve the clarity and accuracy of their results presentation. By addressing these issues, the authors can enhance the readability and understanding of their findings. Therefore, the comment is rated as 4, as it offers clear guidance for improvement but could be more comprehensive by suggesting additional changes or clarifications."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the use of different metrics for different devices, suggesting that a single cost metric should be used instead. However, it does not provide explicit guidance on how the authors should address this issue or what specific metric should be used. The action is implicit and somewhat vague, as the authors are left to infer that they should standardize the cost metric across devices but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the use of different metrics for different devices, suggesting that a single cost metric should be used instead. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or analysis where these metrics are discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspects of the paper need to be revised or how the suggested change would improve the draft. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the use of different metrics for different devices, suggesting that a single cost metric should be used instead. However, the comment does not provide any reasoning, examples, or references to support why this change would be beneficial or how it would improve the paper. Without additional context or justification, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the use of different metrics for different devices, suggesting that a single cost metric should be used instead. While it identifies a potential inconsistency in the approach, it lacks specificity and does not provide any guidance or suggestions on how to address this issue. The comment does not offer actionable advice or detailed feedback on how the authors might improve their draft by standardizing the cost metric. As a result, the comment is 2, as it points out a potential area for improvement but does not provide enough detail or direction for the authors to effectively address it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the maximum iterations set in the experiment and whether they significantly slow down the training speed. While it does not explicitly instruct the authors to provide this information, it implies that the authors should address this concern by including details about the iterations and their impact on training speed. The action is implicit but concrete, as the authors know exactly what information is needed to address the concern. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"twodimention Wasserstein distance\" and the \"Sinkhorn algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the maximum iterations used in the experiment and whether they significantly slow down the training speed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the maximum iterations used in the experiment and their potential impact on training speed. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises a specific question about the maximum iterations used in the experiment and their potential impact on training speed. This is a relevant and actionable point that could help the authors clarify their methodology and address any potential concerns regarding the efficiency of their approach. By asking for this information, the comment provides a clear direction for the authors to improve their draft. However, it could be more helpful if it offered suggestions on how to optimize the iterations or address the potential slowdown. Overall, the comment is 4 as it identifies a critical area for clarification and improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a major weakness in the paper regarding the soundness of the teacher policy. It points out that the teacher policy is trained to maximize distribution matching between the student policy and the expert, but it is unclear whether the student policy can still perform correct distribution matching. The reviewer suggests that theoretical results are needed to address this issue. While the comment implies that the authors should provide theoretical results to support their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to develop theoretical results or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a major weakness in the paper regarding the soundness of the teacher policy. It provides a detailed explanation of the issue, noting that the teacher policy is trained to maximize distribution matching between the student policy and the expert, but it is unclear whether the student policy can still perform correct distribution matching. The reviewer suggests that theoretical results are needed to address this issue. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the methodology or results sections where the teacher policy is discussed. The comment is specific in detailing the issue and suggesting a solution, but it lacks explicit grounding. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks theoretical soundness regarding the teacher policy. It provides a detailed explanation of the issue, noting that the teacher policy is trained to maximize distribution matching between the student policy and the expert, but it is unclear whether the student policy can still perform correct distribution matching. The reviewer suggests that theoretical results are needed to address this issue. This claim is 4 as it provides a clear explanation of the concern and suggests a specific area for improvement. However, it could be strengthened by providing examples or references to similar approaches that have successfully addressed this issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper regarding the soundness of the teacher policy. It highlights a concern about the distribution matching between the student policy and the expert, questioning whether the student policy can still perform correct distribution matching. The reviewer suggests that theoretical results are needed to address this issue, which would provide a more robust foundation for the approach. While the comment points out a critical area for improvement, it lacks specific guidance or suggestions on how to develop these theoretical results or what aspects to focus on. The feedback is 3 as it directs the authors to a specific area needing attention, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed method does not perform well in some classes and recommends that the authors analyze and discuss the reasons behind this performance. While the comment implies that the authors should investigate and explain the performance issues, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the steps to take and may not be entirely sure of the exact approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the poor performance of the proposed method in some classes, and suggests that the authors should analyze and discuss the reasons behind this performance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method does not perform well in some classes and suggests that the authors should analyze and discuss the reasons behind this performance. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of the proposed method in Table 3, noting that it does not perform well in some classes. It suggests that the authors should analyze and discuss the reasons behind this performance, which is a clear and actionable piece of feedback. By addressing this point, the authors can gain a deeper understanding of their method\"s limitations and potentially improve it. However, the comment could be more helpful if it provided additional guidance on how to analyze or discuss the performance issues. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with further suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of rigor in the experimental settings, specifically mentioning that MTT should test on unseen tasks. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets/settings. While the comment implies that the authors should improve the experimental design and provide more detailed explanations, it does not explicitly instruct them on how to achieve these improvements. The action is implicit and somewhat vague, as the authors need to infer that they should enhance the experimental design and analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Some experimental settings\" and \"MTT,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the experimental settings are not rigorously designed and suggests that MTT should test on unseen tasks. Additionally, it recommends further discussion or explanation of the experimental results, particularly regarding the variation of model behavior under different datasets/settings. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some experimental settings are not rigorously designed, specifically mentioning that MTT should test on unseen tasks. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets/settings. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of concrete evidence or references makes the claim 3, as it provides a general direction for improvement but does not fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental settings, noting that some are not rigorously designed. It provides a concrete example by suggesting that MTT should test on unseen tasks, which is a clear and actionable suggestion for improvement. Additionally, the comment recommends further discussion or explanation of the experimental results, particularly regarding the variation of model behavior under different datasets/settings. This feedback is valuable as it directs the authors to enhance the rigor and clarity of their experimental design and analysis. However, the comment could be more helpful if it included specific suggestions on how to address the issues or provided examples of how to improve the experimental discussion. Overall, the comment is 4, as it effectively guides the authors toward improving their experimental methodology and results presentation."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential learning effects due to the order of data collection for the 5 layouts. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the data collection should be randomized to mitigate potential learning effects, but it does not specify whether this is a requirement or a suggestion. Additionally, it lacks concrete details on how to implement a randomized data collection process. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the potential learning effects due to the order of data collection for the 5 layouts. However, it does not specify which part of the paper discusses the data collection process, making it weakly grounded. The comment is specific in its concern about the potential learning effects and suggests that the data collection should be randomized to mitigate this issue. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the potential learning effects due to the order of data collection for the 5 layouts. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The comment lacks specific details or reasoning to justify why the order of data collection could lead to learning effects, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the potential learning effects due to the order of data collection for the 5 layouts. It suggests that the data collection might not be randomized, which could impact the results. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as recommending a randomized data collection process or discussing potential methods to mitigate learning effects. While it identifies a potential problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a possible issue but lacks detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point questions the necessity of considering node ordering in the context of covering the random ordering of atoms in a specific point in the composition space. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or whether it is a critical concern. The comment lacks actionable details, leaving the authors uncertain about what steps, if any, they should take in response. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the relevance of node ordering in the context of covering the random ordering of atoms in a specific point in the composition space. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not detail what aspect of node ordering is being questioned or how it relates to the composition space. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the necessity of considering node ordering in the context of covering the random ordering of atoms in a specific point in the composition space. However, it does not provide any supporting evidence, reasoning, or references to justify why node ordering should not be relevant. The comment lacks specific examples or detailed explanations that would help the authors understand the basis of the claim. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the issue effectively.", "helpfulness_rationale": "The review comment questions the relevance of node ordering in the context of covering the random ordering of atoms in a specific point in the composition space. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or why it is important to consider node ordering. The comment lacks depth and actionable feedback, leaving the authors without a clear understanding of what needs to be improved or how to proceed. As a result, the comment is 1, as it does not offer any constructive direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the previous work 5, which presents a dexterous manipulation benchmark with musculoskeletal hands, detracts from the novelty of the current work. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address the issue of novelty or differentiate their work from the previous work. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the previous work 5, which presents a dexterous manipulation benchmark with musculoskeletal hands, and suggests that it detracts from the novelty of the current work. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides references to the previous work, which helps the authors understand the context of the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the previous work 5 presents a dexterous manipulation benchmark with musculoskeletal hands, which detracts from the novelty of the current work. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed comparisons or examples that would help the authors understand why the previous work is a concern. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the current work, noting that a previous study 5 presents a dexterous manipulation benchmark with musculoskeletal hands, which could detract from the novelty of the current work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their work from the previous study. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential concern but lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the selection of datasets should be made more clear, including the pool of datasets considered and the selection process. It also mentions specific examples of datasets, such as OpenML100 and OpenML CC18, and references relevant literature. Additionally, the comment points out the need to detail the selection of the splitting procedure and split ratios. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed and how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the selection of datasets as a main contribution, allowing the authors to identify the part of the paper being addressed. It also specifies what needs to be addressed, such as the selection process, the pool of datasets considered, and the selection of splitting procedures and split ratios. The comment provides specific examples of datasets, such as OpenML100 and OpenML CC18, and references relevant literature, which further enhances its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the selection of datasets should be made more clear, suggesting that the authors provide details on the pool of datasets considered and the selection process. The comment references specific examples of datasets, such as OpenML100 and OpenML CC18, and provides references to relevant literature. This level of detail and specific references support the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current selection process is lacking. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the selection of datasets should be more clearly explained. It highlights the need to detail the pool of datasets considered and the selection process, referencing examples like OpenML100 and OpenML CC18. Additionally, the comment points out the lack of clarity in the selection of splitting procedures and split ratios, which is also addressed. This feedback is clear and constructive, offering the authors specific guidance on how to improve their draft by providing more detailed information on their dataset selection process. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a critical omission in the ablation study, namely the lack of a comparison with a baseline where an unconditional diffusion model is first refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation. The comment suggests that this comparison would be valuable to determine if the proposed method would outperform these conventional baselines under the same computational constraints. By highlighting this specific comparison, the comment provides a clear and actionable direction for the authors to improve their draft. The feedback is explicit and concrete, giving the authors a direct path to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the ablation study, namely the comparison with a baseline where an unconditional diffusion model is first refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation. This provides clear guidance on what the authors need to address to improve their study. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ablation study lacks a critical comparison, specifically suggesting that it should include a baseline where an unconditional diffusion model is first refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation. The comment argues that comparing to a model initiated with random parameters does not provide a relevant benchmark. This claim is 3 as it provides a logical reasoning for the suggested comparison, but it lacks specific examples or references to support the assertion that the proposed method would outperform these conventional baselines. The authors would need to infer the potential benefits of the suggested comparison based on the provided reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical gap in the ablation study, specifically noting the absence of a comparison with a baseline where an unconditional diffusion model is first refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation. This feedback is valuable as it highlights a specific area where the study could be strengthened by including a relevant benchmark. The comment provides a clear and actionable suggestion for improvement, which is highly beneficial for the authors. However, it could be more helpful if it offered additional guidance on how to conduct this comparison or what specific metrics to focus on. Overall, the comment is 4, as it effectively directs the authors to enhance the robustness and validity of their ablation study."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the tasks in the paper are based on grasping and are too homogeneous in their difficulty. It implies that the authors should consider designing more diverse tasks, possibly by referring to specific projects mentioned in the comment. However, the comment does not provide explicit instructions on how to implement this suggestion or which specific tasks should be considered. The action is implicit and somewhat vague, as the authors need to infer the need for task diversity and identify potential projects to reference. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the tasks in the paper are based on grasping and are too homogeneous in their difficulty. It implies that the authors should consider designing more diverse tasks, possibly by referring to specific projects mentioned in the comment. However, the comment does not specify which part of the paper discusses these tasks, making it weakly grounded. The suggestion to refer to specific projects is specific, as it provides examples of potential sources for task design. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the tasks in the paper are based on grasping and are too homogeneous in their difficulty. It suggests that the authors should refer to specific projects, such as 1 and 2, to design more diverse tasks. However, the comment lacks specific examples or detailed reasoning to support why these tasks are too homogeneous or how referring to these projects would improve the task diversity. The lack of detailed justification or examples makes the claim 3, as the authors may find it challenging to understand the basis of the suggestion without further explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper, noting that all the tasks are based on grasping and are too homogeneous in their difficulty. It suggests that the authors should consider designing more diverse tasks by referring to specific projects, such as those mentioned in the comment. This feedback is 3 as it points out a specific area for improvement and provides a direction for enhancing the task diversity. However, the comment could be more helpful if it offered specific examples of how to design these diverse tasks or provided more detailed guidance on which projects to consider. Overall, the comment provides some direction but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the fairness of the comparison in Table 2, suggesting that the LEPA\"s training data is likely larger than the \"Without Plan/Without SelfReflection\" settings. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to ensure fairness. The comment implies that the authors should consider the size of the training data when making comparisons, but it lacks concrete steps or suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"lines 349360,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the comparison in Table 2 may be unfair due to the likely difference in training data size between the LEPA and the \"Without Plan/Without SelfReflection\" settings. The comment provides a reference to external work, \"LUMOS: LEARNING AGENTS WITH UNIFIED DATA, MODULAR DESIGN, AND OPENSOURCE LLMS,\" which supports the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison in Table 2 is unfair due to the likely difference in training data size between the LEPA and the \"Without Plan/Without SelfReflection\" settings. The reviewer supports this claim by referencing lines 349360, where the settings are described, and by citing an external work, \"LUMOS: LEARNING AGENTS WITH UNIFIED DATA, MODULAR DESIGN, AND OPENSOURCE LLMS.\" This provides a logical basis for the claim, as it suggests that the reviewer has considered the context and referenced relevant information. However, the comment could be strengthened by providing more detailed reasoning or examples of how the training data size affects the fairness of the comparison. Overall, the claim is 4, as it requires some additional context but is supported by logical reasoning and references.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison in Table 2, suggesting that the LEPA\"s training data is likely larger than the \"Without Plan/Without SelfReflection\" settings. This observation is relevant and could impact the interpretation of the results. However, the comment does not provide specific guidance on how the authors might address this issue or suggest ways to ensure fairness in the comparison. While it highlights a potential problem, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the use of synthetic datasets in the experiments and suggests using datasets from the GLUE benchmark and realworld diversity datasets. While the comment implies that the authors should consider using these datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of synthetic datasets in the experiments and suggests using datasets from the GLUE benchmark and realworld diversity datasets. However, it does not specify which part of the paper discusses the use of synthetic datasets, making it weakly grounded. The comment is specific in suggesting the use of GLUE benchmark datasets and realworld diversity datasets, providing clear guidance on what the authors could consider for their experiments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have only experimented with synthetic datasets and suggests using datasets from the GLUE benchmark and realworld diversity datasets. However, the comment does not provide any reasoning or evidence to support why these datasets are necessary or how they would improve the study. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, noting that the authors have only experimented with synthetic datasets and suggesting the use of datasets from the GLUE benchmark and realworld diversity datasets. This feedback is clear and actionable, as it provides specific examples of datasets that could be used to enhance the study. By suggesting these datasets, the comment offers a concrete direction for the authors to improve their work. However, the comment could be more helpful if it included additional context or reasoning for why these datasets are important or how they might impact the results. Overall, the comment is 4, as it provides valuable guidance for enhancing the paper, but it could be more comprehensive with further elaboration."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to add details on how to solve the optimization in the main paper, which is currently lacking. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, as it specifies the exact aspect that needs attention. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding details on how to solve the optimization in the main paper, indicating that this information is currently lacking. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its request for additional details on the optimization process, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks details on how to solve the optimization, which is an important aspect. However, the comment does not provide any specific examples, reasoning, or references to support why this information is crucial or how it could be addressed. Without additional context or justification, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely, the optimization process. It suggests that the authors should include more information on how to solve the optimization, which is an important aspect of the paper. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on what details should be included or how the optimization process should be explained. Despite this, the comment is 4 as it directs the authors to a critical area that needs attention, making it a valuable input for improving the draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions why certain models, such as LLaVAseries and QwenVL, are not included in the evaluation, noting that they are commonly adopted LVLMs. The comment suggests including these models to provide a more comprehensive comparison across different LVLM architectures and training approaches. While the comment implies that the authors should consider including these models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to incorporate these models into the evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions why specific models, LLaVAseries and QwenVL, are not included in the evaluation, noting that they are commonly adopted LVLMs. This provides a clear and specific suggestion for improvement, indicating that the authors should consider including these models for a more comprehensive comparison. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as the methodology or results sections. While the authors can infer that it relates to the evaluation or comparison sections, the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the exclusion of specific models, LLaVAseries and QwenVL, from the evaluation, noting that they are commonly adopted LVLMs. The comment suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. However, the comment lacks specific reasoning or evidence to support why these models are important or how their inclusion would significantly impact the evaluation. Without detailed justification or examples, the claim remains 3, as the authors would need to infer the importance of these models based on the suggestion alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the exclusion of specific models, LLaVAseries and QwenVL, from the evaluation, noting that they are commonly adopted LVLMs. It suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. This feedback is clear and actionable, as it identifies a specific area for improvement by recommending the inclusion of additional models. However, the comment could be more helpful if it provided specific reasons why these models are important or how their inclusion would enhance the evaluation. Overall, the comment is 4 as it guides the authors toward a more comprehensive evaluation, but it could be more detailed to fully address their needs."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include some caption/description as well as OCR heavy datasets. While it implies an action, it does not provide specific guidance on what kind of caption or description should be included or which OCR heavy datasets should be considered. The authors can infer that they need to add this information, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it provides an implicit action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the authors should include some caption/description as well as OCR heavy datasets. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional content, such as captions and OCR heavy datasets, but without clear grounding, the authors may struggle to determine where these additions should be made. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include some caption/description as well as OCR heavy datasets. However, it does not provide any reasoning, examples, or references to support why these additions are necessary or beneficial. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the authors should include some caption/description as well as OCR heavy datasets. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on what kind of caption or description should be included or which OCR heavy datasets should be considered. The feedback is 3 as it points out a gap in the paper, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between Assumption 3.1 and eqn.7, suggesting that the loss of TKD is assumed to be less than IYOR, while eqn.7 tells a different story. However, the comment does not provide explicit guidance on how the authors should address this discrepancy or clarify the issue. The action is implicit, as the authors can infer that they need to reconcile the assumptions and equations, but it lacks concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Assumption 3.1\" and \"eqn.7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the assumption and the equation, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy between Assumption 3.1 and eqn.7, suggesting that the loss of TKD is assumed to be less than IYOR, while eqn.7 tells a different story. This claim is based on a direct comparison of the assumption and the equation, which provides a clear and logical basis for the critique. However, the comment does not provide additional context or references to support the claim further. While the reasoning is sound, the lack of detailed explanation or references makes the claim 4, as it requires the authors to fully understand and address the issue themselves. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific discrepancy between Assumption 3.1 and eqn.7, pointing out that the loss of TKD is assumed to be less than IYOR, while eqn.7 tells a different story. This feedback is clear and actionable, as it highlights a potential error or inconsistency in the assumptions and equations that the authors need to address. By pointing out this discrepancy, the comment provides the authors with a clear direction for revising their draft to ensure consistency and accuracy. However, the comment could be more helpful if it offered suggestions on how to reconcile the assumptions or equations. Overall, the comment is 4, as it effectively directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether question 3, which is mentioned in relation to weaknesses 2 and 4, indicates other limitations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or clarify the issue, leaving the authors without a clear understanding of what needs to be done. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the clarity of question 3, which is mentioned in relation to weaknesses 2 and 4. However, it does not specify which part of the paper this question is from, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not detail what needs to be clarified or improved regarding question 3. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the clarity of question 3, which is mentioned in relation to weaknesses 2 and 4. However, it does not provide any additional context, reasoning, or evidence to support why this question is unclear or how it relates to the mentioned weaknesses. Without further explanation or examples, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of question 3, which is mentioned in relation to weaknesses 2 and 4. However, it does not provide any context or explanation as to what these weaknesses are or how question 3 relates to them. Without additional information or guidance, the authors are left without a clear understanding of what needs to be clarified or improved. The comment lacks specificity and actionable feedback, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the choice of using the lastlayer hidden states for the classifier, suggesting that middle layers might be more effective for probing. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should reconsider their choice of hidden states, but it lacks concrete details on how to implement this change or what specific layers might be more effective. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the choice of using the lastlayer hidden states for the classifier, suggesting that middle layers might be more effective for probing. However, it does not specify which part of the paper discusses this choice, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the methodology but lacks grounding, as it does not explicitly mention a section or figure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using the lastlayer hidden states for the classifier, suggesting that middle layers might be more effective for probing. However, the comment does not provide any references, examples, or detailed reasoning to support this claim. Without specific evidence or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment questions the choice of using the lastlayer hidden states for the classifier, suggesting that middle layers might be more effective for probing. This is a relevant observation that could prompt the authors to reconsider their methodology and potentially improve the accuracy or effectiveness of their model. However, the comment lacks specific suggestions or examples of how the authors might explore using middle layers, which would make it more actionable. While it identifies a potential area for improvement, the feedback is somewhat vague and incomplete, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the motivation behind using GUE to determine tokenization, model architecture, and training objective for the generative model, suggesting that these decisions are arbitrary and potentially incongruous. The reviewer highlights a concern about the generalizability of the representations learned from these modeling decisions, given the narrow set of tasks presented in GUE. While the comment identifies a potential issue with the motivation and generalizability, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they should provide a more robust justification for their modeling choices or explore alternative approaches. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"my first question,\" which allows the authors to identify the part of the paper being addressed. It also specifies the issue by questioning the motivation behind using GUE to determine tokenization, model architecture, and training objective for the generative model. The comment highlights concerns about the arbitrariness and potential incongruity of these decisions, as well as the limited generalizability of the representations learned. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of GUE to determine tokenization, model architecture, and training objective for the generative model is arbitrary and potentially incongruous. The reviewer provides a logical reasoning by suggesting that the representations learned from these modeling decisions may have limited generalizability due to the narrow set of tasks presented in GUE. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and justify the generalizability of their approach to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation behind using GUE to determine tokenization, model architecture, and training objective for the generative model. It questions the arbitrariness and potential incongruity of these decisions, suggesting that the representations learned may have limited generalizability due to the narrow set of tasks presented in GUE. This feedback is 3 as it highlights a critical area for improvement in the paper, prompting the authors to reconsider their approach and provide a more robust justification for their modeling choices. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this issue, such as recommending alternative approaches or justifications for the modeling decisions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the paper needs a major editing pass due to grammar and spelling errors, providing a clear action for the authors to take. However, it does not specify which parts of the paper are particularly problematic or offer guidance on how to address the issues. While the action is direct, the lack of concrete details on how to implement the editing pass makes the comment 3.", "grounding_specificity_rationale": "The comment indicates that the paper has significant grammar and spelling errors, which affects its readability. However, it does not specify which parts of the paper are affected or provide examples of these errors. This makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is 1 as it does not identify specific sections or elements of the paper, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper has significant grammar and spelling errors, which affects its readability. However, it does not provide specific examples or detailed evidence to support this claim. Without concrete examples or references to specific sections of the paper, the authors may find it challenging to understand and address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it reads clunkily due to grammar and spelling errors. This feedback is important as it highlights a fundamental problem that affects the readability and professionalism of the paper. However, the comment lacks specificity and does not provide actionable guidance on how to address these errors or which parts of the paper are most affected. While it points out a critical area for improvement, the lack of detailed suggestions or examples makes it 3, as the authors are left with a general direction but no clear steps to take. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the oddball objective function used in the regression and whether it causes any issues. While the comment identifies areas of concern, it does not provide explicit instructions or concrete suggestions for the authors to address these questions or concerns. The authors are left to infer that they need to clarify these aspects, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises several questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the oddball objective function used in the regression and whether it causes any issues. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The authors may infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the concerns about the estimator and the objective function, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point consists of a series of questions and observations, each of which requires further clarification or justification. It does not contain subjective claims, opinions, or suggestions that would necessitate verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the oddball objective function used in the regression and whether it causes any issues. While the comment identifies critical areas for clarification and potential concerns, it does not provide specific suggestions or guidance on how the authors might address these questions or improve their draft. The feedback is 3 as it prompts the authors to consider these issues, but it lacks actionable advice or detailed guidance, leaving the authors with a general direction but not a clear path forward. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the limitations of OIS in handling interactive segmentation for multiple objects simultaneously. It suggests that the method may struggle to shift focus to a new target object if the target changes between clicks, due to constraints from the previous mask. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the method\"s practical utility. The action is implicit and vague, as the authors are left to infer that they should explore ways to address this issue but are not given specific steps or examples to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OIS\" and \"Objectlevel Understanding,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the method\"s ability to handle interactive segmentation for multiple objects simultaneously and discusses the potential limitation of shifting focus to a new target object due to constraints from the previous mask. The comment provides a specific example from the literature, \"Object Aware Contrastive Prior for Interactive Image Segmentation,\" which further grounds the discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the limitations of OIS in handling interactive segmentation for multiple objects simultaneously. It suggests that the method may struggle to shift focus to a new target object if the target changes between clicks, due to constraints from the previous mask. The comment references a specific work, \"Object Aware Contrastive Prior for Interactive Image Segmentation,\" which provides some support for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 3, as it requires additional information to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation of the OIS method in handling interactive segmentation for multiple objects simultaneously. It highlights a specific issue related to the method\"s reliance on mask guidance from previous interactions, which could hinder its ability to shift focus to a new target object if the target changes between clicks. This feedback is valuable as it points out a practical limitation that could impact the method\"s utility. However, the comment could be more helpful if it provided suggestions or examples on how the authors might address this limitation or improve the method\"s flexibility. Overall, the comment is 3 as it directs the authors\" attention to a critical area for improvement but lacks detailed guidance on how to address the issue."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption made by the proposed system, which is that anomalies would be aligned with concepts. It questions the realism of this assumption and suggests that it implies the user has extensive knowledge of the domain. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their draft. The action is implicit and vague, as the authors are left to infer that they should reconsider their assumption or provide additional context to justify it. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the assumption made by the proposed system, questioning its realism. It provides an example of how anomaly detection systems are typically used in scenarios where the type of anomalies is unknown, such as intrusion and fraud detection. However, the comment does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in its critique of the assumption and the implications it has for the user\"s knowledge of the domain. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the assumption made by the proposed system, questioning its realism. The reviewer provides a logical reasoning by comparing the system to typical anomaly detection scenarios, where the type of anomalies is unknown. This comparison highlights the potential limitations of the proposed system, which assumes anomalies are aligned with concepts. However, the comment lacks specific examples or references to support the claim further, making it 3. The authors would need to consider the reasoning and potentially provide additional evidence or context to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical point about the assumption made by the proposed system, which is that anomalies would be aligned with concepts. It questions the realism of this assumption and highlights the implications it has for the user\"s knowledge of the domain. This feedback is valuable as it prompts the authors to reconsider their assumption and potentially provide additional context or justification for it. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other systems have handled similar assumptions. Overall, the comment is 3 as it identifies a potential weakness in the paper but lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should include a discussion on the current limitations and challenges of HLOP, as well as the potential downsides and limitations of the evaluation process. This feedback provides a clear and direct action for the authors to take, ensuring that they understand what needs to be addressed in their draft. The comment is specific and concrete, as it outlines the exact areas that need further discussion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks discussion on the current limitations and challenges of HLOP, as well as the potential downsides and limitations of the evaluation process. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for additional discussion on these topics, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the current limitations and challenges of HLOP, as well as the potential downsides and limitations of the evaluation process. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the limitations or how they should address them. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of discussion on the current limitations and challenges of HLOP, as well as the potential downsides and limitations of the evaluation process. This feedback is valuable as it highlights an important area for improvement that could enhance the paper\"s comprehensiveness and depth. By suggesting the inclusion of such discussions, the comment provides clear and actionable guidance for the authors to consider. However, it could be more helpful if it offered specific suggestions on what aspects to include in these discussions. Overall, the comment is 4, as it directs the authors toward a critical area for enhancement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors evaluate the effectiveness of their proposed gating scheme on recently released language models, such as FlanT5 and Llama, to enhance the prominence of their contribution. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the evaluation or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests evaluating the proposed gating scheme on recently released language models, such as FlanT5 and Llama, to enhance the contribution of the work. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of these models for evaluation, but without explicit references to sections or parts of the paper, the authors may find it challenging to pinpoint where this feedback applies. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors evaluate the effectiveness of their proposed gating scheme on recently released language models, such as FlanT5 and Llama, to enhance the prominence of their contribution. The claim is 3 as it provides a logical reasoning for why evaluating these models would be beneficial, but it lacks specific examples or references to support the claim. The authors would need to infer the importance of these models based on the suggestion, which could be more robust with additional evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by noting that many more language models have been released after GPT2, which have not been studied in the work. It suggests that evaluating the proposed gating scheme on recently proposed language models, such as FlanT5 and Llama, would enhance the prominence of the contribution. This feedback is clear and actionable, providing a specific direction for the authors to consider in expanding their study. However, it could be more helpful if it included suggestions on how to conduct these evaluations or what specific aspects to focus on. Overall, the comment is 4 as it offers a valuable insight for improving the paper, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should cite and compare their work with more recent studies that might be highly correlated. It provides an example of a specific work, \"Differential Treatment for Stuff and Things,\" that could be relevant for comparison. While the comment implies an action\u2014citing and discussing similar works\u2014the authors are not explicitly instructed to do so. The suggestion is concrete, as it provides a specific example of a work that could be relevant, but the action is implicit. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that more recent works that might be highly correlated need to be cited and compared against, providing an example of a specific work by Wang et al. (cvpr2020) that could be relevant. This provides a clear direction for the authors to consider additional references and comparisons. However, the comment does not specify which part of the paper should include these comparisons, making it weakly grounded. The suggestion is specific in terms of the type of work to consider, but the lack of explicit grounding limits the comment\"s effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more recent works that might be highly correlated need to be cited and compared against. It provides an example of a specific work, \"Differential Treatment for Stuff and Things,\" which could be relevant for comparison. This example supports the claim by offering a concrete reference, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these works might be correlated or similar to the proposed method. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the authors should consider citing and comparing their work with more recent studies that might be highly correlated. It provides a specific example of a relevant work by Wang et al. (cvpr2020) that could be relevant for comparison. This feedback is clear and actionable, as it directs the authors to expand their literature review and contextualize their work within the current state of the field. However, the comment could be more helpful if it included a more detailed explanation of how these works might be correlated or suggestions on specific aspects to compare. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding more detail about how UNKs (unknown words) are handled by the neural decoder or citing the dictionarybased replacement strategy being used. While the comment implies that the authors should provide additional information or references, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify exactly what details should be added or how the citation should be integrated. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding more detail about the handling of UNKs (unknown words) by the neural decoder or citing the dictionarybased replacement strategy being used. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its request for additional detail or a citation, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding more detail about the handling of UNKs (unknown words) by the neural decoder or citing the dictionarybased replacement strategy being used. While the comment implies that the current description is insufficient, it does not provide specific examples or references to support the claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the exact nature of the issue or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should provide more detail about how UNKs (unknown words) are handled by the neural decoder or include a citation to the dictionarybased replacement strategy being used. This feedback is clear and actionable, as it directs the authors to either expand on the existing information or include a reference to support their approach. However, the comment could be more helpful if it provided specific suggestions on what additional details to include or how to integrate the citation. Overall, the comment is 4 as it guides the authors toward enhancing the clarity and credibility of their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their method with other stateoftheart (SOTA) code summarization methods, specifically mentioning the use of pretrained models. This is an explicit action that provides a clear direction for the authors to follow. The suggestion is concrete, as it specifies the type of comparison that should be made, making it 5. The authors know exactly what needs to be done to improve their draft, which is to include comparisons with other SOTA methods, particularly those using pretrained models. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the method with other stateoftheart (SOTA) code summarization methods, specifically mentioning the use of pretrained models. However, it does not specify which part of the paper this comparison should be included in, such as the experimental section or the results discussion. This lack of explicit reference to a specific section makes it weakly grounded. The comment is specific in suggesting a particular comparison, but without clear grounding, the authors may struggle to determine where to incorporate this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that other stateoftheart (SOTA) code summarization methods, particularly those using pretrained models, should be compared in the experiments. This is a claim that requires justification, as it implies that the current experimental setup lacks a comprehensive comparison with existing methods. However, the comment does not provide specific examples of these SOTA methods or detailed reasoning on why they should be included. Without such supporting evidence or references, the claim remains 3, as the authors would need to infer the importance of these comparisons. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should compare their method with other stateoftheart (SOTA) code summarization methods, particularly those using pretrained models. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental section by including comparisons with existing methods. By doing so, the authors can demonstrate the novelty and effectiveness of their approach relative to the current state of the field. However, the comment could be more helpful if it provided examples of specific SOTA methods or detailed guidance on how to conduct these comparisons. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the results in Table 3, specifically questioning the reason for AttendOut having lower variance compared to Scheduled Bernoulli and seeking the statistical significance value when comparing these two methods. While the comment implies that the authors should provide explanations or statistical analyses to address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide additional information but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the results in Table 3, specifically questioning the reason for AttendOut having lower variance compared to Scheduled Bernoulli and seeking the statistical significance value when comparing these two methods. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification and additional information about the results in Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the results presented in Table 3, specifically questioning the reason for AttendOut having lower variance compared to Scheduled Bernoulli and seeking the statistical significance value when comparing these two methods. This feedback is valuable as it prompts the authors to provide additional explanations or analyses to support their findings. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided guidance on what specific analyses might be needed. Despite this, the comment is 3 as it directs the authors\" attention to areas that require further clarification or justification. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a concern about the difference between confidence and accuracy for one sample when using it in Eq. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific changes are needed to improve the draft. The comment lacks actionable details, such as suggesting ways to reconcile the difference or explaining how it affects the equation. Without concrete instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to a specific equation, indicating that it is fully grounded. However, it does not specify what aspect of the equation is problematic or what needs to be addressed, making it underspecific. The authors can identify the part of the paper being addressed, but they may struggle to determine the exact issue or how to address it. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the difference between confidence and accuracy for one sample is unreasonable when using it in Eq. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific issue with the difference between confidence and accuracy for one sample when using it in Eq. However, it does not provide any context, explanation, or suggestions on how this issue might impact the paper or how the authors could address it. Without additional guidance or actionable feedback, the authors are left without a clear understanding of the problem or how to improve their draft. Therefore, the comment is 1, as it lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the method used to calculate the divergence between a sample and the data, specifically noting that it may fail when the sample is shifted from the data distribution. It asks a question about whether there is a way to adapt the method to account for this shift. While the comment identifies a potential issue and suggests a direction for further exploration, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors are left to infer that they should consider ways to address the issue of sample shift. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the method used to calculate the divergence between a sample and the data, specifically mentioning the use of residuals. It questions whether there is a way to adapt the method to account for shifts in the data distribution. However, the comment does not specify which part of the paper discusses this method or where the issue of sample shift is addressed. While the authors might have an idea of where this topic is discussed, the comment lacks full grounding as it does not explicitly mention a specific section or figure. The comment is specific in identifying the issue and suggesting a potential adaptation, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the method used to calculate the divergence between a sample and the data, specifically noting that it may fail when the sample is shifted from the data distribution. The comment questions whether there is a way to adapt the method to account for this shift. While the comment identifies a potential issue, it does not provide specific examples, references, or detailed reasoning to support the claim. The lack of detailed justification or evidence makes the claim 3, as the authors would need to further explore and substantiate the issue themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the method used to calculate the divergence between a sample and the data, specifically noting that it may fail when the sample is shifted from the data distribution. It raises a question about whether there is a way to adapt the method to account for this shift. While the comment highlights a critical area for consideration, it does not provide specific suggestions or guidance on how the authors might address this issue or adapt their method. The feedback is 3 as it points out a potential weakness, but it lacks actionable advice, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the context of word replacement and suggests that replacing a word independently could lead to incoherent text. The reviewer assumes that it is better to replace the whole phrase instead of individual words. While the comment implies that the authors should consider this aspect of their work, it does not provide explicit guidance or concrete steps on how to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the context of word replacement and potentially revise their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 076079, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the context of word replacement and suggests that replacing individual words might lead to incoherent text. The reviewer provides a potential solution by assuming that it is better to replace the whole phrase instead of individual words. This level of detail helps the authors understand what needs to be addressed in their draft. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point raises a question about the context of word replacement and suggests that replacing individual words might lead to incoherent text. The reviewer provides a logical reasoning by assuming that it is better to replace the whole phrase instead of individual words. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to consider the reasoning and potentially conduct experiments to verify the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the context of word replacement in the paper, specifically asking if replacing a word independent of its context could lead to incoherent text. The reviewer suggests that it might be better to replace the whole phrase instead of individual words. While the comment identifies a potential issue and provides a suggestion, it lacks depth and does not offer detailed guidance on how to address this concern. The authors are left with a general idea of what to consider but without specific steps or examples to follow. Therefore, the comment is 3, as it provides some insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests including a runtime comparison of different deep learningbased methods. While it implies that the authors should add this comparison, it does not provide specific guidance on how to conduct the comparison or which methods to include. The action is implicit and somewhat vague, as the authors need to infer that they should add a runtime comparison and determine the specifics themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including a runtime comparison of different deep learningbased methods. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or analysis, making it weakly grounded. The comment is specific in its request for a runtime comparison, but without clear grounding, the authors may struggle to determine where to incorporate this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including a runtime comparison of different deep learningbased methods. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or beneficial. The comment lacks specific details or references that would help the authors understand the importance of this suggestion or how it could improve the paper. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests including a runtime comparison of different deep learningbased methods, which could provide valuable insights into the efficiency and performance of these methods. However, the comment lacks specificity and does not provide guidance on how to conduct this comparison or which methods to include. While it identifies a potential area for improvement, the feedback is somewhat vague and does not offer actionable steps for the authors to follow. Therefore, the comment is 3, as it points out a possible enhancement but lacks depth and detail."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare and explore ECGspecific architectures using SSL or transformerbased methods for the ECG encoder, similar to how different methods were explored for the other two parts of the framework. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional comparisons and explorations. The comment also offers a concrete suggestion by mentioning specific types of architectures that could be considered. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ECG encoder, modality alignment, and LLM backbone\" within the MEIT framework, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the limited use of 1D CNN layers and average pooling in the ECG encoder and suggests comparing and exploring ECGspecific architectures using SSL or transformerbased methods, similar to how different methods were explored for the other two parts of the framework. This provides clear guidance on what needs to be addressed and improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the ECG encoder in the MEIT framework could be improved by comparing it with ECGspecific architectures using SSL or transformerbased methods. The comment provides a logical reasoning by pointing out the limited use of 1D CNN layers and average pooling in the current encoder, implying that more advanced architectures could lead to significant improvements. However, the comment lacks specific examples or references to these alternative architectures, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific weakness in the MEIT framework, namely the limited use of 1D CNN layers and average pooling in the ECG encoder. It suggests that the authors should explore and compare ECGspecific architectures using SSL or transformerbased methods, similar to how different methods were explored for the other two parts of the framework. This feedback is clear and actionable, providing the authors with a concrete direction for improving their work by expanding the comparison and exploration of ECGspecific architectures. However, the comment could be more helpful if it included specific examples or references to these alternative architectures, which would further guide the authors in their efforts. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to rephrase the abstract to avoid confusion about the focus of the paper. It clearly identifies the issue of the abstract suggesting a defense methodology when the paper actually presents a modelagnostic explainability technique for deep neural networks. The action is direct and provides a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abstract, namely that it inaccurately suggests a defense methodology is proposed when the paper actually presents a modelagnostic explainability technique. The comment provides a clear direction for improvement by suggesting a rephrasing to avoid confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract inaccurately suggests a defense methodology is proposed, when in fact the paper presents a modelagnostic explainability technique for deep neural networks. The reviewer provides a clear and logical reasoning for this claim by pointing out the discrepancy between the abstract and the actual focus of the paper. This reasoning is supported by the specific suggestion to rephrase the abstract to reflect the correct focus on explainability. The comment is 5 as it provides a clear and logical explanation for the claim, making it easy for the authors to understand and address the issue. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, which inaccurately suggests that the paper proposes a defense methodology when it actually presents a modelagnostic explainability technique for deep neural networks. It provides a clear and actionable suggestion to rephrase the abstract to avoid confusion, which is a valuable piece of feedback for the authors. By addressing this misrepresentation, the authors can ensure their work is accurately represented and understood by readers. However, the comment could be more helpful if it provided additional context or examples of how to rephrase the abstract effectively. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of comparison with recent methods, specifically mentioning FINER, Incode, and SL2AINR, which propose new activation functions for INRs. While the comment identifies a gap in the comparison, it does not explicitly instruct the authors to include these comparisons or provide specific guidance on how to integrate them into the paper. The action is implicit and somewhat vague, as the authors can infer that they need to expand their comparisons but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparisons with recent methods, specifically mentioning FINER, Incode, and SL2AINR. This allows the authors to accurately identify the part of the paper being addressed, which is the comparison section. The comment is also specific because it clearly specifies what is missing: comparisons with these recent methods that propose new activation functions for INRs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparisons with recent methods, specifically mentioning FINER, Incode, and SL2AINR. This claim is 3 as it provides specific examples of recent methods that could be included in the comparison. However, the comment does not provide detailed reasoning or evidence on why these comparisons are necessary or how they would enhance the paper. The authors would need to infer the importance of these comparisons themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the paper lacks comparisons with recent methods, such as FINER, Incode, and SL2AINR, which propose new activation functions for INRs. This feedback is clear and actionable, as it directs the authors to expand their comparisons to include these recent methods, which could enhance the relevance and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these comparisons effectively. Overall, the comment is 4 as it guides the authors toward a specific enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that a straightforward method, such as the one mentioned in the provided link, works well in practice and challenges the value of research on length extrapolation. It implies that the evaluation setting could be improved. However, the comment does not provide explicit guidance on how to improve the evaluation setting or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the necessary improvements without concrete instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a straightforward method, such as the one mentioned in the provided link, works well in practice and challenges the value of research on length extrapolation. It implies that the evaluation setting could be improved. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or experiment, making it weakly grounded. Additionally, while it provides a reference to a related work, it does not specify how this work challenges the evaluation setting or what specific improvements could be made. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that a straightforward method, as referenced in the provided link, works well in practice and challenges the value of research on length extrapolation. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate why the straightforward method is effective or how it challenges the value of research on length extrapolation. Without these details, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that a straightforward method, as referenced in the provided link, works well in practice and challenges the value of research on length extrapolation. It implies that the evaluation setting could be improved. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how the authors might improve their evaluation setting. Without actionable advice or examples, the authors are left with a general idea of what could be improved but without a clear path forward. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer sufficient guidance to be actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the training and testing environments used in Section 2.4, specifically asking which environment is the training one and which are the testing ones. It also suggests that a crossvalidation approach would be preferable to demonstrate the robustness of the results. While the comment implies that the authors should clarify the training and testing environments and consider a crossvalidation approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide this information and consider the suggested approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the training and testing environments and suggesting a crossvalidation approach. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the training and testing environments used in Section 2.4, specifically asking which environment is the training one and which are the testing ones. It also suggests that a crossvalidation approach would be preferable to demonstrate the robustness of the results. While the comment raises a valid point about the robustness of the results, it does not provide specific evidence or references to support the claim that crossvalidation is necessary or beneficial. The suggestion is logical but lacks detailed justification or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the training and testing environments used in Section 2.4, specifically asking which environment is the training one and which are the testing ones. It also suggests that a crossvalidation approach would be preferable to demonstrate the robustness of the results. This feedback is clear and actionable, as it prompts the authors to clarify their experimental setup and consider a more robust testing methodology. By addressing these points, the authors can enhance the credibility and reliability of their results. However, the comment could be more helpful if it provided specific guidance on how to implement crossvalidation or why it is important. Overall, the comment is 4, as it identifies a significant area for improvement and provides a clear direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of comparison to show how refinement during inference improves generation quality. It notes that while the statistic of the number of refinements is provided, it only confirms the change rather than demonstrating an improvement. This feedback implies that the authors should include a comparison to demonstrate the effectiveness of the refinement process. However, it does not provide specific guidance on how to conduct this comparison or what metrics to use. The action is implicit and somewhat vague, as the authors can infer the need for a comparison but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of a comparison to show how refinement during inference improves generation quality. It mentions the statistic of the number of refinements, suggesting that this only confirms the change rather than demonstrating an improvement. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being discussed. The comment is specific in detailing what is missing, namely a comparison to demonstrate the improvement in generation quality. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to show how refinement during inference improves generation quality. The reviewer notes that while the statistic of the number of refinements is provided, it only confirms the change rather than demonstrating an improvement. This claim is 3 as it highlights a gap in the paper\"s analysis, but it lacks specific examples or references to support the assertion that a comparison is necessary. The comment provides a logical reasoning for the need for a comparison, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved: the lack of a comparison to demonstrate how refinement during inference improves generation quality. It acknowledges that the paper provides a statistic on the number of refinements, but this only confirms the change rather than demonstrating an improvement. This feedback is clear and actionable, as it suggests that the authors should include a comparison to substantiate the claim of improved generation quality. However, the comment could be more helpful if it provided specific suggestions on how to conduct this comparison or what metrics to use. Overall, the comment is 4 as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: \"How long will the MDP take?\" and \"Could you provide the training time comparison of MDP and ImageNet pretraining + individual dataset fineturning?\" These questions imply that the authors should provide information on the training time for the MDP and a comparison with other training methods. However, the comment does not explicitly instruct the authors to include this information or provide guidance on how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to address the questions but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the training time of the MDP and requests a comparison with ImageNet pretraining and individual dataset finetuning. However, it does not specify which part of the paper this inquiry pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its request for training time comparisons, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions: \"How long will the MDP take?\" and \"Could you provide the training time comparison of MDP and ImageNet pretraining + individual dataset fineturning?\" These are factual requests for information, not claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions: \"How long will the MDP take?\" and \"Could you provide the training time comparison of MDP and ImageNet pretraining + individual dataset fineturning?\" These questions are relevant and actionable, as they prompt the authors to provide additional information about the training process and its efficiency. By addressing these questions, the authors can enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it provided context or suggested why this information is important. Overall, the feedback is 3 as it directs the authors to improve their draft by providing additional details, but it could be more comprehensive with further guidance or explanation. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the author\"s claim regarding the design of GPDE, suggesting that it is an incremental improvement over GraphCON. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this claim or what changes, if any, should be made to their draft. Without actionable suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GPDE,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that GPDE is an incremental improvement over GraphCON, providing a clear basis for the critique. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that GPDE is an incremental improvement over GraphCON, specifically noting the substitution of a static encoder for SNN. This claim is 3 as it provides a logical reasoning based on the structure of GPDE and its relationship to GraphCON. However, the comment lacks specific references or detailed comparisons to fully substantiate the claim, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a potential issue with the author\"s claim regarding the design of GPDE, suggesting that it is an incremental improvement over GraphCON. This feedback is 3 as it highlights a possible misrepresentation of the novelty of GPDE, prompting the authors to reconsider their claims. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their argument. To be more helpful, the comment could include recommendations on how to differentiate GPDE from GraphCON or provide examples of how GPDE truly leverages the advantages of both spike ODE and graph ODE. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the proposed method does not significantly outperform Jiang et al. in specific metrics, such as Penetration(Dep), In CR, and SimDisp(Mean). However, it does not provide any explicit or implicit suggestions for improvement. The authors are left without guidance on how to address this issue or what changes might be necessary to enhance their method\"s performance. Without actionable advice or suggestions, the comment lacks utility for the authors in improving their draft. Therefore, it is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific metrics, such as Penetration(Dep), In CR, and SimDisp(Mean), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the performance comparison between the proposed method and Jiang et al., highlighting the small margin of improvement and the worse performance in certain metrics. This provides clear guidance on what needs to be addressed in terms of performance evaluation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method does not significantly outperform Jiang et al. in specific metrics, such as Penetration(Dep), In CR, and SimDisp(Mean). The reviewer provides detailed numerical comparisons, which are verifiable through the specific values provided. However, the comment lacks additional context or explanation to fully substantiate the claim, such as why these metrics are important or how they relate to the overall performance of the method. Therefore, the claim is 4, as it provides a solid foundation but could be strengthened with more detailed reasoning or references.", "helpfulness_rationale": "The review comment highlights a specific issue with the proposed method, noting that it does not significantly outperform Jiang et al. in certain metrics. It provides detailed numerical comparisons, such as the 0.03% improvement in Penetration(Dep) and the worse performance in SimDisp(Mean). This feedback is clear and actionable, as it directs the authors\" attention to areas where their method may need improvement. However, the comment could be more helpful if it suggested ways to address these performance gaps or provided context on why these metrics are important. Overall, the comment is 4 as it identifies a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises two issues. First, it notes that the term \"vFSAD\" refers to OOD detection in timeseries data, which includes a large quantity of work that has not been compared with or even mentioned. This implies that the authors should include a comparison or mention of this work. Second, it points out that the related work subtitles for \"Policy\" and \"Evaluation tasks\" are not descriptive and seemingly unrelated to the actual content. This suggests that the authors should revise these subtitles to better reflect the content. Both actions are explicit and provide clear guidance on what needs to be done, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"vFSAD,\" which allows the authors to identify the part of the paper being addressed. It also specifies the issue by pointing out that the term \"vFSAD\" refers to OOD detection in timeseries data, which includes a large quantity of work that has not been compared with or even mentioned. Additionally, it highlights the lack of descriptive related work subtitles for \"Policy\" and \"Evaluation tasks,\" suggesting that these subtitles are unrelated to the actual content. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two claims. The first claim is that the term \"vFSAD\" refers to OOD detection in timeseries data, which includes a large quantity of work that has not been compared with or even mentioned. This claim is 3 as it provides a logical reasoning that the term \"vFSAD\" is not adequately discussed or compared with existing work, but it lacks specific references or examples to fully substantiate the claim. The second claim is that the related work subtitles for \"Policy\" and \"Evaluation tasks\" are not descriptive and seemingly unrelated to the actual content. This claim is 3 as it highlights a potential issue with the organization of the related work section, but it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the overall comment is rated as 3.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. First, it notes that the term \"vFSAD\" refers to OOD detection in timeseries data, which includes a large quantity of work that has not been compared with or even mentioned. This suggests that the authors should include a comparison or mention of this work, which could enhance the context and relevance of their study. Second, it points out that the related work subtitles for \"Policy\" and \"Evaluation tasks\" are not descriptive and seemingly unrelated to the actual content. This feedback highlights a potential issue with the organization and clarity of the related work section, suggesting that the authors should revise these subtitles to better reflect the content. Both points are clear and actionable, offering specific guidance for improvement. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that an ablation study should be conducted to evaluate the effect of memory size on the results. This provides a clear and direct action for the authors to take, as it specifies exactly what needs to be done to address the ambiguity regarding memory size selection. The comment is concrete because it outlines a specific study that should be conducted, making it 5.", "grounding_specificity_rationale": "The comment suggests adding an ablation study to evaluate the effect of memory size on the results. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for an ablation study to justify the memory size selection, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the effect of memory size is ambiguous and suggests adding an ablation study to justify the memory size selection. However, the comment does not provide any specific reasoning or evidence to support why the current analysis is insufficient or how an ablation study would address the ambiguity. Without detailed justification or examples, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of ambiguity in the paper regarding the effect of memory size. It suggests that an ablation study should be conducted to justify the memory size selection, which is a clear and actionable piece of feedback. By recommending an additional study, the comment provides the authors with a concrete step to take to improve the clarity and justification of their work. However, the comment could be more helpful if it provided more detailed guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the feedback is 4 as it directs the authors toward a meaningful improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the use of the abbreviation \"GNN\" and its full definition, noting that the full definition appears much later in the paper. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should clarify the definition earlier, change the order of sections, or make any other adjustments. The comment lacks actionable advice, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific parts of the paper where the issue is observed, namely the end of page 1 and the end of page 2. It specifies the problem by pointing out the inconsistency in the use of the abbreviation \"GNN\" and its full definition, \"Graph Neural Network (GNN).\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual observation about the placement of the abbreviation \"GNN\" and its full definition in the paper. It does not express an opinion, judgment, or suggestion that requires verification. It is purely descriptive and does not contain any claims or subjective statements. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the placement of the abbreviation \"GNN\" and its full definition in the paper. It points out that the abbreviation appears at the end of page 1, while the full definition is not introduced until the end of page 2. This observation highlights a potential confusion for readers who may not be familiar with the terminology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending a reordering of sections or providing a clearer explanation of the terminology. While it identifies a problem, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the performance of baseline methods on the DAVIS dataset, noting that it is rather low compared to stateoftheart results. It also questions the effectiveness of the proposed loss function on topperforming algorithms. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their draft. There is no clear action for the authors to take, such as recommending specific changes to the methodology or analysis. The lack of actionable advice makes it difficult for the authors to know how to proceed, rendering the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the DAVIS dataset and the performance of baseline methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the low performance compared to stateoftheart results and questioning the effectiveness of the proposed loss function on topperforming algorithms. The reference to a specific paper by Luiten et al. (2020) provides additional context and evidence for the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of baseline methods on the DAVIS dataset is low compared to stateoftheart results, citing a specific example from a referenced paper. This claim is supported by the reference to a study that provides a benchmark for comparison, which helps verify the claim. However, the comment could be strengthened by providing more detailed comparisons or additional references to support the assertion about the effectiveness of the proposed loss function on topperforming algorithms. Overall, the claim is 4, as it provides a solid basis for the assertion but could benefit from further elaboration.", "helpfulness_rationale": "The review comment points out a concern about the performance of baseline methods on the DAVIS dataset, noting that it is rather low compared to stateoftheart results. It also questions the effectiveness of the proposed loss function on topperforming algorithms, suggesting that the current results may not be indicative of the method\"s true potential. While the comment identifies a potential issue with the evaluation of the proposed method, it lacks specific suggestions or guidance on how the authors might address this concern or improve their results. The feedback is 3 as it highlights an area for further investigation, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results for the proposed twostep decoding method, specifically asking if the results in Table 1 with decoder downsampling are obtained with or without the twostep method. It also inquires about the performance difference between the twostep method and the baseline. While the comment implies that the authors should clarify these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information about the results and their comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the results for the proposed twostep decoding method, specifically asking if the results in Table 1 with decoder downsampling are obtained with or without the twostep method. It also inquires about the performance difference between the twostep method and the baseline. However, the comment does not specify which part of the paper should be revised to address these questions, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the results and performance comparison. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the results for the proposed twostep decoding method, specifically asking if the results in Table 1 with decoder downsampling are obtained with or without the twostep method. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the results for the proposed twostep decoding method, specifically asking if the results in Table 1 with decoder downsampling are obtained with or without the twostep method. It also inquires about the performance difference between the twostep method and the baseline. While the comment identifies a potential gap in the paper regarding the reporting of results, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it prompts the authors to clarify their results, but it lacks actionable advice or detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to increase the font size in the figures to improve readability. This is a clear and direct action that the authors can take to address the issue. The comment provides a specific and concrete suggestion, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"figures,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the font size being too small and provides a direct action for improvement: increasing the font size to enhance readability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for improvement regarding the font size in the figures, suggesting that it is too small and should be increased for better readability. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for clarification or improvement, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, identifying a specific issue with the font size in the figures and suggesting a straightforward solution to improve readability. By instructing the authors to increase the font size, the comment provides a concrete step that can be taken to enhance the clarity and accessibility of the figures. This feedback is valuable as it directly addresses a practical issue that can impact the reader\"s experience, making it 5 for the authors to improve their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point notes that only synthetic problems are considered in the experiments, implying that the authors should consider including realworld problems as well. However, the comment does not provide explicit guidance on how to incorporate realworld problems or suggest specific methods for doing so. The action is implicit and somewhat vague, as the authors can infer that they need to expand their experiments to include realworld scenarios, but they are not given concrete steps on how to do this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment indicates that only synthetic problems are considered in the experiments, but it does not specify which part of the paper this observation is based on, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. However, the comment is specific in pointing out the limitation of considering only synthetic problems, which provides some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that only synthetic problems are considered in the experiments. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential limitation in the experiments, noting that only synthetic problems are considered. This is a relevant observation that could impact the generalizability and applicability of the results. However, the comment lacks specificity and does not provide suggestions or guidance on how the authors might address this issue or expand their experiments to include realworld problems. Without actionable advice or detailed feedback, the authors are left with a general observation that does not fully support their efforts to improve the draft. Therefore, the comment is 3, as it identifies a potential area for improvement but does not offer comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include NLE baselines in their comparison, specifically suggesting that they should compare their explainer with other NLE interpretability tools. This feedback provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and actionable, as it outlines a concrete step for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to include NLE baselines in the comparison, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the comparison, namely the inclusion of other NLE interpretability tools. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the authors should include NLE baselines in their comparison, as their explainer generates natural language explanations. This claim is 3 as it provides a logical reasoning for the inclusion of NLE baselines, given the nature of the explainer. However, the comment lacks specific examples or references to other NLE interpretability tools that could be used for comparison, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the authors have only compared their explainer to feature attribution type of explanations, despite generating natural language explanations. It suggests that the authors should include comparisons with other NLE interpretability tools, which would provide a more comprehensive evaluation of their work. This feedback is clear and actionable, offering a concrete suggestion for enhancing the paper\"s analysis and interpretation. However, it could be more helpful if it provided examples of specific NLE interpretability tools to consider or detailed guidance on how to incorporate them into the comparison. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with Eq. (5), noting that only one pertinent positive data point is used, while many other data points satisfy Eq. (1) and Eq. (2). It suggests that Eq. (5) should include an exhaustive test over the diversity of all these data points. While the comment identifies a potential issue and provides a clear direction for improvement, it does not explicitly instruct the authors to make the suggested changes. The action is implicit and somewhat vague, as the authors need to infer that they should expand Eq. (5) to include more data points. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eq. (5), Eq. (1), and Eq. (2)), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that only one pertinent positive data point is used in Eq. (5), while many other data points satisfy Eq. (1) and Eq. (2). The comment further explains that these data points contribute equally to Eq. (3) but have different perturbation directions, and it suggests that Eq. (5) should include an exhaustive test over the diversity of all these data points. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that Eq. (5) uses only one pertinent positive data point, while many other data points satisfy Eq. (1) and Eq. (2). It suggests that Eq. (5) should include an exhaustive test over the diversity of all these data points. The comment provides a logical reasoning by pointing out the potential limitation in the current approach, which is based on a single data point. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the issue to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of data points in Eq. (5), noting that only one pertinent positive data point is used while many other data points satisfy Eq. (1) and Eq. (2). It points out that these data points contribute equally to Eq. (3) but have different perturbation directions, suggesting that Eq. (5) should include an exhaustive test over the diversity of all these data points. This feedback is clear and actionable, as it provides a specific area for improvement and a concrete suggestion for expanding the analysis. By addressing this issue, the authors can enhance the robustness and comprehensiveness of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include a comparison of their results with the supervision data, specifically mentioning InParsV2 and Promptagator. It also implies that the authors should demonstrate how document augmentation can enhance the performance of the existing supervised retriever. While the comment provides a clear direction for the authors to include additional comparisons and analyses, it does not specify how to implement these suggestions or provide detailed guidance on what specific comparisons or analyses should be conducted. The action is explicit but somewhat vague, as the authors know they need to include additional comparisons but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison of results without using supervision data, which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, how document augmentation can enhance the performance of the existing supervised retriever. The comment provides a clear direction for the authors to include additional comparisons and analyses, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the results are compared fully without using supervision data, which is why InParsV2 and Promptagator are not included in the comparison. The reviewer suggests that it would be beneficial to see how document augmentation can enhance the performance of the existing supervised retriever. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that document augmentation would be beneficial. The suggestion is 3, as it provides a logical argument but lacks concrete evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison of results, noting that the authors have not included InParsV2 and Promptagator due to the absence of supervision data. It suggests that it would be beneficial to see how document augmentation can enhance the performance of the existing supervised retriever, given that training signals and trained retrievers are available. This feedback is clear and actionable, as it provides a specific direction for the authors to consider, namely, how document augmentation can improve performance in conjunction with existing supervised retrievers. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4, as it effectively directs the authors to a potential area for improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the cache hierarchy is not discussed, specifically mentioning the order of dimensions, data sharing, and how the individual levels are applied together. It also notes a contradiction between the initial hierarchy claim and the independence of the levels. While the comment identifies specific areas that need clarification or discussion, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to discuss the cache hierarchy and its application, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it highlights areas for improvement but does not provide detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the cache hierarchy, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the order of dimensions in the cache hierarchy, data sharing, and how the individual levels are applied together are not discussed. Additionally, it highlights a contradiction between the initial hierarchy claim and the independence of the levels. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the cache hierarchy is not discussed, specifically mentioning the order of dimensions, data sharing, and how the individual levels are applied together. The reviewer provides a logical reasoning by pointing out a contradiction between the initial hierarchy claim and the independence of the levels. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact aspects that are missing from the discussion, which could be challenging without further guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion of the cache hierarchy, specifically noting the lack of information on the order of dimensions, data sharing, and how the individual levels are applied together. It points out a contradiction between the initial hierarchy claim and the independence of the levels, which is a critical observation that could impact the understanding of the cache hierarchy\"s effectiveness. However, the comment does not provide specific suggestions or guidance on how to address these issues, such as recommending additional experiments or analyses to clarify the hierarchy. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" method for managing GPU memory during pretraining, given the observation that three forward propagations are required before one backpropagation. While the comment does not explicitly instruct the authors to address this issue, it implies that they should provide an explanation or solution for managing GPU memory. The action is implicit but concrete, as the authors know they need to address the issue of GPU memory management. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the method used to manage GPU memory during pretraining, given the observation that three forward propagations are required before one backpropagation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the authors\" method for managing GPU memory during pretraining, given the observation that three forward propagations are required before one backpropagation. It does not contain a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the authors\" method for managing GPU memory during pretraining, given the observation that three forward propagations are required before one backpropagation. This is a relevant and important point that could impact the feasibility and efficiency of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their approach. While it identifies a potential concern, it lacks actionable feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to rewrite and better present their contributions in the abstract. This provides a clear and direct action for the authors to take. However, the comment does not specify what aspects of the abstract need improvement or how to better present the contributions, leaving some room for ambiguity. While the action is explicit, the lack of detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the abstract, specifically noting that it is not wellwritten and difficult to understand the contributions. However, it does not specify which parts of the abstract are problematic or what specific aspects need improvement. This lack of detail makes it difficult for the authors to pinpoint the exact areas that need revision. The comment is weakly grounded as it does not identify a specific section or element of the abstract, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the abstract is not wellwritten and difficult to understand the contributions. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the abstract, noting that it is not wellwritten and difficult to understand the contributions. It provides a clear and actionable suggestion to rewrite and better present the contributions, which is a valuable piece of feedback for the authors. However, the comment lacks specific guidance on what aspects of the abstract need improvement or how to better present the contributions, which could be beneficial for the authors. While it points out a critical area for enhancement, the feedback could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point continues from the previous comment, stating that ADE is a dataset for image parsing that may be biased among different scenes and favor the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the potential bias or improve the dataset\"s performance. The comment lacks actionable advice, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the exact section or aspect that needs attention. Additionally, the comment lacks specificity as it does not provide details on how the dataset might be biased or how it favors the proposed method. Without clear guidance or examples, the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that ADE, a dataset for image parsing, may be biased among different scenes and favor the performance of the proposed method. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment continues from the previous point by mentioning that ADE, a dataset for image parsing, may be biased among different scenes and favor the performance of the proposed method. However, it does not provide any specific guidance or suggestions on how the authors might address this potential bias or improve the dataset\"s performance. The comment lacks actionable feedback or detailed advice, leaving the authors without a clear understanding of what steps to take to enhance their work. As a result, the comment is 1, as it does not offer any constructive direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of two matrices to represent each relation (edge type) in section 2.1.2, suggesting that the matrices might be redundant. The reviewer also notes that many matrices are not used in the following text. While the comment implies that the authors should clarify the rationale behind using two matrices and potentially remove unnecessary ones, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.1.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of two matrices to represent each relation and noting that many matrices are not used in the following text. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the use of two matrices to represent each relation (edge type) in section 2.1.2, suggesting that the matrices might be redundant. The reviewer also notes that many matrices are not used in the following text. While the comment raises a valid point about potential redundancy, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the issue and its significance themselves. Therefore, the comment is 3, as it provides a basis for further exploration but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the representation of relations in section 2.1.2, noting that each relation is represented by two matrices (A, B, C, D, E, F) but questioning whether these matrices are redundant. It also points out that many of these matrices are not used in the following text. This feedback is 3 as it prompts the authors to clarify their representation and potentially simplify their approach. However, the comment could be more helpful if it provided specific suggestions on how to address the redundancy or offered examples of alternative representations. Overall, the comment is 3, as it directs the authors to a specific area for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about a specific statement in Section 2, questioning the meaning of \"the semantics of the upsampled feature map can be stronger than the original one.\" However, it does not provide any guidance or suggestions on how the authors might clarify this point or improve the explanation. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of what needs to be done to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion about the statement \"the semantics of the upsampled feature map can be stronger than the original one.\" This provides clear guidance on what needs to be clarified or explained further. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about a statement in Section 2, specifically questioning the meaning of \"the semantics of the upsampled feature map can be stronger than the original one.\" However, the comment does not provide any additional context, reasoning, or examples to support or clarify the confusion. Without further explanation or references, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper, specifically questioning the meaning of \"the semantics of the upsampled feature map can be stronger than the original one.\" This feedback is valuable as it highlights a potential area of misunderstanding in the paper, prompting the authors to clarify or revise this section to ensure clarity for readers. However, the comment does not provide suggestions or guidance on how to address this issue, such as proposing alternative explanations or examples. While it points out a critical area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should clarify the differences between their method and other methods for predicting user personality, specifically mentioning a reference 1. While the comment implies that the authors should provide a comparison or differentiation, it does not explicitly instruct them to do so or offer specific guidance on how to present this comparison. The action is implicit and somewhat vague, as the authors can infer that they need to address the comparison but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests clarifying the differences between the method presented in the paper and other methods for predicting user personality, specifically mentioning a reference 1. However, it does not specify which part of the paper this comparison should be made in, nor does it provide detailed guidance on how to address the differences. The authors can infer that it relates to the methodology or results sections, but the comment lacks full grounding as it does not explicitly mention these sections. Additionally, while it suggests a comparison, it does not specify what aspects of the methods should be compared or how to present the differences. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should clarify the differences between their method and other methods for predicting user personality, specifically referencing a paper by Yang et al. 1. This claim is 3 as it provides a specific reference to an external work that could be used for comparison. However, the comment lacks detailed reasoning or examples of how the referenced work differs from the authors\" method, which would strengthen the justification. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment suggests that the authors should clarify the differences between their method and other methods for predicting user personality, specifically referencing a paper by Yang et al. 1. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a clearer differentiation between the methods. However, the comment lacks specific guidance on how to present this comparison or what aspects of the methods should be emphasized. While it points out a relevant issue, it does not provide detailed suggestions or examples, leaving the authors with a general direction but not a comprehensive plan for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the theoretical justification for imposing B to be the basis and A to be coordinate in LoRA tuning, suggesting that this constraint might not be necessary for convergence. It also questions the need for step size tuning despite the theoretical claim that a constant step size is sufficient. While the comment identifies areas of uncertainty and potential improvements, it does not provide explicit instructions or concrete suggestions for the authors to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should provide a theoretical justification or consider step size tuning. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses two specific aspects of the paper: the theoretical justification for imposing B as the basis and A as coordinate in LoRA tuning, and the need for step size tuning despite the theoretical claim of a constant step size being sufficient. However, it does not explicitly mention which sections or parts of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the theoretical justification and the need for step size tuning, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the theoretical justification for imposing B as the basis and A as coordinate in LoRA tuning, suggesting that this constraint might not be necessary for convergence. The reviewer also questions the need for step size tuning despite the theoretical claim that a constant step size is sufficient. While the comment identifies areas of uncertainty and potential improvements, it lacks specific reasoning or references to support the claims. The lack of detailed explanation or evidence makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification or examples to be 5.", "helpfulness_rationale": "The review comment raises a question about the theoretical justification for imposing B as the basis and A as coordinate in LoRA tuning, suggesting that this constraint might not be necessary for convergence. It also questions the need for step size tuning despite the theoretical claim that a constant step size is sufficient. While the comment identifies areas of uncertainty and potential improvements, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas for further exploration, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct more ablation studies or analyses on problems other than shortest path problems to make their design more convincing. While the comment implies that the authors should expand their experimental scope, it does not provide specific guidance on which other problems to consider or how to conduct these additional studies. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting more ablation studies or analyses on problems other than shortest path problems to make the design more convincing. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental design or results, but the lack of explicit grounding makes it difficult to pinpoint the exact area needing attention. The comment is specific in suggesting additional analyses, but without clear grounding, it aligns with a 3 label.", "verifiability_rationale": "The review point suggests that the experimental environments are closely related to the shortest path problem and that the design of the architecture (PathGNN) is biased towards this kind of problem. The reviewer recommends conducting more ablation studies or analyses on problems other than shortest path problems to make the design more convincing. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that the current design is biased. This makes the claim 3, as the authors would need to further develop the reasoning to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential bias in the experimental design, noting that most environments are closely related to the shortest path problem and that the architecture (PathGNN) is biased towards this kind of problem. It suggests that conducting more ablation studies or analyses on problems other than shortest path problems would make the design more convincing. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental scope and improve the robustness of their design. However, the comment could be more helpful if it offered examples of alternative problems or suggested specific analyses to conduct. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper could include more recent models, particularly in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. While the comment implies that the authors should expand their comparison to include more recent models, it does not provide specific guidance on which models to consider or how to incorporate them into the analysis. The action is implicit and somewhat vague, as the authors need to infer which models to include and how to integrate them into the study. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could include more recent models, particularly in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the comparison of models, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of more recent models, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could include more recent models, particularly in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. This is a claim that requires justification, as it implies that the current comparison is incomplete or outdated. However, the comment does not provide specific examples of recent models or detailed reasoning to support the claim, making it difficult for the authors to understand the basis of the suggestion. Without such evidence or examples, the claim remains 3, as it lacks the necessary details to fully substantiate the recommendation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper could include more recent models, particularly in multilingual settings or other languages beyond English, when comparing ControlSpeech with baselines. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of more recent models to enhance the comparison. However, the comment lacks specific guidance on which models to consider or how to integrate them into the analysis, leaving the authors with a general direction but not a detailed plan for implementation. To be more helpful, the comment could provide examples of relevant models or suggest specific ways to incorporate them into the study. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of visualization of the learned context token, which is crucial for understanding the differences in context tokens across different groups. It also notes that the paper is simple and effective but lacks novelty and analysis for the insight of the approach. However, the comment does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors are left to infer that they need to include visualizations and analysis to enhance the novelty and insight of their work. While the action is implicit, it is vague because it does not specify how to implement these changes. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights the lack of visualization of the learned context token, which is crucial for understanding the differences in context tokens across different groups. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where this visualization should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what is missing, namely the visualization of the learned context token, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks visualization of the learned context token, which is crucial for understanding the differences in context tokens across different groups. It also suggests that the paper is simple and effective but lacks novelty and analysis for the insight of the approach. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of visualization of the learned context token, which is crucial for understanding the differences in context tokens across different groups. This feedback is actionable as it highlights a gap in the paper that could enhance its clarity and insight. However, the comment could be more helpful if it provided suggestions on how to visualize this information or what specific aspects of the context token should be highlighted. Additionally, the comment mentions that the paper is simple and effective but lacks novelty and analysis, which is a general observation without specific guidance for improvement. Overall, the comment is 3 as it directs the authors to a specific area for enhancement but lacks depth and actionable suggestions for full effectiveness."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should report results for other models besides MetaOptNet to emphasize the generality of their method and demonstrate its effectiveness across multiple baseline models. This feedback provides a clear and direct action for the authors to take, making it 5. The comment is specific and concrete, as it outlines exactly what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current results, which show only small benefits over the baseline model, and suggests that reporting results for other models, such as MetaOptNet, would strengthen the paper by emphasizing the generality of the method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the current results show only small benefits over the baseline model and suggests reporting results for other models to emphasize the generality of the method. However, the comment lacks specific examples or references to support the claim that the current results are insufficient or that reporting results for other models would significantly improve the paper. Without detailed evidence or examples, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental section, noting that the current results show only small benefits over the baseline model. It suggests that reporting results for other models, such as MetaOptNet, would strengthen the paper by emphasizing the generality of the method and demonstrating its effectiveness across multiple baseline models. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the robustness and applicability of their results. However, the comment could be more helpful if it offered guidance on which other models to consider or how to present the results effectively. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper could benefit from a more extensive comparison by including wellestablished methods like FTML and LFW. This feedback is explicit and provides concrete suggestions for the authors to consider, such as including specific methods in their comparison. The action is clear and actionable, as it directs the authors to expand their comparison to provide a more comprehensive evaluation of their proposed method. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from a more extensive comparison by including wellestablished methods like FTML and LFW. However, it does not specify which part of the paper this comparison should be included in, such as the results or discussion sections. This lack of explicit reference to a specific part of the paper makes it weakly grounded. The comment is specific in suggesting the inclusion of specific methods for comparison, which provides some guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from a more extensive comparison by including wellestablished methods like FTML and LFW. The claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples of how these methods would enhance the evaluation. The authors would need to infer the potential benefits of including these methods in the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s comparison with recent baselines, suggesting that a more extensive comparison could be beneficial. It specifically mentions the inclusion of wellestablished methods like FTML and LFW, which would provide a more comprehensive evaluation of the proposed method\"s strengths and weaknesses. This feedback is clear and actionable, as it directs the authors to expand their comparison to include specific methods, offering a concrete way to enhance the paper\"s evaluation. However, the comment could be more helpful if it provided additional context or rationale for why these specific methods are important for comparison. Overall, the comment is 4, as it provides valuable guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the proposed CRF variants underperform the hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It suggests that the focus on modeling the task using a CRF should be downgraded and that location embeddings may be useful for specific types of datasets. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as it lacks concrete steps or suggestions for the authors to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed CRF variants\" and the \"hierarchical transformers (HiTRF),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the underperformance of the CRF variants compared to HiTRF on both the main dataset and the dataset discussed in Appendix D. Additionally, it highlights the lack of discussion about the potential usefulness of location embeddings for specific types of datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed CRF variants underperform the hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It also suggests that location embeddings may be useful for specific types of datasets but are not discussed in the paper. The claim is 3 as it provides a comparison between the CRF variants and HiTRF, which is a logical basis for the claim. However, the comment lacks specific examples or detailed analysis to fully substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the performance of the proposed CRF variants, noting that they underperform the hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It suggests that the focus on modeling the task using a CRF should be downgraded, which is a clear and actionable piece of feedback. Additionally, the comment points out that location embeddings may be useful for specific types of datasets but are not discussed in the paper, providing a potential area for further exploration. However, the comment could be more helpful if it offered specific suggestions on how to address the underperformance or how to discuss the potential usefulness of location embeddings. Overall, the comment is 4 as it highlights critical areas for improvement and provides some direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the clarity of the impact of trainingtesting inconsistency. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the impact or what specific aspects of the trainingtesting inconsistency need to be addressed. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the impact of trainingtesting inconsistency. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the trainingtesting inconsistency are unclear or how they could be clarified. Without explicit references to sections or detailed guidance, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the clarity of the impact of trainingtesting inconsistency. However, it does not provide any supporting evidence, reasoning, or examples to justify why this inconsistency is problematic or how it affects the paper\"s results. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the paper regarding the clarity of the impact of trainingtesting inconsistency. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern. Without actionable feedback or detailed insights, the authors are left without a clear understanding of what needs to be improved or how to improve it. Therefore, the comment is 1, as it does not offer any constructive direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the condition for y membership and questions the validity of some claims. However, it does not provide explicit guidance on how to address these issues or clarify the claims. The authors are left to infer that they need to provide more detailed explanations or evidence to support their claims, but the comment lacks concrete steps or suggestions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the condition for y membership and questions the validity of some claims, specifically mentioning the second line after Eq. This provides some level of grounding as it implies that the issue is related to the mathematical or theoretical sections of the paper. However, it does not specify which claims are not backed up or provide detailed guidance on what needs to be clarified or improved. The comment is specific in identifying the issue with the condition for y membership but lacks specificity in detailing the claims that are not backed up. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the condition for y membership is unclear due to the disjoint nature of the sets S, as defined above. It also questions the validity of some claims, specifically mentioning the second line after Eq. However, the comment does not provide any further explanation, examples, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the condition for y membership, noting that it is unclear due to the disjoint nature of the sets S. It also questions the validity of some claims, specifically mentioning the second line after Eq. This feedback is 3 as it points out a potential area of confusion or error in the paper. However, it lacks detailed guidance or suggestions on how to clarify the condition or support the claims, leaving the authors with a general direction but not a clear path to improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that a few key references that are highly related are not compared and explained. However, it does not provide specific guidance on which references are missing or how they should be integrated into the comparison or explanation. The action is implicit, as the authors need to infer that they should include these references, and it is vague because it lacks concrete details on how to implement this action. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"a few key references that are highly related\" but does not specify which references are missing or how they should be integrated into the comparison or explanation. This lack of specificity makes it difficult for the authors to identify which parts of the paper need revision. Additionally, the comment does not explicitly mention a specific section or part of the paper, making it weakly grounded. Therefore, this comment is 2, aligning with category 2.", "verifiability_rationale": "The review point claims that \"a few key references that are highly related\" are not compared and explained. However, the comment does not provide specific examples of these references or explain why they are important or relevant. Without detailed information or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient detail to fully support the assertion.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, noting that a few key references that are highly related are not compared or explained. This feedback is 3 as it points out a potential gap in the paper\"s analysis or discussion. However, it lacks specificity and does not provide guidance on which references are missing or how they should be integrated into the comparison or explanation. To be more helpful, the comment could include examples of these missing references or suggest ways to address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the analysis of SCL in section 5.2 regarding fewshot ability, specifically questioning the claim that a more regularized representation space by SCL leads to better generalization in fewshot scenarios. The comment points out that the results in Figure 7(c) and (d) do not meet expectations, as COCOLM achieves more improvements with fewer labels and the improvements diminish with more labels. Additionally, it suggests that the authors should check if COCOLM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. While the comment identifies specific issues with the analysis and suggests a potential area for further investigation, it does not provide explicit instructions on how to address these concerns or improve the analysis. The action is implicit and somewhat vague, as the authors need to infer that they should reevaluate the analysis and potentially conduct additional experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2\" and \"Figure 7(c) and (d),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the analysis, questioning the claim that a more regularized representation space by SCL leads to better generalization in fewshot scenarios. The comment points out that the results in Figure 7(c) and (d) do not meet expectations, as COCOLM achieves more improvements with fewer labels and the improvements diminish with more labels. Additionally, it suggests that the authors should check if COCOLM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point claims that the analysis of SCL in section 5.2 regarding fewshot ability is not convincing. It provides specific examples from Figure 7(c) and (d), noting that COCOLM achieves more improvements with fewer labels and that these improvements diminish with more labels. This provides a clear basis for the claim, as it references specific figures and observations to support the critique. However, the comment could be strengthened by providing additional context or references to establish the expectation or standard against which the results are being evaluated. Overall, the claim is 4, as it provides a logical basis but lacks comprehensive evidence or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of SCL in section 5.2 regarding fewshot ability. It questions the claim that a more regularized representation space by SCL leads to better generalization in fewshot scenarios, pointing out that the results in Figure 7(c) and (d) do not meet expectations. The comment provides a clear and actionable suggestion for the authors to check if COCOLM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. This feedback is valuable as it highlights a potential weakness in the analysis and offers a specific direction for further investigation. However, the comment could be more helpful if it provided additional context or suggestions on how to address the issue or improve the analysis. Overall, the comment is 4, as it effectively guides the authors toward improving their draft by identifying a specific area for further exploration."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. While the action is explicit, it lacks concrete details on which LLMs to focus on, what specific experiments to conduct, or how to analyze the results. The authors are given a general direction but not a clear roadmap for implementation. Therefore, the comment is 3, as it provides a clear action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine where to incorporate these additional experiments. Additionally, the comment lacks specificity regarding which LLMs should be considered or how the experiments should be conducted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. However, the comment lacks specific reasoning or evidence to support why this is necessary or how it would contribute to the paper\"s findings. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on which LLMs to focus on, what specific experiments to conduct, or how to analyze the results. The feedback is 3 as it points out a direction for further exploration, but it does not offer actionable steps or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors need to clarify what is considered \"short\" and \"long\" video for the purpose of deciding the downsample layers. It also recommends including an appleapple comparison of SOTA VLM/VideoLLM outputs for the qualitative examples added. While the comment implies that the authors should provide more detailed explanations and comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer what needs to be done but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for clarity on what is considered \"short\" and \"long\" video for the purpose of deciding the downsample layers. Additionally, it suggests including an appleapple comparison of SOTA VLM/VideoLLM outputs for the qualitative examples added. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors need to clarify what is considered \"short\" and \"long\" video for the purpose of deciding the downsample layers. It also recommends including an appleapple comparison of SOTA VLM/VideoLLM outputs for the qualitative examples added. However, the comment does not provide any specific reasoning or evidence to support why this clarification or comparison is necessary. Without additional context or justification, the authors may find it challenging to understand the importance of these suggestions. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely the definition of \"short\" and \"long\" video for the purpose of deciding downsample layers. It suggests that the authors should provide more detailed explanations to clarify this point. Additionally, the comment recommends including an appleapple comparison of SOTA VLM/VideoLLM outputs for the qualitative examples added, which could enhance the paper\"s comprehensiveness. While the comment provides actionable feedback, it could be more helpful by offering specific suggestions on how to clarify the definitions or conduct the comparison. Overall, the comment is 4 as it directs the authors to improve the clarity and depth of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation in the paper regarding the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve efficiency, such as suggesting specific methods or techniques to optimize the process. Without actionable advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a potential limitation regarding the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of efficiency and its potential impact, but it lacks detailed guidance on how to address this limitation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point highlights a potential limitation in the paper regarding the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. However, the comment does not provide any specific examples, data, or references to support this claim. Without additional evidence or detailed reasoning, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper regarding the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. This is a relevant observation that could impact the practical application of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the efficiency of their approach. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, as it highlights an area for consideration but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the technical contribution is thin and recommends focusing on finding additional applications and deeply evaluating the approach to increase the manuscript\"s value. While the comment implies that the authors should explore these areas, it does not provide specific guidance on how to find additional applications or evaluate the approach. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take without detailed instructions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the technical contribution of the paper, specifically mentioning that the algorithm proposed is incremental because the interpolative decomposition is not proposed by the paper. It suggests that the authors focus on finding additional applications and deeply evaluating the approach to increase the manuscript\"s value. However, the comment does not specify which part of the paper discusses the algorithm or the proposed contribution, making it weakly grounded. The comment is specific in suggesting areas for improvement, such as finding additional applications and evaluating the approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical contribution is thin and suggests that the algorithm proposed is incremental because the interpolative decomposition is not original. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The suggestion to focus on additional applications and evaluation is logical but not fully substantiated by evidence or detailed reasoning. Therefore, the comment is 3, as it provides a direction for improvement but lacks sufficient justification for the initial claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the technical contribution is thin and that the algorithm proposed is incremental. It suggests that the authors focus on finding additional applications and deeply evaluating the approach to increase the manuscript\"s value. This feedback is 3 as it points out an area for improvement and provides a direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific suggestions or examples of additional applications or evaluation methods. Overall, the comment provides some guidance but lacks depth and detail, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for information about the neural network library used for implementation, indicating that this detail is missing from the paper. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the draft. The comment provides concrete guidance on how to improve the paper by including this information, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the lack of details on the neural network library used for implementation, which provides full grounding as the authors can accurately identify the part of the paper being addressed. However, the comment is specific in pointing out the missing information but does not provide further guidance on how to address this issue or what specific details should be included. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement requesting information about the neural network library used for implementation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by questioning the lack of details about the neural network library used for implementation. This is a clear and actionable piece of feedback that can help the authors improve their draft by providing the necessary information. However, the comment could be more helpful if it suggested where this information should be included or offered guidance on how to present it effectively. Despite this, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that some descriptions are unclear, specifically mentioning undefined math notations and missing details in figure illustrations. However, it does not provide explicit guidance on how to clarify these issues or what specific changes should be made to improve the clarity. The comment includes a list of questions, which are implicit actions for the authors to address, but these questions do not fully specify the necessary steps for improvement. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on how to implement those changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some descriptions\" and \"some math notations,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by mentioning undefined math notations and missing details in figure illustrations. However, the comment does not provide specific examples or details of what is unclear or missing, which limits its specificity. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that \"some descriptions are unclear\" and provides specific examples, such as undefined math notations and missing details in figure illustrations. However, it does not provide detailed explanations or references to support these claims, making it 3. The authors would need to investigate the specific issues to fully understand and address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the descriptions are unclear, such as undefined math notations and missing details in figure illustrations. This feedback is valuable as it points out specific issues that need clarification, allowing the authors to focus their efforts on improving the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify these issues or offered examples of how to improve the descriptions. Despite this, the comment is 4 as it directs the authors to areas that need attention, providing a clear path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should mention the meaning of the notation \nu in the text, beyond its explanation in Algorithm 1. This is a clear and direct action for the authors to take, providing them with a specific step to improve their draft. The comment is concrete in its guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: mentioning the meaning of the notation \nu in the text. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the explanation of notation \nu in Algorithm 1 is insufficient and recommends mentioning its meaning in the text. This is a request for clarification rather than a claim or opinion. It does not contain subjective judgments, suggestions, or deductions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the explanation of notation \nu in Algorithm 1 is insufficient. It suggests that the authors should mention the meaning of \nu in the text, which is a clear and actionable piece of feedback. By addressing this suggestion, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or examples of how the notation is used in the algorithm, which would further guide the authors in making the necessary improvements. Overall, the comment is 4 as it directs the authors to a specific area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of using noise robust loss on pseudolabels compared to positive learning from Equation 9. It suggests that the model might be underfit due to the pseudolabels being very accurate, which could benefit from a toneddown robust loss. However, the comment does not provide explicit instructions or suggestions for the authors to address this issue. While it identifies a potential area of concern, it lacks concrete guidance on how the authors should investigate or resolve the issue. Therefore, the comment is 3, as it points out a potential problem but does not offer specific steps for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"appendix A.4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by comparing the performance of using noise robust loss on pseudolabels versus positive learning from Equation 9. The comment raises a question about the model underfitting due to the pseudolabels being very accurate, which could benefit from a toneddown robust loss. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of using noise robust loss on pseudolabels compared to positive learning from Equation 9. It suggests that the model might be underfit due to the pseudolabels being very accurate, which could benefit from a toneddown robust loss. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an interesting observation about the performance of using noise robust loss on pseudolabels compared to positive learning from Equation 9. It questions whether the model is underfit due to the pseudolabels being very accurate, which could benefit from a toneddown robust loss. This feedback is 3 as it prompts the authors to consider the potential impact of their choice of loss function and the accuracy of their pseudolabels on model performance. However, the comment lacks specific suggestions or guidance on how the authors might investigate or address this issue, such as recommending experiments or analyses to explore the effect of different loss functions or pseudolabel accuracies. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses confusion about a claim made in the paper regarding the impact of an additional exponentiation on runtime. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify or address the confusion, nor are there suggestions for further analysis or experimentation to support the claim. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line number \"L248\" (\u201drequires an extra exponential\u2026\u201d), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly expresses confusion about the claim regarding the impact of an additional exponentiation on runtime, providing a clear indication of what needs to be clarified or addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about a claim regarding the impact of an additional exponentiation on runtime. However, it does not provide any supporting evidence, reasoning, or references to justify why the claim is unclear or why the reviewer is confused. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about a claim regarding the impact of an additional exponentiation on runtime. However, it does not provide any actionable feedback or suggestions for the authors to clarify or address this confusion. Without specific guidance or examples, the authors are left without a clear understanding of what needs to be improved or how to enhance their draft. Therefore, the comment is 1, as it does not offer any constructive feedback or direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the lack of comparison with existing methods, specifically mentioning \"Rubi\" and \"Removing bias in multimodal classifiers.\" It suggests that the experiments are lacking in comparison with stateoftheart (SOTA) methods. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors are left to infer that they need to include comparisons with these methods but are not given concrete steps on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and abstract sections, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the improvements over existing methods and the lack of comparison with SOTA methods. The comment provides specific examples of related works, which further clarifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are lacking in comparison with stateoftheart (SOTA) methods. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of \"Rubi\" and \"Removing bias in multimodal classifiers\" suggests a direction for comparison, but without further elaboration or references, the claim remains somewhat vague. This makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is rated as 3, as it provides some basis for the claim but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with existing methods, specifically mentioning \"Rubi\" and \"Removing bias in multimodal classifiers.\" It highlights the importance of comparing the proposed methods with established works to demonstrate their improvements and relevance. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what aspects to focus on. While it raises a critical issue, the feedback lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that the experiments show the proposed method enhances performance but notes that this is not surprising, as it introduces more learnable parameters, including the temperature, which has been proven effective in previous works. However, the comment does not provide any actionable advice or suggestions for the authors to improve their draft. It lacks specific guidance on how to address the issue of the method\"s effectiveness or how to enhance the paper\"s contribution. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the results of the experiments, specifically mentioning the enhancement of performance due to the introduction of more learnable parameters, including the temperature. However, it does not specify which part of the paper discusses these experiments or results, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, while it provides a rationale for the observed enhancement, it lacks specificity in terms of what needs to be addressed or improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the enhancement in performance is not surprising because the proposed method introduces more learnable parameters, including the temperature, which has been proven effective in previous works. However, the comment does not provide specific references or examples of these previous works, making it difficult for the authors to fully understand and address the claim. The lack of detailed evidence or references leaves the claim 3, as the authors would need to invest effort to identify and verify the referenced works. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the experiments show the proposed method enhances performance but notes that this is not surprising, as it introduces more learnable parameters, including the temperature, which has been proven effective in previous works. However, the comment does not provide any actionable feedback or suggestions for the authors to address this observation or improve their draft. It lacks specificity and does not offer guidance on how the authors might enhance their work or differentiate their contribution from previous studies. As a result, the comment is 1, as it does not provide the authors with any actionable insights or direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the inspiration from neuroscience research as being unnecessary to the main processing pipeline of the main work, suggesting that it makes the main work distracting. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what changes should be made to improve the draft. Without actionable suggestions or a clear direction for revision, the authors are left without a path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the inspiration from neuroscience research as being unnecessary to the main processing pipeline of the main work, suggesting that it makes the main work distracting. However, it does not specify which part of the paper this critique pertains to, such as a specific section or figure where the neuroscience inspiration is discussed. Without explicit references or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the neuroscience inspiration are considered unnecessary or distracting. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the inspiration from neuroscience research is unnecessary and distracting to the main processing pipeline of the main work. However, the comment lacks specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the inspiration from neuroscience research as being unnecessary and distracting to the main processing pipeline of the main work. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the relevance of the neuroscience inspiration. Without actionable feedback or constructive advice, the comment lacks helpfulness, leaving the authors without a clear path for improvement. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to update the caption of Table 3 by adding information about the source dataset. This is a clear and direct action that the authors can take to improve their draft. The comment also provides a rationale for why this change is necessary, ensuring that the reader has all the necessary information without needing to search elsewhere in the text. The feedback is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: adding information about the source dataset in the caption. The comment provides a clear and actionable suggestion, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the source dataset used in Table 3. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for additional information, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the caption in Table 3, noting that it lacks information about the source dataset. It provides a clear and actionable suggestion to update the caption by including this information, ensuring that the reader has all the necessary details without needing to search elsewhere in the text. This feedback is valuable as it directly addresses a potential source of confusion for readers, offering a straightforward way for the authors to improve their draft. However, the comment could be more helpful if it provided additional context or examples of how to present this information effectively. Overall, the comment is 4, as it guides the authors toward a specific improvement that enhances the clarity and accessibility of their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of explicit descriptions of the specific architectures used in the paper, specifically mentioning the value network, policy networks, and uncertainty aware networks. This feedback provides a clear and explicit action for the authors to take, which is to include detailed descriptions of these architectures. By doing so, the authors can ensure that readers have the necessary information to replicate and evaluate the approach. The comment is explicit and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment highlights the lack of explicit descriptions of the specific architectures used in the paper, specifically mentioning the value network, policy networks, and uncertainty aware networks. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or figure where these architectures are discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks explicit descriptions of the specific architectures used, such as the value network, policy networks, and uncertainty aware networks. This makes it difficult for readers to replicate and evaluate the approach. The comment provides a logical reasoning for the claim, as it highlights the importance of detailed descriptions for reproducibility and evaluation. However, it does not provide specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is 3, as it provides a clear rationale but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of explicit descriptions of the specific architectures used, such as the value network, policy networks, and uncertainty aware networks. This omission makes it difficult for readers to replicate and evaluate the approach. The comment highlights a critical area for improvement that directly impacts the paper\"s reproducibility and clarity. By addressing this feedback, the authors can enhance the transparency and comprehensibility of their work, making it more accessible to readers. However, the comment could be more helpful if it provided specific suggestions on how to include these descriptions or examples of similar architectures for reference. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the explicitness (E) and size (S) of the dataset may be highly related, and it provides a rationale for why the different capacity requirements in the third paragraph might be due to input modality differences. It also implies that the evaluation of disentanglement should provide enough capacity and training time to achieve the desired results. Additionally, it suggests considering the training time, cost, and learning rate if the capacity of probing needs to be evaluated. While the comment provides some guidance, it lacks explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors need to infer what specific changes are needed and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"3rd paragraph,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion about the relationship between explicitness (E) and size (S) of the dataset and the different capacity requirements in the third paragraph. Additionally, it offers a rationale for why the capacity requirements might be due to input modality differences and suggests considering factors like training time, cost, and learning rate if the capacity of probing needs to be evaluated. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point suggests that explicitness (E) and size (S) may be highly related to the given dataset, and it provides a rationale for why the different capacity requirements in the third paragraph might be due to input modality differences. The comment also suggests that the evaluation of disentanglement should provide enough capacity and training time to achieve the desired results, and it implies that factors like training time, cost, and learning rate may influence the final value of DCI. While the comment provides some logical reasoning and a plausible explanation, it lacks specific examples or references to support the claims fully. Therefore, the comment is 3, as it provides a reasonable basis for the suggestions but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment provides a thoughtful analysis of the relationship between explicitness (E) and size (S) of the dataset and their impact on the capacity requirements in the third paragraph. It suggests that these factors may be highly related and offers a rationale for why the different capacity requirements might be due to input modality differences. The comment also implies that the evaluation of disentanglement should provide enough capacity and training time to achieve the desired results, and it suggests considering factors like training time, cost, and learning rate if the capacity of probing needs to be evaluated. This feedback is clear and actionable, as it identifies potential areas for improvement and provides specific suggestions for further analysis. However, it could be more helpful if it included examples or detailed guidance on how to implement these suggestions. Overall, the comment is 4, as it offers valuable insights and direction for enhancing the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to avoid using abbreviations in the paper title. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete suggestion, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the paper title, allowing the authors to accurately identify the part of the paper being discussed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of abbreviations in the title. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement that does not express an opinion, judgment, or suggestion. It is a request for clarification or a suggestion for improvement, but it does not require verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to avoid using abbreviations in the paper title. This feedback is specific and offers a straightforward way for the authors to improve the clarity and accessibility of their work. By addressing this point, the authors can enhance the readability and impact of their paper. However, the comment could be more helpful if it explained why abbreviations should be avoided or suggested alternative ways to present the title. Overall, the feedback is 4 as it provides a concrete action for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part suggests that the authors should mention that the discriminator can transfer to other tasks and domains without further training, which is an explicit action. The second part suggests that the authors should mention that the discriminator can be small, which is also an explicit action. Both suggestions are clear and provide concrete guidance on what the authors should include in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L400,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should mention that the discriminator can be small, which is an important insight. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part suggests that the discriminator can transfer to other tasks and domains without further training, which is a claim that requires justification. The second part mentions that the discriminator can be small, which is a factual statement. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim about the discriminator\"s transferability. This lack of support makes the claim 1, as the authors would need to infer the reasoning themselves. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides two distinct points of feedback. The first part suggests that the authors should mention the discriminator\"s ability to transfer to other tasks and domains without further training, which is a valuable insight that could enhance the paper\"s contribution. The second part highlights an important observation at line 400, where the authors show that the discriminator can be small, which is a significant finding. This feedback is clear and actionable, offering the authors specific areas to address and improve their draft. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these insights into the paper. Overall, the feedback is 4, as it directs the authors to important aspects of their work that could be further developed."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to add the SOTA GNNQE as a baseline and compare it to their approach. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the omission of the SOTA GNNQE from the baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the addition of the SOTA GNNQE as a baseline and its comparison with the current approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the current SOTA GNNQE is omitted from the baselines, despite being the closest work in terms of components to the approach. The reviewer provides a clear and logical reasoning for why this omission is significant, as it would allow for a more comprehensive comparison. However, the comment does not include specific references or examples to support the claim, which would strengthen the argument. Therefore, the claim is 4, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, namely the exclusion of the current SOTA GNNQE from the baselines. It highlights the importance of including this baseline for a more comprehensive comparison with the authors\" approach. By pointing out this oversight, the comment provides clear and actionable feedback that can help the authors improve the rigor and completeness of their work. However, the comment could be more helpful if it suggested specific ways to incorporate the SOTA GNNQE into the analysis or provided guidance on how to compare it effectively. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the pretraining data used for GPT2 and questions whether it can truly understand language. It also questions the reasonableness of the setting and suggests that facts may have been learned in GPT2 before training. The reviewer acknowledges the interest of the topic but emphasizes the importance of addressing these concerns to prove the correctness of the findings. While the comment highlights areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors are left to infer what steps to take to address the reviewer\"s concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the pretraining data used for GPT2 and questions whether it can truly understand language. It also questions the reasonableness of the setting and suggests that facts may have been learned in GPT2 before training. However, the comment does not specify which part of the paper these concerns relate to, such as specific sections, experiments, or results. Without explicit references, the authors may find it challenging to pinpoint the exact areas needing revision. The comment is specific in its critique but lacks grounding, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point raises concerns about the pretraining data used for GPT2, questioning whether it can truly understand language. The reviewer also questions the reasonableness of the setting and suggests that facts may have been learned in GPT2 before training. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for the claims but requires more detailed support to be 5.", "helpfulness_rationale": "The review comment raises concerns about the pretraining data used for GPT2, questioning whether it can truly understand language. It also questions the reasonableness of the setting and suggests that facts may have been learned in GPT2 before training. While the comment identifies potential issues with the methodology, it does not provide specific suggestions or guidance on how the authors might address these concerns. The feedback highlights areas that need clarification but lacks actionable advice, making it 3. The authors are left to infer what steps to take to address the reviewer\"s concerns, which limits the comment\"s usefulness. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed method is not thoroughly explained, specifically mentioning the computation of terms in equation (4) and the optimization algorithm, such as how to calculate $p(x_k|d)$. The reviewer suggests that if mathematical expressions are used, every term should be clearly explained, except for cases where it is extremely obvious. This feedback provides explicit guidance on what needs to be clarified or added to the draft, making it 5. The authors know exactly what aspects of their method need further explanation, and the comment offers a clear standard for what constitutes a thorough explanation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the computation of terms in equation (4) and the optimization algorithm, allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it details what is missing in the explanation, such as the calculation of $p(x_k|d)$ and the optimization algorithm. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not thoroughly explained, specifically mentioning the computation of terms in equation (4) and the optimization algorithm. The reviewer provides a clear and logical reasoning by stating that if mathematical expressions are used, every term should be clearly explained, except for cases where it is extremely obvious. This reasoning is supported by the specific examples provided, such as the calculation of $p(x_k|d)$, which helps the authors understand the areas needing clarification. Therefore, the claim is 4, as it provides a clear basis for the critique but could be strengthened with additional references or examples. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the proposed method, pointing out that the computation of terms in equation (4) and the optimization algorithm are missing. It suggests that if mathematical expressions are used, every term should be clearly explained, except for cases where it is extremely obvious. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By highlighting the need for detailed explanations, the comment empowers the authors to improve the comprehensibility of their work. However, it could be more helpful if it offered suggestions on how to clarify these aspects or provided examples of how to present the optimization algorithm. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that the concept of using a mixture of experts (MoE) for a task is not groundbreaking and has been applied in various tasks, such as general LLM, summarization, and machine translation. It also notes that the application of MoE in text detection is relatively new but not fundamentally novel. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this observation or how it could impact their work. Without actionable suggestions or questions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the concept of employing a mixture of experts (MoE) for a task, noting its extensive application in various tasks like general LLM, summarization, and machine translation. It also mentions that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. However, the comment does not specify which part of the paper this discussion is based on, making it difficult for the authors to identify the exact section being addressed. Additionally, while it provides context about the concept of MoE, it lacks specificity regarding what aspects of the paper need improvement or clarification. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point makes a claim about the concept of employing a mixture of experts (MoE) for a task, noting that it is not groundbreaking and has been extensively applied in various tasks. The comment provides a logical reasoning by referencing the widespread use of MoE in general LLM, summarization, and machine translation. However, it lacks specific examples or references to support the claim about the application of MoE in text detection, which would strengthen the argument. Therefore, the comment is 3, as it provides a logical basis but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment acknowledges that the concept of employing a mixture of experts (MoE) for a task is not groundbreaking, as it has been extensively applied in various tasks such as general LLM, summarization, and machine translation. It also notes that the application of MoE in text detection is relatively new but not fundamentally novel. However, the comment does not provide any actionable feedback or suggestions for improvement. It lacks depth and does not offer insights or guidance on how the authors might address this observation or how it could impact their work. As a result, the comment is 1, as it does not assist the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of statistical analysis to support the claim of significant performance improvement by SpaceTGN compared to other baselines. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue or what specific statistical analysis should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they need to include a statistical analysis to substantiate their claim. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the performance improvement of SpaceTGN compared to other baselines. However, it does not specify which part of the paper this claim is made in, such as a particular section or table where the comparison is discussed. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. The comment is specific in identifying the need for a statistical analysis to support the claim of significance, but without clear grounding, it is 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the authors have made a statement about the performance improvement of SpaceTGN compared to other baselines, but they have not provided a statistical analysis to support this claim. This is a valid observation, as the absence of statistical analysis can make it difficult to assess the significance of the improvement. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to address the lack of statistical analysis to fully substantiate their claim, but the comment itself lacks detailed evidence or reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of statistical analysis to support the claim of significant performance improvement by SpaceTGN compared to other baselines. This is a critical issue that the authors need to address to strengthen their argument and provide a more robust evaluation of their work. However, the comment does not offer specific suggestions on how to conduct the statistical analysis or what metrics to use, leaving the authors with a clear area for improvement but without detailed guidance. While the feedback is clear about the need for statistical analysis, it could be more helpful with additional guidance on how to implement it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a potential source of confusion regarding why certain scores are excerpted versus reproduced. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what specific changes or clarifications are needed to resolve the confusion. As a result, the authors are left without a clear understanding of how to improve their draft. Since the action is implicit and vague, the comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a potential source of confusion regarding why certain scores are excerpted versus reproduced. However, it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or improved to resolve the confusion. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the excerpting of certain scores may cause confusion, but it does not provide any specific examples or reasoning to support this claim. Without detailed explanation or references to what scores are being discussed or why their reproduction is unclear, the comment lacks verifiability. The authors would need more information to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential source of confusion in the paper regarding why certain scores are excerpted versus reproduced. However, it does not provide specific guidance or suggestions on how to clarify this issue or address the confusion. Without actionable advice or examples, the authors are left without a clear understanding of what changes or additions are needed to improve the draft. Therefore, the comment is 2, as it highlights a problem but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should comment on how consistency models achieve something that previous generative models cannot. This implies that the authors should provide additional explanation or analysis to differentiate their approach from existing methods. However, the comment does not explicitly instruct the authors to include this information or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer what needs to be done but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of the method, specifically questioning the originality of using consistency models instead of other generative models. It suggests that the authors should provide more explanation on how consistency models achieve something that previous generative models cannot. However, the comment does not explicitly mention which part of the paper this critique pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in its request for additional explanation, which aligns with a score of 3.", "verifiability_rationale": "The review point claims that the method is \"somewhat simply applying consistency models in place of other generative models for learning target distributions,\" suggesting limited novelty. The reviewer supports this claim by stating that consistency models are a recent trend and that the method is not significantly different from existing approaches. However, the comment lacks specific examples or references to substantiate the claim, making it 3. The authors would need to provide additional context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that the method is not particularly novel as it is simply applying consistency models instead of other generative models. It encourages the authors to provide more explanation on how consistency models achieve something that previous generative models cannot. This feedback is 3 as it points out a specific area for improvement, prompting the authors to clarify the novelty and value of their approach. However, the comment could be more helpful if it provided specific suggestions or examples on how the authors might address this issue. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the evaluation metric used in Table 2, specifically noting that MSE (Mean Squared Error) does not adequately reflect the accuracy of nowcasting. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the evaluation metric. There is no guidance on what alternative metrics could be used or how to better assess the accuracy of nowcasting. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation metric, noting that MSE does not adequately reflect the accuracy of nowcasting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation metric used in Table 2, MSE (Mean Squared Error), does not adequately reflect the accuracy of nowcasting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why MSE is insufficient for assessing nowcasting accuracy. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out a specific issue with the evaluation metric used in Table 2, noting that MSE (Mean Squared Error) may not adequately reflect the accuracy of nowcasting. This is a relevant observation that could help the authors reconsider their choice of evaluation metric and potentially improve the accuracy of their results. However, the comment lacks depth and does not provide suggestions or guidance on alternative metrics or how to address this issue. While it identifies a potential weakness, it does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to add specific models to their ablation study, namely \"CapCapNEClipNEEA\" and \"CapCapNEClipNENEEA,\" based on the overview model of ENGINE. It also suggests that the authors should provide more detailed analysis of the ablation results. This feedback is clear and provides concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ablation study of ENGINE, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding specific models to the ablation study and requests more detailed analysis of the ablation results. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the ablation study of ENGINE is incomplete and suggests adding specific models to the study. However, it does not provide any reasoning or evidence to support why these models should be included or how their inclusion would improve the study. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the ablation study of ENGINE, noting that it is incomplete. It provides a clear and actionable suggestion by recommending the addition of specific models, such as \"CapCapNEClipNEEA\" and \"CapCapNEClipNENEEA,\" based on the overview model of ENGINE. Additionally, it advises the authors to provide more detailed analysis of the ablation results. This feedback is constructive and offers a direct path for the authors to enhance their study, making it 4. However, it could be more helpful if it included additional guidance on how to analyze the ablation results or why these specific models are important. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the discrepancy in mode coverage between GAN optimization in GDIM and DDGAN. It suggests that the authors provide results on more challenging highresolution datasets like LSUN and ImageNet to make their findings more convincing. The comment implies that the authors should conduct additional experiments on these datasets to address the issue. While the action is implicit, it is concrete in suggesting a specific dataset to test on. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the discrepancy in mode coverage between GAN optimization in GDIM and DDGAN, suggesting that the authors provide results on more challenging highresolution datasets like LSUN and ImageNet. It also mentions that methods that work well with CIFAR10/Celeb64 might struggle with LSUN/ImageNet. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting additional experiments and referencing the potential challenges with LSUN and ImageNet. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the discrepancy in mode coverage between GAN optimization in GDIM and DDGAN. It suggests that the authors provide results on more challenging highresolution datasets like LSUN and ImageNet to make their findings more convincing. The comment references a common observation that methods that work well with CIFAR10/Celeb64 might struggle with LSUN/ImageNet. This provides some justification for the claim, but it lacks specific examples or detailed reasoning to fully substantiate the suggestion. Therefore, the comment is 3, as it provides a logical basis but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment raises a question about the discrepancy in mode coverage between GAN optimization in GDIM and DDGAN, suggesting that the authors provide results on more challenging highresolution datasets like LSUN and ImageNet. It also references a common observation that methods that work well with CIFAR10/Celeb64 might struggle with LSUN/ImageNet. This feedback is 3 as it identifies a potential gap in the paper\"s evaluation and suggests a way to address it by conducting additional experiments on more challenging datasets. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what metrics to focus on. Overall, the feedback is actionable but incomplete, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of a statement in Section 5.1, specifically asking, \"Each attribute of the table feature represents a scene\"  what does this mean? This comment is a clarification question that does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the question or improve the draft. As a result, the authors are left without a clear understanding of what needs to be done to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.1\" and the specific phrase, \"Each attribute of the table feature represents a scene,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly questions the meaning of the statement, providing a clear direction for the authors to clarify or revise their explanation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of a statement in the paper. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of a statement in Section 5.1, specifically asking, \"Each attribute of the table feature represents a scene\"  what does this mean? This is a clear and direct question that prompts the authors to clarify their explanation, which is a valuable contribution to the review process. However, the comment does not provide any suggestions or guidance on how to improve the clarity of the explanation or the draft as a whole. While it highlights an area that needs attention, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It also questions the effectiveness of the logsumexp aggregator compared to direct addition, which would correspond to basic prototype comparison with reweighted averages on each prototype. Additionally, the comment suggests that the token reweighting scheme is compatible with existing tokentotoken classifiers like CTX and FRN, but it is unclear how the logsumexp aggregator compares. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors can infer that they need to conduct an ablation study and provide comparisons, but the comment lacks detailed guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the absence of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It also questions the effectiveness of the logsumexp aggregator compared to direct addition, which would correspond to basic prototype comparison with reweighted averages on each prototype. Additionally, the comment suggests that the token reweighting scheme is compatible with existing tokentotoken classifiers like CTX and FRN, but it is unclear how the logsumexp aggregator compares. While the comment does not explicitly mention specific sections or figures, the authors can infer that it relates to the methodology or results sections where these comparisons might be discussed. The comment is specific in detailing what is missing or unclear, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It questions the effectiveness of the logsumexp aggregator compared to direct addition, which would correspond to basic prototype comparison with reweighted averages on each prototype. Additionally, the comment suggests that the token reweighting scheme is compatible with existing tokentotoken classifiers like CTX and FRN, but it is unclear how the logsumexp aggregator compares. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim about the compatibility of the token reweighting scheme with existing classifiers. This makes the claim 3, as it provides a logical basis for the suggestion but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It also questions the effectiveness of the logsumexp aggregator compared to direct addition, which would correspond to basic prototype comparison with reweighted averages on each prototype. Additionally, the comment suggests that the token reweighting scheme is compatible with existing tokentotoken classifiers like CTX and FRN, but it is unclear how the logsumexp aggregator compares. This feedback is valuable as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their study by conducting the necessary ablation studies and comparisons. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what metrics to use. Overall, the comment is 4 as it effectively guides the authors toward improving their draft by addressing a significant gap in their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider using larger datasets, specifically mentioning the datasets mentioned in 2. However, it does not provide explicit instructions on how to incorporate these datasets or what specific actions the authors should take to address the issue. The comment implies that the authors should expand their dataset analysis, but it lacks concrete guidance on how to implement this change. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of limited datasets, allowing the authors to accurately identify the part of the paper being addressed. It also provides specific suggestions by recommending the use of larger datasets, specifically referencing 2 and 1. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that five datasets are insufficient to evaluate the effectiveness of ECGs and suggests considering larger datasets mentioned in 2. The comment provides a reference to 1 and 2, which are external sources that support the claim. This makes the claim 4, as it offers specific references to larger datasets that could be considered. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically the use of only five datasets to evaluate the effectiveness of ECGs. It suggests that larger datasets, as mentioned in 2, should be considered. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their dataset analysis. However, the comment could be more helpful if it included a rationale for why larger datasets are necessary or how they might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include a clear statement about the limitation of only analyzing fully connected ResNets, which is a common practice in ResNets. It also suggests that this limitation should be included in the Broader Impact section. This feedback provides a direct and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of fully connected ResNets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of only analyzing fully connected ResNets, which is a common practice in ResNets, and suggests that the paper should include a clear statement about this limitation in the Broader Impact section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only analyzes fully connected ResNets, which is a limitation as ResNets typically use convolutional layers in practice. The reviewer suggests that the paper should clearly state this limitation and include it in the Broader Impact section. While the claim is logical and based on common knowledge about ResNets, it lacks specific examples or references to support the assertion. This makes the claim 3, as the authors would need to provide additional context or evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it only analyzes fully connected ResNets, which is not typical practice in ResNets. It suggests that the paper should clearly state this limitation and include it in the Broader Impact section. This feedback is clear and actionable, providing the authors with a specific area for improvement and guidance on how to address it. By highlighting this limitation and suggesting its inclusion in the broader impact section, the comment offers valuable insight that can help the authors enhance the comprehensiveness and transparency of their work. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point highlights the performance of a student model trained on the training set, specifically mentioning the ResNet18 model and its performance on MNIST, SVHN, and CIFAR10. It also references early knowledge distillation methods that have surpassed the reported performance. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address the performance issues or incorporate the mentioned methods into their work. Without actionable suggestions or specific instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the training of a student model on the training set, specifically referencing the ResNet18 model and its performance on MNIST, SVHN, and CIFAR10. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides detailed information about the performance of the student model and references early knowledge distillation methods that have surpassed the reported performance. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the performance of a student model trained on the training set, specifically mentioning the ResNet18 model and its performance on MNIST, SVHN, and CIFAR10. It also references early knowledge distillation methods that have surpassed the reported performance. However, the comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely descriptive and factual, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides factual information about the performance of a student model trained on the training set, specifically mentioning the ResNet18 model and its performance on MNIST, SVHN, and CIFAR10. It also references early knowledge distillation methods that have surpassed the reported performance. However, the comment lacks any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address the performance issues or incorporate the mentioned methods into their work. As a result, the comment is not helpful, as it does not provide the authors with any actionable insights or direction for enhancing their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption that only node attributes X affect the causal factors, questioning whether this assumption holds for certain GCN variants like Geniepath or Gated GNN. The reviewer suggests that the message and passing routes are learned in a coupled way, which could potentially break the causal graph assumption in the proposed framework. However, the comment does not provide explicit guidance on how the authors should address this concern or whether they should consider these variants in their framework. The action is implicit and somewhat vague, as it points out a potential issue but does not offer specific steps for the authors to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the assumption that only node attributes X affect the causal factors, questioning whether this assumption holds for certain GCN variants like Geniepath or Gated GNN. However, it does not specify which part of the paper this assumption is made in, making it weakly grounded. The comment is specific in its questioning of the causal graph assumption and provides examples of GCN variants that might challenge this assumption. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the assumption that only node attributes X affect the causal factors, questioning whether this assumption holds for certain GCN variants like Geniepath or Gated GNN. The reviewer suggests that the message and passing routes are learned in a coupled way, which could potentially break the causal graph assumption in the proposed framework. However, the comment lacks specific examples or references to support the claim that these variants would indeed break the assumption. The reasoning is somewhat logical but requires more detailed evidence or examples to be 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the assumption that only node attributes X affect the causal factors, questioning whether this assumption holds for certain GCN variants like Geniepath or Gated GNN. It points out a potential issue with the causal graph assumption in the proposed framework, suggesting that the message and passing routes might be learned in a coupled way, which could break the assumption. This feedback is valuable as it highlights a potential limitation or gap in the current framework, prompting the authors to consider alternative approaches or modifications to address this issue. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this concern. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should consider listing the performance of stateoftheart (SOTA) algorithms in each dataset discussed in Table 1. This would help readers understand the gap between NAS models and humanengineered SOTA architectures. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is concrete in terms of what needs to be done, but it is implicit in the comment, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"preprocessing,\" \"messagepassing,\" and \"postprocessing,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the claim that messagepassing is the most important part of GNN, suggesting that different tasks may use different pre/postprocessing modules. The comment further recommends listing the performance of SOTA algorithms in each dataset discussed in Table 1 to help readers understand the gap between NAS models and humanengineered SOTA architectures. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors have only considered messagepassing layers as the most important part of GNN, despite different tasks using different pre/postprocessing modules. The reviewer suggests that listing the performance of SOTA algorithms in each dataset discussed in Table 1 would help readers understand the gap between NAS models and humanengineered SOTA architectures. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the importance of pre/postprocessing modules. This makes the claim 3, as it requires additional evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the claim that messagepassing layers are the most important part of GNN, despite different tasks using different pre/postprocessing modules. It suggests that the authors should list the performance of SOTA algorithms in each dataset discussed in Table 1 to help readers understand the gap between NAS models and humanengineered SOTA architectures. This feedback is clear and actionable, providing a concrete suggestion for improvement that could enhance the paper\"s comprehensiveness and clarity. By addressing this point, the authors can better position their work in relation to existing literature and provide a more balanced perspective on the importance of different components in GNNs. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be beneficial to demonstrate whether learning the advantage directly is useful. The reviewer questions the importance of learning the advantage directly with the proposed method compared to other methods. While the comment implies that the authors should provide evidence or analysis to support the importance of their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to demonstrate the usefulness of learning the advantage directly. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that it would be beneficial to show whether learning the advantage directly is useful. It also questions the importance of learning the advantage directly with the proposed method compared to other methods. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The authors might infer that it relates to the sections discussing the method or results, but this is not explicitly stated. The comment is specific in its request for evidence and comparison with other methods, but without clear grounding, it remains 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to demonstrate whether learning the advantage directly is useful. The reviewer questions the importance of learning the advantage directly with the proposed method compared to other methods. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that there is little evidence for the importance of learning the advantage directly. This makes the claim 3, as it provides a general critique but lacks the necessary details to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to demonstrate whether learning the advantage directly is useful. It questions the importance of learning the advantage directly with the proposed method compared to other methods, noting that the paper lacks evidence for this importance. While the comment identifies a potential gap in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue or demonstrate the usefulness of their approach. The feedback is 3 as it points out a weakness but lacks actionable advice, making it difficult for the authors to fully understand and address the concern. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests adding explanations about the meaning of variable symbols such as \u03c2, r_i, \u03b1_i, and others in the appended algorithms. While the comment explicitly states the action of adding explanations, it does not provide specific guidance on what aspects of these symbols need clarification or how to present the explanations. The authors are aware of the need to provide more information but may struggle to determine the exact details to include. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests adding explanations about the meaning of variable symbols such as \u03c2, r_i, \u03b1_i, and others in the appended algorithms. However, it does not specify which part of the paper these symbols are used in, making it difficult for the authors to pinpoint the exact sections that need clarification. The comment is specific in suggesting what additional information should be provided, but it lacks grounding as it does not explicitly mention the sections or figures where these symbols are used. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding explanations about the meaning of variable symbols such as \u03c2, r_i, \u03b1_i, and others in the appended algorithms. However, it does not provide any reasoning or justification for why these explanations are necessary or how they would improve the clarity of the paper. Without additional context or examples, the authors may find it challenging to understand the importance of these explanations or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that explanations about the meaning of variable symbols such as \u03c2, r_i, \u03b1_i, and others in the appended algorithms could be added. This feedback is clear and actionable, as it directs the authors to enhance the clarity and comprehensibility of their work by providing additional explanations. However, the comment could be more helpful if it specified which sections of the paper these symbols are used in or provided examples of the types of explanations needed. Overall, the comment is 4 as it guides the authors toward improving the clarity of their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the limited performance gains indicate a lack of innovation and that the method may only represent incremental changes to established methods. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this concern or improve their method to demonstrate more significant innovation. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the limited performance gains indicate a lack of innovation and that the method may only represent incremental changes to established methods. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what specific aspects of the method are lacking in innovation. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what changes or improvements are needed to address the issue of limited innovation. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the limited performance gains suggest a lack of innovation and that the method may only represent incremental changes to established methods. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the limited performance gains indicate a lack of innovation and that the method may only represent incremental changes to established methods. While it identifies a potential issue with the method\"s contribution to the field, it lacks specificity and actionable feedback. The comment does not provide guidance on how the authors might address this concern or suggest ways to enhance the innovation or impact of their method. Without detailed suggestions or examples, the authors are left without a clear path for improvement. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This would provide a clearer picture of the relative strengths and weaknesses of the proposed system. While the comment implies that the authors should include a comparative analysis, it does not explicitly instruct them to do so or provide specific guidance on how to conduct this analysis. The action is implicit and somewhat vague, as the authors can infer the need for a comparative analysis but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology, results, or discussion sections. Without explicit references to specific sections, the authors cannot confidently determine where to incorporate this comparative analysis. The comment is specific in suggesting a comparative analysis, but it lacks grounding as it does not identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This claim is 3 as it provides a logical reasoning for why such an analysis would be beneficial, namely to provide a clearer picture of the relative strengths and weaknesses of the proposed system. However, the comment lacks specific examples or references to existing methods or systems that could be used for comparison, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a clearer understanding of the proposed system\"s strengths and weaknesses relative to others. However, the comment lacks specific guidance on which methods or systems to compare or how to conduct the analysis, leaving the authors with a general direction but not a detailed roadmap for improvement. Therefore, the comment is rated as 3, as it provides some insight but could be more actionable with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the theoretical guarantees of PHGDN_C and its practical performance on a real dataset, specifically the longrange graph benchmark. It suggests that the practical usefulness of PHGDN_C is limited due to its inferior performance compared to existing methods. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue, such as suggesting ways to improve the performance or explaining the discrepancy. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"PHGDN_C,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the theoretical guarantees and the practical performance on the real dataset, particularly the longrange graph benchmark. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the prediction performance of PHGDN_C on a real dataset (longrange graph benchmark) does not outperform existing methods, limiting its practical usefulness. However, the comment lacks specific examples or references to existing methods that are outperforming PHGDN_C, making it difficult for the authors to understand the basis of the claim or address it effectively. Without detailed evidence or comparisons, the claim remains 3, as it provides a general observation but lacks the necessary support to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the practical performance of PHGDN_C, which has theoretical guarantees but does not outperform existing methods on a real dataset (longrange graph benchmark). This feedback highlights a potential limitation in the practical usefulness of the method, providing the authors with a clear area for improvement. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as recommending additional experiments or modifications to enhance performance. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that it is unfair to compare the proposed algorithm with offline RL algorithms for single agents, as the latter are not designed to find an equilibrium. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what changes they should make to their draft. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the comparison of the proposed algorithm with offline RL algorithms for single agents, suggesting that it is unfair due to differences in their objectives. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on how the authors should address this issue. Without explicit references to sections or examples, the authors cannot confidently determine which part of the paper is being discussed, making the comment weakly grounded. Additionally, the comment lacks specificity regarding what needs to be addressed or how the comparison should be adjusted. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that it is unfair to compare the proposed algorithm with offline RL algorithms for single agents, as the latter are not designed to find an equilibrium. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is inappropriate. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with comparing the proposed algorithm with offline RL algorithms for single agents, suggesting that it is unfair due to differences in their objectives. However, the comment lacks specificity and does not provide any actionable guidance or suggestions for how the authors might address this issue or improve their draft. Without detailed feedback or constructive advice, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the paper\"s originality, as it suggests that the three tasks mentioned have been partially covered in prior benchmarks. It implies that the authors should clarify their unique contributions and provide more detailed comparisons to similar works. However, the comment does not explicitly instruct the authors to make these clarifications or comparisons, leaving it as an implicit action. Additionally, while the suggestion is clear, it lacks concrete guidance on how to implement the comparisons or clarify the unique contributions. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment addresses the issue of overlap with prior work, specifically mentioning the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014and their partial coverage in prior benchmarks. It suggests that the paper should clarify its unique contributions and provide more detailed comparisons to similar works. However, the comment does not specify which sections of the paper should include these clarifications or comparisons, making it weakly grounded. The authors can infer that it relates to the methodology and purpose sections, but the lack of explicit references makes it challenging to pinpoint the exact parts. The comment is specific in suggesting the need for more detailed comparisons, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the three tasks mentioned\u2014unanswerable, inconsistent, and counterfactual\u2014have been partially covered in prior benchmarks. However, it does not provide specific examples or references to these prior works, making it difficult for the authors to verify the claim. The suggestion to clarify the paper\"s unique contributions and provide more detailed comparisons to similar works is logical but lacks concrete evidence or detailed reasoning. Therefore, the comment is 3, as it provides a general direction but lacks specific support for the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s originality, noting that the three tasks mentioned\u2014unanswerable, inconsistent, and counterfactual\u2014have been partially covered in prior benchmarks. It suggests that the paper should clarify its unique contributions and provide more detailed comparisons to similar works. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work: distinguishing their contributions from existing research. However, the comment could be more helpful if it provided specific examples of prior works or detailed guidance on how to make these comparisons. Overall, the comment is 4, as it highlights an important area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that Section 1 lacks support materials for the claim that \"human perception is usually invariant to the texture resampling.\" This provides a clear action for the authors to take, which is to provide the necessary support materials to substantiate this claim. The comment is explicit and provides a concrete direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of support materials for the claim that \"human perception is usually invariant to the texture resampling.\" This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 1 lacks support materials for the statement \"human perception is usually invariant to the texture resampling.\" However, the comment does not provide any further explanation, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that Section 1 lacks support materials for the claim that \"human perception is usually invariant to the texture resampling.\" This feedback is clear and actionable, as it directs the authors to provide the necessary support materials to substantiate this claim. However, the comment could be more helpful if it suggested potential sources or methods for providing this support. Despite this, the feedback is 4 as it points out a critical area for improvement and guides the authors toward enhancing the credibility of their claims. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should demonstrate the applicability of MiPKD to other computer vision (CV) tasks beyond singleimage superresolution (SR). It encourages the authors to conduct additional experiments on a broader range of tasks to enhance the method\"s perceived generalizability. While the comment implies that the authors should conduct these experiments, it does not provide specific guidance on which tasks to consider or how to design the experiments. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the generality of the paper, specifically discussing the applicability of MiPKD to other computer vision tasks beyond singleimage superresolution (SR). It suggests conducting additional experiments on a broader range of tasks to enhance the method\"s perceived generalizability. However, the comment does not explicitly mention which part of the paper this discussion is based on, making it weakly grounded. The authors can infer that it relates to the experimental section or the discussion of the method\"s applicability, but this inference is not direct. The comment is specific in suggesting additional experiments to enhance generalizability, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that MiPKD, while primarily discussed in the context of singleimage superresolution (SR) tasks, may not be specifically designed for SR. The reviewer encourages the authors to demonstrate the method\"s applicability to other computer vision (CV) tasks by conducting additional experiments on a broader range of tasks. This claim is 3 as it provides a logical reasoning for the suggestion, noting that the method\"s performance in SR tasks may not necessarily translate to other CV tasks. However, the comment lacks specific examples or references to other CV tasks that could be explored, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s focus on singleimage superresolution (SR) tasks, suggesting that MiPKD may not be specifically designed for this task. It encourages the authors to demonstrate the method\"s applicability to other computer vision (CV) tasks by conducting additional experiments on a broader range of tasks. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the perceived generalizability of their method. However, the comment could be more helpful if it offered suggestions on which other CV tasks to explore or how to design these additional experiments. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that Equations 21 and 22, which describe an alternative scheme, may be omitted without affecting the flow of the section. This comment explicitly states an action for the authors to take, which is to consider removing these equations. However, it does not provide specific guidance on why these equations are unnecessary or how their removal might impact the section\"s flow. While the action is clear, the lack of detailed reasoning or examples makes the comment somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equations 21 and 22,\" allowing the authors to accurately identify the specific parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is that these equations describe an alternative scheme that is not used and may be omitted without affecting the flow of the section. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Equations 21 and 22 describe an alternative scheme that is not used and may be omitted without affecting the flow of the section. However, the comment does not provide any reasoning or evidence to support why these equations are unnecessary or how their removal would not impact the section\"s flow. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that Equations 21 and 22 describe an alternative scheme that is not used and may be omitted without affecting the flow of the section. This feedback is clear and actionable, as it suggests a potential simplification or streamlining of the paper by removing unnecessary content. However, the comment could be more helpful if it provided additional context or reasoning for why these equations are not used or how their removal might impact the overall structure or flow of the paper. Despite this, the comment offers a valuable insight that could help the authors improve the clarity and efficiency of their draft. Therefore, it is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the optimization module uses a simple iteration strategy to optimize two loss functions, and that the overall model builds upon traditional approaches. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the optimization strategy, whether to explore more complex methods, or how to differentiate the model from traditional approaches. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"optimization module\" and the \"two loss functions,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a critique of the model\"s reliance on traditional approaches and suggests that it is incremental. This feedback clearly specifies what the authors need to address, namely, the potential lack of innovation or originality in their approach. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the optimization module relies on a simple iteration strategy and that the overall model builds upon traditional approaches, suggesting it is incremental. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the optimization module uses a simple iteration strategy to optimize two loss functions, suggesting that the overall model builds upon traditional approaches and may be incremental. While the comment identifies a potential limitation, it lacks specific suggestions or guidance on how the authors might address this issue or differentiate their work from traditional approaches. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the writing of the paper can be improved and questions the choice of F(X) for the E(d) case. It also asks for elaboration on how to construct F(X) in the main paper and suggests doing the same for the other two cases in the appendix. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to make these improvements. The authors are left to infer that they need to clarify the choice of F(X) and provide detailed examples in the main paper and appendix. However, the lack of concrete guidance on how to implement these changes makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the writing of the paper can be improved and questions the choice of F(X) for the E(d) case. It also asks for elaboration on how to construct F(X) in the main paper and suggests doing the same for the other two cases in the appendix. While the comment does not explicitly mention a specific section or part of the paper, it provides enough context for the authors to infer that it relates to the methodology or results sections where these choices are discussed. The comment is specific in detailing what needs to be addressed, such as providing more detailed examples of constructing F(X). Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the writing of the paper can be improved and questions the choice of F(X) for the E(d) case. It also asks for elaboration on how to construct F(X) in the main paper and suggests doing the same for the other two cases in the appendix. However, the comment lacks specific reasoning or evidence to support why the choice of F(X) is unclear or how it could be improved. Without detailed explanations or examples, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the clarity of the choice of F(X) for the E(d) case. It questions the choice of 2^d O(d) matrices and suggests that the authors elaborate on how to construct F(X) in the main paper, with the other two cases addressed in the appendix. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s clarity and coherence. By following the recommendation, the authors can improve the comprehensibility of their work for readers. However, the comment could be more helpful if it included additional context or examples to further guide the authors in making these improvements. Overall, the comment is 4, as it effectively directs the authors to enhance the clarity of their paper."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implicit assumptions the paper adopts to make fewshot learning successful. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific assumptions should be considered. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the implicit assumptions the paper adopts to make fewshot learning successful. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is also not specific about what assumptions should be considered or how they might impact the success of fewshot learning. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the implicit assumptions the paper adopts to make fewshot learning successful. However, it does not provide any specific examples, reasoning, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to make improvements based on the feedback.", "helpfulness_rationale": "The review comment raises an important question about the implicit assumptions the paper adopts to make fewshot learning successful. This is a relevant inquiry that could help the authors clarify their methodology and strengthen their argument. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this question or what specific assumptions should be considered. Without actionable feedback or detailed guidance, the authors are left with a general idea of what needs to be explored but without a clear path forward. Therefore, the comment is 3, as it identifies a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors could improve their comparison to prior work by considering other tasks and largescale models. It also recommends providing results for more standard benchmarks in the literature to facilitate comparison. While the comment implies that the authors should expand their comparison, it does not provide specific guidance on which tasks or benchmarks to consider or how to incorporate them into the analysis. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the comparison to prior work could be more thorough by considering other tasks and largescale models, as well as providing results for more standard benchmarks. However, it does not specify which part of the paper this feedback pertains to, such as the methodology or results sections. The authors can infer that it relates to the discussion of prior work and comparisons, but the lack of explicit reference makes it weakly grounded. The comment is specific in suggesting ways to improve the comparison, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the comparison to prior work could be more thorough by considering other tasks and largescale models, as well as providing results for more standard benchmarks. However, the comment does not provide specific examples or references to support the claim that the current comparison is insufficient. Without detailed justification or evidence, the authors may find it challenging to understand the exact areas needing improvement. Therefore, the claim is considered 2, as it lacks sufficient support to be fully actionable.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the thoroughness of the comparison to prior work. It suggests that the authors could expand their comparison to include other tasks and largescale models, as well as provide results for more standard benchmarks in the literature. This feedback is clear and actionable, as it offers a concrete direction for enhancing the paper\"s comparison to prior work. However, the comment could be more helpful if it provided specific examples of tasks or benchmarks to consider, which would further guide the authors in making these improvements. Overall, the comment is 4 as it provides a clear path for enhancing the paper\"s comparison to prior work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. It implies that the contribution of the manuscript could be improved, but it does not provide specific guidance on how to enhance the contribution or what aspects need to be addressed. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about the actions they should take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not specify which part of the paper this assessment is based on, making it difficult for the authors to identify the exact sections that need attention. The comment also lacks specificity regarding what aspects of the manuscript need improvement or how the contribution could be enhanced. Without clear grounding and specificity, the authors are left without a clear direction for revision. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. It implies that the contribution of the manuscript could be improved, but it does not provide specific guidance or suggestions on how to enhance the contribution or what aspects of the manuscript need improvement. The comment lacks actionable feedback or detailed insights, leaving the authors without a clear direction for enhancing their work. As a result, the comment is 1, as it does not offer any constructive feedback or guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the clarity and specificity of the claimed benefits, particularly Benefit 1, which is described as too abstract and lacking contextual detail. It also points out that Benefit 3 includes broad statements without supporting references. However, the comment does not provide explicit guidance or suggestions on how the authors might clarify or improve these benefits. The feedback lacks actionable details, such as recommending specific ways to enhance the clarity or providing examples of how to support the claims with references. As a result, the authors are left without a clear understanding of what changes are needed to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the clarity and specificity of the claimed benefits, particularly Benefit 1, which is described as too abstract and lacking contextual detail. It also points out that Benefit 3 includes broad statements unsupported by references. However, the comment does not specify which sections of the paper these benefits are discussed in, making it difficult for the authors to pinpoint the exact parts that need revision. While the authors might have an idea of where these benefits are mentioned, the lack of explicit references makes the comment weakly grounded. The comment is specific in detailing the issues with the benefits but lacks grounding, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the benefits of understanding the agent\"s performance posttraining are difficult to grasp, particularly Benefit 1, which is described as too abstract and lacking contextual detail. It also critiques Benefit 3 for including broad statements unsupported by references. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of evidence or detailed explanation makes the claim 3, as the authors would need to infer the specific problems and address them without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity and specificity of the claimed benefits, particularly Benefit 1, which is described as too abstract and lacking contextual detail. It also points out that Benefit 3 includes broad statements unsupported by references. While the comment highlights areas that need improvement, it does not provide specific suggestions or guidance on how the authors might clarify or substantiate these benefits. The feedback is 3 as it directs the authors\" attention to areas that need further elaboration, but it lacks actionable advice, making it difficult for the authors to effectively address the issues. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but insufficient for judging effectiveness. While the comment implies that the authors should include quantitative results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should provide quantitative results but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but insufficient for judging effectiveness. However, it does not specify which part of the paper discusses this problem, making it weakly grounded. The comment is specific in its request for quantitative results, but without clear grounding, the authors may struggle to identify the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but insufficient for judging effectiveness. The reviewer provides a logical reasoning by suggesting that quantitative results are necessary for a comprehensive evaluation. However, the comment lacks specific examples or references to support the claim that quantitative results are essential or how they would enhance the evaluation. This makes the claim 3, as it provides a logical basis but lacks detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but insufficient for judging effectiveness. This feedback is 3 as it identifies a gap in the paper that could be addressed to provide a more comprehensive evaluation of the approach. However, the comment does not offer specific suggestions or guidance on how to include quantitative results or what metrics to use, which would make it more actionable. Additionally, the comment is part of a larger review that includes a conclusion and a decision on the paper\"s acceptance, which may distract from the specific feedback on quantitative results. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point questions the categorization of the paper under Fairness/Accountability/Transparency, suggesting that the reviewer might be missing something. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the categorization issue or what specific aspects of the paper might be relevant to this category. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment questions the categorization of the paper under Fairness/Accountability/Transparency, suggesting that the reviewer might be missing something. However, it does not specify which part of the paper this categorization issue pertains to, nor does it provide details on what aspects of the paper might be relevant to this category. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what the reviewer might be missing or what aspects of the paper should be considered for categorization. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the categorization of the paper under Fairness/Accountability/Transparency. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment questions the categorization of the paper under Fairness/Accountability/Transparency, suggesting that the reviewer might be missing something. However, it does not provide any specific feedback or suggestions on how the authors might address this issue or improve their categorization. Without actionable guidance or detailed feedback, the comment lacks helpfulness, as it does not offer the authors a clear path for improvement. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include a machine learning 2step baseline to compare with the heuristic methods. The comment implies that the improvement over baselines could be due to the different class of algorithm, rather than the authors\" assertion that NaviFormer outperforms due to its joint handling of routing and path planning. While the comment provides a clear action for the authors to take, it does not specify how to implement this suggestion, such as which specific machine learning 2step baseline to use or how to integrate it into the comparison. Therefore, the comment is explicit but somewhat vague, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"When comparing to baselines,\" which allows the authors to identify the part of the paper being addressed. It also specifies the issue by suggesting the inclusion of a machine learning 2step baseline to compare with the heuristic methods. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparison to baselines is limited to heuristic methods, suggesting that a machine learning 2step baseline should be included to differentiate between algorithmic improvements and the authors\" assertion of NaviFormer\"s superiority. However, the comment lacks specific examples or references to support the claim that the improvement is due to the different class of algorithm. Without detailed evidence or reasoning, the claim remains 3, as the authors would need to infer the necessity of including a machine learning baseline based on the general logic presented. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the comparison of the proposed method (NaviFormer) to baselines, suggesting that all approaches appear to be heuristic methods. It proposes a specific improvement by recommending the inclusion of a machine learning 2step baseline to differentiate between algorithmic improvements and the authors\" assertion of NaviFormer\"s superiority. This feedback is clear and actionable, providing the authors with a concrete suggestion to enhance the robustness of their comparisons and strengthen their claims. However, the comment could be more helpful if it offered additional guidance on how to implement this suggestion or provided examples of suitable machine learning baselines. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct a fair comparison by applying the planning and layering method to design images generated by other image generative models. This feedback is explicit and provides a clear action for the authors to take, ensuring that the comparison is not biased towards the current method. The suggestion is concrete, as it specifies exactly what needs to be done to improve the fairness of the comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the results seem better than other compared methods but does not specify which part of the paper this observation is based on. It also lacks specificity regarding what aspects of the results are better or how they could be improved. Without explicit references to sections, figures, or specific results, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the suggestion for a fair comparison is 1 in a specific part of the paper, making it difficult for the authors to pinpoint where this change should be implemented. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results seem better than other compared methods but does not specify why this is the case. It suggests that the better performance might be due to the use of a better image generative model, but this is not substantiated with specific examples or references to other methods. The suggestion for a fair comparison is logical but lacks detailed reasoning or evidence to support the claim. Therefore, the comment is 3, as it provides a logical suggestion but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of results, suggesting that the better performance might be due to the use of a better image generative model. It provides a clear and actionable suggestion for improvement by recommending a fair comparison, which involves applying the planning and layering method to design images generated by other image generative models. This feedback is valuable as it guides the authors on how to enhance the robustness and fairness of their comparisons, allowing them to better evaluate the effectiveness of their method. However, the comment could be more helpful if it provided specific examples or references to other image generative models that could be used for comparison. Overall, the comment is 4 as it offers a constructive and actionable suggestion for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the comparative study should include more stateoftheart (SOTA) methods, such as those mentioned by the reviewer. This provides a clear action for the authors to take, which is to expand their comparative study to include these additional methods. The comment also critiques the claim made by the authors regarding the exploitation of modalitymissing data, suggesting that this claim is not justified without a comparison to SOTA methods. This feedback is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparative study, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of stateoftheart methods in the comparative study. The comment provides examples of specific methods that should be included, such as Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al., (2019). This level of detail provides clear guidance on how to improve the paper, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparative study should include more stateoftheart methods, specifically mentioning several examples. This claim is supported by the explicit mention of specific methods that should be included, providing a clear basis for the suggestion. However, the comment lacks detailed reasoning or evidence on why these specific methods are relevant or how they would enhance the study. While the suggestion is logical, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of stateoftheart (SOTA) methods in the comparative study. It specifically mentions several SOTA methods that should be considered, such as Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al., (2019). This feedback is valuable as it directs the authors to expand their analysis to include more relevant and uptodate methods, which could strengthen the claims made in the paper. However, the comment could be more helpful if it provided additional context or reasoning for why these specific methods are important or how they would enhance the study. Overall, the comment is 4 as it offers clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a confusion in the discussion of the dataset, specifically regarding the task being plain polarity classification but also mentioning \"opinion holder\" and \"opinion targets.\" The reviewer suggests that if these additional details are not relevant to the experiments, they should not be mentioned. This feedback is explicit in its action, as it clearly instructs the authors to reconsider the inclusion of these details if they are not relevant to the experiments. However, it does not provide specific guidance on how to determine relevance or how to revise the text if necessary. Therefore, the comment is 4, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 329334,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion of the dataset, pointing out the confusion regarding the task being plain polarity classification but also mentioning \"opinion holder\" and \"opinion targets.\" The comment suggests that if these additional details are not relevant to the experiments, they should not be mentioned. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the discussion of the dataset is confusing, specifically mentioning the use of terms like \"opinion holder\" and \"opinion targets\" when the task is described as plain polarity classification. The reviewer suggests that if these details are not relevant to the experiments, they should not be mentioned. While the comment identifies a potential issue with the clarity of the discussion, it lacks specific examples or references to support the claim. The reasoning is somewhat logical but could be strengthened with more detailed explanation or evidence. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion of the dataset, pointing out a potential confusion regarding the task being plain polarity classification but also mentioning \"opinion holder\" and \"opinion targets.\" It suggests that if these additional details are not relevant to the experiments, they should not be included in the discussion. This feedback is clear and actionable, as it directs the authors to reconsider the relevance of certain details in their discussion and potentially revise the text to avoid confusion. However, the comment could be more helpful if it provided specific suggestions on how to clarify the discussion or rephrase the text to improve clarity. Overall, the comment is 4 as it effectively guides the authors toward improving the clarity and relevance of their discussion."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment continues from the previous point, questioning the necessity of restricting capsule networks and expressing concern about the depth of the group CapNet compared to the simple CapNet. It also notes the lack of information on the number of parameters in the group CapNet, which makes it difficult to assess the benefits of enforcing equivariance. While the comment highlights a potential issue with the experimental setup, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors are left to infer that they should provide more detailed information about the experimental setup and the impact of enforcing equivariance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the previous comment,\" allowing the authors to identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of restricting capsule networks and expressing concern about the depth of the group CapNet compared to the simple CapNet. The comment further highlights the lack of information on the number of parameters in the group CapNet, which makes it difficult to assess the benefits of enforcing equivariance. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the necessity of restricting capsule networks and expresses concern about the depth of the group CapNet compared to the simple CapNet. It also notes the lack of information on the number of parameters in the group CapNet, which makes it difficult to assess the benefits of enforcing equivariance. The comment provides a logical reasoning by pointing out the depth difference and the lack of parameter information, which could impact the evaluation of the experimental results. However, it does not provide specific references or detailed examples to fully substantiate the claim. Therefore, the comment is 3, as it requires additional information or evidence to fully support the critique.", "helpfulness_rationale": "The review comment builds upon the previous point by questioning the necessity of restricting capsule networks and expressing concern about the depth of the group CapNet compared to the simple CapNet. It also notes the lack of information on the number of parameters in the group CapNet, which makes it difficult to assess the benefits of enforcing equivariance. This feedback is 3 as it identifies a potential issue with the experimental setup and suggests that the authors should provide more detailed information to better evaluate the impact of their approach. However, the comment could be more helpful if it offered specific suggestions on how to address these concerns or provided examples of how to present the information more effectively. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific challenge discussed in the paper, namely obtaining meaningful gradients with respect to noisy (intermediate) images, and mentions that this issue has been addressed in various approaches, including DiME, FastDiME, and the Tweedie approach. However, the comment does not provide explicit guidance or suggestions on how the authors should address this challenge in their own work. It lacks concrete details on how the authors might implement these approaches or what specific aspects of their method could be improved to overcome this challenge. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of obtaining meaningful gradients with respect to noisy (intermediate) images, which is a clear and specific concern. Additionally, it references specific approaches like DiME, FastDiME, and the Tweedie approach, providing examples of how this challenge has been addressed in other works. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the challenge of obtaining meaningful gradients with respect to noisy (intermediate) images has been addressed in various approaches, including DiME, FastDiME, and the Tweedie approach. The reviewer provides specific references to these approaches, which helps to verify the claim. However, the comment could be strengthened by providing more detailed explanations or examples of how these approaches address the challenge, which would make it 5. As it stands, the comment is 4, as it provides a solid foundation for the claim but lacks comprehensive details. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment addresses a specific challenge discussed in the paper, namely the difficulty of obtaining meaningful gradients with respect to noisy (intermediate) images. It provides context by mentioning that this issue has been addressed in various approaches, such as DiME, FastDiME, and the Tweedie approach. However, the comment does not offer detailed guidance or suggestions on how the authors might incorporate these approaches or address the challenge in their own work. While it highlights an area of interest, it lacks actionable advice, making it 3. The authors gain some insight into the existing literature but are left without clear steps to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include an evaluation of inference speed on the hardware. This is an explicit action that provides a clear direction for the authors to follow. However, it does not specify how the authors should conduct this evaluation or what specific aspects of inference speed should be considered. While the action is explicit, the lack of concrete details on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include an evaluation of inference speed on the hardware. However, it does not specify which part of the paper this evaluation should be included in, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of an evaluation of inference speed, but without clear grounding, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include an evaluation of inference speed on the hardware. However, it does not provide any supporting evidence, reasoning, or examples to justify why this evaluation is necessary or how it would benefit the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include an evaluation of inference speed on the hardware. While this is a relevant suggestion that could enhance the paper, it lacks specificity and does not provide guidance on how to conduct this evaluation or what aspects of inference speed should be considered. The comment identifies a potential area for improvement but does not offer detailed or actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for the SDP formulation, indicating that the authors should include it in their draft. This is a clear and direct action, providing the authors with a specific task to complete. The comment is concrete because it specifies exactly what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"the SDP formulation,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies what is missing, namely the SDP formulation, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual question asking for the SDP formulation, which is a request for clarification rather than a claim. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where the paper lacks clarity: the SDP formulation for the modified problem. By asking for the SDP formulation, the reviewer prompts the authors to provide a detailed explanation or derivation of the solution method, which could enhance the comprehensibility of the paper. However, the comment does not offer suggestions on how to present this information or why it is important, leaving the authors with a clear gap to fill but without detailed guidance on how to address it. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to provide information on the number of new task combinations used to evaluate compositional generalisability and to clarify that the test results in Table 7 are only from 30 composite instructions. This feedback is clear and provides specific actions for the authors to take, ensuring they know exactly what needs to be addressed in their draft. The comment is 5 as it offers concrete steps for improvement, allowing the authors to make direct changes to their manuscript.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 558\" and \"Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: the number of new task combinations used to evaluate compositional generalisability and the fact that the test results in Table 7 are only from 30 composite instructions. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements requesting clarification on the number of new task combinations used to evaluate compositional generalisability and the source of the test results in Table 7. It does not contain subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the paper lacks clarity and provides actionable feedback. It points out that the authors did not specify the number of new task combinations used to evaluate compositional generalisability, which is crucial information for understanding the results. Additionally, it notes that the test results in Table 7 are only from 30 composite instructions, which could limit the generalizability of the findings. This feedback is clear and actionable, as it directs the authors to provide this information to enhance the comprehensiveness and validity of their results. However, it could be more helpful if it suggested how to present this information or why it is important. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the paper, particularly the figures, are not wellformatted. However, it does not provide any specific guidance or suggestions on how to improve the layout or what aspects of the layout are problematic. Without concrete details or actionable advice, the authors are left without a clear understanding of what changes are needed to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment mentions that the paper, especially the figures, are not wellformatted. However, it does not specify which figures are problematic or what aspects of the layout are not good. This lack of specificity makes it difficult for the authors to identify the exact areas that need improvement. Additionally, the comment does not provide any context or reference to specific sections of the paper, making it challenging for the authors to determine which parts are being addressed. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper, particularly the figures, are not wellformatted. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanation or references to what aspects of the layout are problematic, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the paper, particularly the figures, are not wellformatted. However, it lacks specificity and does not provide any guidance or suggestions on how to improve the layout or what aspects of the figures are problematic. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what changes are needed to address the issue. This makes the comment unhelpful, as it does not offer any direction for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need for clear differentiation from existing works and a detailed comparison with similar techniques to avoid the perception of incremental or lacking novelty. While the comment implies that the authors should provide such differentiation and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to differentiate their work but are not given specific guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the need for clear differentiation from existing works and a detailed comparison with similar techniques to avoid the perception of incremental or lacking novelty. However, it does not specify which parts of the paper should include this differentiation or comparison, making it weakly grounded. The comment is specific in its suggestion to address the perception of incremental novelty, but without clear guidance on where to make these changes, the authors may struggle to implement the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s contributions may be perceived as incremental or lacking substantial novelty due to a lack of clear differentiation from existing works and detailed comparison with similar techniques. However, the comment does not provide specific examples of existing works or techniques that the paper should differentiate itself from, nor does it offer detailed reasoning or evidence to support the claim. This lack of specificity and detailed justification makes the claim 3, as the authors would need to infer the exact areas needing improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s contributions, noting that without clear differentiation from existing works and a detailed comparison with similar techniques, the contributions may be perceived as incremental or lacking substantial novelty. This feedback is valuable as it highlights a potential weakness in the paper\"s presentation of its contributions. However, the comment could be more helpful if it provided specific suggestions on how the authors might differentiate their work or conduct a detailed comparison. By offering actionable guidance, the comment could be more comprehensive and beneficial for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly instructs the authors to explain the difference in baseline results between Table 2 and Table 3 in 3. This is a clear and direct action for the authors to take, providing them with a specific task to address. The comment is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 2\" and \"Table 3 in 3,\" allowing the authors to accurately identify the specific parts of the paper being addressed. This provides full grounding. The comment also specifies the issue by asking for an explanation of the difference in baseline results between these tables, which is clear and specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking the authors to explain the difference in baseline results between Table 2 and Table 3 in 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific issue with the paper, namely the discrepancy in baseline results between Table 2 and Table 3 in 3. By pointing out this inconsistency, the comment prompts the authors to clarify or explain the difference, which could be a critical aspect of their work. However, the comment lacks depth and does not provide guidance on how to address the issue or why it might be important. To be more helpful, the comment could include suggestions on how to resolve the discrepancy or explain its significance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a misleading use of \"execution feedback\" in the title and Figure 2, noting that it is not actually used in the work. It provides a detailed explanation of the issue, pointing out that execution feedback is approximated based on structural perturbations in the AST and that the authors assume any perturbation results in a failure. The comment also critiques the definition of execution feedback in Equation 1, suggesting that it is not guaranteed to make tests fail. This feedback is explicit and provides concrete guidance on how to address the issue, such as clarifying the use of execution feedback and ensuring that the definition is accurate. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"execution feedback\" in the title and Figure 2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by explaining that execution feedback is not actually used in the work and that it is approximated based on structural perturbations in the AST. The comment provides detailed reasoning and examples, such as the definition of execution feedback in Equation 1, to clarify what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of \"execution feedback\" is misleading, as it is not actually used in the work but is approximated based on structural perturbations in the AST. The reviewer provides a detailed explanation of the issue, referencing specific lines of the paper (Lines 233238) and Equation 1 to support their claim. This level of detail and specific references make the claim 5, as it provides a clear and logical reasoning for the critique. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a detailed critique of the use of \"execution feedback\" in the paper, pointing out that it is misleading and not actually used in the work. The reviewer explains that execution feedback is approximated based on structural perturbations in the AST and that the authors assume any such perturbation results in a failure. This feedback is clear and actionable, as it highlights a significant issue with the paper\"s claims and suggests that the authors need to clarify their use of execution feedback and its relationship to structural perturbations. By addressing this critique, the authors can improve the accuracy and clarity of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of information regarding the \"40 target words\" and the use of \"a sequence of dots\" to remove bias in the model. It also notes the absence of details on how many games are sampled to demonstrate the severity of the bias problem. While the comment identifies specific areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these issues. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but are not given specific guidance on what information to include or how to present it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses two specific aspects: the use of \"40 target words\" and the removal of bias using \"a sequence of dots.\" However, it does not specify which part of the paper these elements are discussed in, making it weakly grounded. The comment is specific in detailing what information is missing, such as the nature of the \"40 target words\" and the details of the bias removal process. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the lack of information regarding the \"40 target words\" and the use of \"a sequence of dots\" to remove bias in the model. It also questions the detail provided on the severity of the bias problem, specifically asking for information on how many games are sampled. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to address these concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas where the paper lacks clarity and details, such as the use of \"40 target words\" and the method for removing bias using \"a sequence of dots.\" It also points out the need for more information on the severity of the bias problem, specifically asking for details on how many games are sampled. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it directs the authors to areas that need further elaboration, but it could be more actionable with additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the use of simple datasets and the unrealistic nature of uniformly random missing data in practice. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on which datasets should be used instead, how to make the missing data more realistic, or any suggestions for improvement. As a result, the authors are left without a clear understanding of what steps to take to address these issues. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of simple datasets and the unrealistic nature of uniformly random missing data in practice. However, it does not specify which part of the paper discusses the experiments or the datasets, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity as it does not provide details on what aspects of the datasets or experiments are problematic or how they could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the use of simple datasets and the unrealistic nature of uniformly random missing data in practice. However, it does not provide any supporting evidence, reasoning, or examples to justify why these choices are problematic or how they could be improved. The lack of detailed explanation or references makes it difficult for the authors to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the experiments are conducted on simple datasets and that the uniformly random missing data is unrealistic in practice. However, it does not provide any suggestions or guidance on how to address these issues or improve the experimental setup. Without actionable feedback or specific recommendations, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is 1, as it does not offer any constructive direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Figure 4 lacks legends for the plots, making it difficult to interpret. It suggests that the authors should include what each data point or plot corresponds to. This feedback is clear and provides a direct action for the authors to take, which is to add legends to the plots. The comment is specific and actionable, as it tells the authors exactly what needs to be done to improve the clarity of their figures. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is the lack of legends for the plots, and suggests what needs to be addressed, namely including what each data point or plot corresponds to. This provides clear guidance on how to improve the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 4 lacks legends for the plots, making it difficult to interpret. The comment suggests that including what each data point or plot corresponds to would improve the figure. This is a factual observation about the figure\"s presentation, which does not require additional evidence or justification. The comment is purely descriptive and does not contain subjective opinions, suggestions, or claims that need verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that it lacks legends for the plots, which makes it difficult to interpret. It provides a clear and actionable suggestion to include what each data point or plot corresponds to, which would significantly improve the figure\"s clarity and accessibility. This feedback is direct and constructive, offering the authors a concrete step to enhance the presentation of their results. However, the comment could be more helpful if it also suggested where these legends should be placed or provided examples of how to format them. Overall, the comment is 4 as it effectively guides the authors toward improving the clarity of their figures."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specific focus of the paper on sequencetosequence models and suggests that the general quantizationaware training strategy could be extended to other models. It also requests clarification on whether the proposed robustnessaware quantization scheme offers any specific benefits for sequencetosequence models. While the comment implies that the authors should clarify these points, it does not provide explicit instructions on how to address the questions or what specific information should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification on the paper\"s focus and benefits for sequencetosequence models. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the specific focus of the paper on sequencetosequence models and suggests that the general quantizationaware training strategy could be extended to other models. It also requests clarification on whether the proposed robustnessaware quantization scheme offers any specific benefits for sequencetosequence models. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it is challenging to pinpoint the exact location. The comment is specific in its request for clarification on the paper\"s focus and potential benefits for sequencetosequence models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the paper\"s focus on sequencetosequence models and whether the proposed robustnessaware quantization scheme offers specific benefits for these models. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific focus of the paper on sequencetosequence models and suggests that the general quantizationaware training strategy could be extended to other models. It also requests clarification on whether the proposed robustnessaware quantization scheme offers any specific benefits for sequencetosequence models. While the comment identifies a potential gap in the paper\"s focus and suggests a direction for improvement, it lacks specific guidance or actionable suggestions on how the authors might address this issue. The feedback is 3 as it prompts the authors to consider the broader applicability of their work and highlights an area for potential enhancement, but it could be more beneficial with additional detail or direction. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to provide more ablation on how the algorithm\"s behavior and accuracy of its Q estimates change as the hyperparameter lambda changes. This request is clear and direct, leaving no ambiguity about what the authors need to do to address the comment. The feedback provides a specific action and concrete details on how to implement it, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 2\" and the hyperparameter \"lambda,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: an ablation study on how the algorithm\"s behavior and accuracy of its Q estimates change as the hyperparameter lambda changes. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification and additional information, asking the authors to provide more ablation on how the algorithm\"s behavior and accuracy of its Q estimates change as the hyperparameter lambda changes. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more ablation on how the algorithm\"s behavior and accuracy of its Q estimates change as the hyperparameter lambda changes. This feedback is clear and actionable, as it directs the authors to conduct additional experiments or analyses to better understand the impact of this hyperparameter on the algorithm\"s performance. By addressing this suggestion, the authors can enhance the comprehensiveness and robustness of their results. However, the comment could be more helpful if it provided specific guidance on the types of ablation studies to conduct or the metrics to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the base encoder of the proposed model, asking whether it is pretrained or trained from scratch. This question implies that the authors should clarify this aspect in their paper. However, the comment does not provide explicit guidance on how to address this question or what information should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide clarification but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment poses a question about the base encoder of the proposed model, asking whether it is pretrained or trained from scratch. However, it does not specify which part of the paper this question pertains to, such as a specific section or methodology discussion. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the question is specific in nature, it does not provide guidance on how to address the issue or what information should be included. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a question seeking clarification about the base encoder of the proposed model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the base encoder of the proposed model, asking whether it is pretrained or trained from scratch. While this question is relevant and could provide clarity for the reader, it does not offer any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address this issue or what impact it might have on their work. As a result, the comment is 2, as it does not provide meaningful direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the ethical statement should be extended with more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the ethical statement. The comment is explicit and concrete, giving the authors a clear understanding of how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Ethical Statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely, the discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This level of detail helps the authors understand exactly what needs to be expanded in the ethical statement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ethical statement is wellwritten but suggests it should be extended with more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. The comment provides a specific suggestion for improvement, which is a clear and logical step to enhance the ethical considerations in the paper. However, it does not provide detailed reasoning or examples to fully substantiate the claim that the current ethical statement lacks depth in these areas. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks comprehensive evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges that the ethical statement is wellwritten but suggests that it could be improved by discussing challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This feedback is clear and actionable, providing the authors with a specific direction for enhancing the ethical considerations in their work. By addressing these additional aspects, the authors can ensure their ethical statement is comprehensive and inclusive. However, the comment could be more helpful if it offered examples or further guidance on how to incorporate these discussions into the ethical statement. Overall, the comment is 4 as it provides a clear path for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the length of the minibatches, noting that it may be nonintegers and suggesting that this should be clarified to ensure there are no side effects. It also poses a question about what happens if the minibatch size is much smaller than one, implying that the analysis might not be valid. While the comment identifies a potential issue and suggests clarifying the minibatch size, it does not provide explicit guidance on how to address this concern or what specific steps the authors should take to clarify the issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the minibatch size and its implications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"length of the minibatches tau_t,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the noninteger nature of the minibatch size and suggests that this should be clarified to ensure there are no side effects. The comment further poses a question about what happens if the minibatch size is much smaller than one, implying that the analysis might not be valid. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point raises a concern about the noninteger nature of the minibatch size, tau_t, and suggests that this should be clarified to ensure there are no side effects. The reviewer questions the validity of the analysis if the minibatch size is much smaller than one. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the analysis might not be valid. The reasoning is somewhat logical but requires further elaboration to be 5. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the noninteger nature of the minibatch size, tau_t, and suggests that this should be clarified to ensure there are no side effects. It raises a question about what happens if the minibatch size is much smaller than one, implying that the analysis might not be valid. This feedback is 3 as it points out a specific area that could be clarified or addressed in the paper. However, it lacks detailed guidance on how to clarify this issue or what specific steps the authors should take to ensure the analysis remains valid. While it provides some direction, it could be more helpful with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the importance of examining the computational cost associated with the inference process of the SCALE model, specifically mentioning the two types of decoding involved: STM decoding and LLM decoding. However, it does not provide explicit guidance or suggestions on how the authors should approach this examination or what specific aspects of the computational cost should be considered. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the computational cost but without concrete steps or details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the inference cost associated with the SCALE model, specifically mentioning the two types of decoding involved: STM decoding and LLM decoding. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in its request to examine the computational cost, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests examining the computational cost associated with the inference process of the SCALE model, specifically mentioning the two types of decoding involved: STM decoding and LLM decoding. However, the comment does not provide any specific reasoning, examples, or references to support why this examination is important or how it might impact the paper. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should examine the computational cost associated with the inference process of the SCALE model. It highlights the importance of considering the two types of decoding involved: STM decoding and LLM decoding. This feedback is clear and actionable, as it directs the authors to a particular aspect of their work that could benefit from further analysis and discussion. However, the comment could be more helpful if it provided guidance on how to approach this examination or what specific aspects of the computational cost should be considered. Overall, the comment is 4 as it points the authors in the right direction for enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two main issues: the use of a subset of the complete dataset and the lack of performance comparisons with stateoftheart models, which makes it difficult to demonstrate the effectiveness of the proposed methods. Additionally, it mentions peculiar experimental results, specifically the unsupervised result outperforming the supervised result in the 5th row of Table 2. While the comment identifies these issues, it does not provide explicit guidance on how to address them or suggest specific actions for improvement. The authors are left to infer that they should include a more comprehensive dataset and performance comparisons, as well as investigate the peculiar results. However, the lack of concrete suggestions or detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment addresses two main issues: the use of a subset of the complete dataset and the lack of performance comparisons with stateoftheart models, which makes it difficult to demonstrate the effectiveness of the proposed methods. Additionally, it mentions peculiar experimental results, specifically the unsupervised result outperforming the supervised result in the 5th row of Table 2. While the comment does not explicitly mention specific sections or tables, the authors can infer that it relates to the experimental results and performance comparisons sections. The comment is specific in detailing what is missing or problematic, such as the need for a more comprehensive dataset and performance comparisons. However, it lacks full grounding as it does not explicitly mention the sections or tables being addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the article lacks performance comparisons with stateoftheart models, making it difficult to demonstrate the effectiveness of the proposed methods. It also mentions peculiar experimental results, specifically the unsupervised result outperforming the supervised result in the 5th row of Table 2. While the comment highlights a potential issue with the dataset and experimental setup, it does not provide specific examples or references to support the claim about the stateoftheart models or the peculiar results. The lack of detailed evidence or references makes the claim 3, as the authors would need to investigate these issues further to fully understand and address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper. First, it points out that the article only uses a subset of the complete dataset, which limits the ability to demonstrate the effectiveness of the proposed methods. Second, it notes the lack of performance comparisons with stateoftheart models, which is crucial for evaluating the novelty and impact of the work. Additionally, the comment highlights peculiar experimental results, such as the unsupervised result outperforming the supervised result in the 5th row of Table 2. These observations are valuable as they provide clear areas for improvement, such as expanding the dataset and conducting comprehensive performance comparisons. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of stateoftheart models for comparison. Overall, the feedback is 4 as it directs the authors to important areas that need attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the phrase \"lacks inherent semantic meaning\" is used but not further elaborated upon. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion on what additional information or elaboration is needed, nor is there a specific action for the authors to take. As a result, the comment lacks any actionable advice, leaving the authors without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the phrase \"lacks inherent semantic meaning\" is used in. Without this context, the authors cannot determine where in the paper this issue needs to be addressed. Additionally, the comment lacks specificity as it does not provide any details on what additional elaboration is needed or how the authors might address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the phrase \"lacks inherent semantic meaning\" is used but not further elaborated upon. However, the comment does not provide any reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific phrase, \"lacks inherent semantic meaning,\" that is used in the paper but not further elaborated upon. However, it does not provide any context or explanation as to why this phrase is important or how it relates to the overall content of the paper. Without additional guidance or suggestions for improvement, the authors are left without a clear understanding of what needs to be addressed or how to enhance their draft. Therefore, the comment is 1, as it lacks actionable feedback or insight into how the authors might improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies two issues: the lack of sufficient details or justification for using a large number of hidden units and an additional elementwise function, and the potential bias introduced by treating unobserved ratings as zeros. While the comment highlights these concerns, it does not provide explicit guidance on how the authors should address these issues or what specific details or justifications are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses two specific issues: the lack of details or justification for using a large number of hidden units and an additional elementwise function, and the potential bias introduced by treating unobserved ratings as zeros. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what is missing or problematic, such as the need for more details and justification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient details or justification for using a large number of hidden units and an additional elementwise function, and that treating unobserved ratings as zeros may introduce bias. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the exact nature of the issues or how to address them. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas where the authors could provide more details and justification: the use of a large number of hidden units and an additional elementwise function, and the potential bias introduced by treating unobserved ratings as zeros. While the comment highlights important aspects that need clarification, it does not offer specific suggestions or guidance on how the authors might address these issues. Providing more detailed feedback or examples of how to justify these choices would enhance the comment\"s helpfulness. As it stands, the comment is 3, as it points out areas for improvement but lacks actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the robustness of the claim regarding motivation, specifically questioning the need for MathGLM when other tools can achieve 100% accuracy. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or improve the claim, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the robustness of the claim regarding motivation, specifically questioning the need for MathGLM when other tools can achieve 100% accuracy. However, it does not specify which part of the paper discusses the motivation or the claim about MathGLM, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the motivation are not robust or how the claim could be strengthened. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation for using MathGLM is not robust, as other tools can achieve 100% accuracy for the same calculations. However, the comment does not provide specific examples or references to support this claim, such as comparing MathGLM with these other tools or discussing the limitations of MathGLM. Without detailed evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the robustness of the claim regarding the motivation for using MathGLM, suggesting that other tools can achieve 100% accuracy for the same calculations. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might address this issue or improve their argument. The feedback is vague and lacks actionable guidance, making it 2 for the authors in terms of improving their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the reliance on synthetic datasets and the evaluation of eventbased optical flow in realworld settings, suggesting that this does not accurately reflect eventbased dense tracking. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the evaluation or what specific changes should be made to better reflect eventbased dense tracking. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the use of synthetic datasets and the evaluation of eventbased optical flow in realworld settings, suggesting that this does not accurately reflect eventbased dense tracking. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in identifying the problem with the evaluation methodology, but without clear references to specific sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the reliance on synthetic datasets and the evaluation of eventbased optical flow in realworld settings does not accurately reflect eventbased dense tracking, which is a significant weakness. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that the reliance on synthetic datasets and the evaluation of eventbased optical flow in realworld settings does not accurately reflect eventbased dense tracking. This is a critical observation that highlights a gap in the evaluation methodology, which could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their evaluation methodology. While it points out a significant flaw, it lacks actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights several issues with the paper, including the lack of clarity in the motivation, the opposition to existing research without strong justification, and the weak experiments with limited dataset and LLM size. However, it does not provide explicit guidance or suggestions on how the authors might address these issues. The comment implies that the authors should clarify their motivation, strengthen their experiments, and validate their results more thoroughly, but these actions are not directly stated. The feedback is 3 as it identifies areas for improvement, but it lacks concrete steps or detailed guidance on how to implement these changes. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the motivation of the paper, questioning the opposition to existing research on ensuring diversity in instructiontuning data without strong justification. It also critiques the experiments, noting their limitations in dataset and LLM size, which could lead to unconvincing results. However, the comment does not specify which sections of the paper discuss these issues, making it weakly grounded. The authors can infer that it relates to the introduction and experimental sections, but the lack of explicit references makes it challenging to pinpoint the exact parts needing revision. The comment is specific in detailing the issues with the motivation and experiments, but the lack of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation of the paper is unclear and that it opposes existing research without strong justification. It also criticizes the experiments as weak due to limited dataset and LLM size, which could lead to misleading results. However, the comment lacks specific examples or references to support these claims, such as comparing the paper\"s approach to existing work or detailing how the experiments are weak. This makes the claim 3, as the authors would need to invest effort to understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, including the lack of clarity in the motivation, the opposition to existing research without strong justification, and the weak experiments with limited dataset and LLM size. It also points out that the results are unconvincing and could potentially mislead the community. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve their work. While it highlights important areas for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly questions the absence of confidence intervals on the substitution ASR in Table 3. This is a clear and direct action for the authors to take, as it prompts them to provide an explanation or justification for the omission. The comment provides a specific area for improvement, making it 5. The authors know exactly what needs to be addressed and can take immediate action to clarify this aspect of their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the absence of confidence intervals on the substitution ASR, providing a clear area for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual question about the absence of confidence intervals on the substitution ASR in Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is highly specific and actionable, as it directly questions the absence of confidence intervals on the substitution ASR in Table 3. This feedback is valuable because it prompts the authors to address a potential gap in their analysis, which could enhance the transparency and robustness of their results. By highlighting this omission, the comment provides a clear direction for improvement, making it 5 for the authors. However, it could be more helpful if it suggested how the authors might address this issue or why confidence intervals are important in this context. Overall, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about how to estimate the mean element mu_g for different kernel spaces. While it identifies a specific area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to clarify or provide more information on this estimation process. However, the comment lacks concrete details on how to execute this action, making it 3. The authors know they need to address the issue, but they may struggle to determine the exact steps to take.", "grounding_specificity_rationale": "The comment raises a question about the estimation of the mean element mu_g for different kernel spaces. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of unclear estimation, but it lacks grounding as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of estimating the mean element mu_g for different kernel spaces. However, it does not provide any supporting evidence, reasoning, or references to justify why this aspect is unclear or how it could be clarified. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the estimation of the mean element mu_g for different kernel spaces. This feedback is 3 as it points out a potential gap in the paper that needs clarification. However, it lacks depth and does not provide suggestions or guidance on how the authors might address this issue or clarify the estimation process. To be more helpful, the comment could include specific questions or examples to assist the authors in improving their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, to make the story more complete. While the comment implies that the authors should include these datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion. The authors can infer that they should consider these datasets, but the comment does not provide detailed instructions on how to integrate them into the study. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, to make the story more complete. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the choice of datasets or experimental setup, but the comment lacks full grounding as it does not explicitly mention a specific section. It is specific in suggesting the inclusion of larger datasets, but the lack of grounding makes it difficult for the authors to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, to make the story more complete. The comment provides a logical reasoning for why this would be beneficial, as it would address the issue of baselines not working on larger datasets. However, it lacks specific examples or references to support the claim that ImageNet with reduced dimensions would be a suitable dataset for this purpose. While the reasoning is clear, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced sample and feature dimensions, to make the story more complete. While it identifies a potential area for improvement, it lacks specific guidance or detailed suggestions on how to incorporate these datasets or what specific aspects of the story would be enhanced by their inclusion. The comment provides a general direction but does not offer actionable steps or a clear rationale for why these datasets would be beneficial. As a result, the feedback is 3, as it points out a possible enhancement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the cosine similarity score would be more effective than the Euclidean distance when computing the Decidability. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should explore this alternative or conduct further analysis to compare the two methods. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the use of cosine similarity score versus Euclidean distance in computing the Decidability. However, it does not specify which part of the paper this issue pertains to, such as a specific section or analysis where these methods are discussed. Without explicit references or context, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the suitability of using cosine similarity score instead of Euclidean distance for computing Decidability. However, it does not provide any supporting evidence, reasoning, or references to justify why cosine similarity might be more effective. The comment lacks specific examples or comparisons to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1, as it lacks the necessary evidence or justification to support the suggestion.", "helpfulness_rationale": "The review comment raises a question about the suitability of using cosine similarity score instead of Euclidean distance for computing Decidability. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance or suggestions on how the authors might explore or address this issue. The comment does not offer actionable feedback or insights that would help the authors improve their draft. Therefore, it is 2, as it points out a potential area of interest but does not provide enough detail or direction for the authors to act upon."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the experiments, including the lack of a comparison with other counterpart methods and the insufficiency of the experimental results to validate the proposed method. However, it does not provide explicit guidance on how the authors should address these issues. The comment implies that the authors should conduct more comprehensive experiments and comparisons, but it lacks concrete suggestions on what specific experiments or comparisons should be included. As a result, the authors are left with a vague understanding of what actions to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experiments, specifically mentioning the lack of a comparison with other counterpart methods and the insufficiency of the experimental results. However, it does not specify which part of the paper discusses the experiments, making it weakly grounded. The comment is specific in detailing the issues with the experiments, such as the lack of a comparison and the insufficient results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are weak due to the lack of a comparison with other counterpart methods and insufficient results to validate the proposed method. However, the comment does not provide specific examples of other methods that should be compared or detailed reasoning on why the current results are insufficient. This lack of supporting evidence or references makes the claim 3, as the authors would need to infer the specific issues and address them without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several weaknesses in the experimental section of the paper, specifically noting the lack of a comparison with other counterpart methods and the insufficiency of the experimental results to validate the proposed method. This feedback is clear and actionable, as it highlights specific areas where the authors need to improve their experimental setup and results. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending specific methods to compare with or ways to enhance the experimental design. Overall, the comment is 4 as it directs the authors to focus on strengthening their experimental section, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with the figures related to completion errors, noting that they are not referenced in the relevant analysis sections of the appendix. This provides a clear and direct action for the authors to take, which is to ensure that these figures are properly referenced in the appendix. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figures related to completion errors,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue of not referencing these figures in the relevant analysis sections of the appendix. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual observation about the lack of references to figures related to completion errors in the relevant analysis sections of the appendix. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the figures related to completion errors, noting that they are not referenced in the relevant analysis sections of the appendix. This feedback is clear and actionable, as it directs the authors to ensure that these figures are properly referenced, which can help readers better understand the analysis and its implications. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively integrate these figures into the analysis. Overall, the comment is 4 as it points out a clear area for improvement, but it could be more comprehensive with further guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether perplexity is measured on consistent validation sets across levels. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what steps to take to clarify the measurement of perplexity. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the measurement of perplexity on consistent validation sets across levels. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment, making it difficult for the authors to identify the exact area needing clarification. The comment is specific in its inquiry about the consistency of validation sets, but it lacks grounding as it does not point to a particular part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the consistency of perplexity measurements across validation sets at different levels. However, it does not provide any supporting evidence, reasoning, or references to justify why this inconsistency might be an issue or how it could impact the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a question about the consistency of perplexity measurements across validation sets at different levels. While it identifies a potential area of concern, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, the comment is 2, as it points out a potential issue but does not offer meaningful guidance for resolution."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses an opinion that the setting and algorithm lack originality, suggesting they are incremental combinations of existing methods. However, it also acknowledges the efficiency and novelty of the algorithm for graph labelings. While the comment implies that the authors should address the lack of originality, it does not provide specific guidance on how to do so or suggest ways to enhance the originality of the work. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment expresses an opinion about the originality of the setting and algorithm, suggesting they are incremental combinations of existing methods. However, it also acknowledges the efficiency and novelty of the algorithm for graph labelings. While the comment implies that the authors should address the lack of originality, it does not specify which parts of the paper are being referred to, making it weakly grounded. The comment is specific in its critique of the lack of originality but lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses an opinion about the originality of the setting and algorithm, suggesting they are incremental combinations of existing methods. However, the comment also acknowledges the efficiency and novelty of the algorithm for graph labelings. While the claim about the lack of originality is subjective, the acknowledgment of the algorithm\"s efficiency and novelty provides some justification. However, the comment lacks specific examples or references to support the claim about the lack of originality, making it 3. The authors would need to infer the basis of the claim and potentially seek additional evidence to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment expresses an opinion that the setting and algorithm lack originality, suggesting they are incremental combinations of existing methods. However, it also acknowledges the efficiency and novelty of the algorithm for graph labelings. While the comment identifies a potential weakness in the originality of the work, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the originality of their approach. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with using the state action of the current policy in the target environment as regularization, suggesting that it could harm learning. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to avoid this issue or what modifications might be necessary to improve the regularization process. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the use of state action in the target environment as regularization, suggesting that it could harm learning. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the potential problem with using suboptimal state actions for regularization. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that using the state action of the current policy in the target environment as regularization can harm learning, as it would result in suboptimal state action distribution. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The authors may find it challenging to understand the basis of this assertion without further explanation or evidence. Therefore, the comment is considered 2, as it provides some insight but requires more detailed justification to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with using the state action of the current policy in the target environment as regularization, suggesting that it could harm learning. It provides a logical reasoning for this concern, explaining that a suboptimal policy would result in a suboptimal state action distribution, which could negatively impact the learning process. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their regularization approach. While it highlights a critical point, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the potential negative impact of the feature compactness loss and sharpnessaware minimization on the model\"s performance on base classes. It suggests that if such degradation occurs, it is important to discuss how this issue could be mitigated. While the comment identifies a potential issue and highlights the need for discussion, it does not provide explicit guidance on how to address this concern or what specific steps should be taken to mitigate the issue. The action is implicit and somewhat vague, as the authors are left to infer that they should discuss potential solutions or strategies to maintain performance on base classes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the objective of the feature compactness loss and sharpnessaware minimization, specifically mentioning their impact on reducing distances among base classes. However, it does not specify which part of the paper discusses these methods, making it weakly grounded. The comment is specific in detailing the concern about potential negative impacts on base class performance and the need to discuss mitigation strategies. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the potential negative impact of the feature compactness loss and sharpnessaware minimization on the model\"s performance on base classes. It suggests that if such degradation occurs, it is important to discuss how this issue could be mitigated. However, the comment does not provide specific examples, data, or references to support the claim that this operation could negatively impact performance. The reasoning is logical but lacks detailed evidence or examples, making it 3. Authors would need to further explore and substantiate the claim themselves to fully address it.", "helpfulness_rationale": "The review comment identifies a potential issue with the feature compactness loss and sharpnessaware minimization, suggesting that these operations might negatively impact the model\"s performance on base classes. It highlights the importance of discussing how this issue could be mitigated to maintain performance on the base classes. This feedback is clear and actionable, as it prompts the authors to consider the potential consequences of their approach and encourages them to address this concern in their paper. However, the comment could be more helpful if it provided specific suggestions or examples on how to mitigate the potential negative impact. Overall, the comment is 4 as it directs the authors\" attention to an important aspect of their work that requires further consideration and discussion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the insight and potential for developing new methods from the work, as well as how to prevent attention collapse in CL. However, it does not provide explicit guidance or suggestions on how the authors should address these questions or improve their draft. The authors are left to infer that they need to clarify the insights and potential contributions of their work, as well as explore methods to prevent attention collapse. While the questions are clear, the lack of explicit instructions or concrete steps makes the comment 3.", "grounding_specificity_rationale": "The comment raises questions about the insight and potential for developing new methods from the work, as well as how to prevent attention collapse in CL. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its inquiry about the insight and potential for new methods, but it lacks grounding as it does not point to a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification and insight into the work. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the insight and potential for developing new methods from the work, as well as how to prevent attention collapse in CL. These questions are relevant and can guide the authors in clarifying the significance and contributions of their work. However, the comment lacks specific suggestions or guidance on how the authors might address these questions or improve their draft. While it identifies areas for improvement, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the impact of the CHC model on the capabilities of MLLMs, specifically asking for clarification on the specific attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. It also suggests that case studies or pilot experiments could illustrate the significance of this influence. While the comment does not explicitly instruct the authors to conduct specific experiments or provide detailed guidance on how to address the question, it does imply that the authors should consider exploring these aspects further. The action is implicit but concrete, as it provides a clear direction for the authors to investigate and potentially expand their work. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"main content\" where the CHC model is introduced, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear impact of the CHC model on MLLMs and asks for clarification on the specific attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. Additionally, it suggests the inclusion of case studies or pilot experiments to illustrate the significance of this influence. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the impact of the CHC model on the capabilities of MLLMs, specifically asking for clarification on the specific attributes or behaviors that a powerful MLLM, grounded in CHC theory, would exhibit. The comment suggests that case studies or pilot experiments could illustrate the significance of this influence. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the impact of the CHC model is unclear. This lack of evidence or detailed justification makes the claim 3, as the authors would need to provide additional context or evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of uncertainty in the paper, namely the impact of the CHC model on the capabilities of MLLMs. It asks for clarification on the specific attributes or behaviors that a powerful MLLM, grounded in CHC theory, would exhibit. This feedback is clear and actionable, as it prompts the authors to provide more detailed explanations or examples to clarify the significance of the CHC model. Additionally, the suggestion to include case studies or pilot experiments to illustrate the impact is a valuable direction for the authors to consider. However, the comment could be more helpful if it provided specific examples or references to guide the authors in addressing the issue. Overall, the comment is 4 as it directs the authors to enhance the clarity and depth of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider integrating more uptodate pretraining models to showcase the significance and practical usage of their approach. The reviewer provides specific examples of recent related works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which could be integrated into the study. This feedback is explicit and provides concrete examples of how the authors can enhance their work, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the pretraining model, \"PreGNN,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests integrating more uptodate pretraining models and provides examples of recent related works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation.\" This provides clear guidance on what the authors should consider to improve their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the pretraining model, PreGNN, is outdated and suggests integrating more uptodate models to showcase the significance and practical usage of the approach. The reviewer supports this claim by providing specific examples of recent related works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which are cited with their respective publication details. This provides a clear and robust basis for the claim, making it 5. The inclusion of specific references and examples enhances the credibility of the argument, ensuring that the authors can effectively address the feedback.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that the pretraining model, PreGNN, is relatively old compared to more recent and powerful models. It suggests that integrating more uptodate pretraining models could enhance the significance and practical usage of the approach. The reviewer provides specific examples of recent related works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which could be considered for integration. This feedback is clear and actionable, offering the authors concrete steps to improve their work. However, it could be more helpful if it included a rationale for why these newer models are more powerful or how they could benefit the study. Overall, the comment is 4 as it provides valuable guidance for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the potential engineering challenge posed by the model\"s input, which involves taking the difference between current object pose and target object pose. It notes that object segmentation and pose tracking in the real world can be difficult. However, the comment also praises the authors for documenting their approach well in Section A.3. While the comment highlights a potential issue, it does not provide any explicit or implicit actions for the authors to take to address this challenge or improve their documentation. The feedback lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the potential engineering challenge posed by the model\"s input, which involves taking the difference between current object pose and target object pose. The comment acknowledges the difficulty of object segmentation and pose tracking in the real world but praises the authors for documenting their approach well in the mentioned section. This provides clear guidance on what the authors have done well and what could be improved. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the potential engineering challenge posed by the model\"s input, which involves taking the difference between current object pose and target object pose. It notes that object segmentation and pose tracking in the real world can be difficult. However, the comment also praises the authors for documenting their approach well in Sec. A.3. The claim about the engineering challenge is supported by logical reasoning, as it highlights the complexity of the task and the potential difficulties in realworld applications. The mention of the authors\" documentation provides some verification, but it lacks specific examples or references to substantiate the claim fully. Therefore, the comment is 3, as it provides a logical basis but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment acknowledges the potential engineering challenge posed by the model\"s input, which involves taking the difference between current object pose and target object pose. It highlights the difficulty of object segmentation and pose tracking in the real world, which could be a significant hurdle for the model\"s implementation. However, the comment also praises the authors for documenting their approach well in Section A.3, which is a positive acknowledgment. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address this challenge or improve their documentation further. The feedback is 3 as it points out a potential area of concern, but it lacks depth and actionable advice, making it difficult for the authors to fully benefit from the comment. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more downstream performance of their controllable text generation models, specifically mentioning the potential application of style transfer. While the comment implies that the authors should include additional performance evaluations, it does not explicitly instruct them to do so. The suggestion is concrete in terms of the specific application of style transfer, but the action is still implicit. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 116117,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need for more downstream performance evaluation of the controllable text generation models and suggestions on how to connect the proposed models to real NLG applications. The comment also provides a concrete example of style transfer as a potential starting point. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more downstream performance evaluation of their controllable text generation models, specifically mentioning the potential application of style transfer. The reviewer provides a logical reasoning by suggesting that the proposed models should be connected to realworld natural language generation (NLG) applications to demonstrate their advantage. However, the comment lacks specific examples or references to support the claim that style transfer is a good starting point for such applications. While the suggestion is reasonable, the lack of detailed evidence or examples makes the claim 3, as the authors may need to further develop the idea themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending that the authors include more downstream performance evaluations of their controllable text generation models. It specifically mentions the potential application of style transfer as a starting point for connecting the proposed models to realworld natural language generation (NLG) applications. This feedback is valuable as it directs the authors to a specific area for enhancement, offering a concrete way to demonstrate the practical utility of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct these evaluations or examples of similar studies. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the availability of labels for the GLUE datasets used in the test set performance. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should clarify the availability of labels, address the confusion, or provide additional information. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the availability of labels for the GLUE datasets used in the test set performance. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table where the test set performance is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the availability of labels for the GLUE datasets used in the test set performance. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the availability of labels for the GLUE datasets used in the test set performance. While it identifies a potential area of confusion, it does not provide any actionable feedback or suggestions for the authors to address this issue. The comment lacks depth and does not offer guidance on how the authors might clarify or resolve the confusion. As a result, the comment is 2, as it points out a potential problem but does not assist the authors in improving their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 3.2 could be shortened because many equations are not original contributions but are wellknown in the community. It implies that the authors should consider removing these equations to save space and include more important details. However, the comment does not provide specific guidance on which equations to remove or how to prioritize the inclusion of important details. The action is implicit and somewhat vague, as the authors need to infer which equations to remove and how to prioritize the inclusion of important details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with Section 3.2, which is the inclusion of equations that are not original contributions but are wellknown in the community. The suggestion to shorten the section by removing these equations and using the saved space to include important details provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Section 3.2 could be shortened because many equations are not original contributions but are wellknown in the community. The comment provides a logical reasoning for the suggestion, as it highlights the redundancy of including equations that are already widely known. However, it does not provide specific examples of these equations or references to support the claim, which would strengthen the justification. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with Section 3.2, suggesting that it could be shortened since many equations are not original contributions but are wellknown in the community. This feedback is 3 as it points out a way to improve the paper by reducing unnecessary content and potentially freeing up space for more important details. However, the comment lacks specific guidance on which equations to remove or how to prioritize the inclusion of important details, leaving the authors with a general direction but not a detailed plan for improvement. Therefore, the comment is rated as 3, as it provides some insight but could be more actionable with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification regarding the evaluation method used between automatic and human evaluation in specific figures and tables. This is a clear and direct request for information, providing the authors with a specific action to take. The comment is concrete because it specifies exactly what information is needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3, Table 3, and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: the evaluation method used between automatic and human evaluation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual question seeking clarification about the evaluation method used in specific figures and tables. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of confusion regarding the evaluation method used in Figures 3, 3, and 5. By asking for clarification on this point, the comment prompts the authors to address a potential gap in their explanation or methodology. However, it does not provide any suggestions or guidance on how to resolve this issue or improve the clarity of the paper. While it highlights an area that needs attention, the feedback lacks depth and actionable advice, making it 3 but not comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the understanding of the results, specifically regarding the coverage rate and its relation to the bound by theorem. It asks for clarification or additional assumptions to achieve the desired coverage rate. While the comment identifies a potential issue, it does not provide explicit instructions or concrete suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or provide additional assumptions, but without specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"1 > 0.9, t=5: 0.9 > 1\" and \"the adversary can generate a datum to make an error,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies the issue with the coverage rate and its relation to the bound by theorem, asking for clarification or additional assumptions to achieve the desired coverage rate. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the understanding of the results, specifically regarding the coverage rate and its relation to the bound by theorem. The reviewer asks for clarification or additional assumptions to achieve the desired coverage rate. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the coverage rate is larger than the bound by theorem. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the understanding of the results, specifically regarding the coverage rate and its relation to the bound by theorem. It seeks clarification on whether the reviewer\"s understanding is correct and, if not, what additional assumptions are needed to achieve the desired coverage rate. While the comment identifies a potential misunderstanding, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it prompts the authors to reconsider their assumptions and results, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that using a single translator per language may not be sufficient due to the potential for different translators to make different choices. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative methods for ensuring consistency in the annotations. The action is implicit and vague, as the authors are left to infer that they might need to consider using multiple translators or other strategies to ensure consistency. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that using a single translator per language may not be sufficient due to the potential for different translators to make different choices. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results section where annotations are discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what alternative approaches could be considered to ensure consistency in annotations. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that using a single translator per language may not be sufficient due to the potential for different translators to make different choices. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the use of a single translator per language, suggesting that this approach may not be sufficient due to the potential for different translators to make different choices. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. It does not offer alternative methods or strategies for ensuring consistency in the annotations, leaving the authors without clear direction on how to improve their draft. As a result, the comment is 2, as it identifies a potential issue but does not provide sufficient detail or actionable feedback to be truly beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the order of actions described in the paper, asking \"why not?\" without providing any explicit or implicit suggestions for improvement. The comment lacks actionable guidance, as it does not offer any specific advice or direction on how the authors might address this issue or improve their draft. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the order of actions described in the paper, specifically asking \"why not?\" However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity as it does not detail what aspect of the order of actions is unclear or why it should be changed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking why the order of actions described in the paper is not reversed. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the order of actions described in the paper, specifically asking \"why not?\" However, it lacks specificity and does not provide any context or explanation as to why this order might be problematic or how it could be improved. Without additional details or suggestions, the authors are left without a clear understanding of what aspect of their draft is being questioned or how to address it. This makes the comment 2, as it identifies a potential area of concern but does not offer actionable guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the number of examples, 2000, may be insufficient for the model to learn a specific transformation correctly. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as recommending additional examples, adjusting the model architecture, or providing alternative methods to ensure the model\"s learning. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the number of examples, 2000, may be insufficient for the model to learn a specific transformation correctly. However, it does not specify which part of the paper this issue pertains to, such as a particular section, experiment, or analysis. Without explicit references or context, the authors cannot confidently determine which part of the paper this comment addresses. Additionally, the comment lacks specificity regarding what needs to be addressed or how to improve the number of examples. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that 2000 examples may be insufficient for the model to learn a specific transformation correctly. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the number of examples, 2000, may be insufficient for the model to learn a specific transformation correctly. However, it does not provide any context, reasoning, or specific examples to support this claim. Without additional information or suggestions on how to address this issue, the authors are left without actionable feedback to improve their draft. The comment lacks depth and specificity, making it 2 at best. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the difference between Algorithm 1 and variational inference, specifically regarding the use of a Gaussian distribution to approximate the target distribution. While it does not explicitly instruct the authors to provide an explanation or comparison, the question implies that the authors should address this difference and highlight the advantages of their approach. The action is implicit but clear, as the authors can infer that they need to provide a detailed explanation or comparison. However, the comment lacks concrete guidance on how to present this information, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the difference between Algorithm 1 and variational inference, and it asks for the advantages of the approach. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the difference between Algorithm 1 and variational inference, specifically regarding the use of a Gaussian distribution to approximate the target distribution. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the difference between Algorithm 1 and variational inference, specifically regarding the use of a Gaussian distribution to approximate the target distribution. This is a relevant and important point that could help clarify the novelty and distinctiveness of the proposed algorithm. However, the comment does not provide any suggestions or guidance on how the authors might address this question or improve their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the entailment exercise lacks basic details and suggests that it should be removed from the paper or provided with more empirical and analyzed information. This feedback is clear and provides a direct action for the authors to take, making it 5. The comment specifies what needs to be done to improve the draft, ensuring that the authors know exactly how to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the entailment exercise, suggesting that it lacks basic details and should be removed or provided with more empirical and analyzed information. However, it does not specify which part of the paper discusses the entailment exercise, making it weakly grounded. The comment is specific in detailing what is missing and what needs to be addressed, such as providing more empirical and analyzed information. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the entailment exercise lacks basic details, making it difficult to assess the efficacy of the technique. The reviewer suggests that the exercise should be removed or provided with more empirical and analyzed information. However, the comment does not provide specific examples or detailed reasoning to support why the exercise is insufficient or how it could be improved. This lack of detailed justification makes the claim 3, as the authors would need to infer the exact issues and how to address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the entailment exercise, noting that it lacks basic details and is difficult to assess its efficacy based on the information provided in the paper. The reviewer suggests that the exercise should be removed or provided with more empirical and analyzed information. This feedback is clear and actionable, as it directs the authors to either remove the exercise or enhance it with additional details. However, the comment could be more helpful if it provided specific suggestions on what additional information should be included or how the exercise could be improved. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear path forward, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue with the mathematical expression of the Gaussian distribution in lines 225 and 227, noting that it is ambiguous. However, it does not provide any guidance or suggestions on how to clarify or improve the expression. The authors are left without a clear understanding of what needs to be done to address the ambiguity. Without explicit instructions or examples, the comment lacks actionability, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 225 and line 227,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the mathematical expression of the Gaussian distribution, indicating that it is ambiguous. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the mathematical expression of the Gaussian distribution in lines 225 and 227 is ambiguous. However, it does not provide any further explanation, examples, or references to support this claim. Without additional context or details, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the mathematical expression of the Gaussian distribution in lines 225 and 227, noting that it is ambiguous. This feedback is 3 as it points out a potential area for clarification or improvement in the paper. However, it lacks actionable guidance or suggestions on how to resolve the ambiguity, such as proposing alternative ways to present the expression or recommending specific changes. Without detailed advice, the authors may struggle to address the issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that using only certain types of tokens is insufficient for testing and recommends considering additional types of responses. However, it does not provide specific guidance on which additional types of responses should be considered or how to incorporate them into the testing process. The action is implicit and somewhat vague, as the authors are left to infer what specific types of responses should be included and how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that using only certain types of tokens is insufficient for testing and recommends considering additional types of responses. However, it does not specify which part of the paper this critique pertains to, such as a specific section or experiment, making it weakly grounded. The comment is specific in its suggestion to consider additional types of responses, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that using only certain types of tokens is insufficient for testing and recommends considering additional types of responses. However, the comment lacks specific examples or references to support why additional types of responses are necessary or how they would enhance the testing. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the testing methodology, specifically noting that using only certain types of tokens may not be sufficient. It suggests that additional types of responses should be considered, which is a clear and actionable piece of feedback. However, the comment lacks specific guidance on what additional types of responses should be included or how to incorporate them into the testing process. While it points out a relevant area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires further elaboration to be fully actionable."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the privacy protection capability of the paper, specifically questioning the effectiveness of using chatGPT for text paraphrasing and the reliance on manipulating the temperature (T) for text privacy protection. However, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the privacy protection measures. The comment lacks actionable details, such as recommending alternative methods or specific steps to enhance privacy protection. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the privacy protection capability of the paper, specifically questioning the effectiveness of using chatGPT for text paraphrasing and the reliance on manipulating the temperature (T) for text privacy protection. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the concern about the privacy protection capability and the limitations of the current approach, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the privacy protection capability is insufficient, specifically questioning the effectiveness of using chatGPT for text paraphrasing and the reliance on manipulating the temperature (T) for text privacy protection. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the privacy protection capability of the paper, specifically questioning the effectiveness of using chatGPT for text paraphrasing and the reliance on manipulating the temperature (T) for text privacy protection. While it highlights a potential weakness, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve their approach to privacy protection. Without specific recommendations or examples, the feedback provides limited value to the authors in terms of actionable steps for improvement. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the novelty of the approach described in the manuscript is not significant enough, specifically mentioning the use of word embeddings to define the weight of lexicon terms. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might enhance the novelty or significance of their work. Without actionable advice or specific recommendations, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the novelty of the approach, specifically mentioning the use of word embeddings to define the weight of lexicon terms. This provides clear guidance on what aspect of the paper needs improvement, namely, the novelty and significance of the approach. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the novelty of the approach described in the manuscript is not significant enough, specifically mentioning the use of word embeddings to define the weight of lexicon terms. However, the comment lacks specific examples or references to support this claim, such as comparing it to existing methods or discussing how the novelty could be enhanced. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment identifies a potential weakness in the manuscript, noting that the novelty of the approach described in the general discussion is not significant enough. It specifically mentions the use of word embeddings to define the weight of lexicon terms, suggesting that this aspect may not be novel. However, the comment lacks depth and does not provide specific suggestions or examples on how the authors could enhance the novelty or significance of their approach. Without actionable guidance, the authors are left with a general understanding of the issue but without a clear path to improvement. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper would benefit from comparing its method to nonNeRF methods on the mentioned tasks. This comparison is explicitly stated as a way to help readers better understand the proposed method\"s advantages over conventional methods. The comment provides a clear and direct action for the authors to take, which is to include such a comparison in their draft. However, it does not specify which nonNeRF methods should be compared or how to conduct the comparison, leaving some room for interpretation. Despite this, the action is concrete enough for the authors to know what needs to be done to improve their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from comparing its method to nonNeRF methods on the mentioned tasks. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or experiment. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area that needs attention. The comment is specific in suggesting a comparison to nonNeRF methods, but it lacks grounding as it does not direct the authors to a particular part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from comparing its method to nonNeRF methods on the mentioned tasks. This claim is based on the premise that such a comparison would help readers better understand the proposed method\"s advantages over conventional methods. However, the comment lacks specific examples or references to nonNeRF methods that could be used for comparison, making it 3. The authors would need to infer which methods might be relevant and how to conduct the comparison, which could be challenging without further guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a valuable addition to the paper by recommending a comparison of the proposed method with nonNeRF methods on the mentioned tasks. This comparison would help readers better understand the method\"s advantages and its position relative to conventional methods. The feedback is clear and actionable, providing a specific direction for the authors to enhance their draft. However, it could be more helpful if it included suggestions on which nonNeRF methods to compare or how to conduct the comparison effectively. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy in the terminology used in the paper, specifically questioning whether certain lowerlevel tasks are considered NLU or syntactic tasks. It references a rich literature on morphological and syntactic probing tasks, suggesting that the authors should clarify their terminology. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to the terminology. The action is implicit and somewhat vague, as the authors can infer that they need to clarify their terminology but are not given concrete steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the page numbers \"178:181,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether certain lowerlevel tasks are considered NLU or syntactic tasks, providing a clear direction for the authors to clarify their terminology. Additionally, it references a rich literature on morphological and syntactic probing tasks, which further grounds the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the terminology used in the paper, specifically questioning whether certain lowerlevel tasks are considered NLU or syntactic tasks. The reviewer references a rich literature on morphological and syntactic probing tasks, which provides some context for the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to clarify the terminology themselves to address the issue, but the comment provides a starting point for this clarification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the terminology used in the paper, specifically questioning whether certain lowerlevel tasks are considered NLU or syntactic tasks. It references a rich literature on morphological and syntactic probing tasks, which provides a context for the authors to clarify their terminology. This feedback is clear and actionable, as it prompts the authors to review and potentially revise their terminology to ensure consistency and clarity in their work. However, the comment could be more helpful if it provided specific examples or suggested alternative terminology to clarify the distinction. Overall, the comment is 4, as it directs the authors to an important area for improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should briefly discuss the relationship of their idea to traditional attempts using longterm motion trajectories, specifically mentioning motion segmentation. While the comment implies that the authors should include this discussion, it does not provide explicit instructions on how to integrate it into the paper. The action is implicit and somewhat vague, as the authors are left to infer the specific details of the discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"longterm motion trajectories\" and \"motion segmentation,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for a discussion on the relationship of the authors\" idea to traditional attempts, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using longterm motion trajectories is a traditional idea in computer vision, particularly for motion segmentation. It supports this claim by referencing a specific paper by Keuper et al. (2015) on motion trajectory segmentation. This reference provides a clear and specific example of the traditional use of longterm motion trajectories, making the claim 5. The inclusion of a reference adds robustness to the argument, ensuring that the authors can easily understand and address the feedback. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment acknowledges the use of longterm motion trajectories as a traditional idea in computer vision, particularly for motion segmentation. It suggests that while the introduction of Eulerian vs. Lagrangian views is a nice addition, the authors could further enhance the theoretical and academic value of their approach by discussing the relationship of their idea to traditional attempts. This feedback is clear and actionable, providing a specific suggestion for improvement that could strengthen the paper\"s theoretical foundation without compromising its technical contribution. However, the comment could be more helpful if it included examples or specific points to consider in this discussion. Overall, the comment is 4, as it offers a constructive direction for enhancing the paper\"s academic value."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity in the problem formalization section, specifically regarding the description of task types on graph data. It notes that the section focuses more on formalizing challenges rather than conveying the authors\" task objectives. While the comment identifies a problem, it does not provide explicit guidance on how to address it or suggest specific changes that the authors could make to improve the clarity of the section. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the task objectives and ensure consistency with the section\"s purpose. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"problem formalization section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in describing the specific task types addressed on graph data and the inconsistent focus on formalizing challenges rather than conveying the authors\" task objectives. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the problem formalization section lacks a clear description of the specific task types addressed on graph data, focusing instead on formalizing challenges. The comment suggests that this makes the purpose of the section unclear, as it does not convey the authors\" task objectives. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed reasoning or evidence makes the claim 3, as it requires more information to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the problem formalization section, noting that it lacks a clear description of the specific task types addressed on graph data. It points out that the section focuses more on formalizing challenges rather than conveying the authors\" task objectives, which makes the purpose of the section unclear. This feedback is clear and actionable, as it highlights a critical area for improvement that the authors can address by clarifying the task objectives and ensuring consistency with the section\"s purpose. However, the comment could be more helpful if it provided specific suggestions on how to improve the clarity or examples of what should be included. Overall, the comment is 4, as it directs the authors to a specific area that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of an ablation study on training techniques, specifically mentioning Informative Prior Initialization (IPI) and vprediction. It suggests that such a study would help assess the specific impact of these techniques and compare YOSO\"s performance with other models that could leverage them. While the comment implies that an ablation study should be conducted, it does not provide explicit instructions on how to implement it or which aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for an ablation study and determine how to conduct it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of an ablation study on training techniques, specifically referencing the Informative Prior Initialization (IPI) and vprediction methods. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of lacking an ablation study, which would help assess the impact of these techniques and compare YOSO\"s performance with other models. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of an ablation study on training techniques, specifically Informative Prior Initialization (IPI) and vprediction, makes it difficult to assess their specific impact and compare YOSO\"s performance with other models. The comment provides a logical reasoning by suggesting that an ablation study would help evaluate the effectiveness of these techniques and their potential benefits for other models. However, the comment could be strengthened by providing specific examples or references to other models that could leverage these techniques, which would enhance its verifiability. Therefore, the comment is 4, as it provides a clear rationale but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of an ablation study on training techniques, specifically mentioning Informative Prior Initialization (IPI) and vprediction. This feedback is valuable as it highlights a critical area for improvement that could enhance the paper\"s contribution and understanding of the impact of these techniques. By suggesting the inclusion of an ablation study, the comment provides clear and actionable guidance for the authors to strengthen their work. However, the comment could be more helpful if it offered specific suggestions on how to conduct the ablation study or which aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies two specific issues: redundancy in the content and the lack of a smallscale validation experiment. It explicitly suggests that the authors should present a smallscale validation experiment using the datasets mentioned in the paper. This feedback is clear and provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (229272) where redundancy is identified, allowing the authors to accurately pinpoint the parts of the paper being addressed. It also provides a specific suggestion to present a smallscale validation experiment using the datasets mentioned in the paper. This level of detail and explicit reference to the paper\"s content makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the content is limited and redundant, providing specific examples of paragraphs that are unnecessary. It also suggests a smallscale validation experiment to address the lack of domain knowledge in LLMs. The comment is 4 as it provides clear examples of redundancy and a specific suggestion for improvement, which could be further supported by referencing similar experiments or studies. However, the claim about the content being limited lacks detailed justification or references, making it 3. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: redundancy in the content and the lack of a smallscale validation experiment. It provides clear examples of redundant descriptions, allowing the authors to pinpoint and address these issues. The suggestion to present a smallscale validation experiment using the datasets mentioned in the paper is actionable and constructive, offering a concrete way to enhance the paper. This feedback is clear and provides valuable guidance for the authors to improve their draft, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to rewrite the section on theoretical contributions to make the connections with the proposed method clearer. It provides a specific action for the authors to take, which is to clarify the relationship between the theory and the proposed method. The feedback is clear and direct, giving the authors a concrete step to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"theoretical contributions\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical contributions, namely that their connection to the proposed method is unclear. The reviewer suggests rewriting the section to clarify these connections, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical contributions are too abstract and unclear in their connection to the proposed method. The reviewer suggests that having segregated feature vectors for backdoored and clean data seems artificial and not directly related to EigenGuard. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of detailed justification or references leaves the claim 3, as it requires more information to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical contributions, noting that they are too abstract and unclear in their connection to the proposed method. It provides a clear suggestion to rewrite the section to clarify these connections, which is a valuable piece of feedback. However, the comment could be more helpful if it offered specific guidance on how to make these connections clearer or provided examples of how to structure the theoretical section more effectively. Despite this, the comment is 4 as it directs the authors to a critical area for improvement, providing a clear path for enhancing the clarity and relevance of their theoretical contributions. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of whether the code will be released, specifically mentioning the difficulty in reproducing the GCN implementation without the original code. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify their plans regarding code release, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of whether the code will be released, specifically mentioning the difficulty in reproducing the GCN implementation without the original code. However, it does not specify which part of the paper discusses the code release or the GCN implementation, making it weakly grounded. The comment is specific in its concern about the reproducibility of the code, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of whether the code will be released, specifically mentioning the difficulty in reproducing the GCN implementation without the original code. The comment provides a logical reasoning by pointing out the importance of code release for reproducibility, which is a common practice in scientific research. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to address the concern themselves by clarifying their plans regarding code release. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the clarity of whether the code will be released, specifically mentioning the difficulty in reproducing the GCN implementation without the original code. While it identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern. The comment points out the importance of code release for reproducibility but does not provide actionable steps or examples for the authors to follow. As a result, the feedback is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the use of secondorder Taylor expansions in Equations (9) and (10), suggesting that the differential functions themselves could be used instead. While the comment implies that the authors should reconsider their approach, it does not explicitly instruct them to make this change or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that they should reconsider their method but without specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equations (9) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the use of secondorder Taylor expansions and suggests using the differential functions themselves. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point questions the use of secondorder Taylor expansions in Equations (9) and (10), suggesting that the differential functions themselves could be used instead. However, the comment does not provide any reasoning or evidence to support why this alternative approach would be more appropriate or beneficial. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment questions the use of secondorder Taylor expansions in Equations (9) and (10), suggesting that the differential functions themselves could be used instead. This feedback identifies a specific area where the authors might consider an alternative approach, which could potentially improve the accuracy or efficiency of their model. However, the comment lacks depth and does not provide any rationale or examples for why the differential functions would be a better choice. While it points out a potential area for improvement, it does not offer detailed guidance or suggestions on how to implement this change. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with Table 3, noting that the recall on lemmas/forms seen in training is missing for the encs BPE to character results. It provides references to three external works that could be relevant to this issue. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to incorporate the references or improve the table. The action is implicit and somewhat vague, as the authors can infer that they need to address the missing recall but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the recall on lemmas/forms seen in training for the encs BPE to character results. Additionally, it provides references to external works that could be relevant to this issue, which further specifies the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the recall on lemmas/forms seen in training is missing for the encs BPE to character results in Table 3. This claim is supported by references to three external works, which provide context and evidence for the assertion. However, the comment could be strengthened by including more detailed explanations or examples from the referenced works to fully substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation for the claim but lacks comprehensive details. This aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that the recall on lemmas/forms seen in training is missing for the encs BPE to character results. This is a clear and actionable piece of feedback that can help the authors improve their draft by ensuring that all relevant information is included in the table. The comment also provides references to external works that could be relevant to this issue, which can guide the authors in addressing the problem. However, the comment could be more helpful if it included a more detailed explanation of why this information is important or how it impacts the overall analysis. Overall, the comment is 4 as it provides clear guidance on an area for improvement, but it could be more comprehensive with additional context or suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the claim that better wordalignment improves manytomany translation and questions why the proposed method has no impact on the MLSC setup (Table 3). It suggests that Section 4 touches on this point but lacks an explanation. While the comment implies that the authors should provide an explanation for this discrepancy, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the lack of explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the claim that better wordalignment improves manytomany translation and questions why the proposed method has no impact on the MLSC setup (Table 3). It suggests that Section 4 touches on this point but lacks an explanation. While the comment does not explicitly mention a specific section or table, it implies that Section 4 is the relevant part of the paper. The authors can infer that the comment relates to the discussion of the proposed method\"s impact on the MLSC setup. However, the comment lacks specificity as it does not detail what explanation is needed or how the authors should address the issue. Therefore, the comment is 2, aligning with category 2.", "verifiability_rationale": "The review point questions the claim that better wordalignment improves manytomany translation and points out that the proposed method has no impact on the MLSC setup (Table 3). It suggests that Section 4 touches on this point but lacks an explanation. This is a logical claim based on the observation that the proposed method does not align with the expected outcome, and it highlights a gap in the explanation provided in the paper. However, the comment could be strengthened by providing specific examples or references to support the claim. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks detailed evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment raises a pertinent question about the claim that better wordalignment improves manytomany translation, specifically questioning why the proposed method has no impact on the MLSC setup (Table 3). It points out that Section 4 touches on this point but lacks an explanation, which is a valid observation. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their explanation. While it identifies a gap in the paper, it lacks actionable feedback, making it 3. The authors are left with a clear understanding of what needs to be clarified but without detailed guidance on how to do so. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation of the method, noting that it requires precollected offline datasets and cannot be applied in an online setting where policies interact with the environment. This implies that the authors should consider expanding the applicability of their method to online settings. However, the comment does not provide specific guidance on how to achieve this expansion or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a limitation of the method, specifically its requirement for precollected offline datasets and its inability to be applied in an online setting. However, it does not specify which part of the paper discusses the offline setting or how this limitation affects the applicability of the method. The authors can infer that it relates to the methodology or experimental sections, but the comment lacks full grounding as it does not explicitly mention these sections. It is specific in identifying the issue of offline datasets and the limitation of applicability, but the lack of grounding makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the method is restricted to an offline setting, which limits its applicability. The reviewer provides a logical reasoning by stating that the method requires precollected offline datasets and cannot be applied in an online setting where policies interact with the environment. This reasoning is clear and provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant limitation of the method, specifically its restriction to an offline setting. It highlights that the method requires precollected offline datasets and cannot be applied in an online setting where policies interact with the environment. This feedback is valuable as it points out a critical limitation that the authors need to address to broaden the applicability of their work. However, the comment could be more helpful if it provided suggestions on how to overcome this limitation or offered examples of how to adapt the method for online settings. Despite this, the comment is 4 as it directs the authors\" attention to a crucial area for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of the learned representation is insufficient because it is limited to the linear evaluation setting. It implies that the authors should consider additional downstream tasks, such as finetuning, detection, and segmentation, as reported in the literature. While the comment provides a clear direction for expanding the evaluation, it does not specify which specific tasks should be included or how to implement them. The action is explicit but somewhat vague, as the authors know they need to expand the evaluation but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the evaluation of the learned representation is insufficient because it is limited to the linear evaluation setting. It implies that the authors should consider additional downstream tasks, such as finetuning, detection, and segmentation, as reported in the literature. However, the comment does not specify which part of the paper discusses the evaluation of the learned representation, making it weakly grounded. The suggestion to consider additional tasks is specific, as it provides examples of tasks that could be included. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation of the learned representation is insufficient because it is limited to the linear evaluation setting. The reviewer suggests that additional downstream tasks, such as finetuning, detection, and segmentation, should be considered. This claim is 3 as it provides a logical reasoning for the need to expand the evaluation beyond the current setting. However, the comment lacks specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the learned representation, noting that it is only assessed in the linear evaluation setting. It suggests that additional downstream tasks, such as finetuning, detection, and segmentation, should be considered to provide a more comprehensive evaluation. This feedback is clear and actionable, as it directs the authors to expand their evaluation to include other relevant tasks. However, the comment could be more helpful if it provided specific examples or references to guide the authors in selecting these additional tasks. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the novelty of the paper is low, as stagewise and progressive training have been used for a long time and are common practices. However, it does not provide any specific guidance or suggestions on how the authors could enhance the novelty of their work. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to differentiate the work from existing literature. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically mentioning that stagewise and progressive training have been used for a long time and are common practices. However, it does not specify which part of the paper this critique is based on, such as a particular section or experiment where these methods are discussed. Without explicit references to specific sections or examples, the authors cannot confidently determine which parts of the paper are being addressed. Additionally, the comment lacks specificity in detailing what aspects of the paper are lacking in novelty or how the authors could improve their work. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is low, stating that stagewise and progressive training have been used for a long time and are common practices. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate why these methods are not novel in the context of the paper. Without such support, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the novelty of the paper, stating that stagewise and progressive training have been used for a long time and are common practices. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions or guidance on how the authors could enhance the novelty of their work. Without actionable feedback or constructive criticism, the comment lacks helpfulness, leaving the authors without a clear understanding of what improvements could be made to strengthen their paper. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the applicability of the analysis to more general cases, specifically asking if it can handle more general Markov chains and if there is FFN and nonlinearity on top of the attention layer. While the questions imply that the authors should address these points, they do not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information or analysis to address these questions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the applicability of the analysis to more general cases, specifically asking if it can handle more general Markov chains and if there is FFN and nonlinearity on top of the attention layer. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about the generalizability of the analysis and the potential inclusion of FFN and nonlinearity, but without clear grounding, the authors may struggle to determine where these questions should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification and extension of the analysis. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment raises important questions about the generalizability of the analysis presented in the paper. It asks how the analysis extends to more general cases, specifically whether it can handle more general Markov chains and if there is FFN and nonlinearity on top of the attention layer. These questions prompt the authors to consider the broader applicability of their work and potentially expand their analysis to include more complex scenarios. However, the comment does not provide specific guidance or suggestions on how to address these questions or improve the paper. While it highlights areas for potential expansion, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the discussion of reference 19 in section 3.1 and line 57. It questions whether 19 uses the same Fine state automaton as the current paper or if there is a difference. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the difference, if any. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the relationship between their work and 19 but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.1\" and \"line 57,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether reference 19 uses the same Fine state automaton as the current paper or if there is a difference. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the authors have clearly discussed the use of the same Fine state automaton in reference 19 as in their own work. It highlights a potential gap in the discussion and suggests that the authors clarify this point. However, the comment does not provide specific reasoning or evidence to support the claim that the discussion is unclear or that there is a difference in the automaton used. Without additional context or examples, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3, as it provides some basis for the claim but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion of reference 19 in section 3.1 and line 57, questioning whether the same Fine state automaton is used or if there is a difference. This feedback is clear and actionable, as it prompts the authors to clarify the relationship between their work and the referenced study, potentially improving the clarity and accuracy of their discussion. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of how to clarify the difference, if any. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the auto_weight scheme in algorithm 1, noting that it might require a lot of memory due to the need for intermediate gradients for each domain. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to optimize memory usage or alternative approaches. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the auto_weight scheme, which requires intermediate gradients for each domain, potentially leading to memory issues. The comment further supports this claim by referencing relevant literature, providing additional context and evidence. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the auto_weight scheme in algorithm 1 might require a lot of memory due to the need for intermediate gradients for each domain. This claim is supported by references to two external works, 1 FedGP: Bufferbased Gradient Projection for Continual Federated Learning and 2 FLamby: Datasets and Benchmarks for CrossSilo Federated Learning in Realistic Healthcare Settings. These references provide evidence and context for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the auto_weight scheme in algorithm 1, noting that it might require a lot of memory due to the need for intermediate gradients for each domain. This is a specific and relevant observation that could impact the efficiency and scalability of the algorithm. However, the comment does not provide any suggestions or guidance on how to address this issue, such as proposing alternative approaches or optimizations. Without actionable advice, the authors are left with a vague understanding of the problem but no clear path to improvement. Therefore, the comment is 3, as it highlights a concern but lacks depth and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that the backbone is constrained to be the double LSTM while popular transformers are not involved. It suggests that pretrained language models are not covered as well, and that the application of the method to more extensive model structures remains a potential concern. The comment also mentions that limitations are discussed in Section 6 but questions their sufficiency. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these concerns or specific actions for the authors to take. The feedback is 3 as it points out a limitation and suggests further exploration, but it lacks concrete steps or detailed suggestions for improvement. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the paper in not involving popular transformers as the backbone, despite the double LSTM being used. It mentions that pretrained language models are not covered as well, and raises a concern about the applicability of the method to more extensive model structures. The comment also questions the sufficiency of the limitations discussed in Section 6. While the authors can infer that this comment relates to the methodology or limitations sections, it does not explicitly mention these sections, making it weakly grounded. However, the comment is specific in detailing the issue with the backbone and the need for more extensive model structures. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not cover popular transformers as the backbone, despite using the double LSTM, and questions the sufficiency of the limitations discussed in Section 6. However, the comment lacks specific examples or references to support the claim about the limitations of the paper. Without detailed evidence or reasoning, the authors may find it challenging to address the concerns raised. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically noting that the backbone is constrained to be the double LSTM while popular transformers are not involved. It points out that pretrained language models are not covered as well, which could be a concern for the application of the method to more extensive model structures. The comment also questions the sufficiency of the limitations discussed in Section 6. While the feedback highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this limitation or expand their work to include transformers. This makes the comment 3, as it provides insight into a potential weakness but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the contribution and novelty of the paper, stating that it combines existing techniques and uses variational inference for parameter learning. However, it does not provide any actionable advice or suggestions for the authors to address this critique. There is no guidance on how the authors might enhance the contribution or novelty of their work, nor are there any specific recommendations for improvement. As a result, the comment lacks any actionable content, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the contribution and novelty of the paper, specifically mentioning that the model combines existing techniques like structure learning regularization (NOTEARS) and missing value imputation, and uses variational inference for parameter learning. However, it does not specify which part of the paper this critique is based on, such as a particular section or methodology. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the contribution or novelty are considered limited or how the authors might improve them. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution and novelty of the paper are limited, stating that the model combines existing techniques and uses variational inference for parameter learning. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the assertion. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the contribution and novelty of the paper, stating that it combines existing techniques and uses variational inference for parameter learning. However, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The comment identifies a potential weakness but does not guide the authors on how to enhance the originality or value of their work. Without actionable advice or constructive criticism, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises an interesting question about the efficiency of MSLR, which requires tuning unimodal models before using them in the late fusion process. The reviewer suggests comparing this approach to directly tuning a latefusion model with separate learning rates for each modality, potentially with a similar or less compute budget. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to conduct this analysis or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer the need for a comparison but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MSLR,\" allowing the authors to accurately identify the part of the paper being addressed. It also provides a specific suggestion for comparison, which is clear and actionable. The reviewer suggests comparing the efficiency of MSLR with tuning unimodal models to directly tuning a latefusion model with separate learning rates for each modality, potentially with a similar or less compute budget. This provides a clear direction for the authors to consider in their work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the efficiency of MSLR, which requires tuning unimodal models before using them in the late fusion process. The reviewer suggests comparing this approach to directly tuning a latefusion model with separate learning rates for each modality, potentially with a similar or less compute budget. This is a logical suggestion based on the current setup, but it does not provide specific evidence or references to support the claim that this comparison would be interesting or beneficial. The comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises an interesting question about the efficiency of MSLR, which requires tuning unimodal models before using them in the late fusion process. The reviewer suggests comparing this approach to directly tuning a latefusion model with separate learning rates for each modality, potentially with a similar or less compute budget. This feedback is 3 as it provides a potential area for improvement and suggests a direction for further exploration. However, the comment lacks specific guidance or detailed suggestions on how to conduct this comparison or what metrics to consider. While it offers a valuable insight, it could be more helpful with additional depth and actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "5", "helpfulness_label": "2", "actionability_rationale": "The review point questions the relevance of representing the input using 8 bits, given that 8bit batch norm has been proposed in previous literature. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of novelty or whether the authors should reconsider their approach. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the relevance of representing the input using 8 bits, given that 8bit batch norm has been proposed in previous literature. However, it does not specify which part of the paper discusses this representation or where the authors introduce it. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the novelty is undermined by the existing literature. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the novelty of the work by pointing out that 8bit batch norm has been proposed in previous literature. The reviewer provides a specific reference to an external work (https://arxiv.org/pdf/1805.11046.pdf) to support their claim. This level of detail and reference to an external source enhances the verifiability of the claim, as it allows the authors to understand the basis of the critique and potentially address it. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment questions the relevance of representing the input using 8 bits, given that 8bit batch norm has been proposed in previous literature. This raises a concern about the novelty of the work, as it suggests that the approach may not be original. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or improve the novelty of their work. Without actionable feedback or constructive advice, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the practical relevance of the proposed framework may be limited due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this concern or improve the practical relevance of their framework. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the practical relevance of the proposed framework may be limited due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not specify which part of the paper this observation is based on, nor does it provide details on how the authors might address this concern. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need revision. Additionally, the comment lacks specificity regarding what aspects of the framework are limited or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the practical relevance of the proposed framework may be limited due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or data to support the assertion, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the practical relevance of the proposed framework may be limited due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or enhance the practical relevance of their framework. Without actionable feedback or constructive advice, the comment lacks depth and does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct an experiment to demonstrate the necessity of including $X$ in the calculation of $M_t$, which is currently only based on $C$. This feedback is explicit and provides a clear action for the authors to take, namely conducting an additional experiment. The suggestion is also concrete, as it specifies what the experiment should demonstrate. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding an experiment to demonstrate the necessity of including $X$ in the calculation of $M_t$, which is currently only based on $C$. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for an additional experiment to demonstrate the necessity of $X$, but without explicit grounding, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an experiment should be conducted to demonstrate the necessity of including $X$ in the calculation of $M_t$, which is currently only based on $C$. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the necessity of $X$. The authors would need to infer the importance of $X$ based on the provided reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the experimental setup by suggesting that the authors should conduct an additional experiment to demonstrate the necessity of including $X$ in the calculation of $M_t$. This feedback is clear and actionable, as it provides a specific suggestion for improving the paper by conducting an additional experiment. However, the comment could be more helpful if it explained why the inclusion of $X$ is important or how it might impact the results. Despite this, the suggestion is valuable and provides the authors with a clear direction for enhancing their draft. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point makes a statement about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons, but it does not provide any explicit or implicit actions for the authors to take. It lacks any guidance or suggestions for improvement, leaving the authors without a clear understanding of what they should do with this information. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not refer to any specific part of the paper, such as sections, tables, or figures. It also lacks specificity because it does not provide details on what aspects of the paper are being addressed or how the complexity of problems involving MLPs is related to those involving FBDDs and perceptrons. Without specific references or detailed explanations, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a factual statement about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. It does not express an opinion, suggestion, or claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment makes a factual observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. However, it does not provide any actionable feedback or suggestions for improvement, nor does it offer insights into how the authors might address this observation in their paper. Without any guidance or direction, the comment lacks value for the authors in terms of improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests discussing the generalizability of observations, particularly those in Figure 4, and highlights various hyperparameters that could influence implicit biases in the algorithm. While the comment implies that the authors should consider these factors, it does not explicitly instruct them to include this discussion or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors can infer that they need to discuss generalizability but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the generalizability of observations, particularly those in Figure 4, and mentions various hyperparameters that could influence implicit biases in the algorithm. However, it does not specify which part of the paper should include this discussion, making it weakly grounded. The comment is specific in detailing the aspects that need to be addressed, such as the influence of hyperparameters on implicit biases and their impact on neural representations, geometric metrics, and learning stages. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests discussing the generalizability of observations, particularly those in Figure 4, and highlights various hyperparameters that could influence implicit biases in the algorithm. The comment provides a logical reasoning by mentioning specific hyperparameters that could affect neural representations, geometric metrics, and learning stages. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the claim themselves, which is a minor gap in the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests discussing the generalizability of observations, particularly those in Figure 4, and highlights various hyperparameters that could influence implicit biases in the algorithm. It provides a clear and actionable suggestion by identifying specific factors that could impact neural representations, geometric metrics, and learning stages. This feedback is valuable as it directs the authors to consider potential sources of bias and how they might affect the results. However, the comment could be more helpful if it offered specific examples or methods for addressing these issues. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out two issues: the paper is not wellorganized and uses nonstandard terminology. It provides an example of the nonstandard terminology, \"semihonest,\" and suggests using the more standard term \"honestbutcurious\" to describe the server. While the comment identifies specific issues and offers a concrete suggestion for improvement, it does not explicitly instruct the authors to reorganize the paper or provide detailed guidance on how to achieve this. The action is mostly implicit, as the authors can infer that they need to improve organization and terminology, but the comment lacks explicit instructions on how to do so. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the nonstandard terminology, \"semihonest,\" and suggests using the more standard term \"honestbutcurious\" to describe the server. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not wellorganized and uses nonstandard terminology. It provides a specific example of the nonstandard term \"semihonest\" and suggests using the more standard term \"honestbutcurious\" to describe the server. This provides a clear and specific example to support the claim, making it 4. However, the comment could be strengthened by providing more examples or detailed reasoning about why the organization is problematic. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies two issues with the paper: poor organization and the use of nonstandard terminology. It provides a specific example of the nonstandard term \"semihonest\" and suggests using the more standard term \"honestbutcurious\" to describe the server. This feedback is clear and actionable, as it directs the authors to improve the organization of their paper and to use standard terminology consistently. However, the comment could be more helpful if it offered suggestions on how to reorganize the paper or provided examples of wellorganized papers in the field. Overall, the comment is 4 as it provides specific guidance for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly lists three missing details regarding the experimental setup: the optimizer, the initialization, and PPOzero. This provides clear and direct actions for the authors to take, as they know exactly what information is missing and need to include it in their draft. The feedback is concrete and leaves no ambiguity about what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experimental details,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the optimizer, the initialization, and PPOzero. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements requesting information about the experimental setup, specifically asking for details on the optimizer, initialization, and PPOzero. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks experimental details, namely the optimizer, initialization, and PPOzero. This feedback is clear and actionable, as it directly points out what information is missing and needs to be included in the paper. By addressing these details, the authors can enhance the comprehensiveness and clarity of their experimental section. However, the comment could be more helpful if it provided suggestions on how to present these details or why they are important. Overall, the feedback is 4 as it guides the authors toward improving their draft by filling in critical gaps in the experimental details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for a detailed comparison of the proposed method\"s efficiency and complexity with other existing works. It specifically mentions the requirement for two image encoders and a detector in the decoding process, suggesting that a comparison with and without these components is necessary. While the comment implies that the authors should conduct this analysis, it does not provide explicit instructions on how to perform it or what specific metrics to use. The action is implicit and somewhat vague, as the authors can infer the need for an efficiency analysis but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the specific components it addresses, such as the use of two image encoders (LaVIT and EvaCLIP) and a detector in the Region Sampler. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the need for a detailed comparison in terms of efficiency analysis (total model parameter, FLOPs, memory) with and without the detector and LaVIT. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method requires multiple additional components compared to existing works, specifically mentioning the use of two image encoders and a detector. The reviewer suggests that a detailed comparison in terms of efficiency analysis (total model parameter, FLOPs, memory) is needed. While the comment highlights a potential issue, it lacks specific examples or references to existing works that do not require these additional components. This makes the claim 3, as the authors would need to conduct their own analysis to fully understand the basis of the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, specifically its complexity and efficiency compared to existing works. It points out that the method requires multiple additional components, such as two image encoders and a detector, which may impact its efficiency. The comment suggests that a detailed comparison in terms of efficiency analysis (total model parameter, FLOPs, memory) with and without these components is needed. This feedback is clear and actionable, providing the authors with a specific direction for improvement by suggesting a comprehensive analysis of the method\"s efficiency. However, the comment could be more helpful if it included examples of existing works that do not require these additional components or if it provided guidance on how to conduct the efficiency analysis. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper for claiming that extrapolation error is a major issue in MARL without providing evidence to support this claim. It also questions the relevance of the proposed techniques to addressing extrapolation error and notes the lack of evidence that the proposed method mitigates this error. While the comment highlights a significant gap in the paper, it does not provide explicit guidance or suggestions on how the authors might address these issues. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide evidence and clarify the connection between their techniques and extrapolation error. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim that extrapolation error is a major issue in MARL and questions the evidence provided to support this claim. It also critiques the relevance of the proposed techniques to addressing this issue. However, the comment does not specify which part of the paper makes this claim or where the proposed techniques are discussed, making it weakly grounded. The comment is specific in detailing the lack of evidence and the perceived disconnect between the techniques and the claimed issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks evidence to support the assertion that extrapolation error is a major issue in MARL. It also questions the relevance of the proposed techniques to addressing this issue and the lack of evidence that the proposed method mitigates extrapolation error. The comment provides a logical reasoning by pointing out the absence of evidence and the disconnect between the techniques and the claimed issue. However, it could be strengthened by providing specific examples or references to support the claim. Therefore, the comment is 3, as it provides a logical basis for the critique but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the lack of evidence to support the claim that extrapolation error is a major issue in MARL. It also questions the relevance of the proposed techniques to addressing this issue and the lack of evidence that the proposed method mitigates extrapolation error. This feedback is valuable as it highlights a critical gap in the paper that needs to be addressed. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or what evidence could be included to support the claim. Overall, the comment is 3 as it points out a significant weakness but lacks detailed guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include detailed ondevice results across ablation and comparison studies to substantiate claims about SCHEME\"s efficiency over conventional FFNs. It also mentions the need for details on benchmark configurations, hardware, and input shapes to ensure fair comparisons. While the comment implies that the authors should provide these details, it does not explicitly instruct them to do so. The action is concrete but implicit, as the authors can infer what needs to be done. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 4 and 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of detailed ondevice results across ablation and comparison studies, as well as details on benchmark configurations, hardware, and input shapes to ensure fair comparisons. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ondevice efficiency of SCHEME is underexplored, despite its theoretical complexity advantages. It supports this claim by pointing out that only limited throughput comparisons are presented in Tables 4 and 8, and suggests that detailed ondevice results across ablation and comparison studies would substantiate claims about SCHEME\"s efficiency. The comment also highlights the need for details on benchmark configurations, hardware, and input shapes to ensure fair comparisons. This reasoning is logical and provides a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific studies or benchmarks that support the need for detailed ondevice results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the ondevice efficiency of SCHEME, despite its theoretical complexity advantages. It points out that only limited throughput comparisons are presented in Tables 4 and 8, suggesting that detailed ondevice results across ablation and comparison studies would substantiate claims about SCHEME\"s efficiency over conventional FFNs. Additionally, the comment highlights the need for details on benchmark configurations, hardware, and input shapes to ensure fair comparisons. This feedback is clear and actionable, providing the authors with specific areas to address and improve their draft. However, it could be more helpful if it included suggestions on how to conduct these detailed ondevice studies or what specific details should be included in the benchmark configurations. Overall, the comment is 4, as it effectively guides the authors toward enhancing the paper\"s efficiency claims and ensuring fair comparisons."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential confusion with Long Short Term Memory (LSTM). However, it does not provide specific guidance on how to improve the name or what alternative names might be more appropriate. The action is implicit and lacks concrete details, leaving the authors to infer that they should change the name but without clear direction on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential confusion with Long Short Term Memory (LSTM). However, it does not specify which part of the paper this suggestion pertains to, such as the section where the strategy is introduced or discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, while the comment provides a reason for reconsidering the name, it lacks specificity in suggesting alternative names or how to improve the current one. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential confusion with Long Short Term Memory (LSTM). The reviewer provides a logical reasoning for the claim by pointing out the similarity in names, which could lead to confusion. However, the comment lacks specific examples or references to support the claim further, such as comparing the strategies or discussing how the confusion might impact the reader\"s understanding. This makes the claim 3, as it provides a logical basis but requires more detailed evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential confusion with Long Short Term Memory (LSTM). While the comment identifies a potential issue with the name, it lacks specific guidance or suggestions on how to improve it. The authors are left to infer that they should change the name but without any concrete alternatives or reasoning provided. This limits the helpfulness of the feedback, as it does not offer actionable steps for improvement. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the proposed method is not the best performer in terms of both robustness and fidelity, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the method or what specific changes should be made to enhance its performance. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"the experiments results\" without specifying which experiments or sections of the paper are being referred to, making it difficult for the authors to identify the exact part of the paper being addressed. Additionally, the comment does not specify what aspects of robustness and fidelity are lacking or how the proposed method could be improved. This lack of specificity and grounding makes it challenging for the authors to understand the feedback and address it effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method is not the best performer in terms of both robustness and fidelity. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific data, results, or references to compare the method against other approaches, the claim remains 1. The authors are left without a clear understanding of why the method is not the best performer, making it difficult for them to address the feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment points out that the proposed method is not the best performer in terms of both robustness and fidelity. However, it does not provide any specific details or suggestions on how the authors might improve their method to enhance its performance. Without actionable feedback or guidance on what aspects of the method could be improved or how to address the issues, the comment lacks helpfulness. The authors are left without a clear understanding of what steps to take to enhance their work. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the motivation and logical connection between the concepts of isometry, OT, and disentanglement are not clear. It suggests that the authors should explain the connection between disentanglement and isometry, as well as the need for OT in relation to isometry. The comment provides a clear action for the authors to take, which is to clarify these connections in the revision. However, it does not offer specific guidance on how to make these explanations clearer, leaving some room for interpretation. Therefore, the comment is 4, as it directs the authors to a specific area for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the concepts of isometry, OT, and disentanglement, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in the motivation and logical connection between these concepts, particularly the connection between disentanglement and isometry. The comment further suggests that the authors should explain the need for OT in relation to isometry. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the motivation and logical connection between the concepts of isometry, OT, and disentanglement are not clear. It provides a logical reasoning by pointing out that the connection between disentanglement and isometry is not explained well, and that the need for OT in relation to isometry is unclear. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the connections themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of clarity in the motivation and logical connection between the concepts of isometry, OT, and disentanglement. It highlights the need for the authors to explain how disentanglement connects to isometry and why OT is required for isometry. This feedback is clear and actionable, as it directs the authors to clarify these connections, which is essential for the paper\"s understanding and impact. However, the comment could be more helpful if it provided specific suggestions or examples on how to improve the explanation. Overall, the comment is 4, as it effectively points out a significant weakness and guides the authors toward improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment acknowledges the quality of the results on regular languages but questions their relevance to understanding realworld language models. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or improve the draft to better explain the connection between regular languages and realworld language models. As a result, the authors are left without any actionable steps to follow, making the comment 1.", "grounding_specificity_rationale": "The comment acknowledges the quality of the results on regular languages but questions their relevance to understanding realworld language models. However, it does not specify which part of the paper discusses these results or how they relate to realworld language models. The authors might infer that it relates to the results section, but this inference is not explicit. The comment lacks specificity as it does not provide details on what aspects of the results are unclear or how they could be improved to better explain realworld language models. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges the quality of the results on regular languages but questions their relevance to understanding realworld language models. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results on regular languages are not helpful for explaining realworld language models. Without additional context or explanation, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the quality of the results on regular languages but questions their relevance to understanding realworld language models. While it identifies a potential gap in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation of the connection between regular languages and realworld language models. The comment lacks actionable feedback and depth, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the novelty of the paper compared to the Venom paper 1, specifically regarding the V:N:M proposal. It asks whether the V:N:M concept was already introduced in the Venom paper and, if so, how it differs. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this concern or what specific aspects of their work need to be clarified or improved. Without actionable suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the novelty of the paper compared to the Venom paper 1, specifically regarding the V:N:M proposal. However, it does not specify which part of the paper this issue pertains to, such as a particular section or discussion where the V:N:M proposal is introduced. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the differences between the papers, but without clear grounding, it remains difficult for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the novelty of the paper compared to the Venom paper 1, specifically regarding the V:N:M proposal. The reviewer questions whether the V:N:M concept was already introduced in the Venom paper and, if so, how it differs. This is a request for clarification and does not contain a claim or opinion that requires verification. It is purely factual and seeks information, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises a question about the novelty of the paper compared to the Venom paper 1, specifically regarding the V:N:M proposal. It asks whether the V:N:M concept was already introduced in the Venom paper and, if so, how it differs. While the comment identifies a potential issue with the paper\"s originality, it lacks actionable feedback or suggestions for the authors to address this concern. It does not provide guidance on how the authors might clarify or differentiate their work from the Venom paper, leaving the authors without a clear path for improvement. Therefore, the comment is 2, as it highlights a potential issue but does not offer constructive advice or direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the qualitative intuition of the attribution maps (Fig 2) and the relationship between the attended areas and the actual task. It notes that the attended areas in 3D tasks do not seem to correspond to the 3D worth pixels and that there are clusters of attended pixels without clear semantic meaning. However, the comment acknowledges that the resulting analysis using the attribution maps seems to work, suggesting that there is quantitative value. The reviewer does not provide explicit guidance on how to address these issues or suggest specific improvements, leaving the authors to infer that they should clarify the qualitative value of the attribution maps. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 2\" and \"sec 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the attribution maps, noting that the attended areas do not seem to be related to the actual task and that there are clusters of attended pixels without clear semantic meaning. The comment also acknowledges the quantitative value of the analysis using the attribution maps but highlights the lack of qualitative value. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to a score of 5.", "verifiability_rationale": "The review point raises a concern about the qualitative intuition of the attribution maps (Fig 2), specifically noting that the attended areas do not seem to be related to the actual task and that there are clusters of attended pixels without clear semantic meaning. The reviewer acknowledges that the resulting analysis using the attribution maps seems to work, suggesting that there is quantitative value. However, the comment lacks specific examples or references to support the claim about the lack of qualitative value, making it 3. The authors would need to further explore and justify the qualitative aspects of the attribution maps to address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the qualitative intuition of the attribution maps (Fig 2), noting that the attended areas do not seem to be related to the actual task and that there are clusters of attended pixels without clear semantic meaning. However, the comment acknowledges that the resulting analysis using the attribution maps seems to work, suggesting that there is quantitative value. This feedback highlights a potential issue with the interpretation of the attribution maps and encourages the authors to clarify their qualitative value. While the comment identifies a weakness, it lacks specific suggestions or guidance on how to address the issue, such as proposing alternative methods for interpretation or analysis. Therefore, the comment is 3, as it provides insight but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the title overclaiming the contribution of the paper, specifically regarding the results on two language models, BERT and RoBERTa, and the lack of results on large language models (LLMs) like Llama270b. The reviewer questions the scalability of the proposed method to LLMs and requests empirical justification if it is scalable. Additionally, the comment points out a minor typographical error regarding the consistency of the term \"ROBERTA\" in Section 3.3 and \"RoBerta\" in the Introduction. While the comment identifies specific issues and requests for clarification, it does not provide explicit guidance on how to address the overclaim or improve the scalability of the method. The authors can infer that they need to provide additional results or justification, but the comment lacks concrete steps or detailed suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title and specific sections of the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue with the title, questioning the overclaim of the contribution and the lack of results on large language models like Llama270b. The comment further suggests that the authors provide empirical justification for the scalability of their method to LLMs. Additionally, it points out a minor typographical error regarding the consistency of the term \"ROBERTA\" in Section 3.3 and \"RoBerta\" in the Introduction. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the title overclaims the contribution of the paper, as it focuses on results from two language models (BERT and RoBERTa) but lacks results from large language models (LLMs) like Llama270b. The reviewer questions the scalability of the proposed method to LLMs and requests empirical justification if it is scalable. This claim is 3 as it highlights a potential gap in the paper\"s scope and suggests a specific area for improvement. However, the comment lacks detailed examples or references to support the claim that the title overclaims the contribution, making it 3. The authors would need to address the issue by providing additional results or justification, which is not explicitly outlined in the comment.", "helpfulness_rationale": "The review comment identifies a potential issue with the title, suggesting that it overclaims the contribution of the paper. It points out that the results are shown only on two language models, BERT and RoBERTa, and questions the scalability to large language models like Llama270b. This feedback is valuable as it prompts the authors to reconsider the scope and claims of their work. Additionally, the comment provides a specific suggestion to show empirical justification for scalability, which is actionable. However, the comment could be more helpful by offering guidance on how to address the overclaim or suggesting ways to expand the scope of the paper. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the lack of motivation for choosing date and country as possible spurious correlating variables with gender, noting that the paper only speculates about their potential for showing spurious correlations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this critique or improve the paper, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the lack of motivation for choosing date and country as possible spurious correlating variables with gender, noting that the paper only speculates about their potential for showing spurious correlations. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the lack of motivation but lacks grounding, as it does not clearly indicate where in the paper this issue is discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the paper for lacking motivation in choosing date and country as possible spurious correlating variables with gender. The reviewer suggests that the paper only speculates about their potential for showing spurious correlations. However, the comment does not provide any specific reasoning, examples, or references to support why these variables are problematic or how they could lead to spurious correlations. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it lacks motivation for choosing date and country as possible spurious correlating variables with gender. The reviewer points out that the paper only speculates about their potential for showing spurious correlations, which is a valid critique. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their justification for these choices. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the originality and contribution of the paper, specifically questioning the significance of exchanging channels using Batch Normalization (BN). It also suggests that Theorem 1 is based on existing work and is a simple fact. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback lacks actionable details, such as recommending ways to enhance the originality or provide additional context for Theorem 1. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses specific points related to the paper, such as the use of Batch Normalization (BN) for channel exchange and the basis of Theorem 1. However, it does not explicitly mention which section or part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its critique of the originality and contribution of the paper, as well as the reliance on existing work for Theorem 1. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the originality and contribution of the paper, specifically questioning the significance of exchanging channels using Batch Normalization (BN). It also suggests that Theorem 1 is based on existing work and is a simple fact. However, the comment lacks specific references or detailed reasoning to support these claims. The mention of Theorem 1 and its reliance on 38 provides some context, but the critique is not fully substantiated with evidence or examples. This makes the claim 3, as it requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment raises concerns about the originality and contribution of the paper, specifically questioning the significance of exchanging channels using Batch Normalization (BN). It also suggests that Theorem 1 is based on existing work and is a simple fact. While the comment identifies potential issues with the paper, it lacks actionable feedback or suggestions for improvement. It does not provide guidance on how the authors might address these concerns or enhance the originality of their work. As a result, the comment is 3, as it points out areas for improvement but does not offer detailed guidance on how to address them. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part suggests that if the method is meant as a main contribution and a practical method, more indepth studies are needed to establish its effectiveness in improving damping in secondorder methods. This is an implicit suggestion for the authors to conduct additional studies to validate their claims. The second part is a question about the notation, specifically asking what K denotes and whether it is equal to NC. This is a request for clarification, which is explicit but does not provide guidance on how to address the issue. Overall, the comment provides some actionable feedback but lacks detailed guidance on how to conduct the additional studies or clarify the notation. Therefore, it is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the notation of \"K\" and asking for clarification on its exact meaning. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts: a suggestion for further study to establish the effectiveness of the method and a question about the notation. The first part is a request for additional studies, which is a claim that requires justification or evidence to support the need for more indepth analysis. The second part is a factual question about the notation, which does not contain a claim. Therefore, the first part is 3, as it suggests a direction for further research but lacks specific examples or references, while the second part is factual and does not require verification. Overall, the comment is a mix of verifiable and nonverifiable elements, aligning with a score of 3.", "helpfulness_rationale": "The review comment provides two distinct pieces of feedback. The first part suggests that if the method is intended as a main contribution and a practical method, more indepth studies are needed to establish its effectiveness in improving damping in secondorder methods. This is a clear and actionable suggestion that encourages the authors to conduct additional research to validate their claims. The second part is a question about the notation, specifically asking what K denotes and whether it is equal to NC. This request for clarification is also helpful as it prompts the authors to address a potential ambiguity in their work. Overall, the comment is 4 as it offers actionable feedback and a clear direction for improvement, making it a valuable resource for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that an indepth analysis of the parameters k and N in the ablation study would enhance readers\" understanding of the algorithm. It also implies that an analysis of the running time or complexity, particularly the impact of k and N on the running time, would be beneficial. The comment explicitly states the need for more analysis, providing a clear action for the authors to take. However, it does not specify how to conduct this analysis or what specific aspects to focus on, which makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and the corresponding description, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting an indepth analysis of the parameters k and N in the ablation study, as well as an analysis of the running time or complexity. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that an indepth analysis of the parameters k and N in the ablation study would enhance readers\" understanding of the algorithm. It also implies that an analysis of the running time or complexity, particularly the impact of k and N on the running time, would be beneficial. However, the comment lacks specific examples or references to support why this analysis is necessary or how it would improve the paper. The suggestion is 3 as it provides a logical rationale for additional analysis, but it lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for enhancing the paper by recommending an indepth analysis of the parameters k and N in the ablation study. It also suggests analyzing the running time or complexity, particularly the impact of these parameters on the running time. This feedback is valuable as it identifies specific areas for improvement that could significantly enhance the readers\" understanding of the algorithm. Additionally, the comment points out a minor inconsistency between Figure 2 and its description, which is a helpful observation for the authors to address. Overall, the comment is 4 as it offers actionable suggestions for improving the draft, but it could be more comprehensive by providing more detailed guidance on how to conduct the analyses. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the lack of standard deviation in the results presented in Appendix B and asks for clarification on whether the 10 runs were done over random hyperparameter configurations for all baselines or with the best selected hyperparameters\" values. While the comment does not explicitly instruct the authors to include standard deviation or provide specific guidance on how to address the issue, it does imply that these details should be included. The action is implicit but concrete, as the authors can infer that they need to provide this information. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix B,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the absence of standard deviation in the results and seeks clarification on whether the 10 runs were done over random hyperparameter configurations or with the best selected hyperparameters\" values. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the absence of standard deviation in the results presented in Appendix B and seeks clarification on whether the 10 runs were done over random hyperparameter configurations for all baselines or with the best selected hyperparameters\" values. This is a request for clarification and does not contain a subjective claim or opinion that requires verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the lack of standard deviation in the results presented in Appendix B. It also seeks clarification on whether the 10 runs were done over random hyperparameter configurations for all baselines or with the best selected hyperparameters\" values. This feedback is valuable as it points out a potential gap in the presentation of results and prompts the authors to provide additional information that could enhance the transparency and robustness of their findings. However, the comment could be more helpful if it suggested including standard deviation or provided guidance on how to present this information effectively. Overall, the comment is 3 as it identifies an area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include more details about the task generation process in the main text rather than only in the appendix section. This provides a clear and direct action for the authors to take, ensuring that readers have a better understanding of the experimental setup. The comment is specific and actionable, as it clearly outlines what needs to be done to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that more details about the task generation process should be included in the main text rather than only in the appendix section. While it does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the experimental setup or methodology sections. The comment is specific in its request for more details, but it lacks full grounding as it does not explicitly mention the sections where these details should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details about the task generation process should be included in the main text, rather than only in the appendix section. This claim is based on the premise that providing more details would enhance the reader\"s understanding of the experimental setup and strengthen the paper\"s presentation. However, the comment does not provide specific examples or reasoning to support why these details are crucial or how they would improve the paper. Without additional context or justification, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that more details about the task generation process should be included in the main text rather than only in the appendix section. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s presentation and clarity. By incorporating these details into the main text, the authors can better inform readers about the experimental setup, which is crucial for understanding the paper\"s contributions. However, the comment could be more helpful if it provided specific examples of what details should be included or how they would enhance the paper. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point describes a specific aspect of the paper, namely the formation of new groups across previous local windows to connect tokens beyond local windows. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this aspect is a strength or a weakness, nor are there suggestions for improvement or clarification. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the formation of new groups across previous local windows to connect tokens beyond local windows. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not provide any further details or context about why this aspect is important or how it relates to the overall paper. Without additional information or guidance, the authors may not fully understand what needs to be addressed or improved. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point is a factual statement describing a specific aspect of the paper, namely the formation of new groups across previous local windows to connect tokens beyond local windows. It does not express an opinion, make a claim, or suggest changes. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a factual description of a specific aspect of the paper, namely the formation of new groups across previous local windows to connect tokens beyond local windows. However, it lacks any analysis, critique, or suggestions for improvement. Without additional context or guidance, the authors are left without actionable feedback on how to enhance their work or address potential weaknesses. Therefore, the comment is 1, as it does not offer any value to the authors in terms of improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the similarity between the proposed DD risk and the DRO risk, noting that the only difference is the use of entropy to capture distributional differences. It suggests that the authors should provide a more comprehensive illustration of the advantage of this specific distance metric and why it might lead to better generalization performance compared to other metrics used in DRO. While the comment implies that the authors should provide additional explanation and analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to present the additional information. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DD risk\" and \"DRO risk,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the advantage of the specific distance metric used and suggesting a more comprehensive illustration of its benefits. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a claim about the similarity between the proposed DD risk and the DRO risk, noting that the only difference is the use of entropy to capture distributional differences. It suggests that the authors should provide a more comprehensive illustration of the advantage of this specific distance metric and why it might lead to better generalization performance compared to others. The comment references works using different distance metrics in DRO literature, such as $f$divergence, Wasserstein distance, and MMD distance, and mentions that risk bounds have been derived for these metrics. This provides some support for the claim, but it lacks specific examples or detailed comparisons to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed evidence or examples to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the similarity between the proposed DD risk and the DRO risk, noting that the only difference is the use of entropy to capture distributional differences. It suggests that the authors should provide a more comprehensive illustration of the advantage of this specific distance metric and why it might lead to better generalization performance compared to others. This feedback is clear and actionable, as it highlights a specific area for improvement and offers a direction for the authors to enhance their explanation. By addressing these points, the authors can strengthen their paper and provide a more comprehensive understanding of their approach. Therefore, the comment is rated as 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the nature of the TREx dataset, asking whether it is a distantly supervised dataset with no human labels. It also suggests evaluating the dataset on annotated datasets like TACRED or FewRel. While the comment implies that the authors should clarify the nature of the dataset and consider evaluating it on other datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question about the dataset and consider evaluating it on other datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the nature of the TREx dataset, specifically whether it is a distantly supervised dataset with no human labels. It also suggests evaluating the dataset on annotated datasets like TACRED or FewRel. However, the comment does not specify which part of the paper discusses the TREx dataset, making it weakly grounded. The authors can infer that it relates to the dataset section, but this inference is not explicit. The comment is specific in suggesting alternative datasets for evaluation, which provides some guidance on how to address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question about the nature of the TREx dataset and a suggestion to evaluate it on annotated datasets like TACRED or FewRel. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the nature of the TREx dataset, specifically whether it is a distantly supervised dataset with no human labels. It also suggests evaluating the dataset on annotated datasets like TACRED or FewRel, which could provide a more robust evaluation. This feedback is 3 as it prompts the authors to clarify the nature of their dataset and consider alternative evaluation methods. However, the comment could be more helpful if it provided additional context or reasoning behind the suggestion to evaluate on other datasets. Overall, the comment offers a direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests looking at the training and validation curves of different losses and asks whether the model can bring all three losses down simultaneously. It also inquires about any tricks related to weighing these losses. While the comment implies that the authors should include these analyses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to conduct these analyses or what metrics to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests looking at the training and validation curves of different losses and asks about the model\"s ability to bring all three losses down simultaneously. It also inquires about any tricks related to weighing these losses. However, the comment does not specify which part of the paper this analysis should be included in, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for additional analysis, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point suggests looking at the training and validation curves of different losses and asks whether the model can bring all three losses down simultaneously. It also inquires about any tricks related to weighing these losses. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests a specific analysis that could enhance the paper, namely looking at the training and validation curves of different losses to understand the model\"s ability to bring all three losses down simultaneously. It also inquires about any tricks related to weighing these losses. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by conducting additional analyses. However, the comment could be more helpful if it offered suggestions on how to interpret the curves or what specific metrics to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the paper\"s claim regarding the NPhardness of computing the GOSPA metric. It points out that the paper lacks a rigorous theoretical argument or proof and instead relies on a citation that is not provided. The comment also notes that the claim is not generally true for assignment problems and suggests that it may be possible to reduce GOSPA to an exact polynomialtime computable assignment problem. Additionally, the comment highlights a contradiction in the paper, as it claims NPhardness but later assumes access to the optimal assignment matrix, which would limit the applicability. The comment provides clear and actionable feedback by pointing out the lack of a rigorous argument, suggesting a potential reduction to an assignment problem, and identifying a contradiction in the paper. However, it does not explicitly instruct the authors to provide a rigorous argument or proof, which would make the action more concrete. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the NPhardness of computing the GOSPA metric, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of a rigorous theoretical argument or proof, the reliance on a citation that is not provided, and the contradiction in assuming access to the optimal assignment matrix. The comment provides detailed feedback on the theoretical basis of the claim, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s assertion about the NPhardness of computing the GOSPA metric lacks a rigorous theoretical argument or proof. It critiques the paper for relying on a citation that is not provided and points out that the claim is not generally true for assignment problems. The comment also suggests that it may be possible to reduce GOSPA to an exact polynomialtime computable assignment problem, which would avoid all relaxations. Additionally, it highlights a contradiction in the paper, as it claims NPhardness but later assumes access to the optimal assignment matrix, which would limit the applicability. The comment provides logical reasoning and references to common knowledge about assignment problems, making the claim 4. However, the lack of specific references or detailed examples could be improved to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper\"s claim regarding the NPhardness of computing the GOSPA metric. It points out that the paper lacks a rigorous theoretical argument or proof, relying instead on a citation that is not provided. The comment also highlights that the claim is not generally true for assignment problems and suggests that it may be possible to reduce GOSPA to an exact polynomialtime computable assignment problem, avoiding all relaxations. Additionally, it identifies a contradiction in the paper, as it claims NPhardness but later assumes access to the optimal assignment matrix, which would limit the applicability. This feedback is clear and actionable, as it directs the authors to provide a rigorous argument or proof for their claim and addresses a significant flaw in the paper\"s logic. However, it could be more helpful if it offered specific guidance on how to address these issues. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include an algorithmic writeup of the solution to the pricing problem. While the comment explicitly states an action, it does not provide specific guidance on how to implement this suggestion, such as which aspects of the algorithm should be included or how to present it. The authors are left with a general idea of what needs to be done but without detailed instructions on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including an algorithmic writeup of the solution to the pricing problem. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or chapter where the pricing problem is discussed. Without explicit references, the authors may find it challenging to determine where to incorporate this suggestion. The comment is specific in its request for an algorithmic writeup but lacks grounding, as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including an algorithmic writeup of the solution to the pricing problem would be helpful. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that including an algorithmic writeup of the solution to the pricing problem would be beneficial. This feedback is 3 as it identifies a specific area where the paper could be improved by providing more detailed information on the solution methodology. However, the comment lacks depth and does not offer guidance on how to structure or present this algorithmic writeup, which would be valuable for the authors. While it points out a potential enhancement, it does not provide actionable steps or detailed suggestions for implementation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of clarity regarding the effectiveness of model averaging in balancing the tradeoff between KL divergence and reward. It suggests that achieving this tradeoff requires intelligent exploration and gradual updates during initialization, but it is unclear how this relates to the proposed technique or if there are other possible mechanisms. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue or suggest specific steps to clarify the relationship. The action is implicit and somewhat vague, as the authors are left to infer what needs to be done without concrete instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to the effectiveness of model averaging in balancing the tradeoff between KL divergence and reward. It raises a concern about the lack of clarity regarding how this tradeoff is achieved and suggests that it may involve intelligent exploration and gradual updates during initialization. However, the comment does not specify which part of the paper discusses model averaging or where this issue is addressed, making it weakly grounded. The comment is specific in detailing the issue of unclear effectiveness and potential mechanisms, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of clarity regarding the effectiveness of model averaging in balancing the tradeoff between KL divergence and reward. The reviewer suggests that achieving this tradeoff requires intelligent exploration and gradual updates during initialization, but it is unclear how this relates to the proposed technique or if there are other possible mechanisms. The comment provides a logical reasoning based on the reviewer\"s understanding, but it lacks specific examples or references to support the claim. This makes the claim 3, as it provides a logical framework but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the effectiveness of model averaging in balancing the tradeoff between KL divergence and reward. It highlights a lack of clarity in understanding how this tradeoff is achieved and suggests that it may involve intelligent exploration and gradual updates during initialization. While the comment points out a potential gap in the explanation, it does not provide specific suggestions or examples on how the authors might address this issue or improve their explanation. The feedback is 3 as it directs the authors\" attention to an area needing further clarification, but it lacks actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should discuss a possible generalization with a different distribution for the size of the batches. While the comment implies that the authors should include this discussion, it does not provide specific guidance on how to approach it or what aspects to consider. The action is implicit and somewhat vague, as the authors need to infer that they should discuss a specific topic and determine how to structure this discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing a possible generalization with a different distribution for the size of the batches. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in suggesting a particular topic for discussion, but without clear grounding, the authors may struggle to identify the exact section where this discussion should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests discussing a possible generalization with a different distribution for the size of the batches. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it could enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the authors should discuss a possible generalization with a different distribution for the size of the batches. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to approach this discussion or what aspects to consider. The feedback is 3 as it points out a possible enhancement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the analysis, noting that it only considers the case of batch size = 1 and questions the impact of batch size on the effective initialization scale. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their analysis to include different batch sizes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a limitation in the analysis, specifically mentioning that it only considers the case of batch size = 1 and questions the impact of batch size on the effective initialization scale. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the analysis, but without clear grounding, the authors may struggle to determine where to address this feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the analysis by noting that it only considers the case of batch size = 1 and raises a concern about the impact of batch size on the effective initialization scale. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate why this limitation is significant or how it affects the analysis. Without additional context or justification, the claim remains vague and 1, leaving the authors without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the analysis by pointing out that it only considers the case of batch size = 1 and questions the impact of batch size on the effective initialization scale. This feedback is 3 as it highlights an area where the authors could expand their analysis to provide a more comprehensive understanding of the model\"s behavior. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or analyses to include. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results presented in Figure 7, specifically questioning why more data leads to lower results on the ImageNet linear evaluation. The reviewer provides an example of sampling 50% of the data yielding better results than sampling 100% of the data. While the comment highlights a potential issue with the results, it does not provide explicit guidance on how the authors should address this concern or improve their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to investigate and explain this discrepancy in the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the results shown in Figure 7, specifically why more data leads to lower results on the ImageNet linear evaluation. The reviewer provides an example of sampling 50% of the data yielding better results than sampling 100% of the data, which adds clarity to the issue being raised. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the results presented in Figure 7, specifically why more data leads to lower results on the ImageNet linear evaluation. The reviewer provides an example of sampling 50% of the data yielding better results than sampling 100% of the data. This example is a logical observation that challenges the results, but it lacks specific references or detailed reasoning to fully substantiate the claim. The comment provides a basis for questioning the results but requires further elaboration or evidence to be 5. Therefore, the comment is 3.", "helpfulness_rationale": "The review comment raises a question about the results presented in Figure 7, specifically why more data leads to lower results on the ImageNet linear evaluation. It provides an example of sampling 50% of the data yielding better results than sampling 100% of the data, which highlights a potential issue with the analysis. While the comment identifies a specific area of concern, it does not offer suggestions or guidance on how the authors might investigate or address this discrepancy. The feedback is 3 as it points out a potential issue, but it lacks actionable advice, making it more beneficial for the authors to understand the problem rather than directly improving their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the lack of comprehensive evaluation in the paper, specifically noting the absence of quantitative results on the FVD metric, which is widely recognized and robust for evaluating temporal video prediction. The comment suggests that including FVD would enhance the paper\"s credibility and make it more comparable to other video generation methods. While the comment implies that the authors should include FVD, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include FVD and understand how it would enhance their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VBench\" as the primary evaluation benchmark, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of quantitative results on the FVD metric, which is widely recognized and robust for evaluating temporal video prediction. This provides clear guidance on what needs to be addressed to enhance the paper\"s credibility and comparability with other video generation methods. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comprehensive evaluation, specifically noting the absence of quantitative results on the FVD metric, which is widely recognized and robust for evaluating temporal video prediction. The comment provides a logical reasoning by suggesting that including FVD would enhance the paper\"s credibility and make it more comparable to other video generation methods. However, the comment could be strengthened by providing specific examples or references to studies that use FVD or similar metrics, which would further substantiate the claim. Overall, the comment is 4, as it provides a clear rationale but lacks detailed evidence or examples, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper\"s evaluation by pointing out the lack of comprehensive evaluation using the FVD metric, which is widely recognized and robust for evaluating temporal video prediction. It suggests that including FVD would enhance the paper\"s credibility and make it more comparable to other video generation methods. This feedback is clear and actionable, as it provides a specific metric to consider and a rationale for its importance. However, the comment could be more helpful by offering guidance on how to incorporate FVD into the evaluation or suggesting alternative metrics that might be relevant. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the technical details in section 2.2 are hard to follow, but it does not provide any specific guidance or suggestions on how to improve this aspect. There is no explicit or implicit action for the authors to take, leaving them without a clear understanding of what changes are needed to address the issue. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"2.2,\" indicating that it addresses a specific section of the paper. However, it does not specify what aspect of the technical details is hard to follow, nor does it provide any guidance on how to improve this aspect. This lack of specificity makes it difficult for the authors to pinpoint the exact issues and take corrective actions. Therefore, the comment is 2, aligning with category 2.", "verifiability_rationale": "The review point claims that the technical details in section 2.2 are hard to follow. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed explanation or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the technical details in section 2.2 are hard to follow, which is a valid observation. However, it lacks specificity and does not provide any guidance or suggestions on how to improve the clarity or presentation of the technical details. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, the comment is 2, as it identifies a problem but does not offer any actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the improvements offered by EVA over the backbone models, specifically OTFlow, in terms of designability and success rates. It also asks whether the design choices of adding geometry information and motifinterpolation benefit over prior backbones. While the comment implies that the authors should provide a comparison or explanation of these improvements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question of improvements and benefits. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"empirical evaluation for motifcoupling on the RFDiffusion benchmark and an insilico vaccine design benchmark,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the improvements offered by EVA over the backbone models, particularly OTFlow, in terms of designability and success rates. The comment further asks whether the design choices of adding geometry information and motifinterpolation benefit over prior backbones. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the improvements offered by EVA over the backbone models, specifically OTFlow, in terms of designability and success rates. It also asks whether the design choices of adding geometry information and motifinterpolation benefit over prior backbones. While the comment poses questions and suggests areas for improvement, it does not provide specific evidence, examples, or references to support the claim. The lack of detailed justification or evidence makes the claim 3, as the authors would need to provide additional information to fully address the questions raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the improvements offered by EVA over the backbone models, specifically OTFlow, in terms of designability and success rates. It also questions whether the design choices of adding geometry information and motifinterpolation benefit over prior backbones. This feedback is valuable as it prompts the authors to clarify and substantiate their claims regarding the novelty and advantages of their approach. By addressing these questions, the authors can better articulate the contributions of their work and provide a more comprehensive understanding of its benefits. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might demonstrate these improvements. Overall, the comment is 4 as it identifies a key area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a problem with the repetition of identical sentences in the Abstract, Introduction, and Conclusion sections of the paper. However, it does not provide any explicit or implicit guidance on how to address this issue. The authors are left without any actionable steps to take, such as suggestions for rephrasing or restructuring the text to avoid repetition. Without specific instructions or examples, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a problem with the repetition of identical sentences in the Abstract, Introduction, and Conclusion sections of the paper. However, it does not specify which sentences are identical or where they occur, making it difficult for the authors to pinpoint the exact parts of the paper that need revision. Additionally, the comment lacks specificity regarding what needs to be addressed or how to improve the text. Without detailed guidance, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is too much repetition of identical sentences in the Abstract, Introduction, and Conclusion sections of the paper. However, it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand the extent of the issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the repetition of identical sentences in the Abstract, Introduction, and Conclusion sections of the paper. This is a relevant observation that could impact the clarity and coherence of the paper. However, the comment lacks depth and does not provide any suggestions or guidance on how to address this issue. Without actionable feedback or examples of how to rephrase or structure the text to avoid repetition, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a problem but does not offer meaningful guidance for resolution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification about the reward function used in the ablation studies. It requests information on whether the reward function is \"sEH.\" This is a clear and direct request for additional information, providing the authors with a specific action to take. The comment is explicit and concrete, as it specifies exactly what information is needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Reward Function,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification about the reward function used in the ablation studies and whether it is \"sEH.\" This provides clear guidance on what information is needed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual question seeking clarification about the reward function used in the ablation studies. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of the paper that requires clarification: the reward function used in the ablation studies. By asking for this information, the reviewer prompts the authors to provide details that could enhance the transparency and comprehensiveness of their work. However, the comment lacks depth and does not offer suggestions or guidance on how to address this issue or why it is important. To be more helpful, the comment could include a rationale for why this information is crucial or how it might impact the interpretation of the results. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the comparison between selfgenerated code and previous work, noting that using selfgenerated code samples the model twice for each generation, while the original technique only generates the code once. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative methods for comparison. The action is implicit and vague, as the authors are left to infer that they might need to reconsider their comparison methodology but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the comparison between selfgenerated code and previous work, mentioning that using selfgenerated code samples the model twice for each generation, while the original technique only generates the code once. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the comparison methodology, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that using selfgenerated code for comparison is not fair because it samples the model twice for each generation, while the original technique only generates the code once. The comment provides a logical reasoning for why this could affect the fairness of the comparison, but it lacks specific examples or references to support the claim. This makes the comment 3, as the authors would need to further explore the implications of this difference to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between selfgenerated code and previous work, noting that using selfgenerated code samples the model twice for each generation, while the original technique only generates the code once. This observation highlights a potential bias in the comparison that could affect the fairness of the evaluation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that Sections 3 and 4, which should be the main contributions of the paper, are squeezed into a single page. It specifically mentions the lack of precise mathematical definitions for the quantum states in Eq (4), which makes it hard to follow. This feedback provides a clear and explicit action for the authors to take: they should expand Sections 3 and 4 to include the missing mathematical definitions. The comment is specific and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sections 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of precise mathematical definitions for the quantum states in Eq (4), which makes it hard to follow. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Sections 3 and 4, which should be the main contributions of the paper, are squeezed into a single page. It further specifies that the lack of precise mathematical definitions for the quantum states in Eq (4) makes it hard to follow. This claim is 3 as it provides a specific example of what is missing, but it lacks detailed reasoning or references to support the assertion that Sections 3 and 4 should be the main contributions. The comment suggests that the authors should expand these sections, but it does not fully substantiate the claim that they are the main contributions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that Sections 3 and 4, which should be the main contributions, are squeezed into a single page. It points out the lack of precise mathematical definitions for the quantum states in Eq (4), which makes it hard to follow. This feedback is clear and actionable, as it provides a concrete area for improvement by suggesting that the authors should expand these sections to include the missing definitions. However, the comment could be more helpful if it offered suggestions on how to present these definitions or provided examples of similar work that addresses this issue. Overall, the comment is 4 as it directs the authors to a critical area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of the results with respect to underrepresented groups, specifically mentioning females and blacks. It implies that the authors should consider whether these groups are discriminated against by the recommendations of LLMs. However, the comment does not provide explicit guidance on how to address this concern or what specific actions the authors should take to investigate or mitigate potential biases. The action is implicit and somewhat vague, as the authors need to infer that they should investigate fairness issues and potentially make adjustments to their methodology or analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the fairness of the results with respect to underrepresented groups, specifically mentioning females and blacks. However, it does not specify which part of the paper this concern pertains to, such as the methodology, results, or discussion sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its concern about fairness, it is 1 because it does not indicate where in the paper this issue should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the fairness of the results with respect to underrepresented groups, specifically mentioning females and blacks. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that there might be discrimination. The comment lacks specific examples or detailed analysis to justify the concern, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the fairness of the results with respect to underrepresented groups, specifically mentioning females and blacks. This is a relevant concern that the authors should address to ensure their work is inclusive and equitable. However, the comment lacks specificity and does not provide actionable guidance on how the authors might investigate or mitigate potential biases. It does not suggest specific methods or analyses that could be employed to address the issue, leaving the authors with a general direction but without detailed steps to take. Therefore, the comment is 3, as it identifies an important area for consideration but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides several minor comments, each of which suggests specific improvements. First, it notes that the paragraph on Covariance in Section 1 is too long, which affects the legibility of the paper. Second, it points out that the paper only provides two illustrations for generating two types of longtailed datasets, suggesting that more details should be added to support the experiments on longtailed datasets. Third, it mentions that the tables and figures are dense due to limited pages, suggesting that more pages could be allocated to the experiments on longtailed datasets. Each comment is explicit and provides concrete guidance on how to improve the draft, making the feedback 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1\" and \"the paragraph that describes Covariance,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the paragraph\"s length, which affects legibility, and suggests adding more details to the experiments on longtailed datasets. Additionally, it mentions the density of tables and figures due to limited pages, suggesting that more pages could be allocated to the experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of three separate comments, each addressing a specific aspect of the paper. The first comment suggests that the paragraph on Covariance in Section 1 is too long, which affects legibility. This is a subjective opinion based on the reviewer\"s perception of the paragraph\"s length, but it lacks specific evidence or examples to support the claim. The second comment notes that the paper only provides two illustrations for generating two types of longtailed datasets, suggesting that more details are needed to support the experiments on longtailed datasets. This is a logical observation but lacks specific examples or references to substantiate the claim. The third comment mentions the density of tables and figures due to limited pages, suggesting that more pages could be allocated to the experiments on longtailed datasets. This is a factual observation without an opinion or suggestion for improvement. Overall, the review point consists of a mix of subjective opinions, logical observations, and factual statements, making it difficult to classify as a single claim. Therefore, it is best categorized as \"No.\"", "helpfulness_rationale": "The review comment provides several specific and actionable suggestions for improving the paper. It identifies a potential issue with the legibility of the paper due to a long paragraph in Section 1, which could be addressed by restructuring or condensing the content. It also highlights the importance of the experiments on longtailed datasets, suggesting that more details should be added to support this contribution. Additionally, the comment notes the density of tables and figures due to limited pages, suggesting that more space could be allocated to these sections. These suggestions are clear and provide the authors with concrete steps to enhance the clarity and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the necessary changes to make ECDiffusers work on realworld data. While it implies that the authors should consider these changes, it does not provide explicit guidance or suggestions on how to address this issue. The action is implicit and somewhat vague, as the authors are left to infer what specific changes might be needed and how to implement them. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment poses a question about the necessary changes to make ECDiffusers work on realworld data. However, it does not specify which part of the paper this question pertains to, nor does it provide details on what specific aspects of the ECDiffusers need to be addressed or improved. Without explicit references to sections or examples, the authors cannot confidently determine which part of the paper the comment addresses. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification on the necessary changes to make ECDiffusers work on realworld data. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the necessary changes to make ECDiffusers work on realworld data. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. The comment does not offer actionable feedback or insights that would help the authors improve their draft. As a result, it is 2, as it points out a potential area of concern but does not provide the authors with a clear path forward."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reliability of the evaluation and suggests that a human study might be needed to assess the efficacy of the evaluation protocol. However, it does not provide explicit instructions or concrete suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should consider conducting a human study or providing additional evidence to support the evaluation protocol\"s reliability. Additionally, the comment lacks specific guidance on how to conduct such a study or what aspects to focus on. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment raises a question about the reliability of the evaluation and suggests a potential need for a human study to assess the efficacy of the evaluation protocol. However, it does not specify which part of the paper this concern pertains to, such as the methodology or results sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Additionally, while the comment suggests a specific area for improvement (the need for a human study), it does not provide detailed guidance on how to conduct such a study or what aspects to focus on. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the reliability of the evaluation and suggests that a human study might be needed to assess the efficacy of the evaluation protocol. However, the comment does not provide any supporting evidence, reasoning, or references to justify why a human study is necessary or how it would improve the evaluation. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a critical question about the reliability of the evaluation and suggests that a human study might be needed to assess the efficacy of the evaluation protocol. This is a relevant concern that could impact the validity and credibility of the results. However, the comment lacks specificity and does not provide detailed guidance on how to conduct such a study or what aspects to focus on. While it identifies an important area for improvement, the feedback could be more actionable and helpful by offering suggestions or examples on how to address the issue. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the novelty of the work, specifically comparing it to prior work. However, it does not provide any explicit or implicit actions for the authors to take in response to this concern. There is no guidance on how the authors might address the perceived lack of novelty or what specific aspects of their work could be improved to enhance its originality. Without actionable suggestions or a clear direction for improvement, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the novelty of the work, specifically comparing it to prior work. However, it does not specify which parts of the paper are being addressed or what aspects of the work are considered incremental. Without explicit references to sections, figures, or specific contributions, the authors cannot confidently determine which parts of the paper need attention. The comment is vague and lacks specificity, making it difficult for the authors to pinpoint the areas that need improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution of the work is somewhat incremental compared to prior work. However, it does not provide specific examples or detailed comparisons to substantiate this claim. The mention of prior work (von Kugelgen et al. 2021; Daunhawer et al. 2023) is a starting point, but without further elaboration or references to specific aspects of the work that are considered incremental, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail for full verification.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the work, specifically comparing it to prior work. However, it does not provide specific examples or detailed analysis of how the current work differs from the prior work, nor does it suggest ways to enhance the novelty or originality of the contribution. Without actionable feedback or guidance, the authors are left without a clear understanding of what aspects of their work need improvement or how to address the perceived lack of novelty. Therefore, the comment is 1, as it does not offer any constructive direction for the authors to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the dependency of PromptMix\"s performance on the quality of questions and answers generated by the LLM. It suggests that an analysis on which opensource LLMs would work with this approach or a parameter count cutoff below which performance would degrade would be beneficial. While the comment implies that the authors should conduct such an analysis, it does not explicitly instruct them to do so. The action is concrete in terms of what needs to be analyzed, but it is implicit in the suggestion to conduct the analysis. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that the performance of PromptMix depends on the quality of questions and answers generated by the LLM, and it implies that an analysis of which opensource LLMs would work with this approach or a parameter count cutoff below which performance would degrade would be beneficial. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what kind of analysis would be beneficial, but without explicit references to sections or parts of the paper, the authors may find it challenging to determine where to incorporate this feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the performance of PromptMix depends on the quality of questions and answers generated by the LLM, and it implies that an analysis of which opensource LLMs would work with this approach or a parameter count cutoff below which performance would degrade would be beneficial. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the performance is dependent on the quality of the LLM. This makes the claim 3, as it provides a general direction for analysis but lacks the necessary details to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s approach, noting that the performance of PromptMix depends on the quality of questions and answers generated by the LLM. It suggests that an analysis of which opensource LLMs would work with this approach or a parameter count cutoff below which performance would degrade would be beneficial. This feedback is clear and actionable, as it provides a specific direction for further analysis that could enhance the paper\"s robustness and applicability. However, the comment could be more helpful if it included examples or references to specific LLMs or parameter counts for comparison. Overall, the comment is 4 as it guides the authors toward a meaningful area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the feasibility of the submodularity approach subroutine, which uses the SATURATE algorithm (Krause et al., 2008) and is said to scale with N^5. It suggests that the authors should comment on the feasibility of this approach and provides a specific example by asking about the runtimes of simulations for large models in Section 6. This feedback is explicit and provides a clear action for the authors to take, which is to address the feasibility of the approach and include runtime data for large models. The suggestion is concrete, as it specifies what information should be included, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"appendix D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the feasibility of the submodularity approach subroutine and suggests that the authors should comment on this aspect. Additionally, it provides a specific example by asking about the runtimes of simulations for large models in Section 6. This level of detail and guidance makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the feasibility of the submodularity approach subroutine, which uses the SATURATE algorithm (Krause et al., 2008) and is said to scale with N^5. The reviewer suggests that the authors should comment on this feasibility and provides a specific example by asking about the runtimes of simulations for large models in Section 6. This request for additional information is logical and provides a clear direction for the authors to address the concern. However, the comment does not include specific references or detailed reasoning to fully substantiate the claim about the feasibility of the approach. Therefore, the comment is 4, as it provides a clear direction but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment raises a concern about the feasibility of the submodularity approach subroutine, which uses the SATURATE algorithm (Krause et al., 2008) and is said to scale with N^5. It suggests that the authors should comment on the feasibility of this approach and provides a specific example by asking about the runtimes of simulations for large models in Section 6. This feedback is actionable and provides a clear direction for the authors to address the issue by including runtime data for large models. However, the comment could be more helpful if it offered additional guidance on how to present or interpret the runtime data. Overall, the comment is 4 as it identifies a potential area for improvement and provides a specific suggestion, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the explanation of inference at test time could be improved with more details. However, it does not provide specific guidance on what additional details should be included or how to enhance the explanation. The action is implicit and somewhat vague, as the authors are left to infer what specific details are needed without explicit instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Inference at test time,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the explanation could be improved with more details. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the explanation of inference at test time could be improved with more details. However, it does not provide specific examples or reasoning to support why additional details are necessary or how they would enhance the explanation. The comment lacks detailed justification or references, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a specific area where the paper could be improved by suggesting that the explanation of inference at test time could benefit from more details. This feedback is 3 as it points out a potential weakness in the paper and encourages the authors to provide additional information. However, it lacks specificity and does not offer detailed guidance on what additional details should be included or how to enhance the explanation. To be more helpful, the comment could provide examples or suggestions for what specific details might be missing. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the correctness and soundness of the paper, specifically regarding the evaluation of programs generated by CodeChain and the effectiveness of submodule generation. It also mentions a slight performance drop in the 5th iteration of selfrevise prompting. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The actions are implicit and vague, as the authors are left to infer what specific changes or improvements are needed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses three specific areas: the evaluation of programs generated by CodeChain, the effectiveness of submodule generation, and the analysis of selfrevise prompting. However, it does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the evaluation, effectiveness, and performance drop, but without explicit references to sections, the authors may find it challenging to pinpoint the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims regarding the correctness and soundness of the paper. It questions the evaluation of programs generated by CodeChain, suggesting that the Likert scale judgment by GPT4 may not align with human preference. It also expresses uncertainty about the effectiveness of submodule generation and notes a slight performance drop in the 5th iteration of selfrevise prompting. However, the comment lacks specific examples, references, or detailed reasoning to support these claims, making it difficult for the authors to understand and address the concerns. The lack of evidence or detailed justification makes the claims 2, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises several concerns about the correctness and soundness of the paper. It questions the evaluation of programs generated by CodeChain, suggesting that the Likert scale judgment by GPT4 may not align with human preference. It also expresses uncertainty about the effectiveness of submodule generation and notes a slight performance drop in the 5th iteration of selfrevise prompting. While the comment identifies important areas for clarification and improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out potential weaknesses, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the interpretation of the authors\" argument regarding deferring classifiers and their impact on subgroup accuracy. It seeks clarification on whether the higher overall accuracy at a given minimum subgroup accuracy implies that the error rates between subgroups are more unevenly distributed for the deferring classifier, potentially making it less fair. While the comment does not explicitly instruct the authors to clarify or address this point, it does imply that the authors should provide further explanation or clarification. The action is implicit and somewhat vague, as it does not specify how the authors should address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 306307, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the interpretation of the authors\" argument regarding deferring classifiers and their impact on subgroup accuracy. The comment provides a logical reasoning and a potential implication of the argument, which helps the authors understand the issue and potentially address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the interpretation of the authors\" argument regarding deferring classifiers and their impact on subgroup accuracy. It seeks clarification on whether the higher overall accuracy at a given minimum subgroup accuracy implies that the error rates between subgroups are more unevenly distributed for the deferring classifier, potentially making it less fair. The comment provides a logical reasoning and a potential implication of the argument, but it does not offer specific evidence or references to support the claim. While the reasoning is clear, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the interpretation of the authors\" argument regarding deferring classifiers and their impact on subgroup accuracy. It seeks clarification on whether the higher overall accuracy at a given minimum subgroup accuracy implies that the error rates between subgroups are more unevenly distributed for the deferring classifier, potentially making it less fair. This feedback is valuable as it prompts the authors to reconsider their argument and potentially address any misconceptions or implications in their analysis. However, the comment could be more helpful if it provided additional context or suggestions on how to clarify or address the issue. Overall, the comment is 3 as it identifies a potential area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a gap in the paper, noting that the claim about the relational embedding module improving object classification lacks supporting evidence. It suggests that the authors should report the improvement on object classification directly, in addition to the overall scene graph results. This feedback provides a clear and concrete action for the authors to take, ensuring that they can directly address the issue by including the requested results. The comment is explicit and provides specific guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 107, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim about the relational embedding module improving object classification, noting the lack of supporting results. The comment suggests that the authors should report the improvement on object classification directly, in addition to the overall scene graph results. This provides clear guidance on what needs to be addressed to strengthen the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks supporting evidence for the claim that the relational embedding module significantly improves object classification. The reviewer suggests that reporting the improvement on object classification directly would strengthen the paper. This claim is 3 as it highlights a gap in the paper\"s presentation of results, but it lacks specific examples or references to support the assertion that the relational embedding module does indeed improve object classification. The comment provides a logical suggestion for improvement but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the claim about the relational embedding module improving object classification lacks supporting evidence. It suggests that the authors should report the improvement on object classification directly, in addition to the overall scene graph results. This feedback is clear and actionable, providing the authors with a concrete step to take to strengthen their paper. By addressing this gap, the authors can enhance the credibility and impact of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point provides a comparison between the current manuscript and a previous work on hypergraph attention networks for multimodal learning. It highlights that the novelty of the current manuscript lies in adding selfsupervised learning on top of existing work, which is considered a relatively small contribution. While the comment identifies a potential limitation in the scope of the manuscript, it does not provide explicit guidance or suggestions for how the authors might address this issue or enhance the novelty of their work. The action is implicit and vague, as the authors are left without clear direction on how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the scope of the paper, which is combining selfsupervised learning with multimodal representation learning based on hypergraph. It also references a specific paper, \"Hypergraph Attention Networks for Multimodal Learning,\" which allows the authors to identify the part of the paper being addressed. The comment is specific because it compares the current manuscript to the referenced paper, highlighting the novelty of adding selfsupervised learning on top of existing work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the scope of the paper is narrow, as it combines selfsupervised learning with multimodal representation learning based on hypergraph, and that this novelty is relatively small compared to existing work. The reviewer supports this claim by referencing a specific paper, \"Hypergraph Attention Networks for Multimodal Learning,\" which explores similar concepts. This external reference provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a comparative analysis of the current manuscript with a previous work on hypergraph attention networks for multimodal learning. It highlights that the novelty of the current manuscript lies in adding selfsupervised learning on top of existing work, which is considered a relatively small contribution. While the comment identifies a potential limitation in the scope of the manuscript, it does not offer specific suggestions or guidance on how the authors might enhance the novelty or broaden the scope of their work. The feedback is 3 as it points out a weakness, but it lacks actionable advice, making it difficult for the authors to effectively address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the difficulty of finding intuitive attention examples, as shown in Figure 4. However, it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should address this issue, how they might find more intuitive examples, or if it is a concern that needs attention. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the difficulty of finding intuitive attention examples as shown in Figure 4. However, it does not specify which part of the paper this figure is located in, making it difficult for the authors to pinpoint the exact section being addressed. Additionally, the comment lacks specificity regarding what is unclear or what needs to be addressed. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the difficulty of finding intuitive attention examples as shown in Figure 4. It does not contain any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the difficulty of finding intuitive attention examples as shown in Figure 4. While it identifies a potential area of concern, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this issue or what specific aspects of the examples might be unclear or unhelpful. Without actionable advice or detailed feedback, the comment does not effectively support the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification regarding the difference between 01 and 10 in Figure 1. This is an explicit question that directly prompts the authors to provide an explanation or clarification. The action is clear and concrete, as it specifies exactly what the authors need to address. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the difference between 01 and 10 in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual question seeking clarification about the difference between 01 and 10 in Figure 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is a factual question seeking clarification about the difference between 01 and 10 in Figure 1. While it does not provide an opinion or suggestion for improvement, it does highlight a specific area where the authors may need to provide additional explanation or clarification. This feedback is 3 as it prompts the authors to address a potential ambiguity in their work, but it lacks depth and does not offer broader guidance for improving the draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to keep a separate \"Related Work\" section and suggests shifting the bullet points \"Traditional AES,\" \"Deep Neural AES,\" and \"Pretraining AES\" from the \"Introduction\" section to the \"Related Work\" section. This provides clear and direct guidance on what needs to be done to improve the draft. The action is explicit and concrete, as the authors know exactly what changes to make to align with the reviewer\"s suggestion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Introduction\" section of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by suggesting that the \"Related Work\" section should be separate and that the bullet points \"Traditional AES,\" \"Deep Neural AES,\" and \"Pretraining AES\" should be moved to the \"Related Work\" section. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests separating the \"Related Work\" section from the \"Introduction\" section and moving specific bullet points to the \"Related Work\" section. However, it does not provide any reasoning or evidence to support why this separation is necessary or beneficial. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the \"Related Work\" section should be separated from the \"Introduction\" section. It identifies a specific issue with the current structure, where the \"Introduction\" section includes both introductory content and related work, which can be confusing for readers. The comment offers a concrete suggestion to move the bullet points \"Traditional AES,\" \"Deep Neural AES,\" and \"Pretraining AES\" to the \"Related Work\" section, which would improve the organization and clarity of the paper. This feedback is detailed and actionable, making it 5 for the authors to enhance the structure and readability of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper spends a significant amount of space describing the rules and data augmentation methods used in constructing the benchmark, but suggests that the overall process and rationale for construction could be presented more clearly. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so or offer specific guidance on how to improve the clarity. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the clarity of the construction process but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s dedication to describing rules and data augmentation methods used in constructing the benchmark, suggesting that the overall process and rationale for construction could be presented more clearly. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure, making it weakly grounded. The comment is specific in identifying the need for clearer presentation of the overall process and rationale, but without explicit references to specific sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper spends significant space describing rules and data augmentation methods used in constructing the benchmark, but suggests that the overall process and rationale for construction could be presented more clearly. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand exactly what aspects of the construction process are unclear or how they could be improved. Without additional context or examples, the claim remains vague and 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, noting that while it dedicates significant space to describing rules and data augmentation methods used in constructing the benchmark, the overall process and rationale for construction could be presented more clearly. This feedback is 3 as it points out a potential weakness in the paper\"s organization and suggests a way to enhance its clarity. However, the comment lacks detailed guidance or suggestions on how to achieve this clarity, such as specific examples of what aspects of the process or rationale should be emphasized. To be more helpful, the comment could include actionable advice or examples to assist the authors in making the necessary improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several areas where the paper lacks content, specifically mentioning the absence of literature reviews on recent advances in active learning communities, particularly in the context of Bayesian learning. It points out the relevance of Bayesian Coreset, which is directly related to the work but is not discussed in the literature review. Additionally, the comment suggests discussing how the current setup is more advanced than related studies, referencing specific works. While the comment implies that the authors should include these discussions, it does not provide explicit instructions on how to incorporate them or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of content in the paper, specifically pointing out the absence of literature reviews on recent advances in active learning communities, particularly in the context of Bayesian learning. It references specific examples, such as Bayesian Coreset, which is directly relevant to the work but is not discussed in the literature review. Additionally, the comment suggests discussing how the current setup is more advanced than related studies, referencing specific works. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks content, specifically mentioning the absence of literature reviews on recent advances in active learning communities, particularly in the context of Bayesian learning. It references specific examples, such as Bayesian Coreset, which is directly relevant to the work but is not discussed in the literature review. Additionally, the comment suggests discussing how the current setup is more advanced than related studies, referencing specific works. This provides a clear and specific basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several areas where the paper lacks content, specifically in the literature review of recent advances in active learning communities, particularly in the context of Bayesian learning. It points out the omission of relevant works like Bayesian Coreset, which is directly related to the paper\"s focus, and suggests discussing how the current setup is more advanced than related studies. This feedback is clear and actionable, as it provides specific examples of what the authors should include in their literature review to enhance the paper\"s depth and relevance. However, the comment could be more helpful if it offered suggestions on how to integrate these references or discussed potential benefits of including them. Overall, the comment is 4, as it directs the authors to improve their draft by addressing critical gaps in the literature review."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the \"onetomany relationship\" in Figure 2 makes it difficult to understand the presented trends and that the plots contain a significant amount of noise. However, it does not provide any explicit or implicit suggestions on how to address these issues or improve the clarity of the figure. The authors are left without guidance on how to enhance the figure or reduce the noise, making it difficult for them to take actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely the \"onetomany relationship\" and the presence of noise, which makes it difficult to understand the presented trends. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"onetomany relationship\" in Figure 2 makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. However, the comment does not provide any specific reasoning, examples, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that the \"onetomany relationship\" makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. This feedback is 3 as it points out a potential problem with the visual representation of the data, which could impact the clarity and effectiveness of the figure. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues, such as recommending ways to improve the figure or reduce the noise. While it highlights an area for improvement, the feedback could be more helpful with additional detail or specific advice. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns and questions about the comparison of DFSSATTEN with existing algorithms like Performer and Reformer. It suggests that the speedup given by DFSSATTEN is mostly due to lowlevel optimization and hardware support, which might make a direct comparison unfair. The comment also questions whether DFSSATTEN supports training from scratch, given the authors\" argument that existing methods are often trained from scratch. The reviewer provides a suggestion for DFSSATTEN to accelerate training from scratch, but this is not studied in the paper. While the comment raises important questions and suggests a potential direction for improvement, it does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors need to infer that they should address the issues raised and consider the suggested improvements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it details the issue of comparing DFSSATTEN with existing algorithms like Performer and Reformer, questioning the fairness of the comparison due to the lack of deep optimization. The comment further highlights the importance of training from scratch, given the popularity and significance of pretraining, and suggests that DFSSATTEN should support training from scratch. This provides clear guidance on what needs to be addressed in the introduction section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the speedup of DFSSATTEN being mostly due to lowlevel optimization and hardware support, suggesting that this might make a direct comparison with existing algorithms like Performer and Reformer unfair. The reviewer also questions whether DFSSATTEN supports training from scratch, given the authors\" argument that existing methods are often trained from scratch. While the comment provides some reasoning, it lacks specific examples or references to support the claim about the unfairness of the comparison or the need for DFSSATTEN to support training from scratch. This makes the claim 3, as it requires more detailed evidence or examples to fully substantiate the points being made.", "helpfulness_rationale": "The review comment raises several important points and questions that could help the authors improve their draft. It highlights the potential unfairness of comparing DFSSATTEN with existing algorithms like Performer and Reformer due to the lack of deep optimization, suggesting that this might impact the speedup claimed by DFSSATTEN. The comment also questions whether DFSSATTEN supports training from scratch, given the authors\" argument that existing methods are often trained from scratch. This is an important consideration, especially in light of the growing importance of pretraining. The reviewer provides a clear suggestion for DFSSATTEN to accelerate training from scratch, which could be a valuable addition to the paper. However, the comment could be more helpful if it offered specific guidance on how to address these issues or provided examples of how to optimize DFSSATTEN for training from scratch. Overall, the comment is 4 as it identifies key areas for improvement and provides a direction for further exploration, but it could be more comprehensive with additional details and suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point mentions that VMISITIDIFDSM was evaluated on a blackbox setting when their method was evaluated on a defended model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation, whether it is a concern or a suggestion for improvement, or what specific changes should be made. As a result, the comment lacks actionability and does not provide the authors with any direction for improving their draft. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment mentions \"VMISITIDIFDSM\" and \"blackbox setting,\" which provides some context for the authors to identify the part of the paper being addressed. However, it does not specify which section or subsection this evaluation is discussed in, making it weakly grounded. The comment is specific in pointing out the evaluation on a blackbox setting when the method was evaluated on a defended model, but it lacks detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that VMISITIDIFDSM was evaluated on a blackbox setting when their method was evaluated on a defended model. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific issue with the evaluation of VMISITIDIFDSM, noting that it was conducted on a blackbox setting when the method was evaluated on a defended model. However, the comment does not provide any context, explanation, or suggestions for how this observation might impact the results or the interpretation of the findings. Without additional guidance or insight, the authors are left without a clear understanding of the significance of this observation or how to address it. As a result, the comment is 1, as it lacks actionable feedback or constructive suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the clarity of the proposed method\"s description could be improved, and it directs the authors to the questions section for details. However, it does not provide specific guidance on how to improve the clarity or what aspects of the description need clarification. The action is implicit and somewhat vague, as the authors are left to infer what changes are needed without explicit instructions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the clarity of the proposed method\"s description could be improved, but it does not specify which part of the paper this issue pertains to. It refers to the \"questions section,\" but this is not a specific part of the paper, making it difficult for the authors to pinpoint the exact area needing improvement. The comment is vague and lacks specificity, as it does not provide detailed guidance on what aspects of the description need clarification. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the clarity of the proposed method\"s description could be improved. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand what aspects of the description are unclear or how to improve them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the clarity of the proposed method\"s description, suggesting that it could be improved. However, it does not provide specific guidance or examples of what aspects of the description are unclear or how they could be clarified. Without detailed feedback or suggestions, the authors are left with a general direction but no actionable steps to enhance the clarity of their work. This lack of specificity makes the comment 2, as it does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the independence of the pruning strategy across different layers in the GNN and suggests that if an edge is pruned in one layer, it should be pruned in other layers as well. It asks whether such observations are made in the empirical evaluations or if the authors can explain why such correlations are not considered. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the question or what kind of analysis or explanation is needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the independence of the pruning strategy across different layers in the GNN and suggests that if an edge is pruned in one layer, it should be pruned in other layers as well. It asks whether such observations are made in the empirical evaluations or if the authors can explain why such correlations are not considered. However, the comment does not specify which part of the paper discusses the pruning strategy or where the authors should address this issue. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in its question about the pruning strategy, but without clear grounding, it aligns with a score of 2.", "verifiability_rationale": "The review point raises a question about the independence of the pruning strategy across different layers in the GNN and suggests that if an edge is pruned in one layer, it should be pruned in other layers as well. The comment does not contain a claim or opinion but rather poses a question seeking clarification or further explanation. It does not present any subjective judgments or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an interesting question about the independence of the pruning strategy across different layers in the GNN. It suggests that if an edge is pruned in one layer, it should be pruned in other layers as well, and asks whether such observations are made in the empirical evaluations or if the authors can explain why such correlations are not considered. This feedback is 3 as it prompts the authors to consider a potential correlation between layers that could impact the pruning strategy. However, the comment lacks specific guidance on how to address this issue or what kind of analysis or explanation would be most beneficial. To be more helpful, the comment could suggest ways to explore this correlation or provide examples of how it might impact the results. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the experimental validation, noting that it only considers CIFAR10/100 as indistribution data. The reviewer questions whether the conclusions would generalize to other indistribution datasets and suggests that some nuance might be needed. However, the comment does not provide explicit guidance on how the authors should address this issue or whether they should consider additional datasets. The action is implicit and somewhat vague, as the authors are left to infer that they might need to expand their experimental validation to other datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental validation, specifically mentioning that it only considers CIFAR10/100 as indistribution data. This provides full grounding as it explicitly references a specific aspect of the paper, allowing the authors to accurately identify the part being addressed. The comment is also specific because it raises a concern about the generalizability of the conclusions to other indistribution datasets and suggests that some nuance might be needed. However, it does not provide explicit guidance on how to address this issue or suggest specific datasets to consider. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the experimental validation, noting that it only considers CIFAR10/100 as indistribution data. The reviewer questions whether the conclusions would generalize to other indistribution datasets and suggests that some nuance might be needed. However, the comment does not provide specific examples or references to support this claim, making it 3. The suggestion to consider other datasets is logical, but the lack of detailed reasoning or evidence limits the comprehensiveness of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the experimental results, noting that the validation only considers CIFAR10/100 as indistribution data. It questions whether the conclusions would hold for other indistribution datasets and suggests that some nuance might be needed. This feedback is clear and actionable, as it prompts the authors to consider expanding their experimental validation to other datasets to ensure the robustness of their findings. However, the comment could be more helpful if it provided specific suggestions on which datasets to consider or how to address the issue of generalizability. Overall, the comment is 4, as it identifies a critical area for improvement and guides the authors toward enhancing the validity of their results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alphadivergence to provide insights. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not provide detailed guidance on how to calculate or present the gradient conflicts ratio. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alphadivergence to provide insights. This provides clear guidance on what additional information should be included to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that AlphaNets trained with alphadivergence do not benefit from the method presented in the paper. The reviewer provides a specific observation from Table 8, which implies that the method is not effective for this particular case. However, the comment lacks detailed reasoning or evidence to support why this observation is significant or how it relates to the overall effectiveness of the method. Without additional context or analysis, the claim remains 3, as it provides a basis for further exploration but lacks comprehensive justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 8, suggesting that AlphaNets trained with alphadivergence do not benefit from the method described in the paper. It provides a clear and actionable suggestion by recommending that the authors show the gradient conflicts ratio for this particular case, which could offer insights into the effectiveness of the method. This feedback is valuable as it directs the authors to a potential area of improvement in their analysis and presentation of results. However, the comment could be more helpful if it provided additional context or explanation on why the gradient conflicts ratio is important or how it might impact the interpretation of the results. Overall, the comment is 4, as it offers a clear direction for enhancing the paper, but it could be more comprehensive with further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the explicit SDF supervision in Section 3.2, specifically questioning the need for occlusion handling and viewawareness. The reviewer suggests that a simpler approach could be to sample a subset of the sparse point cloud and apply the loss on the 3D location without occlusion reasoning. The comment implies that the authors should provide a good reason or conduct an ablation study to justify the current setup. While the comment identifies an area for improvement, it does not provide explicit instructions on how to address the issue or conduct the suggested ablation study. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, including \"Sec. 3.2\" and line numbers \"L. 165,\" \"L. 173,\" and \"L. 177  178,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by questioning the need for occlusion handling and viewawareness in the explicit SDF supervision and suggests a simpler approach. The comment further implies that a good reason or ablation study is missing to justify the current setup. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with a score of 5.", "verifiability_rationale": "The review point questions the necessity of explicit SDF supervision with occlusion handling and viewawareness, suggesting a simpler approach. The reviewer provides a logical reasoning by stating that a subset of the sparse point cloud could be sampled and the loss applied without occlusion reasoning, which seems more straightforward. However, the comment lacks specific examples or references to support the claim that the current setup is unnecessarily complex. While the reasoning is clear, the absence of detailed evidence or references makes the claim 3, as the authors may need to further substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the explicit SDF supervision in Section 3.2, questioning the need for occlusion handling and viewawareness. It suggests a simpler approach by sampling a subset of the sparse point cloud and applying the loss without occlusion reasoning. The comment implies that the authors should provide a good reason or conduct an ablation study to justify the current setup, which is a clear and actionable suggestion for improvement. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to conduct the ablation study or what aspects to focus on. Overall, the feedback is 4 as it directs the authors to a critical area that requires further justification or experimentation."}
